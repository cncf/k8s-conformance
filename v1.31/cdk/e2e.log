  I0904 17:58:12.688406      19 e2e.go:109] Starting e2e run "2c9e080d-826b-49f6-9d11-79341a950aa0" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1725472692 - will randomize all specs

Will run 404 of 6603 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:154
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0904 17:58:12.851404 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 17:58:12.856872 19 helper.go:48] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0904 17:58:12.897471 19 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0904 17:58:12.902926 19 e2e.go:153] 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  I0904 17:58:12.903169 19 e2e.go:245] e2e test version: v1.31.0
  I0904 17:58:12.905004 19 e2e.go:254] kube-apiserver version: v1.31.0
  I0904 17:58:12.905231 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 17:58:12.910428 19 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.059 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 09/04/24 17:58:13.138
  I0904 17:58:13.138254 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/04/24 17:58:13.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:58:13.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:58:13.157
  STEP: create the container to handle the HTTPGet hook request. @ 09/04/24 17:58:13.164
  STEP: create the pod with lifecycle hook @ 09/04/24 17:58:19.197
  STEP: delete the pod with lifecycle hook @ 09/04/24 17:58:21.215
  STEP: check prestop hook @ 09/04/24 17:58:45.289
  I0904 17:58:45.308857 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1562" for this suite. @ 09/04/24 17:58:45.313
• [32.181 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 09/04/24 17:58:45.319
  I0904 17:58:45.319704 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 17:58:45.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:58:45.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:58:45.34
  STEP: Creating secret with name secret-test-map-da2dcc21-847a-4589-96fc-b3ae1a3c7ac0 @ 09/04/24 17:58:45.343
  STEP: Creating a pod to test consume secrets @ 09/04/24 17:58:45.348
  STEP: Saw pod success @ 09/04/24 17:58:51.375
  I0904 17:58:51.380219 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-secrets-ba23bbee-4d35-4e3e-b5f3-3af6a6e77388 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 17:58:51.395
  I0904 17:58:51.413917 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5916" for this suite. @ 09/04/24 17:58:51.417
• [6.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:348
  STEP: Creating a kubernetes client @ 09/04/24 17:58:51.423
  I0904 17:58:51.423245 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename field-validation @ 09/04/24 17:58:51.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:58:51.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:58:51.444
  I0904 17:58:51.448123 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  W0904 17:58:51.448726      19 field_validation.go:421] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0008137b0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W0904 17:58:53.993274      19 warnings.go:70] unknown field "alpha"
  W0904 17:58:53.993296      19 warnings.go:70] unknown field "beta"
  W0904 17:58:53.993299      19 warnings.go:70] unknown field "delta"
  W0904 17:58:53.993305      19 warnings.go:70] unknown field "epsilon"
  W0904 17:58:53.993308      19 warnings.go:70] unknown field "gamma"
  I0904 17:58:54.541958 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7047" for this suite. @ 09/04/24 17:58:54.546
• [3.129 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 09/04/24 17:58:54.552
  I0904 17:58:54.552487 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 17:58:54.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:58:54.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:58:54.574
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 17:58:54.582
  STEP: Saw pod success @ 09/04/24 17:58:58.607
  I0904 17:58:58.611164 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-5cdf5fc9-fed2-4f12-b29f-e178177a26a4 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 17:58:58.617
  I0904 17:58:58.633285 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9377" for this suite. @ 09/04/24 17:58:58.636
• [4.092 seconds]
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:821
  STEP: Creating a kubernetes client @ 09/04/24 17:58:58.644
  I0904 17:58:58.644474 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 17:58:58.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:58:58.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:58:58.663
  STEP: creating service multi-endpoint-test in namespace services-2252 @ 09/04/24 17:58:58.666
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2252 to expose endpoints map[] @ 09/04/24 17:58:58.682
  I0904 17:58:58.692189 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2252 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2252 @ 09/04/24 17:58:58.692
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2252 to expose endpoints map[pod1:[100]] @ 09/04/24 17:59:00.716
  I0904 17:59:00.728423 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2252 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-2252 @ 09/04/24 17:59:00.728
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2252 to expose endpoints map[pod1:[100] pod2:[101]] @ 09/04/24 17:59:02.747
  I0904 17:59:02.763871 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2252 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 09/04/24 17:59:02.763
  I0904 17:59:02.763926 19 resource.go:361] Creating new exec pod
  I0904 17:59:05.781628 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-2252 exec execpod52d95 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0904 17:59:05.884275 19 builder.go:146] stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  I0904 17:59:05.884314 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 17:59:05.884493 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-2252 exec execpod52d95 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.42 80'
  I0904 17:59:05.970880 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.42 80\nConnection to 10.152.183.42 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0904 17:59:05.970925 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 17:59:05.971000 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-2252 exec execpod52d95 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0904 17:59:06.061752 19 builder.go:146] stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  I0904 17:59:06.061801 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 17:59:06.061875 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-2252 exec execpod52d95 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.42 81'
  I0904 17:59:06.148691 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.42 81\n+ echo hostName\nConnection to 10.152.183.42 81 port [tcp/*] succeeded!\n"
  I0904 17:59:06.148737 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2252 @ 09/04/24 17:59:06.148
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2252 to expose endpoints map[pod2:[101]] @ 09/04/24 17:59:06.167
  I0904 17:59:06.183224 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2252 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-2252 @ 09/04/24 17:59:06.183
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2252 to expose endpoints map[] @ 09/04/24 17:59:06.202
  I0904 17:59:06.214862 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2252 exposes endpoints map[]
  I0904 17:59:06.231888 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2252" for this suite. @ 09/04/24 17:59:06.237
• [7.598 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 09/04/24 17:59:06.242
  I0904 17:59:06.242560 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename namespaces @ 09/04/24 17:59:06.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:59:06.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:59:06.262
  STEP: creating a Namespace @ 09/04/24 17:59:06.265
  STEP: patching the Namespace @ 09/04/24 17:59:06.279
  STEP: get the Namespace and ensuring it has the label @ 09/04/24 17:59:06.287
  I0904 17:59:06.294953 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-602" for this suite. @ 09/04/24 17:59:06.298
  STEP: Destroying namespace "nspatchtest-ffcd7504-659e-4556-a509-0ca5355f2927-1063" for this suite. @ 09/04/24 17:59:06.303
• [0.069 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 09/04/24 17:59:06.311
  I0904 17:59:06.311394 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/04/24 17:59:06.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:59:06.331
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:59:06.335
  I0904 17:59:06.338777 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 17:59:06.880684 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2260" for this suite. @ 09/04/24 17:59:06.886
• [0.584 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 09/04/24 17:59:06.895
  I0904 17:59:06.895598 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 17:59:06.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:59:06.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:59:06.915
  STEP: Creating configMap with name configmap-test-upd-92d2b6a6-d084-4521-82fa-f645a7ded5ca @ 09/04/24 17:59:06.923
  STEP: Creating the pod @ 09/04/24 17:59:06.927
  STEP: Waiting for pod with text data @ 09/04/24 17:59:10.952
  STEP: Waiting for pod with binary data @ 09/04/24 17:59:10.959
  I0904 17:59:10.965617 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3016" for this suite. @ 09/04/24 17:59:10.969
• [4.083 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 09/04/24 17:59:10.978
  I0904 17:59:10.978598 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename runtimeclass @ 09/04/24 17:59:10.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:59:10.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:59:10.997
  I0904 17:59:11.025146 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3484" for this suite. @ 09/04/24 17:59:11.029
• [0.060 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 09/04/24 17:59:11.038
  I0904 17:59:11.038442 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replicaset @ 09/04/24 17:59:11.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:59:11.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:59:11.06
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 09/04/24 17:59:11.064
  STEP: When a replicaset with a matching selector is created @ 09/04/24 17:59:15.094
  STEP: Then the orphan pod is adopted @ 09/04/24 17:59:15.101
  STEP: When the matched label of one of its pods change @ 09/04/24 17:59:16.109
  I0904 17:59:16.112843 19 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 09/04/24 17:59:16.123
  I0904 17:59:17.134069 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7062" for this suite. @ 09/04/24 17:59:17.137
• [6.111 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:235
  STEP: Creating a kubernetes client @ 09/04/24 17:59:17.149
  I0904 17:59:17.149600 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 17:59:17.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:59:17.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:59:17.185
  STEP: Counting existing ResourceQuota @ 09/04/24 17:59:17.189
  STEP: Creating a ResourceQuota @ 09/04/24 17:59:22.193
  STEP: Ensuring resource quota status is calculated @ 09/04/24 17:59:22.197
  STEP: Creating a Pod that fits quota @ 09/04/24 17:59:24.203
  STEP: Ensuring ResourceQuota status captures the pod usage @ 09/04/24 17:59:24.218
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 09/04/24 17:59:26.223
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 09/04/24 17:59:26.225
  STEP: Ensuring a pod cannot update its resource requirements @ 09/04/24 17:59:26.228
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 09/04/24 17:59:26.232
  STEP: Deleting the pod @ 09/04/24 17:59:28.236
  STEP: Ensuring resource quota status released the pod usage @ 09/04/24 17:59:28.26
  I0904 17:59:30.266863 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8635" for this suite. @ 09/04/24 17:59:30.271
• [13.128 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 09/04/24 17:59:30.278
  I0904 17:59:30.278099 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 17:59:30.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:59:30.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:59:30.296
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 17:59:30.299
  STEP: Saw pod success @ 09/04/24 17:59:32.32
  I0904 17:59:32.324064 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-38afffdb-23e2-481a-8ca5-17c5da20f98c container client-container: <nil>
  STEP: delete the pod @ 09/04/24 17:59:32.331
  I0904 17:59:32.350125 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8615" for this suite. @ 09/04/24 17:59:32.354
• [2.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 09/04/24 17:59:32.361
  I0904 17:59:32.361739 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename cronjob @ 09/04/24 17:59:32.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 17:59:32.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 17:59:32.382
  STEP: Creating a ReplaceConcurrent cronjob @ 09/04/24 17:59:32.385
  STEP: Ensuring a job is scheduled @ 09/04/24 17:59:32.39
  STEP: Ensuring exactly one is scheduled @ 09/04/24 18:00:00.395
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 09/04/24 18:00:00.398
  STEP: Ensuring the job is replaced with a new one @ 09/04/24 18:00:00.402
  STEP: Removing cronjob @ 09/04/24 18:01:00.407
  I0904 18:01:00.413441 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9379" for this suite. @ 09/04/24 18:01:00.417
• [88.066 seconds]
------------------------------
SSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:284
  STEP: Creating a kubernetes client @ 09/04/24 18:01:00.427
  I0904 18:01:00.427633 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename taint-single-pod @ 09/04/24 18:01:00.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:01:00.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:01:00.453
  I0904 18:01:00.456591 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  I0904 18:02:00.457618 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I0904 18:02:00.462424 19 taints.go:144] Starting informer...
  STEP: Starting pod... @ 09/04/24 18:02:00.462
  I0904 18:02:00.678731 19 taints.go:294] Pod is running on ip-172-31-21-169. Tainting Node
  STEP: Trying to apply a taint on the Node @ 09/04/24 18:02:00.678
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/04/24 18:02:00.688
  STEP: Waiting short time to make sure Pod is queued for deletion @ 09/04/24 18:02:00.694
  I0904 18:02:00.694484 19 taints.go:313] Pod wasn't evicted. Proceeding
  I0904 18:02:00.694496 19 taints.go:320] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/04/24 18:02:00.713
  STEP: Waiting some time to make sure that toleration time passed. @ 09/04/24 18:02:00.721
  I0904 18:03:15.722564 19 taints.go:329] Pod wasn't evicted. Test successful
  I0904 18:03:15.722807 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-736" for this suite. @ 09/04/24 18:03:15.728
• [135.307 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3184
  STEP: Creating a kubernetes client @ 09/04/24 18:03:15.734
  I0904 18:03:15.734693 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:03:15.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:15.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:15.76
  STEP: fetching services @ 09/04/24 18:03:15.763
  I0904 18:03:15.767428 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9033" for this suite. @ 09/04/24 18:03:15.77
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 09/04/24 18:03:15.778
  I0904 18:03:15.778415 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:03:15.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:15.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:15.8
  STEP: creating a ConfigMap @ 09/04/24 18:03:15.803
  STEP: fetching the ConfigMap @ 09/04/24 18:03:15.807
  STEP: patching the ConfigMap @ 09/04/24 18:03:15.811
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 09/04/24 18:03:15.817
  STEP: deleting the ConfigMap by collection with a label selector @ 09/04/24 18:03:15.82
  STEP: listing all ConfigMaps in test namespace @ 09/04/24 18:03:15.828
  I0904 18:03:15.831863 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6570" for this suite. @ 09/04/24 18:03:15.835
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:90
  STEP: Creating a kubernetes client @ 09/04/24 18:03:15.84
  I0904 18:03:15.840651 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename disruption @ 09/04/24 18:03:15.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:15.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:15.867
  STEP: Creating a kubernetes client @ 09/04/24 18:03:15.871
  I0904 18:03:15.871847 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename disruption-2 @ 09/04/24 18:03:15.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:15.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:15.893
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:03:15.9
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:03:17.911
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:03:19.923
  STEP: listing a collection of PDBs across all namespaces @ 09/04/24 18:03:21.93
  STEP: listing a collection of PDBs in namespace disruption-5552 @ 09/04/24 18:03:21.933
  STEP: deleting a collection of PDBs @ 09/04/24 18:03:21.937
  STEP: Waiting for the PDB collection to be deleted @ 09/04/24 18:03:21.947
  I0904 18:03:21.950479 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-3163" for this suite. @ 09/04/24 18:03:21.954
  I0904 18:03:21.959497 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5552" for this suite. @ 09/04/24 18:03:21.962
• [6.131 seconds]
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 09/04/24 18:03:21.971
  I0904 18:03:21.971484 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/04/24 18:03:21.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:21.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:21.99
  STEP: creating a policy with variables @ 09/04/24 18:03:22
  STEP: waiting until the marker is denied @ 09/04/24 18:03:22.028
  STEP: testing a replicated Deployment to be allowed @ 09/04/24 18:03:22.938
  STEP: testing a non-replicated ReplicaSet not to be denied @ 09/04/24 18:03:22.952
  I0904 18:03:23.000664 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-1637" for this suite. @ 09/04/24 18:03:23.008
• [1.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 09/04/24 18:03:23.022
  I0904 18:03:23.022594 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename gc @ 09/04/24 18:03:23.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:23.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:23.046
  STEP: create the rc @ 09/04/24 18:03:23.05
  W0904 18:03:23.056165      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 09/04/24 18:03:28.059
  STEP: wait for all pods to be garbage collected @ 09/04/24 18:03:28.065
  STEP: Gathering metrics @ 09/04/24 18:03:33.073
  W0904 18:03:33.079251      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0904 18:03:33.079278 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0904 18:03:33.079492 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1436" for this suite. @ 09/04/24 18:03:33.083
• [10.069 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 09/04/24 18:03:33.092
  I0904 18:03:33.092271 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename gc @ 09/04/24 18:03:33.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:33.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:33.117
  I0904 18:03:33.162993 19 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1b1a5e66-efd4-45fc-a749-1ad308ca0575", Controller:(*bool)(0xc001f2b776), BlockOwnerDeletion:(*bool)(0xc001f2b777)}}
  I0904 18:03:33.176220 19 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"eb2bbf1b-1d60-489d-bf26-be7d05a5dfa7", Controller:(*bool)(0xc00212a9d6), BlockOwnerDeletion:(*bool)(0xc00212a9d7)}}
  I0904 18:03:33.181672 19 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"17e838d6-082b-4bd3-9d89-6b64d5ea1b26", Controller:(*bool)(0xc00212ac16), BlockOwnerDeletion:(*bool)(0xc00212ac17)}}
  I0904 18:03:38.201010 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8904" for this suite. @ 09/04/24 18:03:38.203
• [5.120 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 09/04/24 18:03:38.212
  I0904 18:03:38.212626 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 18:03:38.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:38.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:38.234
  STEP: creating secret secrets-4929/secret-test-7c4919fb-780d-4f54-ac08-58daad78c3cf @ 09/04/24 18:03:38.237
  STEP: Creating a pod to test consume secrets @ 09/04/24 18:03:38.243
  STEP: Saw pod success @ 09/04/24 18:03:42.27
  I0904 18:03:42.275007 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-706237d9-5582-4df9-bf7f-9b1de4c94fc9 container env-test: <nil>
  STEP: delete the pod @ 09/04/24 18:03:42.286
  I0904 18:03:42.305124 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4929" for this suite. @ 09/04/24 18:03:42.309
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 09/04/24 18:03:42.316
  I0904 18:03:42.316346 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 18:03:42.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:42.332
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:42.336
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 09/04/24 18:03:42.339
  I0904 18:03:42.339750 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 09/04/24 18:03:47.457
  I0904 18:03:47.458257 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:03:48.726649 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:03:53.658732 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2123" for this suite. @ 09/04/24 18:03:53.666
• [11.357 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 09/04/24 18:03:53.673
  I0904 18:03:53.673496 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename deployment @ 09/04/24 18:03:53.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:53.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:53.694
  I0904 18:03:53.698806 19 deployment.go:1645] Creating simple deployment test-new-deployment
  I0904 18:03:53.719461 19 deployment.go:222] deployment "test-new-deployment" doesn't have the required revision set
  STEP: getting scale subresource @ 09/04/24 18:03:55.735
  STEP: updating a scale subresource @ 09/04/24 18:03:55.738
  STEP: verifying the deployment Spec.Replicas was modified @ 09/04/24 18:03:55.744
  STEP: Patch a scale subresource @ 09/04/24 18:03:55.748
  I0904 18:03:55.772192 19 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2166",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4e87a923-dc56-4942-b251-2665611ee442",
      ResourceVersion: (string) (len=4) "6744",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861069833,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-64bcfc6446\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0904 18:03:55.779814 19 deployment.go:39] New ReplicaSet "test-new-deployment-64bcfc6446" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-64bcfc6446",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2166",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "63869bc4-acca-4294-a856-b9080312343c",
      ResourceVersion: (string) (len=4) "6750",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861069833,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "4e87a923-dc56-4942-b251-2665611ee442",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 65 38 37 61 39  32 33 2d 64 63 35 36 2d  |\"4e87a923-dc56-|
              00000120  34 39 34 32 2d 62 32 35  31 2d 32 36 36 35 36 31  |4942-b251-266561|
              00000130  31 65 65 34 34 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |1ee442\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:03:55.783533 19 deployment.go:67] Pod "test-new-deployment-64bcfc6446-nvzdp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-64bcfc6446-nvzdp",
      GenerateName: (string) (len=31) "test-new-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2166",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a2164483-9541-463a-b99f-476bdca6dfdb",
      ResourceVersion: (string) (len=4) "6749",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861069835,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "63869bc4-acca-4294-a856-b9080312343c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 33  38 36 39 62 63 34 2d 61  |d\":\"63869bc4-a|
              00000090  63 63 61 2d 34 32 39 34  2d 61 38 35 36 2d 62 39  |cca-4294-a856-b9|
              000000a0  30 38 30 33 31 32 33 34  33 63 5c 22 7d 22 3a 7b  |080312343c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6q9tw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6q9tw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069835,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:03:55.784958 19 deployment.go:67] Pod "test-new-deployment-64bcfc6446-rk49v" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-64bcfc6446-rk49v",
      GenerateName: (string) (len=31) "test-new-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2166",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d7ddf591-8e74-492f-bcea-c96d5e5fccae",
      ResourceVersion: (string) (len=4) "6738",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861069833,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "63869bc4-acca-4294-a856-b9080312343c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 33  38 36 39 62 63 34 2d 61  |d\":\"63869bc4-a|
              00000090  63 63 61 2d 34 32 39 34  2d 61 38 35 36 2d 62 39  |cca-4294-a856-b9|
              000000a0  30 38 30 33 31 32 33 34  33 63 5c 22 7d 22 3a 7b  |080312343c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 34  36 2e 31 34 32 5c 22 7d  |2.168.146.142\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-x74jd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-x74jd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069834,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861069833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.21.169",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.21.169"
        }
      },
      PodIP: (string) (len=15) "192.168.146.142",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.146.142"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861069833,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861069834,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://2f85026ba238ec7880b9e94ff64f291e82dca005e45e50d9bfc2c17dd25a4f91",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-x74jd",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:03:55.786221 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2166" for this suite. @ 09/04/24 18:03:55.794
• [2.156 seconds]
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 09/04/24 18:03:55.829
  I0904 18:03:55.830007 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 18:03:55.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:55.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:55.865
  I0904 18:03:55.874538 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: creating the pod @ 09/04/24 18:03:55.874
  STEP: submitting the pod to kubernetes @ 09/04/24 18:03:55.875
  I0904 18:03:57.965820 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5071" for this suite. @ 09/04/24 18:03:57.97
• [2.149 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:495
  STEP: Creating a kubernetes client @ 09/04/24 18:03:57.979
  I0904 18:03:57.979642 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:03:57.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:03:57.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:03:58.002
  STEP: Setting up server cert @ 09/04/24 18:03:58.027
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:03:58.267
  STEP: Deploying the webhook pod @ 09/04/24 18:03:58.275
  STEP: Wait for the deployment to be ready @ 09/04/24 18:03:58.287
  I0904 18:03:58.302805 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/04/24 18:04:00.316
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:04:00.329
  I0904 18:04:01.330853 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 09/04/24 18:04:01.345
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 09/04/24 18:04:01.377
  STEP: Creating a configMap that should not be mutated @ 09/04/24 18:04:01.386
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 09/04/24 18:04:01.397
  STEP: Creating a configMap that should be mutated @ 09/04/24 18:04:01.404
  I0904 18:04:01.465726 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2068" for this suite. @ 09/04/24 18:04:01.471
  STEP: Destroying namespace "webhook-markers-1300" for this suite. @ 09/04/24 18:04:01.479
• [3.506 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 09/04/24 18:04:01.485
  I0904 18:04:01.485849 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 18:04:01.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:04:01.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:04:01.509
  I0904 18:04:01.558069 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4361" for this suite. @ 09/04/24 18:04:01.56
• [0.080 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 09/04/24 18:04:01.566
  I0904 18:04:01.566334 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename certificates @ 09/04/24 18:04:01.566
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:04:01.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:04:01.584
  STEP: getting /apis @ 09/04/24 18:04:02.011
  STEP: getting /apis/certificates.k8s.io @ 09/04/24 18:04:02.016
  STEP: getting /apis/certificates.k8s.io/v1 @ 09/04/24 18:04:02.017
  STEP: creating @ 09/04/24 18:04:02.019
  STEP: getting @ 09/04/24 18:04:02.039
  STEP: listing @ 09/04/24 18:04:02.043
  STEP: watching @ 09/04/24 18:04:02.046
  I0904 18:04:02.046223 19 certificates.go:316] starting watch
  STEP: patching @ 09/04/24 18:04:02.047
  STEP: updating @ 09/04/24 18:04:02.054
  I0904 18:04:02.061108 19 certificates.go:332] waiting for watch events with expected annotations
  I0904 18:04:02.061141 19 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 09/04/24 18:04:02.061
  STEP: patching /approval @ 09/04/24 18:04:02.064
  STEP: updating /approval @ 09/04/24 18:04:02.071
  STEP: getting /status @ 09/04/24 18:04:02.078
  STEP: patching /status @ 09/04/24 18:04:02.08
  STEP: updating /status @ 09/04/24 18:04:02.088
  STEP: deleting @ 09/04/24 18:04:02.097
  STEP: deleting a collection @ 09/04/24 18:04:02.109
  I0904 18:04:02.122633 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-3662" for this suite. @ 09/04/24 18:04:02.126
• [0.571 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 09/04/24 18:04:02.137
  I0904 18:04:02.137348 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/04/24 18:04:02.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:04:02.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:04:02.158
  I0904 18:04:02.162254 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:04:03.190577 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1353" for this suite. @ 09/04/24 18:04:03.196
• [1.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 09/04/24 18:04:03.203
  I0904 18:04:03.203016 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename watch @ 09/04/24 18:04:03.203
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:04:03.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:04:03.221
  STEP: creating a watch on configmaps @ 09/04/24 18:04:03.225
  STEP: creating a new configmap @ 09/04/24 18:04:03.227
  STEP: modifying the configmap once @ 09/04/24 18:04:03.231
  STEP: closing the watch once it receives two notifications @ 09/04/24 18:04:03.24
  I0904 18:04:03.240958 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6164  c87d237c-8f7a-4bdc-b622-3f14baf596f1 6969 0 2024-09-04 18:04:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-09-04 18:04:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:04:03.241105 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6164  c87d237c-8f7a-4bdc-b622-3f14baf596f1 6970 0 2024-09-04 18:04:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-09-04 18:04:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 09/04/24 18:04:03.241
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 09/04/24 18:04:03.252
  STEP: deleting the configmap @ 09/04/24 18:04:03.253
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 09/04/24 18:04:03.259
  I0904 18:04:03.259784 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6164  c87d237c-8f7a-4bdc-b622-3f14baf596f1 6971 0 2024-09-04 18:04:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-09-04 18:04:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:04:03.260040 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6164  c87d237c-8f7a-4bdc-b622-3f14baf596f1 6972 0 2024-09-04 18:04:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-09-04 18:04:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:04:03.260109 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6164" for this suite. @ 09/04/24 18:04:03.263
• [0.066 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 09/04/24 18:04:03.269
  I0904 18:04:03.269043 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename containers @ 09/04/24 18:04:03.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:04:03.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:04:03.288
  STEP: Creating a pod to test override all @ 09/04/24 18:04:03.291
  STEP: Saw pod success @ 09/04/24 18:04:07.316
  I0904 18:04:07.319659 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod client-containers-b7c20fe5-141a-4747-a8cb-d6847986a71b container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:04:07.341
  I0904 18:04:07.368608 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4634" for this suite. @ 09/04/24 18:04:07.374
• [4.121 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 09/04/24 18:04:07.389
  I0904 18:04:07.389817 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/04/24 18:04:07.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:04:07.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:04:07.427
  I0904 18:04:07.431468 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:04:13.641668 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5309" for this suite. @ 09/04/24 18:04:13.645
• [6.263 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 09/04/24 18:04:13.652
  I0904 18:04:13.652689 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubelet-test @ 09/04/24 18:04:13.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:04:13.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:04:13.671
  I0904 18:04:13.701081 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1903" for this suite. @ 09/04/24 18:04:13.704
• [0.060 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 09/04/24 18:04:13.712
  I0904 18:04:13.712862 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:04:13.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:04:13.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:04:13.731
  STEP: Creating pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382 @ 09/04/24 18:04:13.737
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/04/24 18:04:15.758
  I0904 18:04:15.761666 19 container_probe.go:1749] Initial restart count of pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 is 0
  I0904 18:04:15.765623 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:17.771307 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:19.776868 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:21.783111 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:23.789656 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:25.795742 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:27.801749 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:29.807871 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:31.813916 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:33.818884 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:35.823987 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:37.828694 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:39.834858 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:41.839999 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:43.845592 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:45.851534 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:47.857706 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:49.863570 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:51.868942 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:53.875156 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:55.879674 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:57.885940 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:04:59.891604 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:01.896674 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:03.901619 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:05.906806 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:07.911743 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:09.918280 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:11.922971 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:13.928692 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:15.934755 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:17.940807 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:19.945950 19 container_probe.go:1759] Get pod test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 in namespace container-probe-8382
  I0904 18:05:19.945984 19 container_probe.go:1763] Restart count of pod container-probe-8382/test-grpc-5d747df8-943c-4c3b-9dcc-c39b55a1bd58 is now 1 (1m4.184294547s elapsed)
  STEP: deleting the pod @ 09/04/24 18:05:19.946
  I0904 18:05:19.957686 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8382" for this suite. @ 09/04/24 18:05:19.962
• [66.256 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 09/04/24 18:05:19.969
  I0904 18:05:19.969285 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:05:19.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:05:19.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:05:19.993
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:05:19.999
  STEP: Saw pod success @ 09/04/24 18:05:24.032
  I0904 18:05:24.037168 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-e98a6d96-374b-4f6c-8980-3d0c08ae03e5 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:05:24.044
  I0904 18:05:24.063262 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8425" for this suite. @ 09/04/24 18:05:24.066
• [4.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 09/04/24 18:05:24.074
  I0904 18:05:24.074100 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename endpointslice @ 09/04/24 18:05:24.074
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:05:24.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:05:24.095
  I0904 18:05:26.161727 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5822" for this suite. @ 09/04/24 18:05:26.166
• [2.098 seconds]
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 09/04/24 18:05:26.172
  I0904 18:05:26.172608 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename events @ 09/04/24 18:05:26.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:05:26.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:05:26.193
  STEP: Create set of events @ 09/04/24 18:05:26.197
  I0904 18:05:26.202198 19 core_events.go:198] created test-event-1
  I0904 18:05:26.206048 19 core_events.go:198] created test-event-2
  I0904 18:05:26.210802 19 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 09/04/24 18:05:26.21
  STEP: delete collection of events @ 09/04/24 18:05:26.214
  I0904 18:05:26.214461 19 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 09/04/24 18:05:26.232
  I0904 18:05:26.232436 19 core_events.go:230] requesting list of events to confirm quantity
  I0904 18:05:26.235917 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1867" for this suite. @ 09/04/24 18:05:26.239
• [0.074 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 09/04/24 18:05:26.246
  I0904 18:05:26.247020 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename tables @ 09/04/24 18:05:26.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:05:26.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:05:26.266
  I0904 18:05:26.272910 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-7409" for this suite. @ 09/04/24 18:05:26.276
• [0.036 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 09/04/24 18:05:26.283
  I0904 18:05:26.283468 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename svcaccounts @ 09/04/24 18:05:26.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:05:26.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:05:26.303
  I0904 18:05:26.320451 19 service_accounts.go:618] created pod
  STEP: Saw pod success @ 09/04/24 18:05:30.338
  I0904 18:06:00.340215 19 service_accounts.go:624] polling logs
  I0904 18:06:00.347520 19 service_accounts.go:634] Pod logs: 
  I0904 18:05:26.840515       1 log.go:245] OK: Got token
  I0904 18:05:26.840555       1 log.go:245] validating with in-cluster discovery
  I0904 18:05:26.840766       1 log.go:245] OK: got issuer https://kubernetes.default.svc
  I0904 18:05:26.840978       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7248:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0001c59c0), NotBefore:(*jwt.NumericDate)(0xc0001c5b40), IssuedAt:(*jwt.NumericDate)(0xc0001c59d0), ID:"d1710b7d-7fed-438b-bd1b-28a8f286608b"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7248", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"a55fa4e5-b19d-4518-83db-daa896d71dd0"}}}
  I0904 18:05:26.847608       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I0904 18:05:26.851642       1 log.go:245] OK: Validated signature on JWT
  I0904 18:05:26.851731       1 log.go:245] OK: Got valid claims from token!
  I0904 18:05:26.851770       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7248:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0000135b0), NotBefore:(*jwt.NumericDate)(0xc0000135d8), IssuedAt:(*jwt.NumericDate)(0xc0000135b8), ID:"d1710b7d-7fed-438b-bd1b-28a8f286608b"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7248", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"a55fa4e5-b19d-4518-83db-daa896d71dd0"}}}

  I0904 18:06:00.347555 19 service_accounts.go:638] completed pod
  I0904 18:06:00.354064 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7248" for this suite. @ 09/04/24 18:06:00.359
• [34.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1044
  STEP: Creating a kubernetes client @ 09/04/24 18:06:00.367
  I0904 18:06:00.367168 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 18:06:00.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:00.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:06:00.388
  STEP: create deployment with httpd image @ 09/04/24 18:06:00.391
  I0904 18:06:00.391423 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9617 create -f -'
  I0904 18:06:00.455887 19 builder.go:146] stderr: ""
  I0904 18:06:00.455939 19 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 09/04/24 18:06:00.455
  I0904 18:06:00.456032 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9617 diff -f -'
  I0904 18:06:04.731247 19 builder.go:135] rc: 1
  I0904 18:06:04.731418 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9617 delete -f -'
  I0904 18:06:04.776217 19 builder.go:146] stderr: ""
  I0904 18:06:04.776250 19 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I0904 18:06:04.776382 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9617" for this suite. @ 09/04/24 18:06:04.779
• [4.421 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1391
  STEP: Creating a kubernetes client @ 09/04/24 18:06:04.788
  I0904 18:06:04.788029 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 18:06:04.788
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:04.854
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:06:04.858
  I0904 18:06:04.862495 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9368 create -f -'
  I0904 18:06:04.953383 19 builder.go:146] stderr: ""
  I0904 18:06:04.953426 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I0904 18:06:04.953521 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9368 create -f -'
  I0904 18:06:05.034686 19 builder.go:146] stderr: ""
  I0904 18:06:05.034731 19 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/04/24 18:06:05.034
  I0904 18:06:06.039196 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0904 18:06:06.039231 19 framework.go:733] Found 1 / 1
  I0904 18:06:06.039245 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0904 18:06:06.043842 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0904 18:06:06.043858 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0904 18:06:06.043943 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9368 describe pod agnhost-primary-kl89x'
  I0904 18:06:06.098872 19 builder.go:146] stderr: ""
  I0904 18:06:06.098932 19 builder.go:147] stdout: "Name:             agnhost-primary-kl89x\nNamespace:        kubectl-9368\nPriority:         0\nService Account:  default\nNode:             ip-172-31-40-239/172.31.40.239\nStart Time:       Wed, 04 Sep 2024 18:06:04 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.104.135\nIPs:\n  IP:           192.168.104.135\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://208de5c4cf7d509a2a617677068b29f41d6473ee488748b2b65dd22b9cceb036\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.52\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 04 Sep 2024 18:06:05 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-zvw64 (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-zvw64:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-9368/agnhost-primary-kl89x to ip-172-31-40-239\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.52\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  I0904 18:06:06.099023 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9368 describe rc agnhost-primary'
  I0904 18:06:06.151075 19 builder.go:146] stderr: ""
  I0904 18:06:06.151115 19 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9368\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.52\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-kl89x\n"
  I0904 18:06:06.151177 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9368 describe service agnhost-primary'
  I0904 18:06:06.200907 19 builder.go:146] stderr: ""
  I0904 18:06:06.200941 19 builder.go:147] stdout: "Name:                     agnhost-primary\nNamespace:                kubectl-9368\nLabels:                   app=agnhost\n                          role=primary\nAnnotations:              <none>\nSelector:                 app=agnhost,role=primary\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.152.183.221\nIPs:                      10.152.183.221\nPort:                     <unset>  6379/TCP\nTargetPort:               agnhost-server/TCP\nEndpoints:                192.168.104.135:6379\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n"
  I0904 18:06:06.204683 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9368 describe node ip-172-31-21-169'
  I0904 18:06:06.284435 19 builder.go:146] stderr: ""
  I0904 18:06:06.284530 19 builder.go:147] stdout: "Name:               ip-172-31-21-169\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    juju.io/cloud=ec2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-21-169\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 04 Sep 2024 17:53:42 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-21-169\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 04 Sep 2024 18:05:56 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 04 Sep 2024 17:55:32 +0000   Wed, 04 Sep 2024 17:55:32 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Wed, 04 Sep 2024 18:04:28 +0000   Wed, 04 Sep 2024 17:53:42 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 04 Sep 2024 18:04:28 +0000   Wed, 04 Sep 2024 17:53:42 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 04 Sep 2024 18:04:28 +0000   Wed, 04 Sep 2024 17:53:42 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 04 Sep 2024 18:04:28 +0000   Wed, 04 Sep 2024 17:54:14 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.31.21.169\n  Hostname:    ip-172-31-21-169\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7958128Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7855728Ki\n  pods:               110\nSystem Info:\n  Machine ID:                      ec237e155b9f71026aec7028a3eafa7c\n  System UUID:                     ec237e15-5b9f-7102-6aec-7028a3eafa7c\n  Boot ID:                         57c65b90-1804-4400-9724-6438732c3478\n  Kernel Version:                  6.5.0-1024-aws\n  OS Image:                        Ubuntu 22.04.4 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.6.8\n  Kubelet Version:                 v1.31.0\n  Kube-Proxy Version:              \nNon-terminated Pods:               (4 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-8z5w8           0 (0%)        0 (0%)      0 (0%)           0 (0%)         3m55s\n  kube-system                      calico-node-2rjpm                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         10m\n  sonobuoy                         sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         8m4s\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-zslmr    0 (0%)        0 (0%)      0 (0%)           0 (0%)         8m2s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From             Message\n  ----    ------                   ----               ----             -------\n  Normal  Starting                 12m                kube-proxy       \n  Normal  Starting                 12m                kube-proxy       \n  Normal  RegisteredNode           12m                node-controller  Node ip-172-31-21-169 event: Registered Node ip-172-31-21-169 in Controller\n  Normal  Starting                 12m                kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  12m (x6 over 12m)  kubelet          Node ip-172-31-21-169 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    12m (x6 over 12m)  kubelet          Node ip-172-31-21-169 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     12m (x6 over 12m)  kubelet          Node ip-172-31-21-169 status is now: NodeHasSufficientPID\n  Normal  NodeReady                11m                kubelet          Node ip-172-31-21-169 status is now: NodeReady\n"
  I0904 18:06:06.284581 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9368 describe namespace kubectl-9368'
  I0904 18:06:06.332713 19 builder.go:146] stderr: ""
  I0904 18:06:06.332751 19 builder.go:147] stdout: "Name:         kubectl-9368\nLabels:       e2e-framework=kubectl\n              e2e-run=2c9e080d-826b-49f6-9d11-79341a950aa0\n              kubernetes.io/metadata.name=kubectl-9368\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0904 18:06:06.332853 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9368" for this suite. @ 09/04/24 18:06:06.337
• [1.556 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 09/04/24 18:06:06.344
  I0904 18:06:06.344549 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 18:06:06.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:06.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:06:06.363
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 09/04/24 18:06:06.366
  STEP: Saw pod success @ 09/04/24 18:06:10.395
  I0904 18:06:10.398061 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-a1f92906-235e-4c5f-b189-2f459c819305 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 18:06:10.404
  I0904 18:06:10.422649 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2561" for this suite. @ 09/04/24 18:06:10.425
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 09/04/24 18:06:10.432
  I0904 18:06:10.432956 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:06:10.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:10.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:06:10.455
  STEP: Creating configMap with name configmap-test-volume-c19e4fcf-268a-4014-8d21-a0e7a39afbf5 @ 09/04/24 18:06:10.458
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:06:10.462
  STEP: Saw pod success @ 09/04/24 18:06:14.487
  I0904 18:06:14.492141 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-745a17dd-0d87-421a-a43c-c903eb33fd00 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:06:14.5
  I0904 18:06:14.518692 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5096" for this suite. @ 09/04/24 18:06:14.523
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 09/04/24 18:06:14.529
  I0904 18:06:14.529019 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename namespaces @ 09/04/24 18:06:14.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:14.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:06:14.548
  STEP: Creating a test namespace @ 09/04/24 18:06:14.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:14.566
  STEP: Creating a pod in the namespace @ 09/04/24 18:06:14.57
  STEP: Waiting for the pod to have running status @ 09/04/24 18:06:14.579
  STEP: Deleting the namespace @ 09/04/24 18:06:16.589
  STEP: Waiting for the namespace to be removed. @ 09/04/24 18:06:16.596
  STEP: Recreating the namespace @ 09/04/24 18:06:27.6
  STEP: Verifying there are no pods in the namespace @ 09/04/24 18:06:27.617
  I0904 18:06:27.621979 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7001" for this suite. @ 09/04/24 18:06:27.624
  STEP: Destroying namespace "nsdeletetest-3890" for this suite. @ 09/04/24 18:06:27.631
  I0904 18:06:27.635438 19 framework.go:370] Namespace nsdeletetest-3890 was already deleted
  STEP: Destroying namespace "nsdeletetest-1762" for this suite. @ 09/04/24 18:06:27.635
• [13.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:167
  STEP: Creating a kubernetes client @ 09/04/24 18:06:27.641
  I0904 18:06:27.641191 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl-logs @ 09/04/24 18:06:27.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:27.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:06:27.67
  STEP: creating a pod @ 09/04/24 18:06:27.674
  I0904 18:06:27.674597 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-logs-9227 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.52 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0904 18:06:27.721704 19 builder.go:146] stderr: ""
  I0904 18:06:27.721726 19 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 09/04/24 18:06:27.721
  I0904 18:06:27.721793 19 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  I0904 18:06:29.730328 19 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 09/04/24 18:06:29.73
  I0904 18:06:29.730488 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-logs-9227 logs logs-generator logs-generator'
  I0904 18:06:29.776950 19 builder.go:146] stderr: ""
  I0904 18:06:29.776988 19 builder.go:147] stdout: "I0904 18:06:28.240781       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/r656 457\nI0904 18:06:28.441203       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/82z4 296\nI0904 18:06:28.641548       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/hhdg 339\nI0904 18:06:28.841837       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/8d2 381\nI0904 18:06:29.041158       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/w4tn 456\nI0904 18:06:29.241453       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/ms5g 358\nI0904 18:06:29.441752       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/jkwr 258\nI0904 18:06:29.640931       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/9s6 238\n"
  STEP: limiting log lines @ 09/04/24 18:06:29.777
  I0904 18:06:29.777050 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-logs-9227 logs logs-generator logs-generator --tail=1'
  I0904 18:06:29.825753 19 builder.go:146] stderr: ""
  I0904 18:06:29.825792 19 builder.go:147] stdout: "I0904 18:06:29.640931       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/9s6 238\n"
  I0904 18:06:29.825800 19 logs.go:180] got output "I0904 18:06:29.640931       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/9s6 238\n"
  STEP: limiting log bytes @ 09/04/24 18:06:29.825
  I0904 18:06:29.825864 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-logs-9227 logs logs-generator logs-generator --limit-bytes=1'
  I0904 18:06:29.872960 19 builder.go:146] stderr: ""
  I0904 18:06:29.872992 19 builder.go:147] stdout: "I"
  I0904 18:06:29.873000 19 logs.go:186] got output "I"
  STEP: exposing timestamps @ 09/04/24 18:06:29.873
  I0904 18:06:29.873113 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-logs-9227 logs logs-generator logs-generator --tail=1 --timestamps'
  I0904 18:06:29.919713 19 builder.go:146] stderr: ""
  I0904 18:06:29.919748 19 builder.go:147] stdout: "2024-09-04T18:06:29.841340191Z I0904 18:06:29.841242       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/7hr4 374\n"
  I0904 18:06:29.919757 19 logs.go:192] got output "2024-09-04T18:06:29.841340191Z I0904 18:06:29.841242       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/7hr4 374\n"
  STEP: restricting to a time range @ 09/04/24 18:06:29.919
  I0904 18:06:32.420550 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-logs-9227 logs logs-generator logs-generator --since=1s'
  I0904 18:06:32.467668 19 builder.go:146] stderr: ""
  I0904 18:06:32.467710 19 builder.go:147] stdout: "I0904 18:06:31.640861       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/x4x 598\nI0904 18:06:31.841188       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/2qj 342\nI0904 18:06:32.041592       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/qfdb 522\nI0904 18:06:32.240839       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/2gl 472\nI0904 18:06:32.441165       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/b8l 517\n"
  I0904 18:06:32.467821 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-logs-9227 logs logs-generator logs-generator --since=24h'
  I0904 18:06:32.513219 19 builder.go:146] stderr: ""
  I0904 18:06:32.513266 19 builder.go:147] stdout: "I0904 18:06:28.240781       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/r656 457\nI0904 18:06:28.441203       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/82z4 296\nI0904 18:06:28.641548       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/hhdg 339\nI0904 18:06:28.841837       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/8d2 381\nI0904 18:06:29.041158       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/w4tn 456\nI0904 18:06:29.241453       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/ms5g 358\nI0904 18:06:29.441752       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/jkwr 258\nI0904 18:06:29.640931       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/9s6 238\nI0904 18:06:29.841242       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/7hr4 374\nI0904 18:06:30.041560       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/qgl 260\nI0904 18:06:30.240814       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/gqv 426\nI0904 18:06:30.441126       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/hpv 324\nI0904 18:06:30.641417       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/c7px 413\nI0904 18:06:30.841642       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/b7b 465\nI0904 18:06:31.040906       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/k5sg 282\nI0904 18:06:31.241230       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/2m5 405\nI0904 18:06:31.441616       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/2hf 288\nI0904 18:06:31.640861       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/x4x 598\nI0904 18:06:31.841188       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/2qj 342\nI0904 18:06:32.041592       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/qfdb 522\nI0904 18:06:32.240839       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/2gl 472\nI0904 18:06:32.441165       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/b8l 517\n"
  I0904 18:06:32.513396 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-logs-9227 delete pod logs-generator'
  I0904 18:06:33.775185 19 builder.go:146] stderr: ""
  I0904 18:06:33.775220 19 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I0904 18:06:33.775349 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-9227" for this suite. @ 09/04/24 18:06:33.779
• [6.144 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:139
  STEP: Creating a kubernetes client @ 09/04/24 18:06:33.785
  I0904 18:06:33.785524 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename dns @ 09/04/24 18:06:33.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:33.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:06:33.806
  STEP: Creating a test headless service @ 09/04/24 18:06:33.812
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1414.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1414.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1414.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1414.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1414.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1414.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1414.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1414.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1414.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1414.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 198.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.198_udp@PTR;check="$$(dig +tcp +noall +answer +search 198.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.198_tcp@PTR;sleep 1; done
   @ 09/04/24 18:06:33.836
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1414.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1414.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1414.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1414.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1414.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1414.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1414.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1414.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1414.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1414.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 198.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.198_udp@PTR;check="$$(dig +tcp +noall +answer +search 198.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.198_tcp@PTR;sleep 1; done
   @ 09/04/24 18:06:33.836
  STEP: creating a pod to probe DNS @ 09/04/24 18:06:33.836
  STEP: submitting the pod to kubernetes @ 09/04/24 18:06:33.836
  STEP: retrieving the pod @ 09/04/24 18:06:41.881
  STEP: looking for the results for each expected name from probers @ 09/04/24 18:06:41.884
  I0904 18:06:41.889601 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-1414.svc.cluster.local from pod dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f: the server could not find the requested resource (get pods dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f)
  I0904 18:06:41.894348 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-1414.svc.cluster.local from pod dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f: the server could not find the requested resource (get pods dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f)
  I0904 18:06:41.897706 19 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local from pod dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f: the server could not find the requested resource (get pods dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f)
  I0904 18:06:41.902226 19 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local from pod dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f: the server could not find the requested resource (get pods dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f)
  I0904 18:06:41.922673 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-1414.svc.cluster.local from pod dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f: the server could not find the requested resource (get pods dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f)
  I0904 18:06:41.926932 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-1414.svc.cluster.local from pod dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f: the server could not find the requested resource (get pods dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f)
  I0904 18:06:41.931277 19 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local from pod dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f: the server could not find the requested resource (get pods dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f)
  I0904 18:06:41.934782 19 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local from pod dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f: the server could not find the requested resource (get pods dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f)
  I0904 18:06:41.952540 19 dns_common.go:489] Lookups using dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f failed for: [wheezy_udp@dns-test-service.dns-1414.svc.cluster.local wheezy_tcp@dns-test-service.dns-1414.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local jessie_udp@dns-test-service.dns-1414.svc.cluster.local jessie_tcp@dns-test-service.dns-1414.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1414.svc.cluster.local]

  I0904 18:06:41.958782 19 dns_common.go:495] Pod client logs for webserver: 
  I0904 18:06:41.964466 19 dns_common.go:495] Pod client logs for querier: 
  I0904 18:06:41.971282 19 dns_common.go:495] Pod client logs for jessie-querier: 
  I0904 18:06:46.953812 19 dns_common.go:527] DNS probes using dns-1414/dns-test-5dfbd763-27c1-4431-b9c6-bf885245e18f succeeded

  STEP: deleting the pod @ 09/04/24 18:06:46.953
  STEP: deleting the test service @ 09/04/24 18:06:46.97
  STEP: deleting the test headless service @ 09/04/24 18:06:47.008
  I0904 18:06:47.026969 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1414" for this suite. @ 09/04/24 18:06:47.03
• [13.251 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:331
  STEP: Creating a kubernetes client @ 09/04/24 18:06:47.037
  I0904 18:06:47.037090 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename dns @ 09/04/24 18:06:47.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:06:47.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:06:47.064
  STEP: Creating a test externalName service @ 09/04/24 18:06:47.068
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2825.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2825.svc.cluster.local; sleep 1; done
   @ 09/04/24 18:06:47.072
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2825.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2825.svc.cluster.local; sleep 1; done
   @ 09/04/24 18:06:47.072
  STEP: creating a pod to probe DNS @ 09/04/24 18:06:47.072
  STEP: submitting the pod to kubernetes @ 09/04/24 18:06:47.072
  STEP: retrieving the pod @ 09/04/24 18:06:59.12
  STEP: looking for the results for each expected name from probers @ 09/04/24 18:06:59.124
  I0904 18:06:59.134264 19 dns_common.go:552] DNS probes using dns-test-6ff24396-d322-43c1-ba30-d330b44322bc succeeded

  STEP: changing the externalName to bar.example.com @ 09/04/24 18:06:59.134
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2825.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2825.svc.cluster.local; sleep 1; done
   @ 09/04/24 18:06:59.143
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2825.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2825.svc.cluster.local; sleep 1; done
   @ 09/04/24 18:06:59.143
  STEP: creating a second pod to probe DNS @ 09/04/24 18:06:59.143
  STEP: submitting the pod to kubernetes @ 09/04/24 18:06:59.143
  STEP: retrieving the pod @ 09/04/24 18:07:05.176
  STEP: looking for the results for each expected name from probers @ 09/04/24 18:07:05.18
  I0904 18:07:05.190201 19 dns_common.go:552] DNS probes using dns-test-efbefaba-5b2f-4ad1-ba0a-204219f367a2 succeeded

  STEP: changing the service to type=ClusterIP @ 09/04/24 18:07:05.19
  W0904 18:07:05.207996      19 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2825.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2825.svc.cluster.local; sleep 1; done
   @ 09/04/24 18:07:05.208
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2825.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2825.svc.cluster.local; sleep 1; done
   @ 09/04/24 18:07:05.208
  STEP: creating a third pod to probe DNS @ 09/04/24 18:07:05.208
  STEP: submitting the pod to kubernetes @ 09/04/24 18:07:05.212
  STEP: retrieving the pod @ 09/04/24 18:07:07.228
  STEP: looking for the results for each expected name from probers @ 09/04/24 18:07:07.232
  I0904 18:07:07.242190 19 dns_common.go:552] DNS probes using dns-test-76f9fedb-98c4-43f6-b79b-bc89182f4ca5 succeeded

  STEP: deleting the pod @ 09/04/24 18:07:07.242
  STEP: deleting the pod @ 09/04/24 18:07:07.256
  STEP: deleting the pod @ 09/04/24 18:07:07.27
  STEP: deleting the test externalName service @ 09/04/24 18:07:07.284
  I0904 18:07:07.302082 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2825" for this suite. @ 09/04/24 18:07:07.305
• [20.275 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 09/04/24 18:07:07.312
  I0904 18:07:07.312220 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 18:07:07.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:07:07.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:07:07.334
  STEP: Create set of pods @ 09/04/24 18:07:07.338
  I0904 18:07:07.347963 19 pods.go:871] created test-pod-1
  I0904 18:07:07.355677 19 pods.go:871] created test-pod-2
  I0904 18:07:07.369204 19 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 09/04/24 18:07:07.369
  STEP: waiting for all pods to be deleted @ 09/04/24 18:07:17.426
  I0904 18:07:17.430422 19 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  I0904 18:07:18.431630 19 pods.go:1140] Pod quantity 1 is different from expected quantity 0
  I0904 18:07:19.431616 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-238" for this suite. @ 09/04/24 18:07:19.435
• [12.132 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:57
  STEP: Creating a kubernetes client @ 09/04/24 18:07:19.444
  I0904 18:07:19.444171 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename volumeattachment @ 09/04/24 18:07:19.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:07:19.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:07:19.465
  STEP: Create VolumeAttachment "va-e2e-9t48j" on node "ip-172-31-29-199" @ 09/04/24 18:07:19.472
  STEP: Get VolumeAttachment "va-e2e-9t48j" on node "ip-172-31-29-199" @ 09/04/24 18:07:19.478
  STEP: Patch VolumeAttachment "va-e2e-9t48j" on node "ip-172-31-29-199" @ 09/04/24 18:07:19.481
  STEP: List VolumeAttachments with "va-e2e-9t48j=patched" label @ 09/04/24 18:07:19.487
  STEP: Delete VolumeAttachment "va-e2e-9t48j" on node "ip-172-31-29-199" @ 09/04/24 18:07:19.493
  STEP: Confirm deletion of VolumeAttachment "va-e2e-9t48j" on node "ip-172-31-29-199" @ 09/04/24 18:07:19.498
  STEP: Create VolumeAttachment "va-e2e-pjpxx" on node "ip-172-31-40-239" @ 09/04/24 18:07:19.504
  STEP: Update the VolumeAttachment "va-e2e-pjpxx" on node "ip-172-31-40-239" with label "va-e2e=updated" @ 09/04/24 18:07:19.508
  STEP: Create VolumeAttachment "va-e2e-6ng94" on node "ip-172-31-21-169" @ 09/04/24 18:07:19.52
  STEP: Update the VolumeAttachment "va-e2e-6ng94" on node "ip-172-31-21-169" with label "va-e2e=updated" @ 09/04/24 18:07:19.525
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 09/04/24 18:07:19.533
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 09/04/24 18:07:19.544
  I0904 18:07:19.548392 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-173" for this suite. @ 09/04/24 18:07:19.552
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:965
  STEP: Creating a kubernetes client @ 09/04/24 18:07:19.561
  I0904 18:07:19.561166 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename statefulset @ 09/04/24 18:07:19.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:07:19.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:07:19.581
  STEP: Creating service test in namespace statefulset-8681 @ 09/04/24 18:07:19.585
  I0904 18:07:19.602774 19 wait.go:40] Found 0 stateful pods, waiting for 1
  I0904 18:07:29.606784 19 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 09/04/24 18:07:29.614
  I0904 18:07:29.632527 19 wait.go:40] Found 1 stateful pods, waiting for 2
  I0904 18:07:39.632268 19 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0904 18:07:39.632301 19 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 09/04/24 18:07:39.64
  STEP: Delete all of the StatefulSets @ 09/04/24 18:07:39.643
  STEP: Verify that StatefulSets have been deleted @ 09/04/24 18:07:39.651
  I0904 18:07:39.655652 19 statefulset.go:138] Deleting all statefulset in ns statefulset-8681
  I0904 18:07:39.673587 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8681" for this suite. @ 09/04/24 18:07:39.676
• [20.123 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 09/04/24 18:07:39.684
  I0904 18:07:39.684198 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:07:39.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:07:39.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:07:39.706
  STEP: Creating configMap configmap-1358/configmap-test-b78cc061-1688-4c97-a96f-42984d83c4ad @ 09/04/24 18:07:39.709
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:07:39.713
  STEP: Saw pod success @ 09/04/24 18:07:43.742
  I0904 18:07:43.747263 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-62506a57-1464-4b68-acdb-c6e754f6bc8e container env-test: <nil>
  STEP: delete the pod @ 09/04/24 18:07:43.754
  I0904 18:07:43.775263 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1358" for this suite. @ 09/04/24 18:07:43.779
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1513
  STEP: Creating a kubernetes client @ 09/04/24 18:07:43.79
  I0904 18:07:43.790244 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:07:43.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:07:43.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:07:43.81
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-879 @ 09/04/24 18:07:43.903
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 09/04/24 18:07:43.92
  STEP: creating service externalsvc in namespace services-879 @ 09/04/24 18:07:43.92
  STEP: creating replication controller externalsvc in namespace services-879 @ 09/04/24 18:07:43.932
  I0904 18:07:43.941304      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-879, replica count: 2
  I0904 18:07:46.991875      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 09/04/24 18:07:46.997
  I0904 18:07:47.017062 19 resource.go:361] Creating new exec pod
  I0904 18:07:49.037483 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-879 exec execpodk4sf9 -- /bin/sh -x -c nslookup nodeport-service.services-879.svc.cluster.local'
  I0904 18:07:49.136653 19 builder.go:146] stderr: "+ nslookup nodeport-service.services-879.svc.cluster.local\n"
  I0904 18:07:49.136712 19 builder.go:147] stdout: "Server:\t\t10.152.183.70\nAddress:\t10.152.183.70#53\n\nnodeport-service.services-879.svc.cluster.local\tcanonical name = externalsvc.services-879.svc.cluster.local.\nName:\texternalsvc.services-879.svc.cluster.local\nAddress: 10.152.183.141\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-879, will wait for the garbage collector to delete the pods @ 09/04/24 18:07:49.136
  I0904 18:07:49.199369 19 resources.go:139] Deleting ReplicationController externalsvc took: 7.533801ms
  I0904 18:07:49.299774 19 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.39962ms
  I0904 18:07:52.118026 19 service.go:1524] Cleaning up the NodePort to ExternalName test service
  I0904 18:07:52.128854 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-879" for this suite. @ 09/04/24 18:07:52.132
• [8.350 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 09/04/24 18:07:52.14
  I0904 18:07:52.140723 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 18:07:52.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:07:52.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:07:52.159
  I0904 18:07:52.165878 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/04/24 18:07:53.522
  I0904 18:07:53.522504 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4403 --namespace=crd-publish-openapi-4403 create -f -'
  I0904 18:07:55.587470 19 builder.go:146] stderr: ""
  I0904 18:07:55.587506 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-926-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0904 18:07:55.587549 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4403 --namespace=crd-publish-openapi-4403 delete e2e-test-crd-publish-openapi-926-crds test-cr'
  I0904 18:07:55.657698 19 builder.go:146] stderr: ""
  I0904 18:07:55.657743 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-926-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I0904 18:07:55.657784 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4403 --namespace=crd-publish-openapi-4403 apply -f -'
  I0904 18:07:55.738388 19 builder.go:146] stderr: ""
  I0904 18:07:55.738432 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-926-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0904 18:07:55.738470 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4403 --namespace=crd-publish-openapi-4403 delete e2e-test-crd-publish-openapi-926-crds test-cr'
  I0904 18:07:55.803725 19 builder.go:146] stderr: ""
  I0904 18:07:55.803779 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-926-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 09/04/24 18:07:55.803
  I0904 18:07:55.803851 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4403 explain e2e-test-crd-publish-openapi-926-crds'
  I0904 18:07:55.862604 19 builder.go:146] stderr: ""
  I0904 18:07:55.862791 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-926-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I0904 18:07:57.073617 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4403" for this suite. @ 09/04/24 18:07:57.08
• [4.948 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:851
  STEP: Creating a kubernetes client @ 09/04/24 18:07:57.089
  I0904 18:07:57.089073 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename daemonsets @ 09/04/24 18:07:57.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:07:57.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:07:57.11
  STEP: Creating simple DaemonSet "daemon-set" @ 09/04/24 18:07:57.132
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/04/24 18:07:57.136
  I0904 18:07:57.140341 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:07:57.140419 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:07:57.144160 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:07:57.144172 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  I0904 18:07:58.141652 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:07:58.141709 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:07:58.144858 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0904 18:07:58.144874 19 fixtures.go:130] Node ip-172-31-40-239 is running 0 daemon pod, expected 1
  I0904 18:07:59.142797 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:07:59.142841 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:07:59.146741 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:07:59.146760 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:00.142327 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:00.142375 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:00.146118 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:00.146136 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:01.141630 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:01.141672 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:01.145639 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:01.145656 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:02.141954 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:02.141999 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:02.145216 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:02.145233 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:03.141161 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:03.141201 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:03.144632 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:03.144646 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:04.142252 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:04.142296 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:04.146534 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:04.146553 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:05.141841 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:05.141877 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:05.145179 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:05.145199 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:06.141691 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:06.141736 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:06.146025 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:06.146058 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:07.142258 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:07.142303 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:07.146599 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:07.146621 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:08.143977 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:08.144030 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:08.147765 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:08.147787 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:09.142680 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:09.142729 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:09.147287 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:09.147308 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:10.142502 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:10.142546 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:10.146227 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:10.146246 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:11.142408 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:11.142456 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:11.145670 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:11.145688 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:12.141427 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:12.141501 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:12.145580 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 18:08:12.145605 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  I0904 18:08:13.142759 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:13.142886 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:08:13.146482 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 18:08:13.146502 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 09/04/24 18:08:13.15
  STEP: DeleteCollection of the DaemonSets @ 09/04/24 18:08:13.153
  STEP: Verify that ReplicaSets have been deleted @ 09/04/24 18:08:13.161
  I0904 18:08:13.172174 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8704"},"items":null}

  I0904 18:08:13.181565 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8707"},"items":[{"metadata":{"name":"daemon-set-8wr8g","generateName":"daemon-set-","namespace":"daemonsets-772","uid":"5795f0b0-6c23-4192-b6ec-6a5265e0c0aa","resourceVersion":"8701","creationTimestamp":"2024-09-04T18:07:57Z","labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"30b5aa44-7f98-4848-907f-56e245a609bd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-09-04T18:07:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30b5aa44-7f98-4848-907f-56e245a609bd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-09-04T18:08:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.243.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-jfb6p","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-jfb6p","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-7-223","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-7-223"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:08:12Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:08:12Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:08:12Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"}],"hostIP":"172.31.7.223","hostIPs":[{"ip":"172.31.7.223"}],"podIP":"192.168.243.7","podIPs":[{"ip":"192.168.243.7"}],"startTime":"2024-09-04T18:07:57Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-09-04T18:08:12Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://5cb9f99093a1e45ae5cb4951899a024ebeca642f54ebeb4f0ede04c6389e0cfa","started":true,"volumeMounts":[{"name":"kube-api-access-jfb6p","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-gx2ck","generateName":"daemon-set-","namespace":"daemonsets-772","uid":"6b6b0280-84f7-431b-9313-37adf14e9b64","resourceVersion":"8706","creationTimestamp":"2024-09-04T18:07:57Z","deletionTimestamp":"2024-09-04T18:08:43Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"30b5aa44-7f98-4848-907f-56e245a609bd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-09-04T18:07:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30b5aa44-7f98-4848-907f-56e245a609bd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-09-04T18:07:59Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.104.140\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-92mpp","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-92mpp","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-40-239","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-40-239"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:59Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:59Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:59Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"}],"hostIP":"172.31.40.239","hostIPs":[{"ip":"172.31.40.239"}],"podIP":"192.168.104.140","podIPs":[{"ip":"192.168.104.140"}],"startTime":"2024-09-04T18:07:57Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-09-04T18:07:58Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://84898065d616d5c3af602a0b834f143d24cb1c4c62f99ec3d8afab75277a3324","started":true,"volumeMounts":[{"name":"kube-api-access-92mpp","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tchjw","generateName":"daemon-set-","namespace":"daemonsets-772","uid":"4c71d596-27c6-41a2-923d-3ee26e5803da","resourceVersion":"8705","creationTimestamp":"2024-09-04T18:07:57Z","deletionTimestamp":"2024-09-04T18:08:43Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"30b5aa44-7f98-4848-907f-56e245a609bd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-09-04T18:07:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30b5aa44-7f98-4848-907f-56e245a609bd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-09-04T18:07:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.146.163\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-cbgln","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-cbgln","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-21-169","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-21-169"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-04T18:07:57Z"}],"hostIP":"172.31.21.169","hostIPs":[{"ip":"172.31.21.169"}],"podIP":"192.168.146.163","podIPs":[{"ip":"192.168.146.163"}],"startTime":"2024-09-04T18:07:57Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-09-04T18:07:57Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://50154027c4576e92385ba54a5e46bf52af25593906159b2cfd996627d99d4ae1","started":true,"volumeMounts":[{"name":"kube-api-access-cbgln","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}}]}

  I0904 18:08:13.198169 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-772" for this suite. @ 09/04/24 18:08:13.201
• [16.118 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:393
  STEP: Creating a kubernetes client @ 09/04/24 18:08:13.207
  I0904 18:08:13.207800 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 18:08:13.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:08:13.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:08:13.236
  STEP: creating all guestbook components @ 09/04/24 18:08:13.239
  I0904 18:08:13.239606 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0904 18:08:13.239955 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 create -f -'
  I0904 18:08:13.363062 19 builder.go:146] stderr: ""
  I0904 18:08:13.363112 19 builder.go:147] stdout: "service/agnhost-replica created\n"
  I0904 18:08:13.363159 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0904 18:08:13.363209 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 create -f -'
  I0904 18:08:13.482312 19 builder.go:146] stderr: ""
  I0904 18:08:13.482350 19 builder.go:147] stdout: "service/agnhost-primary created\n"
  I0904 18:08:13.482396 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0904 18:08:13.482448 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 create -f -'
  I0904 18:08:13.562915 19 builder.go:146] stderr: ""
  I0904 18:08:13.562959 19 builder.go:147] stdout: "service/frontend created\n"
  I0904 18:08:13.563023 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0904 18:08:13.563100 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 create -f -'
  I0904 18:08:13.621651 19 builder.go:146] stderr: ""
  I0904 18:08:13.621686 19 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I0904 18:08:13.621745 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0904 18:08:13.621805 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 create -f -'
  I0904 18:08:13.688761 19 builder.go:146] stderr: ""
  I0904 18:08:13.688801 19 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I0904 18:08:13.688913 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0904 18:08:13.689040 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 create -f -'
  I0904 18:08:13.746084 19 builder.go:146] stderr: ""
  I0904 18:08:13.746122 19 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 09/04/24 18:08:13.746
  I0904 18:08:13.746162 19 kubectl.go:2272] Waiting for all frontend pods to be Running.
  I0904 18:08:48.799758 19 kubectl.go:2276] Waiting for frontend to serve content.
  I0904 18:08:48.811756 19 kubectl.go:2281] Trying to add a new entry to the guestbook.
  I0904 18:08:48.825931 19 kubectl.go:2286] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 09/04/24 18:08:48.836
  I0904 18:08:48.836785 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 delete --grace-period=0 --force -f -'
  I0904 18:08:48.893106 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 18:08:48.893136 19 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 09/04/24 18:08:48.893
  I0904 18:08:48.893238 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 delete --grace-period=0 --force -f -'
  I0904 18:08:48.951412 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 18:08:48.951440 19 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 09/04/24 18:08:48.951
  I0904 18:08:48.951540 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 delete --grace-period=0 --force -f -'
  I0904 18:08:49.011272 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 18:08:49.011304 19 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 09/04/24 18:08:49.011
  I0904 18:08:49.011467 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 delete --grace-period=0 --force -f -'
  I0904 18:08:49.056340 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 18:08:49.056376 19 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 09/04/24 18:08:49.056
  I0904 18:08:49.056479 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 delete --grace-period=0 --force -f -'
  I0904 18:08:49.115570 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 18:08:49.115633 19 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 09/04/24 18:08:49.115
  I0904 18:08:49.115777 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5690 delete --grace-period=0 --force -f -'
  I0904 18:08:49.175229 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 18:08:49.175276 19 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I0904 18:08:49.175386 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5690" for this suite. @ 09/04/24 18:08:49.178
• [35.977 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:454
  STEP: Creating a kubernetes client @ 09/04/24 18:08:49.185
  I0904 18:08:49.185386 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 18:08:49.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:08:49.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:08:49.261
  STEP: Counting existing ResourceQuota @ 09/04/24 18:08:49.264
  STEP: Creating a ResourceQuota @ 09/04/24 18:08:54.269
  STEP: Ensuring resource quota status is calculated @ 09/04/24 18:08:54.278
  STEP: Creating a ReplicaSet @ 09/04/24 18:08:56.283
  STEP: Ensuring resource quota status captures replicaset creation @ 09/04/24 18:08:56.297
  STEP: Deleting a ReplicaSet @ 09/04/24 18:08:58.303
  STEP: Ensuring resource quota status released usage @ 09/04/24 18:08:58.311
  I0904 18:09:00.317507 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5962" for this suite. @ 09/04/24 18:09:00.321
• [11.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 09/04/24 18:09:00.329
  I0904 18:09:00.329709 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 18:09:00.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:09:00.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:09:00.353
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 09/04/24 18:09:00.357
  STEP: Saw pod success @ 09/04/24 18:09:02.376
  I0904 18:09:02.379931 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-143c1031-7de0-4e26-9d6d-af27f38cd841 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 18:09:02.388
  I0904 18:09:02.405204 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6483" for this suite. @ 09/04/24 18:09:02.409
• [2.085 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 09/04/24 18:09:02.415
  I0904 18:09:02.415025 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:09:02.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:09:02.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:09:02.437
  STEP: Creating pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880 @ 09/04/24 18:09:02.445
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/04/24 18:09:04.463
  I0904 18:09:04.467550 19 container_probe.go:1749] Initial restart count of pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 is 0
  I0904 18:09:04.471521 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:06.476239 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:08.481388 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:10.487785 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:12.493778 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:14.498525 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:16.503656 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:18.509365 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:20.514267 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:22.519122 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:24.524987 19 container_probe.go:1759] Get pod liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 in namespace container-probe-3880
  I0904 18:09:24.525021 19 container_probe.go:1763] Restart count of pod container-probe-3880/liveness-03ce03f5-f268-495a-9b7c-bacac36afc41 is now 1 (20.057444524s elapsed)
  STEP: deleting the pod @ 09/04/24 18:09:24.525
  I0904 18:09:24.539860 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3880" for this suite. @ 09/04/24 18:09:24.544
• [22.136 seconds]
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 09/04/24 18:09:24.551
  I0904 18:09:24.551283 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:09:24.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:09:24.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:09:24.571
  STEP: Creating secret with name s-test-opt-del-e8652fab-2308-4790-8427-8441b473b248 @ 09/04/24 18:09:24.578
  STEP: Creating secret with name s-test-opt-upd-1c3423db-60f4-4818-94ec-9d8018012c04 @ 09/04/24 18:09:24.584
  STEP: Creating the pod @ 09/04/24 18:09:24.588
  STEP: Deleting secret s-test-opt-del-e8652fab-2308-4790-8427-8441b473b248 @ 09/04/24 18:09:26.637
  STEP: Updating secret s-test-opt-upd-1c3423db-60f4-4818-94ec-9d8018012c04 @ 09/04/24 18:09:26.644
  STEP: Creating secret with name s-test-opt-create-10e8d0d5-511c-4a3e-9bef-1ece94093ec2 @ 09/04/24 18:09:26.649
  STEP: waiting to observe update in volume @ 09/04/24 18:09:26.653
  I0904 18:10:44.993519 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2839" for this suite. @ 09/04/24 18:10:44.997
• [80.453 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 09/04/24 18:10:45.004
  I0904 18:10:45.004349 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename endpointslicemirroring @ 09/04/24 18:10:45.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:10:45.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:10:45.027
  STEP: mirroring a new custom Endpoint @ 09/04/24 18:10:45.044
  I0904 18:10:45.055255 19 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  STEP: mirroring an update to a custom Endpoint @ 09/04/24 18:10:47.059
  I0904 18:10:47.071369 19 endpointslicemirroring.go:171] Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  STEP: mirroring deletion of a custom Endpoint @ 09/04/24 18:10:49.077
  I0904 18:10:49.087250 19 endpointslicemirroring.go:194] Waiting for 0 EndpointSlices to exist, got 1
  I0904 18:10:51.092529 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-1051" for this suite. @ 09/04/24 18:10:51.096
• [6.099 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 09/04/24 18:10:51.103
  I0904 18:10:51.103250 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:10:51.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:10:51.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:10:51.123
  STEP: Creating a pod to test downward api env vars @ 09/04/24 18:10:51.127
  STEP: Saw pod success @ 09/04/24 18:10:55.151
  I0904 18:10:55.155712 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downward-api-2d09a829-b28a-487d-888a-88be406425eb container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 18:10:55.163
  I0904 18:10:55.180024 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7082" for this suite. @ 09/04/24 18:10:55.184
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 09/04/24 18:10:55.192
  I0904 18:10:55.192999 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 18:10:55.193
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:10:55.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:10:55.213
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 09/04/24 18:10:55.217
  STEP: Saw pod success @ 09/04/24 18:10:59.24
  I0904 18:10:59.244577 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-213f73c7-813a-403b-b80b-b614887af87a container test-container: <nil>
  STEP: delete the pod @ 09/04/24 18:10:59.25
  I0904 18:10:59.267362 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-556" for this suite. @ 09/04/24 18:10:59.271
• [4.085 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:247
  STEP: Creating a kubernetes client @ 09/04/24 18:10:59.277
  I0904 18:10:59.277954 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:10:59.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:10:59.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:10:59.298
  STEP: Setting up server cert @ 09/04/24 18:10:59.33
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:10:59.436
  STEP: Deploying the webhook pod @ 09/04/24 18:10:59.446
  STEP: Wait for the deployment to be ready @ 09/04/24 18:10:59.461
  I0904 18:10:59.470937 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/04/24 18:11:01.483
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:11:01.493
  I0904 18:11:02.493228 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 09/04/24 18:11:02.504
  STEP: create a configmap that should be updated by the webhook @ 09/04/24 18:11:02.518
  I0904 18:11:02.563375 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7755" for this suite. @ 09/04/24 18:11:02.568
  STEP: Destroying namespace "webhook-markers-43" for this suite. @ 09/04/24 18:11:02.576
• [3.308 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 09/04/24 18:11:02.585
  I0904 18:11:02.585768 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 18:11:02.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:11:02.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:11:02.606
  STEP: Creating secret with name secret-test-fdb56fe6-3c6c-4e5f-b831-6b8c41c64bbf @ 09/04/24 18:11:02.609
  STEP: Creating a pod to test consume secrets @ 09/04/24 18:11:02.622
  STEP: Saw pod success @ 09/04/24 18:11:06.649
  I0904 18:11:06.653203 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-secrets-ce81c222-e35f-455a-88c6-6d1481b5149d container secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 18:11:06.66
  I0904 18:11:06.678885 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-195" for this suite. @ 09/04/24 18:11:06.683
• [4.106 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:814
  STEP: Creating a kubernetes client @ 09/04/24 18:11:06.691
  I0904 18:11:06.691802 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:11:06.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:11:06.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:11:06.714
  STEP: Setting up server cert @ 09/04/24 18:11:06.738
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:11:06.996
  STEP: Deploying the webhook pod @ 09/04/24 18:11:07.002
  STEP: Wait for the deployment to be ready @ 09/04/24 18:11:07.015
  I0904 18:11:07.025785 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/04/24 18:11:09.04
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:11:09.051
  I0904 18:11:10.051708 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 09/04/24 18:11:10.06
  I0904 18:11:10.099362 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7059" for this suite. @ 09/04/24 18:11:10.102
  STEP: Destroying namespace "webhook-markers-6988" for this suite. @ 09/04/24 18:11:10.109
• [3.423 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 09/04/24 18:11:10.114
  I0904 18:11:10.114517 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replicaset @ 09/04/24 18:11:10.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:11:10.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:11:10.135
  STEP: Create a ReplicaSet @ 09/04/24 18:11:10.141
  STEP: Verify that the required pods have come up @ 09/04/24 18:11:10.147
  I0904 18:11:10.150491 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 3
  I0904 18:11:15.154349 19 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 09/04/24 18:11:15.154
  I0904 18:11:15.157969 19 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 09/04/24 18:11:15.157
  STEP: DeleteCollection of the ReplicaSets @ 09/04/24 18:11:15.161
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 09/04/24 18:11:15.168
  I0904 18:11:15.171352 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4107" for this suite. @ 09/04/24 18:11:15.174
• [5.074 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 09/04/24 18:11:15.188
  I0904 18:11:15.188325 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:11:15.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:11:15.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:11:15.215
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:11:15.219
  STEP: Saw pod success @ 09/04/24 18:11:19.245
  I0904 18:11:19.249162 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-3c3ddb85-d4a3-4f37-8804-4ac984eeccb9 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:11:19.255
  I0904 18:11:19.273729 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4286" for this suite. @ 09/04/24 18:11:19.277
• [4.095 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:79
  STEP: Creating a kubernetes client @ 09/04/24 18:11:19.283
  I0904 18:11:19.283713 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 18:11:19.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:11:19.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:11:19.312
  STEP: Counting existing ResourceQuota @ 09/04/24 18:11:19.316
  STEP: Creating a ResourceQuota @ 09/04/24 18:11:24.32
  STEP: Ensuring resource quota status is calculated @ 09/04/24 18:11:24.325
  I0904 18:11:26.332305 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-401" for this suite. @ 09/04/24 18:11:26.336
• [7.059 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 09/04/24 18:11:26.343
  I0904 18:11:26.343338 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 18:11:26.343
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:11:26.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:11:26.363
  STEP: Creating secret with name secret-test-a539e68d-d207-47b8-b016-dcffb78e35a2 @ 09/04/24 18:11:26.366
  STEP: Creating a pod to test consume secrets @ 09/04/24 18:11:26.37
  STEP: Saw pod success @ 09/04/24 18:11:30.394
  I0904 18:11:30.398870 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-secrets-610ab6e6-3d97-4e42-90d8-5e936a1a6daf container secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 18:11:30.404
  I0904 18:11:30.422287 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7016" for this suite. @ 09/04/24 18:11:30.426
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 09/04/24 18:11:30.432
  I0904 18:11:30.432751 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename discovery @ 09/04/24 18:11:30.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:11:30.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:11:30.454
  STEP: Setting up server cert @ 09/04/24 18:11:30.459
  I0904 18:11:30.607358 19 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0904 18:11:30.608886 19 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0904 18:11:30.608905 19 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0904 18:11:30.608942 19 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0904 18:11:30.608948 19 discovery.go:139] Checking APIGroup: apps
  I0904 18:11:30.610618 19 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0904 18:11:30.610636 19 discovery.go:148] Versions found [{apps/v1 v1}]
  I0904 18:11:30.610642 19 discovery.go:154] apps/v1 matches apps/v1
  I0904 18:11:30.610647 19 discovery.go:139] Checking APIGroup: events.k8s.io
  I0904 18:11:30.612034 19 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0904 18:11:30.612045 19 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0904 18:11:30.612060 19 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0904 18:11:30.612071 19 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0904 18:11:30.613409 19 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0904 18:11:30.613421 19 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0904 18:11:30.613482 19 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0904 18:11:30.613523 19 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0904 18:11:30.615244 19 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0904 18:11:30.615262 19 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0904 18:11:30.615319 19 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0904 18:11:30.615359 19 discovery.go:139] Checking APIGroup: autoscaling
  I0904 18:11:30.616807 19 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0904 18:11:30.616818 19 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0904 18:11:30.616823 19 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0904 18:11:30.616828 19 discovery.go:139] Checking APIGroup: batch
  I0904 18:11:30.618246 19 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0904 18:11:30.618257 19 discovery.go:148] Versions found [{batch/v1 v1}]
  I0904 18:11:30.618263 19 discovery.go:154] batch/v1 matches batch/v1
  I0904 18:11:30.618268 19 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0904 18:11:30.619622 19 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0904 18:11:30.619631 19 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0904 18:11:30.619636 19 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0904 18:11:30.619707 19 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0904 18:11:30.621238 19 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0904 18:11:30.621256 19 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0904 18:11:30.621262 19 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0904 18:11:30.621279 19 discovery.go:139] Checking APIGroup: policy
  I0904 18:11:30.622939 19 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0904 18:11:30.622959 19 discovery.go:148] Versions found [{policy/v1 v1}]
  I0904 18:11:30.622968 19 discovery.go:154] policy/v1 matches policy/v1
  I0904 18:11:30.623024 19 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0904 18:11:30.624382 19 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0904 18:11:30.624399 19 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0904 18:11:30.624404 19 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0904 18:11:30.624410 19 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0904 18:11:30.625779 19 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0904 18:11:30.625789 19 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0904 18:11:30.625794 19 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0904 18:11:30.625846 19 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0904 18:11:30.627199 19 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0904 18:11:30.627249 19 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0904 18:11:30.627260 19 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0904 18:11:30.627266 19 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0904 18:11:30.628579 19 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0904 18:11:30.628587 19 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0904 18:11:30.628592 19 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0904 18:11:30.628597 19 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0904 18:11:30.630142 19 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0904 18:11:30.630161 19 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0904 18:11:30.630167 19 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0904 18:11:30.630173 19 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0904 18:11:30.631588 19 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0904 18:11:30.631600 19 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0904 18:11:30.631605 19 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0904 18:11:30.631613 19 discovery.go:139] Checking APIGroup: node.k8s.io
  I0904 18:11:30.633046 19 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0904 18:11:30.633055 19 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0904 18:11:30.633060 19 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0904 18:11:30.633065 19 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0904 18:11:30.634562 19 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0904 18:11:30.634582 19 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0904 18:11:30.634588 19 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0904 18:11:30.634593 19 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0904 18:11:30.635974 19 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0904 18:11:30.635987 19 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  I0904 18:11:30.635992 19 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0904 18:11:30.635998 19 discovery.go:139] Checking APIGroup: metrics.k8s.io
  I0904 18:11:30.637362 19 discovery.go:147] PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  I0904 18:11:30.637371 19 discovery.go:148] Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  I0904 18:11:30.637376 19 discovery.go:154] metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  I0904 18:11:30.637522 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-7563" for this suite. @ 09/04/24 18:11:30.642
• [0.218 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 09/04/24 18:11:30.65
  I0904 18:11:30.650936 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:11:30.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:11:30.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:11:30.671
  STEP: Creating pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954 @ 09/04/24 18:11:30.675
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/04/24 18:11:32.692
  I0904 18:11:32.696611 19 container_probe.go:1749] Initial restart count of pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 is 0
  I0904 18:11:32.699504 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:34.704587 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:36.710199 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:38.716815 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:40.723197 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:42.728935 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:44.734471 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:46.739365 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:48.745276 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:50.750563 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:52.756814 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:52.756850 19 container_probe.go:1763] Restart count of pod container-probe-6954/liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 is now 1 (20.060218161s elapsed)
  I0904 18:11:54.762741 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:56.768903 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:11:58.774631 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:00.779418 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:02.784905 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:04.789738 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:06.795253 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:08.800904 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:10.805733 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:12.811342 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:12.811407 19 container_probe.go:1763] Restart count of pod container-probe-6954/liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 is now 2 (40.114774713s elapsed)
  I0904 18:12:14.816969 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:16.822691 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:18.828540 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:20.834201 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:22.839987 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:24.844766 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:26.851194 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:28.857494 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:30.862634 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:32.868925 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:32.868955 19 container_probe.go:1763] Restart count of pod container-probe-6954/liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 is now 3 (1m0.172323168s elapsed)
  I0904 18:12:34.874290 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:36.879736 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:38.886056 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:40.891679 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:42.897411 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:44.901962 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:46.907408 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:48.912487 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:50.918214 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:52.924181 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:52.924213 19 container_probe.go:1763] Restart count of pod container-probe-6954/liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 is now 4 (1m20.227580929s elapsed)
  I0904 18:12:54.929012 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:56.935051 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:12:58.940315 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:00.945252 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:02.950348 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:04.955023 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:06.960656 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:08.965692 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:10.971951 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:12.977592 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:14.983037 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:16.988248 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:18.992988 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:20.998509 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:23.003508 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:25.008512 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:27.014679 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:29.019137 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:31.024299 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:33.030018 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:35.034479 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:37.041358 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:39.046400 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:41.051080 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:43.056845 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:45.061667 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:47.067892 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:49.072761 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:51.077751 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:53.082869 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:55.087389 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:57.093242 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:13:59.098731 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:14:01.104589 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:14:03.110276 19 container_probe.go:1759] Get pod liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 in namespace container-probe-6954
  I0904 18:14:03.110309 19 container_probe.go:1763] Restart count of pod container-probe-6954/liveness-f8076a2f-71e1-4e13-830f-d878183b57b2 is now 5 (2m30.413676896s elapsed)
  STEP: deleting the pod @ 09/04/24 18:14:03.11
  I0904 18:14:03.123790 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6954" for this suite. @ 09/04/24 18:14:03.128
• [152.485 seconds]
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 09/04/24 18:14:03.135
  I0904 18:14:03.135518 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename proxy @ 09/04/24 18:14:03.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:14:03.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:14:03.157
  I0904 18:14:03.161196 19 proxy.go:293] Creating pod...
  I0904 18:14:05.181517 19 proxy.go:317] Creating service...
  I0904 18:14:05.192154 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/pods/agnhost/proxy/some/path/with/DELETE
  I0904 18:14:05.196953 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0904 18:14:05.196994 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/pods/agnhost/proxy/some/path/with/GET
  I0904 18:14:05.201824 19 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0904 18:14:05.201856 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/pods/agnhost/proxy/some/path/with/HEAD
  I0904 18:14:05.205208 19 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0904 18:14:05.205227 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/pods/agnhost/proxy/some/path/with/OPTIONS
  I0904 18:14:05.208573 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0904 18:14:05.208598 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/pods/agnhost/proxy/some/path/with/PATCH
  I0904 18:14:05.211505 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0904 18:14:05.211520 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/pods/agnhost/proxy/some/path/with/POST
  I0904 18:14:05.215775 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0904 18:14:05.215807 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/pods/agnhost/proxy/some/path/with/PUT
  I0904 18:14:05.219342 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0904 18:14:05.219358 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/services/test-service/proxy/some/path/with/DELETE
  I0904 18:14:05.224327 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0904 18:14:05.224380 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/services/test-service/proxy/some/path/with/GET
  I0904 18:14:05.230593 19 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0904 18:14:05.230626 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/services/test-service/proxy/some/path/with/HEAD
  I0904 18:14:05.235884 19 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0904 18:14:05.235904 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/services/test-service/proxy/some/path/with/OPTIONS
  I0904 18:14:05.240590 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0904 18:14:05.240855 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/services/test-service/proxy/some/path/with/PATCH
  I0904 18:14:05.246592 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0904 18:14:05.246622 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/services/test-service/proxy/some/path/with/POST
  I0904 18:14:05.251516 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0904 18:14:05.251549 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6757/services/test-service/proxy/some/path/with/PUT
  I0904 18:14:05.256390 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0904 18:14:05.256579 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-6757" for this suite. @ 09/04/24 18:14:05.26
• [2.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 09/04/24 18:14:05.267
  I0904 18:14:05.267324 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename subpath @ 09/04/24 18:14:05.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:14:05.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:14:05.286
  STEP: Setting up data @ 09/04/24 18:14:05.289
  STEP: Creating pod pod-subpath-test-configmap-6fkc @ 09/04/24 18:14:05.298
  STEP: Creating a pod to test atomic-volume-subpath @ 09/04/24 18:14:05.298
  STEP: Saw pod success @ 09/04/24 18:14:29.38
  I0904 18:14:29.384474 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-subpath-test-configmap-6fkc container test-container-subpath-configmap-6fkc: <nil>
  STEP: delete the pod @ 09/04/24 18:14:29.399
  STEP: Deleting pod pod-subpath-test-configmap-6fkc @ 09/04/24 18:14:29.415
  I0904 18:14:29.415745 19 delete.go:62] Deleting pod "pod-subpath-test-configmap-6fkc" in namespace "subpath-9233"
  I0904 18:14:29.419599 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9233" for this suite. @ 09/04/24 18:14:29.423
• [24.162 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 09/04/24 18:14:29.43
  I0904 18:14:29.430021 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:14:29.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:14:29.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:14:29.45
  STEP: Creating configMap with name projected-configmap-test-volume-map-e84794cc-f23d-4ded-9210-bc814b63981f @ 09/04/24 18:14:29.454
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:14:29.458
  STEP: Saw pod success @ 09/04/24 18:14:33.481
  I0904 18:14:33.485671 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-configmaps-e600acc5-b1ad-4dcc-be2f-99b0042c20e7 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:14:33.492
  I0904 18:14:33.508285 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5994" for this suite. @ 09/04/24 18:14:33.511
• [4.088 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2216
  STEP: Creating a kubernetes client @ 09/04/24 18:14:33.517
  I0904 18:14:33.517970 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:14:33.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:14:33.537
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:14:33.541
  STEP: creating service in namespace services-6252 @ 09/04/24 18:14:33.544
  STEP: creating service affinity-nodeport-transition in namespace services-6252 @ 09/04/24 18:14:33.544
  STEP: creating replication controller affinity-nodeport-transition in namespace services-6252 @ 09/04/24 18:14:33.558
  I0904 18:14:33.563959      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-6252, replica count: 3
  I0904 18:14:36.614304      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 18:14:36.627526 19 resource.go:361] Creating new exec pod
  I0904 18:14:39.646243 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6252 exec execpod-affinityr427t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I0904 18:14:39.737688 19 builder.go:146] stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  I0904 18:14:39.737738 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:14:39.737901 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6252 exec execpod-affinityr427t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.214 80'
  I0904 18:14:39.824589 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.214 80\n+ echo hostName\nConnection to 10.152.183.214 80 port [tcp/http] succeeded!\n"
  I0904 18:14:39.824647 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:14:39.824726 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6252 exec execpod-affinityr427t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.40.239 31453'
  I0904 18:14:39.914918 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.40.239 31453\n+ echo hostName\nConnection to 172.31.40.239 31453 port [tcp/*] succeeded!\n"
  I0904 18:14:39.914958 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:14:39.915040 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6252 exec execpod-affinityr427t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.21.169 31453'
  I0904 18:14:39.999858 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.21.169 31453\n+ echo hostName\nConnection to 172.31.21.169 31453 port [tcp/*] succeeded!\n"
  I0904 18:14:39.999921 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:14:40.012521 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6252 exec execpod-affinityr427t -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.21.169:31453/ ; done'
  I0904 18:14:40.156320 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n"
  I0904 18:14:40.156373 19 builder.go:147] stdout: "\naffinity-nodeport-transition-5jjvp\naffinity-nodeport-transition-jkwkq\naffinity-nodeport-transition-jkwkq\naffinity-nodeport-transition-5jjvp\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-jkwkq\naffinity-nodeport-transition-jkwkq\naffinity-nodeport-transition-jkwkq\naffinity-nodeport-transition-5jjvp\naffinity-nodeport-transition-5jjvp\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-jkwkq\naffinity-nodeport-transition-jkwkq\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z"
  I0904 18:14:40.156386 19 service.go:242] Received response from host: affinity-nodeport-transition-5jjvp
  I0904 18:14:40.156395 19 service.go:242] Received response from host: affinity-nodeport-transition-jkwkq
  I0904 18:14:40.156401 19 service.go:242] Received response from host: affinity-nodeport-transition-jkwkq
  I0904 18:14:40.156406 19 service.go:242] Received response from host: affinity-nodeport-transition-5jjvp
  I0904 18:14:40.156412 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.156416 19 service.go:242] Received response from host: affinity-nodeport-transition-jkwkq
  I0904 18:14:40.156421 19 service.go:242] Received response from host: affinity-nodeport-transition-jkwkq
  I0904 18:14:40.156440 19 service.go:242] Received response from host: affinity-nodeport-transition-jkwkq
  I0904 18:14:40.156445 19 service.go:242] Received response from host: affinity-nodeport-transition-5jjvp
  I0904 18:14:40.156451 19 service.go:242] Received response from host: affinity-nodeport-transition-5jjvp
  I0904 18:14:40.156455 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.156460 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.156476 19 service.go:242] Received response from host: affinity-nodeport-transition-jkwkq
  I0904 18:14:40.156481 19 service.go:242] Received response from host: affinity-nodeport-transition-jkwkq
  I0904 18:14:40.156485 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.156490 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.165950 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6252 exec execpod-affinityr427t -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.21.169:31453/ ; done'
  I0904 18:14:40.318670 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:31453/\n"
  I0904 18:14:40.318733 19 builder.go:147] stdout: "\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z\naffinity-nodeport-transition-h9j6z"
  I0904 18:14:40.318746 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318753 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318763 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318768 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318774 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318780 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318784 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318789 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318795 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318802 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318807 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318812 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318818 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318824 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318829 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318834 19 service.go:242] Received response from host: affinity-nodeport-transition-h9j6z
  I0904 18:14:40.318921 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6252, will wait for the garbage collector to delete the pods @ 09/04/24 18:14:40.332
  I0904 18:14:40.394891 19 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 7.505152ms
  I0904 18:14:40.495396 19 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 100.500595ms
  I0904 18:14:43.423150 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6252" for this suite. @ 09/04/24 18:14:43.427
• [9.915 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:164
  STEP: Creating a kubernetes client @ 09/04/24 18:14:43.433
  I0904 18:14:43.433199 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 18:14:43.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:14:43.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:14:43.455
  STEP: Discovering how many secrets are in namespace by default @ 09/04/24 18:14:43.458
  STEP: Counting existing ResourceQuota @ 09/04/24 18:14:48.462
  STEP: Creating a ResourceQuota @ 09/04/24 18:14:53.467
  STEP: Ensuring resource quota status is calculated @ 09/04/24 18:14:53.473
  STEP: Creating a Secret @ 09/04/24 18:14:55.478
  STEP: Ensuring resource quota status captures secret creation @ 09/04/24 18:14:55.49
  STEP: Deleting a secret @ 09/04/24 18:14:57.495
  STEP: Ensuring resource quota status released usage @ 09/04/24 18:14:57.502
  I0904 18:14:59.507865 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7005" for this suite. @ 09/04/24 18:14:59.511
• [16.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:643
  STEP: Creating a kubernetes client @ 09/04/24 18:14:59.519
  I0904 18:14:59.519046 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:14:59.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:14:59.537
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:14:59.544
  STEP: Setting up server cert @ 09/04/24 18:14:59.574
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:14:59.7
  STEP: Deploying the webhook pod @ 09/04/24 18:14:59.709
  STEP: Wait for the deployment to be ready @ 09/04/24 18:14:59.723
  I0904 18:14:59.732791 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/04/24 18:15:01.749
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:15:01.765
  I0904 18:15:02.766336 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 09/04/24 18:15:02.846
  STEP: Creating a configMap that should be mutated @ 09/04/24 18:15:02.856
  STEP: Deleting the collection of validation webhooks @ 09/04/24 18:15:02.875
  STEP: Creating a configMap that should not be mutated @ 09/04/24 18:15:02.921
  I0904 18:15:02.983901 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2924" for this suite. @ 09/04/24 18:15:02.989
  STEP: Destroying namespace "webhook-markers-5126" for this suite. @ 09/04/24 18:15:02.999
• [3.487 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 09/04/24 18:15:03.006
  I0904 18:15:03.006244 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename events @ 09/04/24 18:15:03.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:15:03.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:15:03.027
  STEP: creating a test event @ 09/04/24 18:15:03.031
  STEP: listing all events in all namespaces @ 09/04/24 18:15:03.166
  STEP: patching the test event @ 09/04/24 18:15:03.177
  STEP: fetching the test event @ 09/04/24 18:15:03.184
  STEP: updating the test event @ 09/04/24 18:15:03.188
  STEP: getting the test event @ 09/04/24 18:15:03.199
  STEP: deleting the test event @ 09/04/24 18:15:03.202
  STEP: listing all events in all namespaces @ 09/04/24 18:15:03.21
  I0904 18:15:03.238180 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-9056" for this suite. @ 09/04/24 18:15:03.245
• [0.247 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 09/04/24 18:15:03.253
  I0904 18:15:03.253028 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-pred @ 09/04/24 18:15:03.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:15:03.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:15:03.279
  I0904 18:15:03.282921 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0904 18:15:03.289924 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I0904 18:15:03.293879 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-21-169 before test
  I0904 18:15:03.298297 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-8z5w8 from ingress-nginx-kubernetes-worker started at 2024-09-04 18:02:11 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.298314 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 18:15:03.298322 19 predicates.go:957] calico-node-2rjpm from kube-system started at 2024-09-04 17:55:30 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.298337 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 18:15:03.298342 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-09-04 17:58:02 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.298447 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0904 18:15:03.298454 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-zslmr from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 18:15:03.298459 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 18:15:03.298469 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0904 18:15:03.298475 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-40-239 before test
  I0904 18:15:03.303680 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-n2qsn from ingress-nginx-kubernetes-worker started at 2024-09-04 17:47:19 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.303693 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 18:15:03.303699 19 predicates.go:957] calico-node-kswsn from kube-system started at 2024-09-04 17:55:51 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.303770 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 18:15:03.303821 19 predicates.go:957] sonobuoy-e2e-job-7c4b682519124aad from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 18:15:03.303862 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0904 18:15:03.303910 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 18:15:03.303955 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-lk4m4 from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 18:15:03.304005 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 18:15:03.304033 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0904 18:15:03.304078 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-7-223 before test
  I0904 18:15:03.308849 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-z5zrp from ingress-nginx-kubernetes-worker started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.308863 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 18:15:03.308869 19 predicates.go:957] calico-node-bc9bt from kube-system started at 2024-09-04 17:55:40 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.308874 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 18:15:03.308900 19 predicates.go:957] coredns-5b4857d7c8-brh4s from kube-system started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.308975 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0904 18:15:03.309016 19 predicates.go:957] kube-state-metrics-5d7bdccd49-77shl from kube-system started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.309021 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 0
  I0904 18:15:03.309029 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-v8zbg from kube-system started at 2024-09-04 17:46:10 +0000 UTC (2 container statuses recorded)
  I0904 18:15:03.309034 19 predicates.go:959] 	Container metrics-server ready: true, restart count 0
  I0904 18:15:03.309039 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I0904 18:15:03.309044 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-lr685 from kubernetes-dashboard started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.309049 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I0904 18:15:03.309054 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-862w2 from kubernetes-dashboard started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 18:15:03.309059 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 0
  I0904 18:15:03.309065 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-wh7sc from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 18:15:03.309090 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 18:15:03.309096 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 09/04/24 18:15:03.309
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17f21d30f4430b73], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] @ 09/04/24 18:15:03.337
  I0904 18:15:04.334413 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5333" for this suite. @ 09/04/24 18:15:04.338
• [1.093 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 09/04/24 18:15:04.347
  I0904 18:15:04.347052 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:15:04.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:15:04.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:15:04.365
  STEP: Creating pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915 @ 09/04/24 18:15:04.369
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/04/24 18:15:06.389
  I0904 18:15:06.393215 19 container_probe.go:1749] Initial restart count of pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 is 0
  I0904 18:15:06.396590 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:08.404124 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:10.409885 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:12.414530 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:14.419877 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:16.425280 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:18.428734 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:20.434493 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:22.440314 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:24.446564 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:26.451622 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:28.457254 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:30.462818 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:32.468730 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:34.474217 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:36.479671 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:38.485409 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:40.490578 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:42.495637 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:44.500652 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:46.506472 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:48.511398 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:50.515571 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:52.521655 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:54.527124 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:56.533650 19 container_probe.go:1759] Get pod busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 in namespace container-probe-9915
  I0904 18:15:56.533683 19 container_probe.go:1763] Restart count of pod container-probe-9915/busybox-cd4a1966-054e-404d-a748-f4e680ed2b23 is now 1 (50.140443349s elapsed)
  STEP: deleting the pod @ 09/04/24 18:15:56.533
  I0904 18:15:56.547657 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9915" for this suite. @ 09/04/24 18:15:56.551
• [52.211 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 09/04/24 18:15:56.558
  I0904 18:15:56.558202 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename discovery @ 09/04/24 18:15:56.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:15:56.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:15:56.578
  STEP: Setting up server cert @ 09/04/24 18:15:56.582
  STEP: Requesting APIResourceList from "/api/v1" @ 09/04/24 18:15:56.753
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 09/04/24 18:15:56.755
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 09/04/24 18:15:56.757
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 09/04/24 18:15:56.758
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 09/04/24 18:15:56.76
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 09/04/24 18:15:56.761
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 09/04/24 18:15:56.763
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 09/04/24 18:15:56.764
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 09/04/24 18:15:56.766
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 09/04/24 18:15:56.767
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 09/04/24 18:15:56.768
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 09/04/24 18:15:56.77
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 09/04/24 18:15:56.771
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 09/04/24 18:15:56.773
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 09/04/24 18:15:56.774
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 09/04/24 18:15:56.776
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 09/04/24 18:15:56.777
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 09/04/24 18:15:56.778
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 09/04/24 18:15:56.78
  I0904 18:15:56.781792 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-108" for this suite. @ 09/04/24 18:15:56.786
• [0.236 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 09/04/24 18:15:56.794
  I0904 18:15:56.794588 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:15:56.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:15:56.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:15:56.816
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:15:56.819
  STEP: Saw pod success @ 09/04/24 18:16:00.841
  I0904 18:16:00.845867 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-52959328-ad7d-409e-8663-79776479e6ac container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:16:00.853
  I0904 18:16:00.872126 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4391" for this suite. @ 09/04/24 18:16:00.875
• [4.089 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:235
  STEP: Creating a kubernetes client @ 09/04/24 18:16:00.883
  I0904 18:16:00.883238 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:16:00.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:16:00.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:16:00.904
  STEP: Setting up server cert @ 09/04/24 18:16:00.932
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:16:01.07
  STEP: Deploying the webhook pod @ 09/04/24 18:16:01.08
  STEP: Wait for the deployment to be ready @ 09/04/24 18:16:01.094
  I0904 18:16:01.101643 19 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 09/04/24 18:16:03.114
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:16:03.127
  I0904 18:16:04.127629 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 09/04/24 18:16:04.136
  STEP: create a namespace for the webhook @ 09/04/24 18:16:04.148
  STEP: create a configmap should be unconditionally rejected by the webhook @ 09/04/24 18:16:04.179
  I0904 18:16:04.371153 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-703" for this suite. @ 09/04/24 18:16:04.377
  STEP: Destroying namespace "webhook-markers-9353" for this suite. @ 09/04/24 18:16:04.384
  STEP: Destroying namespace "fail-closed-namespace-5651" for this suite. @ 09/04/24 18:16:04.391
• [3.513 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 09/04/24 18:16:04.396
  I0904 18:16:04.396914 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 18:16:04.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:16:04.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:16:04.417
  STEP: Creating secret with name secret-test-map-71e06281-ea41-4535-9b40-96b8349c609c @ 09/04/24 18:16:04.42
  STEP: Creating a pod to test consume secrets @ 09/04/24 18:16:04.424
  STEP: Saw pod success @ 09/04/24 18:16:08.445
  I0904 18:16:08.448877 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-secrets-f1f1043a-d70b-48bf-b05e-327acf51fe14 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 18:16:08.455
  I0904 18:16:08.472220 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2337" for this suite. @ 09/04/24 18:16:08.475
• [4.084 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:746
  STEP: Creating a kubernetes client @ 09/04/24 18:16:08.481
  I0904 18:16:08.481445 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 18:16:08.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:16:08.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:16:08.502
  STEP: Creating a ResourceQuota with terminating scope @ 09/04/24 18:16:08.505
  STEP: Ensuring ResourceQuota status is calculated @ 09/04/24 18:16:08.51
  STEP: Creating a ResourceQuota with not terminating scope @ 09/04/24 18:16:10.515
  STEP: Ensuring ResourceQuota status is calculated @ 09/04/24 18:16:10.52
  STEP: Creating a long running pod @ 09/04/24 18:16:12.525
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 09/04/24 18:16:12.54
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 09/04/24 18:16:14.545
  STEP: Deleting the pod @ 09/04/24 18:16:16.55
  STEP: Ensuring resource quota status released the pod usage @ 09/04/24 18:16:16.565
  STEP: Creating a terminating pod @ 09/04/24 18:16:18.569
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 09/04/24 18:16:18.581
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 09/04/24 18:16:20.587
  STEP: Deleting the pod @ 09/04/24 18:16:22.592
  STEP: Ensuring resource quota status released the pod usage @ 09/04/24 18:16:22.602
  I0904 18:16:24.607553 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-450" for this suite. @ 09/04/24 18:16:24.611
• [16.137 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:196
  STEP: Creating a kubernetes client @ 09/04/24 18:16:24.618
  I0904 18:16:24.618288 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:16:24.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:16:24.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:16:24.641
  STEP: Setting up server cert @ 09/04/24 18:16:24.668
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:16:25.09
  STEP: Deploying the webhook pod @ 09/04/24 18:16:25.097
  STEP: Wait for the deployment to be ready @ 09/04/24 18:16:25.11
  I0904 18:16:25.117595 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/04/24 18:16:27.131
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:16:27.143
  I0904 18:16:28.143974 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 09/04/24 18:16:28.152
  I0904 18:16:28.326814 19 webhook.go:2669] Waiting for webhook configuration to be ready...
  STEP: create a pod that should be denied by the webhook @ 09/04/24 18:16:28.433
  STEP: create a pod that causes the webhook to hang @ 09/04/24 18:16:28.443
  STEP: create a configmap that should be denied by the webhook @ 09/04/24 18:16:38.451
  STEP: create a configmap that should be admitted by the webhook @ 09/04/24 18:16:38.458
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 09/04/24 18:16:38.466
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 09/04/24 18:16:38.476
  STEP: create a namespace that bypass the webhook @ 09/04/24 18:16:38.481
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 09/04/24 18:16:38.497
  I0904 18:16:38.542932 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9945" for this suite. @ 09/04/24 18:16:38.546
  STEP: Destroying namespace "webhook-markers-2840" for this suite. @ 09/04/24 18:16:38.561
  STEP: Destroying namespace "exempted-namespace-9494" for this suite. @ 09/04/24 18:16:38.567
• [13.955 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 09/04/24 18:16:38.574
  I0904 18:16:38.574162 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename deployment @ 09/04/24 18:16:38.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:16:38.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:16:38.595
  I0904 18:16:38.598993 19 deployment.go:792] Creating deployment "test-recreate-deployment"
  I0904 18:16:38.604002 19 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0904 18:16:38.610027 19 deployment.go:222] deployment "test-recreate-deployment" doesn't have the required revision set
  I0904 18:16:40.620081 19 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I0904 18:16:40.624234 19 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I0904 18:16:40.635563 19 deployment.go:313] Updating deployment test-recreate-deployment
  I0904 18:16:40.635586 19 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0904 18:16:40.742356 19 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2038",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2e74e8e4-7c1b-4522-ba72-b3c402de2f38",
      ResourceVersion: (string) (len=5) "11410",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070598,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070598,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-88d47c55d\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0904 18:16:40.746918 19 deployment.go:39] New ReplicaSet "test-recreate-deployment-88d47c55d" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-88d47c55d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2038",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "598cefee-359f-4569-aed0-475b58d95670",
      ResourceVersion: (string) (len=5) "11409",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070600,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "2e74e8e4-7c1b-4522-ba72-b3c402de2f38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 65 37 34 65 38  65 34 2d 37 63 31 62 2d  |\"2e74e8e4-7c1b-|
              00000120  34 35 32 32 2d 62 61 37  32 2d 62 33 63 34 30 32  |4522-ba72-b3c402|
              00000130  64 65 32 66 33 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |de2f38\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:16:40.748864 19 deployment.go:44] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0904 18:16:40.749052 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-7549bcf47c",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2038",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4da14193-0bf7-4c4e-af3b-3c7904f617de",
      ResourceVersion: (string) (len=5) "11398",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070598,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "2e74e8e4-7c1b-4522-ba72-b3c402de2f38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 65 37 34 65 38  65 34 2d 37 63 31 62 2d  |\"2e74e8e4-7c1b-|
              00000120  34 35 32 32 2d 62 61 37  32 2d 62 33 63 34 30 32  |4522-ba72-b3c402|
              00000130  64 65 32 66 33 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |de2f38\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c",
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:16:40.753716 19 deployment.go:67] Pod "test-recreate-deployment-88d47c55d-cwhnh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-88d47c55d-cwhnh",
      GenerateName: (string) (len=35) "test-recreate-deployment-88d47c55d-",
      Namespace: (string) (len=15) "deployment-2038",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3fc0ef4a-e95f-49ba-9279-e3cc8cde8e0b",
      ResourceVersion: (string) (len=5) "11408",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070600,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-88d47c55d",
          UID: (types.UID) (len=36) "598cefee-359f-4569-aed0-475b58d95670",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 39  38 63 65 66 65 65 2d 33  |d\":\"598cefee-3|
              00000090  35 39 66 2d 34 35 36 39  2d 61 65 64 30 2d 34 37  |59f-4569-aed0-47|
              000000a0  35 62 35 38 64 39 35 36  37 30 5c 22 7d 22 3a 7b  |5b58d95670\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-m4855",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-m4855",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.21.169",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.21.169"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070600,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-m4855",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:16:40.755321 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2038" for this suite. @ 09/04/24 18:16:40.759
• [2.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 09/04/24 18:16:40.766
  I0904 18:16:40.766816 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename deployment @ 09/04/24 18:16:40.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:16:40.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:16:40.789
  I0904 18:16:40.792720 19 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0904 18:16:40.800465 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I0904 18:16:45.804925 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/04/24 18:16:45.804
  I0904 18:16:45.805056 19 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I0904 18:16:45.811493 19 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0904 18:16:45.818169 19 deployment.go:222] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  I0904 18:16:47.828070 19 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0904 18:16:47.831451 19 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0904 18:16:47.841205 19 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4699",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1003fa96-4260-4fe1-90a8-26f94d981978",
      ResourceVersion: (string) (len=5) "11529",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070605,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070605,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070605,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070605,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070605,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-56bb5bb765\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0904 18:16:47.845659 19 deployment.go:39] New ReplicaSet "test-rolling-update-deployment-56bb5bb765" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-56bb5bb765",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4699",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fd1cf887-c47c-4589-8714-c8a8b455e505",
      ResourceVersion: (string) (len=5) "11519",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070605,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "1003fa96-4260-4fe1-90a8-26f94d981978",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070605,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 31 30 30 33 66 61  39 36 2d 34 32 36 30 2d  |\"1003fa96-4260-|
              00000120  34 66 65 31 2d 39 30 61  38 2d 32 36 66 39 34 64  |4fe1-90a8-26f94d|
              00000130  39 38 31 39 37 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |981978\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:16:47.846491 19 deployment.go:44] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0904 18:16:47.846731 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4699",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ae739ac3-e963-4316-8ec5-873184857e58",
      ResourceVersion: (string) (len=5) "11528",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070600,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "1003fa96-4260-4fe1-90a8-26f94d981978",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 31 30 30 33 66 61 39  |"uid\":\"1003fa9|
              000000b0  36 2d 34 32 36 30 2d 34  66 65 31 2d 39 30 61 38  |6-4260-4fe1-90a8|
              000000c0  2d 32 36 66 39 34 64 39  38 31 39 37 38 5c 22 7d  |-26f94d981978\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:16:47.851689 19 deployment.go:67] Pod "test-rolling-update-deployment-56bb5bb765-w9gs2" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-56bb5bb765-w9gs2",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-56bb5bb765-",
      Namespace: (string) (len=15) "deployment-4699",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d9628898-a57b-4641-a985-6e18ae883624",
      ResourceVersion: (string) (len=5) "11518",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070605,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765",
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-56bb5bb765",
          UID: (types.UID) (len=36) "fd1cf887-c47c-4589-8714-c8a8b455e505",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070605,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 64  31 63 66 38 38 37 2d 63  |d\":\"fd1cf887-c|
              00000090  34 37 63 2d 34 35 38 39  2d 38 37 31 34 2d 63 38  |47c-4589-8714-c8|
              000000a0  61 38 62 34 35 35 65 35  30 35 5c 22 7d 22 3a 7b  |a8b455e505\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 34  36 2e 31 39 31 5c 22 7d  |2.168.146.191\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kbgvf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kbgvf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070605,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070606,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861070605,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.21.169",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.21.169"
        }
      },
      PodIP: (string) (len=15) "192.168.146.191",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.146.191"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861070605,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861070606,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6",
          ContainerID: (string) (len=77) "containerd://70a3205f6433591ab1f79d7faa2703a11453f85d605e705040801831a9c3f898",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-kbgvf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:16:47.852984 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4699" for this suite. @ 09/04/24 18:16:47.856
• [7.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 09/04/24 18:16:47.865
  I0904 18:16:47.865633 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename subpath @ 09/04/24 18:16:47.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:16:47.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:16:47.887
  STEP: Setting up data @ 09/04/24 18:16:47.89
  STEP: Creating pod pod-subpath-test-configmap-4lxm @ 09/04/24 18:16:47.898
  STEP: Creating a pod to test atomic-volume-subpath @ 09/04/24 18:16:47.899
  STEP: Saw pod success @ 09/04/24 18:17:11.976
  I0904 18:17:11.980706 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-subpath-test-configmap-4lxm container test-container-subpath-configmap-4lxm: <nil>
  STEP: delete the pod @ 09/04/24 18:17:11.998
  STEP: Deleting pod pod-subpath-test-configmap-4lxm @ 09/04/24 18:17:12.016
  I0904 18:17:12.016619 19 delete.go:62] Deleting pod "pod-subpath-test-configmap-4lxm" in namespace "subpath-8493"
  I0904 18:17:12.020184 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8493" for this suite. @ 09/04/24 18:17:12.023
• [24.164 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:329
  STEP: Creating a kubernetes client @ 09/04/24 18:17:12.03
  I0904 18:17:12.030023 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-preemption @ 09/04/24 18:17:12.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:17:12.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:17:12.052
  I0904 18:17:12.072483 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  I0904 18:18:12.078531 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Select a node to run the lower and higher priority pods @ 09/04/24 18:18:12.082
  STEP: Create a low priority pod that consumes 1/1 of node resources @ 09/04/24 18:18:12.09
  I0904 18:18:12.100911 19 preemption.go:367] Created pod: victim-pod
  STEP: Wait for the victim pod to be scheduled @ 09/04/24 18:18:12.1
  STEP: Create a high priority pod to trigger preemption of the lower priority pod @ 09/04/24 18:18:14.11
  I0904 18:18:14.118718 19 preemption.go:385] Created pod: preemptor-pod
  STEP: Waiting for the victim pod to be terminating @ 09/04/24 18:18:14.118
  STEP: Verifying the pod has the pod disruption condition @ 09/04/24 18:18:16.128
  I0904 18:18:16.131362 19 pod_client.go:378] Removing pod's "victim-pod" finalizer: "example.com/test-finalizer"
  I0904 18:18:16.646032 19 pod_client.go:173] Successfully updated pod "victim-pod"
  I0904 18:18:16.679102 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2776" for this suite. @ 09/04/24 18:18:16.683
• [64.661 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 09/04/24 18:18:16.691
  I0904 18:18:16.691356 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename svc-latency @ 09/04/24 18:18:16.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:18:16.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:18:16.71
  I0904 18:18:16.714396 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-3098 @ 09/04/24 18:18:16.715
  I0904 18:18:16.720641      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3098, replica count: 1
  I0904 18:18:17.772028      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 18:18:18.772189      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 18:18:18.883641 19 service_latency.go:356] Created: latency-svc-rtdh9
  I0904 18:18:18.892534 19 service_latency.go:363] Got endpoints: latency-svc-rtdh9 [19.695935ms]
  I0904 18:18:18.903093 19 service_latency.go:356] Created: latency-svc-m92wq
  I0904 18:18:18.908096 19 service_latency.go:356] Created: latency-svc-ddzk6
  I0904 18:18:18.910709 19 service_latency.go:363] Got endpoints: latency-svc-m92wq [17.870339ms]
  I0904 18:18:18.915149 19 service_latency.go:356] Created: latency-svc-pq7p9
  I0904 18:18:18.920875 19 service_latency.go:363] Got endpoints: latency-svc-ddzk6 [28.275202ms]
  I0904 18:18:18.921754 19 service_latency.go:356] Created: latency-svc-f6ntv
  I0904 18:18:18.921801 19 service_latency.go:363] Got endpoints: latency-svc-pq7p9 [28.852864ms]
  I0904 18:18:18.929285 19 service_latency.go:356] Created: latency-svc-klkxz
  I0904 18:18:18.931451 19 service_latency.go:363] Got endpoints: latency-svc-f6ntv [38.564271ms]
  I0904 18:18:18.935053 19 service_latency.go:363] Got endpoints: latency-svc-klkxz [42.133657ms]
  I0904 18:18:18.939547 19 service_latency.go:356] Created: latency-svc-8sdpl
  I0904 18:18:18.942672 19 service_latency.go:356] Created: latency-svc-zmkb5
  I0904 18:18:18.944872 19 service_latency.go:363] Got endpoints: latency-svc-8sdpl [51.858079ms]
  I0904 18:18:18.949976 19 service_latency.go:363] Got endpoints: latency-svc-zmkb5 [56.903319ms]
  I0904 18:18:18.951043 19 service_latency.go:356] Created: latency-svc-586cl
  I0904 18:18:18.959707 19 service_latency.go:363] Got endpoints: latency-svc-586cl [66.466339ms]
  I0904 18:18:18.962052 19 service_latency.go:356] Created: latency-svc-vdmpw
  I0904 18:18:18.964359 19 service_latency.go:363] Got endpoints: latency-svc-vdmpw [71.37791ms]
  I0904 18:18:18.964998 19 service_latency.go:356] Created: latency-svc-phbvp
  I0904 18:18:18.969923 19 service_latency.go:363] Got endpoints: latency-svc-phbvp [76.793073ms]
  I0904 18:18:18.974742 19 service_latency.go:356] Created: latency-svc-j6j8z
  I0904 18:18:18.980898 19 service_latency.go:363] Got endpoints: latency-svc-j6j8z [87.792142ms]
  I0904 18:18:18.981894 19 service_latency.go:356] Created: latency-svc-7x7pl
  I0904 18:18:18.986945 19 service_latency.go:356] Created: latency-svc-pnq6f
  I0904 18:18:18.988172 19 service_latency.go:363] Got endpoints: latency-svc-7x7pl [95.022884ms]
  I0904 18:18:18.996756 19 service_latency.go:363] Got endpoints: latency-svc-pnq6f [103.712058ms]
  I0904 18:18:19.049999 19 service_latency.go:356] Created: latency-svc-cdv8w
  I0904 18:18:19.052343 19 service_latency.go:356] Created: latency-svc-j2lw5
  I0904 18:18:19.052767 19 service_latency.go:356] Created: latency-svc-smwps
  I0904 18:18:19.053632 19 service_latency.go:356] Created: latency-svc-fdc27
  I0904 18:18:19.053943 19 service_latency.go:356] Created: latency-svc-857p9
  I0904 18:18:19.054031 19 service_latency.go:356] Created: latency-svc-jz8n9
  I0904 18:18:19.054097 19 service_latency.go:356] Created: latency-svc-5wk88
  I0904 18:18:19.055441 19 service_latency.go:356] Created: latency-svc-skxhh
  I0904 18:18:19.057272 19 service_latency.go:356] Created: latency-svc-wbjm6
  I0904 18:18:19.057278 19 service_latency.go:356] Created: latency-svc-9zllg
  I0904 18:18:19.057646 19 service_latency.go:356] Created: latency-svc-f9mz2
  I0904 18:18:19.058115 19 service_latency.go:356] Created: latency-svc-mv922
  I0904 18:18:19.058177 19 service_latency.go:356] Created: latency-svc-ksbps
  I0904 18:18:19.058008 19 service_latency.go:356] Created: latency-svc-npsnm
  I0904 18:18:19.057911 19 service_latency.go:356] Created: latency-svc-8qgcq
  I0904 18:18:19.063272 19 service_latency.go:363] Got endpoints: latency-svc-j2lw5 [113.269594ms]
  I0904 18:18:19.071843 19 service_latency.go:363] Got endpoints: latency-svc-cdv8w [150.795867ms]
  I0904 18:18:19.077402 19 service_latency.go:363] Got endpoints: latency-svc-9zllg [132.509818ms]
  I0904 18:18:19.077425 19 service_latency.go:363] Got endpoints: latency-svc-fdc27 [80.639968ms]
  I0904 18:18:19.077883 19 service_latency.go:363] Got endpoints: latency-svc-wbjm6 [184.692774ms]
  I0904 18:18:19.079203 19 service_latency.go:356] Created: latency-svc-6q4d9
  I0904 18:18:19.080330 19 service_latency.go:363] Got endpoints: latency-svc-5wk88 [169.59646ms]
  I0904 18:18:19.080700 19 service_latency.go:363] Got endpoints: latency-svc-jz8n9 [92.506367ms]
  I0904 18:18:19.087567 19 service_latency.go:356] Created: latency-svc-7qs68
  I0904 18:18:19.089340 19 service_latency.go:363] Got endpoints: latency-svc-ksbps [196.111491ms]
  I0904 18:18:19.089341 19 service_latency.go:363] Got endpoints: latency-svc-857p9 [167.508557ms]
  I0904 18:18:19.095516 19 service_latency.go:363] Got endpoints: latency-svc-smwps [114.580406ms]
  I0904 18:18:19.098145 19 service_latency.go:363] Got endpoints: latency-svc-f9mz2 [163.014522ms]
  I0904 18:18:19.098273 19 service_latency.go:363] Got endpoints: latency-svc-skxhh [133.875565ms]
  I0904 18:18:19.099471 19 service_latency.go:356] Created: latency-svc-48vkx
  I0904 18:18:19.101046 19 service_latency.go:363] Got endpoints: latency-svc-mv922 [169.370422ms]
  I0904 18:18:19.101170 19 service_latency.go:363] Got endpoints: latency-svc-npsnm [141.438545ms]
  I0904 18:18:19.103756 19 service_latency.go:363] Got endpoints: latency-svc-8qgcq [133.811973ms]
  I0904 18:18:19.109313 19 service_latency.go:356] Created: latency-svc-6w92w
  I0904 18:18:19.109546 19 service_latency.go:363] Got endpoints: latency-svc-7qs68 [37.668214ms]
  I0904 18:18:19.110826 19 service_latency.go:363] Got endpoints: latency-svc-6q4d9 [47.529663ms]
  I0904 18:18:19.118839 19 service_latency.go:356] Created: latency-svc-bhlng
  I0904 18:18:19.119000 19 service_latency.go:363] Got endpoints: latency-svc-48vkx [40.988974ms]
  I0904 18:18:19.119599 19 service_latency.go:363] Got endpoints: latency-svc-6w92w [42.045778ms]
  I0904 18:18:19.123254 19 service_latency.go:363] Got endpoints: latency-svc-bhlng [45.774958ms]
  I0904 18:18:19.124298 19 service_latency.go:356] Created: latency-svc-8lpjk
  I0904 18:18:19.130093 19 service_latency.go:356] Created: latency-svc-b924w
  I0904 18:18:19.135451 19 service_latency.go:356] Created: latency-svc-2trz6
  I0904 18:18:19.140596 19 service_latency.go:356] Created: latency-svc-zgcrx
  I0904 18:18:19.141071 19 service_latency.go:363] Got endpoints: latency-svc-8lpjk [60.723036ms]
  I0904 18:18:19.150516 19 service_latency.go:356] Created: latency-svc-5777l
  I0904 18:18:19.156658 19 service_latency.go:356] Created: latency-svc-xvpmt
  I0904 18:18:19.188620 19 service_latency.go:356] Created: latency-svc-kn2bv
  I0904 18:18:19.191066 19 service_latency.go:363] Got endpoints: latency-svc-b924w [110.18208ms]
  I0904 18:18:19.196868 19 service_latency.go:356] Created: latency-svc-jtktl
  I0904 18:18:19.201063 19 service_latency.go:356] Created: latency-svc-zbjdq
  I0904 18:18:19.205274 19 service_latency.go:356] Created: latency-svc-qd6rx
  I0904 18:18:19.213528 19 service_latency.go:356] Created: latency-svc-9jcg5
  I0904 18:18:19.216639 19 service_latency.go:356] Created: latency-svc-nl8c2
  I0904 18:18:19.220799 19 service_latency.go:356] Created: latency-svc-cbdtb
  I0904 18:18:19.231420 19 service_latency.go:356] Created: latency-svc-nr9gg
  I0904 18:18:19.238263 19 service_latency.go:363] Got endpoints: latency-svc-2trz6 [148.712306ms]
  I0904 18:18:19.238628 19 service_latency.go:356] Created: latency-svc-frx7k
  I0904 18:18:19.243398 19 service_latency.go:356] Created: latency-svc-kblmq
  I0904 18:18:19.250051 19 service_latency.go:356] Created: latency-svc-459z5
  I0904 18:18:19.255332 19 service_latency.go:356] Created: latency-svc-jqk9w
  I0904 18:18:19.291731 19 service_latency.go:363] Got endpoints: latency-svc-zgcrx [202.345489ms]
  I0904 18:18:19.303395 19 service_latency.go:356] Created: latency-svc-8h2bz
  I0904 18:18:19.339766 19 service_latency.go:363] Got endpoints: latency-svc-5777l [244.010589ms]
  I0904 18:18:19.350931 19 service_latency.go:356] Created: latency-svc-jcpl5
  I0904 18:18:19.390365 19 service_latency.go:363] Got endpoints: latency-svc-xvpmt [292.191408ms]
  I0904 18:18:19.400404 19 service_latency.go:356] Created: latency-svc-6rtph
  I0904 18:18:19.441520 19 service_latency.go:363] Got endpoints: latency-svc-kn2bv [343.127397ms]
  I0904 18:18:19.450814 19 service_latency.go:356] Created: latency-svc-28xxg
  I0904 18:18:19.491011 19 service_latency.go:363] Got endpoints: latency-svc-jtktl [389.937883ms]
  I0904 18:18:19.502038 19 service_latency.go:356] Created: latency-svc-dtbhf
  I0904 18:18:19.539460 19 service_latency.go:363] Got endpoints: latency-svc-zbjdq [438.162536ms]
  I0904 18:18:19.552151 19 service_latency.go:356] Created: latency-svc-zsxvb
  I0904 18:18:19.589678 19 service_latency.go:363] Got endpoints: latency-svc-qd6rx [485.890833ms]
  I0904 18:18:19.598596 19 service_latency.go:356] Created: latency-svc-w8m5m
  I0904 18:18:19.641832 19 service_latency.go:363] Got endpoints: latency-svc-9jcg5 [532.253997ms]
  I0904 18:18:19.652700 19 service_latency.go:356] Created: latency-svc-26jvz
  I0904 18:18:19.690774 19 service_latency.go:363] Got endpoints: latency-svc-nl8c2 [579.922141ms]
  I0904 18:18:19.700778 19 service_latency.go:356] Created: latency-svc-cpphw
  I0904 18:18:19.741432 19 service_latency.go:363] Got endpoints: latency-svc-cbdtb [622.408437ms]
  I0904 18:18:19.751597 19 service_latency.go:356] Created: latency-svc-qwlr4
  I0904 18:18:19.789406 19 service_latency.go:363] Got endpoints: latency-svc-nr9gg [669.784549ms]
  I0904 18:18:19.801715 19 service_latency.go:356] Created: latency-svc-rtqv5
  I0904 18:18:19.839919 19 service_latency.go:363] Got endpoints: latency-svc-frx7k [716.640662ms]
  I0904 18:18:19.849412 19 service_latency.go:356] Created: latency-svc-dffsn
  I0904 18:18:19.890069 19 service_latency.go:363] Got endpoints: latency-svc-kblmq [748.952459ms]
  I0904 18:18:19.901129 19 service_latency.go:356] Created: latency-svc-lbd2v
  I0904 18:18:19.940054 19 service_latency.go:363] Got endpoints: latency-svc-459z5 [748.959598ms]
  I0904 18:18:19.949860 19 service_latency.go:356] Created: latency-svc-bbrxm
  I0904 18:18:19.991346 19 service_latency.go:363] Got endpoints: latency-svc-jqk9w [753.027842ms]
  I0904 18:18:20.002432 19 service_latency.go:356] Created: latency-svc-g6vt5
  I0904 18:18:20.041364 19 service_latency.go:363] Got endpoints: latency-svc-8h2bz [749.570431ms]
  I0904 18:18:20.052474 19 service_latency.go:356] Created: latency-svc-2lxh5
  I0904 18:18:20.089731 19 service_latency.go:363] Got endpoints: latency-svc-jcpl5 [749.899109ms]
  I0904 18:18:20.099646 19 service_latency.go:356] Created: latency-svc-d7vq5
  I0904 18:18:20.140714 19 service_latency.go:363] Got endpoints: latency-svc-6rtph [750.303644ms]
  I0904 18:18:20.152461 19 service_latency.go:356] Created: latency-svc-swww2
  I0904 18:18:20.192556 19 service_latency.go:363] Got endpoints: latency-svc-28xxg [750.989952ms]
  I0904 18:18:20.201567 19 service_latency.go:356] Created: latency-svc-rd4ml
  I0904 18:18:20.240719 19 service_latency.go:363] Got endpoints: latency-svc-dtbhf [749.548875ms]
  I0904 18:18:20.252173 19 service_latency.go:356] Created: latency-svc-w6vtc
  I0904 18:18:20.290449 19 service_latency.go:363] Got endpoints: latency-svc-zsxvb [750.914673ms]
  I0904 18:18:20.299709 19 service_latency.go:356] Created: latency-svc-rzgvk
  I0904 18:18:20.343133 19 service_latency.go:363] Got endpoints: latency-svc-w8m5m [753.401609ms]
  I0904 18:18:20.352697 19 service_latency.go:356] Created: latency-svc-pvwtf
  I0904 18:18:20.390767 19 service_latency.go:363] Got endpoints: latency-svc-26jvz [748.708437ms]
  I0904 18:18:20.402818 19 service_latency.go:356] Created: latency-svc-kzwrb
  I0904 18:18:20.439468 19 service_latency.go:363] Got endpoints: latency-svc-cpphw [748.597029ms]
  I0904 18:18:20.452652 19 service_latency.go:356] Created: latency-svc-mhjm7
  I0904 18:18:20.489333 19 service_latency.go:363] Got endpoints: latency-svc-qwlr4 [747.77468ms]
  I0904 18:18:20.498316 19 service_latency.go:356] Created: latency-svc-6gwwf
  I0904 18:18:20.541798 19 service_latency.go:363] Got endpoints: latency-svc-rtqv5 [752.337912ms]
  I0904 18:18:20.553054 19 service_latency.go:356] Created: latency-svc-bv62k
  I0904 18:18:20.591518 19 service_latency.go:363] Got endpoints: latency-svc-dffsn [751.543928ms]
  I0904 18:18:20.601227 19 service_latency.go:356] Created: latency-svc-8xqw9
  I0904 18:18:20.641315 19 service_latency.go:363] Got endpoints: latency-svc-lbd2v [751.198441ms]
  I0904 18:18:20.650118 19 service_latency.go:356] Created: latency-svc-mq494
  I0904 18:18:20.689011 19 service_latency.go:363] Got endpoints: latency-svc-bbrxm [748.91084ms]
  I0904 18:18:20.702103 19 service_latency.go:356] Created: latency-svc-wmr8k
  I0904 18:18:20.740597 19 service_latency.go:363] Got endpoints: latency-svc-g6vt5 [749.164202ms]
  I0904 18:18:20.752521 19 service_latency.go:356] Created: latency-svc-2bnm4
  I0904 18:18:20.789703 19 service_latency.go:363] Got endpoints: latency-svc-2lxh5 [748.186563ms]
  I0904 18:18:20.798672 19 service_latency.go:356] Created: latency-svc-tdh9b
  I0904 18:18:20.840338 19 service_latency.go:363] Got endpoints: latency-svc-d7vq5 [750.562977ms]
  I0904 18:18:20.849317 19 service_latency.go:356] Created: latency-svc-cq9wl
  I0904 18:18:20.890890 19 service_latency.go:363] Got endpoints: latency-svc-swww2 [750.131483ms]
  I0904 18:18:20.903640 19 service_latency.go:356] Created: latency-svc-sqxdn
  I0904 18:18:20.941058 19 service_latency.go:363] Got endpoints: latency-svc-rd4ml [748.451075ms]
  I0904 18:18:20.950809 19 service_latency.go:356] Created: latency-svc-bxpdj
  I0904 18:18:20.989686 19 service_latency.go:363] Got endpoints: latency-svc-w6vtc [748.518728ms]
  I0904 18:18:21.001427 19 service_latency.go:356] Created: latency-svc-ngtsr
  I0904 18:18:21.039563 19 service_latency.go:363] Got endpoints: latency-svc-rzgvk [749.066547ms]
  I0904 18:18:21.049207 19 service_latency.go:356] Created: latency-svc-px265
  I0904 18:18:21.090774 19 service_latency.go:363] Got endpoints: latency-svc-pvwtf [747.597128ms]
  I0904 18:18:21.100331 19 service_latency.go:356] Created: latency-svc-dhd6d
  I0904 18:18:21.140814 19 service_latency.go:363] Got endpoints: latency-svc-kzwrb [749.736129ms]
  I0904 18:18:21.150399 19 service_latency.go:356] Created: latency-svc-m5drg
  I0904 18:18:21.189360 19 service_latency.go:363] Got endpoints: latency-svc-mhjm7 [749.710442ms]
  I0904 18:18:21.200731 19 service_latency.go:356] Created: latency-svc-jf9b9
  I0904 18:18:21.241735 19 service_latency.go:363] Got endpoints: latency-svc-6gwwf [752.35242ms]
  I0904 18:18:21.251377 19 service_latency.go:356] Created: latency-svc-cg89t
  I0904 18:18:21.297843 19 service_latency.go:363] Got endpoints: latency-svc-bv62k [755.663729ms]
  I0904 18:18:21.309810 19 service_latency.go:356] Created: latency-svc-mzr8j
  I0904 18:18:21.351382 19 service_latency.go:363] Got endpoints: latency-svc-8xqw9 [759.815986ms]
  I0904 18:18:21.367504 19 service_latency.go:356] Created: latency-svc-7g9zr
  I0904 18:18:21.390730 19 service_latency.go:363] Got endpoints: latency-svc-mq494 [749.368553ms]
  I0904 18:18:21.400835 19 service_latency.go:356] Created: latency-svc-t5tt8
  I0904 18:18:21.439407 19 service_latency.go:363] Got endpoints: latency-svc-wmr8k [750.35448ms]
  I0904 18:18:21.449187 19 service_latency.go:356] Created: latency-svc-qb29b
  I0904 18:18:21.490776 19 service_latency.go:363] Got endpoints: latency-svc-2bnm4 [750.130167ms]
  I0904 18:18:21.501252 19 service_latency.go:356] Created: latency-svc-hnxxx
  I0904 18:18:21.541647 19 service_latency.go:363] Got endpoints: latency-svc-tdh9b [751.903916ms]
  I0904 18:18:21.550781 19 service_latency.go:356] Created: latency-svc-kc22p
  I0904 18:18:21.589279 19 service_latency.go:363] Got endpoints: latency-svc-cq9wl [748.90741ms]
  I0904 18:18:21.599052 19 service_latency.go:356] Created: latency-svc-h9czg
  I0904 18:18:21.639287 19 service_latency.go:363] Got endpoints: latency-svc-sqxdn [748.27075ms]
  I0904 18:18:21.651717 19 service_latency.go:356] Created: latency-svc-dsg6c
  I0904 18:18:21.689791 19 service_latency.go:363] Got endpoints: latency-svc-bxpdj [748.554995ms]
  I0904 18:18:21.700257 19 service_latency.go:356] Created: latency-svc-7882c
  I0904 18:18:21.738798 19 service_latency.go:363] Got endpoints: latency-svc-ngtsr [749.071757ms]
  I0904 18:18:21.749188 19 service_latency.go:356] Created: latency-svc-whlxx
  I0904 18:18:21.788849 19 service_latency.go:363] Got endpoints: latency-svc-px265 [749.246016ms]
  I0904 18:18:21.809599 19 service_latency.go:356] Created: latency-svc-mstx4
  I0904 18:18:21.841365 19 service_latency.go:363] Got endpoints: latency-svc-dhd6d [750.426966ms]
  I0904 18:18:21.850392 19 service_latency.go:356] Created: latency-svc-fnmhr
  I0904 18:18:21.888103 19 service_latency.go:363] Got endpoints: latency-svc-m5drg [746.927721ms]
  I0904 18:18:21.900760 19 service_latency.go:356] Created: latency-svc-sxdd9
  I0904 18:18:21.943620 19 service_latency.go:363] Got endpoints: latency-svc-jf9b9 [754.215198ms]
  I0904 18:18:21.954139 19 service_latency.go:356] Created: latency-svc-mlvt6
  I0904 18:18:21.991401 19 service_latency.go:363] Got endpoints: latency-svc-cg89t [749.601205ms]
  I0904 18:18:21.999508 19 service_latency.go:356] Created: latency-svc-dg9sh
  I0904 18:18:22.040206 19 service_latency.go:363] Got endpoints: latency-svc-mzr8j [742.310564ms]
  I0904 18:18:22.052869 19 service_latency.go:356] Created: latency-svc-9x4jq
  I0904 18:18:22.090126 19 service_latency.go:363] Got endpoints: latency-svc-7g9zr [738.506149ms]
  I0904 18:18:22.099073 19 service_latency.go:356] Created: latency-svc-zqvhc
  I0904 18:18:22.142261 19 service_latency.go:363] Got endpoints: latency-svc-t5tt8 [751.489787ms]
  I0904 18:18:22.151928 19 service_latency.go:356] Created: latency-svc-ckqmp
  I0904 18:18:22.191953 19 service_latency.go:363] Got endpoints: latency-svc-qb29b [752.503091ms]
  I0904 18:18:22.200819 19 service_latency.go:356] Created: latency-svc-gtcp4
  I0904 18:18:22.239270 19 service_latency.go:363] Got endpoints: latency-svc-hnxxx [748.190245ms]
  I0904 18:18:22.250660 19 service_latency.go:356] Created: latency-svc-pcr2w
  I0904 18:18:22.288654 19 service_latency.go:363] Got endpoints: latency-svc-kc22p [746.961557ms]
  I0904 18:18:22.297969 19 service_latency.go:356] Created: latency-svc-dbh98
  I0904 18:18:22.340586 19 service_latency.go:363] Got endpoints: latency-svc-h9czg [751.067211ms]
  I0904 18:18:22.352096 19 service_latency.go:356] Created: latency-svc-2jwv7
  I0904 18:18:22.391833 19 service_latency.go:363] Got endpoints: latency-svc-dsg6c [752.460168ms]
  I0904 18:18:22.400986 19 service_latency.go:356] Created: latency-svc-dhrbr
  I0904 18:18:22.441478 19 service_latency.go:363] Got endpoints: latency-svc-7882c [751.366549ms]
  I0904 18:18:22.450642 19 service_latency.go:356] Created: latency-svc-v477j
  I0904 18:18:22.489438 19 service_latency.go:363] Got endpoints: latency-svc-whlxx [750.594322ms]
  I0904 18:18:22.501266 19 service_latency.go:356] Created: latency-svc-njkcz
  I0904 18:18:22.538439 19 service_latency.go:363] Got endpoints: latency-svc-mstx4 [749.543586ms]
  I0904 18:18:22.548030 19 service_latency.go:356] Created: latency-svc-cs9pf
  I0904 18:18:22.590879 19 service_latency.go:363] Got endpoints: latency-svc-fnmhr [749.467151ms]
  I0904 18:18:22.599300 19 service_latency.go:356] Created: latency-svc-gpcxv
  I0904 18:18:22.640365 19 service_latency.go:363] Got endpoints: latency-svc-sxdd9 [752.221159ms]
  I0904 18:18:22.650719 19 service_latency.go:356] Created: latency-svc-r8mhc
  I0904 18:18:22.689804 19 service_latency.go:363] Got endpoints: latency-svc-mlvt6 [746.144595ms]
  I0904 18:18:22.701494 19 service_latency.go:356] Created: latency-svc-x6hh8
  I0904 18:18:22.739334 19 service_latency.go:363] Got endpoints: latency-svc-dg9sh [747.894782ms]
  I0904 18:18:22.748176 19 service_latency.go:356] Created: latency-svc-klddg
  I0904 18:18:22.790595 19 service_latency.go:363] Got endpoints: latency-svc-9x4jq [750.338198ms]
  I0904 18:18:22.800096 19 service_latency.go:356] Created: latency-svc-jn8l6
  I0904 18:18:22.840441 19 service_latency.go:363] Got endpoints: latency-svc-zqvhc [750.270912ms]
  I0904 18:18:22.850670 19 service_latency.go:356] Created: latency-svc-w2wff
  I0904 18:18:22.890249 19 service_latency.go:363] Got endpoints: latency-svc-ckqmp [747.845735ms]
  I0904 18:18:22.900086 19 service_latency.go:356] Created: latency-svc-8fjfn
  I0904 18:18:22.938666 19 service_latency.go:363] Got endpoints: latency-svc-gtcp4 [746.668404ms]
  I0904 18:18:22.949522 19 service_latency.go:356] Created: latency-svc-qrtwl
  I0904 18:18:22.989375 19 service_latency.go:363] Got endpoints: latency-svc-pcr2w [749.704513ms]
  I0904 18:18:23.003617 19 service_latency.go:356] Created: latency-svc-2fmj6
  I0904 18:18:23.039004 19 service_latency.go:363] Got endpoints: latency-svc-dbh98 [750.302181ms]
  I0904 18:18:23.048179 19 service_latency.go:356] Created: latency-svc-b2xzq
  I0904 18:18:23.090417 19 service_latency.go:363] Got endpoints: latency-svc-2jwv7 [749.788082ms]
  I0904 18:18:23.099524 19 service_latency.go:356] Created: latency-svc-62lg8
  I0904 18:18:23.140264 19 service_latency.go:363] Got endpoints: latency-svc-dhrbr [748.382476ms]
  I0904 18:18:23.157640 19 service_latency.go:356] Created: latency-svc-b9mb2
  I0904 18:18:23.189544 19 service_latency.go:363] Got endpoints: latency-svc-v477j [748.019092ms]
  I0904 18:18:23.199506 19 service_latency.go:356] Created: latency-svc-4x7pq
  I0904 18:18:23.240510 19 service_latency.go:363] Got endpoints: latency-svc-njkcz [751.00423ms]
  I0904 18:18:23.248827 19 service_latency.go:356] Created: latency-svc-bvvxk
  I0904 18:18:23.290057 19 service_latency.go:363] Got endpoints: latency-svc-cs9pf [751.567513ms]
  I0904 18:18:23.300417 19 service_latency.go:356] Created: latency-svc-pbvkw
  I0904 18:18:23.339587 19 service_latency.go:363] Got endpoints: latency-svc-gpcxv [748.325027ms]
  I0904 18:18:23.349745 19 service_latency.go:356] Created: latency-svc-5fr6d
  I0904 18:18:23.390272 19 service_latency.go:363] Got endpoints: latency-svc-r8mhc [749.856007ms]
  I0904 18:18:23.400499 19 service_latency.go:356] Created: latency-svc-h9n86
  I0904 18:18:23.441673 19 service_latency.go:363] Got endpoints: latency-svc-x6hh8 [751.825087ms]
  I0904 18:18:23.452156 19 service_latency.go:356] Created: latency-svc-ntrp2
  I0904 18:18:23.491143 19 service_latency.go:363] Got endpoints: latency-svc-klddg [751.728656ms]
  I0904 18:18:23.500108 19 service_latency.go:356] Created: latency-svc-sjmnq
  I0904 18:18:23.540534 19 service_latency.go:363] Got endpoints: latency-svc-jn8l6 [749.896219ms]
  I0904 18:18:23.552108 19 service_latency.go:356] Created: latency-svc-x9xqb
  I0904 18:18:23.589999 19 service_latency.go:363] Got endpoints: latency-svc-w2wff [749.487207ms]
  I0904 18:18:23.598585 19 service_latency.go:356] Created: latency-svc-bmzbg
  I0904 18:18:23.641708 19 service_latency.go:363] Got endpoints: latency-svc-8fjfn [751.20609ms]
  I0904 18:18:23.651705 19 service_latency.go:356] Created: latency-svc-fgstg
  I0904 18:18:23.691762 19 service_latency.go:363] Got endpoints: latency-svc-qrtwl [753.05714ms]
  I0904 18:18:23.701492 19 service_latency.go:356] Created: latency-svc-bq55c
  I0904 18:18:23.739764 19 service_latency.go:363] Got endpoints: latency-svc-2fmj6 [750.348839ms]
  I0904 18:18:23.776561 19 service_latency.go:356] Created: latency-svc-64lxq
  I0904 18:18:23.790012 19 service_latency.go:363] Got endpoints: latency-svc-b2xzq [750.842029ms]
  I0904 18:18:23.800282 19 service_latency.go:356] Created: latency-svc-bp8q7
  I0904 18:18:23.840877 19 service_latency.go:363] Got endpoints: latency-svc-62lg8 [750.399742ms]
  I0904 18:18:23.850321 19 service_latency.go:356] Created: latency-svc-zmrgz
  I0904 18:18:23.891912 19 service_latency.go:363] Got endpoints: latency-svc-b9mb2 [751.412315ms]
  I0904 18:18:23.906901 19 service_latency.go:356] Created: latency-svc-ngzk4
  I0904 18:18:23.942334 19 service_latency.go:363] Got endpoints: latency-svc-4x7pq [752.754283ms]
  I0904 18:18:23.956034 19 service_latency.go:356] Created: latency-svc-mgqhr
  I0904 18:18:23.989893 19 service_latency.go:363] Got endpoints: latency-svc-bvvxk [749.344668ms]
  I0904 18:18:24.002047 19 service_latency.go:356] Created: latency-svc-xdbp4
  I0904 18:18:24.040961 19 service_latency.go:363] Got endpoints: latency-svc-pbvkw [750.871448ms]
  I0904 18:18:24.052653 19 service_latency.go:356] Created: latency-svc-4nfv5
  I0904 18:18:24.089715 19 service_latency.go:363] Got endpoints: latency-svc-5fr6d [749.772598ms]
  I0904 18:18:24.099821 19 service_latency.go:356] Created: latency-svc-hscdq
  I0904 18:18:24.140840 19 service_latency.go:363] Got endpoints: latency-svc-h9n86 [750.509773ms]
  I0904 18:18:24.150125 19 service_latency.go:356] Created: latency-svc-ckfsz
  I0904 18:18:24.193447 19 service_latency.go:363] Got endpoints: latency-svc-ntrp2 [751.73449ms]
  I0904 18:18:24.203602 19 service_latency.go:356] Created: latency-svc-brlsv
  I0904 18:18:24.240876 19 service_latency.go:363] Got endpoints: latency-svc-sjmnq [749.503254ms]
  I0904 18:18:24.341878 19 service_latency.go:363] Got endpoints: latency-svc-bmzbg [751.821874ms]
  I0904 18:18:24.350501 19 service_latency.go:363] Got endpoints: latency-svc-x9xqb [809.701353ms]
  I0904 18:18:24.354340 19 service_latency.go:356] Created: latency-svc-l52dk
  I0904 18:18:24.359281 19 service_latency.go:356] Created: latency-svc-tjzrk
  I0904 18:18:24.364877 19 service_latency.go:356] Created: latency-svc-4jb8d
  I0904 18:18:24.391867 19 service_latency.go:363] Got endpoints: latency-svc-fgstg [749.903292ms]
  I0904 18:18:24.400576 19 service_latency.go:356] Created: latency-svc-76978
  I0904 18:18:24.442851 19 service_latency.go:363] Got endpoints: latency-svc-bq55c [751.04342ms]
  I0904 18:18:24.453489 19 service_latency.go:356] Created: latency-svc-26774
  I0904 18:18:24.491208 19 service_latency.go:363] Got endpoints: latency-svc-64lxq [751.238533ms]
  I0904 18:18:24.503485 19 service_latency.go:356] Created: latency-svc-vhqdw
  I0904 18:18:24.539542 19 service_latency.go:363] Got endpoints: latency-svc-bp8q7 [749.495276ms]
  I0904 18:18:24.548166 19 service_latency.go:356] Created: latency-svc-mhq4l
  I0904 18:18:24.590957 19 service_latency.go:363] Got endpoints: latency-svc-zmrgz [749.810096ms]
  I0904 18:18:24.602428 19 service_latency.go:356] Created: latency-svc-q96b9
  I0904 18:18:24.641241 19 service_latency.go:363] Got endpoints: latency-svc-ngzk4 [749.190674ms]
  I0904 18:18:24.652801 19 service_latency.go:356] Created: latency-svc-nzhbl
  I0904 18:18:24.689880 19 service_latency.go:363] Got endpoints: latency-svc-mgqhr [747.504001ms]
  I0904 18:18:24.701499 19 service_latency.go:356] Created: latency-svc-wvqg6
  I0904 18:18:24.740549 19 service_latency.go:363] Got endpoints: latency-svc-xdbp4 [750.616354ms]
  I0904 18:18:24.749798 19 service_latency.go:356] Created: latency-svc-27l8p
  I0904 18:18:24.791686 19 service_latency.go:363] Got endpoints: latency-svc-4nfv5 [750.680768ms]
  I0904 18:18:24.807061 19 service_latency.go:356] Created: latency-svc-r8ks8
  I0904 18:18:24.839521 19 service_latency.go:363] Got endpoints: latency-svc-hscdq [749.767131ms]
  I0904 18:18:24.848505 19 service_latency.go:356] Created: latency-svc-c4fnv
  I0904 18:18:24.891933 19 service_latency.go:363] Got endpoints: latency-svc-ckfsz [751.055966ms]
  I0904 18:18:24.903458 19 service_latency.go:356] Created: latency-svc-tjbcg
  I0904 18:18:24.942389 19 service_latency.go:363] Got endpoints: latency-svc-brlsv [748.863534ms]
  I0904 18:18:24.954280 19 service_latency.go:356] Created: latency-svc-9227k
  I0904 18:18:24.989668 19 service_latency.go:363] Got endpoints: latency-svc-l52dk [748.432401ms]
  I0904 18:18:25.000765 19 service_latency.go:356] Created: latency-svc-c7m4w
  I0904 18:18:25.040895 19 service_latency.go:363] Got endpoints: latency-svc-tjzrk [698.642652ms]
  I0904 18:18:25.050157 19 service_latency.go:356] Created: latency-svc-vrrlp
  I0904 18:18:25.091898 19 service_latency.go:363] Got endpoints: latency-svc-4jb8d [741.360465ms]
  I0904 18:18:25.102251 19 service_latency.go:356] Created: latency-svc-9fxht
  I0904 18:18:25.141624 19 service_latency.go:363] Got endpoints: latency-svc-76978 [749.576829ms]
  I0904 18:18:25.152706 19 service_latency.go:356] Created: latency-svc-p9nkj
  I0904 18:18:25.189781 19 service_latency.go:363] Got endpoints: latency-svc-26774 [746.893528ms]
  I0904 18:18:25.203424 19 service_latency.go:356] Created: latency-svc-w2mtg
  I0904 18:18:25.240453 19 service_latency.go:363] Got endpoints: latency-svc-vhqdw [749.195852ms]
  I0904 18:18:25.252581 19 service_latency.go:356] Created: latency-svc-jdks7
  I0904 18:18:25.289818 19 service_latency.go:363] Got endpoints: latency-svc-mhq4l [750.233514ms]
  I0904 18:18:25.298091 19 service_latency.go:356] Created: latency-svc-8f2b9
  I0904 18:18:25.340830 19 service_latency.go:363] Got endpoints: latency-svc-q96b9 [749.826141ms]
  I0904 18:18:25.351689 19 service_latency.go:356] Created: latency-svc-rjkgc
  I0904 18:18:25.391994 19 service_latency.go:363] Got endpoints: latency-svc-nzhbl [750.716599ms]
  I0904 18:18:25.404833 19 service_latency.go:356] Created: latency-svc-4xhfz
  I0904 18:18:25.439813 19 service_latency.go:363] Got endpoints: latency-svc-wvqg6 [749.893164ms]
  I0904 18:18:25.450472 19 service_latency.go:356] Created: latency-svc-6c5zs
  I0904 18:18:25.492134 19 service_latency.go:363] Got endpoints: latency-svc-27l8p [751.543171ms]
  I0904 18:18:25.501855 19 service_latency.go:356] Created: latency-svc-2r5vw
  I0904 18:18:25.541275 19 service_latency.go:363] Got endpoints: latency-svc-r8ks8 [749.511728ms]
  I0904 18:18:25.551877 19 service_latency.go:356] Created: latency-svc-5sq56
  I0904 18:18:25.590731 19 service_latency.go:363] Got endpoints: latency-svc-c4fnv [751.163576ms]
  I0904 18:18:25.601766 19 service_latency.go:356] Created: latency-svc-qvr7x
  I0904 18:18:25.639728 19 service_latency.go:363] Got endpoints: latency-svc-tjbcg [747.751968ms]
  I0904 18:18:25.652136 19 service_latency.go:356] Created: latency-svc-2gfxh
  I0904 18:18:25.693025 19 service_latency.go:363] Got endpoints: latency-svc-9227k [750.517433ms]
  I0904 18:18:25.704148 19 service_latency.go:356] Created: latency-svc-7hm4d
  I0904 18:18:25.741249 19 service_latency.go:363] Got endpoints: latency-svc-c7m4w [751.543422ms]
  I0904 18:18:25.750245 19 service_latency.go:356] Created: latency-svc-l5snh
  I0904 18:18:25.791336 19 service_latency.go:363] Got endpoints: latency-svc-vrrlp [750.3083ms]
  I0904 18:18:25.802436 19 service_latency.go:356] Created: latency-svc-m5ddq
  I0904 18:18:25.840502 19 service_latency.go:363] Got endpoints: latency-svc-9fxht [748.194767ms]
  I0904 18:18:25.853528 19 service_latency.go:356] Created: latency-svc-zdp4r
  I0904 18:18:25.889859 19 service_latency.go:363] Got endpoints: latency-svc-p9nkj [748.188536ms]
  I0904 18:18:25.901498 19 service_latency.go:356] Created: latency-svc-hbqj5
  I0904 18:18:25.942583 19 service_latency.go:363] Got endpoints: latency-svc-w2mtg [752.764934ms]
  I0904 18:18:25.953362 19 service_latency.go:356] Created: latency-svc-r7tgj
  I0904 18:18:25.991299 19 service_latency.go:363] Got endpoints: latency-svc-jdks7 [750.807244ms]
  I0904 18:18:26.000529 19 service_latency.go:356] Created: latency-svc-pvtft
  I0904 18:18:26.041589 19 service_latency.go:363] Got endpoints: latency-svc-8f2b9 [751.718921ms]
  I0904 18:18:26.051319 19 service_latency.go:356] Created: latency-svc-cmd42
  I0904 18:18:26.090869 19 service_latency.go:363] Got endpoints: latency-svc-rjkgc [749.765972ms]
  I0904 18:18:26.101430 19 service_latency.go:356] Created: latency-svc-8tkcb
  I0904 18:18:26.140175 19 service_latency.go:363] Got endpoints: latency-svc-4xhfz [748.143651ms]
  I0904 18:18:26.151244 19 service_latency.go:356] Created: latency-svc-nppw7
  I0904 18:18:26.188987 19 service_latency.go:363] Got endpoints: latency-svc-6c5zs [749.067666ms]
  I0904 18:18:26.198035 19 service_latency.go:356] Created: latency-svc-9wtth
  I0904 18:18:26.240527 19 service_latency.go:363] Got endpoints: latency-svc-2r5vw [748.346313ms]
  I0904 18:18:26.252530 19 service_latency.go:356] Created: latency-svc-5htr7
  I0904 18:18:26.292053 19 service_latency.go:363] Got endpoints: latency-svc-5sq56 [750.721121ms]
  I0904 18:18:26.303275 19 service_latency.go:356] Created: latency-svc-5hb29
  I0904 18:18:26.340951 19 service_latency.go:363] Got endpoints: latency-svc-qvr7x [750.168136ms]
  I0904 18:18:26.349676 19 service_latency.go:356] Created: latency-svc-bzz7l
  I0904 18:18:26.390518 19 service_latency.go:363] Got endpoints: latency-svc-2gfxh [750.75032ms]
  I0904 18:18:26.402311 19 service_latency.go:356] Created: latency-svc-dmgp9
  I0904 18:18:26.440921 19 service_latency.go:363] Got endpoints: latency-svc-7hm4d [747.654571ms]
  I0904 18:18:26.450974 19 service_latency.go:356] Created: latency-svc-ff8n2
  I0904 18:18:26.490548 19 service_latency.go:363] Got endpoints: latency-svc-l5snh [749.257804ms]
  I0904 18:18:26.500432 19 service_latency.go:356] Created: latency-svc-97nsg
  I0904 18:18:26.542614 19 service_latency.go:363] Got endpoints: latency-svc-m5ddq [751.235358ms]
  I0904 18:18:26.552798 19 service_latency.go:356] Created: latency-svc-vns6q
  I0904 18:18:26.589750 19 service_latency.go:363] Got endpoints: latency-svc-zdp4r [749.203434ms]
  I0904 18:18:26.601053 19 service_latency.go:356] Created: latency-svc-4dwsh
  I0904 18:18:26.641202 19 service_latency.go:363] Got endpoints: latency-svc-hbqj5 [751.297211ms]
  I0904 18:18:26.649948 19 service_latency.go:356] Created: latency-svc-rvz67
  I0904 18:18:26.691196 19 service_latency.go:363] Got endpoints: latency-svc-r7tgj [748.573295ms]
  I0904 18:18:26.700100 19 service_latency.go:356] Created: latency-svc-7gzkl
  I0904 18:18:26.741270 19 service_latency.go:363] Got endpoints: latency-svc-pvtft [749.912278ms]
  I0904 18:18:26.791734 19 service_latency.go:363] Got endpoints: latency-svc-cmd42 [750.01994ms]
  I0904 18:18:26.841397 19 service_latency.go:363] Got endpoints: latency-svc-8tkcb [750.477891ms]
  I0904 18:18:26.889403 19 service_latency.go:363] Got endpoints: latency-svc-nppw7 [749.002807ms]
  I0904 18:18:26.940805 19 service_latency.go:363] Got endpoints: latency-svc-9wtth [751.776694ms]
  I0904 18:18:26.991696 19 service_latency.go:363] Got endpoints: latency-svc-5htr7 [751.134929ms]
  I0904 18:18:27.041319 19 service_latency.go:363] Got endpoints: latency-svc-5hb29 [749.218127ms]
  I0904 18:18:27.092158 19 service_latency.go:363] Got endpoints: latency-svc-bzz7l [751.150805ms]
  I0904 18:18:27.140137 19 service_latency.go:363] Got endpoints: latency-svc-dmgp9 [749.41563ms]
  I0904 18:18:27.190693 19 service_latency.go:363] Got endpoints: latency-svc-ff8n2 [749.628441ms]
  I0904 18:18:27.239245 19 service_latency.go:363] Got endpoints: latency-svc-97nsg [748.652042ms]
  I0904 18:18:27.291201 19 service_latency.go:363] Got endpoints: latency-svc-vns6q [748.543746ms]
  I0904 18:18:27.340289 19 service_latency.go:363] Got endpoints: latency-svc-4dwsh [750.493994ms]
  I0904 18:18:27.389476 19 service_latency.go:363] Got endpoints: latency-svc-rvz67 [748.210355ms]
  I0904 18:18:27.443190 19 service_latency.go:363] Got endpoints: latency-svc-7gzkl [751.959678ms]
  I0904 18:18:27.443275 19 service_latency.go:114] Latencies: [17.870339ms 28.275202ms 28.852864ms 37.668214ms 38.564271ms 40.988974ms 42.045778ms 42.133657ms 45.774958ms 47.529663ms 51.858079ms 56.903319ms 60.723036ms 66.466339ms 71.37791ms 76.793073ms 80.639968ms 87.792142ms 92.506367ms 95.022884ms 103.712058ms 110.18208ms 113.269594ms 114.580406ms 132.509818ms 133.811973ms 133.875565ms 141.438545ms 148.712306ms 150.795867ms 163.014522ms 167.508557ms 169.370422ms 169.59646ms 184.692774ms 196.111491ms 202.345489ms 244.010589ms 292.191408ms 343.127397ms 389.937883ms 438.162536ms 485.890833ms 532.253997ms 579.922141ms 622.408437ms 669.784549ms 698.642652ms 716.640662ms 738.506149ms 741.360465ms 742.310564ms 746.144595ms 746.668404ms 746.893528ms 746.927721ms 746.961557ms 747.504001ms 747.597128ms 747.654571ms 747.751968ms 747.77468ms 747.845735ms 747.894782ms 748.019092ms 748.143651ms 748.186563ms 748.188536ms 748.190245ms 748.194767ms 748.210355ms 748.27075ms 748.325027ms 748.346313ms 748.382476ms 748.432401ms 748.451075ms 748.518728ms 748.543746ms 748.554995ms 748.573295ms 748.597029ms 748.652042ms 748.708437ms 748.863534ms 748.90741ms 748.91084ms 748.952459ms 748.959598ms 749.002807ms 749.066547ms 749.067666ms 749.071757ms 749.164202ms 749.190674ms 749.195852ms 749.203434ms 749.218127ms 749.246016ms 749.257804ms 749.344668ms 749.368553ms 749.41563ms 749.467151ms 749.487207ms 749.495276ms 749.503254ms 749.511728ms 749.543586ms 749.548875ms 749.570431ms 749.576829ms 749.601205ms 749.628441ms 749.704513ms 749.710442ms 749.736129ms 749.765972ms 749.767131ms 749.772598ms 749.788082ms 749.810096ms 749.826141ms 749.856007ms 749.893164ms 749.896219ms 749.899109ms 749.903292ms 749.912278ms 750.01994ms 750.130167ms 750.131483ms 750.168136ms 750.233514ms 750.270912ms 750.302181ms 750.303644ms 750.3083ms 750.338198ms 750.348839ms 750.35448ms 750.399742ms 750.426966ms 750.477891ms 750.493994ms 750.509773ms 750.517433ms 750.562977ms 750.594322ms 750.616354ms 750.680768ms 750.716599ms 750.721121ms 750.75032ms 750.807244ms 750.842029ms 750.871448ms 750.914673ms 750.989952ms 751.00423ms 751.04342ms 751.055966ms 751.067211ms 751.134929ms 751.150805ms 751.163576ms 751.198441ms 751.20609ms 751.235358ms 751.238533ms 751.297211ms 751.366549ms 751.412315ms 751.489787ms 751.543171ms 751.543422ms 751.543928ms 751.567513ms 751.718921ms 751.728656ms 751.73449ms 751.776694ms 751.821874ms 751.825087ms 751.903916ms 751.959678ms 752.221159ms 752.337912ms 752.35242ms 752.460168ms 752.503091ms 752.754283ms 752.764934ms 753.027842ms 753.05714ms 753.401609ms 754.215198ms 755.663729ms 759.815986ms 809.701353ms]
  I0904 18:18:27.443287 19 service_latency.go:118] 50 %ile: 749.344668ms
  I0904 18:18:27.443293 19 service_latency.go:119] 90 %ile: 751.73449ms
  I0904 18:18:27.443298 19 service_latency.go:120] 99 %ile: 759.815986ms
  I0904 18:18:27.443304 19 service_latency.go:121] Total sample count: 200
  I0904 18:18:27.443456 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-3098" for this suite. @ 09/04/24 18:18:27.448
• [10.765 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
  STEP: Creating a kubernetes client @ 09/04/24 18:18:27.456
  I0904 18:18:27.456366 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 18:18:27.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:18:27.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:18:27.478
  STEP: creating the pod @ 09/04/24 18:18:27.481
  I0904 18:18:27.481739 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6072 create -f -'
  I0904 18:18:27.562215 19 builder.go:146] stderr: ""
  I0904 18:18:27.562255 19 builder.go:147] stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 09/04/24 18:18:29.574
  I0904 18:18:29.574585 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6072 label pods pause testing-label=testing-label-value'
  I0904 18:18:29.624506 19 builder.go:146] stderr: ""
  I0904 18:18:29.624541 19 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 09/04/24 18:18:29.624
  I0904 18:18:29.624629 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6072 get pod pause -L testing-label'
  I0904 18:18:29.665409 19 builder.go:146] stderr: ""
  I0904 18:18:29.665436 19 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 09/04/24 18:18:29.665
  I0904 18:18:29.665571 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6072 label pods pause testing-label-'
  I0904 18:18:29.713196 19 builder.go:146] stderr: ""
  I0904 18:18:29.713228 19 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 09/04/24 18:18:29.713
  I0904 18:18:29.713332 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6072 get pod pause -L testing-label'
  I0904 18:18:29.752482 19 builder.go:146] stderr: ""
  I0904 18:18:29.752514 19 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 09/04/24 18:18:29.752
  I0904 18:18:29.752693 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6072 delete --grace-period=0 --force -f -'
  I0904 18:18:29.805524 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 18:18:29.805559 19 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I0904 18:18:29.805594 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6072 get rc,svc -l name=pause --no-headers'
  I0904 18:18:29.850825 19 builder.go:146] stderr: "No resources found in kubectl-6072 namespace.\n"
  I0904 18:18:29.850859 19 builder.go:147] stdout: ""
  I0904 18:18:29.850942 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6072 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0904 18:18:29.889207 19 builder.go:146] stderr: ""
  I0904 18:18:29.889247 19 builder.go:147] stdout: ""
  I0904 18:18:29.889343 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6072" for this suite. @ 09/04/24 18:18:29.895
• [2.447 seconds]
------------------------------
SSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 09/04/24 18:18:29.903
  I0904 18:18:29.903074 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename events @ 09/04/24 18:18:29.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:18:29.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:18:29.927
  STEP: creating a test event @ 09/04/24 18:18:29.93
  STEP: listing events in all namespaces @ 09/04/24 18:18:29.937
  STEP: listing events in test namespace @ 09/04/24 18:18:29.975
  STEP: listing events with field selection filtering on source @ 09/04/24 18:18:29.985
  STEP: listing events with field selection filtering on reportingController @ 09/04/24 18:18:29.997
  STEP: getting the test event @ 09/04/24 18:18:30.001
  STEP: patching the test event @ 09/04/24 18:18:30.005
  STEP: getting the test event @ 09/04/24 18:18:30.014
  STEP: updating the test event @ 09/04/24 18:18:30.018
  STEP: getting the test event @ 09/04/24 18:18:30.024
  STEP: deleting the test event @ 09/04/24 18:18:30.027
  STEP: listing events in all namespaces @ 09/04/24 18:18:30.034
  STEP: listing events in test namespace @ 09/04/24 18:18:30.045
  I0904 18:18:30.049881 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2170" for this suite. @ 09/04/24 18:18:30.054
• [0.158 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 09/04/24 18:18:30.06
  I0904 18:18:30.060883 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:18:30.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:18:30.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:18:30.081
  STEP: Creating pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764 @ 09/04/24 18:18:30.084
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/04/24 18:18:32.099
  I0904 18:18:32.103005 19 container_probe.go:1749] Initial restart count of pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 is 0
  I0904 18:18:32.106154 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:34.110242 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:36.114729 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:38.119043 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:40.124718 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:42.131154 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:44.136945 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:46.142651 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:48.147470 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:50.153496 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:52.159122 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:54.164771 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:56.170510 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:18:58.176481 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:00.182081 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:02.188930 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:04.194486 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:06.199226 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:08.204726 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:10.210641 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:12.216299 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:14.222478 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:16.227859 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:18.233640 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:20.240022 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:22.246029 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:24.252050 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:26.257725 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:28.263021 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:30.269222 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:32.274657 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:34.279891 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:36.284519 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:38.289671 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:40.294766 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:42.300235 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:44.306087 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:46.311649 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:48.317265 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:50.322873 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:52.328134 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:54.333262 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:56.338648 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:19:58.344327 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:00.350013 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:02.357630 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:04.363318 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:06.369641 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:08.376346 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:10.381794 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:12.387364 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:14.393282 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:16.398545 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:18.403729 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:20.408112 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:22.413579 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:24.417816 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:26.423112 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:28.429423 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:30.433886 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:32.439823 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:34.444507 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:36.449746 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:38.455458 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:40.461770 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:42.467408 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:44.473333 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:46.477743 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:48.482446 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:50.488924 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:52.494296 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:54.500496 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:56.505735 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:20:58.510934 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:00.516144 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:02.520839 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:04.526162 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:06.532012 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:08.537759 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:10.543785 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:12.549131 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:14.553932 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:16.559251 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:18.565162 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:20.569883 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:22.575571 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:24.580883 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:26.586364 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:28.591333 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:30.596558 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:32.603745 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:34.609238 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:36.614812 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:38.620065 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:40.624589 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:42.630513 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:44.635862 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:46.642241 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:48.647235 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:50.651816 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:52.657321 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:54.662646 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:56.667039 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:21:58.672556 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:00.678239 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:02.684625 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:04.690139 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:06.695727 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:08.704401 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:10.711769 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:12.717408 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:14.723481 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:16.729279 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:18.734410 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:20.739604 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:22.746492 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:24.751593 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:26.755986 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:28.761452 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  I0904 18:22:30.766217 19 container_probe.go:1759] Get pod test-webserver-a7149a8a-0e0c-4de4-845b-64818a9d8a28 in namespace container-probe-1764
  STEP: deleting the pod @ 09/04/24 18:22:32.766
  I0904 18:22:32.782611 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1764" for this suite. @ 09/04/24 18:22:32.786
• [242.735 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:878
  STEP: Creating a kubernetes client @ 09/04/24 18:22:32.796
  I0904 18:22:32.796051 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename job @ 09/04/24 18:22:32.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:22:32.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:22:32.817
  STEP: Creating a job @ 09/04/24 18:22:32.82
  STEP: Ensuring active pods == parallelism @ 09/04/24 18:22:32.825
  STEP: delete a job @ 09/04/24 18:22:34.831
  STEP: deleting Job.batch foo in namespace job-246, will wait for the garbage collector to delete the pods @ 09/04/24 18:22:34.831
  I0904 18:22:34.893925 19 resources.go:139] Deleting Job.batch foo took: 7.586651ms
  I0904 18:22:35.094958 19 resources.go:163] Terminating Job.batch foo pods took: 201.026393ms
  STEP: Ensuring job was deleted @ 09/04/24 18:22:37.495
  I0904 18:22:37.500943 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-246" for this suite. @ 09/04/24 18:22:37.504
• [4.717 seconds]
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3703
  STEP: Creating a kubernetes client @ 09/04/24 18:22:37.512
  I0904 18:22:37.512848 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:22:37.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:22:37.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:22:37.532
  STEP: creating service multiprotocol-test in namespace services-1913 @ 09/04/24 18:22:37.535
  STEP: creating pod pod1 in namespace services-1913 @ 09/04/24 18:22:37.544
  STEP: Creating pod pod1 in namespace services-1913 @ 09/04/24 18:22:37.544
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-1913 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 09/04/24 18:22:39.567
  I0904 18:22:39.580459 19 service.go:4392] successfully validated that service multiprotocol-test in namespace services-1913 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 09/04/24 18:22:39.58
  I0904 18:22:39.580504 19 resource.go:361] Creating new exec pod
  I0904 18:22:41.595756 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80'
  I0904 18:22:41.687321 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.84 80\nConnection to 10.152.183.84 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0904 18:22:41.687359 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:22:41.687429 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.84 80'
  I0904 18:22:45.776475 19 builder.go:146] stderr: "+ nc -v -u -w 2 10.152.183.84 80\n+ echo hostName\nConnection to 10.152.183.84 80 port [udp/*] succeeded!\n"
  I0904 18:22:45.776519 19 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 09/04/24 18:22:45.776
  I0904 18:22:45.786622 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80'
  I0904 18:22:45.866475 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.84 80\nConnection to 10.152.183.84 80 port [tcp/http] succeeded!\n"
  I0904 18:22:45.866507 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:22:45.866579 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.84 80'
  I0904 18:22:49.948304 19 builder.go:146] stderr: "+ nc -v -u -w 2 10.152.183.84 80\n+ echo hostName\nConnection to 10.152.183.84 80 port [udp/*] succeeded!\n"
  I0904 18:22:49.948350 19 builder.go:147] stdout: ""
  I0904 18:22:49.948400 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.84 80'
  I0904 18:22:54.036464 19 builder.go:146] stderr: "+ nc -v -u -w 2 10.152.183.84 80\n+ echo hostName\nConnection to 10.152.183.84 80 port [udp/*] succeeded!\n"
  I0904 18:22:54.036507 19 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 09/04/24 18:22:54.036
  I0904 18:22:54.047004 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.84 80'
  I0904 18:22:58.128530 19 builder.go:146] stderr: "+ nc -v -u -w 2 10.152.183.84 80\n+ echo hostName\nConnection to 10.152.183.84 80 port [udp/*] succeeded!\n"
  I0904 18:22:58.128574 19 builder.go:147] stdout: "pod1"
  I0904 18:22:58.128676 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80'
  I0904 18:23:00.216932 19 builder.go:135] rc: 1
  I0904 18:23:00.216999 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.84 80
  + echo hostName
  nc: connect to 10.152.183.84 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0904 18:23:00.217066 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80'
  I0904 18:23:02.304710 19 builder.go:135] rc: 1
  I0904 18:23:02.304769 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.84 80
  + echo hostName
  nc: connect to 10.152.183.84 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0904 18:23:02.305000 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80'
  I0904 18:23:04.393354 19 builder.go:135] rc: 1
  I0904 18:23:04.393430 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-1913 exec execpod4ltz7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.84 80
  + echo hostName
  nc: connect to 10.152.183.84 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0904 18:23:04.393586 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1913" for this suite. @ 09/04/24 18:23:04.398
• [26.895 seconds]
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 09/04/24 18:23:04.407
  I0904 18:23:04.407365 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replication-controller @ 09/04/24 18:23:04.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:23:04.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:23:04.427
  STEP: Creating replication controller my-hostname-basic-979d1f9d-fdc9-42b3-85b6-f88caab035d2 @ 09/04/24 18:23:04.43
  I0904 18:23:04.440130 19 resource.go:87] Pod name my-hostname-basic-979d1f9d-fdc9-42b3-85b6-f88caab035d2: Found 0 pods out of 1
  I0904 18:23:09.446013 19 resource.go:87] Pod name my-hostname-basic-979d1f9d-fdc9-42b3-85b6-f88caab035d2: Found 1 pods out of 1
  I0904 18:23:09.446047 19 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-979d1f9d-fdc9-42b3-85b6-f88caab035d2" are running
  I0904 18:23:09.449305 19 rc.go:523] Pod "my-hostname-basic-979d1f9d-fdc9-42b3-85b6-f88caab035d2-l6z8c" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 18:23:05 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 18:23:04 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 18:23:05 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 18:23:05 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 18:23:04 +0000 UTC Reason: Message:}])
  I0904 18:23:09.449329 19 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 09/04/24 18:23:09.449
  I0904 18:23:09.461404 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4902" for this suite. @ 09/04/24 18:23:09.464
• [5.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 09/04/24 18:23:09.469
  I0904 18:23:09.469780 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 18:23:09.47
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:23:09.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:23:09.491
  STEP: Creating secret with name secret-test-0ac7b49d-218c-45dc-9e57-9dd0ea6a591c @ 09/04/24 18:23:09.494
  STEP: Creating a pod to test consume secrets @ 09/04/24 18:23:09.5
  STEP: Saw pod success @ 09/04/24 18:23:13.521
  I0904 18:23:13.525478 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-secrets-b1d7a8f5-701c-4348-85ac-1df3b27a132c container secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 18:23:13.545
  I0904 18:23:13.562736 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2445" for this suite. @ 09/04/24 18:23:13.566
• [4.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 09/04/24 18:23:13.574
  I0904 18:23:13.574346 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:23:13.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:23:13.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:23:13.596
  STEP: Creating pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289 @ 09/04/24 18:23:13.6
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/04/24 18:23:15.616
  I0904 18:23:15.620432 19 container_probe.go:1749] Initial restart count of pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 is 0
  I0904 18:23:15.624024 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:17.630534 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:19.635577 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:21.640906 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:23.645642 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:25.650057 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:27.655952 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:29.661763 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:31.666408 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:33.671798 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:35.677220 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:37.681850 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:39.687519 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:41.692755 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:43.698724 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:45.704039 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:47.708577 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:49.714478 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:51.720616 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:53.726135 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:55.731325 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:57.736741 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:23:59.742507 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:01.747991 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:03.752749 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:05.759349 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:07.765259 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:09.771539 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:11.777647 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:13.783322 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:15.789289 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:17.795130 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:19.800580 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:21.806120 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:23.811547 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:25.816348 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:27.821725 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:29.827110 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:31.833243 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:33.838775 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:35.844801 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:37.850332 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:39.856700 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:41.862558 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:43.868912 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:45.874563 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:47.881014 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:49.887675 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:51.893149 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:53.898187 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:55.902845 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:57.908609 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:24:59.914511 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:01.919889 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:03.925692 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:05.930971 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:07.937738 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:09.943364 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:11.949176 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:13.955186 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:15.960596 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:17.965284 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:19.971066 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:21.976102 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:23.981753 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:25.987652 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:27.993241 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:29.998369 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:32.003092 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:34.007668 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:36.013745 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:38.018975 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:40.024803 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:42.030736 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:44.035338 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:46.040254 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:48.045491 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:50.052217 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:52.058292 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:54.063322 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:56.069432 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:25:58.074482 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:00.080204 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:02.085722 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:04.091371 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:06.097509 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:08.103463 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:10.110684 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:12.116218 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:14.122011 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:16.127086 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:18.133316 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:20.138583 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:22.144198 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:24.149108 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:26.153411 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:28.159253 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:30.165165 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:32.169814 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:34.175447 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:36.180858 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:38.185448 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:40.190486 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:42.195980 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:44.202293 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:46.206590 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:48.212056 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:50.217242 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:52.221924 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:54.227445 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:56.232462 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:26:58.237714 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:27:00.244089 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:27:02.249270 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:27:04.254543 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:27:06.261315 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:27:08.266986 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:27:10.272881 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:27:12.278146 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  I0904 18:27:14.283480 19 container_probe.go:1759] Get pod busybox-f8f50f42-55d0-44e6-8632-c932421025d9 in namespace container-probe-1289
  STEP: deleting the pod @ 09/04/24 18:27:16.283
  I0904 18:27:16.298786 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1289" for this suite. @ 09/04/24 18:27:16.303
• [242.736 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 09/04/24 18:27:16.31
  I0904 18:27:16.310146 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename gc @ 09/04/24 18:27:16.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:27:16.331
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:27:16.334
  STEP: create the rc @ 09/04/24 18:27:16.341
  W0904 18:27:16.348349      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 09/04/24 18:27:22.353
  STEP: wait for the rc to be deleted @ 09/04/24 18:27:22.362
  I0904 18:27:23.373856 19 garbage_collector.go:670] 83 pods remaining
  I0904 18:27:23.373979 19 garbage_collector.go:677] 83 pods has nil DeletionTimestamp
  I0904 18:27:23.374009 19 garbage_collector.go:678] 
  I0904 18:27:24.372375 19 garbage_collector.go:670] 68 pods remaining
  I0904 18:27:24.372405 19 garbage_collector.go:677] 68 pods has nil DeletionTimestamp
  I0904 18:27:24.372410 19 garbage_collector.go:678] 
  I0904 18:27:25.373558 19 garbage_collector.go:670] 60 pods remaining
  I0904 18:27:25.373583 19 garbage_collector.go:677] 60 pods has nil DeletionTimestamp
  I0904 18:27:25.373588 19 garbage_collector.go:678] 
  I0904 18:27:26.380916 19 garbage_collector.go:670] 43 pods remaining
  I0904 18:27:26.381035 19 garbage_collector.go:677] 43 pods has nil DeletionTimestamp
  I0904 18:27:26.381065 19 garbage_collector.go:678] 
  I0904 18:27:27.374096 19 garbage_collector.go:670] 28 pods remaining
  I0904 18:27:27.374200 19 garbage_collector.go:677] 28 pods has nil DeletionTimestamp
  I0904 18:27:27.374228 19 garbage_collector.go:678] 
  I0904 18:27:28.371142 19 garbage_collector.go:670] 20 pods remaining
  I0904 18:27:28.371167 19 garbage_collector.go:677] 20 pods has nil DeletionTimestamp
  I0904 18:27:28.371173 19 garbage_collector.go:678] 
  STEP: Gathering metrics @ 09/04/24 18:27:29.388
  W0904 18:27:29.395324      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0904 18:27:29.395356 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0904 18:27:29.395542 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1061" for this suite. @ 09/04/24 18:27:29.399
• [13.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 09/04/24 18:27:29.408
  I0904 18:27:29.408075 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replication-controller @ 09/04/24 18:27:29.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:27:29.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:27:29.438
  STEP: Creating ReplicationController "e2e-rc-497dr" @ 09/04/24 18:27:29.443
  I0904 18:27:29.450882 19 rc.go:792] Get Replication Controller "e2e-rc-497dr" to confirm replicas
  I0904 18:27:30.451628 19 rc.go:792] Get Replication Controller "e2e-rc-497dr" to confirm replicas
  I0904 18:27:30.455253 19 rc.go:801] Found 1 replicas for "e2e-rc-497dr" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-497dr" @ 09/04/24 18:27:30.455
  STEP: Updating a scale subresource @ 09/04/24 18:27:30.458
  STEP: Verifying replicas where modified for replication controller "e2e-rc-497dr" @ 09/04/24 18:27:30.464
  I0904 18:27:30.464045 19 rc.go:792] Get Replication Controller "e2e-rc-497dr" to confirm replicas
  I0904 18:27:31.464076 19 rc.go:792] Get Replication Controller "e2e-rc-497dr" to confirm replicas
  I0904 18:27:31.469010 19 rc.go:801] Found 2 replicas for "e2e-rc-497dr" replication controller
  I0904 18:27:31.469179 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1349" for this suite. @ 09/04/24 18:27:31.472
• [2.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:999
  STEP: Creating a kubernetes client @ 09/04/24 18:27:31.481
  I0904 18:27:31.481786 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 18:27:31.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:27:31.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:27:31.504
  STEP: Creating a ResourceQuota @ 09/04/24 18:27:31.508
  STEP: Getting a ResourceQuota @ 09/04/24 18:27:31.512
  STEP: Listing all ResourceQuotas with LabelSelector @ 09/04/24 18:27:31.516
  STEP: Patching the ResourceQuota @ 09/04/24 18:27:31.519
  STEP: Deleting a Collection of ResourceQuotas @ 09/04/24 18:27:31.525
  STEP: Verifying the deleted ResourceQuota @ 09/04/24 18:27:31.534
  I0904 18:27:31.537694 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4642" for this suite. @ 09/04/24 18:27:31.541
• [0.066 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 09/04/24 18:27:31.547
  I0904 18:27:31.547760 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:27:31.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:27:31.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:27:31.567
  I0904 18:27:53.648614 19 container_probe.go:92] Container started at 2024-09-04 18:27:32 +0000 UTC, pod became ready at 2024-09-04 18:27:51 +0000 UTC
  I0904 18:27:53.648835 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-496" for this suite. @ 09/04/24 18:27:53.652
• [22.112 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 09/04/24 18:27:53.659
  I0904 18:27:53.659767 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replicaset @ 09/04/24 18:27:53.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:27:53.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:27:53.681
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 09/04/24 18:27:53.684
  I0904 18:27:53.694801 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I0904 18:27:58.699333 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/04/24 18:27:58.699
  STEP: getting scale subresource @ 09/04/24 18:27:58.699
  STEP: updating a scale subresource @ 09/04/24 18:27:58.702
  STEP: verifying the replicaset Spec.Replicas was modified @ 09/04/24 18:27:58.709
  STEP: Patch a scale subresource @ 09/04/24 18:27:58.715
  I0904 18:27:58.723408 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6708" for this suite. @ 09/04/24 18:27:58.729
• [5.078 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 09/04/24 18:27:58.738
  I0904 18:27:58.738500 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sysctl @ 09/04/24 18:27:58.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:27:58.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:27:58.757
  STEP: Creating a pod with one valid and two invalid sysctls @ 09/04/24 18:27:58.761
  I0904 18:27:58.765186 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7097" for this suite. @ 09/04/24 18:27:58.768
• [0.037 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 09/04/24 18:27:58.775
  I0904 18:27:58.775154 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename daemonsets @ 09/04/24 18:27:58.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:27:58.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:27:58.794
  I0904 18:27:58.814579 19 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 09/04/24 18:27:58.82
  I0904 18:27:58.823800 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:27:58.823851 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 09/04/24 18:27:58.823
  I0904 18:27:58.842372 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:27:58.842456 19 fixtures.go:130] Node ip-172-31-40-239 is running 0 daemon pod, expected 1
  I0904 18:27:59.844775 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:27:59.844893 19 fixtures.go:130] Node ip-172-31-40-239 is running 0 daemon pod, expected 1
  I0904 18:28:00.844048 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0904 18:28:00.844089 19 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 09/04/24 18:28:00.848
  I0904 18:28:00.863719 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0904 18:28:00.863747 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  I0904 18:28:01.866112 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:28:01.866147 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 09/04/24 18:28:01.866
  I0904 18:28:01.879887 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:28:01.879908 19 fixtures.go:130] Node ip-172-31-40-239 is running 0 daemon pod, expected 1
  I0904 18:28:02.878413 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:28:02.878446 19 fixtures.go:130] Node ip-172-31-40-239 is running 0 daemon pod, expected 1
  I0904 18:28:03.878262 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0904 18:28:03.878294 19 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/04/24 18:28:03.884
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1647, will wait for the garbage collector to delete the pods @ 09/04/24 18:28:03.884
  I0904 18:28:03.944262 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 5.939644ms
  I0904 18:28:04.046266 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.996945ms
  I0904 18:28:05.552343 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:28:05.552374 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0904 18:28:05.556186 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17651"},"items":null}

  I0904 18:28:05.559507 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17651"},"items":null}

  I0904 18:28:05.583246 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1647" for this suite. @ 09/04/24 18:28:05.59
• [6.821 seconds]
------------------------------
S
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:750
  STEP: Creating a kubernetes client @ 09/04/24 18:28:05.596
  I0904 18:28:05.596315 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:28:05.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:28:05.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:28:05.616
  I0904 18:28:05.623665 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1855" for this suite. @ 09/04/24 18:28:05.627
• [0.037 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:490
  STEP: Creating a kubernetes client @ 09/04/24 18:28:05.633
  I0904 18:28:05.633514 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename job @ 09/04/24 18:28:05.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:28:05.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:28:05.654
  STEP: Creating Indexed job @ 09/04/24 18:28:05.657
  STEP: Ensuring job reaches completions @ 09/04/24 18:28:05.662
  STEP: Ensuring pods with index for job exist @ 09/04/24 18:28:15.674
  I0904 18:28:15.678090 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6470" for this suite. @ 09/04/24 18:28:15.682
• [10.055 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 09/04/24 18:28:15.688
  I0904 18:28:15.688694 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:28:15.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:28:15.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:28:15.709
  STEP: Creating configMap with name configmap-test-upd-18e39c25-9937-427a-9fad-9de3fb921b6d @ 09/04/24 18:28:15.716
  STEP: Creating the pod @ 09/04/24 18:28:15.722
  STEP: Updating configmap configmap-test-upd-18e39c25-9937-427a-9fad-9de3fb921b6d @ 09/04/24 18:28:17.76
  STEP: waiting to observe update in volume @ 09/04/24 18:28:17.766
  I0904 18:29:46.149763 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8208" for this suite. @ 09/04/24 18:29:46.153
• [90.474 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:324
  STEP: Creating a kubernetes client @ 09/04/24 18:29:46.162
  I0904 18:29:46.162781 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename statefulset @ 09/04/24 18:29:46.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:29:46.18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:29:46.183
  STEP: Creating service test in namespace statefulset-352 @ 09/04/24 18:29:46.187
  STEP: Creating a new StatefulSet @ 09/04/24 18:29:46.192
  I0904 18:29:46.203278 19 wait.go:40] Found 0 stateful pods, waiting for 3
  I0904 18:29:56.207403 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0904 18:29:56.207439 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0904 18:29:56.207445 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0904 18:29:56.219017 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-352 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 18:29:56.313146 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 18:29:56.313180 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 18:29:56.313192 19 statefulset.go:2450] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 09/04/24 18:30:06.322
  I0904 18:30:06.332530 19 statefulset.go:2507] Updating stateful set ss2
  STEP: Creating a new revision @ 09/04/24 18:30:06.332
  STEP: Updating Pods in reverse ordinal order @ 09/04/24 18:30:16.341
  I0904 18:30:16.344724 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-352 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0904 18:30:16.430505 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0904 18:30:16.430553 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 18:30:16.430562 19 statefulset.go:2474] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  STEP: Rolling back to a previous revision @ 09/04/24 18:30:36.449
  I0904 18:30:36.449135 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-352 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 18:30:36.540597 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 18:30:36.540632 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 18:30:36.540641 19 statefulset.go:2450] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 18:30:46.561646 19 statefulset.go:2507] Updating stateful set ss2
  STEP: Rolling back update in reverse ordinal order @ 09/04/24 18:30:56.571
  I0904 18:30:56.575008 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-352 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0904 18:30:56.654154 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0904 18:30:56.654183 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 18:30:56.654191 19 statefulset.go:2474] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0904 18:31:06.675077 19 wait.go:158] Waiting for StatefulSet statefulset-352/ss2 to complete update
  I0904 18:31:16.679343 19 statefulset.go:138] Deleting all statefulset in ns statefulset-352
  I0904 18:31:16.682706 19 rest.go:150] Scaling statefulset ss2 to 0
  I0904 18:31:26.698086 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0904 18:31:26.701316 19 rest.go:88] Deleting statefulset ss2
  I0904 18:31:26.714723 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-352" for this suite. @ 09/04/24 18:31:26.718
• [100.562 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 09/04/24 18:31:26.724
  I0904 18:31:26.724892 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename svcaccounts @ 09/04/24 18:31:26.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:26.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:26.744
  STEP: reading a file in the container @ 09/04/24 18:31:28.774
  I0904 18:31:28.774120 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6318 pod-service-account-1c3f0043-fbd7-4f22-ab15-cb194dc5349a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 09/04/24 18:31:28.862
  I0904 18:31:28.862665 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6318 pod-service-account-1c3f0043-fbd7-4f22-ab15-cb194dc5349a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 09/04/24 18:31:28.946
  I0904 18:31:28.946181 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6318 pod-service-account-1c3f0043-fbd7-4f22-ab15-cb194dc5349a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I0904 18:31:29.039275 19 service_accounts.go:114] Got root ca configmap in namespace "svcaccounts-6318"
  I0904 18:31:29.041546 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6318" for this suite. @ 09/04/24 18:31:29.045
• [2.328 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:166
  STEP: Creating a kubernetes client @ 09/04/24 18:31:29.053
  I0904 18:31:29.053324 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename field-validation @ 09/04/24 18:31:29.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:29.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:29.075
  I0904 18:31:29.078525 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  W0904 18:31:31.633939      19 warnings.go:70] unknown field "alpha"
  W0904 18:31:31.633960      19 warnings.go:70] unknown field "beta"
  W0904 18:31:31.633963      19 warnings.go:70] unknown field "delta"
  W0904 18:31:31.633966      19 warnings.go:70] unknown field "epsilon"
  W0904 18:31:31.633968      19 warnings.go:70] unknown field "gamma"
  I0904 18:31:32.184487 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9488" for this suite. @ 09/04/24 18:31:32.188
• [3.143 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 09/04/24 18:31:32.196
  I0904 18:31:32.196435 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename csiinlinevolumes @ 09/04/24 18:31:32.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:32.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:32.218
  STEP: Creating two CSIDrivers @ 09/04/24 18:31:32.221
  STEP: Getting "inline-driver-77176efe-7412-49df-9ea0-20841bfbc9a1" & "inline-driver-46dcf5dd-8f9b-4ecb-8791-a91623154897" @ 09/04/24 18:31:32.239
  STEP: Patching the CSIDriver "inline-driver-46dcf5dd-8f9b-4ecb-8791-a91623154897" @ 09/04/24 18:31:32.246
  STEP: Updating the CSIDriver "inline-driver-46dcf5dd-8f9b-4ecb-8791-a91623154897" @ 09/04/24 18:31:32.252
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-5335" @ 09/04/24 18:31:32.261
  STEP: Deleting CSIDriver "inline-driver-77176efe-7412-49df-9ea0-20841bfbc9a1" @ 09/04/24 18:31:32.265
  STEP: Confirm deletion of CSIDriver "inline-driver-77176efe-7412-49df-9ea0-20841bfbc9a1" @ 09/04/24 18:31:32.273
  STEP: Deleting CSIDriver "inline-driver-46dcf5dd-8f9b-4ecb-8791-a91623154897" via DeleteCollection @ 09/04/24 18:31:32.276
  STEP: Confirm deletion of CSIDriver "inline-driver-46dcf5dd-8f9b-4ecb-8791-a91623154897" @ 09/04/24 18:31:32.285
  I0904 18:31:32.289106 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5335" for this suite. @ 09/04/24 18:31:32.292
• [0.103 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 09/04/24 18:31:32.299
  I0904 18:31:32.299998 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename daemonsets @ 09/04/24 18:31:32.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:32.321
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:32.324
  I0904 18:31:32.349078 19 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0904 18:31:32.355514 19 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I0904 18:31:32.361789 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:32.361819 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:32.365043 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:31:32.365066 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  I0904 18:31:33.361393 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:33.361438 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:33.371300 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0904 18:31:33.371318 19 fixtures.go:130] Node ip-172-31-40-239 is running 0 daemon pod, expected 1
  I0904 18:31:34.361113 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:34.361157 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:34.364479 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 18:31:34.364505 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  I0904 18:31:34.364518 19 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0904 18:31:34.374458 19 daemon_set.go:102] Updating DaemonSet daemon-set
  I0904 18:31:35.388452 19 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0904 18:31:35.399312 19 daemon_set.go:102] Updating DaemonSet daemon-set
  I0904 18:31:35.399337 19 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I0904 18:31:35.402369 19 daemon_set.go:1193] Wrong image for pod: daemon-set-89nhz. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I0904 18:31:35.402389 19 daemon_set.go:1198] Pod daemon-set-89nhz is not available
  I0904 18:31:35.406077 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:35.406120 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:36.408078 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:36.408121 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:37.404714 19 daemon_set.go:1198] Pod daemon-set-lcbrv is not available
  I0904 18:31:37.408414 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:31:37.408455 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 09/04/24 18:31:37.415
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7700, will wait for the garbage collector to delete the pods @ 09/04/24 18:31:37.415
  I0904 18:31:37.474292 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 6.001936ms
  I0904 18:31:37.575827 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.528423ms
  I0904 18:31:39.380467 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:31:39.380505 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0904 18:31:39.384122 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18903"},"items":null}

  I0904 18:31:39.387536 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18903"},"items":null}

  I0904 18:31:39.401645 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7700" for this suite. @ 09/04/24 18:31:39.405
• [7.112 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 09/04/24 18:31:39.411
  I0904 18:31:39.411816 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 18:31:39.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:39.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:39.436
  STEP: set up a multi version CRD @ 09/04/24 18:31:39.439
  I0904 18:31:39.439980 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: mark a version not serverd @ 09/04/24 18:31:42.528
  STEP: check the unserved version gets removed @ 09/04/24 18:31:42.546
  STEP: check the other version is not changed @ 09/04/24 18:31:43.372
  I0904 18:31:45.838958 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2946" for this suite. @ 09/04/24 18:31:45.847
• [6.443 seconds]
------------------------------
S
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 09/04/24 18:31:45.854
  I0904 18:31:45.854794 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:31:45.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:45.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:45.874
  STEP: Creating configMap configmap-7317/configmap-test-04ee0f0c-d8ec-46ff-bb61-08dde89d98c7 @ 09/04/24 18:31:45.878
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:31:45.882
  STEP: Saw pod success @ 09/04/24 18:31:49.906
  I0904 18:31:49.910272 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-19976d96-188b-4e42-8c25-6aff0b44d962 container env-test: <nil>
  STEP: delete the pod @ 09/04/24 18:31:49.919
  I0904 18:31:49.939301 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7317" for this suite. @ 09/04/24 18:31:49.943
• [4.095 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 09/04/24 18:31:49.95
  I0904 18:31:49.950387 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 18:31:49.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:49.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:49.972
  STEP: creating the pod @ 09/04/24 18:31:49.975
  STEP: setting up watch @ 09/04/24 18:31:49.975
  STEP: submitting the pod to kubernetes @ 09/04/24 18:31:50.078
  STEP: verifying the pod is in kubernetes @ 09/04/24 18:31:50.09
  STEP: verifying pod creation was observed @ 09/04/24 18:31:50.095
  STEP: deleting the pod gracefully @ 09/04/24 18:31:52.109
  STEP: verifying pod deletion was observed @ 09/04/24 18:31:52.118
  I0904 18:31:53.319751 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2703" for this suite. @ 09/04/24 18:31:53.324
• [3.381 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 09/04/24 18:31:53.331
  I0904 18:31:53.331532 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename proxy @ 09/04/24 18:31:53.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:53.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:53.352
  I0904 18:31:53.356146 19 proxy.go:387] Creating pod...
  I0904 18:31:55.374200 19 proxy.go:411] Creating service...
  I0904 18:31:55.383922 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/pods/agnhost/proxy?method=DELETE
  I0904 18:31:55.389302 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0904 18:31:55.389339 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/pods/agnhost/proxy?method=OPTIONS
  I0904 18:31:55.396161 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0904 18:31:55.396385 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/pods/agnhost/proxy?method=PATCH
  I0904 18:31:55.399810 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0904 18:31:55.399831 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/pods/agnhost/proxy?method=POST
  I0904 18:31:55.402854 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0904 18:31:55.402939 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/pods/agnhost/proxy?method=PUT
  I0904 18:31:55.407547 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0904 18:31:55.407834 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/services/e2e-proxy-test-service/proxy?method=DELETE
  I0904 18:31:55.413638 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0904 18:31:55.413678 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0904 18:31:55.418011 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0904 18:31:55.418031 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/services/e2e-proxy-test-service/proxy?method=PATCH
  I0904 18:31:55.424808 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0904 18:31:55.424840 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/services/e2e-proxy-test-service/proxy?method=POST
  I0904 18:31:55.430508 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0904 18:31:55.430544 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/services/e2e-proxy-test-service/proxy?method=PUT
  I0904 18:31:55.434984 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0904 18:31:55.435020 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/pods/agnhost/proxy?method=GET
  I0904 18:31:55.438465 19 proxy.go:487] http.Client request:GET StatusCode:301
  I0904 18:31:55.438488 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/services/e2e-proxy-test-service/proxy?method=GET
  I0904 18:31:55.443631 19 proxy.go:487] http.Client request:GET StatusCode:301
  I0904 18:31:55.443651 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/pods/agnhost/proxy?method=HEAD
  I0904 18:31:55.446831 19 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0904 18:31:55.446850 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2782/services/e2e-proxy-test-service/proxy?method=HEAD
  I0904 18:31:55.451928 19 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0904 18:31:55.452084 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2782" for this suite. @ 09/04/24 18:31:55.456
• [2.134 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 09/04/24 18:31:55.466
  I0904 18:31:55.466223 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename apf @ 09/04/24 18:31:55.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:55.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:55.488
  STEP: getting /apis @ 09/04/24 18:31:55.491
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 09/04/24 18:31:55.495
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 09/04/24 18:31:55.497
  STEP: creating @ 09/04/24 18:31:55.498
  STEP: getting @ 09/04/24 18:31:55.514
  STEP: listing @ 09/04/24 18:31:55.517
  STEP: watching @ 09/04/24 18:31:55.521
  I0904 18:31:55.521223 19 flowcontrol.go:394] starting watch
  STEP: patching @ 09/04/24 18:31:55.522
  STEP: updating @ 09/04/24 18:31:55.529
  I0904 18:31:55.537548 19 flowcontrol.go:422] waiting for watch events with expected annotations
  STEP: getting /status @ 09/04/24 18:31:55.537
  STEP: patching /status @ 09/04/24 18:31:55.54
  STEP: updating /status @ 09/04/24 18:31:55.545
  STEP: deleting @ 09/04/24 18:31:55.579
  STEP: deleting a collection @ 09/04/24 18:31:55.592
  I0904 18:31:55.610574 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-181" for this suite. @ 09/04/24 18:31:55.613
• [0.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 09/04/24 18:31:55.62
  I0904 18:31:55.620331 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replication-controller @ 09/04/24 18:31:55.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:55.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:55.643
  STEP: creating a ReplicationController @ 09/04/24 18:31:55.65
  STEP: waiting for RC to be added @ 09/04/24 18:31:55.657
  STEP: waiting for available Replicas @ 09/04/24 18:31:55.657
  STEP: patching ReplicationController @ 09/04/24 18:31:56.321
  STEP: waiting for RC to be modified @ 09/04/24 18:31:56.329
  STEP: patching ReplicationController status @ 09/04/24 18:31:56.329
  STEP: waiting for RC to be modified @ 09/04/24 18:31:56.335
  STEP: waiting for available Replicas @ 09/04/24 18:31:56.335
  STEP: fetching ReplicationController status @ 09/04/24 18:31:56.341
  STEP: patching ReplicationController scale @ 09/04/24 18:31:56.345
  STEP: waiting for RC to be modified @ 09/04/24 18:31:56.35
  STEP: waiting for ReplicationController's scale to be the max amount @ 09/04/24 18:31:56.351
  STEP: fetching ReplicationController; ensuring that it's patched @ 09/04/24 18:31:57.871
  STEP: updating ReplicationController status @ 09/04/24 18:31:57.875
  STEP: waiting for RC to be modified @ 09/04/24 18:31:57.881
  STEP: listing all ReplicationControllers @ 09/04/24 18:31:57.881
  STEP: checking that ReplicationController has expected values @ 09/04/24 18:31:57.884
  STEP: deleting ReplicationControllers by collection @ 09/04/24 18:31:57.884
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 09/04/24 18:31:57.893
  I0904 18:31:57.940431 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0904 18:31:57.940678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-503" for this suite. @ 09/04/24 18:31:57.944
• [2.331 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 09/04/24 18:31:57.951
  I0904 18:31:57.951855 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:31:57.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:31:57.97
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:31:57.974
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:31:57.978
  E0904 18:31:58.940835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:31:59.941078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:00.941126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:01.941230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:32:02.005
  I0904 18:32:02.009314 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-f09fa733-985e-467d-91c3-1d9c5f97295c container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:32:02.014
  I0904 18:32:02.030754 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2503" for this suite. @ 09/04/24 18:32:02.035
• [4.092 seconds]
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1473
  STEP: Creating a kubernetes client @ 09/04/24 18:32:02.043
  I0904 18:32:02.043893 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:32:02.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:32:02.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:32:02.067
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8542 @ 09/04/24 18:32:02.074
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 09/04/24 18:32:02.091
  STEP: creating service externalsvc in namespace services-8542 @ 09/04/24 18:32:02.091
  STEP: creating replication controller externalsvc in namespace services-8542 @ 09/04/24 18:32:02.102
  I0904 18:32:02.109554      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8542, replica count: 2
  E0904 18:32:02.942050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:03.942174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:04.942701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:05.161131      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 09/04/24 18:32:05.166
  I0904 18:32:05.179674 19 resource.go:361] Creating new exec pod
  E0904 18:32:05.942811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:06.942908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:07.197503 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-8542 exec execpodsnsqx -- /bin/sh -x -c nslookup clusterip-service.services-8542.svc.cluster.local'
  I0904 18:32:07.292954 19 builder.go:146] stderr: "+ nslookup clusterip-service.services-8542.svc.cluster.local\n"
  I0904 18:32:07.293006 19 builder.go:147] stdout: "Server:\t\t10.152.183.70\nAddress:\t10.152.183.70#53\n\nclusterip-service.services-8542.svc.cluster.local\tcanonical name = externalsvc.services-8542.svc.cluster.local.\nName:\texternalsvc.services-8542.svc.cluster.local\nAddress: 10.152.183.20\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-8542, will wait for the garbage collector to delete the pods @ 09/04/24 18:32:07.293
  I0904 18:32:07.355544 19 resources.go:139] Deleting ReplicationController externalsvc took: 7.640583ms
  I0904 18:32:07.456659 19 resources.go:163] Terminating ReplicationController externalsvc pods took: 101.110286ms
  E0904 18:32:07.943877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:08.944094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:09.944624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:10.475249 19 service.go:1482] Cleaning up the ClusterIP to ExternalName test service
  I0904 18:32:10.485742 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8542" for this suite. @ 09/04/24 18:32:10.489
• [8.451 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 09/04/24 18:32:10.495
  I0904 18:32:10.495564 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:32:10.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:32:10.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:32:10.515
  STEP: Creating pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593 @ 09/04/24 18:32:10.519
  E0904 18:32:10.944670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:11.945155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/04/24 18:32:12.537
  I0904 18:32:12.541281 19 container_probe.go:1749] Initial restart count of pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea is 0
  I0904 18:32:12.544862 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:12.945611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:13.945868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:14.549544 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:14.945992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:15.946967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:16.554792 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:16.947256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:17.947856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:18.561224 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:18.948712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:19.948922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:20.566333 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:20.949864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:21.950053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:22.571274 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:22.950938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:23.951021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:24.576057 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:24.951579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:25.951702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:26.581997 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:26.952529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:27.952970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:28.587288 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:28.953742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:29.953834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:30.592608 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:30.953955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:31.953997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:32.598212 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:32.954662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:33.954774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:34.603443 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:34.954825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:35.954930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:36.608237 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:36.955716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:37.955843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:38.613702 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:38.956140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:39.956305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:40.619347 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:40.956776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:41.956970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:42.625408 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:42.957904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:43.958664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:44.630992 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:44.959472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:45.959573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:46.636523 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:46.959916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:47.960941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:48.642002 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:48.961449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:49.961597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:50.647279 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:50.962650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:51.962832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:52.652691 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:52.962931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:53.963106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:54.657738 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:54.964163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:55.964362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:56.663445 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:56.964905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:57.965188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:32:58.669328 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:32:58.965761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:32:59.966663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:00.674543 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:00.966762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:01.966942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:02.683166 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:02.967665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:03.967847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:04.688808 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:04.967949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:05.968151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:06.693538 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:06.968962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:07.969220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:08.699724 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:08.970079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:09.970175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:10.704276 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:10.970606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:11.970701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:12.708061 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:12.971449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:13.971686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:14.714009 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:14.972405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:15.973027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:16.719434 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:16.973837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:17.973926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:18.724178 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:18.974633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:19.974870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:20.729736 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:20.975054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:21.975225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:22.735197 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:22.975494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:23.975868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:24.740966 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:24.976200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:25.976299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:26.746007 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:26.977246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:27.978172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:28.751050 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:28.978289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:29.978670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:30.757156 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:30.979419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:31.979529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:32.762731 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:32.980041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:33.980138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:34.767894 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:34.980176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:35.981252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:36.773711 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:36.981987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:37.982241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:38.779033 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:38.982350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:39.982675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:40.783914 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:40.983193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:41.983291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:42.788907 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:42.984253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:43.984502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:44.794536 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:44.984888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:45.985186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:46.800307 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:46.985700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:47.985925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:48.805195 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:48.986452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:49.986566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:50.810632 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:50.986939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:51.987766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:52.816883 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:52.988140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:53.988333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:54.821628 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:54.988954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:55.989034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:56.827737 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:56.989986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:57.990060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:33:58.832394 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:33:58.990654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:33:59.990851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:00.837332 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:00.991603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:01.991791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:02.843766 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:02.991993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:03.992186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:04.848799 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:04.993096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:05.993223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:06.854615 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:06.993905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:07.994126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:08.862540 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:08.994850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:09.995019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:10.868120 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:10.995372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:11.995626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:12.874079 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:12.996274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:13.996370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:14.879448 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:14.996887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:15.996929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:16.884051 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:16.997260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:17.997994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:18.889716 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:18.998967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:19.999084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:20.895219 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:20.999453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:21.999620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:22.900601 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:22.999759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:23.999853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:24.905645 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:24.999930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:26.000100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:26.910565 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:27.000788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:28.000968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:28.916662 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:29.001855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:30.002670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:30.922978 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:31.003204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:32.003471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:32.928047 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:33.004257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:34.004371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:34.934070 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:35.005208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:36.005325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:36.939493 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:37.005564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:38.005609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:38.944411 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:39.006612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:40.006737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:40.950345 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:41.007505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:42.007683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:42.954714 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:43.007820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:44.008008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:44.960520 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:45.008683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:46.008846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:46.965921 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:47.009079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:48.009985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:48.971239 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:49.010382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:50.010577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:50.977274 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:51.011422      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:52.011558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:52.982984 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:53.012056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:54.012176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:54.988134 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:55.012422      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:56.012534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:56.993638 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:57.012784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:34:58.012908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:34:58.998891 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:34:59.012918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:00.013087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:01.003564 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:01.013712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:02.014664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:03.014900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:03.016762 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:04.015025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:05.015196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:05.021770 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:06.015313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:07.015417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:07.027699 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:08.015900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:09.016105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:09.033563 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:10.016626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:11.016726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:11.038704 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:12.017618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:13.017714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:13.043863 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:14.017805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:15.017903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:15.048674 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:16.018680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:17.018772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:17.054038 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:18.018866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:19.018960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:19.058801 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:20.019681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:21.020724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:21.063718 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:22.021619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:23.022686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:23.068010 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:24.022780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:25.022971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:25.072771 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:26.023739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:27.023747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:27.078064 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:28.023900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:29.024004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:29.083052 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:30.024043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:31.024136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:31.088259 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:32.024233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:33.024471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:33.093532 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:34.025581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:35.025635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:35.098570 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:36.025745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:37.026716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:37.103981 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:38.026791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:39.026934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:39.108483 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:40.027474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:41.027669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:41.113592 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:42.027938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:43.028218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:43.119327 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:44.028302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:45.028390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:45.124290 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:46.028684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:47.028854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:47.129779 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:48.028862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:49.029038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:49.135818 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:50.029589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:51.029685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:51.140719 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:52.030683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:53.030780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:53.146428 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:54.031377      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:55.031462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:55.151531 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:56.031514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:57.031565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:57.156350 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:35:58.032410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:35:59.032597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:35:59.161770 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:36:00.032679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:01.032882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:01.167138 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:36:02.032991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:03.033203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:03.172408 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:36:04.033357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:05.033572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:05.178161 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:36:06.033625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:07.034701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:07.183700 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:36:08.034707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:09.034946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:09.189600 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:36:10.035043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:11.035350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:11.195077 19 container_probe.go:1759] Get pod test-grpc-0ecdc0f0-4a2b-4539-b4ac-197dccd906ea in namespace container-probe-2593
  E0904 18:36:12.036002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:13.036195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/04/24 18:36:13.195
  I0904 18:36:13.210374 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2593" for this suite. @ 09/04/24 18:36:13.214
• [242.726 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 09/04/24 18:36:13.221
  I0904 18:36:13.221317 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename init-container @ 09/04/24 18:36:13.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:36:13.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:36:13.242
  STEP: creating the pod @ 09/04/24 18:36:13.245
  I0904 18:36:13.245367 19 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E0904 18:36:14.036333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:15.037018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:16.037737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:16.722774 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1725" for this suite. @ 09/04/24 18:36:16.727
• [3.515 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 09/04/24 18:36:16.736
  I0904 18:36:16.736476 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename hostport @ 09/04/24 18:36:16.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:36:16.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:36:16.758
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 09/04/24 18:36:16.764
  E0904 18:36:17.038687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:18.038940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.40.239 on the node which pod1 resides and expect scheduled @ 09/04/24 18:36:18.781
  E0904 18:36:19.039744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:20.039855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:21.040709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:22.041757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:23.042267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:24.042371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:25.043128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:26.043231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:27.043329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:28.043444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:29.043468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:30.043575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.40.239 but use UDP protocol on the node which pod2 resides @ 09/04/24 18:36:30.824
  E0904 18:36:31.044167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:32.044326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:33.045297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:34.045407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 09/04/24 18:36:34.859
  I0904 18:36:34.859310 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.40.239 http://127.0.0.1:54323/hostname] Namespace:hostport-4942 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:36:34.859327 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:36:34.859724 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:36:34.859763 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4942/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.40.239+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.40.239, port: 54323 @ 09/04/24 18:36:34.916
  I0904 18:36:34.916918 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.40.239:54323/hostname] Namespace:hostport-4942 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:36:34.916935 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:36:34.917323 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:36:34.917377 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4942/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.40.239%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.40.239, port: 54323 UDP @ 09/04/24 18:36:34.968
  I0904 18:36:34.968479 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.40.239 54323] Namespace:hostport-4942 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:36:34.968496 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:36:34.968936 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:36:34.969071 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4942/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.40.239+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0904 18:36:35.045571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:36.045689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:37.045805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:38.045904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:39.045982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:40.016039 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-4942" for this suite. @ 09/04/24 18:36:40.021
• [23.293 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 09/04/24 18:36:40.029
  I0904 18:36:40.030008 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/04/24 18:36:40.03
  E0904 18:36:40.046813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:36:40.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:36:40.052
  STEP: create the container to handle the HTTPGet hook request. @ 09/04/24 18:36:40.059
  E0904 18:36:41.046972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:42.047063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/04/24 18:36:42.081
  E0904 18:36:43.048057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:44.048277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 09/04/24 18:36:44.1
  STEP: delete the pod with lifecycle hook @ 09/04/24 18:36:44.118
  E0904 18:36:45.048385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:46.048775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:46.135750 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-808" for this suite. @ 09/04/24 18:36:46.139
• [6.116 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 09/04/24 18:36:46.146
  I0904 18:36:46.146522 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 18:36:46.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:36:46.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:36:46.168
  STEP: Creating a pod to test emptydir volume type on node default medium @ 09/04/24 18:36:46.172
  E0904 18:36:47.048883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:48.049010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:36:48.19
  I0904 18:36:48.194769 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-bd788953-3c9d-430f-9e37-448e780cfaa5 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 18:36:48.212
  I0904 18:36:48.229373 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2030" for this suite. @ 09/04/24 18:36:48.233
• [2.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 09/04/24 18:36:48.24
  I0904 18:36:48.240759 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 18:36:48.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:36:48.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:36:48.26
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 09/04/24 18:36:48.263
  I0904 18:36:48.263906 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 18:36:49.049594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:49.534571 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 18:36:50.050011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:51.050336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:52.050498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:53.051057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:54.051589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:36:54.483080 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8755" for this suite. @ 09/04/24 18:36:54.491
• [6.257 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:104
  STEP: Creating a kubernetes client @ 09/04/24 18:36:54.497
  I0904 18:36:54.497827 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 18:36:54.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:36:54.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:36:54.52
  STEP: Counting existing ResourceQuota @ 09/04/24 18:36:54.523
  E0904 18:36:55.051930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:56.052755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:57.053750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:58.054548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:36:59.055443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/04/24 18:36:59.53
  STEP: Ensuring resource quota status is calculated @ 09/04/24 18:36:59.535
  E0904 18:37:00.055582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:01.055690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 09/04/24 18:37:01.541
  STEP: Creating a NodePort Service @ 09/04/24 18:37:01.701
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 09/04/24 18:37:01.721
  STEP: Ensuring resource quota status captures service creation @ 09/04/24 18:37:01.74
  E0904 18:37:02.055825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:03.056596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 09/04/24 18:37:03.746
  STEP: Ensuring resource quota status released usage @ 09/04/24 18:37:03.776
  E0904 18:37:04.057168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:05.057985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:37:05.782113 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4571" for this suite. @ 09/04/24 18:37:05.786
• [11.296 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3619
  STEP: Creating a kubernetes client @ 09/04/24 18:37:05.794
  I0904 18:37:05.794169 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:37:05.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:37:05.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:37:05.814
  STEP: creating a collection of services @ 09/04/24 18:37:05.818
  I0904 18:37:05.818192 19 service.go:3655] Creating e2e-svc-a-5mkhd
  I0904 18:37:05.829186 19 service.go:3655] Creating e2e-svc-b-5d5h6
  I0904 18:37:05.838221 19 service.go:3655] Creating e2e-svc-c-r568z
  STEP: deleting service collection @ 09/04/24 18:37:05.851
  I0904 18:37:05.875737 19 service.go:3690] Collection of services has been deleted
  I0904 18:37:05.875917 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1268" for this suite. @ 09/04/24 18:37:05.879
• [0.091 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:626
  STEP: Creating a kubernetes client @ 09/04/24 18:37:05.886
  I0904 18:37:05.886527 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-preemption @ 09/04/24 18:37:05.887
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:37:05.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:37:05.907
  I0904 18:37:05.923503 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0904 18:37:06.058090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:07.058678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:08.059331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:09.059394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:10.060045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:11.060105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:12.061166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:13.061388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:14.062194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:15.062677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:16.063297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:17.063426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:18.064298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:19.064368      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:20.064843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:21.065897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:22.066152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:23.067073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:24.067311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:25.067850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:26.068893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:27.068993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:28.069651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:29.069752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:30.070178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:31.070650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:32.071230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:33.071339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:34.071923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:35.072041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:36.072852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:37.072961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:38.073435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:39.073598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:40.074091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:41.074194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:42.074637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:43.074733      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:44.074995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:45.075169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:46.075854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:47.076182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:48.076241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:49.076415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:50.076874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:51.076968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:52.077236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:53.078094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:54.078277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:55.078274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:56.079030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:57.079241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:58.079361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:37:59.079419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:00.080203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:01.080703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:02.081234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:03.081347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:04.081655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:05.082671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:05.928036 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 09/04/24 18:38:05.932
  I0904 18:38:05.932488 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-preemption-path @ 09/04/24 18:38:05.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:05.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:05.955
  STEP: Finding an available node @ 09/04/24 18:38:05.958
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/04/24 18:38:05.958
  E0904 18:38:06.083060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:07.083179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/04/24 18:38:07.977
  I0904 18:38:07.991962 19 preemption.go:585] found a healthy node: ip-172-31-21-169
  E0904 18:38:08.083141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:09.083597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:10.084163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:11.084799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:12.085199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:13.086255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:14.053737 19 preemption.go:708] pods created so far: [1 1 1]
  I0904 18:38:14.053767 19 preemption.go:709] length of pods created so far: 3
  E0904 18:38:14.086785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:15.087734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:16.064843 19 preemption.go:726] pods created so far: [2 2 1]
  E0904 18:38:16.087981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:17.088123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:18.089089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:19.090016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:20.090116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:21.090212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:22.090296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:23.090558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:23.131742 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-475" for this suite. @ 09/04/24 18:38:23.136
  I0904 18:38:23.142468 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-27" for this suite. @ 09/04/24 18:38:23.147
• [77.267 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 09/04/24 18:38:23.153
  I0904 18:38:23.153824 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename deployment @ 09/04/24 18:38:23.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:23.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:23.174
  STEP: creating a Deployment @ 09/04/24 18:38:23.18
  I0904 18:38:23.180391 19 deployment.go:507] Creating simple deployment test-deployment-p4l4z
  I0904 18:38:23.192472 19 deployment.go:222] new replicaset for deployment "test-deployment-p4l4z" is yet to be created
  E0904 18:38:24.090659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:25.090751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Getting /status @ 09/04/24 18:38:25.207
  I0904 18:38:25.211483 19 deployment.go:532] Deployment test-deployment-p4l4z has Conditions: [{Available True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-p4l4z-f4dbbbf74" has successfully progressed.}]
  STEP: updating Deployment Status @ 09/04/24 18:38:25.211
  I0904 18:38:25.221229 19 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 38, 24, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 38, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 38, 24, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 38, 23, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-p4l4z-f4dbbbf74\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 09/04/24 18:38:25.221
  I0904 18:38:25.223097 19 deployment.go:579] Observed &Deployment event: ADDED
  I0904 18:38:25.223115 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-p4l4z-f4dbbbf74"}
  I0904 18:38:25.223185 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I0904 18:38:25.223197 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-p4l4z-f4dbbbf74"}
  I0904 18:38:25.223206 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0904 18:38:25.223299 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I0904 18:38:25.223426 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0904 18:38:25.223520 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-p4l4z-f4dbbbf74" is progressing.}
  I0904 18:38:25.223672 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I0904 18:38:25.223686 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0904 18:38:25.223694 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-p4l4z-f4dbbbf74" has successfully progressed.}
  I0904 18:38:25.223771 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I0904 18:38:25.223784 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0904 18:38:25.223792 19 deployment.go:575] Observed Deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-p4l4z-f4dbbbf74" has successfully progressed.}
  I0904 18:38:25.223802 19 deployment.go:572] Found Deployment test-deployment-p4l4z in namespace deployment-8954 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0904 18:38:25.223810 19 deployment.go:583] Deployment test-deployment-p4l4z has an updated status
  STEP: patching the Statefulset Status @ 09/04/24 18:38:25.223
  I0904 18:38:25.223833 19 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0904 18:38:25.230416 19 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 09/04/24 18:38:25.23
  I0904 18:38:25.232141 19 deployment.go:616] Observed &Deployment event: ADDED
  I0904 18:38:25.232174 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-p4l4z-f4dbbbf74"}
  I0904 18:38:25.232276 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I0904 18:38:25.232310 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-p4l4z-f4dbbbf74"}
  I0904 18:38:25.232348 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0904 18:38:25.232445 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I0904 18:38:25.232543 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0904 18:38:25.232591 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:23 +0000 UTC 2024-09-04 18:38:23 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-p4l4z-f4dbbbf74" is progressing.}
  I0904 18:38:25.232701 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I0904 18:38:25.232719 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0904 18:38:25.232728 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-p4l4z-f4dbbbf74" has successfully progressed.}
  I0904 18:38:25.232853 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I0904 18:38:25.232882 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0904 18:38:25.232890 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-04 18:38:24 +0000 UTC 2024-09-04 18:38:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-p4l4z-f4dbbbf74" has successfully progressed.}
  I0904 18:38:25.232898 19 deployment.go:612] Observed deployment test-deployment-p4l4z in namespace deployment-8954 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0904 18:38:25.232986 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I0904 18:38:25.233000 19 deployment.go:609] Found deployment test-deployment-p4l4z in namespace deployment-8954 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0904 18:38:25.233008 19 deployment.go:620] Deployment test-deployment-p4l4z has a patched status
  I0904 18:38:25.237704 19 deployment.go:633] Deployment "test-deployment-p4l4z":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-p4l4z",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c2548f08-69df-4abf-abb5-f1d627c4fba5",
      ResourceVersion: (string) (len=5) "20635",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071903,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071904,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=224) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |ions":{},"f:obse|
              00000090  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              000000a0  7b 7d 2c 22 66 3a 72 65  61 64 79 52 65 70 6c 69  |{},"f:readyRepli|
              000000b0  63 61 73 22 3a 7b 7d 2c  22 66 3a 72 65 70 6c 69  |cas":{},"f:repli|
              000000c0  63 61 73 22 3a 7b 7d 2c  22 66 3a 75 70 64 61 74  |cas":{},"f:updat|
              000000d0  65 64 52 65 70 6c 69 63  61 73 22 3a 7b 7d 7d 7d  |edReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071905,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=1) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0904 18:38:25.241580 19 deployment.go:39] New ReplicaSet "test-deployment-p4l4z-f4dbbbf74" of Deployment "test-deployment-p4l4z":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-p4l4z-f4dbbbf74",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "369bd0a3-4dc1-4291-8427-c412235d5a85",
      ResourceVersion: (string) (len=5) "20631",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071903,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-p4l4z",
          UID: (types.UID) (len=36) "c2548f08-69df-4abf-abb5-f1d627c4fba5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 63 32 35  |k:{\"uid\":\"c25|
              00000120  34 38 66 30 38 2d 36 39  64 66 2d 34 61 62 66 2d  |48f08-69df-4abf-|
              00000130  61 62 62 35 2d 66 31 64  36 32 37 63 34 66 62 61  |abb5-f1d627c4fba|
              00000140  35 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |5\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071904,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:38:25.246298 19 deployment.go:67] Pod "test-deployment-p4l4z-f4dbbbf74-nd59g" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "test-deployment-p4l4z-f4dbbbf74-nd59g",
      GenerateName: (string) (len=32) "test-deployment-p4l4z-f4dbbbf74-",
      Namespace: (string) (len=15) "deployment-8954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "863c6cbb-8753-4275-9293-b23cfe20f4dd",
      ResourceVersion: (string) (len=5) "20630",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071903,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "test-deployment-p4l4z-f4dbbbf74",
          UID: (types.UID) (len=36) "369bd0a3-4dc1-4291-8427-c412235d5a85",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 33 36 39 62 64 30 61  33 2d 34 64 63 31 2d 34  |"369bd0a3-4dc1-4|
              000000a0  32 39 31 2d 38 34 32 37  2d 63 34 31 32 32 33 35  |291-8427-c412235|
              000000b0  64 35 61 38 35 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |d5a85\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071904,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 30  34 2e 31 33 36 5c 22 7d  |2.168.104.136\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mv2z4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mv2z4",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071904,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071904,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071904,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071903,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.40.239",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.40.239"
        }
      },
      PodIP: (string) (len=15) "192.168.104.136",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.104.136"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071903,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071903,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f7e4d70e6256d17d6f89c084db0b3c8170d44a33aa12052a8a11b86c963d4717",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-mv2z4",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:25.247446 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8954" for this suite. @ 09/04/24 18:38:25.25
• [2.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 09/04/24 18:38:25.256
  I0904 18:38:25.256869 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/04/24 18:38:25.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:25.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:25.277
  STEP: create the container to handle the HTTPGet hook request. @ 09/04/24 18:38:25.284
  E0904 18:38:26.091073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:27.091333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/04/24 18:38:27.304
  E0904 18:38:28.091776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:29.091857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 09/04/24 18:38:29.323
  E0904 18:38:30.091988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:31.092088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 09/04/24 18:38:31.344
  I0904 18:38:31.369207 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9371" for this suite. @ 09/04/24 18:38:31.376
• [6.127 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 09/04/24 18:38:31.384
  I0904 18:38:31.384134 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename deployment @ 09/04/24 18:38:31.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:31.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:31.402
  I0904 18:38:31.405608 19 deployment.go:1196] Creating deployment "webserver-deployment"
  I0904 18:38:31.410055 19 deployment.go:1200] Waiting for observed generation 1
  E0904 18:38:32.092174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:33.092382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:33.417374 19 deployment.go:1205] Waiting for all required pods to come up
  I0904 18:38:33.420994 19 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 09/04/24 18:38:33.421
  I0904 18:38:33.421071 19 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I0904 18:38:33.427797 19 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I0904 18:38:33.438522 19 deployment.go:313] Updating deployment webserver-deployment
  I0904 18:38:33.438548 19 deployment.go:1224] Waiting for observed generation 2
  E0904 18:38:34.093293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:35.093582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:35.447158 19 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0904 18:38:35.451323 19 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0904 18:38:35.454572 19 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0904 18:38:35.463996 19 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0904 18:38:35.464017 19 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0904 18:38:35.467515 19 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0904 18:38:35.474278 19 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0904 18:38:35.474296 19 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0904 18:38:35.484445 19 deployment.go:313] Updating deployment webserver-deployment
  I0904 18:38:35.484469 19 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0904 18:38:35.490695 19 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0904 18:38:35.493310 19 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0904 18:38:35.505874 19 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b9b43c09-c814-4955-a13e-15ed49e0e5cb",
      ResourceVersion: (string) (len=5) "21042",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-786f49d774\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0904 18:38:35.514699 19 deployment.go:39] New ReplicaSet "webserver-deployment-786f49d774" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-786f49d774",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d84a5d14-ac08-450c-bbe2-9daaa56387eb",
      ResourceVersion: (string) (len=5) "21046",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "b9b43c09-c814-4955-a13e-15ed49e0e5cb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 39 62 34 33 63  30 39 2d 63 38 31 34 2d  |\"b9b43c09-c814-|
              00000120  34 39 35 35 2d 61 31 33  65 2d 31 35 65 64 34 39  |4955-a13e-15ed49|
              00000130  65 30 65 35 63 62 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e0e5cb\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:38:35.515444 19 deployment.go:44] All old ReplicaSets of Deployment "webserver-deployment":
  I0904 18:38:35.515715 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-64bcfc6446",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
      ResourceVersion: (string) (len=5) "21043",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "b9b43c09-c814-4955-a13e-15ed49e0e5cb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 39 62 34 33 63  30 39 2d 63 38 31 34 2d  |\"b9b43c09-c814-|
              00000120  34 39 35 35 2d 61 31 33  65 2d 31 35 65 64 34 39  |4955-a13e-15ed49|
              00000130  65 30 65 35 63 62 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e0e5cb\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:38:35.526848 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-4kcdf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-4kcdf",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "93cf0404-592d-4716-ac20-9da17e8188af",
      ResourceVersion: (string) (len=5) "20916",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 30  34 2e 31 33 39 5c 22 7d  |2.168.104.139\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-z4xr8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-z4xr8",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.40.239",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.40.239"
        }
      },
      PodIP: (string) (len=15) "192.168.104.139",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.104.139"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071912,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://239f246b72f3676894473d3f53e2b742d9690b020eb5ac67631f31b372e3bb11",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-z4xr8",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.528260 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-52qgz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-52qgz",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e97fc7ce-2e84-4793-aee9-335ae7a8686d",
      ResourceVersion: (string) (len=5) "21047",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071915,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hkc72",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hkc72",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.529311 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-697f4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-697f4",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c0927678-f9ef-4c8b-967e-f18bcaca7301",
      ResourceVersion: (string) (len=5) "21056",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071915,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xpnpk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xpnpk",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.530353 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-brlzl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-brlzl",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f2786c0a-2dd4-4166-a816-ee29ee78b00d",
      ResourceVersion: (string) (len=5) "20910",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 30  34 2e 31 33 38 5c 22 7d  |2.168.104.138\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4zcwm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4zcwm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.40.239",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.40.239"
        }
      },
      PodIP: (string) (len=15) "192.168.104.138",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.104.138"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071912,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://19055edcf151311b6c5f929dce8dec257b76390052e8612c7b59c38cf5fcfd12",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-4zcwm",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.531801 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-lcknt" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-lcknt",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "22033a15-685f-49ce-af68-2305ca132dca",
      ResourceVersion: (string) (len=5) "20931",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 34  36 2e 31 33 39 5c 22 7d  |2.168.146.139\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dgv5c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dgv5c",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.21.169",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.21.169"
        }
      },
      PodIP: (string) (len=15) "192.168.146.139",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.146.139"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071912,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://e963eb13cbdc71cb1f3b0d2dc3b387c949a1d4b767ecd7ce23f902ccb3172cae",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-dgv5c",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.533285 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-mcxrb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-mcxrb",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e2c640db-8a5a-4d8e-9486-c43ad26b8441",
      ResourceVersion: (string) (len=5) "21055",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071915,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5vd4g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5vd4g",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.534315 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-n4khl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-n4khl",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d4ee8025-33b4-4f1b-9f44-029f63427a3d",
      ResourceVersion: (string) (len=5) "20906",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  33 2e 35 30 5c 22 7d 22  |2.168.243.50\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sws77",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sws77",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-7-223",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.7.223",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.7.223"
        }
      },
      PodIP: (string) (len=14) "192.168.243.50",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.243.50"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071912,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a427d24903ffd0bfe426554417f979e233eddfba1178e8fbad23b6ce9c0e0d10",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-sws77",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.535746 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-ph277" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-ph277",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "661be0ff-a763-482c-97ba-6b15bc3bcf8f",
      ResourceVersion: (string) (len=5) "20913",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 30  34 2e 31 34 30 5c 22 7d  |2.168.104.140\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bhjdf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bhjdf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.40.239",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.40.239"
        }
      },
      PodIP: (string) (len=15) "192.168.104.140",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.104.140"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071912,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a78bfd8b82f37856ce1244976697ab9ccfec5c8ba420869271254b4899bbffb8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-bhjdf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.540778 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-pl5m9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-pl5m9",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "195c51db-c4a8-47a8-a7d4-6980ba3ca611",
      ResourceVersion: (string) (len=5) "20928",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 34  36 2e 31 37 30 5c 22 7d  |2.168.146.170\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jf5nl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jf5nl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.21.169",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.21.169"
        }
      },
      PodIP: (string) (len=15) "192.168.146.170",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.146.170"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071912,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://ea71ca4543939c1f67328bf51a2ac0df0b6756df91194a4177f1049ff18625ae",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jf5nl",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.541972 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-rt6vj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-rt6vj",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "211d095b-387f-4ba1-a508-1dd65a7b46ce",
      ResourceVersion: (string) (len=5) "20934",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  33 2e 35 31 5c 22 7d 22  |2.168.243.51\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qmf46",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qmf46",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-7-223",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.7.223",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.7.223"
        }
      },
      PodIP: (string) (len=14) "192.168.243.51",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.243.51"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071912,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://104ddbf10a204d3cd2da9fc49384d7e8746c5a521a6f6fc92462d2f3fb522308",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-qmf46",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.543088 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-s4f27" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-s4f27",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "08ce69da-cbdb-4fca-a50c-708c2dfe5714",
      ResourceVersion: (string) (len=5) "20902",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  33 2e 34 39 5c 22 7d 22  |2.168.243.49\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-blf4f",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-blf4f",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-7-223",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.7.223",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.7.223"
        }
      },
      PodIP: (string) (len=14) "192.168.243.49",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.243.49"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861071912,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0356c5d97c004477fd517b9eb54abfbd99a6a48353b6c04c5e2e3bcb2431e130",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-blf4f",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.544114 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-v6hcq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-v6hcq",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2056622e-7109-4f94-b26a-39c2bb3f9e43",
      ResourceVersion: (string) (len=5) "21057",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071915,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "4a65aff0-2870-4387-b75b-d71feaadb83a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 61  36 35 61 66 66 30 2d 32  |d\":\"4a65aff0-2|
              00000090  38 37 30 2d 34 33 38 37  2d 62 37 35 62 2d 64 37  |870-4387-b75b-d7|
              000000a0  31 66 65 61 61 64 62 38  33 61 5c 22 7d 22 3a 7b  |1feaadb83a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n6rxh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n6rxh",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.545233 19 deployment.go:67] Pod "webserver-deployment-786f49d774-9rwxl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-9rwxl",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "378349e0-63c6-4ac1-b0ce-75a7de839eb9",
      ResourceVersion: (string) (len=5) "21030",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "d84a5d14-ac08-450c-bbe2-9daaa56387eb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 38  34 61 35 64 31 34 2d 61  |d\":\"d84a5d14-a|
              00000090  63 30 38 2d 34 35 30 63  2d 62 62 65 32 2d 39 64  |c08-450c-bbe2-9d|
              000000a0  61 61 61 35 36 33 38 37  65 62 5c 22 7d 22 3a 7b  |aaa56387eb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 30 34 2e 31  34 31 5c 22 7d 22 3a 7b  |68.104.141\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6hl6s",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6hl6s",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.40.239",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.40.239"
        }
      },
      PodIP: (string) (len=15) "192.168.104.141",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.104.141"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-6hl6s",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.546382 19 deployment.go:67] Pod "webserver-deployment-786f49d774-fn27g" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-fn27g",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aeb90254-1c92-4404-9e17-50d6eca77e53",
      ResourceVersion: (string) (len=5) "21023",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "d84a5d14-ac08-450c-bbe2-9daaa56387eb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 38  34 61 35 64 31 34 2d 61  |d\":\"d84a5d14-a|
              00000090  63 30 38 2d 34 35 30 63  2d 62 62 65 32 2d 39 64  |c08-450c-bbe2-9d|
              000000a0  61 61 61 35 36 33 38 37  65 62 5c 22 7d 22 3a 7b  |aaa56387eb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 34 33 2e 35  32 5c 22 7d 22 3a 7b 22  |68.243.52\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rgjkr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rgjkr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-7-223",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.7.223",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.7.223"
        }
      },
      PodIP: (string) (len=14) "192.168.243.52",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.243.52"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-rgjkr",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.547522 19 deployment.go:67] Pod "webserver-deployment-786f49d774-hrk4f" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-hrk4f",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "793c2c6b-88df-40ca-a56d-46b9d97bc1d6",
      ResourceVersion: (string) (len=5) "21033",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "d84a5d14-ac08-450c-bbe2-9daaa56387eb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 38  34 61 35 64 31 34 2d 61  |d\":\"d84a5d14-a|
              00000090  63 30 38 2d 34 35 30 63  2d 62 62 65 32 2d 39 64  |c08-450c-bbe2-9d|
              000000a0  61 61 61 35 36 33 38 37  65 62 5c 22 7d 22 3a 7b  |aaa56387eb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 30 34 2e 31  34 32 5c 22 7d 22 3a 7b  |68.104.142\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xzmf6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xzmf6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.40.239",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.40.239"
        }
      },
      PodIP: (string) (len=15) "192.168.104.142",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.104.142"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-xzmf6",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.548627 19 deployment.go:67] Pod "webserver-deployment-786f49d774-nzw9v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-nzw9v",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "382756ed-5384-4dc6-91d0-114cf59754c7",
      ResourceVersion: (string) (len=5) "21039",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "d84a5d14-ac08-450c-bbe2-9daaa56387eb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 38  34 61 35 64 31 34 2d 61  |d\":\"d84a5d14-a|
              00000090  63 30 38 2d 34 35 30 63  2d 62 62 65 32 2d 39 64  |c08-450c-bbe2-9d|
              000000a0  61 61 61 35 36 33 38 37  65 62 5c 22 7d 22 3a 7b  |aaa56387eb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 34 36 2e 31  36 38 5c 22 7d 22 3a 7b  |68.146.168\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-48ncb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-48ncb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.21.169",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.21.169"
        }
      },
      PodIP: (string) (len=15) "192.168.146.168",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.146.168"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-48ncb",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.551781 19 deployment.go:67] Pod "webserver-deployment-786f49d774-t9vgk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-t9vgk",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7631e7ca-e087-442d-a0e1-3dd1261cf364",
      ResourceVersion: (string) (len=5) "21037",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "d84a5d14-ac08-450c-bbe2-9daaa56387eb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 38  34 61 35 64 31 34 2d 61  |d\":\"d84a5d14-a|
              00000090  63 30 38 2d 34 35 30 63  2d 62 62 65 32 2d 39 64  |c08-450c-bbe2-9d|
              000000a0  61 61 61 35 36 33 38 37  65 62 5c 22 7d 22 3a 7b  |aaa56387eb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 34 36 2e 31  34 35 5c 22 7d 22 3a 7b  |68.146.145\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t69zq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t69zq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-21-169",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071914,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071913,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.21.169",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.21.169"
        }
      },
      PodIP: (string) (len=15) "192.168.146.145",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.146.145"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071913,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-t69zq",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.552793 19 deployment.go:67] Pod "webserver-deployment-786f49d774-x9zjg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-x9zjg",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-9995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "13d35578-02e1-4eb6-987d-5a643bb98a6a",
      ResourceVersion: (string) (len=5) "21050",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861071915,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "d84a5d14-ac08-450c-bbe2-9daaa56387eb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861071915,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 38  34 61 35 64 31 34 2d 61  |d\":\"d84a5d14-a|
              00000090  63 30 38 2d 34 35 30 63  2d 62 62 65 32 2d 39 64  |c08-450c-bbe2-9d|
              000000a0  61 61 61 35 36 33 38 37  65 62 5c 22 7d 22 3a 7b  |aaa56387eb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gslpp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gslpp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:38:35.553370 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9995" for this suite. @ 09/04/24 18:38:35.571
• [4.198 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 09/04/24 18:38:35.582
  I0904 18:38:35.582210 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename var-expansion @ 09/04/24 18:38:35.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:35.676
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:35.679
  E0904 18:38:36.093808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:37.093936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:37.971800 19 delete.go:62] Deleting pod "var-expansion-71a57f1a-3380-49a2-b704-49c779b4c916" in namespace "var-expansion-3290"
  I0904 18:38:37.980893 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-71a57f1a-3380-49a2-b704-49c779b4c916" to be fully deleted
  E0904 18:38:38.094037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:39.094128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:39.990519 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3290" for this suite. @ 09/04/24 18:38:39.994
• [4.418 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1723
  STEP: Creating a kubernetes client @ 09/04/24 18:38:40
  I0904 18:38:40.000676 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 18:38:40.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:40.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:40.022
  I0904 18:38:40.025635 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5808 version'
  I0904 18:38:40.061374 19 builder.go:146] stderr: ""
  I0904 18:38:40.061401 19 builder.go:147] stdout: "Client Version: v1.31.0\nKustomize Version: v5.4.2\nServer Version: v1.31.0\n"
  I0904 18:38:40.061612 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5808" for this suite. @ 09/04/24 18:38:40.065
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 09/04/24 18:38:40.074
  I0904 18:38:40.074013 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename runtimeclass @ 09/04/24 18:38:40.074
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:40.091
  E0904 18:38:40.100706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:40.102
  STEP: Deleting RuntimeClass runtimeclass-1358-delete-me @ 09/04/24 18:38:40.112
  STEP: Waiting for the RuntimeClass to disappear @ 09/04/24 18:38:40.117
  I0904 18:38:40.126978 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1358" for this suite. @ 09/04/24 18:38:40.13
• [0.063 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:111
  STEP: Creating a kubernetes client @ 09/04/24 18:38:40.136
  I0904 18:38:40.136733 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename disruption @ 09/04/24 18:38:40.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:40.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:40.156
  STEP: creating the pdb @ 09/04/24 18:38:40.159
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:38:40.165
  E0904 18:38:41.101439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:42.101623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 09/04/24 18:38:42.17
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:38:42.178
  E0904 18:38:43.101716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:44.102679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 09/04/24 18:38:44.185
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:38:44.195
  E0904 18:38:45.102785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:46.102880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 09/04/24 18:38:46.207
  I0904 18:38:46.212050 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9628" for this suite. @ 09/04/24 18:38:46.215
• [6.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:429
  STEP: Creating a kubernetes client @ 09/04/24 18:38:46.222
  I0904 18:38:46.222110 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pv @ 09/04/24 18:38:46.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:46.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:46.243
  STEP: Creating initial PV and PVC @ 09/04/24 18:38:46.246
  I0904 18:38:46.246528 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-6293" @ 09/04/24 18:38:46.26
  STEP: Listing PVCs in namespace "pv-6293" @ 09/04/24 18:38:46.262
  STEP: Patching the PV "pv-6293-ccjks" @ 09/04/24 18:38:46.266
  STEP: Patching the PVC "pvc-6qgk6" @ 09/04/24 18:38:46.276
  STEP: Getting PV "pv-6293-ccjks" @ 09/04/24 18:38:46.282
  STEP: Getting PVC "pvc-6qgk6" @ 09/04/24 18:38:46.285
  STEP: Deleting PVC "pvc-6qgk6" @ 09/04/24 18:38:46.289
  STEP: Confirm deletion of PVC "pvc-6qgk6" @ 09/04/24 18:38:46.297
  E0904 18:38:47.102976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:48.103055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-6293-ccjks" @ 09/04/24 18:38:48.307
  STEP: Confirm deletion of PV "pv-6293-ccjks" @ 09/04/24 18:38:48.314
  E0904 18:38:49.103158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:50.103350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 09/04/24 18:38:50.321
  I0904 18:38:50.321975 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-6293-thrwk" @ 09/04/24 18:38:50.335
  STEP: Updating the PVC "pvc-hbgvt" @ 09/04/24 18:38:50.369
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-hbgvt=updated" @ 09/04/24 18:38:50.377
  STEP: Deleting PVC "pvc-hbgvt" via DeleteCollection @ 09/04/24 18:38:50.38
  STEP: Confirm deletion of PVC "pvc-hbgvt" @ 09/04/24 18:38:50.388
  E0904 18:38:51.103509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:52.103718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-6293-thrwk" via DeleteCollection @ 09/04/24 18:38:52.396
  STEP: Confirm deletion of PV "pv-6293-thrwk" @ 09/04/24 18:38:52.405
  E0904 18:38:53.104039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:54.104134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:38:54.412913 19 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0904 18:38:54.412942 19 pv.go:205] Deleting PersistentVolumeClaim "pvc-hbgvt"
  I0904 18:38:54.416022 19 pv.go:193] Deleting PersistentVolume "pv-6293-thrwk"
  I0904 18:38:54.419371 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-6293" for this suite. @ 09/04/24 18:38:54.423
• [8.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 09/04/24 18:38:54.429
  I0904 18:38:54.429946 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:38:54.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:54.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:54.45
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:38:54.453
  E0904 18:38:55.104241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:56.104572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:57.104687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:38:58.105024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:38:58.478
  I0904 18:38:58.481668 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-f882a024-961a-425c-ab4d-a5504245a5f8 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:38:58.49
  I0904 18:38:58.505826 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3068" for this suite. @ 09/04/24 18:38:58.509
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 09/04/24 18:38:58.515
  I0904 18:38:58.515491 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename security-context-test @ 09/04/24 18:38:58.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:38:58.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:38:58.537
  E0904 18:38:59.105618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:00.105711      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:01.106623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:02.107702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:39:02.567805 19 security_context.go:538] Got logs for pod "busybox-privileged-false-80062544-3ec8-4967-8183-57075b3c067b": "ip: RTNETLINK answers: Operation not permitted\n"
  I0904 18:39:02.568039 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7801" for this suite. @ 09/04/24 18:39:02.572
• [4.064 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 09/04/24 18:39:02.579
  I0904 18:39:02.579662 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubelet-test @ 09/04/24 18:39:02.58
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:39:02.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:39:02.6
  STEP: Waiting for pod completion @ 09/04/24 18:39:02.611
  E0904 18:39:03.108398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:04.108485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:05.109099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:06.109193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:39:06.630708 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2290" for this suite. @ 09/04/24 18:39:06.634
• [4.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 09/04/24 18:39:06.641
  I0904 18:39:06.641337 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename lease-test @ 09/04/24 18:39:06.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:39:06.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:39:06.663
  I0904 18:39:06.720650 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-225" for this suite. @ 09/04/24 18:39:06.724
• [0.090 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 09/04/24 18:39:06.731
  I0904 18:39:06.731054 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename var-expansion @ 09/04/24 18:39:06.731
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:39:06.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:39:06.751
  STEP: creating the pod @ 09/04/24 18:39:06.757
  STEP: waiting for pod running @ 09/04/24 18:39:06.774
  E0904 18:39:07.110051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:08.111081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 09/04/24 18:39:08.783
  I0904 18:39:08.786565 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-1555 PodName:var-expansion-8c887f45-8d9f-44ee-b98c-7e44eb0668db ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:39:08.786589 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:39:08.787010 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:39:08.787084 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-1555/pods/var-expansion-8c887f45-8d9f-44ee-b98c-7e44eb0668db/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 09/04/24 18:39:08.84
  I0904 18:39:08.844952 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-1555 PodName:var-expansion-8c887f45-8d9f-44ee-b98c-7e44eb0668db ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:39:08.844978 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:39:08.845393 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:39:08.845495 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-1555/pods/var-expansion-8c887f45-8d9f-44ee-b98c-7e44eb0668db/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 09/04/24 18:39:08.903
  E0904 18:39:09.111277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:39:09.416753 19 pod_client.go:173] Successfully updated pod "var-expansion-8c887f45-8d9f-44ee-b98c-7e44eb0668db"
  STEP: waiting for annotated pod running @ 09/04/24 18:39:09.416
  STEP: deleting the pod gracefully @ 09/04/24 18:39:09.42
  I0904 18:39:09.420696 19 delete.go:62] Deleting pod "var-expansion-8c887f45-8d9f-44ee-b98c-7e44eb0668db" in namespace "var-expansion-1555"
  I0904 18:39:09.428593 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-8c887f45-8d9f-44ee-b98c-7e44eb0668db" to be fully deleted
  E0904 18:39:10.111974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:11.112076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:12.112183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:13.112296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:14.112390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:15.112507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:16.112640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:17.113615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:18.114212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:19.114496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:20.114679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:21.114973      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:22.115795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:23.116137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:24.116284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:25.116399      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:26.117476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:27.117552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:28.118563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:29.118780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:30.118871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:31.119079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:32.120152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:33.121093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:34.121608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:35.121715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:36.122595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:37.122697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:38.122791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:39.123503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:40.123618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:41.123757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:39:41.514970 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1555" for this suite. @ 09/04/24 18:39:41.519
• [34.795 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 09/04/24 18:39:41.525
  I0904 18:39:41.525945 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 18:39:41.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:39:41.544
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:39:41.547
  E0904 18:39:42.124440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:43.124520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:44.124592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:45.124695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:46.124799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:47.124931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:39:47.603
  I0904 18:39:47.606689 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod client-envvars-9553e108-9ac4-44b7-8cbe-bc7f2c6b5a0b container env3cont: <nil>
  STEP: delete the pod @ 09/04/24 18:39:47.612
  I0904 18:39:47.628992 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-209" for this suite. @ 09/04/24 18:39:47.632
• [6.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:712
  STEP: Creating a kubernetes client @ 09/04/24 18:39:47.638
  I0904 18:39:47.638449 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:39:47.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:39:47.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:39:47.66
  STEP: Setting up server cert @ 09/04/24 18:39:47.686
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:39:48.073
  STEP: Deploying the webhook pod @ 09/04/24 18:39:48.082
  STEP: Wait for the deployment to be ready @ 09/04/24 18:39:48.093
  I0904 18:39:48.100469 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 18:39:48.125538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:49.125651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 18:39:50.113
  E0904 18:39:50.126567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:39:50.127
  E0904 18:39:51.126735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:39:51.127886 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 09/04/24 18:39:51.136
  STEP: verifying the validating webhook match conditions @ 09/04/24 18:39:51.143
  STEP: updating the validating webhook match conditions @ 09/04/24 18:39:51.146
  STEP: verifying the validating webhook match conditions @ 09/04/24 18:39:51.154
  I0904 18:39:51.196380 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5092" for this suite. @ 09/04/24 18:39:51.199
  STEP: Destroying namespace "webhook-markers-8275" for this suite. @ 09/04/24 18:39:51.208
• [3.576 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 09/04/24 18:39:51.214
  I0904 18:39:51.214491 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:39:51.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:39:51.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:39:51.234
  STEP: Creating configMap with name configmap-test-volume-a653a60e-9aac-45b4-b445-56eca65f02d7 @ 09/04/24 18:39:51.237
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:39:51.243
  E0904 18:39:52.126839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:53.127089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:54.127262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:55.127542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:39:55.265
  I0904 18:39:55.268804 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-d2cf7e2c-8d5b-4440-9376-2f1b9995c2da container configmap-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 18:39:55.274
  I0904 18:39:55.290151 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3692" for this suite. @ 09/04/24 18:39:55.294
• [4.085 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 09/04/24 18:39:55.299
  I0904 18:39:55.299769 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:39:55.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:39:55.316
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:39:55.319
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:39:55.323
  E0904 18:39:56.127595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:57.127753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:39:57.339
  I0904 18:39:57.342789 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-a4e455ba-6acd-4269-b8f7-c2fbc92d9813 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:39:57.348
  I0904 18:39:57.363891 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9145" for this suite. @ 09/04/24 18:39:57.366
• [2.073 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2194
  STEP: Creating a kubernetes client @ 09/04/24 18:39:57.372
  I0904 18:39:57.372660 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:39:57.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:39:57.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:39:57.393
  STEP: creating service in namespace services-8151 @ 09/04/24 18:39:57.396
  STEP: creating service affinity-nodeport in namespace services-8151 @ 09/04/24 18:39:57.396
  STEP: creating replication controller affinity-nodeport in namespace services-8151 @ 09/04/24 18:39:57.407
  I0904 18:39:57.414782      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-8151, replica count: 3
  E0904 18:39:58.128438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:39:59.129280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:00.130080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:00.465597      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 18:40:00.476469 19 resource.go:361] Creating new exec pod
  E0904 18:40:01.130751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:02.130854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:03.130921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:03.497583 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-8151 exec execpod-affinitytrsd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0904 18:40:03.593355 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  I0904 18:40:03.593398 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:40:03.593485 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-8151 exec execpod-affinitytrsd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.59 80'
  I0904 18:40:03.684084 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.59 80\n+ echo hostName\nConnection to 10.152.183.59 80 port [tcp/http] succeeded!\n"
  I0904 18:40:03.684137 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:40:03.684302 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-8151 exec execpod-affinitytrsd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.21.169 30464'
  I0904 18:40:03.768842 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.21.169 30464\nConnection to 172.31.21.169 30464 port [tcp/*] succeeded!\n"
  I0904 18:40:03.768893 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:40:03.768993 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-8151 exec execpod-affinitytrsd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.223 30464'
  I0904 18:40:03.850015 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.7.223 30464\n+ echo hostName\nConnection to 172.31.7.223 30464 port [tcp/*] succeeded!\n"
  I0904 18:40:03.850069 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:40:03.850129 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-8151 exec execpod-affinitytrsd5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.21.169:30464/ ; done'
  I0904 18:40:03.994221 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.21.169:30464/\n"
  I0904 18:40:03.994272 19 builder.go:147] stdout: "\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh\naffinity-nodeport-mkcvh"
  I0904 18:40:03.994285 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994293 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994299 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994304 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994310 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994314 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994334 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994339 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994345 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994352 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994369 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994378 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994383 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994388 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994410 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994415 19 service.go:242] Received response from host: affinity-nodeport-mkcvh
  I0904 18:40:03.994499 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-8151, will wait for the garbage collector to delete the pods @ 09/04/24 18:40:04.008
  I0904 18:40:04.069314 19 resources.go:139] Deleting ReplicationController affinity-nodeport took: 7.612386ms
  E0904 18:40:04.132017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:04.170221 19 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 100.900816ms
  E0904 18:40:05.132397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:06.132739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:07.133816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:07.187844 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8151" for this suite. @ 09/04/24 18:40:07.191
• [9.825 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 09/04/24 18:40:07.197
  I0904 18:40:07.197530 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:40:07.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:07.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:07.22
  STEP: Creating configMap with name projected-configmap-test-volume-6c323edb-c1c0-49a4-9d05-3e2dacc5b295 @ 09/04/24 18:40:07.223
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:40:07.228
  E0904 18:40:08.134666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:09.134752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:10.134851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:11.135047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:40:11.25
  I0904 18:40:11.254135 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-configmaps-e6d49c84-45c1-4f53-824a-636c64b93ca7 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 18:40:11.26
  I0904 18:40:11.276107 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3664" for this suite. @ 09/04/24 18:40:11.279
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 09/04/24 18:40:11.285
  I0904 18:40:11.285561 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:40:11.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:11.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:11.306
  STEP: Creating a pod to test downward api env vars @ 09/04/24 18:40:11.311
  E0904 18:40:12.135161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:13.135485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:14.135684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:15.135809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:40:15.332
  I0904 18:40:15.336304 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downward-api-e748d99a-8994-49d1-8723-75383324978b container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 18:40:15.342
  I0904 18:40:15.356274 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2904" for this suite. @ 09/04/24 18:40:15.359
• [4.082 seconds]
------------------------------
SSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 09/04/24 18:40:15.367
  I0904 18:40:15.367527 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename limitrange @ 09/04/24 18:40:15.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:15.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:15.387
  STEP: Creating a LimitRange @ 09/04/24 18:40:15.39
  STEP: Setting up watch @ 09/04/24 18:40:15.39
  STEP: Submitting a LimitRange @ 09/04/24 18:40:15.494
  STEP: Verifying LimitRange creation was observed @ 09/04/24 18:40:15.5
  STEP: Fetching the LimitRange to ensure it has proper values @ 09/04/24 18:40:15.5
  I0904 18:40:15.504130 19 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0904 18:40:15.504154 19 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 09/04/24 18:40:15.504
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 09/04/24 18:40:15.509
  I0904 18:40:15.512228 19 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0904 18:40:15.512249 19 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 09/04/24 18:40:15.512
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 09/04/24 18:40:15.518
  I0904 18:40:15.521965 19 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0904 18:40:15.521987 19 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 09/04/24 18:40:15.522
  STEP: Failing to create a Pod with more than max resources @ 09/04/24 18:40:15.523
  STEP: Updating a LimitRange @ 09/04/24 18:40:15.525
  STEP: Verifying LimitRange updating is effective @ 09/04/24 18:40:15.532
  E0904 18:40:16.135913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:17.136125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 09/04/24 18:40:17.538
  STEP: Failing to create a Pod with more than max resources @ 09/04/24 18:40:17.543
  STEP: Deleting a LimitRange @ 09/04/24 18:40:17.545
  STEP: Verifying the LimitRange was deleted @ 09/04/24 18:40:17.553
  E0904 18:40:18.136892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:19.137010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:20.137123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:21.137195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:22.137321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:22.559514 19 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 09/04/24 18:40:22.559
  I0904 18:40:22.567941 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-8628" for this suite. @ 09/04/24 18:40:22.572
• [7.211 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1075
  STEP: Creating a kubernetes client @ 09/04/24 18:40:22.579
  I0904 18:40:22.579174 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 18:40:22.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:22.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:22.6
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/04/24 18:40:22.603
  I0904 18:40:22.603672 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-421 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0904 18:40:22.658128 19 builder.go:146] stderr: ""
  I0904 18:40:22.658157 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 09/04/24 18:40:22.658
  I0904 18:40:22.658218 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-421 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I0904 18:40:22.703878 19 builder.go:146] stderr: ""
  I0904 18:40:22.703907 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/04/24 18:40:22.703
  I0904 18:40:22.707409 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-421 delete pods e2e-test-httpd-pod'
  E0904 18:40:23.138060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:24.138157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:24.222308 19 builder.go:146] stderr: ""
  I0904 18:40:24.222349 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0904 18:40:24.222566 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-421" for this suite. @ 09/04/24 18:40:24.226
• [1.653 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2179
  STEP: Creating a kubernetes client @ 09/04/24 18:40:24.233
  I0904 18:40:24.233062 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:40:24.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:24.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:24.251
  STEP: creating service in namespace services-6641 @ 09/04/24 18:40:24.255
  STEP: creating service affinity-clusterip-transition in namespace services-6641 @ 09/04/24 18:40:24.255
  STEP: creating replication controller affinity-clusterip-transition in namespace services-6641 @ 09/04/24 18:40:24.262
  I0904 18:40:24.268826      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-6641, replica count: 3
  E0904 18:40:25.138968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:26.139074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:27.139188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:27.319372      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 18:40:27.327535 19 resource.go:361] Creating new exec pod
  E0904 18:40:28.139355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:29.139558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:30.140168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:30.344663 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6641 exec execpod-affinity7d6t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I0904 18:40:30.436295 19 builder.go:146] stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  I0904 18:40:30.436337 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:40:30.436437 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6641 exec execpod-affinity7d6t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.71 80'
  I0904 18:40:30.514910 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.71 80\nConnection to 10.152.183.71 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0904 18:40:30.514960 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:40:30.525678 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6641 exec execpod-affinity7d6t5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.71:80/ ; done'
  I0904 18:40:30.661234 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n"
  I0904 18:40:30.661312 19 builder.go:147] stdout: "\naffinity-clusterip-transition-dmn59\naffinity-clusterip-transition-gwt2q\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-dmn59\naffinity-clusterip-transition-dmn59\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-dmn59\naffinity-clusterip-transition-dmn59\naffinity-clusterip-transition-dmn59\naffinity-clusterip-transition-gwt2q\naffinity-clusterip-transition-dmn59\naffinity-clusterip-transition-gwt2q\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-gwt2q\naffinity-clusterip-transition-dmn59\naffinity-clusterip-transition-dmn59"
  I0904 18:40:30.661324 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.661332 19 service.go:242] Received response from host: affinity-clusterip-transition-gwt2q
  I0904 18:40:30.661338 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.661343 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.661348 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.661353 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.661360 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.661365 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.661371 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.661378 19 service.go:242] Received response from host: affinity-clusterip-transition-gwt2q
  I0904 18:40:30.661384 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.661390 19 service.go:242] Received response from host: affinity-clusterip-transition-gwt2q
  I0904 18:40:30.661394 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.661399 19 service.go:242] Received response from host: affinity-clusterip-transition-gwt2q
  I0904 18:40:30.661405 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.661410 19 service.go:242] Received response from host: affinity-clusterip-transition-dmn59
  I0904 18:40:30.671092 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-6641 exec execpod-affinity7d6t5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.71:80/ ; done'
  I0904 18:40:30.829430 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.71:80/\n"
  I0904 18:40:30.829499 19 builder.go:147] stdout: "\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg\naffinity-clusterip-transition-xvrbg"
  I0904 18:40:30.829513 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829521 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829527 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829531 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829536 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829541 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829547 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829552 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829630 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829675 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829682 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829708 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829713 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829719 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829725 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829741 19 service.go:242] Received response from host: affinity-clusterip-transition-xvrbg
  I0904 18:40:30.829828 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-6641, will wait for the garbage collector to delete the pods @ 09/04/24 18:40:30.843
  I0904 18:40:31.008077 19 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 6.799464ms
  I0904 18:40:31.109185 19 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 101.101684ms
  E0904 18:40:31.140355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:32.140715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:33.141194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:34.141988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:34.325049 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6641" for this suite. @ 09/04/24 18:40:34.328
• [10.102 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:174
  STEP: Creating a kubernetes client @ 09/04/24 18:40:34.337
  I0904 18:40:34.337055 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-webhook @ 09/04/24 18:40:34.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:34.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:34.356
  STEP: Setting up server cert @ 09/04/24 18:40:34.359
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 09/04/24 18:40:34.467
  STEP: Deploying the custom resource conversion webhook pod @ 09/04/24 18:40:34.476
  STEP: Wait for the deployment to be ready @ 09/04/24 18:40:34.49
  I0904 18:40:34.496462 19 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0904 18:40:35.142109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:36.142902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 18:40:36.51
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:40:36.519
  E0904 18:40:37.143895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:37.520309 19 util.go:420] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0904 18:40:37.529134 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 18:40:38.144831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:39.144954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 09/04/24 18:40:40.078
  STEP: Create a v2 custom resource @ 09/04/24 18:40:40.093
  STEP: List CRs in v1 @ 09/04/24 18:40:40.119
  STEP: List CRs in v2 @ 09/04/24 18:40:40.124
  E0904 18:40:40.145615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:40.677818 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-7898" for this suite. @ 09/04/24 18:40:40.682
• [6.353 seconds]
------------------------------
S
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:907
  STEP: Creating a kubernetes client @ 09/04/24 18:40:40.69
  I0904 18:40:40.690126 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename job @ 09/04/24 18:40:40.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:40.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:40.71
  STEP: Creating a job @ 09/04/24 18:40:40.713
  STEP: Ensuring active pods == parallelism @ 09/04/24 18:40:40.719
  E0904 18:40:41.146131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:42.146191      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 09/04/24 18:40:42.725
  E0904 18:40:43.147153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:43.241096 19 pod_client.go:173] Successfully updated pod "adopt-release-8vmn9"
  STEP: Checking that the Job readopts the Pod @ 09/04/24 18:40:43.241
  E0904 18:40:44.147283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:45.147490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 09/04/24 18:40:45.249
  I0904 18:40:45.759563 19 pod_client.go:173] Successfully updated pod "adopt-release-8vmn9"
  STEP: Checking that the Job releases the Pod @ 09/04/24 18:40:45.759
  E0904 18:40:46.147597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:47.148323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:40:47.769857 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5509" for this suite. @ 09/04/24 18:40:47.773
• [7.089 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 09/04/24 18:40:47.779
  I0904 18:40:47.779561 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:40:47.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:47.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:47.798
  STEP: Creating secret with name projected-secret-test-6164664d-98d1-4684-86d2-687ca9896822 @ 09/04/24 18:40:47.801
  STEP: Creating a pod to test consume secrets @ 09/04/24 18:40:47.813
  E0904 18:40:48.148804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:49.149607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:50.150355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:51.150443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:40:51.834
  I0904 18:40:51.838971 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-projected-secrets-1aa79db5-51ae-46af-b461-9698ef71a973 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 18:40:51.846
  I0904 18:40:51.862619 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2897" for this suite. @ 09/04/24 18:40:51.866
• [4.093 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:644
  STEP: Creating a kubernetes client @ 09/04/24 18:40:51.872
  I0904 18:40:51.872199 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename statefulset @ 09/04/24 18:40:51.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:40:51.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:40:51.894
  STEP: Creating service test in namespace statefulset-3372 @ 09/04/24 18:40:51.897
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 09/04/24 18:40:51.902
  STEP: Creating stateful set ss in namespace statefulset-3372 @ 09/04/24 18:40:51.905
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3372 @ 09/04/24 18:40:51.91
  I0904 18:40:51.914287 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E0904 18:40:52.151526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:53.151734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:54.151836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:55.151899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:56.152145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:57.152256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:58.152319      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:40:59.152487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:00.152618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:01.153679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:01.917032 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 09/04/24 18:41:01.917
  I0904 18:41:01.921231 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-3372 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 18:41:02.010315 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 18:41:02.010357 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 18:41:02.010366 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 18:41:02.015159 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0904 18:41:02.154363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:03.155160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:04.155268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:05.156151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:06.156240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:07.157186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:08.158224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:09.158725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:10.159018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:11.159221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:12.016553 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0904 18:41:12.016594 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0904 18:41:12.033142 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 9.999999825s
  E0904 18:41:12.159366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:13.038391 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 8.996997043s
  E0904 18:41:13.159585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:14.043554 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 7.991715764s
  E0904 18:41:14.159695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:15.047935 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 6.98659653s
  E0904 18:41:15.160361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:16.053107 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 5.982183635s
  E0904 18:41:16.161302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:17.058370 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 4.97708206s
  E0904 18:41:17.161598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:18.063636 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 3.971545177s
  E0904 18:41:18.161815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:19.068757 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 2.966347039s
  E0904 18:41:19.161872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:20.074632 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 1.960444306s
  E0904 18:41:20.162839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:21.079207 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 955.427289ms
  E0904 18:41:21.163392      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3372 @ 09/04/24 18:41:22.08
  I0904 18:41:22.085771 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-3372 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0904 18:41:22.164169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:22.175329 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0904 18:41:22.175359 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 18:41:22.175368 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0904 18:41:22.179777 19 wait.go:40] Found 1 stateful pods, waiting for 3
  E0904 18:41:23.164242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:24.164332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:25.164427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:26.164533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:27.164667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:28.164784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:29.164958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:30.165213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:31.165261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:32.165495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:32.180961 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0904 18:41:32.180986 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0904 18:41:32.180994 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 09/04/24 18:41:32.181
  STEP: Scale down will halt with unhealthy stateful pod @ 09/04/24 18:41:32.181
  I0904 18:41:32.188251 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-3372 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 18:41:32.282996 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 18:41:32.283023 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 18:41:32.283040 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 18:41:32.283076 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-3372 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 18:41:32.369073 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 18:41:32.369110 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 18:41:32.369118 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 18:41:32.369159 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-3372 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 18:41:32.475672 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 18:41:32.475723 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 18:41:32.475732 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 18:41:32.475739 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0904 18:41:32.480439 19 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0904 18:41:33.166502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:34.166590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:35.166682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:36.166876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:37.166990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:38.167238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:39.167340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:40.167647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:41.167861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:42.168160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:42.485543 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0904 18:41:42.485577 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0904 18:41:42.485583 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0904 18:41:42.497272 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 9.999999841s
  E0904 18:41:43.169151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:43.502326 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 8.996958572s
  E0904 18:41:44.170111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:44.507115 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 7.99199678s
  E0904 18:41:45.170763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:45.511778 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 6.98726562s
  E0904 18:41:46.171419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:46.517118 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 5.982504323s
  E0904 18:41:47.171524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:47.522974 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 4.976380312s
  E0904 18:41:48.171656      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:48.527387 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 3.971292505s
  E0904 18:41:49.172052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:49.532555 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 2.966927294s
  E0904 18:41:50.172147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:50.538373 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 1.96081194s
  E0904 18:41:51.173118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:41:51.542997 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 955.888108ms
  E0904 18:41:52.173619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3372 @ 09/04/24 18:41:52.543
  I0904 18:41:52.548003 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-3372 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0904 18:41:52.651265 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0904 18:41:52.651313 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 18:41:52.651323 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0904 18:41:52.651365 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-3372 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0904 18:41:52.742462 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0904 18:41:52.742505 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 18:41:52.742517 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0904 18:41:52.742562 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-3372 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0904 18:41:52.840847 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0904 18:41:52.840887 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 18:41:52.840897 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0904 18:41:52.840906 19 rest.go:150] Scaling statefulset ss to 0
  E0904 18:41:53.174480      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:54.174585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:55.174967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:56.175247      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:57.175435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:58.175566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:41:59.175811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:00.175991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:01.176169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:02.176303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 09/04/24 18:42:02.851
  I0904 18:42:02.851894 19 statefulset.go:138] Deleting all statefulset in ns statefulset-3372
  I0904 18:42:02.855218 19 rest.go:150] Scaling statefulset ss to 0
  I0904 18:42:02.862284 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0904 18:42:02.865812 19 rest.go:88] Deleting statefulset ss
  I0904 18:42:02.878539 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3372" for this suite. @ 09/04/24 18:42:02.881
• [71.015 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 09/04/24 18:42:02.888
  I0904 18:42:02.888844 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename subpath @ 09/04/24 18:42:02.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:42:02.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:42:02.906
  STEP: Setting up data @ 09/04/24 18:42:02.909
  STEP: Creating pod pod-subpath-test-projected-jsw7 @ 09/04/24 18:42:02.917
  STEP: Creating a pod to test atomic-volume-subpath @ 09/04/24 18:42:02.917
  E0904 18:42:03.176357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:04.176445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:05.176994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:06.177149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:07.177235      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:08.177489      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:09.178165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:10.178693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:11.179296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:12.179379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:13.180289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:14.180375      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:15.180463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:16.181364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:17.181539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:18.182487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:19.182594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:20.182705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:21.182764      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:22.182936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:23.183547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:24.183746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:25.183842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:26.184023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:42:26.989
  I0904 18:42:26.992635 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-subpath-test-projected-jsw7 container test-container-subpath-projected-jsw7: <nil>
  STEP: delete the pod @ 09/04/24 18:42:27.011
  STEP: Deleting pod pod-subpath-test-projected-jsw7 @ 09/04/24 18:42:27.029
  I0904 18:42:27.029526 19 delete.go:62] Deleting pod "pod-subpath-test-projected-jsw7" in namespace "subpath-3716"
  I0904 18:42:27.033005 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3716" for this suite. @ 09/04/24 18:42:27.036
• [24.155 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:905
  STEP: Creating a kubernetes client @ 09/04/24 18:42:27.044
  I0904 18:42:27.044183 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename statefulset @ 09/04/24 18:42:27.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:42:27.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:42:27.063
  STEP: Creating service test in namespace statefulset-4021 @ 09/04/24 18:42:27.066
  STEP: Creating statefulset ss in namespace statefulset-4021 @ 09/04/24 18:42:27.07
  I0904 18:42:27.081969 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E0904 18:42:27.184229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:28.184323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:29.184533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:30.184736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:31.184825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:32.185050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:33.185136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:34.185276      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:35.185389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:36.185450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:42:37.084177 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 09/04/24 18:42:37.091
  STEP: updating a scale subresource @ 09/04/24 18:42:37.095
  STEP: verifying the statefulset Spec.Replicas was modified @ 09/04/24 18:42:37.102
  STEP: Patch a scale subresource @ 09/04/24 18:42:37.106
  E0904 18:42:37.185528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the statefulset Spec.Replicas was modified @ 09/04/24 18:42:37.222
  I0904 18:42:37.227221 19 statefulset.go:138] Deleting all statefulset in ns statefulset-4021
  I0904 18:42:37.230540 19 rest.go:150] Scaling statefulset ss to 0
  E0904 18:42:38.185622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:39.185705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:40.186676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:41.186784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:42.186908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:43.187130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:44.187281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:45.187415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:46.187502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:47.187692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:42:47.246490 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0904 18:42:47.249644 19 rest.go:88] Deleting statefulset ss
  I0904 18:42:47.262392 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4021" for this suite. @ 09/04/24 18:42:47.265
• [20.230 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 09/04/24 18:42:47.274
  I0904 18:42:47.274611 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename var-expansion @ 09/04/24 18:42:47.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:42:47.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:42:47.298
  STEP: creating the pod with failed condition @ 09/04/24 18:42:47.301
  E0904 18:42:48.187829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:49.187953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:50.188389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:51.188469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:52.189437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:53.189620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:54.189806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:55.190687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:56.190808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:57.191014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:58.191248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:42:59.191360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:00.191446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:01.191661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:02.191693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:03.191774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:04.191884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:05.192090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:06.193021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:07.193117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:08.193798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:09.193965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:10.193992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:11.194673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:12.195482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:13.195831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:14.195928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:15.196046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:16.196182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:17.196378      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:18.197083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:19.197170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:20.197661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:21.197758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:22.198660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:23.198809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:24.198923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:25.199018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:26.199523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:27.200533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:28.200638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:29.200736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:30.201695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:31.201792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:32.202700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:33.202777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:34.203783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:35.203902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:36.204004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:37.204125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:38.204826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:39.204933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:40.205945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:41.206020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:42.206125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:43.206230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:44.206337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:45.206441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:46.206553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:47.206649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:48.207032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:49.207145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:50.207242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:51.207358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:52.207920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:53.208055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:54.208182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:55.208486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:56.209528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:57.209612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:58.209706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:43:59.210647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:00.211604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:01.211739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:02.211847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:03.211906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:04.212050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:05.212225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:06.212359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:07.212465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:08.212778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:09.212751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:10.212798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:11.213015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:12.213599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:13.213699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:14.213801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:15.213871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:16.213970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:17.214693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:18.215391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:19.215580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:20.215676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:21.215865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:22.215967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:23.216197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:24.216308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:25.216504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:26.216584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:27.216783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:28.217530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:29.217632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:30.218539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:31.218753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:32.219369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:33.219650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:34.220261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:35.221065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:36.221581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:37.221688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:38.221776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:39.221872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:40.222671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:41.222855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:42.222946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:43.223181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:44.223273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:45.223446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:46.223560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:47.223740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating the pod @ 09/04/24 18:44:47.31
  I0904 18:44:47.824386 19 pod_client.go:173] Successfully updated pod "var-expansion-16677c0c-42a5-4ac1-ab55-5d451d14ee4e"
  STEP: waiting for pod running @ 09/04/24 18:44:47.824
  E0904 18:44:48.223842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:49.223956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 09/04/24 18:44:49.832
  I0904 18:44:49.832416 19 delete.go:62] Deleting pod "var-expansion-16677c0c-42a5-4ac1-ab55-5d451d14ee4e" in namespace "var-expansion-1371"
  I0904 18:44:49.840575 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-16677c0c-42a5-4ac1-ab55-5d451d14ee4e" to be fully deleted
  E0904 18:44:50.224706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:51.224935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:52.225061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:53.225171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:54.225251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:55.225364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:56.225623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:57.225720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:58.226688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:44:59.226787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:00.227633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:01.227976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:02.228087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:03.228206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:04.228292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:05.228410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:06.229105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:07.229267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:08.229367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:09.229476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:10.230216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:11.230303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:12.231207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:13.232206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:14.232995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:15.233098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:16.233909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:17.234698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:18.235391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:19.235601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:20.236534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:21.236639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:21.925310 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1371" for this suite. @ 09/04/24 18:45:21.929
• [154.661 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 09/04/24 18:45:21.936
  I0904 18:45:21.936468 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 18:45:21.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:45:21.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:45:21.958
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 09/04/24 18:45:21.961
  I0904 18:45:21.961695 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 18:45:22.237062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:23.186945 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 18:45:23.237761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:24.238064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:25.239079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:26.239745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:27.239942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:28.130212 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4423" for this suite. @ 09/04/24 18:45:28.138
• [6.211 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:116
  STEP: Creating a kubernetes client @ 09/04/24 18:45:28.147
  I0904 18:45:28.148006 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:45:28.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:45:28.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:45:28.164
  STEP: Setting up server cert @ 09/04/24 18:45:28.188
  E0904 18:45:28.240968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:45:28.432
  STEP: Deploying the webhook pod @ 09/04/24 18:45:28.441
  STEP: Wait for the deployment to be ready @ 09/04/24 18:45:28.455
  I0904 18:45:28.463234 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 18:45:29.241019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:30.241296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 18:45:30.475
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:45:30.487
  E0904 18:45:31.241419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:31.487843 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 09/04/24 18:45:31.497
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 09/04/24 18:45:31.499
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 09/04/24 18:45:31.499
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 09/04/24 18:45:31.499
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 09/04/24 18:45:31.5
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 09/04/24 18:45:31.5
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 09/04/24 18:45:31.501
  I0904 18:45:31.537771 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3426" for this suite. @ 09/04/24 18:45:31.541
  STEP: Destroying namespace "webhook-markers-8782" for this suite. @ 09/04/24 18:45:31.549
• [3.411 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:207
  STEP: Creating a kubernetes client @ 09/04/24 18:45:31.559
  I0904 18:45:31.559508 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:45:31.56
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:45:31.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:45:31.576
  STEP: Setting up server cert @ 09/04/24 18:45:31.599
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:45:31.729
  STEP: Deploying the webhook pod @ 09/04/24 18:45:31.735
  STEP: Wait for the deployment to be ready @ 09/04/24 18:45:31.746
  I0904 18:45:31.756637 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 18:45:32.242259      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:33.243255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 18:45:33.767
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:45:33.776
  E0904 18:45:34.243850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:34.777513 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 09/04/24 18:45:34.786
  STEP: create a pod @ 09/04/24 18:45:34.8
  E0904 18:45:35.244059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:36.244200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 09/04/24 18:45:36.818
  I0904 18:45:36.818217 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=webhook-4477 attach --namespace=webhook-4477 to-be-attached-pod -i -c=container1'
  I0904 18:45:36.873123 19 builder.go:135] rc: 1
  I0904 18:45:36.923188 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4477" for this suite. @ 09/04/24 18:45:36.927
  STEP: Destroying namespace "webhook-markers-5395" for this suite. @ 09/04/24 18:45:36.937
• [5.383 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 09/04/24 18:45:36.942
  I0904 18:45:36.942862 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename deployment @ 09/04/24 18:45:36.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:45:36.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:45:36.964
  I0904 18:45:36.976106 19 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E0904 18:45:37.244560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:38.244666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:39.244797      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:40.244865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:41.245052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:41.983318 19 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/04/24 18:45:41.983
  I0904 18:45:41.983452 19 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0904 18:45:42.245759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:43.245814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:43.987943 19 deployment.go:921] Creating deployment "test-rollover-deployment"
  I0904 18:45:43.997816 19 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E0904 18:45:44.246710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:45.246835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:46.004710 19 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I0904 18:45:46.012223 19 deployment.go:943] Ensure that both replica sets have 1 created replica
  I0904 18:45:46.018800 19 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0904 18:45:46.027392 19 deployment.go:313] Updating deployment test-rollover-deployment
  I0904 18:45:46.027421 19 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0904 18:45:46.247776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:47.248003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:48.037340 19 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0904 18:45:48.043022 19 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I0904 18:45:48.049950 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0904 18:45:48.050007 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:45:48.248172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:49.248426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:50.059523 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0904 18:45:50.059577 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:45:50.248794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:51.248886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:52.058412 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0904 18:45:52.058478 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:45:52.249652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:53.250190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:54.059033 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0904 18:45:54.059107 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:45:54.251087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:55.252210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:56.064396 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0904 18:45:56.064462 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 45, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 45, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:45:56.252627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:45:57.252872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:45:58.059191 19 deployment.go:94] 
  I0904 18:45:58.059227 19 deployment.go:974] Ensure that both old replica sets have no replicas
  I0904 18:45:58.070663 19 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7382",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d90e5521-5d40-4708-9830-2d05adb2cd07",
      ResourceVersion: (string) (len=5) "24133",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861072343,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072357,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072344,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072344,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072357,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072344,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5f974d7468\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0904 18:45:58.078031 19 deployment.go:39] New ReplicaSet "test-rollover-deployment-5f974d7468" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5f974d7468",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7382",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "406345a4-4d3b-4319-9e04-d084d07e6e69",
      ResourceVersion: (string) (len=5) "24123",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861072346,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "d90e5521-5d40-4708-9830-2d05adb2cd07",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 39 30 65 35 35  32 31 2d 35 64 34 30 2d  |\"d90e5521-5d40-|
              00000120  34 37 30 38 2d 39 38 33  30 2d 32 64 30 35 61 64  |4708-9830-2d05ad|
              00000130  62 32 63 64 30 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b2cd07\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072357,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:45:58.078477 19 deployment.go:44] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0904 18:45:58.078657 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7382",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "97a95a4e-d708-4f6a-a341-e34226fe040a",
      ResourceVersion: (string) (len=5) "24132",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861072336,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "pod": (string) (len=5) "httpd",
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "d90e5521-5d40-4708-9830-2d05adb2cd07",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072357,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  64 39 30 65 35 35 32 31  2d 35 64 34 30 2d 34 37  |d90e5521-5d40-47|
              000000c0  30 38 2d 39 38 33 30 2d  32 64 30 35 61 64 62 32  |08-9830-2d05adb2|
              000000d0  63 64 30 37 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |cd07\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072357,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:45:58.079256 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-55f4dbffff",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7382",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3fb31d0d-2866-4a39-8268-c1da8184508d",
      ResourceVersion: (string) (len=5) "24083",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861072344,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "d90e5521-5d40-4708-9830-2d05adb2cd07",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 39 30 65 35 35  32 31 2d 35 64 34 30 2d  |\"d90e5521-5d40-|
              00000120  34 37 30 38 2d 39 38 33  30 2d 32 64 30 35 61 64  |4708-9830-2d05ad|
              00000130  62 32 63 64 30 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b2cd07\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 18:45:58.084118 19 deployment.go:67] Pod "test-rollover-deployment-5f974d7468-dmscr" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5f974d7468-dmscr",
      GenerateName: (string) (len=36) "test-rollover-deployment-5f974d7468-",
      Namespace: (string) (len=15) "deployment-7382",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e91f1ea0-c111-433e-bed3-8df7bbc0ee84",
      ResourceVersion: (string) (len=5) "24096",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861072346,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468",
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5f974d7468",
          UID: (types.UID) (len=36) "406345a4-4d3b-4319-9e04-d084d07e6e69",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 30  36 33 34 35 61 34 2d 34  |d\":\"406345a4-4|
              00000090  64 33 62 2d 34 33 31 39  2d 39 65 30 34 2d 64 30  |d3b-4319-9e04-d0|
              000000a0  38 34 64 30 37 65 36 65  36 39 5c 22 7d 22 3a 7b  |84d07e6e69\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072347,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 30  34 2e 31 37 34 5c 22 7d  |2.168.104.174\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rftmm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rftmm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072347,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072347,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072347,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861072346,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.40.239",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.40.239"
        }
      },
      PodIP: (string) (len=15) "192.168.104.174",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.104.174"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861072346,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861072346,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6",
          ContainerID: (string) (len=77) "containerd://efcb2f4f364dde56fe853bf3ba4c60806399c74bee7146d3cb727b4bac47f428",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-rftmm",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 18:45:58.085729 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7382" for this suite. @ 09/04/24 18:45:58.09
• [21.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 09/04/24 18:45:58.096
  I0904 18:45:58.096819 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename apf @ 09/04/24 18:45:58.097
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:45:58.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:45:58.115
  STEP: getting /apis @ 09/04/24 18:45:58.119
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 09/04/24 18:45:58.123
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 09/04/24 18:45:58.124
  STEP: creating @ 09/04/24 18:45:58.125
  STEP: getting @ 09/04/24 18:45:58.141
  STEP: listing @ 09/04/24 18:45:58.144
  STEP: watching @ 09/04/24 18:45:58.148
  I0904 18:45:58.148403 19 flowcontrol.go:620] starting watch
  STEP: patching @ 09/04/24 18:45:58.149
  STEP: updating @ 09/04/24 18:45:58.155
  I0904 18:45:58.164616 19 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 09/04/24 18:45:58.164
  STEP: patching /status @ 09/04/24 18:45:58.168
  STEP: updating /status @ 09/04/24 18:45:58.175
  STEP: deleting @ 09/04/24 18:45:58.184
  STEP: deleting a collection @ 09/04/24 18:45:58.195
  I0904 18:45:58.214783 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-2633" for this suite. @ 09/04/24 18:45:58.217
• [0.126 seconds]
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 09/04/24 18:45:58.223
  I0904 18:45:58.223435 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:45:58.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:45:58.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:45:58.243
  STEP: Creating configMap with name cm-test-opt-del-3a3b70ba-2c48-451c-b551-a637738766d0 @ 09/04/24 18:45:58.25
  E0904 18:45:58.253736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating configMap with name cm-test-opt-upd-f697c1a3-e195-4ad2-bfd8-c536bf6ed512 @ 09/04/24 18:45:58.255
  STEP: Creating the pod @ 09/04/24 18:45:58.26
  E0904 18:45:59.253910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:00.254663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-3a3b70ba-2c48-451c-b551-a637738766d0 @ 09/04/24 18:46:00.303
  STEP: Updating configmap cm-test-opt-upd-f697c1a3-e195-4ad2-bfd8-c536bf6ed512 @ 09/04/24 18:46:00.309
  STEP: Creating configMap with name cm-test-opt-create-1d62f303-7fe5-48bd-b49d-db2fd54c90ab @ 09/04/24 18:46:00.317
  STEP: waiting to observe update in volume @ 09/04/24 18:46:00.321
  E0904 18:46:01.254785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:02.254893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:03.255067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:04.255091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:05.255210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:06.255433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:07.255539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:08.255626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:09.255756      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:10.255871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:11.255987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:12.256206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:13.256231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:14.256444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:15.256587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:16.256804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:17.256903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:18.256956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:19.257066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:20.257272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:21.257503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:22.257643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:23.258703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:24.258793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:25.259592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:26.259740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:27.259939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:28.260239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:29.260625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:30.260748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:31.260837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:32.261038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:33.261148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:34.261363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:35.261632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:36.262691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:37.262773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:38.262888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:39.263074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:40.263177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:41.263292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:42.263384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:43.263489      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:44.263614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:45.264594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:46.264728      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:47.265310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:48.265382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:49.265503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:50.265589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:51.265721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:52.265820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:53.266664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:54.266869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:55.267568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:56.267715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:57.268557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:58.269448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:46:59.270363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:00.270738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:01.271158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:02.271362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:03.271563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:04.271661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:05.272356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:06.272556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:07.273583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:08.273632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:09.274520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:10.274736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:11.274838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:12.274938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:13.275042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:14.275147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:15.275259      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:16.275454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:17.276238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:18.276346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:19.277239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:20.277373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:21.277506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:22.277598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:23.278645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:24.278746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:47:24.697921 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5277" for this suite. @ 09/04/24 18:47:24.7
• [86.483 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 09/04/24 18:47:24.707
  I0904 18:47:24.707579 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename ingressclass @ 09/04/24 18:47:24.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:47:24.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:47:24.736
  STEP: getting /apis @ 09/04/24 18:47:24.774
  STEP: getting /apis/networking.k8s.io @ 09/04/24 18:47:24.778
  STEP: getting /apis/networking.k8s.iov1 @ 09/04/24 18:47:24.779
  STEP: creating @ 09/04/24 18:47:24.78
  STEP: getting @ 09/04/24 18:47:24.795
  STEP: listing @ 09/04/24 18:47:24.798
  STEP: watching @ 09/04/24 18:47:24.8
  I0904 18:47:24.800914 19 ingressclass.go:348] starting watch
  STEP: patching @ 09/04/24 18:47:24.802
  STEP: updating @ 09/04/24 18:47:24.807
  I0904 18:47:24.812178 19 ingressclass.go:364] waiting for watch events with expected annotations
  I0904 18:47:24.812222 19 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 09/04/24 18:47:24.812
  STEP: deleting a collection @ 09/04/24 18:47:24.823
  I0904 18:47:24.838195 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-9882" for this suite. @ 09/04/24 18:47:24.841
• [0.141 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 09/04/24 18:47:24.848
  I0904 18:47:24.848674 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:47:24.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:47:24.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:47:24.865
  I0904 18:47:24.902712 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7463" for this suite. @ 09/04/24 18:47:24.906
• [0.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:139
  STEP: Creating a kubernetes client @ 09/04/24 18:47:24.913
  I0904 18:47:24.913316 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-webhook @ 09/04/24 18:47:24.913
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:47:24.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:47:24.931
  STEP: Setting up server cert @ 09/04/24 18:47:24.935
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 09/04/24 18:47:25.128
  STEP: Deploying the custom resource conversion webhook pod @ 09/04/24 18:47:25.137
  STEP: Wait for the deployment to be ready @ 09/04/24 18:47:25.15
  I0904 18:47:25.161237 19 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0904 18:47:25.279394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:26.279509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 18:47:27.175
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:47:27.185
  E0904 18:47:27.279718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:47:28.186028 19 util.go:420] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0904 18:47:28.197297 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 18:47:28.279878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:29.280249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:30.281267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 09/04/24 18:47:30.75
  STEP: v2 custom resource should be converted @ 09/04/24 18:47:30.757
  E0904 18:47:31.281625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:47:31.317699 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-9256" for this suite. @ 09/04/24 18:47:31.323
• [6.418 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 09/04/24 18:47:31.331
  I0904 18:47:31.331979 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename deployment @ 09/04/24 18:47:31.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:47:31.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:47:31.362
  STEP: creating a Deployment @ 09/04/24 18:47:31.387
  STEP: waiting for Deployment to be created @ 09/04/24 18:47:31.395
  STEP: waiting for all Replicas to be Ready @ 09/04/24 18:47:31.401
  I0904 18:47:31.405903 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0904 18:47:31.405992 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0904 18:47:31.408414 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0904 18:47:31.408435 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0904 18:47:31.424987 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0904 18:47:31.425008 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0904 18:47:31.461993 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0904 18:47:31.462076 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0904 18:47:32.281777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:47:32.320255 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0904 18:47:32.320285 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0904 18:47:32.915267 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 09/04/24 18:47:32.915
  I0904 18:47:32.925109 19 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 09/04/24 18:47:32.925
  I0904 18:47:32.926777 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0
  I0904 18:47:32.926795 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0
  I0904 18:47:32.926810 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0
  I0904 18:47:32.926816 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0
  I0904 18:47:32.926823 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0
  I0904 18:47:32.926828 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0
  I0904 18:47:32.926848 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0
  I0904 18:47:32.926853 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 0
  I0904 18:47:32.926970 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:32.926983 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:32.926991 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:32.927001 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:32.927027 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:32.927033 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:32.935666 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:32.935769 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:32.961933 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:32.961953 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:32.971646 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:32.971697 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:32.983899 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:32.983918 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  E0904 18:47:33.282337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:47:33.934275 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:33.934306 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:33.959873 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  STEP: listing Deployments @ 09/04/24 18:47:33.959
  I0904 18:47:33.962866 19 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 09/04/24 18:47:33.962
  I0904 18:47:33.974404 19 deployment.go:360] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 09/04/24 18:47:33.974
  I0904 18:47:33.983188 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0904 18:47:33.985557 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0904 18:47:34.018472 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0904 18:47:34.031377 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0904 18:47:34.040130 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0904 18:47:34.282601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:47:34.936393 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0904 18:47:34.973756 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0904 18:47:34.985816 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0904 18:47:35.283253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:36.283427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:47:36.346523 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 09/04/24 18:47:36.369
  STEP: fetching the DeploymentStatus @ 09/04/24 18:47:36.376
  I0904 18:47:36.386007 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:36.386036 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:36.386043 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:36.386101 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:36.386110 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 1
  I0904 18:47:36.386117 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:36.386186 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:36.386193 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 2
  I0904 18:47:36.386200 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-3038 with ReadyReplicas 3
  STEP: deleting the Deployment @ 09/04/24 18:47:36.386
  I0904 18:47:36.398388 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.398878 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.398892 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399047 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399079 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399314 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399346 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399483 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399561 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399631 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399640 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.399686 19 deployment.go:475] observed event type MODIFIED
  I0904 18:47:36.402376 19 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I0904 18:47:36.407739 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3038" for this suite. @ 09/04/24 18:47:36.412
• [5.092 seconds]
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:115
  STEP: Creating a kubernetes client @ 09/04/24 18:47:36.423
  I0904 18:47:36.423993 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename field-validation @ 09/04/24 18:47:36.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:47:36.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:47:36.447
  STEP: apply creating a deployment @ 09/04/24 18:47:36.451
  I0904 18:47:36.473237 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8701" for this suite. @ 09/04/24 18:47:36.477
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 09/04/24 18:47:36.486
  I0904 18:47:36.486853 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-runtime @ 09/04/24 18:47:36.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:47:36.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:47:36.523
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 09/04/24 18:47:36.538
  E0904 18:47:37.283685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:38.283810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:39.284649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:40.284765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:41.284872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:42.285912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:43.286653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:44.286710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:45.286829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:46.286950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:47.287044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:48.287483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:49.288511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:50.289574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:51.290608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:52.291667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:53.291761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 09/04/24 18:47:53.63
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 09/04/24 18:47:53.634
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 09/04/24 18:47:53.641
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 09/04/24 18:47:53.641
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 09/04/24 18:47:53.661
  E0904 18:47:54.291851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:55.292861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:47:56.292967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 09/04/24 18:47:56.681
  E0904 18:47:57.293677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 09/04/24 18:47:57.691
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 09/04/24 18:47:57.698
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 09/04/24 18:47:57.698
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 09/04/24 18:47:57.72
  E0904 18:47:58.293776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 09/04/24 18:47:58.73
  E0904 18:47:59.294689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:00.294796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 09/04/24 18:48:00.744
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 09/04/24 18:48:00.751
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 09/04/24 18:48:00.751
  I0904 18:48:00.777658 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1673" for this suite. @ 09/04/24 18:48:00.781
• [24.303 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 09/04/24 18:48:00.789
  I0904 18:48:00.790005 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 18:48:00.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:00.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:00.812
  STEP: creating a secret @ 09/04/24 18:48:00.815
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 09/04/24 18:48:00.819
  STEP: patching the secret @ 09/04/24 18:48:00.823
  STEP: deleting the secret using a LabelSelector @ 09/04/24 18:48:00.831
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 09/04/24 18:48:00.838
  I0904 18:48:00.842217 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5290" for this suite. @ 09/04/24 18:48:00.846
• [0.063 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 09/04/24 18:48:00.853
  I0904 18:48:00.853177 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:48:00.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:00.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:00.874
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:48:00.877
  E0904 18:48:01.294968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:02.295134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:03.296072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:04.296192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:48:04.896
  I0904 18:48:04.901275 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-b5509089-6106-49bd-a3ef-5048e99b6c26 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:48:04.914
  I0904 18:48:04.931902 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8474" for this suite. @ 09/04/24 18:48:04.935
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 09/04/24 18:48:04.943
  I0904 18:48:04.943961 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 18:48:04.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:04.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:04.964
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 09/04/24 18:48:04.967
  E0904 18:48:05.296945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:06.297249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:07.297730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:08.297824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:48:08.986
  I0904 18:48:08.990926 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-c2b2a991-6728-4a6f-a58f-f697c927f87d container test-container: <nil>
  STEP: delete the pod @ 09/04/24 18:48:08.997
  I0904 18:48:09.013203 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7894" for this suite. @ 09/04/24 18:48:09.015
• [4.078 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 09/04/24 18:48:09.022
  I0904 18:48:09.022151 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename svcaccounts @ 09/04/24 18:48:09.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:09.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:09.039
  STEP: Creating a pod to test service account token:  @ 09/04/24 18:48:09.043
  E0904 18:48:09.298568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:10.298662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:11.298766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:12.298856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:48:13.067
  I0904 18:48:13.071604 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod test-pod-1b672091-f3b0-475c-8f33-5661edfe9c57 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:48:13.078
  I0904 18:48:13.098452 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1883" for this suite. @ 09/04/24 18:48:13.103
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 09/04/24 18:48:13.111
  I0904 18:48:13.111712 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:48:13.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:13.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:13.135
  STEP: Creating configMap with name projected-configmap-test-volume-340d62c0-6be2-466d-9c6a-8246e951fa01 @ 09/04/24 18:48:13.138
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:48:13.144
  E0904 18:48:13.299742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:14.299844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:15.300467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:16.300552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:48:17.167
  I0904 18:48:17.172092 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-configmaps-26603e4f-b031-46f3-bd4a-cc72b4586fe8 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:48:17.177
  I0904 18:48:17.196436 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7249" for this suite. @ 09/04/24 18:48:17.2
• [4.096 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 09/04/24 18:48:17.207
  I0904 18:48:17.207457 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename ingress @ 09/04/24 18:48:17.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:17.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:17.227
  STEP: getting /apis @ 09/04/24 18:48:17.23
  STEP: getting /apis/networking.k8s.io @ 09/04/24 18:48:17.233
  STEP: getting /apis/networking.k8s.iov1 @ 09/04/24 18:48:17.234
  STEP: creating @ 09/04/24 18:48:17.236
  STEP: getting @ 09/04/24 18:48:17.253
  E0904 18:48:17.300637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: listing @ 09/04/24 18:48:17.344
  STEP: watching @ 09/04/24 18:48:17.352
  I0904 18:48:17.352547 19 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 09/04/24 18:48:17.354
  STEP: cluster-wide watching @ 09/04/24 18:48:17.356
  I0904 18:48:17.356582 19 ingress.go:198] starting watch
  STEP: patching @ 09/04/24 18:48:17.357
  STEP: updating @ 09/04/24 18:48:17.362
  I0904 18:48:17.372319 19 ingress.go:221] waiting for watch events with expected annotations
  I0904 18:48:17.372347 19 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 09/04/24 18:48:17.372
  STEP: updating /status @ 09/04/24 18:48:17.378
  STEP: get /status @ 09/04/24 18:48:17.388
  STEP: deleting @ 09/04/24 18:48:17.398
  STEP: deleting a collection @ 09/04/24 18:48:17.413
  I0904 18:48:17.431308 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-4916" for this suite. @ 09/04/24 18:48:17.436
• [0.241 seconds]
------------------------------
SS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:668
  STEP: Creating a kubernetes client @ 09/04/24 18:48:17.448
  I0904 18:48:17.448859 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pv @ 09/04/24 18:48:17.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:17.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:17.472
  STEP: Creating initial PV and PVC @ 09/04/24 18:48:17.476
  I0904 18:48:17.476038 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-3550" @ 09/04/24 18:48:17.491
  STEP: Listing PVCs in namespace "pv-3550" @ 09/04/24 18:48:17.501
  STEP: Reading "pvc-jhgf6" Status @ 09/04/24 18:48:17.505
  STEP: Reading "pv-3550-zhvt8" Status @ 09/04/24 18:48:17.51
  STEP: Patching "pvc-jhgf6" Status @ 09/04/24 18:48:17.516
  STEP: Patching "pv-3550-zhvt8" Status @ 09/04/24 18:48:17.522
  STEP: Updating "pvc-jhgf6" Status @ 09/04/24 18:48:17.529
  STEP: Updating "pv-3550-zhvt8" Status @ 09/04/24 18:48:17.537
  I0904 18:48:17.547095 19 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0904 18:48:17.547115 19 pv.go:205] Deleting PersistentVolumeClaim "pvc-jhgf6"
  I0904 18:48:17.553964 19 pv.go:193] Deleting PersistentVolume "pv-3550-zhvt8"
  I0904 18:48:17.559350 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-3550" for this suite. @ 09/04/24 18:48:17.564
• [0.121 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 09/04/24 18:48:17.569
  I0904 18:48:17.569951 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename containers @ 09/04/24 18:48:17.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:17.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:17.591
  STEP: Creating a pod to test override arguments @ 09/04/24 18:48:17.594
  E0904 18:48:18.301772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:19.301895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:20.302651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:21.302761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:48:21.62
  I0904 18:48:21.625107 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod client-containers-118dfd37-7717-49d4-b7ec-0195fb5d1163 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:48:21.631
  I0904 18:48:21.648383 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6166" for this suite. @ 09/04/24 18:48:21.652
• [4.089 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:890
  STEP: Creating a kubernetes client @ 09/04/24 18:48:21.659
  I0904 18:48:21.659545 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename daemonsets @ 09/04/24 18:48:21.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:21.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:21.678
  STEP: Creating simple DaemonSet "daemon-set" @ 09/04/24 18:48:21.702
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/04/24 18:48:21.708
  I0904 18:48:21.712781 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:48:21.712852 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:48:21.716323 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:48:21.716341 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 18:48:22.303036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:48:22.713505 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:48:22.713549 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:48:22.717408 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0904 18:48:22.717425 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 18:48:23.304096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:48:23.713368 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:48:23.713412 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:48:23.717380 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 18:48:23.717397 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 09/04/24 18:48:23.72
  I0904 18:48:23.724352 19 daemon_set.go:927] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 09/04/24 18:48:23.724
  I0904 18:48:23.734712 19 daemon_set.go:947] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 09/04/24 18:48:23.734
  I0904 18:48:23.736574 19 daemon_set.go:972] Observed &DaemonSet event: ADDED
  I0904 18:48:23.736643 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.736714 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.736884 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.736961 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.736977 19 daemon_set.go:965] Found daemon set daemon-set in namespace daemonsets-3993 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0904 18:48:23.737004 19 daemon_set.go:976] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 09/04/24 18:48:23.737
  STEP: watching for the daemon set status to be patched @ 09/04/24 18:48:23.744
  I0904 18:48:23.745685 19 daemon_set.go:1016] Observed &DaemonSet event: ADDED
  I0904 18:48:23.745782 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.745852 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.745988 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.746034 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.746047 19 daemon_set.go:1012] Observed daemon set daemon-set in namespace daemonsets-3993 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0904 18:48:23.746102 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0904 18:48:23.746143 19 daemon_set.go:1009] Found daemon set daemon-set in namespace daemonsets-3993 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0904 18:48:23.746151 19 daemon_set.go:1020] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 09/04/24 18:48:23.748
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3993, will wait for the garbage collector to delete the pods @ 09/04/24 18:48:23.748
  I0904 18:48:23.809243 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.339182ms
  I0904 18:48:23.910074 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.82557ms
  E0904 18:48:24.304586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:25.304907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:48:25.515734 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 18:48:25.515767 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0904 18:48:25.520126 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25349"},"items":null}

  I0904 18:48:25.524503 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25349"},"items":null}

  I0904 18:48:25.539827 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3993" for this suite. @ 09/04/24 18:48:25.544
• [3.891 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:167
  STEP: Creating a kubernetes client @ 09/04/24 18:48:25.55
  I0904 18:48:25.550999 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename disruption @ 09/04/24 18:48:25.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:25.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:25.575
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:48:25.585
  E0904 18:48:26.304986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:27.305159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 09/04/24 18:48:27.591
  STEP: Waiting for all pods to be running @ 09/04/24 18:48:27.621
  I0904 18:48:27.624670 19 disruption.go:691] running pods: 0 < 1
  E0904 18:48:28.305326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:29.305442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 09/04/24 18:48:29.627
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:48:29.639
  STEP: Patching PodDisruptionBudget status @ 09/04/24 18:48:29.646
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:48:29.653
  I0904 18:48:29.657749 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8974" for this suite. @ 09/04/24 18:48:29.66
• [4.117 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:838
  STEP: Creating a kubernetes client @ 09/04/24 18:48:29.668
  I0904 18:48:29.668525 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:48:29.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:29.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:29.686
  STEP: Setting up server cert @ 09/04/24 18:48:29.715
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:48:29.876
  STEP: Deploying the webhook pod @ 09/04/24 18:48:29.886
  STEP: Wait for the deployment to be ready @ 09/04/24 18:48:29.896
  I0904 18:48:29.904434 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 18:48:30.305690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:31.306699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 18:48:31.918
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:48:31.93
  E0904 18:48:32.306805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:48:32.930559 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 09/04/24 18:48:32.939
  I0904 18:48:32.983504 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6300" for this suite. @ 09/04/24 18:48:32.99
  STEP: Destroying namespace "webhook-markers-8483" for this suite. @ 09/04/24 18:48:32.997
• [3.335 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 09/04/24 18:48:33.003
  I0904 18:48:33.003637 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename cronjob @ 09/04/24 18:48:33.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:48:33.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:48:33.026
  STEP: Creating a ForbidConcurrent cronjob @ 09/04/24 18:48:33.03
  STEP: Ensuring a job is scheduled @ 09/04/24 18:48:33.035
  E0904 18:48:33.306943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:34.307399      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:35.307509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:36.307662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:37.308682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:38.308780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:39.309402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:40.309597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:41.309902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:42.309801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:43.310662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:44.310760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:45.310870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:46.311075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:47.312100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:48.312249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:49.312733      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:50.312926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:51.313616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:52.314670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:53.315746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:54.316084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:55.317026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:56.317140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:57.317905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:58.318221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:48:59.318346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:00.318870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 09/04/24 18:49:01.04
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 09/04/24 18:49:01.043
  STEP: Ensuring no more jobs are scheduled @ 09/04/24 18:49:01.047
  STEP: Removing cronjob @ 09/04/24 18:49:01.05
  I0904 18:49:01.056307 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-936" for this suite. @ 09/04/24 18:49:01.061
• [28.067 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1034
  STEP: Creating a kubernetes client @ 09/04/24 18:49:01.07
  I0904 18:49:01.070485 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename statefulset @ 09/04/24 18:49:01.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:49:01.094
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:49:01.098
  STEP: Creating service test in namespace statefulset-3510 @ 09/04/24 18:49:01.166
  STEP: Creating statefulset ss in namespace statefulset-3510 @ 09/04/24 18:49:01.178
  I0904 18:49:01.188007 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E0904 18:49:01.319277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:02.319450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:03.319739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:04.319838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:05.319940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:06.320004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:07.320143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:08.320362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:09.321271      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:10.321487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:11.189862 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 09/04/24 18:49:11.198
  STEP: Getting /status @ 09/04/24 18:49:11.205
  I0904 18:49:11.209165 19 statefulset.go:1070] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 09/04/24 18:49:11.209
  I0904 18:49:11.218522 19 statefulset.go:1090] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 09/04/24 18:49:11.218
  I0904 18:49:11.220408 19 statefulset.go:1118] Observed &StatefulSet event: ADDED
  I0904 18:49:11.220441 19 statefulset.go:1111] Found Statefulset ss in namespace statefulset-3510 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0904 18:49:11.220490 19 statefulset.go:1122] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 09/04/24 18:49:11.22
  I0904 18:49:11.220545 19 statefulset.go:1126] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0904 18:49:11.228140 19 statefulset.go:1130] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 09/04/24 18:49:11.228
  I0904 18:49:11.230108 19 statefulset.go:1155] Observed &StatefulSet event: ADDED
  I0904 18:49:11.230139 19 statefulset.go:1151] Observed Statefulset ss in namespace statefulset-3510 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0904 18:49:11.230233 19 statefulset.go:1155] Observed &StatefulSet event: MODIFIED
  I0904 18:49:11.230281 19 statefulset.go:138] Deleting all statefulset in ns statefulset-3510
  I0904 18:49:11.234087 19 rest.go:150] Scaling statefulset ss to 0
  E0904 18:49:11.321705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:12.321820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:13.321895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:14.321993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:15.322113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:16.322209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:17.322672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:18.322774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:19.322879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:20.322982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:21.248432 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0904 18:49:21.252719 19 rest.go:88] Deleting statefulset ss
  I0904 18:49:21.267113 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3510" for this suite. @ 09/04/24 18:49:21.271
• [20.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 09/04/24 18:49:21.279
  I0904 18:49:21.279307 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 18:49:21.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:49:21.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:49:21.3
  STEP: Creating Pod @ 09/04/24 18:49:21.303
  E0904 18:49:21.323075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:22.324148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 09/04/24 18:49:23.322
  I0904 18:49:23.322942 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-4900 PodName:pod-sharedvolume-bac6c0bc-b862-4deb-a2b5-dd9505660b5d ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:49:23.323095 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:49:23.323522 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:49:23.323582 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-4900/pods/pod-sharedvolume-bac6c0bc-b862-4deb-a2b5-dd9505660b5d/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  E0904 18:49:23.324954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:23.381696 19 exec_util.go:111] Exec stderr: ""
  I0904 18:49:23.381933 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4900" for this suite. @ 09/04/24 18:49:23.387
• [2.115 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
  STEP: Creating a kubernetes client @ 09/04/24 18:49:23.394
  I0904 18:49:23.395003 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 18:49:23.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:49:23.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:49:23.415
  STEP: creating Agnhost RC @ 09/04/24 18:49:23.418
  I0904 18:49:23.418794 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6872 create -f -'
  I0904 18:49:23.495329 19 builder.go:146] stderr: ""
  I0904 18:49:23.495359 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/04/24 18:49:23.495
  E0904 18:49:24.325285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:24.499645 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0904 18:49:24.499675 19 framework.go:733] Found 1 / 1
  I0904 18:49:24.499688 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 09/04/24 18:49:24.499
  I0904 18:49:24.502518 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0904 18:49:24.502535 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0904 18:49:24.502626 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-6872 patch pod agnhost-primary-9794b -p {"metadata":{"annotations":{"x":"y"}}}'
  I0904 18:49:24.549913 19 builder.go:146] stderr: ""
  I0904 18:49:24.549938 19 builder.go:147] stdout: "pod/agnhost-primary-9794b patched\n"
  STEP: checking annotations @ 09/04/24 18:49:24.549
  I0904 18:49:24.554759 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0904 18:49:24.554779 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0904 18:49:24.554920 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6872" for this suite. @ 09/04/24 18:49:24.558
• [1.170 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:288
  STEP: Creating a kubernetes client @ 09/04/24 18:49:24.564
  I0904 18:49:24.564879 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename dns @ 09/04/24 18:49:24.565
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:49:24.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:49:24.582
  STEP: Creating a test headless service @ 09/04/24 18:49:24.585
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5883.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5883.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5883.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5883.svc.cluster.local;sleep 1; done
   @ 09/04/24 18:49:24.592
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5883.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5883.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5883.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5883.svc.cluster.local;sleep 1; done
   @ 09/04/24 18:49:24.592
  STEP: creating a pod to probe DNS @ 09/04/24 18:49:24.592
  STEP: submitting the pod to kubernetes @ 09/04/24 18:49:24.592
  E0904 18:49:25.325400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:26.325499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/04/24 18:49:26.612
  STEP: looking for the results for each expected name from probers @ 09/04/24 18:49:26.615
  I0904 18:49:26.621141 19 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local from pod dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700: the server could not find the requested resource (get pods dns-test-232ea95d-a6ca-4124-a461-eebec38d0700)
  I0904 18:49:26.625759 19 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local from pod dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700: the server could not find the requested resource (get pods dns-test-232ea95d-a6ca-4124-a461-eebec38d0700)
  I0904 18:49:26.629494 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-5883.svc.cluster.local from pod dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700: the server could not find the requested resource (get pods dns-test-232ea95d-a6ca-4124-a461-eebec38d0700)
  I0904 18:49:26.633669 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-5883.svc.cluster.local from pod dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700: the server could not find the requested resource (get pods dns-test-232ea95d-a6ca-4124-a461-eebec38d0700)
  I0904 18:49:26.638039 19 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local from pod dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700: the server could not find the requested resource (get pods dns-test-232ea95d-a6ca-4124-a461-eebec38d0700)
  I0904 18:49:26.641358 19 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local from pod dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700: the server could not find the requested resource (get pods dns-test-232ea95d-a6ca-4124-a461-eebec38d0700)
  I0904 18:49:26.645095 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-5883.svc.cluster.local from pod dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700: the server could not find the requested resource (get pods dns-test-232ea95d-a6ca-4124-a461-eebec38d0700)
  I0904 18:49:26.649581 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-5883.svc.cluster.local from pod dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700: the server could not find the requested resource (get pods dns-test-232ea95d-a6ca-4124-a461-eebec38d0700)
  I0904 18:49:26.649607 19 dns_common.go:489] Lookups using dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5883.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5883.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5883.svc.cluster.local jessie_udp@dns-test-service-2.dns-5883.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5883.svc.cluster.local]

  I0904 18:49:26.665011 19 dns_common.go:495] Pod client logs for webserver: 
  I0904 18:49:26.672417 19 dns_common.go:495] Pod client logs for querier: 
  I0904 18:49:26.678393 19 dns_common.go:495] Pod client logs for jessie-querier: 
  E0904 18:49:27.325623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:28.325739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:29.325810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:30.325915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:31.326701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:31.653246 19 dns_common.go:527] DNS probes using dns-5883/dns-test-232ea95d-a6ca-4124-a461-eebec38d0700 succeeded

  STEP: deleting the pod @ 09/04/24 18:49:31.653
  STEP: deleting the test headless service @ 09/04/24 18:49:31.682
  I0904 18:49:31.708782 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5883" for this suite. @ 09/04/24 18:49:31.714
• [7.163 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2157
  STEP: Creating a kubernetes client @ 09/04/24 18:49:31.727
  I0904 18:49:31.727796 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:49:31.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:49:31.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:49:31.751
  STEP: creating service in namespace services-2429 @ 09/04/24 18:49:31.755
  STEP: creating service affinity-clusterip in namespace services-2429 @ 09/04/24 18:49:31.755
  STEP: creating replication controller affinity-clusterip in namespace services-2429 @ 09/04/24 18:49:31.777
  I0904 18:49:31.786495      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-2429, replica count: 3
  E0904 18:49:32.327223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:33.328067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:34.328187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:34.836810      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 18:49:34.843184 19 resource.go:361] Creating new exec pod
  E0904 18:49:35.328275      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:36.329035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:37.330087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:37.858870 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-2429 exec execpod-affinity9xh52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0904 18:49:37.952097 19 builder.go:146] stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  I0904 18:49:37.952138 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:49:37.952273 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-2429 exec execpod-affinity9xh52 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.252 80'
  I0904 18:49:38.034986 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.252 80\nConnection to 10.152.183.252 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0904 18:49:38.035025 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 18:49:38.035144 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-2429 exec execpod-affinity9xh52 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.252:80/ ; done'
  I0904 18:49:38.162939 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.252:80/\n"
  I0904 18:49:38.162995 19 builder.go:147] stdout: "\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr\naffinity-clusterip-264nr"
  I0904 18:49:38.163009 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163018 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163023 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163028 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163034 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163039 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163044 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163050 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163055 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163059 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163065 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163070 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163075 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163200 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163207 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163213 19 service.go:242] Received response from host: affinity-clusterip-264nr
  I0904 18:49:38.163283 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-2429, will wait for the garbage collector to delete the pods @ 09/04/24 18:49:38.18
  I0904 18:49:38.241663 19 resources.go:139] Deleting ReplicationController affinity-clusterip took: 8.405892ms
  E0904 18:49:38.331104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:38.342296 19 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 100.630642ms
  E0904 18:49:39.331352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:40.331419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:41.333832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:49:41.563803 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2429" for this suite. @ 09/04/24 18:49:41.568
• [9.849 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 09/04/24 18:49:41.576
  I0904 18:49:41.576961 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:49:41.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:49:41.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:49:41.596
  STEP: Creating configMap with name configmap-test-volume-map-edbcbbd1-08e3-4cab-b1d3-85f4167d1088 @ 09/04/24 18:49:41.599
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:49:41.604
  E0904 18:49:42.333932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:43.334035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:44.334689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:45.334780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:49:45.84
  I0904 18:49:45.845042 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-31eac0ae-bada-409b-90c1-04537d4854f0 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:49:45.85
  I0904 18:49:45.867233 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6644" for this suite. @ 09/04/24 18:49:45.871
• [4.301 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:859
  STEP: Creating a kubernetes client @ 09/04/24 18:49:45.878
  I0904 18:49:45.878500 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 18:49:45.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:49:45.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:49:45.896
  STEP: Creating a ResourceQuota with best effort scope @ 09/04/24 18:49:45.899
  STEP: Ensuring ResourceQuota status is calculated @ 09/04/24 18:49:45.904
  E0904 18:49:46.335785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:47.336008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 09/04/24 18:49:47.909
  STEP: Ensuring ResourceQuota status is calculated @ 09/04/24 18:49:47.914
  E0904 18:49:48.336659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:49.336767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 09/04/24 18:49:49.919
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 09/04/24 18:49:49.933
  E0904 18:49:50.337710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:51.340926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 09/04/24 18:49:51.936
  E0904 18:49:52.341330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:53.341612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 09/04/24 18:49:53.942
  STEP: Ensuring resource quota status released the pod usage @ 09/04/24 18:49:53.958
  E0904 18:49:54.342681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:55.342782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 09/04/24 18:49:55.962
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 09/04/24 18:49:55.978
  E0904 18:49:56.343004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:57.343098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 09/04/24 18:49:57.984
  E0904 18:49:58.343696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:49:59.343802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 09/04/24 18:49:59.988
  STEP: Ensuring resource quota status released the pod usage @ 09/04/24 18:50:00.006
  E0904 18:50:00.343884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:01.346364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:50:02.011439 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4940" for this suite. @ 09/04/24 18:50:02.017
• [16.147 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 09/04/24 18:50:02.025
  I0904 18:50:02.025321 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:50:02.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:50:02.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:50:02.045
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:50:02.049
  E0904 18:50:02.347133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:03.348046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:04.349010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:05.349178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:50:06.072
  I0904 18:50:06.076651 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-79cdcd21-75ed-475e-b6e7-b162965b3265 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:50:06.081
  I0904 18:50:06.099436 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3931" for this suite. @ 09/04/24 18:50:06.103
• [4.086 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 09/04/24 18:50:06.111
  I0904 18:50:06.111428 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:50:06.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:50:06.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:50:06.133
  STEP: Creating the pod @ 09/04/24 18:50:06.136
  E0904 18:50:06.349898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:07.350684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:08.351303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:50:08.681717 19 pod_client.go:173] Successfully updated pod "annotationupdate9077cbdc-69b8-4a79-86d8-30a0567f2130"
  E0904 18:50:09.352308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:10.352523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:50:10.696431 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6464" for this suite. @ 09/04/24 18:50:10.701
• [4.601 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 09/04/24 18:50:10.712
  I0904 18:50:10.712921 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pod-network-test @ 09/04/24 18:50:10.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:50:10.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:50:10.733
  STEP: Performing setup for networking test in namespace pod-network-test-7903 @ 09/04/24 18:50:10.736
  STEP: creating a selector @ 09/04/24 18:50:10.736
  STEP: Creating the service pods in kubernetes @ 09/04/24 18:50:10.736
  I0904 18:50:10.736915 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0904 18:50:11.354308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:12.354388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:13.354438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:14.354641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:15.355341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:16.355446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:17.355554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:18.355658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:19.355775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:20.355879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:21.356553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:22.356628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/04/24 18:50:22.823
  E0904 18:50:23.356768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:24.356873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:50:24.859127 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0904 18:50:24.859158 19 utils.go:496] Going to poll 192.168.146.131 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0904 18:50:24.863594 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.146.131 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7903 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:50:24.863609 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:50:24.864008 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:50:24.864079 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7903/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.146.131+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0904 18:50:25.357677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:50:25.929316 19 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0904 18:50:25.929364 19 utils.go:496] Going to poll 192.168.104.155 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0904 18:50:25.932976 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.104.155 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7903 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:50:25.932998 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:50:25.933385 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:50:25.933426 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7903/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.104.155+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0904 18:50:26.358535      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:50:26.988079 19 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0904 18:50:26.988129 19 utils.go:496] Going to poll 192.168.243.58 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0904 18:50:26.993631 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.243.58 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7903 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:50:26.993653 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:50:26.994016 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:50:26.994054 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7903/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.243.58+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0904 18:50:27.359512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:50:28.043923 19 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I0904 18:50:28.044063 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-7903" for this suite. @ 09/04/24 18:50:28.047
• [17.341 seconds]
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:814
  STEP: Creating a kubernetes client @ 09/04/24 18:50:28.054
  I0904 18:50:28.054119 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-preemption @ 09/04/24 18:50:28.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:50:28.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:50:28.075
  I0904 18:50:28.094827 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0904 18:50:28.360487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:29.360591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:30.360668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:31.362413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:32.363366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:33.363614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:34.364087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:35.364311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:36.365317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:37.365431      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:38.366383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:39.366695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:40.367462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:41.368923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:42.369768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:43.370031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:44.370708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:45.370794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:46.371732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:47.371912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:48.372897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:49.372994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:50.373953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:51.374366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:52.375377      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:53.375485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:54.376130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:55.376511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:56.377175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:57.377891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:58.378804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:50:59.378898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:00.379624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:01.380606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:02.380701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:03.380794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:04.380938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:05.381011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:06.382114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:07.382177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:08.383037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:09.383072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:10.383954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:11.384048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:12.384153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:13.384262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:14.385106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:15.385305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:16.385947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:17.386727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:18.387593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:19.387705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:20.387830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:21.388032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:22.388143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:23.388349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:24.389199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:25.389595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:26.389706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:27.390536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:28.099305 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 09/04/24 18:51:28.103
  I0904 18:51:28.103416 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-preemption-path @ 09/04/24 18:51:28.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:28.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:28.124
  I0904 18:51:28.140738 19 preemption.go:820] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0904 18:51:28.143895 19 preemption.go:826] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  I0904 18:51:28.203477 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-5010" for this suite. @ 09/04/24 18:51:28.207
  I0904 18:51:28.212658 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-8250" for this suite. @ 09/04/24 18:51:28.216
• [60.168 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 09/04/24 18:51:28.222
  I0904 18:51:28.222091 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-runtime @ 09/04/24 18:51:28.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:28.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:28.242
  STEP: create the container @ 09/04/24 18:51:28.246
  W0904 18:51:28.253219      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 09/04/24 18:51:28.253
  E0904 18:51:28.390832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:29.390939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:30.390962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/04/24 18:51:31.274
  STEP: the container should be terminated @ 09/04/24 18:51:31.278
  STEP: the termination message should be set @ 09/04/24 18:51:31.278
  I0904 18:51:31.278938 19 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 09/04/24 18:51:31.278
  I0904 18:51:31.294029 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4489" for this suite. @ 09/04/24 18:51:31.296
• [3.080 seconds]
------------------------------
S
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 09/04/24 18:51:31.302
  I0904 18:51:31.302321 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 09/04/24 18:51:31.302
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:31.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:31.321
  STEP: Setting up the test @ 09/04/24 18:51:31.326
  STEP: Creating hostNetwork=false pod @ 09/04/24 18:51:31.326
  E0904 18:51:31.391850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:32.391984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 09/04/24 18:51:33.36
  E0904 18:51:33.392388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:34.392467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Running the test @ 09/04/24 18:51:35.384
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 09/04/24 18:51:35.384
  I0904 18:51:35.384419 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.384437 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.384828 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.384863 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  E0904 18:51:35.393524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:35.429209 19 exec_util.go:111] Exec stderr: ""
  I0904 18:51:35.429252 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.429308 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.429748 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.429820 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0904 18:51:35.476841 19 exec_util.go:111] Exec stderr: ""
  I0904 18:51:35.476886 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.476894 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.477314 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.477363 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0904 18:51:35.521692 19 exec_util.go:111] Exec stderr: ""
  I0904 18:51:35.521789 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.521822 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.522194 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.522243 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0904 18:51:35.573127 19 exec_util.go:111] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 09/04/24 18:51:35.573
  I0904 18:51:35.573205 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.573213 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.573680 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.573744 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0904 18:51:35.620956 19 exec_util.go:111] Exec stderr: ""
  I0904 18:51:35.621011 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.621169 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.621643 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.621717 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0904 18:51:35.669486 19 exec_util.go:111] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 09/04/24 18:51:35.669
  I0904 18:51:35.669762 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.669799 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.670561 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.670685 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0904 18:51:35.723912 19 exec_util.go:111] Exec stderr: ""
  I0904 18:51:35.724050 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.724096 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.724582 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.724711 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0904 18:51:35.788192 19 exec_util.go:111] Exec stderr: ""
  I0904 18:51:35.788411 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.788464 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.789337 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.789531 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0904 18:51:35.843701 19 exec_util.go:111] Exec stderr: ""
  I0904 18:51:35.843833 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1970 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:51:35.843882 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:51:35.844583 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:51:35.844720 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1970/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0904 18:51:35.900162 19 exec_util.go:111] Exec stderr: ""
  I0904 18:51:35.900417 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-1970" for this suite. @ 09/04/24 18:51:35.905
• [4.611 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:107
  STEP: Creating a kubernetes client @ 09/04/24 18:51:35.914
  I0904 18:51:35.914062 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename job @ 09/04/24 18:51:35.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:35.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:35.934
  STEP: Looking for a node to schedule job pod @ 09/04/24 18:51:35.938
  STEP: Creating a job @ 09/04/24 18:51:35.941
  STEP: Ensuring job fails @ 09/04/24 18:51:35.948
  E0904 18:51:36.394216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:37.394283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:38.394400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:39.394526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:39.957068 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3484" for this suite. @ 09/04/24 18:51:39.961
• [4.054 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 09/04/24 18:51:39.968
  I0904 18:51:39.968366 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-runtime @ 09/04/24 18:51:39.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:39.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:39.989
  STEP: create the container @ 09/04/24 18:51:39.993
  W0904 18:51:40.002231      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 09/04/24 18:51:40.002
  E0904 18:51:40.394580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:41.394689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/04/24 18:51:42.018
  STEP: the container should be terminated @ 09/04/24 18:51:42.022
  STEP: the termination message should be set @ 09/04/24 18:51:42.022
  I0904 18:51:42.022708 19 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 09/04/24 18:51:42.022
  I0904 18:51:42.038291 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5702" for this suite. @ 09/04/24 18:51:42.041
• [2.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 09/04/24 18:51:42.049
  I0904 18:51:42.049602 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename limitrange @ 09/04/24 18:51:42.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:42.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:42.069
  STEP: Creating LimitRange "e2e-limitrange-xmk96" in namespace "limitrange-5133" @ 09/04/24 18:51:42.072
  STEP: Creating another limitRange in another namespace @ 09/04/24 18:51:42.077
  I0904 18:51:42.101492 19 limit_range.go:299] Namespace "e2e-limitrange-xmk96-9371" created
  I0904 18:51:42.101515 19 limit_range.go:300] Creating LimitRange "e2e-limitrange-xmk96" in namespace "e2e-limitrange-xmk96-9371"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-xmk96" @ 09/04/24 18:51:42.107
  I0904 18:51:42.111296 19 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-xmk96" in "limitrange-5133" namespace @ 09/04/24 18:51:42.111
  I0904 18:51:42.116495 19 limit_range.go:335] LimitRange "e2e-limitrange-xmk96" has been patched
  STEP: Delete LimitRange "e2e-limitrange-xmk96" by Collection with labelSelector: "e2e-limitrange-xmk96=patched" @ 09/04/24 18:51:42.116
  STEP: Confirm that the limitRange "e2e-limitrange-xmk96" has been deleted @ 09/04/24 18:51:42.123
  I0904 18:51:42.123102 19 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0904 18:51:42.126242 19 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-xmk96=patched"
  I0904 18:51:42.126261 19 limit_range.go:344] LimitRange "e2e-limitrange-xmk96" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-xmk96" @ 09/04/24 18:51:42.126
  I0904 18:51:42.129796 19 limit_range.go:350] Found 1 limitRange
  I0904 18:51:42.129892 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-5133" for this suite. @ 09/04/24 18:51:42.132
  STEP: Destroying namespace "e2e-limitrange-xmk96-9371" for this suite. @ 09/04/24 18:51:42.139
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 09/04/24 18:51:42.147
  I0904 18:51:42.147065 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replicaset @ 09/04/24 18:51:42.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:42.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:42.165
  STEP: Create a Replicaset @ 09/04/24 18:51:42.174
  STEP: Verify that the required pods have come up. @ 09/04/24 18:51:42.179
  I0904 18:51:42.183290 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0904 18:51:42.395684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:43.396698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:44.396823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:45.396925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:46.397009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:47.186916 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/04/24 18:51:47.186
  STEP: Getting /status @ 09/04/24 18:51:47.186
  I0904 18:51:47.191458 19 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 09/04/24 18:51:47.191
  I0904 18:51:47.205209 19 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 09/04/24 18:51:47.205
  I0904 18:51:47.207391 19 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I0904 18:51:47.207461 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0904 18:51:47.207594 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0904 18:51:47.207654 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0904 18:51:47.207703 19 replica_set.go:682] Found replicaset test-rs in namespace replicaset-5549 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0904 18:51:47.207719 19 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 09/04/24 18:51:47.207
  I0904 18:51:47.207741 19 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0904 18:51:47.216600 19 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 09/04/24 18:51:47.216
  I0904 18:51:47.219649 19 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I0904 18:51:47.219729 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0904 18:51:47.219857 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0904 18:51:47.219923 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0904 18:51:47.219970 19 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-5549 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0904 18:51:47.220048 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0904 18:51:47.220077 19 replica_set.go:718] Found replicaset test-rs in namespace replicaset-5549 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0904 18:51:47.220086 19 replica_set.go:729] Replicaset test-rs has a patched status
  I0904 18:51:47.220172 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5549" for this suite. @ 09/04/24 18:51:47.225
• [5.092 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:144
  STEP: Creating a kubernetes client @ 09/04/24 18:51:47.239
  I0904 18:51:47.239488 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename disruption @ 09/04/24 18:51:47.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:47.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:47.262
  STEP: Waiting for the pdb to be processed @ 09/04/24 18:51:47.278
  E0904 18:51:47.397996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:48.398457      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 09/04/24 18:51:49.313
  I0904 18:51:49.319675 19 disruption.go:691] running pods: 0 < 3
  E0904 18:51:49.398796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:50.398938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:51.322334 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-763" for this suite. @ 09/04/24 18:51:51.326
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 09/04/24 18:51:51.34
  I0904 18:51:51.340928 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename controllerrevisions @ 09/04/24 18:51:51.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:51.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:51.375
  E0904 18:51:51.399762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating DaemonSet "e2e-wmxf4-daemon-set" @ 09/04/24 18:51:51.4
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/04/24 18:51:51.407
  I0904 18:51:51.411737 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:51:51.411777 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:51:51.415283 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-wmxf4-daemon-set: 0
  I0904 18:51:51.415302 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 18:51:52.399934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:52.412658 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:51:52.412705 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:51:52.417000 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-wmxf4-daemon-set: 0
  I0904 18:51:52.417018 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 18:51:53.400027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:53.412166 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:51:53.412201 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 18:51:53.416250 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-wmxf4-daemon-set: 3
  I0904 18:51:53.416266 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset e2e-wmxf4-daemon-set
  STEP: Confirm DaemonSet "e2e-wmxf4-daemon-set" successfully created with "daemonset-name=e2e-wmxf4-daemon-set" label @ 09/04/24 18:51:53.419
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-wmxf4-daemon-set" @ 09/04/24 18:51:53.426
  I0904 18:51:53.430114 19 controller_revision.go:162] Located ControllerRevision: "e2e-wmxf4-daemon-set-79fbc9d6"
  STEP: Patching ControllerRevision "e2e-wmxf4-daemon-set-79fbc9d6" @ 09/04/24 18:51:53.433
  I0904 18:51:53.441360 19 controller_revision.go:173] e2e-wmxf4-daemon-set-79fbc9d6 has been patched
  STEP: Create a new ControllerRevision @ 09/04/24 18:51:53.441
  I0904 18:51:53.447335 19 controller_revision.go:191] Created ControllerRevision: e2e-wmxf4-daemon-set-779449976
  STEP: Confirm that there are two ControllerRevisions @ 09/04/24 18:51:53.447
  I0904 18:51:53.447385 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0904 18:51:53.450644 19 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-wmxf4-daemon-set-79fbc9d6" @ 09/04/24 18:51:53.45
  STEP: Confirm that there is only one ControllerRevision @ 09/04/24 18:51:53.456
  I0904 18:51:53.456199 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0904 18:51:53.459388 19 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-wmxf4-daemon-set-779449976" @ 09/04/24 18:51:53.461
  I0904 18:51:53.473676 19 controller_revision.go:220] e2e-wmxf4-daemon-set-779449976 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 09/04/24 18:51:53.473
  W0904 18:51:53.480115      19 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 09/04/24 18:51:53.48
  I0904 18:51:53.480191 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  E0904 18:51:54.400750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:54.481050 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0904 18:51:54.485165 19 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-wmxf4-daemon-set-779449976=updated" @ 09/04/24 18:51:54.485
  STEP: Confirm that there is only one ControllerRevision @ 09/04/24 18:51:54.493
  I0904 18:51:54.493860 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0904 18:51:54.496486 19 controller_revision.go:265] Found 1 ControllerRevisions
  I0904 18:51:54.499669 19 controller_revision.go:246] ControllerRevision "e2e-wmxf4-daemon-set-7b8779bbbf" has revision 3
  STEP: Deleting DaemonSet "e2e-wmxf4-daemon-set" @ 09/04/24 18:51:54.503
  STEP: deleting DaemonSet.extensions e2e-wmxf4-daemon-set in namespace controllerrevisions-2532, will wait for the garbage collector to delete the pods @ 09/04/24 18:51:54.503
  I0904 18:51:54.564841 19 resources.go:139] Deleting DaemonSet.extensions e2e-wmxf4-daemon-set took: 8.616488ms
  I0904 18:51:54.665927 19 resources.go:163] Terminating DaemonSet.extensions e2e-wmxf4-daemon-set pods took: 101.078168ms
  E0904 18:51:55.401533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:56.402118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:51:56.470114 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-wmxf4-daemon-set: 0
  I0904 18:51:56.470141 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-wmxf4-daemon-set
  I0904 18:51:56.473388 19 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27059"},"items":null}

  I0904 18:51:56.475905 19 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27060"},"items":null}

  I0904 18:51:56.488389 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-2532" for this suite. @ 09/04/24 18:51:56.492
• [5.159 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 09/04/24 18:51:56.5
  I0904 18:51:56.500038 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 18:51:56.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:56.516
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:56.519
  STEP: creating the pod @ 09/04/24 18:51:56.523
  STEP: submitting the pod to kubernetes @ 09/04/24 18:51:56.523
  E0904 18:51:57.402980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:51:58.403333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 09/04/24 18:51:58.548
  STEP: updating the pod @ 09/04/24 18:51:58.551
  I0904 18:51:59.066770 19 pod_client.go:173] Successfully updated pod "pod-update-06e7dd07-322a-4358-9683-ad4865922a65"
  STEP: verifying the updated pod is in kubernetes @ 09/04/24 18:51:59.07
  I0904 18:51:59.074053 19 pods.go:391] Pod update OK
  I0904 18:51:59.074205 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-999" for this suite. @ 09/04/24 18:51:59.077
• [2.585 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 09/04/24 18:51:59.086
  I0904 18:51:59.086831 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:51:59.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:51:59.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:51:59.105
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:51:59.108
  E0904 18:51:59.403729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:00.403837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:52:01.126
  I0904 18:52:01.130235 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod downwardapi-volume-96441e9a-4480-46e8-b919-54e8d38326d2 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:52:01.141
  I0904 18:52:01.159571 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8113" for this suite. @ 09/04/24 18:52:01.164
• [2.084 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:763
  STEP: Creating a kubernetes client @ 09/04/24 18:52:01.17
  I0904 18:52:01.170895 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:52:01.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:52:01.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:52:01.198
  STEP: Setting up server cert @ 09/04/24 18:52:01.223
  E0904 18:52:01.405391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:52:01.531
  STEP: Deploying the webhook pod @ 09/04/24 18:52:01.539
  STEP: Wait for the deployment to be ready @ 09/04/24 18:52:01.551
  I0904 18:52:01.572063 19 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0904 18:52:02.405622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:03.406669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 18:52:03.583
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:52:03.593
  E0904 18:52:04.406774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:52:04.594101 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 09/04/24 18:52:04.602
  STEP: verifying the mutating webhook match conditions @ 09/04/24 18:52:04.612
  STEP: updating the mutating webhook match conditions @ 09/04/24 18:52:04.614
  STEP: verifying the mutating webhook match conditions @ 09/04/24 18:52:04.624
  I0904 18:52:04.669740 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8305" for this suite. @ 09/04/24 18:52:04.672
  STEP: Destroying namespace "webhook-markers-2001" for this suite. @ 09/04/24 18:52:04.679
• [3.517 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 09/04/24 18:52:04.688
  I0904 18:52:04.688586 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:52:04.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:52:04.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:52:04.708
  STEP: Creating the pod @ 09/04/24 18:52:04.711
  E0904 18:52:05.407784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:06.407889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:52:07.261675 19 pod_client.go:173] Successfully updated pod "labelsupdatee60caf7d-c525-413a-b66c-d22ce11d00ec"
  E0904 18:52:07.408936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:08.409063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:52:09.275883 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6560" for this suite. @ 09/04/24 18:52:09.279
• [4.597 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 09/04/24 18:52:09.285
  I0904 18:52:09.285713 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:52:09.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:52:09.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:52:09.307
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:52:09.31
  E0904 18:52:09.409836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:10.409953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:11.410070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:12.410299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:52:13.333
  I0904 18:52:13.336719 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-ecb9c0fc-74d5-4355-914a-43115bad045f container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:52:13.344
  I0904 18:52:13.366484 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1835" for this suite. @ 09/04/24 18:52:13.392
• [4.117 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1756
  STEP: Creating a kubernetes client @ 09/04/24 18:52:13.402
  I0904 18:52:13.402714 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 18:52:13.403
  E0904 18:52:13.410788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:52:13.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:52:13.443
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/04/24 18:52:13.446
  I0904 18:52:13.446866 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-3984 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0904 18:52:13.496447 19 builder.go:146] stderr: ""
  I0904 18:52:13.496468 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 09/04/24 18:52:13.496
  I0904 18:52:13.500971 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-3984 delete pods e2e-test-httpd-pod'
  E0904 18:52:14.410933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:15.411040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:52:15.541533 19 builder.go:146] stderr: ""
  I0904 18:52:15.541568 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0904 18:52:15.541765 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3984" for this suite. @ 09/04/24 18:52:15.545
• [2.149 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 09/04/24 18:52:15.551
  I0904 18:52:15.551634 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename security-context-test @ 09/04/24 18:52:15.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:52:15.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:52:15.57
  E0904 18:52:16.411157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:17.411542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:18.412208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:19.412317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:52:19.594480 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8582" for this suite. @ 09/04/24 18:52:19.597
• [4.051 seconds]
------------------------------
SS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:444
  STEP: Creating a kubernetes client @ 09/04/24 18:52:19.603
  I0904 18:52:19.603191 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename taint-multiple-pods @ 09/04/24 18:52:19.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:52:19.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:52:19.624
  I0904 18:52:19.627284 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0904 18:52:20.413313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:21.413524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:22.413615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:23.413720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:24.413819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:25.413884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:26.414016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:27.414110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:28.414203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:29.414279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:30.414410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:31.414597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:32.414699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:33.414825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:34.414911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:35.415043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:36.415145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:37.416174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:38.416607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:39.416822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:40.417561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:41.417624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:42.418696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:43.418998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:44.419325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:45.419767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:46.419861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:47.420501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:48.420618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:49.421043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:50.421154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:51.421246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:52.421363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:53.421598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:54.422401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:55.423447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:56.424037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:57.424819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:58.425740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:52:59.425836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:00.426586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:01.426954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:02.427072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:03.427351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:04.427899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:05.428113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:06.428358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:07.428459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:08.429186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:09.429339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:10.429592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:11.430659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:12.431374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:13.431913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:14.432918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:15.433044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:16.433166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:17.433352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:18.433626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:19.433702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:53:19.628140 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I0904 18:53:19.632152 19 taints.go:144] Starting informer...
  STEP: Starting pods... @ 09/04/24 18:53:19.632
  I0904 18:53:19.855265 19 taints.go:463] Pod1 is running on ip-172-31-21-169. Tainting Node
  E0904 18:53:20.433819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:21.433896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:53:22.080589 19 taints.go:471] Pod2 is running on ip-172-31-21-169. Tainting Node
  STEP: Trying to apply a taint on the Node @ 09/04/24 18:53:22.08
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/04/24 18:53:22.092
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 09/04/24 18:53:22.105
  E0904 18:53:22.434571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:23.434913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:24.435017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:25.435164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:26.435256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:27.435377      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:53:27.624486 19 taints.go:492] Noticed Pod "taint-eviction-b1" gets evicted.
  E0904 18:53:28.435542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:29.435812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:30.435896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:31.435947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:32.436080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:33.436186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:34.436301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:35.436471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:36.436562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:37.436871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:38.436976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:39.437215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:40.437418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:41.437618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:42.437716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:43.437812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:44.437882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:45.438680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:46.438823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:47.439583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:53:47.654695 19 taints.go:492] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/04/24 18:53:47.665
  I0904 18:53:47.669263 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-3633" for this suite. @ 09/04/24 18:53:47.673
• [88.078 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 09/04/24 18:53:47.681
  I0904 18:53:47.681674 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 18:53:47.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:53:47.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:53:47.704
  STEP: Creating configMap with name configmap-test-volume-ca2f39d8-3ffd-414f-8198-267f0dc658dd @ 09/04/24 18:53:47.707
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:53:47.712
  E0904 18:53:48.439717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:49.440757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:50.441665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:51.441762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:53:51.736
  I0904 18:53:51.739519 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-0a017622-c031-4e98-b448-5c1f2076be4e container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:53:51.758
  I0904 18:53:51.776919 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6477" for this suite. @ 09/04/24 18:53:51.779
• [4.104 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:341
  STEP: Creating a kubernetes client @ 09/04/24 18:53:51.785
  I0904 18:53:51.785849 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename cronjob @ 09/04/24 18:53:51.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:53:51.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:53:51.806
  STEP: Creating a cronjob @ 09/04/24 18:53:51.81
  STEP: creating @ 09/04/24 18:53:51.81
  STEP: getting @ 09/04/24 18:53:51.815
  STEP: listing @ 09/04/24 18:53:51.818
  STEP: watching @ 09/04/24 18:53:51.82
  I0904 18:53:51.820928 19 cronjob.go:370] starting watch
  STEP: cluster-wide listing @ 09/04/24 18:53:51.822
  STEP: cluster-wide watching @ 09/04/24 18:53:51.825
  I0904 18:53:51.825917 19 cronjob.go:382] starting watch
  STEP: patching @ 09/04/24 18:53:51.827
  STEP: updating @ 09/04/24 18:53:51.834
  I0904 18:53:51.842339 19 cronjob.go:406] waiting for watch events with expected annotations
  I0904 18:53:51.842363 19 cronjob.go:420] saw patched and updated annotations
  STEP: patching /status @ 09/04/24 18:53:51.842
  STEP: updating /status @ 09/04/24 18:53:51.849
  STEP: get /status @ 09/04/24 18:53:51.856
  STEP: deleting @ 09/04/24 18:53:51.859
  STEP: deleting a collection @ 09/04/24 18:53:51.872
  I0904 18:53:51.882698 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6070" for this suite. @ 09/04/24 18:53:51.886
• [0.107 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3209
  STEP: Creating a kubernetes client @ 09/04/24 18:53:51.892
  I0904 18:53:51.892654 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 18:53:51.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:53:51.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:53:51.909
  STEP: creating an Endpoint @ 09/04/24 18:53:51.916
  STEP: waiting for available Endpoint @ 09/04/24 18:53:51.921
  STEP: listing all Endpoints @ 09/04/24 18:53:51.922
  STEP: updating the Endpoint @ 09/04/24 18:53:51.926
  STEP: fetching the Endpoint @ 09/04/24 18:53:51.932
  STEP: patching the Endpoint @ 09/04/24 18:53:51.935
  STEP: fetching the Endpoint @ 09/04/24 18:53:51.942
  STEP: deleting the Endpoint by Collection @ 09/04/24 18:53:51.946
  STEP: waiting for Endpoint deletion @ 09/04/24 18:53:51.953
  STEP: fetching the Endpoint @ 09/04/24 18:53:51.954
  I0904 18:53:51.957830 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3836" for this suite. @ 09/04/24 18:53:51.961
• [0.074 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 09/04/24 18:53:51.966
  I0904 18:53:51.966915 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:53:51.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:53:51.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:53:51.984
  STEP: Creating configMap with name projected-configmap-test-volume-map-d4e4e29e-8eb0-4f17-8d65-3688a5c82d39 @ 09/04/24 18:53:51.987
  STEP: Creating a pod to test consume configMaps @ 09/04/24 18:53:51.994
  E0904 18:53:52.441858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:53.441948      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:53:54.011
  I0904 18:53:54.016282 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-configmaps-1b1d9c7c-1309-4a61-803e-b8bb6223af12 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 18:53:54.021
  I0904 18:53:54.040278 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5367" for this suite. @ 09/04/24 18:53:54.044
• [2.083 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 09/04/24 18:53:54.05
  I0904 18:53:54.050338 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 18:53:54.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:53:54.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:53:54.069
  STEP: Creating pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801 @ 09/04/24 18:53:54.072
  E0904 18:53:54.442698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:55.442956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/04/24 18:53:56.087
  I0904 18:53:56.091808 19 container_probe.go:1749] Initial restart count of pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 is 0
  I0904 18:53:56.096077 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:53:56.443640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:57.443747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:53:58.101345 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:53:58.444838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:53:59.444929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:00.106063 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:00.445576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:01.445677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:02.111363 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:02.446710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:03.446826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:04.116821 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:04.446915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:05.447124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:06.121724 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:06.448156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:07.448367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:08.127494 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:08.448954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:09.449179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:10.133313 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:10.449774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:11.449863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:12.137299 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:12.450759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:13.450893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:14.142667 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:14.451032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:15.451139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:16.147964 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:16.451224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:17.451344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:18.153207 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:18.451430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:19.451625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:20.157919 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:20.452367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:21.453057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:22.163833 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:22.453184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:23.453395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:24.169171 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:24.453529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:25.453625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:26.174889 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:26.454307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:27.454698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:28.180906 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:28.455270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:29.455957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:30.185729 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:30.456069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:31.456255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:32.191169 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:32.456388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:33.456765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:34.196742 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:34.456995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:35.457309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:36.200952 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:36.458375      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:37.458476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:38.206596 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:38.459019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:39.459116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:40.211165 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:40.459562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:41.459652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:42.216469 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:42.460607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:43.460729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:44.221408 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:44.460789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:45.460912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:46.226499 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:46.461847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:47.462700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:48.230638 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:48.462900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:49.462987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:50.234668 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:50.464024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:51.464233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:52.239944 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:52.465297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:53.465409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:54.243878 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:54.466215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:55.466291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:56.248703 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:56.467057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:57.467163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:54:58.252736 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:54:58.468034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:54:59.468149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:00.257782 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:00.469100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:01.469291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:02.263587 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:02.469935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:03.470690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:04.268894 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:04.471239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:05.471308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:06.274738 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:06.472036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:07.473000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:08.280334 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:08.473648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:09.473753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:10.287000 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:10.474289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:11.474404      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:12.292690 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:12.474950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:13.474977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:14.297111 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:14.475418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:15.475595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:16.302169 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:16.476526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:17.476683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:18.306503 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:18.477541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:19.477594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:20.311611 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:20.477926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:21.478648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:22.316515 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:22.478722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:23.479279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:24.321397 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:24.479631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:25.479724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:26.326665 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:26.479897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:27.480388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:28.331584 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:28.480759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:29.480854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:30.337142 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:30.481308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:31.481486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:32.341230 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:32.482507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:33.482600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:34.346293 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:34.483552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:35.484553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:36.351699 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:36.484971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:37.485146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:38.356616 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:38.485890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:39.486666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:40.360615 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:40.486730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:41.486900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:42.365340 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:42.487571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:43.487920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:44.369655 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:44.488930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:45.489073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:46.375090 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:46.489160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:47.489261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:48.379255 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:48.489388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:49.489581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:50.384414 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:50.490604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:51.491348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:52.388940 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:52.492167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:53.492456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:54.395102 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:54.493373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:55.493578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:56.399469 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:56.493598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:57.493705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:55:58.404234 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:55:58.494471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:55:59.494646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:00.408685 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:00.494841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:01.495037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:02.414882 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:02.496104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:03.496349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:04.420592 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:04.496769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:05.496865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:06.425585 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:06.497714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:07.498671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:08.430783 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:08.498992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:09.499205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:10.435998 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:10.500178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:11.500283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:12.440504 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:12.500678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:13.501046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:14.446200 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:14.501389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:15.501587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:16.451856 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:16.502005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:17.502689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:18.457740 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:18.502933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:19.503155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:20.464132 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:20.503216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:21.503649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:22.468528 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:22.504632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:23.504771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:24.474672 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:24.505802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:25.505912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:26.479594 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:26.506715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:27.506837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:28.482994 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:28.507124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:29.507258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:30.488321 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:30.507655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:31.507764      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:32.493110 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:32.508257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:33.508626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:34.496902 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:34.509052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:35.509205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:36.501168 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:36.509237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:37.510250      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:38.506371 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:38.510496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:39.510649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:40.511052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:40.513776 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:41.511860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:42.512041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:42.520847 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:43.513106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:44.513208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:44.526850 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:45.513624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:46.513718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:46.531927 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:47.514691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:48.514803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:48.536607 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:49.514881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:50.515000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:50.542624 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:51.515105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:52.515358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:52.547720 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:53.515451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:54.515725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:54.552686 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:55.516685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:56.516886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:56.557471 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:57.517486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:56:58.517612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:56:58.563145 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:56:59.518367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:00.518694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:00.568046 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:01.519043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:02.519138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:02.573496 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:03.519557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:04.520558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:04.578489 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:05.520868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:06.520945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:06.584342 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:07.521334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:08.521612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:08.590126 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:09.522570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:10.522674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:10.595656 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:11.523663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:12.523769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:12.600387 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:13.523847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:14.524038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:14.606198 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:15.524161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:16.524424      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:16.611776 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:17.524539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:18.524837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:18.616650 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:19.525629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:20.525708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:20.621627 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:21.526613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:22.526790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:22.626276 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:23.527374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:24.527560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:24.631916 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:25.527662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:26.527821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:26.636191 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:27.528163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:28.528449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:28.641548 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:29.528520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:30.528735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:30.645645 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:31.529493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:32.529644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:32.650611 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:33.530667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:34.530861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:34.656106 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:35.530951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:36.531127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:36.661476 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:37.531237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:38.531488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:38.665673 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:39.531570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:40.531683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:40.670134 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:41.531776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:42.531891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:42.675530 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:43.531989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:44.532168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:44.681289 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:45.532239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:46.532348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:46.686076 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:47.533004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:48.533290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:48.691406 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:49.533340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:50.533554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:50.696206 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:51.533631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:52.534709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:52.701758 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:53.534831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:54.534875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:57:54.706131 19 container_probe.go:1759] Get pod liveness-7d707c47-7a98-4c2f-aa3a-3571696000b4 in namespace container-probe-1801
  E0904 18:57:55.534992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:56.535081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/04/24 18:57:56.706
  I0904 18:57:56.720849 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1801" for this suite. @ 09/04/24 18:57:56.725
• [242.680 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 09/04/24 18:57:56.73
  I0904 18:57:56.730374 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 18:57:56.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:57:56.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:57:56.749
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 09/04/24 18:57:56.753
  E0904 18:57:57.535198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:58.535456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:57:59.535553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:00.535645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:58:00.778
  I0904 18:58:00.781870 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-ad021998-eb80-431f-9ed2-05eaac20ae1d container test-container: <nil>
  STEP: delete the pod @ 09/04/24 18:58:00.792
  I0904 18:58:00.811896 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9643" for this suite. @ 09/04/24 18:58:00.814
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 09/04/24 18:58:00.823
  I0904 18:58:00.823518 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename namespaces @ 09/04/24 18:58:00.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:58:00.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:58:00.843
  STEP: Updating Namespace "namespaces-6848" @ 09/04/24 18:58:00.847
  I0904 18:58:00.854365 19 namespace.go:389] Namespace "namespaces-6848" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"2c9e080d-826b-49f6-9d11-79341a950aa0", "kubernetes.io/metadata.name":"namespaces-6848", "namespaces-6848":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0904 18:58:00.854495 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6848" for this suite. @ 09/04/24 18:58:00.861
• [0.046 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 09/04/24 18:58:00.869
  I0904 18:58:00.869501 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename watch @ 09/04/24 18:58:00.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:58:00.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:58:00.885
  STEP: creating a watch on configmaps with label A @ 09/04/24 18:58:00.889
  STEP: creating a watch on configmaps with label B @ 09/04/24 18:58:00.89
  STEP: creating a watch on configmaps with label A or B @ 09/04/24 18:58:00.891
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 09/04/24 18:58:00.893
  I0904 18:58:00.897967 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5414  472ae1cb-80e5-48c6-aee7-431715bdd1a9 28367 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:58:00.898046 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5414  472ae1cb-80e5-48c6-aee7-431715bdd1a9 28367 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 09/04/24 18:58:00.898
  I0904 18:58:00.904923 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5414  472ae1cb-80e5-48c6-aee7-431715bdd1a9 28368 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:58:00.905051 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5414  472ae1cb-80e5-48c6-aee7-431715bdd1a9 28368 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 09/04/24 18:58:00.905
  I0904 18:58:00.913031 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5414  472ae1cb-80e5-48c6-aee7-431715bdd1a9 28369 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:58:00.913112 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5414  472ae1cb-80e5-48c6-aee7-431715bdd1a9 28369 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 09/04/24 18:58:00.913
  I0904 18:58:00.919479 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5414  472ae1cb-80e5-48c6-aee7-431715bdd1a9 28370 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:58:00.919503 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5414  472ae1cb-80e5-48c6-aee7-431715bdd1a9 28370 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 09/04/24 18:58:00.919
  I0904 18:58:00.924999 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5414  e61c487e-04da-47a8-a7a2-060c155f461d 28371 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:58:00.925258 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5414  e61c487e-04da-47a8-a7a2-060c155f461d 28371 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0904 18:58:01.535761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:02.535840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:03.535942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:04.536144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:05.536230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:06.536433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:07.536627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:08.536761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:09.536857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:10.536924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 09/04/24 18:58:10.925
  I0904 18:58:10.934570 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5414  e61c487e-04da-47a8-a7a2-060c155f461d 28418 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 18:58:10.934617 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5414  e61c487e-04da-47a8-a7a2-060c155f461d 28418 0 2024-09-04 18:58:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-09-04 18:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0904 18:58:11.537040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:12.537321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:13.537618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:14.537619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:15.537741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:16.537828      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:17.537908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:18.538014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:19.538136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:20.539005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:20.935783 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5414" for this suite. @ 09/04/24 18:58:20.941
• [20.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 09/04/24 18:58:20.949
  I0904 18:58:20.949671 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename svcaccounts @ 09/04/24 18:58:20.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:58:20.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:58:20.976
  I0904 18:58:21.004035 19 service_accounts.go:253] created pod pod-service-account-defaultsa
  I0904 18:58:21.004056 19 service_accounts.go:267] pod pod-service-account-defaultsa service account token volume mount: true
  I0904 18:58:21.010794 19 service_accounts.go:253] created pod pod-service-account-mountsa
  I0904 18:58:21.010813 19 service_accounts.go:267] pod pod-service-account-mountsa service account token volume mount: true
  I0904 18:58:21.026110 19 service_accounts.go:253] created pod pod-service-account-nomountsa
  I0904 18:58:21.026142 19 service_accounts.go:267] pod pod-service-account-nomountsa service account token volume mount: false
  I0904 18:58:21.040781 19 service_accounts.go:253] created pod pod-service-account-defaultsa-mountspec
  I0904 18:58:21.040870 19 service_accounts.go:267] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0904 18:58:21.049970 19 service_accounts.go:253] created pod pod-service-account-mountsa-mountspec
  I0904 18:58:21.050054 19 service_accounts.go:267] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0904 18:58:21.062151 19 service_accounts.go:253] created pod pod-service-account-nomountsa-mountspec
  I0904 18:58:21.062234 19 service_accounts.go:267] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0904 18:58:21.072932 19 service_accounts.go:253] created pod pod-service-account-defaultsa-nomountspec
  I0904 18:58:21.072995 19 service_accounts.go:267] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0904 18:58:21.081416 19 service_accounts.go:253] created pod pod-service-account-mountsa-nomountspec
  I0904 18:58:21.081527 19 service_accounts.go:267] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0904 18:58:21.090639 19 service_accounts.go:253] created pod pod-service-account-nomountsa-nomountspec
  I0904 18:58:21.090720 19 service_accounts.go:267] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0904 18:58:21.090855 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5023" for this suite. @ 09/04/24 18:58:21.095
• [0.156 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:218
  STEP: Creating a kubernetes client @ 09/04/24 18:58:21.105
  I0904 18:58:21.105543 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 18:58:21.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:58:21.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:58:21.13
  STEP: Setting up server cert @ 09/04/24 18:58:21.156
  E0904 18:58:21.539803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 18:58:21.627
  STEP: Deploying the webhook pod @ 09/04/24 18:58:21.637
  STEP: Wait for the deployment to be ready @ 09/04/24 18:58:21.654
  I0904 18:58:21.665256 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 18:58:22.540802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:23.540918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 18:58:23.681
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 18:58:23.696
  E0904 18:58:24.541035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:24.697379 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0904 18:58:24.706643 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 09/04/24 18:58:25.216
  STEP: Creating a custom resource that should be denied by the webhook @ 09/04/24 18:58:25.23
  E0904 18:58:25.541755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:26.542758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 09/04/24 18:58:27.245
  STEP: Updating the custom resource with disallowed data should be denied @ 09/04/24 18:58:27.253
  STEP: Deleting the custom resource should be denied @ 09/04/24 18:58:27.262
  STEP: Remove the offending key and value from the custom resource data @ 09/04/24 18:58:27.269
  STEP: Deleting the updated custom resource should be successful @ 09/04/24 18:58:27.277
  E0904 18:58:27.543459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:27.854288 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-107" for this suite. @ 09/04/24 18:58:27.859
  STEP: Destroying namespace "webhook-markers-268" for this suite. @ 09/04/24 18:58:27.866
• [6.769 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 09/04/24 18:58:27.874
  I0904 18:58:27.874971 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename aggregator @ 09/04/24 18:58:27.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:58:27.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:58:27.894
  I0904 18:58:27.897620 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Registering the sample API server. @ 09/04/24 18:58:27.898
  I0904 18:58:28.245635 19 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I0904 18:58:28.281483 19 deployment.go:222] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0904 18:58:28.543564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:29.543771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:30.328113 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:30.544418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:31.544519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:32.332763 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:32.545049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:33.545354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:34.332935 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:34.546240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:35.546709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:36.332380 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:36.547680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:37.547782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:38.332875 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:38.548179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:39.548427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:40.332828 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:40.549224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:41.549422      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:42.332164 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:42.550462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:43.550776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:44.333198 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:44.551454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:45.551568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:46.332724 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:46.551981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:47.552090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:48.334000 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:48.552196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:49.552309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:50.334715 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:50.553071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:51.553209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:52.333219 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 18:58:52.553546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:53.553626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:58:54.455813 19 aggregator.go:755] Waited 114.114344ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 09/04/24 18:58:54.492
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 09/04/24 18:58:54.496
  STEP: List APIServices @ 09/04/24 18:58:54.503
  I0904 18:58:54.508212 19 aggregator.go:556] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 09/04/24 18:58:54.508
  I0904 18:58:54.520437 19 aggregator.go:581] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 09/04/24 18:58:54.52
  I0904 18:58:54.531686 19 aggregator.go:607] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.September, 4, 18, 58, 54, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 09/04/24 18:58:54.531
  I0904 18:58:54.534776 19 aggregator.go:625] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-09-04 18:58:54 +0000 UTC Passed all checks passed}
  I0904 18:58:54.534798 19 aggregator.go:621] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0904 18:58:54.534807 19 aggregator.go:631] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 09/04/24 18:58:54.534
  I0904 18:58:54.545484 19 aggregator.go:647] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1628719209" @ 09/04/24 18:58:54.545
  E0904 18:58:54.554364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 09/04/24 18:58:54.556
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 09/04/24 18:58:54.563
  STEP: Patch APIService Status @ 09/04/24 18:58:54.566
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 09/04/24 18:58:54.574
  I0904 18:58:54.577936 19 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-09-04 18:58:54 +0000 UTC Passed all checks passed}
  I0904 18:58:54.577962 19 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0904 18:58:54.578039 19 aggregator.go:721] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0904 18:58:54.578118 19 aggregator.go:731] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 09/04/24 18:58:54.578
  STEP: Confirm that the generated APIService has been deleted @ 09/04/24 18:58:54.585
  I0904 18:58:54.585899 19 aggregator.go:792] Requesting list of APIServices to confirm quantity
  I0904 18:58:54.589132 19 aggregator.go:802] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0904 18:58:54.589174 19 aggregator.go:744] APIService v1alpha1.wardle.example.com has been deleted.
  I0904 18:58:54.691089 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-4069" for this suite. @ 09/04/24 18:58:54.695
• [26.827 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 09/04/24 18:58:54.702
  I0904 18:58:54.702137 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 18:58:54.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:58:54.719
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:58:54.723
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:58:54.726
  E0904 18:58:55.554747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:56.554955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:57.555085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:58.555174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:58:59.555259      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:00.555340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:01.556347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:02.556466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:03.556553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:04.556763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:05.556873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:06.557072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:59:06.778
  I0904 18:59:06.782633 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-a8db7424-2aa6-4b7e-b033-2839a1f96754 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:59:06.812
  I0904 18:59:06.831454 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4250" for this suite. @ 09/04/24 18:59:06.836
• [12.141 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 09/04/24 18:59:06.843
  I0904 18:59:06.843259 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:59:06.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:59:06.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:59:06.863
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:59:06.867
  E0904 18:59:07.557910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:08.558035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:09.558563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:10.559518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:59:10.893
  I0904 18:59:10.897222 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-85cecd6b-dadd-403a-b4c1-1c034e47d731 container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:59:10.903
  I0904 18:59:10.921892 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7546" for this suite. @ 09/04/24 18:59:10.925
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 09/04/24 18:59:10.931
  I0904 18:59:10.931630 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 09/04/24 18:59:10.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:59:10.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:59:10.951
  STEP: creating a target pod @ 09/04/24 18:59:10.954
  E0904 18:59:11.559599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:12.559839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 09/04/24 18:59:12.975
  E0904 18:59:13.560684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:14.560776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 09/04/24 18:59:14.995
  I0904 18:59:14.995827 19 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-102 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 18:59:14.995843 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 18:59:14.996318 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 18:59:14.996386 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-102/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0904 18:59:15.053332 19 exec_util.go:111] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 09/04/24 18:59:15.059
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 09/04/24 18:59:15.064
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 09/04/24 18:59:15.074
  I0904 18:59:15.078860 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-102" for this suite. @ 09/04/24 18:59:15.082
• [4.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 09/04/24 18:59:15.091
  I0904 18:59:15.091100 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename init-container @ 09/04/24 18:59:15.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:59:15.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:59:15.111
  STEP: creating the pod @ 09/04/24 18:59:15.115
  I0904 18:59:15.115560 19 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E0904 18:59:15.561745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:16.562676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:17.563601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:18.563844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:59:19.335221 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5143" for this suite. @ 09/04/24 18:59:19.34
• [4.258 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 09/04/24 18:59:19.349
  I0904 18:59:19.349208 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 18:59:19.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:59:19.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:59:19.369
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 18:59:19.372
  E0904 18:59:19.564201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:20.564293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 18:59:21.394
  I0904 18:59:21.397845 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-5c18adff-3ac4-4dbe-b06d-58b38c8154af container client-container: <nil>
  STEP: delete the pod @ 09/04/24 18:59:21.402
  I0904 18:59:21.421166 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5622" for this suite. @ 09/04/24 18:59:21.425
• [2.083 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 09/04/24 18:59:21.432
  I0904 18:59:21.432790 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/04/24 18:59:21.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:59:21.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:59:21.454
  I0904 18:59:21.457517 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 18:59:21.564381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:22.564508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:23.564842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:59:24.536249 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-899" for this suite. @ 09/04/24 18:59:24.54
• [3.114 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 09/04/24 18:59:24.546
  I0904 18:59:24.546685 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename var-expansion @ 09/04/24 18:59:24.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:59:24.563
  E0904 18:59:24.564910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:59:24.567
  E0904 18:59:25.565097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:26.565207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:59:26.590122 19 delete.go:62] Deleting pod "var-expansion-a1848479-d158-412e-9df1-fd1650c200a8" in namespace "var-expansion-3055"
  I0904 18:59:26.596473 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-a1848479-d158-412e-9df1-fd1650c200a8" to be fully deleted
  E0904 18:59:27.565595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:28.565704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 18:59:28.606875 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3055" for this suite. @ 09/04/24 18:59:28.61
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 09/04/24 18:59:28.617
  I0904 18:59:28.617377 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename cronjob @ 09/04/24 18:59:28.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 18:59:28.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 18:59:28.639
  STEP: Creating a cronjob @ 09/04/24 18:59:28.642
  STEP: Ensuring more than one job is running at a time @ 09/04/24 18:59:28.647
  E0904 18:59:29.566725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:30.566941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:31.567044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:32.567240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:33.567341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:34.567552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:35.568609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:36.568845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:37.569677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:38.569783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:39.570685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:40.570785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:41.570892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:42.571082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:43.571193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:44.571296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:45.572228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:46.572336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:47.572443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:48.572524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:49.572691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:50.572793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:51.572886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:52.573134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:53.573622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:54.574707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:55.574808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:56.574903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:57.575014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:58.575103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 18:59:59.575247      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:00.575448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:01.575589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:02.575848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:03.576446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:04.576637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:05.576708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:06.576818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:07.576878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:08.576982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:09.577606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:10.577707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:11.577808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:12.577900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:13.578347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:14.578699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:15.579771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:16.579951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:17.580687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:18.581011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:19.581124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:20.581300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:21.581666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:22.582666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:23.583037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:24.583140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:25.583252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:26.583363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:27.583480      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:28.583593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:29.583697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:30.583920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:31.583961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:32.584049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:33.584167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:34.584235      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:35.585181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:36.585314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:37.585491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:38.585625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:39.586689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:40.586872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:41.587597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:42.587792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:43.587901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:44.588123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:45.588262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:46.588553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:47.588667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:48.588787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:49.589601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:50.589703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:51.590671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:52.590749      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:53.590886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:54.590975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:55.591084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:56.591159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:57.591269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:58.591504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:00:59.591649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:00.591825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 09/04/24 19:01:00.651
  STEP: Removing cronjob @ 09/04/24 19:01:00.655
  I0904 19:01:00.662786 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9723" for this suite. @ 09/04/24 19:01:00.666
• [92.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1396
  STEP: Creating a kubernetes client @ 09/04/24 19:01:00.676
  I0904 19:01:00.676350 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 19:01:00.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:01:00.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:01:00.709
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5781 @ 09/04/24 19:01:00.713
  STEP: changing the ExternalName service to type=ClusterIP @ 09/04/24 19:01:00.718
  STEP: creating replication controller externalname-service in namespace services-5781 @ 09/04/24 19:01:00.736
  I0904 19:01:00.742806      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5781, replica count: 2
  E0904 19:01:01.592047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:02.592267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:03.592372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:01:03.793754      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 19:01:03.793788 19 resource.go:361] Creating new exec pod
  E0904 19:01:04.593414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:05.593628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:06.593703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:01:06.813984 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5781 exec execpod4844j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0904 19:01:06.906122 19 builder.go:146] stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0904 19:01:06.906161 19 builder.go:147] stdout: "externalname-service-6pftv"
  I0904 19:01:06.906241 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5781 exec execpod4844j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.164 80'
  I0904 19:01:06.992352 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.164 80\n+ echo hostName\nConnection to 10.152.183.164 80 port [tcp/http] succeeded!\n"
  I0904 19:01:06.992393 19 builder.go:147] stdout: ""
  E0904 19:01:07.593817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:01:07.906353 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5781 exec execpod4844j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.164 80'
  I0904 19:01:07.993070 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.164 80\n+ echo hostName\nConnection to 10.152.183.164 80 port [tcp/http] succeeded!\n"
  I0904 19:01:07.993121 19 builder.go:147] stdout: ""
  E0904 19:01:08.594652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:01:08.907166 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5781 exec execpod4844j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.164 80'
  I0904 19:01:09.012427 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.164 80\n+ echo hostName\nConnection to 10.152.183.164 80 port [tcp/http] succeeded!\n"
  I0904 19:01:09.012466 19 builder.go:147] stdout: "externalname-service-6pftv"
  I0904 19:01:09.012619 19 service.go:1405] Cleaning up the ExternalName to ClusterIP test service
  I0904 19:01:09.033563 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5781" for this suite. @ 09/04/24 19:01:09.038
• [8.370 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 09/04/24 19:01:09.046
  I0904 19:01:09.046437 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename conformance-tests @ 09/04/24 19:01:09.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:01:09.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:01:09.066
  STEP: Getting node addresses @ 09/04/24 19:01:09.07
  I0904 19:01:09.070214 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0904 19:01:09.074948 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-5067" for this suite. @ 09/04/24 19:01:09.078
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 09/04/24 19:01:09.086
  I0904 19:01:09.086138 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 19:01:09.086
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:01:09.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:01:09.108
  STEP: Creating secret with name s-test-opt-del-b7a0004c-23cd-46d7-a8f0-021c6f5f342c @ 09/04/24 19:01:09.116
  STEP: Creating secret with name s-test-opt-upd-fbe653f8-74fc-4952-9475-7584f5905088 @ 09/04/24 19:01:09.12
  STEP: Creating the pod @ 09/04/24 19:01:09.125
  E0904 19:01:09.594746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:10.594866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-b7a0004c-23cd-46d7-a8f0-021c6f5f342c @ 09/04/24 19:01:11.18
  STEP: Updating secret s-test-opt-upd-fbe653f8-74fc-4952-9475-7584f5905088 @ 09/04/24 19:01:11.187
  STEP: Creating secret with name s-test-opt-create-641e2b3f-1514-44d3-a31e-e45bed9af96f @ 09/04/24 19:01:11.192
  STEP: waiting to observe update in volume @ 09/04/24 19:01:11.196
  E0904 19:01:11.594884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:12.595135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:13.595216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:14.595427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:15.596155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:16.596289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:17.596408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:18.596759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:19.596666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:20.596857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:21.597443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:22.597589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:23.598440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:24.599165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:25.599819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:26.599932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:27.599977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:28.600304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:29.601307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:30.601441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:31.601608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:32.601705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:33.602416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:34.602529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:35.603228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:36.603413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:37.603527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:38.603895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:39.604714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:40.604928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:41.605775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:42.605871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:43.606447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:44.606584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:45.606972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:46.607077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:47.607824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:48.607935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:49.608580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:50.608807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:51.608910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:52.609005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:53.609345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:54.609493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:55.609578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:56.609620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:57.610466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:58.610573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:01:59.610881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:00.610965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:01.614258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:02.614668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:03.614707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:04.614802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:05.614890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:06.614982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:07.615776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:08.615893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:09.616784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:10.616887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:11.617538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:12.617620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:13.618679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:14.618816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:15.619610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:16.619745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:17.619927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:18.620016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:19.620944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:20.621136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:02:21.515192 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-991" for this suite. @ 09/04/24 19:02:21.518
• [72.441 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1148
  STEP: Creating a kubernetes client @ 09/04/24 19:02:21.527
  I0904 19:02:21.527832 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename job @ 09/04/24 19:02:21.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:02:21.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:02:21.549
  STEP: Creating a suspended job @ 09/04/24 19:02:21.555
  STEP: Patching the Job @ 09/04/24 19:02:21.56
  STEP: Watching for Job to be patched @ 09/04/24 19:02:21.577
  I0904 19:02:21.579554 19 job.go:1330] Event ADDED observed for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k] and annotations: map[]
  I0904 19:02:21.579572 19 job.go:1330] Event MODIFIED observed for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k] and annotations: map[]
  I0904 19:02:21.579582 19 job.go:1333] Event MODIFIED found for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched] and annotations: map[]
  STEP: Updating the job @ 09/04/24 19:02:21.579
  STEP: Watching for Job to be updated @ 09/04/24 19:02:21.589
  I0904 19:02:21.591014 19 job.go:1333] Event MODIFIED found for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched] and annotations: map[updated:true]
  I0904 19:02:21.591038 19 job.go:1226] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 09/04/24 19:02:21.591
  I0904 19:02:21.594246 19 job.go:1233] Job: e2e-vlv7k as labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched]
  STEP: Waiting for job to complete @ 09/04/24 19:02:21.594
  E0904 19:02:21.621413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:22.621597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:23.622698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:24.622777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:25.623830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:26.623906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:27.624618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:28.624766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:29.625631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:30.626672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 09/04/24 19:02:31.604
  STEP: Watching for Job to be deleted @ 09/04/24 19:02:31.612
  I0904 19:02:31.614417 19 job.go:1330] Event MODIFIED observed for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched] and annotations: map[updated:true]
  I0904 19:02:31.614454 19 job.go:1330] Event MODIFIED observed for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched] and annotations: map[updated:true]
  I0904 19:02:31.614465 19 job.go:1330] Event MODIFIED observed for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched] and annotations: map[updated:true]
  I0904 19:02:31.614608 19 job.go:1330] Event MODIFIED observed for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched] and annotations: map[updated:true]
  I0904 19:02:31.614639 19 job.go:1330] Event MODIFIED observed for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched] and annotations: map[updated:true]
  I0904 19:02:31.614650 19 job.go:1333] Event DELETED found for Job e2e-vlv7k in namespace job-8384 with labels: map[e2e-job-label:e2e-vlv7k e2e-vlv7k:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 09/04/24 19:02:31.614
  I0904 19:02:31.620617 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0904 19:02:31.627669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "job-8384" for this suite. @ 09/04/24 19:02:31.637
• [10.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 09/04/24 19:02:31.651
  I0904 19:02:31.651571 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename gc @ 09/04/24 19:02:31.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:02:31.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:02:31.672
  STEP: create the deployment @ 09/04/24 19:02:31.675
  W0904 19:02:31.680034      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 09/04/24 19:02:31.68
  STEP: delete the deployment @ 09/04/24 19:02:32.184
  STEP: wait for all rs to be garbage collected @ 09/04/24 19:02:32.193
  STEP: expected 0 rs, got 1 rs @ 09/04/24 19:02:32.197
  STEP: expected 0 pods, got 2 pods @ 09/04/24 19:02:32.201
  E0904 19:02:32.627839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/04/24 19:02:32.706
  W0904 19:02:32.712176      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0904 19:02:32.712288 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0904 19:02:32.713029 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6037" for this suite. @ 09/04/24 19:02:32.716
• [1.073 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:312
  STEP: Creating a kubernetes client @ 09/04/24 19:02:32.724
  I0904 19:02:32.724172 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:02:32.724
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:02:32.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:02:32.743
  STEP: Setting up server cert @ 09/04/24 19:02:32.767
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:02:33.187
  STEP: Deploying the webhook pod @ 09/04/24 19:02:33.195
  STEP: Wait for the deployment to be ready @ 09/04/24 19:02:33.209
  I0904 19:02:33.217983 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:02:33.628539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:34.628731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:02:35.231
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:02:35.243
  E0904 19:02:35.629495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:02:36.243899 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0904 19:02:36.252910 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:02:36.629623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9313-crds.webhook.example.com via the AdmissionRegistration API @ 09/04/24 19:02:36.766
  STEP: Creating a custom resource while v1 is storage version @ 09/04/24 19:02:36.781
  E0904 19:02:37.630150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:38.630318      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 09/04/24 19:02:38.814
  STEP: Patching the custom resource while v2 is storage version @ 09/04/24 19:02:38.829
  I0904 19:02:39.424218 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8896" for this suite. @ 09/04/24 19:02:39.428
  STEP: Destroying namespace "webhook-markers-8303" for this suite. @ 09/04/24 19:02:39.435
• [6.721 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 09/04/24 19:02:39.445
  I0904 19:02:39.445118 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename csi-storageclass @ 09/04/24 19:02:39.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:02:39.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:02:39.462
  STEP: Creating a StorageClass @ 09/04/24 19:02:39.466
  STEP: Get StorageClass "e2e-mzblc" @ 09/04/24 19:02:39.472
  STEP: Patching the StorageClass "e2e-mzblc" @ 09/04/24 19:02:39.475
  STEP: Delete StorageClass "e2e-mzblc" @ 09/04/24 19:02:39.481
  STEP: Confirm deletion of StorageClass "e2e-mzblc" @ 09/04/24 19:02:39.487
  STEP: Create a replacement StorageClass @ 09/04/24 19:02:39.49
  STEP: Updating StorageClass "e2e-v2-d9r7t" @ 09/04/24 19:02:39.494
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-d9r7t=updated" @ 09/04/24 19:02:39.502
  STEP: Deleting StorageClass "e2e-v2-d9r7t" via DeleteCollection @ 09/04/24 19:02:39.505
  STEP: Confirm deletion of StorageClass "e2e-v2-d9r7t" @ 09/04/24 19:02:39.512
  I0904 19:02:39.515895 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-769" for this suite. @ 09/04/24 19:02:39.52
• [0.083 seconds]
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 09/04/24 19:02:39.528
  I0904 19:02:39.528251 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-runtime @ 09/04/24 19:02:39.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:02:39.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:02:39.549
  STEP: create the container @ 09/04/24 19:02:39.556
  W0904 19:02:39.564193      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 09/04/24 19:02:39.564
  E0904 19:02:39.630689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:40.630746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:41.631579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/04/24 19:02:42.583
  STEP: the container should be terminated @ 09/04/24 19:02:42.588
  STEP: the termination message should be set @ 09/04/24 19:02:42.588
  I0904 19:02:42.588506 19 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 09/04/24 19:02:42.588
  I0904 19:02:42.607393 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3701" for this suite. @ 09/04/24 19:02:42.61
• [3.088 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:788
  STEP: Creating a kubernetes client @ 09/04/24 19:02:42.616
  I0904 19:02:42.616465 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename job @ 09/04/24 19:02:42.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:02:42.631
  E0904 19:02:42.632281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:02:42.636
  STEP: Creating a job @ 09/04/24 19:02:42.64
  STEP: Ensuring job reaches completions @ 09/04/24 19:02:42.645
  E0904 19:02:43.632110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:44.632323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:45.632426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:46.632652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:47.632770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:48.633053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:49.633632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:50.633721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:51.633821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:52.633918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:53.634047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:54.634704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:02:54.657988 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8015" for this suite. @ 09/04/24 19:02:54.663
• [12.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:796
  STEP: Creating a kubernetes client @ 09/04/24 19:02:54.671
  I0904 19:02:54.671584 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename statefulset @ 09/04/24 19:02:54.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:02:54.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:02:54.695
  STEP: Creating service test in namespace statefulset-4783 @ 09/04/24 19:02:54.698
  STEP: Looking for a node to schedule stateful set and pod @ 09/04/24 19:02:54.707
  STEP: Creating pod with conflicting port in namespace statefulset-4783 @ 09/04/24 19:02:54.715
  STEP: Waiting until pod test-pod will start running in namespace statefulset-4783 @ 09/04/24 19:02:54.722
  E0904 19:02:55.634814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:56.634942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-4783 @ 09/04/24 19:02:56.73
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4783 @ 09/04/24 19:02:56.737
  I0904 19:02:56.755447 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4783, name: ss-0, uid: db74cef2-1a27-424a-bd82-8be04cb569ca, status phase: Pending. Waiting for statefulset controller to delete.
  I0904 19:02:56.776241 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4783, name: ss-0, uid: db74cef2-1a27-424a-bd82-8be04cb569ca, status phase: Failed. Waiting for statefulset controller to delete.
  I0904 19:02:56.784877 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4783, name: ss-0, uid: db74cef2-1a27-424a-bd82-8be04cb569ca, status phase: Failed. Waiting for statefulset controller to delete.
  I0904 19:02:56.789802 19 statefulset.go:863] Observed delete event for stateful pod ss-0 in namespace statefulset-4783
  STEP: Removing pod with conflicting port in namespace statefulset-4783 @ 09/04/24 19:02:56.789
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4783 and will be in running state @ 09/04/24 19:02:56.809
  E0904 19:02:57.635023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:02:58.635134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:02:58.820756 19 statefulset.go:138] Deleting all statefulset in ns statefulset-4783
  I0904 19:02:58.824558 19 rest.go:150] Scaling statefulset ss to 0
  E0904 19:02:59.635208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:00.635320      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:01.635405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:02.635505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:03.635634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:04.635750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:05.635838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:06.636032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:07.636219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:08.636270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:03:08.838465 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0904 19:03:08.842250 19 rest.go:88] Deleting statefulset ss
  I0904 19:03:08.859299 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4783" for this suite. @ 09/04/24 19:03:08.862
• [14.197 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 09/04/24 19:03:08.869
  I0904 19:03:08.869354 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename cronjob @ 09/04/24 19:03:08.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:03:08.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:03:08.89
  STEP: Creating a suspended cronjob @ 09/04/24 19:03:08.893
  STEP: Ensuring no jobs are scheduled @ 09/04/24 19:03:08.9
  E0904 19:03:09.637074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:10.637234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:11.637366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:12.637431      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:13.637552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:14.637638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:15.637727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:16.637855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:17.637972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:18.638290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:19.638374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:20.638666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:21.639538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:22.639629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:23.640488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:24.640578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:25.640883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:26.641062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:27.642044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:28.642927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:29.643026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:30.643264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:31.643901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:32.644007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:33.644648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:34.644743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:35.644936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:36.645081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:37.646095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:38.646641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:39.646768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:40.647114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:41.647217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:42.647483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:43.647574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:44.647773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:45.648645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:46.648755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:47.649425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:48.649578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:49.650250      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:50.650660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:51.650710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:52.650795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:53.650909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:54.651148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:55.651243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:56.651421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:57.651833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:58.652145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:03:59.652830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:00.653005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:01.653032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:02.653213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:03.653580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:04.654639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:05.654734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:06.654927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:07.655050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:08.655358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:09.655495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:10.655697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:11.656300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:12.656441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:13.657315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:14.657419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:15.657586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:16.657645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:17.657705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:18.657813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:19.657954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:20.658643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:21.658726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:22.658992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:23.659940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:24.660675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:25.661120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:26.661845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:27.662665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:28.663584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:29.664600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:30.664705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:31.665373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:32.665590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:33.666442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:34.666547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:35.666646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:36.666832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:37.667760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:38.667841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:39.668238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:40.668473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:41.668556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:42.668854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:43.668957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:44.669891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:45.669979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:46.670770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:47.671481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:48.671591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:49.671737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:50.672069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:51.672513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:52.672733      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:53.673799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:54.673936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:55.674645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:56.674753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:57.674836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:58.674879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:04:59.675095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:00.675183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:01.676109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:02.676281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:03.677353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:04.677553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:05.678339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:06.678514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:07.679396      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:08.679580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:09.680027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:10.680162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:11.680546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:12.680818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:13.681745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:14.681821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:15.681901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:16.681995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:17.682097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:18.682365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:19.682661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:20.682790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:21.683778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:22.683940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:23.684751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:24.685559      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:25.685652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:26.686678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:27.686727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:28.686813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:29.687809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:30.687967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:31.688072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:32.688252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:33.689032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:34.689144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:35.689987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:36.690077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:37.690212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:38.690298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:39.690555      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:40.690785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:41.691298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:42.691691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:43.692763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:44.692949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:45.693438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:46.693592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:47.694631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:48.694795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:49.695464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:50.695640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:51.696737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:52.697731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:53.698141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:54.698655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:55.698847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:56.698920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:57.699583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:58.700358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:05:59.700826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:00.700912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:01.701925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:02.702727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:03.703232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:04.703479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:05.703932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:06.704043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:07.704718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:08.705545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:09.705584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:10.705685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:11.706669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:12.706741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:13.706945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:14.707127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:15.708170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:16.708420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:17.708798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:18.708995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:19.709091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:20.709191      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:21.709940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:22.710316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:23.711139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:24.711226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:25.712265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:26.712452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:27.713226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:28.713339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:29.714402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:30.714716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:31.714979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:32.715355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:33.715910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:34.716002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:35.717074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:36.717185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:37.717282      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:38.717516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:39.718107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:40.718674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:41.719418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:42.719734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:43.719902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:44.720696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:45.721735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:46.722668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:47.723713      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:48.723841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:49.724560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:50.724771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:51.725594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:52.725898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:53.726667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:54.726852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:55.727016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:56.727230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:57.727477      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:58.727750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:06:59.728650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:00.728743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:01.729537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:02.729754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:03.729916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:04.730024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:05.730892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:06.731115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:07.732168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:08.732366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:09.733311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:10.733574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:11.733922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:12.733956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:13.734423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:14.734623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:15.735397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:16.735614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:17.735661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:18.735993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:19.736571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:20.736677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:21.737688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:22.738744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:23.738789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:24.738943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:25.738996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:26.739454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:27.740225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:28.740314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:29.740734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:30.740824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:31.740853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:32.741738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:33.742682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:34.742795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:35.743814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:36.744063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:37.744406      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:38.744598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:39.744779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:40.744990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:41.745930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:42.745983      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:43.746404      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:44.746513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:45.747556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:46.747732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:47.748346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:48.748492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:49.748677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:50.748748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:51.748772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:52.749745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:53.749876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:54.750185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:55.750440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:56.751140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:57.751557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:58.751737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:07:59.752805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:00.752905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:01.753002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:02.753362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:03.754447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:04.754550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:05.754956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:06.755052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:07.755947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:08.756189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 09/04/24 19:08:08.901
  STEP: Removing cronjob @ 09/04/24 19:08:08.905
  I0904 19:08:08.912678 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-63" for this suite. @ 09/04/24 19:08:08.916
• [300.055 seconds]
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 09/04/24 19:08:08.924
  I0904 19:08:08.924089 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename podtemplate @ 09/04/24 19:08:08.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:08.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:08.942
  STEP: Create set of pod templates @ 09/04/24 19:08:08.945
  I0904 19:08:08.952613 19 podtemplates.go:143] created test-podtemplate-1
  I0904 19:08:08.956844 19 podtemplates.go:143] created test-podtemplate-2
  I0904 19:08:08.961912 19 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 09/04/24 19:08:08.961
  STEP: delete collection of pod templates @ 09/04/24 19:08:08.965
  I0904 19:08:08.965578 19 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 09/04/24 19:08:08.982
  I0904 19:08:08.982543 19 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0904 19:08:08.986972 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8454" for this suite. @ 09/04/24 19:08:08.994
• [0.079 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1435
  STEP: Creating a kubernetes client @ 09/04/24 19:08:09.003
  I0904 19:08:09.003359 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 19:08:09.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:09.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:09.135
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-906 @ 09/04/24 19:08:09.139
  STEP: changing the ExternalName service to type=NodePort @ 09/04/24 19:08:09.145
  STEP: creating replication controller externalname-service in namespace services-906 @ 09/04/24 19:08:09.165
  I0904 19:08:09.174138      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-906, replica count: 2
  E0904 19:08:09.756904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:10.757384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:11.757615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:12.225009      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 19:08:12.225055 19 resource.go:361] Creating new exec pod
  E0904 19:08:12.757710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:13.757816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:14.758610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:15.249137 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-906 exec execpodqc99l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0904 19:08:15.345845 19 builder.go:146] stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0904 19:08:15.345881 19 builder.go:147] stdout: "externalname-service-7fxsx"
  I0904 19:08:15.346011 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-906 exec execpodqc99l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.43 80'
  I0904 19:08:15.432744 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.43 80\n+ echo hostName\nConnection to 10.152.183.43 80 port [tcp/http] succeeded!\n"
  I0904 19:08:15.432787 19 builder.go:147] stdout: "externalname-service-7fxsx"
  I0904 19:08:15.432865 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-906 exec execpodqc99l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.223 31697'
  I0904 19:08:15.521123 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.7.223 31697\n+ echo hostName\nConnection to 172.31.7.223 31697 port [tcp/*] succeeded!\n"
  I0904 19:08:15.521161 19 builder.go:147] stdout: ""
  E0904 19:08:15.759562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:16.432980 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-906 exec execpodqc99l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.223 31697'
  I0904 19:08:16.521600 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.7.223 31697\n+ echo hostName\nConnection to 172.31.7.223 31697 port [tcp/*] succeeded!\n"
  I0904 19:08:16.521638 19 builder.go:147] stdout: ""
  E0904 19:08:16.759734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:17.433561 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-906 exec execpodqc99l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.223 31697'
  I0904 19:08:17.521219 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.7.223 31697\n+ echo hostName\nConnection to 172.31.7.223 31697 port [tcp/*] succeeded!\n"
  I0904 19:08:17.521257 19 builder.go:147] stdout: ""
  E0904 19:08:17.760757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:18.433701 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-906 exec execpodqc99l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.223 31697'
  I0904 19:08:18.520949 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.7.223 31697\n+ echo hostName\nConnection to 172.31.7.223 31697 port [tcp/*] succeeded!\n"
  I0904 19:08:18.520988 19 builder.go:147] stdout: "externalname-service-9rjpj"
  I0904 19:08:18.521120 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-906 exec execpodqc99l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.40.239 31697'
  I0904 19:08:18.613025 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.40.239 31697\n+ echo hostName\nConnection to 172.31.40.239 31697 port [tcp/*] succeeded!\n"
  I0904 19:08:18.613078 19 builder.go:147] stdout: ""
  E0904 19:08:18.761260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:19.522174 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-906 exec execpodqc99l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.40.239 31697'
  I0904 19:08:19.611887 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.40.239 31697\n+ echo hostName\nConnection to 172.31.40.239 31697 port [tcp/*] succeeded!\n"
  I0904 19:08:19.611926 19 builder.go:147] stdout: "externalname-service-7fxsx"
  I0904 19:08:19.612064 19 service.go:1444] Cleaning up the ExternalName to NodePort test service
  I0904 19:08:19.637311 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-906" for this suite. @ 09/04/24 19:08:19.641
• [10.648 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 09/04/24 19:08:19.651
  I0904 19:08:19.651923 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename endpointslice @ 09/04/24 19:08:19.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:19.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:19.673
  STEP: getting /apis @ 09/04/24 19:08:19.676
  STEP: getting /apis/discovery.k8s.io @ 09/04/24 19:08:19.679
  STEP: getting /apis/discovery.k8s.iov1 @ 09/04/24 19:08:19.681
  STEP: creating @ 09/04/24 19:08:19.682
  STEP: getting @ 09/04/24 19:08:19.699
  STEP: listing @ 09/04/24 19:08:19.702
  STEP: watching @ 09/04/24 19:08:19.706
  I0904 19:08:19.706105 19 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 09/04/24 19:08:19.707
  STEP: cluster-wide watching @ 09/04/24 19:08:19.711
  I0904 19:08:19.711623 19 endpointslice.go:459] starting watch
  STEP: patching @ 09/04/24 19:08:19.713
  STEP: updating @ 09/04/24 19:08:19.717
  I0904 19:08:19.728688 19 endpointslice.go:482] waiting for watch events with expected annotations
  I0904 19:08:19.728719 19 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 09/04/24 19:08:19.728
  STEP: deleting a collection @ 09/04/24 19:08:19.741
  I0904 19:08:19.757685 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0904 19:08:19.761745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "endpointslice-5144" for this suite. @ 09/04/24 19:08:19.762
• [0.120 seconds]
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 09/04/24 19:08:19.771
  I0904 19:08:19.771692 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replication-controller @ 09/04/24 19:08:19.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:19.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:19.793
  STEP: Given a ReplicationController is created @ 09/04/24 19:08:19.798
  STEP: When the matched label of one of its pods change @ 09/04/24 19:08:19.805
  I0904 19:08:19.808476 19 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  E0904 19:08:20.761906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:21.762004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:22.762680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:23.762903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:24.762989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:24.812996 19 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 09/04/24 19:08:24.824
  E0904 19:08:25.763079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:25.834296 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9445" for this suite. @ 09/04/24 19:08:25.837
• [6.074 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 09/04/24 19:08:25.845
  I0904 19:08:25.845371 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename gc @ 09/04/24 19:08:25.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:25.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:25.863
  STEP: create the deployment @ 09/04/24 19:08:25.866
  W0904 19:08:25.871853      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 09/04/24 19:08:25.871
  STEP: delete the deployment @ 09/04/24 19:08:26.379
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 09/04/24 19:08:26.387
  E0904 19:08:26.763195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/04/24 19:08:26.904
  W0904 19:08:26.911271      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0904 19:08:26.911371 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0904 19:08:26.912072 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7795" for this suite. @ 09/04/24 19:08:26.916
• [1.078 seconds]
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:337
  STEP: Creating a kubernetes client @ 09/04/24 19:08:26.923
  I0904 19:08:26.923531 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 19:08:26.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:26.939
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:26.943
  STEP: creating a replication controller @ 09/04/24 19:08:26.946
  I0904 19:08:26.946500 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 create -f -'
  I0904 19:08:27.059040 19 builder.go:146] stderr: ""
  I0904 19:08:27.062423 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/04/24 19:08:27.062
  I0904 19:08:27.062527 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0904 19:08:27.139679 19 builder.go:146] stderr: ""
  I0904 19:08:27.139720 19 builder.go:147] stdout: "update-demo-nautilus-7lph6 update-demo-nautilus-k9kg6 "
  I0904 19:08:27.139752 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods update-demo-nautilus-7lph6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:08:27.182526 19 builder.go:146] stderr: ""
  I0904 19:08:27.182564 19 builder.go:147] stdout: ""
  I0904 19:08:27.182572 19 kubectl.go:2502] update-demo-nautilus-7lph6 is created but not running
  E0904 19:08:27.763418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:28.763499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:29.763574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:30.763728      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:31.764259      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:32.183625 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0904 19:08:32.282124 19 builder.go:146] stderr: ""
  I0904 19:08:32.282167 19 builder.go:147] stdout: "update-demo-nautilus-7lph6 update-demo-nautilus-k9kg6 "
  I0904 19:08:32.282209 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods update-demo-nautilus-7lph6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:08:32.329188 19 builder.go:146] stderr: ""
  I0904 19:08:32.329234 19 builder.go:147] stdout: "true"
  I0904 19:08:32.329273 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods update-demo-nautilus-7lph6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0904 19:08:32.371277 19 builder.go:146] stderr: ""
  I0904 19:08:32.371307 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0904 19:08:32.371319 19 kubectl.go:2393] validating pod update-demo-nautilus-7lph6
  I0904 19:08:32.378249 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0904 19:08:32.378344 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0904 19:08:32.378359 19 kubectl.go:2520] update-demo-nautilus-7lph6 is verified up and running
  I0904 19:08:32.378397 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods update-demo-nautilus-k9kg6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:08:32.420776 19 builder.go:146] stderr: ""
  I0904 19:08:32.420800 19 builder.go:147] stdout: ""
  I0904 19:08:32.420808 19 kubectl.go:2502] update-demo-nautilus-k9kg6 is created but not running
  E0904 19:08:32.764359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:33.764539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:34.764731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:35.764854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:36.764966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:37.421819 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0904 19:08:37.464899 19 builder.go:146] stderr: ""
  I0904 19:08:37.464946 19 builder.go:147] stdout: "update-demo-nautilus-7lph6 update-demo-nautilus-k9kg6 "
  I0904 19:08:37.464984 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods update-demo-nautilus-7lph6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:08:37.503085 19 builder.go:146] stderr: ""
  I0904 19:08:37.503117 19 builder.go:147] stdout: "true"
  I0904 19:08:37.503153 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods update-demo-nautilus-7lph6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0904 19:08:37.541809 19 builder.go:146] stderr: ""
  I0904 19:08:37.541850 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0904 19:08:37.541861 19 kubectl.go:2393] validating pod update-demo-nautilus-7lph6
  I0904 19:08:37.546967 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0904 19:08:37.547045 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0904 19:08:37.547060 19 kubectl.go:2520] update-demo-nautilus-7lph6 is verified up and running
  I0904 19:08:37.547118 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods update-demo-nautilus-k9kg6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:08:37.584627 19 builder.go:146] stderr: ""
  I0904 19:08:37.584653 19 builder.go:147] stdout: "true"
  I0904 19:08:37.584689 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods update-demo-nautilus-k9kg6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0904 19:08:37.623107 19 builder.go:146] stderr: ""
  I0904 19:08:37.623139 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0904 19:08:37.623148 19 kubectl.go:2393] validating pod update-demo-nautilus-k9kg6
  I0904 19:08:37.630035 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0904 19:08:37.630074 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0904 19:08:37.630099 19 kubectl.go:2520] update-demo-nautilus-k9kg6 is verified up and running
  STEP: using delete to clean up resources @ 09/04/24 19:08:37.63
  I0904 19:08:37.630191 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 delete --grace-period=0 --force -f -'
  I0904 19:08:37.675266 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 19:08:37.675294 19 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0904 19:08:37.675338 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get rc,svc -l name=update-demo --no-headers'
  I0904 19:08:37.730724 19 builder.go:146] stderr: "No resources found in kubectl-344 namespace.\n"
  I0904 19:08:37.730759 19 builder.go:147] stdout: ""
  I0904 19:08:37.730799 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-344 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  E0904 19:08:37.765800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:37.792458 19 builder.go:146] stderr: ""
  I0904 19:08:37.792514 19 builder.go:147] stdout: ""
  I0904 19:08:37.792616 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-344" for this suite. @ 09/04/24 19:08:37.797
• [10.881 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1260
  STEP: Creating a kubernetes client @ 09/04/24 19:08:37.804
  I0904 19:08:37.804853 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 19:08:37.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:37.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:37.823
  STEP: creating service nodeport-test with type=NodePort in namespace services-4224 @ 09/04/24 19:08:37.827
  STEP: creating replication controller nodeport-test in namespace services-4224 @ 09/04/24 19:08:37.853
  I0904 19:08:37.860620      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4224, replica count: 2
  E0904 19:08:38.766357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:39.766505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:40.766609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:40.911909      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 19:08:40.911940 19 resource.go:361] Creating new exec pod
  E0904 19:08:41.766709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:42.767139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:43.767256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:43.935724 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-4224 exec execpod6jsc6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0904 19:08:44.025777 19 builder.go:146] stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I0904 19:08:44.025816 19 builder.go:147] stdout: "nodeport-test-zw9nt"
  I0904 19:08:44.025945 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-4224 exec execpod6jsc6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.36 80'
  I0904 19:08:44.112550 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.36 80\n+ echo hostName\nConnection to 10.152.183.36 80 port [tcp/http] succeeded!\n"
  I0904 19:08:44.112595 19 builder.go:147] stdout: ""
  E0904 19:08:44.767296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:45.026658 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-4224 exec execpod6jsc6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.36 80'
  I0904 19:08:45.114575 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.36 80\nConnection to 10.152.183.36 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0904 19:08:45.114618 19 builder.go:147] stdout: "nodeport-test-9qclg"
  I0904 19:08:45.114805 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-4224 exec execpod6jsc6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.40.239 30959'
  I0904 19:08:45.204836 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.40.239 30959\nConnection to 172.31.40.239 30959 port [tcp/*] succeeded!\n"
  I0904 19:08:45.204874 19 builder.go:147] stdout: "nodeport-test-zw9nt"
  I0904 19:08:45.204971 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-4224 exec execpod6jsc6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.21.169 30959'
  I0904 19:08:45.292532 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.21.169 30959\n+ echo hostName\nConnection to 172.31.21.169 30959 port [tcp/*] succeeded!\n"
  I0904 19:08:45.292570 19 builder.go:147] stdout: ""
  E0904 19:08:45.768205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:46.205924 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-4224 exec execpod6jsc6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.21.169 30959'
  I0904 19:08:46.290773 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.21.169 30959\n+ echo hostName\nConnection to 172.31.21.169 30959 port [tcp/*] succeeded!\n"
  I0904 19:08:46.290810 19 builder.go:147] stdout: ""
  E0904 19:08:46.768362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:47.206006 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-4224 exec execpod6jsc6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.21.169 30959'
  I0904 19:08:47.291615 19 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.21.169 30959\nConnection to 172.31.21.169 30959 port [tcp/*] succeeded!\n+ echo hostName\n"
  I0904 19:08:47.291655 19 builder.go:147] stdout: "nodeport-test-9qclg"
  I0904 19:08:47.291896 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4224" for this suite. @ 09/04/24 19:08:47.295
• [9.498 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 09/04/24 19:08:47.303
  I0904 19:08:47.303296 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 19:08:47.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:47.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:47.324
  STEP: creating pod @ 09/04/24 19:08:47.331
  E0904 19:08:47.769515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:48.769665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:08:49.360859 19 pods.go:83] Pod pod-hostip-3a14ccaa-94dc-4021-acc7-8903b6ef794b has hostIP: 172.31.40.239
  I0904 19:08:49.360962 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5155" for this suite. @ 09/04/24 19:08:49.365
• [2.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 09/04/24 19:08:49.372
  I0904 19:08:49.372239 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename namespaces @ 09/04/24 19:08:49.372
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:49.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:49.393
  STEP: Read namespace status @ 09/04/24 19:08:49.399
  I0904 19:08:49.403455 19 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 09/04/24 19:08:49.403
  I0904 19:08:49.409019 19 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 09/04/24 19:08:49.409
  I0904 19:08:49.419616 19 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0904 19:08:49.419687 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2991" for this suite. @ 09/04/24 19:08:49.423
• [0.059 seconds]
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 09/04/24 19:08:49.431
  I0904 19:08:49.431492 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pod-network-test @ 09/04/24 19:08:49.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:08:49.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:08:49.451
  STEP: Performing setup for networking test in namespace pod-network-test-6321 @ 09/04/24 19:08:49.455
  STEP: creating a selector @ 09/04/24 19:08:49.455
  STEP: Creating the service pods in kubernetes @ 09/04/24 19:08:49.455
  I0904 19:08:49.455403 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0904 19:08:49.769809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:50.769881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:51.770654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:52.770858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:53.771644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:54.771746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:55.772412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:56.772512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:57.773522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:58.773669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:08:59.774289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:00.774698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:01.775081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:02.775379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:03.775894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:04.776004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:05.776789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:06.776881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:07.777799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:08.777916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:09.778972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:10.779449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/04/24 19:09:11.558
  E0904 19:09:11.780215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:12.780420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:09:13.577672 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0904 19:09:13.577699 19 networking.go:42] Breadth first check of 192.168.146.178 on host 172.31.21.169...
  I0904 19:09:13.581186 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.146.179:9080/dial?request=hostname&protocol=udp&host=192.168.146.178&port=8081&tries=1'] Namespace:pod-network-test-6321 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:09:13.581206 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:09:13.581636 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:09:13.581676 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6321/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.146.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.146.178%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0904 19:09:13.627812 19 utils.go:356] Waiting for responses: map[]
  I0904 19:09:13.627861 19 utils.go:360] reached 192.168.146.178 after 0/1 tries
  I0904 19:09:13.627879 19 networking.go:42] Breadth first check of 192.168.104.162 on host 172.31.40.239...
  I0904 19:09:13.632842 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.146.179:9080/dial?request=hostname&protocol=udp&host=192.168.104.162&port=8081&tries=1'] Namespace:pod-network-test-6321 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:09:13.632865 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:09:13.633248 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:09:13.633309 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6321/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.146.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.104.162%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0904 19:09:13.680425 19 utils.go:356] Waiting for responses: map[]
  I0904 19:09:13.680452 19 utils.go:360] reached 192.168.104.162 after 0/1 tries
  I0904 19:09:13.680460 19 networking.go:42] Breadth first check of 192.168.243.63 on host 172.31.7.223...
  I0904 19:09:13.683826 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.146.179:9080/dial?request=hostname&protocol=udp&host=192.168.243.63&port=8081&tries=1'] Namespace:pod-network-test-6321 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:09:13.683842 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:09:13.684225 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:09:13.684263 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6321/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.146.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.243.63%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0904 19:09:13.736526 19 utils.go:356] Waiting for responses: map[]
  I0904 19:09:13.736575 19 utils.go:360] reached 192.168.243.63 after 0/1 tries
  I0904 19:09:13.736585 19 networking.go:53] Going to retry 0 out of 3 pods....
  I0904 19:09:13.736681 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6321" for this suite. @ 09/04/24 19:09:13.741
• [24.317 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 09/04/24 19:09:13.748
  I0904 19:09:13.748844 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replication-controller @ 09/04/24 19:09:13.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:09:13.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:09:13.768
  I0904 19:09:13.771166 19 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0904 19:09:13.780566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:14.780698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 09/04/24 19:09:14.784
  STEP: Checking rc "condition-test" has the desired failure condition set @ 09/04/24 19:09:14.79
  E0904 19:09:15.780768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 09/04/24 19:09:15.8
  I0904 19:09:15.812609 19 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 09/04/24 19:09:15.812
  I0904 19:09:15.817286 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2144" for this suite. @ 09/04/24 19:09:15.82
• [2.082 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 09/04/24 19:09:15.831
  I0904 19:09:15.831189 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename init-container @ 09/04/24 19:09:15.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:09:15.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:09:15.854
  STEP: creating the pod @ 09/04/24 19:09:15.857
  I0904 19:09:15.857967 19 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E0904 19:09:16.781348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:17.781758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:18.782029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:19.781963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:20.782704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:21.782887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:22.783190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:23.783343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:24.783518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:25.783714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:26.783872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:27.784185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:28.784363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:29.784578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:30.784775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:31.784968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:32.785571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:33.785617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:34.785720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:35.785801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:36.785889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:37.786821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:38.787001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:39.787206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:40.787413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:41.787624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:42.787930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:43.788870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:44.789799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:45.789919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:46.789966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:47.790658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:48.790760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:49.790860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:50.791076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:51.791237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:52.791329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:53.791506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:54.791660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:55.791850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:56.792056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:57.793103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:09:58.391998 19 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-13fd8f05-dec2-4fee-8fc6-b4b659e58f31", GenerateName:"", Namespace:"init-container-4324", SelfLink:"", UID:"37f06b8a-f740-416e-810c-ff98e48cdc55", ResourceVersion:"31926", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 9, 15, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"857959833"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 9, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0035a66c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 9, 58, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0035a6738), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-n9lm9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004fd8ba0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil), Image:(*v1.ImageVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-n9lm9", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-n9lm9", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.10", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-n9lm9", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0007df300), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-40-239", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002cf4f00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007df390)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007df3b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0007df3b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0007df3bc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0050aaa50), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 4, 19, 9, 17, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 4, 19, 9, 15, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 4, 19, 9, 15, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 4, 19, 9, 15, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 4, 19, 9, 15, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.40.239", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.31.40.239"}}, PodIP:"192.168.104.184", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.104.184"}}, StartTime:time.Date(2024, time.September, 4, 19, 9, 15, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000430230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004302a0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://d03c837e9bd06ed9dcba063ea53fe034c4545fbd30e4f9e2c3539eb52d00cc77", Started:(*bool)(0xc0007df46a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-n9lm9", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0050aaa90)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004fd8c00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0007df47d), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-n9lm9", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0050aaaa0)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004fd8be0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.10", ImageID:"", ContainerID:"", Started:(*bool)(0xc0007df434), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-n9lm9", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0050aaa60)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I0904 19:09:58.392186 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-4324" for this suite. @ 09/04/24 19:09:58.398
• [42.575 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:406
  STEP: Creating a kubernetes client @ 09/04/24 19:09:58.406
  I0904 19:09:58.406236 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/04/24 19:09:58.406
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:09:58.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:09:58.426
  STEP: getting /apis @ 09/04/24 19:09:58.436
  STEP: getting /apis/admissionregistration.k8s.io @ 09/04/24 19:09:58.44
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 09/04/24 19:09:58.441
  STEP: creating @ 09/04/24 19:09:58.443
  STEP: getting @ 09/04/24 19:09:58.47
  STEP: listing @ 09/04/24 19:09:58.474
  STEP: watching @ 09/04/24 19:09:58.478
  I0904 19:09:58.479004 19 validatingadmissionpolicy.go:523] starting watch
  STEP: patching @ 09/04/24 19:09:58.481
  STEP: updating @ 09/04/24 19:09:58.489
  I0904 19:09:58.520867 19 validatingadmissionpolicy.go:552] waiting for watch events with expected annotations
  STEP: getting /status @ 09/04/24 19:09:58.52
  STEP: patching /status @ 09/04/24 19:09:58.534
  STEP: updating /status @ 09/04/24 19:09:58.541
  STEP: deleting @ 09/04/24 19:09:58.555
  STEP: deleting a collection @ 09/04/24 19:09:58.573
  I0904 19:09:58.591515 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-2127" for this suite. @ 09/04/24 19:09:58.594
• [0.196 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 09/04/24 19:09:58.602
  I0904 19:09:58.602428 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 19:09:58.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:09:58.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:09:58.622
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 09/04/24 19:09:58.625
  E0904 19:09:58.793182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:09:59.793301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:00.794339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:01.794452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:10:02.654
  I0904 19:10:02.657585 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-fcd2fd65-1aea-4f1a-aa71-0a4edc857d24 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:10:02.674
  I0904 19:10:02.694992 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5727" for this suite. @ 09/04/24 19:10:02.699
• [4.104 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 09/04/24 19:10:02.706
  I0904 19:10:02.706425 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 19:10:02.706
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:10:02.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:10:02.726
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 09/04/24 19:10:02.729
  E0904 19:10:02.795022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:03.795206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:04.796236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:05.796360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:10:06.756
  I0904 19:10:06.760561 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-f55b1213-ea60-41e4-802e-b6d54f5432d3 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:10:06.765
  I0904 19:10:06.784137 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-558" for this suite. @ 09/04/24 19:10:06.788
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:302
  E0904 19:10:06.796688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a kubernetes client @ 09/04/24 19:10:06.796
  I0904 19:10:06.796807 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename security-context @ 09/04/24 19:10:06.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:10:06.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:10:06.818
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 09/04/24 19:10:06.822
  E0904 19:10:07.797906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:08.797981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:09.798891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:10.799011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:10:10.844
  I0904 19:10:10.848648 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod security-context-47ac8bc9-8b49-4f4e-86cc-2f994c638631 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:10:10.856
  I0904 19:10:10.885681 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-9335" for this suite. @ 09/04/24 19:10:10.889
• [4.101 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 09/04/24 19:10:10.898
  I0904 19:10:10.898035 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 19:10:10.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:10:10.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:10:10.925
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 09/04/24 19:10:10.928
  E0904 19:10:11.799203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:12.800270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:13.800823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:14.800917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:10:14.964
  I0904 19:10:14.967616 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-b779aa31-5d55-4cfe-9763-e55be4ca34f7 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:10:14.974
  I0904 19:10:14.992596 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2213" for this suite. @ 09/04/24 19:10:14.996
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 09/04/24 19:10:15.003
  I0904 19:10:15.003707 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 19:10:15.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:10:15.02
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:10:15.023
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 09/04/24 19:10:15.027
  E0904 19:10:15.801288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:16.801401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:10:17.047
  I0904 19:10:17.051615 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-1c4ab80e-ed9b-4f95-8e12-47e73b36a132 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:10:17.057
  I0904 19:10:17.073601 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3768" for this suite. @ 09/04/24 19:10:17.077
• [2.080 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1066
  STEP: Creating a kubernetes client @ 09/04/24 19:10:17.084
  I0904 19:10:17.084346 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 19:10:17.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:10:17.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:10:17.113
  STEP: Creating resourceQuota "e2e-rq-status-78qpb" @ 09/04/24 19:10:17.119
  I0904 19:10:17.132793 19 resource_quota.go:1102] Resource quota "e2e-rq-status-78qpb" reports spec: hard cpu limit of 500m
  I0904 19:10:17.132812 19 resource_quota.go:1104] Resource quota "e2e-rq-status-78qpb" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-78qpb" /status @ 09/04/24 19:10:17.132
  STEP: Confirm /status for "e2e-rq-status-78qpb" resourceQuota via watch @ 09/04/24 19:10:17.146
  I0904 19:10:17.148316 19 resource_quota.go:1131] observed resourceQuota "e2e-rq-status-78qpb" in namespace "resourcequota-7226" with hard status: v1.ResourceList(nil)
  I0904 19:10:17.148393 19 resource_quota.go:1134] Found resourceQuota "e2e-rq-status-78qpb" in namespace "resourcequota-7226" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0904 19:10:17.148405 19 resource_quota.go:1141] ResourceQuota "e2e-rq-status-78qpb" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 09/04/24 19:10:17.151
  I0904 19:10:17.158447 19 resource_quota.go:1152] Resource quota "e2e-rq-status-78qpb" reports spec: hard cpu limit of 1
  I0904 19:10:17.158469 19 resource_quota.go:1153] Resource quota "e2e-rq-status-78qpb" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-78qpb" /status @ 09/04/24 19:10:17.158
  STEP: Confirm /status for "e2e-rq-status-78qpb" resourceQuota via watch @ 09/04/24 19:10:17.173
  I0904 19:10:17.175434 19 resource_quota.go:1175] observed resourceQuota "e2e-rq-status-78qpb" in namespace "resourcequota-7226" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0904 19:10:17.175458 19 resource_quota.go:1178] Found resourceQuota "e2e-rq-status-78qpb" in namespace "resourcequota-7226" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0904 19:10:17.175467 19 resource_quota.go:1185] ResourceQuota "e2e-rq-status-78qpb" /status was patched
  STEP: Get "e2e-rq-status-78qpb" /status @ 09/04/24 19:10:17.175
  I0904 19:10:17.178267 19 resource_quota.go:1196] Resourcequota "e2e-rq-status-78qpb" reports status: hard cpu of 1
  I0904 19:10:17.178286 19 resource_quota.go:1198] Resourcequota "e2e-rq-status-78qpb" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-78qpb" /status before checking Spec is unchanged @ 09/04/24 19:10:17.182
  I0904 19:10:17.201268 19 resource_quota.go:1218] Resourcequota "e2e-rq-status-78qpb" reports status: hard cpu of 2
  I0904 19:10:17.201299 19 resource_quota.go:1220] Resourcequota "e2e-rq-status-78qpb" reports status: hard memory of 2Gi
  I0904 19:10:17.203302 19 resource_quota.go:1229] observed resourceQuota "e2e-rq-status-78qpb" in namespace "resourcequota-7226" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0904 19:10:17.203325 19 resource_quota.go:1232] Found resourceQuota "e2e-rq-status-78qpb" in namespace "resourcequota-7226" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0904 19:10:17.207788 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039afe48), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039afea8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039afef0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:17.801623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:18.801702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:19.801796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:20.801905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:21.801976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:10:22.207680 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b641f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64258), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b642a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:22.802463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:23.802547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:24.802645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:25.802760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:26.802901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:10:27.208022 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581b4d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581b500), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581b530), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:27.803769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:28.804795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:29.804960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:30.805086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:31.805177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:10:32.207538 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581b770), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581b7b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581b800), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:32.805292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:33.805396      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:34.805547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:35.805623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:36.805730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:10:37.209738 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581ba10), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581ba40), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581ba88), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:37.806550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:38.806659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:39.806730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:40.806835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:41.806950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:10:42.208313 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64600), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64660), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64690), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:42.807033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:43.807150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:44.807233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:45.807536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:46.807715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:10:47.208584 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b648b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64948), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64990), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:47.808378      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:48.808626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:49.808739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:50.808817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:51.808904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:10:52.207908 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64be8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64c30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64c90), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:52.809700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:53.809786      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:54.809858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:55.809950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:56.810063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:10:57.208167 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581be18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581be60), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00581be90), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:10:57.810857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:58.810931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:10:59.811131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:00.811220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:01.811304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:02.207830 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64f60), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64f90), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b64fd8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:11:02.811632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:03.811730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:04.812163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:05.812274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:06.812410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:07.208819 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-78qpb" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-78qpb", GenerateName:"", Namespace:"resourcequota-7226", SelfLink:"", UID:"bf282398-8a02-40e2-8754-0bd8ad25ad7c", ResourceVersion:"32169", Generation:0, CreationTimestamp:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-78qpb"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b65140), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b65188), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 4, 19, 10, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b651b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0904 19:11:07.812630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:08.812752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:09.812854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:10.812949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:11.813052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:12.207258 19 resource_quota.go:1260] ResourceQuota "e2e-rq-status-78qpb" Spec was unchanged and /status reset
  I0904 19:11:12.207379 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7226" for this suite. @ 09/04/24 19:11:12.21
• [55.133 seconds]
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 09/04/24 19:11:12.217
  I0904 19:11:12.217130 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename chunking @ 09/04/24 19:11:12.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:12.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:12.235
  STEP: creating a large number of resources @ 09/04/24 19:11:12.238
  E0904 19:11:12.813508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:13.813907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:14.814730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:15.815331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:16.815721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:17.816286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:18.816296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:19.816943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:20.816990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:21.817258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:22.817684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:23.817861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:24.818380      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:25.819029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:26.819444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:27.819817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:28.820731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:29.821542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 09/04/24 19:11:29.925
  I0904 19:11:29.972339 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0904 19:11:30.023444 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0904 19:11:30.073401 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0904 19:11:30.122723 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0904 19:11:30.173004 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0904 19:11:30.223660 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0904 19:11:30.271074 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0904 19:11:30.323108 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0904 19:11:30.374600 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0904 19:11:30.421843 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0904 19:11:30.472748 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0904 19:11:30.522986 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0904 19:11:30.572106 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0904 19:11:30.623374 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0904 19:11:30.673917 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0904 19:11:30.721824 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0904 19:11:30.772814 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  E0904 19:11:30.822294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:30.822846 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0904 19:11:30.872017 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0904 19:11:30.923134 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0904 19:11:30.972820 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0904 19:11:31.021747 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0904 19:11:31.072789 19 chunking.go:98] Retrieved 17/17 results with rv 32741 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDEsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0904 19:11:31.123038 19 chunking.go:98] Retrieved 9/17 results with rv 32741 and continue 
  I0904 19:11:31.172402 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0904 19:11:31.223345 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0904 19:11:31.273877 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0904 19:11:31.321812 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0904 19:11:31.374771 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0904 19:11:31.422921 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0904 19:11:31.471988 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0904 19:11:31.523401 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0904 19:11:31.573777 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0904 19:11:31.621877 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0904 19:11:31.673089 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0904 19:11:31.723258 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0904 19:11:31.773069 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  E0904 19:11:31.822685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:31.823167 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0904 19:11:31.873000 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0904 19:11:31.922043 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0904 19:11:31.973010 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0904 19:11:32.023558 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0904 19:11:32.071584 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0904 19:11:32.122854 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0904 19:11:32.172960 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0904 19:11:32.222277 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0904 19:11:32.273590 19 chunking.go:98] Retrieved 17/17 results with rv 32744 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDQsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0904 19:11:32.322563 19 chunking.go:98] Retrieved 9/17 results with rv 32744 and continue 
  I0904 19:11:32.371764 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0904 19:11:32.423444 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0904 19:11:32.473357 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0904 19:11:32.522625 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0904 19:11:32.572604 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0904 19:11:32.622915 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0904 19:11:32.672412 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0904 19:11:32.723452 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0904 19:11:32.772272 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0904 19:11:32.822177 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  E0904 19:11:32.823265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:32.873014 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0904 19:11:32.923264 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0904 19:11:32.972481 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0904 19:11:33.025070 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0904 19:11:33.073484 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0904 19:11:33.121740 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0904 19:11:33.172845 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0904 19:11:33.222640 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0904 19:11:33.271858 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0904 19:11:33.322721 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0904 19:11:33.372999 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0904 19:11:33.422559 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0904 19:11:33.472515 19 chunking.go:98] Retrieved 17/17 results with rv 32748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzI3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0904 19:11:33.522453 19 chunking.go:98] Retrieved 9/17 results with rv 32748 and continue 
  STEP: retrieving those results all at once @ 09/04/24 19:11:33.522
  I0904 19:11:33.576340 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-5409" for this suite. @ 09/04/24 19:11:33.623
• [21.462 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 09/04/24 19:11:33.679
  I0904 19:11:33.679664 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 19:11:33.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:33.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:33.699
  STEP: Creating projection with secret that has name secret-emptykey-test-e4680526-4a9d-4c53-b539-a1fda6b08b2b @ 09/04/24 19:11:33.702
  I0904 19:11:33.704830 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9061" for this suite. @ 09/04/24 19:11:33.708
• [0.037 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 09/04/24 19:11:33.716
  I0904 19:11:33.716798 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 09/04/24 19:11:33.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:33.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:33.738
  STEP: creating a target pod @ 09/04/24 19:11:33.741
  E0904 19:11:33.823818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:34.824043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 09/04/24 19:11:35.768
  E0904 19:11:35.824180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:36.824296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 09/04/24 19:11:37.784
  I0904 19:11:37.784613 19 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5078 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:11:37.784630 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:11:37.785108 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:11:37.785174 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-5078/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  E0904 19:11:37.824339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:37.829191 19 exec_util.go:111] Exec stderr: ""
  I0904 19:11:37.836807 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5078" for this suite. @ 09/04/24 19:11:37.841
• [4.130 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 09/04/24 19:11:37.847
  I0904 19:11:37.847354 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:11:37.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:37.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:37.872
  STEP: Creating configMap with name projected-configmap-test-volume-55fbff92-fc79-4acb-b0bd-afc0fc34729f @ 09/04/24 19:11:37.875
  STEP: Creating a pod to test consume configMaps @ 09/04/24 19:11:37.882
  E0904 19:11:38.824496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:39.824815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:40.824909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:41.825185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:11:41.907
  I0904 19:11:41.911838 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-configmaps-54a6e398-1ea0-400c-9b17-6346749b9333 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 19:11:41.918
  I0904 19:11:41.935564 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2124" for this suite. @ 09/04/24 19:11:41.939
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 09/04/24 19:11:41.948
  I0904 19:11:41.948871 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 19:11:41.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:41.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:41.97
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 09/04/24 19:11:41.973
  E0904 19:11:42.825268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:43.825405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:44.825620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:45.825699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:11:46
  I0904 19:11:46.005019 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-3c1c8bce-85db-4795-ad96-fb9c602bb937 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:11:46.024
  I0904 19:11:46.053212 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1871" for this suite. @ 09/04/24 19:11:46.056
• [4.114 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 09/04/24 19:11:46.063
  I0904 19:11:46.063050 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename deployment @ 09/04/24 19:11:46.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:46.081
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:46.084
  I0904 19:11:46.097401 19 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E0904 19:11:46.826706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:47.826773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:48.826984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:49.827210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:50.827286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:51.107981 19 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/04/24 19:11:51.108
  I0904 19:11:51.108058 19 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 09/04/24 19:11:51.132
  E0904 19:11:51.827651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:52.827953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:11:53.174790 19 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5222",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "33f7cc16-ed49-4711-b2f2-184822c038c4",
      ResourceVersion: (string) (len=5) "33360",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861073911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=75) "ReplicaSet \"test-cleanup-deployment-898f8f847\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0904 19:11:53.179367 19 deployment.go:39] New ReplicaSet "test-cleanup-deployment-898f8f847" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=33) "test-cleanup-deployment-898f8f847",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5222",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4070ee78-11b4-435d-908e-60588078963a",
      ResourceVersion: (string) (len=5) "33350",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861073911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "898f8f847"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "33f7cc16-ed49-4711-b2f2-184822c038c4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 33 66 37 63 63  31 36 2d 65 64 34 39 2d  |\"33f7cc16-ed49-|
              00000120  34 37 31 31 2d 62 32 66  32 2d 31 38 34 38 32 32  |4711-b2f2-184822|
              00000130  63 30 33 38 63 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c038c4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "898f8f847"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "898f8f847"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0904 19:11:53.187828 19 deployment.go:67] Pod "test-cleanup-deployment-898f8f847-2g9gh" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=39) "test-cleanup-deployment-898f8f847-2g9gh",
      GenerateName: (string) (len=34) "test-cleanup-deployment-898f8f847-",
      Namespace: (string) (len=15) "deployment-5222",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f7f5adab-c99e-4abc-850a-120c4767b64c",
      ResourceVersion: (string) (len=5) "33349",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861073911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "898f8f847"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=33) "test-cleanup-deployment-898f8f847",
          UID: (types.UID) (len=36) "4070ee78-11b4-435d-908e-60588078963a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 30  37 30 65 65 37 38 2d 31  |d\":\"4070ee78-1|
              00000090  31 62 34 2d 34 33 35 64  2d 39 30 38 65 2d 36 30  |1b4-435d-908e-60|
              000000a0  35 38 38 30 37 38 39 36  33 61 5c 22 7d 22 3a 7b  |588078963a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 30  34 2e 31 38 35 5c 22 7d  |2.168.104.185\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-58j6j",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-58j6j",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-40-239",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861073911,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.40.239",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.40.239"
        }
      },
      PodIP: (string) (len=15) "192.168.104.185",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.104.185"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861073911,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861073911,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6",
          ContainerID: (string) (len=77) "containerd://95f3cb0b440ac7206b509cfc3a787a1a054beadb2b16bf3e6b1e3bd86b956f1e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-58j6j",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0904 19:11:53.189341 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5222" for this suite. @ 09/04/24 19:11:53.194
• [7.139 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 09/04/24 19:11:53.202
  I0904 19:11:53.202612 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:11:53.203
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:53.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:53.224
  STEP: Creating projection with secret that has name projected-secret-test-map-51d3828d-e269-439b-bc78-16f3cd663ea1 @ 09/04/24 19:11:53.231
  STEP: Creating a pod to test consume secrets @ 09/04/24 19:11:53.235
  E0904 19:11:53.828076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:54.828194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:55.829174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:56.829253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:11:57.258
  I0904 19:11:57.262494 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-secrets-2127eb57-2ff5-4cd2-8be1-00900d8b56bf container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 19:11:57.268
  I0904 19:11:57.289614 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9427" for this suite. @ 09/04/24 19:11:57.293
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 09/04/24 19:11:57.299
  I0904 19:11:57.299461 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename runtimeclass @ 09/04/24 19:11:57.299
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:57.316
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:57.32
  STEP: getting /apis @ 09/04/24 19:11:57.323
  STEP: getting /apis/node.k8s.io @ 09/04/24 19:11:57.327
  STEP: getting /apis/node.k8s.io/v1 @ 09/04/24 19:11:57.328
  STEP: creating @ 09/04/24 19:11:57.33
  STEP: watching @ 09/04/24 19:11:57.344
  I0904 19:11:57.344557 19 runtimeclass.go:275] starting watch
  STEP: getting @ 09/04/24 19:11:57.351
  STEP: listing @ 09/04/24 19:11:57.354
  STEP: patching @ 09/04/24 19:11:57.357
  STEP: updating @ 09/04/24 19:11:57.363
  I0904 19:11:57.368043 19 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 09/04/24 19:11:57.368
  STEP: deleting a collection @ 09/04/24 19:11:57.476
  I0904 19:11:57.492354 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6486" for this suite. @ 09/04/24 19:11:57.496
• [0.202 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 09/04/24 19:11:57.501
  I0904 19:11:57.501724 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:11:57.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:11:57.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:11:57.524
  STEP: Creating the pod @ 09/04/24 19:11:57.527
  E0904 19:11:57.829835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:58.830703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:11:59.830811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:12:00.067633 19 pod_client.go:173] Successfully updated pod "annotationupdatec6df3481-e009-475e-8c4d-7a9231f49862"
  E0904 19:12:00.830971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:01.831197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:02.831872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:03.831994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:12:04.091498 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7309" for this suite. @ 09/04/24 19:12:04.095
• [6.601 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:398
  STEP: Creating a kubernetes client @ 09/04/24 19:12:04.102
  I0904 19:12:04.102848 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 19:12:04.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:12:04.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:12:04.125
  STEP: Counting existing ResourceQuota @ 09/04/24 19:12:04.128
  E0904 19:12:04.832224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:05.832351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:06.832493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:07.833058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:08.834087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/04/24 19:12:09.132
  STEP: Ensuring resource quota status is calculated @ 09/04/24 19:12:09.137
  E0904 19:12:09.834193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:10.834306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 09/04/24 19:12:11.142
  STEP: Ensuring resource quota status captures replication controller creation @ 09/04/24 19:12:11.156
  E0904 19:12:11.834409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:12.834679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 09/04/24 19:12:13.161
  STEP: Ensuring resource quota status released usage @ 09/04/24 19:12:13.167
  E0904 19:12:13.834969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:14.835181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:12:15.171882 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9856" for this suite. @ 09/04/24 19:12:15.176
• [11.083 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 09/04/24 19:12:15.186
  I0904 19:12:15.186433 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename watch @ 09/04/24 19:12:15.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:12:15.206
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:12:15.212
  STEP: getting a starting resourceVersion @ 09/04/24 19:12:15.216
  STEP: starting a background goroutine to produce watch events @ 09/04/24 19:12:15.22
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 09/04/24 19:12:15.22
  E0904 19:12:15.835189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:16.836076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:17.836616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:12:17.994865 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4506" for this suite. @ 09/04/24 19:12:18.042
• [2.910 seconds]
------------------------------
SSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 09/04/24 19:12:18.096
  I0904 19:12:18.096189 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename events @ 09/04/24 19:12:18.096
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:12:18.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:12:18.121
  STEP: Create set of events @ 09/04/24 19:12:18.125
  STEP: get a list of Events with a label in the current namespace @ 09/04/24 19:12:18.143
  STEP: delete a list of events @ 09/04/24 19:12:18.148
  I0904 19:12:18.148380 19 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 09/04/24 19:12:18.17
  I0904 19:12:18.174845 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8016" for this suite. @ 09/04/24 19:12:18.179
• [0.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 09/04/24 19:12:18.189
  I0904 19:12:18.189574 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replicaset @ 09/04/24 19:12:18.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:12:18.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:12:18.215
  I0904 19:12:18.219146 19 replica_set.go:191] Creating ReplicaSet my-hostname-basic-f42de8a2-3126-478d-9b0d-fc4f40a57844
  I0904 19:12:18.232433 19 resource.go:87] Pod name my-hostname-basic-f42de8a2-3126-478d-9b0d-fc4f40a57844: Found 0 pods out of 1
  E0904 19:12:18.837170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:19.837347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:20.837434      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:21.837602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:22.837727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:12:23.237020 19 resource.go:87] Pod name my-hostname-basic-f42de8a2-3126-478d-9b0d-fc4f40a57844: Found 1 pods out of 1
  I0904 19:12:23.237051 19 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-f42de8a2-3126-478d-9b0d-fc4f40a57844" is running
  I0904 19:12:23.240568 19 replica_set.go:220] Pod "my-hostname-basic-f42de8a2-3126-478d-9b0d-fc4f40a57844-4hwsd" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 19:12:19 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 19:12:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 19:12:19 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 19:12:19 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-04 19:12:18 +0000 UTC Reason: Message:}])
  I0904 19:12:23.240587 19 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 09/04/24 19:12:23.24
  I0904 19:12:23.252901 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8121" for this suite. @ 09/04/24 19:12:23.258
• [5.075 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:331
  STEP: Creating a kubernetes client @ 09/04/24 19:12:23.264
  I0904 19:12:23.264724 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 19:12:23.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:12:23.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:12:23.29
  E0904 19:12:23.837808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:24.838662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:25.838681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:26.839653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:27.840330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:28.840389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:29.840456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:30.841433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:31.841632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:32.841933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:33.842525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:34.843095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:35.843642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:36.844649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:37.845271      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:38.845380      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:39.845494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 09/04/24 19:12:40.299
  E0904 19:12:40.845603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:41.846425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:42.846870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:43.847269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:44.848223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/04/24 19:12:45.304
  STEP: Ensuring resource quota status is calculated @ 09/04/24 19:12:45.309
  E0904 19:12:45.848380      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:46.848491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 09/04/24 19:12:47.315
  STEP: Ensuring resource quota status captures configMap creation @ 09/04/24 19:12:47.326
  E0904 19:12:47.848799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:48.849838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 09/04/24 19:12:49.33
  STEP: Ensuring resource quota status released usage @ 09/04/24 19:12:49.336
  E0904 19:12:49.850527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:50.850733      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:12:51.350232 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9864" for this suite. @ 09/04/24 19:12:51.358
• [28.110 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:127
  STEP: Creating a kubernetes client @ 09/04/24 19:12:51.375
  I0904 19:12:51.375157 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-preemption @ 09/04/24 19:12:51.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:12:51.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:12:51.399
  I0904 19:12:51.414811 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0904 19:12:51.851116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:52.851931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:53.852854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:54.852929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:55.853746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:56.853828      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:57.854861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:58.854952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:12:59.855661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:00.855755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:01.856373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:02.857249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:03.858285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:04.858673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:05.859619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:06.859868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:07.860862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:08.860990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:09.861682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:10.861752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:11.862672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:12.862748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:13.862849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:14.862964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:15.863074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:16.863149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:17.863431      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:18.863529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:19.864286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:20.864485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:21.864604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:22.864722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:23.865408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:24.865617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:25.866306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:26.866392      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:27.866749      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:28.866914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:29.867914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:30.868011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:31.868509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:32.868858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:33.869634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:34.869818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:35.870060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:36.870150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:37.870685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:38.871142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:39.871327      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:40.871510      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:41.872012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:42.872086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:43.872902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:44.873100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:45.873843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:46.873911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:47.874707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:48.875288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:49.875562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:50.875645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:13:51.419778 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 09/04/24 19:13:51.422
  I0904 19:13:51.445634 19 preemption.go:175] Created pod: pod0-0-sched-preemption-low-priority
  I0904 19:13:51.453107 19 preemption.go:175] Created pod: pod0-1-sched-preemption-medium-priority
  I0904 19:13:51.468827 19 preemption.go:175] Created pod: pod1-0-sched-preemption-medium-priority
  I0904 19:13:51.482971 19 preemption.go:175] Created pod: pod1-1-sched-preemption-medium-priority
  I0904 19:13:51.506332 19 preemption.go:175] Created pod: pod2-0-sched-preemption-medium-priority
  I0904 19:13:51.515238 19 preemption.go:175] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 09/04/24 19:13:51.515
  E0904 19:13:51.876338      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:52.876414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 09/04/24 19:13:53.547
  E0904 19:13:53.877285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:54.877503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:55.878046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:56.878702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:13:57.626882 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2889" for this suite. @ 09/04/24 19:13:57.63
• [66.262 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:673
  STEP: Creating a kubernetes client @ 09/04/24 19:13:57.637
  I0904 19:13:57.637660 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/04/24 19:13:57.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:13:57.653
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:13:57.658
  STEP: getting /apis @ 09/04/24 19:13:57.666
  STEP: getting /apis/admissionregistration.k8s.io @ 09/04/24 19:13:57.671
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 09/04/24 19:13:57.672
  STEP: creating @ 09/04/24 19:13:57.674
  STEP: getting @ 09/04/24 19:13:57.69
  STEP: listing @ 09/04/24 19:13:57.693
  STEP: watching @ 09/04/24 19:13:57.697
  I0904 19:13:57.697397 19 validatingadmissionpolicy.go:768] starting watch
  STEP: patching @ 09/04/24 19:13:57.699
  STEP: updating @ 09/04/24 19:13:57.704
  I0904 19:13:57.713238 19 validatingadmissionpolicy.go:796] waiting for watch events with expected annotations
  STEP: deleting @ 09/04/24 19:13:57.713
  STEP: deleting a collection @ 09/04/24 19:13:57.724
  I0904 19:13:57.740749 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-7923" for this suite. @ 09/04/24 19:13:57.744
• [0.114 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 09/04/24 19:13:57.752
  I0904 19:13:57.752258 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replicaset @ 09/04/24 19:13:57.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:13:57.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:13:57.772
  I0904 19:13:57.795228 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0904 19:13:57.879539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:58.879660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:13:59.879774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:00.880555      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:01.880626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:02.800053 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/04/24 19:14:02.8
  STEP: Scaling up "test-rs" replicaset @ 09/04/24 19:14:02.8
  I0904 19:14:02.812570 19 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 09/04/24 19:14:02.812
  I0904 19:14:02.834972 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-5399 with ReadyReplicas 1, AvailableReplicas 1
  I0904 19:14:02.840383 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-5399 with ReadyReplicas 1, AvailableReplicas 1
  I0904 19:14:02.865657 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-5399 with ReadyReplicas 1, AvailableReplicas 1
  I0904 19:14:02.871049 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-5399 with ReadyReplicas 1, AvailableReplicas 1
  E0904 19:14:02.884205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:03.808727 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-5399 with ReadyReplicas 2, AvailableReplicas 2
  I0904 19:14:03.855344 19 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-5399 with ReadyReplicas 3 found true
  I0904 19:14:03.855467 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5399" for this suite. @ 09/04/24 19:14:03.859
• [6.113 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 09/04/24 19:14:03.865
  I0904 19:14:03.865085 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename podtemplate @ 09/04/24 19:14:03.865
  E0904 19:14:03.884338      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:03.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:14:03.893
  I0904 19:14:03.928884 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8230" for this suite. @ 09/04/24 19:14:03.932
• [0.073 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 09/04/24 19:14:03.938
  I0904 19:14:03.938636 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename namespaces @ 09/04/24 19:14:03.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:03.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:14:03.957
  STEP: Creating a test namespace @ 09/04/24 19:14:03.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:03.976
  STEP: Creating a service in the namespace @ 09/04/24 19:14:03.98
  STEP: Deleting the namespace @ 09/04/24 19:14:03.991
  STEP: Waiting for the namespace to be removed. @ 09/04/24 19:14:04.002
  E0904 19:14:04.885247      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:05.885680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:06.886666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:07.887708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:08.888197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:09.888303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 09/04/24 19:14:10.006
  STEP: Verifying there is no service in the namespace @ 09/04/24 19:14:10.02
  I0904 19:14:10.025110 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-828" for this suite. @ 09/04/24 19:14:10.028
  STEP: Destroying namespace "nsdeletetest-6037" for this suite. @ 09/04/24 19:14:10.033
  I0904 19:14:10.037162 19 framework.go:370] Namespace nsdeletetest-6037 was already deleted
  STEP: Destroying namespace "nsdeletetest-3921" for this suite. @ 09/04/24 19:14:10.037
• [6.104 seconds]
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 09/04/24 19:14:10.042
  I0904 19:14:10.042543 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-pred @ 09/04/24 19:14:10.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:10.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:14:10.062
  I0904 19:14:10.065681 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0904 19:14:10.071609 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I0904 19:14:10.075138 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-21-169 before test
  I0904 19:14:10.079882 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-d6dp4 from ingress-nginx-kubernetes-worker started at 2024-09-04 18:53:47 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.079894 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:14:10.079900 19 predicates.go:957] calico-node-2rjpm from kube-system started at 2024-09-04 17:55:30 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.079906 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:14:10.079912 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-09-04 17:58:02 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.079916 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0904 19:14:10.079921 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-zslmr from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:14:10.079926 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:14:10.079931 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0904 19:14:10.079935 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-40-239 before test
  I0904 19:14:10.084989 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-n2qsn from ingress-nginx-kubernetes-worker started at 2024-09-04 17:47:19 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.085003 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:14:10.085009 19 predicates.go:957] calico-node-kswsn from kube-system started at 2024-09-04 17:55:51 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.085014 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:14:10.085019 19 predicates.go:957] sonobuoy-e2e-job-7c4b682519124aad from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:14:10.085023 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0904 19:14:10.085027 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:14:10.085032 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-lk4m4 from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:14:10.085036 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:14:10.085053 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0904 19:14:10.085073 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-7-223 before test
  I0904 19:14:10.089366 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-z5zrp from ingress-nginx-kubernetes-worker started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.089377 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:14:10.089383 19 predicates.go:957] calico-node-bc9bt from kube-system started at 2024-09-04 17:55:40 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.089434 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:14:10.089502 19 predicates.go:957] coredns-5b4857d7c8-brh4s from kube-system started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.089572 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0904 19:14:10.089587 19 predicates.go:957] kube-state-metrics-5d7bdccd49-77shl from kube-system started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.089658 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 0
  I0904 19:14:10.089695 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-v8zbg from kube-system started at 2024-09-04 17:46:10 +0000 UTC (2 container statuses recorded)
  I0904 19:14:10.089757 19 predicates.go:959] 	Container metrics-server ready: true, restart count 0
  I0904 19:14:10.089790 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I0904 19:14:10.089838 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-lr685 from kubernetes-dashboard started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.089891 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I0904 19:14:10.089902 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-862w2 from kubernetes-dashboard started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:14:10.089907 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 0
  I0904 19:14:10.089913 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-wh7sc from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:14:10.089917 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:14:10.089922 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-21-169 @ 09/04/24 19:14:10.104
  STEP: verifying the node has the label node ip-172-31-40-239 @ 09/04/24 19:14:10.118
  STEP: verifying the node has the label node ip-172-31-7-223 @ 09/04/24 19:14:10.13
  I0904 19:14:10.141555 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-d6dp4 requesting resource cpu=0m on Node ip-172-31-21-169
  I0904 19:14:10.141635 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-n2qsn requesting resource cpu=0m on Node ip-172-31-40-239
  I0904 19:14:10.141662 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-z5zrp requesting resource cpu=0m on Node ip-172-31-7-223
  I0904 19:14:10.141706 19 predicates.go:372] Pod calico-node-2rjpm requesting resource cpu=250m on Node ip-172-31-21-169
  I0904 19:14:10.141731 19 predicates.go:372] Pod calico-node-bc9bt requesting resource cpu=250m on Node ip-172-31-7-223
  I0904 19:14:10.141769 19 predicates.go:372] Pod calico-node-kswsn requesting resource cpu=250m on Node ip-172-31-40-239
  I0904 19:14:10.141783 19 predicates.go:372] Pod coredns-5b4857d7c8-brh4s requesting resource cpu=100m on Node ip-172-31-7-223
  I0904 19:14:10.141789 19 predicates.go:372] Pod kube-state-metrics-5d7bdccd49-77shl requesting resource cpu=0m on Node ip-172-31-7-223
  I0904 19:14:10.141797 19 predicates.go:372] Pod metrics-server-v0.7.1-6c77d69467-v8zbg requesting resource cpu=5m on Node ip-172-31-7-223
  I0904 19:14:10.141803 19 predicates.go:372] Pod dashboard-metrics-scraper-64757cf48d-lr685 requesting resource cpu=0m on Node ip-172-31-7-223
  I0904 19:14:10.141811 19 predicates.go:372] Pod kubernetes-dashboard-7b6b7bcb5d-862w2 requesting resource cpu=0m on Node ip-172-31-7-223
  I0904 19:14:10.141816 19 predicates.go:372] Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-21-169
  I0904 19:14:10.141821 19 predicates.go:372] Pod sonobuoy-e2e-job-7c4b682519124aad requesting resource cpu=0m on Node ip-172-31-40-239
  I0904 19:14:10.141826 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-lk4m4 requesting resource cpu=0m on Node ip-172-31-40-239
  I0904 19:14:10.141831 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-wh7sc requesting resource cpu=0m on Node ip-172-31-7-223
  I0904 19:14:10.141837 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-zslmr requesting resource cpu=0m on Node ip-172-31-21-169
  STEP: Starting Pods to consume most of the cluster CPU. @ 09/04/24 19:14:10.141
  I0904 19:14:10.141859 19 predicates.go:382] Creating a pod which consumes cpu=1225m on Node ip-172-31-21-169
  I0904 19:14:10.147716 19 predicates.go:382] Creating a pod which consumes cpu=1225m on Node ip-172-31-40-239
  I0904 19:14:10.160394 19 predicates.go:382] Creating a pod which consumes cpu=1151m on Node ip-172-31-7-223
  E0904 19:14:10.888446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:11.888545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 09/04/24 19:14:12.186
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-58ac5138-9125-4c2d-ada2-6a8d67f35a2d.17f2206ac479fa8f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8094/filler-pod-58ac5138-9125-4c2d-ada2-6a8d67f35a2d to ip-172-31-7-223] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-58ac5138-9125-4c2d-ada2-6a8d67f35a2d.17f2206ae0ed62d8], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-58ac5138-9125-4c2d-ada2-6a8d67f35a2d.17f2206ae21243a2], Reason = [Created], Message = [Created container filler-pod-58ac5138-9125-4c2d-ada2-6a8d67f35a2d] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-58ac5138-9125-4c2d-ada2-6a8d67f35a2d.17f2206ae4ac098a], Reason = [Started], Message = [Started container filler-pod-58ac5138-9125-4c2d-ada2-6a8d67f35a2d] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-946ce871-0d37-43dd-ac33-aba6843b46e3.17f2206ac3957a59], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8094/filler-pod-946ce871-0d37-43dd-ac33-aba6843b46e3 to ip-172-31-21-169] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-946ce871-0d37-43dd-ac33-aba6843b46e3.17f2206adfbf231a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-946ce871-0d37-43dd-ac33-aba6843b46e3.17f2206ae0a7bf75], Reason = [Created], Message = [Created container filler-pod-946ce871-0d37-43dd-ac33-aba6843b46e3] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-946ce871-0d37-43dd-ac33-aba6843b46e3.17f2206ae47a2b2d], Reason = [Started], Message = [Started container filler-pod-946ce871-0d37-43dd-ac33-aba6843b46e3] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-fc76ef18-b2c9-454c-aca3-214a581e6718.17f2206ac4170893], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8094/filler-pod-fc76ef18-b2c9-454c-aca3-214a581e6718 to ip-172-31-40-239] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-fc76ef18-b2c9-454c-aca3-214a581e6718.17f2206ae0f29b27], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-fc76ef18-b2c9-454c-aca3-214a581e6718.17f2206ae1cf48d0], Reason = [Created], Message = [Created container filler-pod-fc76ef18-b2c9-454c-aca3-214a581e6718] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-fc76ef18-b2c9-454c-aca3-214a581e6718.17f2206ae50eb39f], Reason = [Started], Message = [Started container filler-pod-fc76ef18-b2c9-454c-aca3-214a581e6718] @ 09/04/24 19:14:12.19
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17f2206b3d4fcde2], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] @ 09/04/24 19:14:12.204
  E0904 19:14:12.888941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label node off the node ip-172-31-21-169 @ 09/04/24 19:14:13.204
  STEP: verifying the node doesn't have the label node @ 09/04/24 19:14:13.215
  STEP: removing the label node off the node ip-172-31-40-239 @ 09/04/24 19:14:13.219
  STEP: verifying the node doesn't have the label node @ 09/04/24 19:14:13.23
  STEP: removing the label node off the node ip-172-31-7-223 @ 09/04/24 19:14:13.429
  STEP: verifying the node doesn't have the label node @ 09/04/24 19:14:13.441
  I0904 19:14:13.444930 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8094" for this suite. @ 09/04/24 19:14:13.448
• [3.414 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:472
  STEP: Creating a kubernetes client @ 09/04/24 19:14:13.456
  I0904 19:14:13.456640 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename field-validation @ 09/04/24 19:14:13.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:13.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:14:13.477
  I0904 19:14:13.480765 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:14:13.889563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:14.889652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:15.889762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W0904 19:14:16.019734      19 warnings.go:70] unknown field "alpha"
  W0904 19:14:16.019752      19 warnings.go:70] unknown field "beta"
  W0904 19:14:16.019755      19 warnings.go:70] unknown field "delta"
  W0904 19:14:16.019757      19 warnings.go:70] unknown field "epsilon"
  W0904 19:14:16.019760      19 warnings.go:70] unknown field "gamma"
  I0904 19:14:16.571482 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3175" for this suite. @ 09/04/24 19:14:16.574
• [3.124 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 09/04/24 19:14:16.58
  I0904 19:14:16.580673 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename runtimeclass @ 09/04/24 19:14:16.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:16.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:14:16.603
  E0904 19:14:16.890562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:17.891082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:18.631695 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8428" for this suite. @ 09/04/24 19:14:18.635
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 09/04/24 19:14:18.643
  I0904 19:14:18.643794 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 19:14:18.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:18.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:14:18.662
  I0904 19:14:18.665426 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: creating the pod @ 09/04/24 19:14:18.665
  STEP: submitting the pod to kubernetes @ 09/04/24 19:14:18.665
  E0904 19:14:18.891896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:19.892108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:20.704131 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5911" for this suite. @ 09/04/24 19:14:20.708
• [2.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 09/04/24 19:14:20.717
  I0904 19:14:20.717777 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename prestop @ 09/04/24 19:14:20.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:20.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:14:20.741
  STEP: Creating server pod server in namespace prestop-1675 @ 09/04/24 19:14:20.745
  STEP: Waiting for pods to come up. @ 09/04/24 19:14:20.754
  E0904 19:14:20.893029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:21.893484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-1675 @ 09/04/24 19:14:22.768
  E0904 19:14:22.894150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:23.894434      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 09/04/24 19:14:24.786
  E0904 19:14:24.894902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:25.894976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:26.895078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:27.895215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:28.895316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:29.801836 19 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 09/04/24 19:14:29.802
  I0904 19:14:29.817161 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-1675" for this suite. @ 09/04/24 19:14:29.821
• [9.118 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:754
  STEP: Creating a kubernetes client @ 09/04/24 19:14:29.835
  I0904 19:14:29.835394 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename statefulset @ 09/04/24 19:14:29.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:14:29.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:14:29.864
  STEP: Creating service test in namespace statefulset-4012 @ 09/04/24 19:14:29.869
  STEP: Creating stateful set ss in namespace statefulset-4012 @ 09/04/24 19:14:29.876
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4012 @ 09/04/24 19:14:29.883
  I0904 19:14:29.885841 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E0904 19:14:29.896060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:30.896237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:31.896379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:32.896773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:33.896958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:34.897073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:35.897199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:36.897303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:37.897477      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:38.897624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:39.890044 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 09/04/24 19:14:39.89
  I0904 19:14:39.894202 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-4012 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0904 19:14:39.898509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:39.993378 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 19:14:39.993404 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 19:14:39.993411 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 19:14:39.997833 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0904 19:14:40.898682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:41.898782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:42.899097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:43.899424      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:44.899550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:45.899739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:46.899809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:47.900060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:48.900947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:14:49.901059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:49.998799 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0904 19:14:49.998838 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0904 19:14:50.017421 19 resource.go:168] POD   NODE              PHASE    GRACE  CONDITIONS
  I0904 19:14:50.017480 19 resource.go:175] ss-0  ip-172-31-21-169  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:31 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:40 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:40 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:29 +0000 UTC  }]
  I0904 19:14:50.017540 19 resource.go:178] 
  I0904 19:14:50.017547 19 statefulset.go:2413] StatefulSet ss has not reached scale 3, at 1
  E0904 19:14:50.901177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:51.023131 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 8.995277601s
  E0904 19:14:51.901661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:52.029074 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 7.989937711s
  E0904 19:14:52.901761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:53.034331 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 6.983871536s
  E0904 19:14:53.902697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:54.040142 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 5.978803163s
  E0904 19:14:54.903661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:55.044925 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 4.972929098s
  E0904 19:14:55.903906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:56.049025 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 3.968655022s
  E0904 19:14:56.904021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:57.054314 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 2.964489977s
  E0904 19:14:57.904439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:58.059638 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 1.959125979s
  E0904 19:14:58.904727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:14:59.064259 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 953.736416ms
  E0904 19:14:59.905151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4012 @ 09/04/24 19:15:00.064
  I0904 19:15:00.069672 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-4012 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0904 19:15:00.154528 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0904 19:15:00.154568 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 19:15:00.154578 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0904 19:15:00.154618 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-4012 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0904 19:15:00.247313 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0904 19:15:00.247361 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 19:15:00.247374 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0904 19:15:00.247424 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-4012 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0904 19:15:00.340187 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0904 19:15:00.340224 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0904 19:15:00.340253 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0904 19:15:00.344132 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
  E0904 19:15:00.905851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:01.906692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:02.907059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:03.907283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:04.907572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:05.907652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:06.908185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:07.908526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:08.908735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:09.908834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:10.346826 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0904 19:15:10.346851 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0904 19:15:10.346858 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 09/04/24 19:15:10.346
  I0904 19:15:10.351325 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-4012 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 19:15:10.434449 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 19:15:10.434483 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 19:15:10.434492 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 19:15:10.434534 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-4012 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 19:15:10.522765 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 19:15:10.522807 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 19:15:10.522815 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 19:15:10.522852 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=statefulset-4012 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0904 19:15:10.610717 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0904 19:15:10.610750 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0904 19:15:10.610758 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0904 19:15:10.610766 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0904 19:15:10.615301 19 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 2
  E0904 19:15:10.909750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:11.910665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:12.910736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:13.910847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:14.911026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:15.911134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:16.911313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:17.911363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:18.911532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:19.911719      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:20.620736 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0904 19:15:20.620767 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0904 19:15:20.620773 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0904 19:15:20.639236 19 resource.go:168] POD   NODE              PHASE    GRACE  CONDITIONS
  I0904 19:15:20.639563 19 resource.go:175] ss-0  ip-172-31-21-169  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:31 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:29 +0000 UTC  }]
  I0904 19:15:20.639690 19 resource.go:175] ss-1  ip-172-31-40-239  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC  }]
  I0904 19:15:20.639807 19 resource.go:175] ss-2  ip-172-31-7-223   Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC  }]
  I0904 19:15:20.639876 19 resource.go:178] 
  I0904 19:15:20.639957 19 statefulset.go:2413] StatefulSet ss has not reached scale 0, at 3
  E0904 19:15:20.911842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:21.643741 19 resource.go:168] POD   NODE              PHASE      GRACE  CONDITIONS
  I0904 19:15:21.643792 19 resource.go:175] ss-1  ip-172-31-40-239  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:20 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:11 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:11 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC  }]
  I0904 19:15:21.643863 19 resource.go:175] ss-2  ip-172-31-7-223   Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:21 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:11 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:15:11 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:14:50 +0000 UTC  }]
  I0904 19:15:21.643868 19 resource.go:178] 
  I0904 19:15:21.643884 19 statefulset.go:2413] StatefulSet ss has not reached scale 0, at 2
  E0904 19:15:21.911912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:22.648962 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 7.986779536s
  E0904 19:15:22.912486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:23.653686 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 6.981879379s
  E0904 19:15:23.913186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:24.659603 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 5.976383589s
  E0904 19:15:24.914100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:25.664196 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 4.970977874s
  E0904 19:15:25.914607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:26.668939 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 3.966627704s
  E0904 19:15:26.915383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:27.674027 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 2.961900701s
  E0904 19:15:27.915544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:28.680179 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 1.955914544s
  E0904 19:15:28.916683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:29.685903 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 950.340489ms
  E0904 19:15:29.917294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4012 @ 09/04/24 19:15:30.686
  I0904 19:15:30.690120 19 rest.go:150] Scaling statefulset ss to 0
  I0904 19:15:30.697359 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0904 19:15:30.701023 19 statefulset.go:138] Deleting all statefulset in ns statefulset-4012
  I0904 19:15:30.703888 19 rest.go:150] Scaling statefulset ss to 0
  I0904 19:15:30.711084 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0904 19:15:30.714872 19 rest.go:88] Deleting statefulset ss
  I0904 19:15:30.729373 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4012" for this suite. @ 09/04/24 19:15:30.733
• [60.906 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 09/04/24 19:15:30.741
  I0904 19:15:30.741649 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubelet-test @ 09/04/24 19:15:30.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:15:30.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:15:30.759
  E0904 19:15:30.917610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:31.917701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:32.917859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:33.917970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:34.780220 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1435" for this suite. @ 09/04/24 19:15:34.784
• [4.053 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:258
  STEP: Creating a kubernetes client @ 09/04/24 19:15:34.794
  I0904 19:15:34.794268 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:15:34.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:15:34.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:15:34.816
  STEP: Setting up server cert @ 09/04/24 19:15:34.842
  E0904 19:15:34.918308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:15:34.958
  STEP: Deploying the webhook pod @ 09/04/24 19:15:34.968
  STEP: Wait for the deployment to be ready @ 09/04/24 19:15:34.983
  I0904 19:15:34.994481 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:15:35.918442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:36.918753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:15:37.006
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:15:37.019
  E0904 19:15:37.919729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:15:38.019985 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 09/04/24 19:15:38.029
  STEP: create a pod that should be updated by the webhook @ 09/04/24 19:15:38.043
  I0904 19:15:38.108530 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7995" for this suite. @ 09/04/24 19:15:38.114
  STEP: Destroying namespace "webhook-markers-4149" for this suite. @ 09/04/24 19:15:38.121
• [3.332 seconds]
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:409
  STEP: Creating a kubernetes client @ 09/04/24 19:15:38.126
  I0904 19:15:38.126383 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename dns @ 09/04/24 19:15:38.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:15:38.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:15:38.148
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 09/04/24 19:15:38.151
  I0904 19:15:38.160124 19 dns.go:421] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7793  845091d4-3a81-41ef-96be-00099c40da1c 35047 0 2024-09-04 19:15:38 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-09-04 19:15:38 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nmxmv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,Image:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.52,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nmxmv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,SupplementalGroupsPolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0904 19:15:38.919835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:39.919922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 09/04/24 19:15:40.168
  I0904 19:15:40.168075 19 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7793 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:15:40.168091 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:15:40.168571 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:15:40.168612 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7793/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 09/04/24 19:15:40.225
  I0904 19:15:40.226131 19 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7793 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:15:40.226186 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:15:40.226550 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:15:40.226639 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7793/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0904 19:15:40.283199 19 dns.go:423] Deleting pod test-dns-nameservers...
  I0904 19:15:40.296535 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7793" for this suite. @ 09/04/24 19:15:40.301
• [2.182 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 09/04/24 19:15:40.308
  I0904 19:15:40.308318 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename subpath @ 09/04/24 19:15:40.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:15:40.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:15:40.329
  STEP: Setting up data @ 09/04/24 19:15:40.333
  STEP: Creating pod pod-subpath-test-secret-zk9g @ 09/04/24 19:15:40.341
  STEP: Creating a pod to test atomic-volume-subpath @ 09/04/24 19:15:40.341
  E0904 19:15:40.920790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:41.920865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:42.921599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:43.921695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:44.922665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:45.922763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:46.923492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:47.923887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:48.924904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:49.925112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:50.926072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:51.926164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:52.926689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:53.926990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:54.927976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:55.928083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:56.928179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:57.928932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:58.929282      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:15:59.929383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:00.929746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:01.929843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:02.930872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:03.931367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:16:04.42
  I0904 19:16:04.425517 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-subpath-test-secret-zk9g container test-container-subpath-secret-zk9g: <nil>
  STEP: delete the pod @ 09/04/24 19:16:04.437
  STEP: Deleting pod pod-subpath-test-secret-zk9g @ 09/04/24 19:16:04.456
  I0904 19:16:04.456175 19 delete.go:62] Deleting pod "pod-subpath-test-secret-zk9g" in namespace "subpath-6916"
  I0904 19:16:04.459336 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6916" for this suite. @ 09/04/24 19:16:04.463
• [24.162 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 09/04/24 19:16:04.47
  I0904 19:16:04.470811 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 19:16:04.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:04.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:04.491
  STEP: Creating a pod to test downward api env vars @ 09/04/24 19:16:04.495
  E0904 19:16:04.931452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:05.931629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:06.931724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:07.932783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:16:08.52
  I0904 19:16:08.523844 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downward-api-5c8c675d-76ba-4f68-9cc5-d1443205d666 container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 19:16:08.542
  I0904 19:16:08.564335 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2820" for this suite. @ 09/04/24 19:16:08.568
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 09/04/24 19:16:08.574
  I0904 19:16:08.574857 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename daemonsets @ 09/04/24 19:16:08.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:08.591
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:08.594
  I0904 19:16:08.616425 19 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/04/24 19:16:08.623
  I0904 19:16:08.627102 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:08.627153 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:08.630505 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 19:16:08.630524 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 19:16:08.933040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:09.628414 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:09.628455 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:09.631752 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0904 19:16:09.631779 19 fixtures.go:130] Node ip-172-31-40-239 is running 0 daemon pod, expected 1
  E0904 19:16:09.933091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:10.629574 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:10.629613 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:10.632580 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 19:16:10.632600 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 09/04/24 19:16:10.643
  STEP: Check that daemon pods images are updated. @ 09/04/24 19:16:10.653
  I0904 19:16:10.657204 19 daemon_set.go:1193] Wrong image for pod: daemon-set-2hmv4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0904 19:16:10.657221 19 daemon_set.go:1193] Wrong image for pod: daemon-set-4zqkf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0904 19:16:10.657236 19 daemon_set.go:1193] Wrong image for pod: daemon-set-j4qh5. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0904 19:16:10.664311 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:10.664417 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0904 19:16:10.933693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:11.659391 19 daemon_set.go:1193] Wrong image for pod: daemon-set-2hmv4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0904 19:16:11.659426 19 daemon_set.go:1198] Pod daemon-set-826bs is not available
  I0904 19:16:11.659433 19 daemon_set.go:1193] Wrong image for pod: daemon-set-j4qh5. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0904 19:16:11.663982 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:11.664012 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0904 19:16:11.934279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:12.658572 19 daemon_set.go:1193] Wrong image for pod: daemon-set-2hmv4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0904 19:16:12.658605 19 daemon_set.go:1198] Pod daemon-set-jqsn5 is not available
  I0904 19:16:12.661812 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:12.661856 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0904 19:16:12.935209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:13.662744 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:13.662782 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0904 19:16:13.936011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:14.658427 19 daemon_set.go:1198] Pod daemon-set-rj2ld is not available
  I0904 19:16:14.662378 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:14.662409 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 09/04/24 19:16:14.662
  I0904 19:16:14.665662 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:14.665698 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:14.669187 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 19:16:14.669201 19 fixtures.go:130] Node ip-172-31-40-239 is running 0 daemon pod, expected 1
  E0904 19:16:14.936615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:15.668750 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:15.668794 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:16:15.672944 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 19:16:15.672962 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/04/24 19:16:15.689
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3, will wait for the garbage collector to delete the pods @ 09/04/24 19:16:15.689
  I0904 19:16:15.750538 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.605986ms
  I0904 19:16:15.851269 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.726961ms
  E0904 19:16:15.937567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:16.937920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:17.056548 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 19:16:17.056578 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0904 19:16:17.060710 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35407"},"items":null}

  I0904 19:16:17.064037 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35407"},"items":null}

  I0904 19:16:17.079438 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3" for this suite. @ 09/04/24 19:16:17.082
• [8.516 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 09/04/24 19:16:17.09
  I0904 19:16:17.090916 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 19:16:17.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:17.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:17.11
  STEP: Creating secret with name secret-test-28b768b2-2f8f-4e3e-977b-5754048b7f27 @ 09/04/24 19:16:17.136
  STEP: Creating a pod to test consume secrets @ 09/04/24 19:16:17.141
  E0904 19:16:17.937990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:18.938113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:19.938706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:20.938812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:16:21.167
  I0904 19:16:21.171567 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-secrets-7a97fa42-2f73-48cd-b806-11ffdb173bbb container secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 19:16:21.177
  I0904 19:16:21.195763 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4721" for this suite. @ 09/04/24 19:16:21.2
  STEP: Destroying namespace "secret-namespace-6580" for this suite. @ 09/04/24 19:16:21.207
• [4.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 09/04/24 19:16:21.212
  I0904 19:16:21.212963 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename svcaccounts @ 09/04/24 19:16:21.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:21.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:21.231
  STEP: creating a ServiceAccount @ 09/04/24 19:16:21.235
  STEP: watching for the ServiceAccount to be added @ 09/04/24 19:16:21.244
  STEP: patching the ServiceAccount @ 09/04/24 19:16:21.245
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 09/04/24 19:16:21.252
  STEP: deleting the ServiceAccount @ 09/04/24 19:16:21.256
  I0904 19:16:21.270812 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8290" for this suite. @ 09/04/24 19:16:21.274
• [0.066 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:282
  STEP: Creating a kubernetes client @ 09/04/24 19:16:21.279
  I0904 19:16:21.279834 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:16:21.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:21.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:21.301
  STEP: Setting up server cert @ 09/04/24 19:16:21.327
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:16:21.472
  STEP: Deploying the webhook pod @ 09/04/24 19:16:21.48
  STEP: Wait for the deployment to be ready @ 09/04/24 19:16:21.495
  I0904 19:16:21.503915 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:16:21.939449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:22.939825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:16:23.516
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:16:23.532
  E0904 19:16:23.940620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:24.532231 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0904 19:16:24.540671 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:16:24.941361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7813-crds.webhook.example.com via the AdmissionRegistration API @ 09/04/24 19:16:25.053
  STEP: Creating a custom resource that should be mutated by the webhook @ 09/04/24 19:16:25.069
  E0904 19:16:25.941414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:26.941617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:27.648677 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2567" for this suite. @ 09/04/24 19:16:27.653
  STEP: Destroying namespace "webhook-markers-5165" for this suite. @ 09/04/24 19:16:27.66
• [6.388 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 09/04/24 19:16:27.667
  I0904 19:16:27.667769 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:16:27.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:27.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:27.685
  STEP: Creating projection with secret that has name projected-secret-test-04f684db-af6c-4311-bdd0-1cba0765c204 @ 09/04/24 19:16:27.688
  STEP: Creating a pod to test consume secrets @ 09/04/24 19:16:27.692
  E0904 19:16:27.941846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:28.941964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:16:29.71
  I0904 19:16:29.714805 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-secrets-c669d37f-2621-46e7-ba12-dd8f1f829492 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 19:16:29.722
  I0904 19:16:29.738574 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1007" for this suite. @ 09/04/24 19:16:29.741
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 09/04/24 19:16:29.747
  I0904 19:16:29.747342 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 19:16:29.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:29.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:29.768
  STEP: Creating a pod to test downward api env vars @ 09/04/24 19:16:29.814
  E0904 19:16:29.942052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:30.942692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:16:31.835
  I0904 19:16:31.839103 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downward-api-01279679-c8e2-4358-a2e0-614df5e0c235 container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 19:16:31.847
  I0904 19:16:31.864915 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3107" for this suite. @ 09/04/24 19:16:31.869
• [2.129 seconds]
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 09/04/24 19:16:31.876
  I0904 19:16:31.876224 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename replication-controller @ 09/04/24 19:16:31.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:31.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:31.896
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 09/04/24 19:16:31.899
  E0904 19:16:31.943359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:32.943690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 09/04/24 19:16:33.926
  STEP: Then the orphan pod is adopted @ 09/04/24 19:16:33.93
  E0904 19:16:33.943744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:34.941116 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0904 19:16:34.943745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-6243" for this suite. @ 09/04/24 19:16:34.944
• [3.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 09/04/24 19:16:34.95
  I0904 19:16:34.950527 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename watch @ 09/04/24 19:16:34.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:34.967
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:34.97
  STEP: creating a new configmap @ 09/04/24 19:16:34.973
  STEP: modifying the configmap once @ 09/04/24 19:16:34.978
  STEP: modifying the configmap a second time @ 09/04/24 19:16:34.986
  STEP: deleting the configmap @ 09/04/24 19:16:34.995
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 09/04/24 19:16:35.009
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 09/04/24 19:16:35.011
  I0904 19:16:35.011589 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6179  718074c4-5bf4-486c-8b1e-f9e63d87b7b4 35729 0 2024-09-04 19:16:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-09-04 19:16:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 19:16:35.011709 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6179  718074c4-5bf4-486c-8b1e-f9e63d87b7b4 35732 0 2024-09-04 19:16:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-09-04 19:16:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 19:16:35.011822 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6179" for this suite. @ 09/04/24 19:16:35.016
• [0.071 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 09/04/24 19:16:35.022
  I0904 19:16:35.022028 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 19:16:35.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:35.04
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:35.043
  I0904 19:16:35.046652 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:16:35.943895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/04/24 19:16:36.276
  I0904 19:16:36.277056 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4570 --namespace=crd-publish-openapi-4570 create -f -'
  E0904 19:16:36.944128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:37.944402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:38.341858 19 builder.go:146] stderr: ""
  I0904 19:16:38.341903 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6391-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0904 19:16:38.342027 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4570 --namespace=crd-publish-openapi-4570 delete e2e-test-crd-publish-openapi-6391-crds test-cr'
  I0904 19:16:38.387775 19 builder.go:146] stderr: ""
  I0904 19:16:38.387808 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6391-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I0904 19:16:38.387843 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4570 --namespace=crd-publish-openapi-4570 apply -f -'
  I0904 19:16:38.439572 19 builder.go:146] stderr: ""
  I0904 19:16:38.439620 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6391-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0904 19:16:38.439659 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4570 --namespace=crd-publish-openapi-4570 delete e2e-test-crd-publish-openapi-6391-crds test-cr'
  I0904 19:16:38.485449 19 builder.go:146] stderr: ""
  I0904 19:16:38.485509 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6391-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 09/04/24 19:16:38.485
  I0904 19:16:38.485566 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4570 explain e2e-test-crd-publish-openapi-6391-crds'
  I0904 19:16:38.556031 19 builder.go:146] stderr: ""
  I0904 19:16:38.556099 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-6391-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0904 19:16:38.945142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:39.839286 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4570" for this suite. @ 09/04/24 19:16:39.848
• [4.836 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 09/04/24 19:16:39.857
  I0904 19:16:39.857950 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename gc @ 09/04/24 19:16:39.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:39.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:39.879
  STEP: create the rc1 @ 09/04/24 19:16:39.887
  STEP: create the rc2 @ 09/04/24 19:16:39.892
  E0904 19:16:39.945449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:40.945665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:41.946026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:42.949800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:43.950743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:44.953708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 09/04/24 19:16:45.903
  E0904 19:16:45.953983      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 09/04/24 19:16:46.286
  STEP: wait for the rc to be deleted @ 09/04/24 19:16:46.292
  E0904 19:16:46.954698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:47.955068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:48.955372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:49.955565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:50.955655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:51.303121 19 garbage_collector.go:762] 70 pods remaining
  I0904 19:16:51.303147 19 garbage_collector.go:769] 70 pods has nil DeletionTimestamp
  I0904 19:16:51.303153 19 garbage_collector.go:770] 
  E0904 19:16:51.956295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:52.956944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:53.957219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:54.957390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:55.957599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/04/24 19:16:56.304
  W0904 19:16:56.310813      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0904 19:16:56.310838 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0904 19:16:56.310885 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-29c2s" in namespace "gc-6021"
  I0904 19:16:56.327321 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2fjk9" in namespace "gc-6021"
  I0904 19:16:56.344886 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2lk8p" in namespace "gc-6021"
  I0904 19:16:56.357317 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2mz4b" in namespace "gc-6021"
  I0904 19:16:56.367474 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4cw82" in namespace "gc-6021"
  I0904 19:16:56.378918 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4dzx4" in namespace "gc-6021"
  I0904 19:16:56.390919 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4nbg6" in namespace "gc-6021"
  I0904 19:16:56.402562 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5228f" in namespace "gc-6021"
  I0904 19:16:56.415221 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-56b4h" in namespace "gc-6021"
  I0904 19:16:56.427368 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-585lh" in namespace "gc-6021"
  I0904 19:16:56.441406 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5bk86" in namespace "gc-6021"
  I0904 19:16:56.456310 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5fsfl" in namespace "gc-6021"
  I0904 19:16:56.467774 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5j2r5" in namespace "gc-6021"
  I0904 19:16:56.478665 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6qcks" in namespace "gc-6021"
  I0904 19:16:56.494068 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6tj4r" in namespace "gc-6021"
  I0904 19:16:56.509083 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7bm8d" in namespace "gc-6021"
  I0904 19:16:56.521275 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7lpz9" in namespace "gc-6021"
  I0904 19:16:56.532735 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7xr65" in namespace "gc-6021"
  I0904 19:16:56.544835 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8gkjj" in namespace "gc-6021"
  I0904 19:16:56.555107 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8st7t" in namespace "gc-6021"
  I0904 19:16:56.568794 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-98dts" in namespace "gc-6021"
  I0904 19:16:56.580331 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9lrrg" in namespace "gc-6021"
  I0904 19:16:56.592702 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9tt9t" in namespace "gc-6021"
  I0904 19:16:56.606631 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b76qs" in namespace "gc-6021"
  I0904 19:16:56.623042 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b8lcm" in namespace "gc-6021"
  I0904 19:16:56.640129 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bfzsz" in namespace "gc-6021"
  I0904 19:16:56.654705 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bhzwh" in namespace "gc-6021"
  I0904 19:16:56.671733 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bqzmb" in namespace "gc-6021"
  I0904 19:16:56.689565 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-crmg7" in namespace "gc-6021"
  I0904 19:16:56.701832 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cv9n5" in namespace "gc-6021"
  I0904 19:16:56.721379 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d65lc" in namespace "gc-6021"
  I0904 19:16:56.733663 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dg7hp" in namespace "gc-6021"
  I0904 19:16:56.744826 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dgjt7" in namespace "gc-6021"
  I0904 19:16:56.758018 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dknql" in namespace "gc-6021"
  I0904 19:16:56.774113 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dmnsm" in namespace "gc-6021"
  I0904 19:16:56.795696 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-drrlx" in namespace "gc-6021"
  I0904 19:16:56.809872 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dtphp" in namespace "gc-6021"
  I0904 19:16:56.824014 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f72cf" in namespace "gc-6021"
  I0904 19:16:56.840133 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f7xss" in namespace "gc-6021"
  I0904 19:16:56.854344 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fbq7f" in namespace "gc-6021"
  I0904 19:16:56.866067 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-frtm9" in namespace "gc-6021"
  I0904 19:16:56.875365 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ggjth" in namespace "gc-6021"
  I0904 19:16:56.894122 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gh2r8" in namespace "gc-6021"
  I0904 19:16:56.907156 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gpvmr" in namespace "gc-6021"
  I0904 19:16:56.920962 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-h9b4w" in namespace "gc-6021"
  I0904 19:16:56.937702 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-h9t42" in namespace "gc-6021"
  I0904 19:16:56.950409 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hfj6c" in namespace "gc-6021"
  E0904 19:16:56.958890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:16:56.963603 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hnxft" in namespace "gc-6021"
  I0904 19:16:56.977759 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j62tl" in namespace "gc-6021"
  I0904 19:16:56.996378 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j9lnf" in namespace "gc-6021"
  I0904 19:16:57.013413 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6021" for this suite. @ 09/04/24 19:16:57.019
• [17.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:270
  STEP: Creating a kubernetes client @ 09/04/24 19:16:57.03
  I0904 19:16:57.030198 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:16:57.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:16:57.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:16:57.071
  STEP: Setting up server cert @ 09/04/24 19:16:57.107
  E0904 19:16:57.974837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:16:58.051
  STEP: Deploying the webhook pod @ 09/04/24 19:16:58.164
  STEP: Wait for the deployment to be ready @ 09/04/24 19:16:58.183
  I0904 19:16:58.194598 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:16:58.959810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:16:59.959887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:17:00.207
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:17:00.217
  E0904 19:17:00.960001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:17:01.218425 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 09/04/24 19:17:01.227
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 09/04/24 19:17:01.24
  STEP: Creating a dummy validating-webhook-configuration object @ 09/04/24 19:17:01.252
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 09/04/24 19:17:01.261
  STEP: Creating a dummy mutating-webhook-configuration object @ 09/04/24 19:17:01.27
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 09/04/24 19:17:01.277
  I0904 19:17:01.336755 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7854" for this suite. @ 09/04/24 19:17:01.34
  STEP: Destroying namespace "webhook-markers-9687" for this suite. @ 09/04/24 19:17:01.352
• [4.333 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 09/04/24 19:17:01.369
  I0904 19:17:01.369854 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename svcaccounts @ 09/04/24 19:17:01.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:01.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:01.399
  STEP: Creating ServiceAccount "e2e-sa-t2v2s"  @ 09/04/24 19:17:01.403
  I0904 19:17:01.407810 19 service_accounts.go:825] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-t2v2s"  @ 09/04/24 19:17:01.407
  I0904 19:17:01.415903 19 service_accounts.go:839] AutomountServiceAccountToken: true
  I0904 19:17:01.415981 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7466" for this suite. @ 09/04/24 19:17:01.419
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 09/04/24 19:17:01.428
  I0904 19:17:01.428681 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:17:01.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:01.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:01.45
  STEP: Creating configMap with name projected-configmap-test-volume-119b0147-bddd-4a35-b65d-67ced4ee19b0 @ 09/04/24 19:17:01.453
  STEP: Creating a pod to test consume configMaps @ 09/04/24 19:17:01.459
  E0904 19:17:01.960076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:02.960960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:03.961084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:04.961244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:17:05.487
  I0904 19:17:05.491397 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-configmaps-3f147c0f-2773-46e8-8aa4-0ba6c4c4737a container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 19:17:05.501
  I0904 19:17:05.515125 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5235" for this suite. @ 09/04/24 19:17:05.518
• [4.097 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:287
  STEP: Creating a kubernetes client @ 09/04/24 19:17:05.526
  I0904 19:17:05.526294 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename field-validation @ 09/04/24 19:17:05.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:05.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:05.548
  I0904 19:17:05.552366 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:17:05.962260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:06.962662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:07.962896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:17:08.634170 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6455" for this suite. @ 09/04/24 19:17:08.637
• [3.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 09/04/24 19:17:08.643
  I0904 19:17:08.643724 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 19:17:08.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:08.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:08.664
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 09/04/24 19:17:08.667
  E0904 19:17:08.963015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:09.963223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:10.964072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:11.964140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:17:12.688
  I0904 19:17:12.693974 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-48ea5b3c-f934-4764-8469-d8d57c82cdb4 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:17:12.699
  I0904 19:17:12.716030 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9230" for this suite. @ 09/04/24 19:17:12.72
• [4.083 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 09/04/24 19:17:12.726
  I0904 19:17:12.726939 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename endpointslice @ 09/04/24 19:17:12.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:12.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:12.748
  I0904 19:17:12.761023 19 endpointslice.go:1045] Endpoints addresses: [172.31.29.199 172.31.79.72] , ports: [6443]
  I0904 19:17:12.761070 19 endpointslice.go:1075] EndpointSlices addresses: [172.31.29.199 172.31.79.72] , ports: [6443]
  I0904 19:17:12.761166 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-680" for this suite. @ 09/04/24 19:17:12.764
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 09/04/24 19:17:12.77
  I0904 19:17:12.770232 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-pred @ 09/04/24 19:17:12.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:12.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:12.792
  I0904 19:17:12.796333 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0904 19:17:12.803387 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I0904 19:17:12.806985 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-21-169 before test
  I0904 19:17:12.811769 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-d6dp4 from ingress-nginx-kubernetes-worker started at 2024-09-04 18:53:47 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.811851 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:17:12.811902 19 predicates.go:957] calico-node-2rjpm from kube-system started at 2024-09-04 17:55:30 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.811948 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:17:12.811991 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-09-04 17:58:02 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.812017 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0904 19:17:12.812043 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-zslmr from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:17:12.812069 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:17:12.812094 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0904 19:17:12.812121 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-40-239 before test
  I0904 19:17:12.817512 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-n2qsn from ingress-nginx-kubernetes-worker started at 2024-09-04 17:47:19 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.817531 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:17:12.817549 19 predicates.go:957] calico-node-kswsn from kube-system started at 2024-09-04 17:55:51 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.817555 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:17:12.817560 19 predicates.go:957] sonobuoy-e2e-job-7c4b682519124aad from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:17:12.817565 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0904 19:17:12.817571 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:17:12.817577 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-lk4m4 from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:17:12.817582 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:17:12.817588 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0904 19:17:12.817593 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-7-223 before test
  I0904 19:17:12.822175 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-z5zrp from ingress-nginx-kubernetes-worker started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.822268 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:17:12.822302 19 predicates.go:957] calico-node-bc9bt from kube-system started at 2024-09-04 17:55:40 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.822343 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:17:12.822376 19 predicates.go:957] coredns-5b4857d7c8-brh4s from kube-system started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.822422 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0904 19:17:12.822448 19 predicates.go:957] kube-state-metrics-5d7bdccd49-77shl from kube-system started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.822469 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 0
  I0904 19:17:12.822504 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-v8zbg from kube-system started at 2024-09-04 17:46:10 +0000 UTC (2 container statuses recorded)
  I0904 19:17:12.822528 19 predicates.go:959] 	Container metrics-server ready: true, restart count 0
  I0904 19:17:12.822550 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I0904 19:17:12.822586 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-lr685 from kubernetes-dashboard started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.822611 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I0904 19:17:12.822636 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-862w2 from kubernetes-dashboard started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:17:12.822676 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 0
  I0904 19:17:12.822700 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-wh7sc from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:17:12.822724 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:17:12.822761 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/04/24 19:17:12.822
  E0904 19:17:12.964815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:13.964882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/04/24 19:17:14.84
  STEP: Trying to apply a random label on the found node. @ 09/04/24 19:17:14.854
  STEP: verifying the node has the label kubernetes.io/e2e-6dd67c87-070c-4349-93ae-a59cd2ad3bf2 42 @ 09/04/24 19:17:14.862
  STEP: Trying to relaunch the pod, now with labels. @ 09/04/24 19:17:14.865
  E0904 19:17:14.964949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:15.965148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-6dd67c87-070c-4349-93ae-a59cd2ad3bf2 off the node ip-172-31-21-169 @ 09/04/24 19:17:16.886
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-6dd67c87-070c-4349-93ae-a59cd2ad3bf2 @ 09/04/24 19:17:16.897
  I0904 19:17:16.901214 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2631" for this suite. @ 09/04/24 19:17:16.908
• [4.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 09/04/24 19:17:16.917
  I0904 19:17:16.917071 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 19:17:16.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:16.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:16.939
  STEP: creating the pod @ 09/04/24 19:17:16.942
  STEP: submitting the pod to kubernetes @ 09/04/24 19:17:16.942
  W0904 19:17:16.951574      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0904 19:17:16.965311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:17.965694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:18.966106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 09/04/24 19:17:18.966
  STEP: updating the pod @ 09/04/24 19:17:18.97
  I0904 19:17:19.484785 19 pod_client.go:173] Successfully updated pod "pod-update-activedeadlineseconds-2b06ee94-d266-4411-b9b3-bb42cda5f1ea"
  E0904 19:17:19.966697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:20.966910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:21.967448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:22.967848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:17:23.497784 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7607" for this suite. @ 09/04/24 19:17:23.501
• [6.590 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:400
  STEP: Creating a kubernetes client @ 09/04/24 19:17:23.507
  I0904 19:17:23.507413 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:17:23.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:23.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:23.528
  STEP: Setting up server cert @ 09/04/24 19:17:23.554
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:17:23.787
  STEP: Deploying the webhook pod @ 09/04/24 19:17:23.794
  STEP: Wait for the deployment to be ready @ 09/04/24 19:17:23.805
  I0904 19:17:23.813915 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:17:23.968179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:24.968264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:17:25.825
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:17:25.836
  E0904 19:17:25.968710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:17:26.836438 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 09/04/24 19:17:26.844
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/04/24 19:17:26.856
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 09/04/24 19:17:26.862
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/04/24 19:17:26.873
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 09/04/24 19:17:26.884
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/04/24 19:17:26.891
  I0904 19:17:26.931179 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8949" for this suite. @ 09/04/24 19:17:26.937
  STEP: Destroying namespace "webhook-markers-3417" for this suite. @ 09/04/24 19:17:26.945
• [3.445 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 09/04/24 19:17:26.953
  I0904 19:17:26.953199 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/04/24 19:17:26.953
  E0904 19:17:26.969318      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:26.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:26.972
  I0904 19:17:26.980132 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-9921" for this suite. @ 09/04/24 19:17:26.985
• [0.039 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 09/04/24 19:17:26.991
  I0904 19:17:26.991951 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename csiinlinevolumes @ 09/04/24 19:17:26.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:27.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:27.011
  STEP: creating @ 09/04/24 19:17:27.014
  STEP: getting @ 09/04/24 19:17:27.03
  STEP: listing in namespace @ 09/04/24 19:17:27.033
  STEP: patching @ 09/04/24 19:17:27.036
  STEP: deleting @ 09/04/24 19:17:27.044
  I0904 19:17:27.060812 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-6011" for this suite. @ 09/04/24 19:17:27.063
• [0.078 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 09/04/24 19:17:27.069
  I0904 19:17:27.069954 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-runtime @ 09/04/24 19:17:27.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:27.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:27.091
  STEP: create the container @ 09/04/24 19:17:27.094
  W0904 19:17:27.102664      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 09/04/24 19:17:27.102
  E0904 19:17:27.969487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:28.969649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:29.969709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/04/24 19:17:30.122
  STEP: the container should be terminated @ 09/04/24 19:17:30.125
  STEP: the termination message should be set @ 09/04/24 19:17:30.125
  I0904 19:17:30.125565 19 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 09/04/24 19:17:30.125
  I0904 19:17:30.144044 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3770" for this suite. @ 09/04/24 19:17:30.148
• [3.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 09/04/24 19:17:30.16
  I0904 19:17:30.160240 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/04/24 19:17:30.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:30.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:30.18
  STEP: create the container to handle the HTTPGet hook request. @ 09/04/24 19:17:30.187
  E0904 19:17:30.970427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:31.970540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/04/24 19:17:32.206
  E0904 19:17:32.970635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:33.970715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 09/04/24 19:17:34.228
  STEP: delete the pod with lifecycle hook @ 09/04/24 19:17:34.245
  E0904 19:17:34.971567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:35.971618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:17:36.262048 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-724" for this suite. @ 09/04/24 19:17:36.266
• [6.115 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 09/04/24 19:17:36.275
  I0904 19:17:36.275410 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 19:17:36.276
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:36.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:36.297
  STEP: Creating configMap with name configmap-test-volume-map-57c52905-5ec8-443b-abf0-5f6326a1ae9d @ 09/04/24 19:17:36.301
  STEP: Creating a pod to test consume configMaps @ 09/04/24 19:17:36.307
  E0904 19:17:36.972467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:37.972558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:38.973596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:39.973661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:17:40.331
  I0904 19:17:40.334472 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-d6d0ead6-25b4-4858-846b-a2029aacae68 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 19:17:40.341
  I0904 19:17:40.356548 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4562" for this suite. @ 09/04/24 19:17:40.359
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 09/04/24 19:17:40.368
  I0904 19:17:40.368551 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 19:17:40.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:40.516
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:40.519
  STEP: set up a multi version CRD @ 09/04/24 19:17:40.523
  I0904 19:17:40.523653 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:17:40.974692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:41.975036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:42.975119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: rename a version @ 09/04/24 19:17:43.754
  STEP: check the new version name is served @ 09/04/24 19:17:43.77
  E0904 19:17:43.975906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 09/04/24 19:17:44.568
  E0904 19:17:44.976652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 09/04/24 19:17:45.175
  E0904 19:17:45.977043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:46.985494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:17:47.709714 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3758" for this suite. @ 09/04/24 19:17:47.716
• [7.354 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:221
  STEP: Creating a kubernetes client @ 09/04/24 19:17:47.722
  I0904 19:17:47.722888 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-preemption @ 09/04/24 19:17:47.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:17:47.742
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:17:47.745
  I0904 19:17:47.764388 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0904 19:17:47.985638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:48.986685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:49.987455      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:50.987663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:51.988485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:52.988828      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:53.989539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:54.989625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:55.990207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:56.990309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:57.990679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:58.990780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:17:59.991612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:00.991701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:01.992363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:02.992443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:03.993304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:04.993390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:05.994283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:06.994348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:07.995350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:08.995513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:09.996361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:10.996421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:11.997044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:12.997750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:13.998298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:14.999039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:16.000121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:17.000909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:18.001129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:19.001313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:20.002361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:21.002449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:22.003122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:23.003956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:24.004078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:25.004213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:26.005205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:27.005322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:28.005425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:29.005619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:30.006616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:31.006820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:32.007779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:33.008215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:34.009033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:35.009133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:36.009882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:37.010654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:38.011172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:39.011277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:40.011321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:41.011508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:42.011968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:43.012071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:44.012316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:45.012498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:46.012564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:47.012766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:18:47.769665 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 09/04/24 19:18:47.772
  I0904 19:18:47.792737 19 preemption.go:266] Created pod: pod0-0-sched-preemption-low-priority
  I0904 19:18:47.799359 19 preemption.go:266] Created pod: pod0-1-sched-preemption-medium-priority
  I0904 19:18:47.813508 19 preemption.go:266] Created pod: pod1-0-sched-preemption-medium-priority
  I0904 19:18:47.825900 19 preemption.go:266] Created pod: pod1-1-sched-preemption-medium-priority
  I0904 19:18:47.841086 19 preemption.go:266] Created pod: pod2-0-sched-preemption-medium-priority
  I0904 19:18:47.956590 19 preemption.go:266] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 09/04/24 19:18:47.956
  E0904 19:18:48.013105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:49.013212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 09/04/24 19:18:49.984
  E0904 19:18:50.013780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:51.013920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:52.014178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:53.015259      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:54.015409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:18:54.090862 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3908" for this suite. @ 09/04/24 19:18:54.094
• [66.378 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 09/04/24 19:18:54.1
  I0904 19:18:54.100760 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 19:18:54.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:18:54.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:18:54.123
  STEP: Creating configMap with name cm-test-opt-del-8acf153c-234a-49ca-8a73-d75cdcb348ba @ 09/04/24 19:18:54.129
  STEP: Creating configMap with name cm-test-opt-upd-7af991f2-1963-4d15-ae73-99bcaf3b94dd @ 09/04/24 19:18:54.134
  STEP: Creating the pod @ 09/04/24 19:18:54.137
  E0904 19:18:55.015566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:56.015643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-8acf153c-234a-49ca-8a73-d75cdcb348ba @ 09/04/24 19:18:56.185
  STEP: Updating configmap cm-test-opt-upd-7af991f2-1963-4d15-ae73-99bcaf3b94dd @ 09/04/24 19:18:56.192
  STEP: Creating configMap with name cm-test-opt-create-2d1d43b6-c416-48dc-9971-18f368cb85f5 @ 09/04/24 19:18:56.196
  STEP: waiting to observe update in volume @ 09/04/24 19:18:56.201
  E0904 19:18:57.016101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:58.017028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:18:59.017065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:00.017146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:01.017618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:02.017644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:03.018687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:04.018778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:05.019279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:06.019374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:07.019487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:08.019842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:09.020268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:10.020673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:11.020785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:12.020861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:13.021901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:14.021992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:15.022074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:16.022183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:17.022694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:18.022950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:19.023293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:20.023424      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:21.023862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:22.024108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:23.024905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:24.025111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:25.026062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:26.026160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:27.026263      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:28.026373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:29.026482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:30.027539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:31.027651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:32.027766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:33.028731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:34.028831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:35.028928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:36.029033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:37.029983      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:38.031011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:39.031144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:40.031363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:41.031459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:42.031571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:43.032145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:44.032361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:45.032481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:46.032560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:47.033330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:48.033429      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:49.034126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:50.034226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:51.034337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:52.034432      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:53.034537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:54.034651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:55.034757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:56.034977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:57.035087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:58.035321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:19:59.036280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:00.036426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:01.036850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:02.037088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:03.037695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:04.037776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:05.038765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:06.038920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:07.039877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:08.039951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:09.040790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:10.040896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:11.041403      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:12.041628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:13.042094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:14.042694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:20:14.556311 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4396" for this suite. @ 09/04/24 19:20:14.56
• [80.468 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 09/04/24 19:20:14.569
  I0904 19:20:14.569101 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubelet-test @ 09/04/24 19:20:14.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:14.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:14.589
  E0904 19:20:15.043625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:16.044084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:20:16.622189 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8228" for this suite. @ 09/04/24 19:20:16.626
• [2.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 09/04/24 19:20:16.635
  I0904 19:20:16.635511 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:20:16.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:16.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:16.656
  STEP: Creating configMap with name projected-configmap-test-volume-map-3be30743-1efa-4e6a-b685-56f943d39680 @ 09/04/24 19:20:16.659
  STEP: Creating a pod to test consume configMaps @ 09/04/24 19:20:16.666
  E0904 19:20:17.044414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:18.044511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:19.044618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:20.044723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:20:20.689
  I0904 19:20:20.693153 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-projected-configmaps-4ebae1bb-0848-4335-9f52-099e033181a0 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 19:20:20.699
  I0904 19:20:20.715896 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-665" for this suite. @ 09/04/24 19:20:20.718
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1054
  STEP: Creating a kubernetes client @ 09/04/24 19:20:20.728
  I0904 19:20:20.728321 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename job @ 09/04/24 19:20:20.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:20.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:20.748
  STEP: Creating a job @ 09/04/24 19:20:20.751
  STEP: Ensure pods equal to parallelism count is attached to the job @ 09/04/24 19:20:20.756
  E0904 19:20:21.045600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:22.045709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching /status @ 09/04/24 19:20:22.761
  STEP: updating /status @ 09/04/24 19:20:22.769
  STEP: get /status @ 09/04/24 19:20:22.776
  I0904 19:20:22.780043 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3090" for this suite. @ 09/04/24 19:20:22.783
• [2.065 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 09/04/24 19:20:22.793
  I0904 19:20:22.793193 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:20:22.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:22.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:22.813
  STEP: Creating projection with secret that has name projected-secret-test-03fafede-7d10-49ef-ac25-e97190d467c0 @ 09/04/24 19:20:22.816
  STEP: Creating a pod to test consume secrets @ 09/04/24 19:20:22.821
  E0904 19:20:23.046095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:24.046541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:25.046497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:26.046590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:20:26.841
  I0904 19:20:26.844885 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-projected-secrets-81f87c43-29df-4324-a420-dbac31346ec4 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 19:20:26.85
  I0904 19:20:26.864496 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5584" for this suite. @ 09/04/24 19:20:26.867
• [4.081 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 09/04/24 19:20:26.874
  I0904 19:20:26.874692 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename watch @ 09/04/24 19:20:26.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:26.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:26.896
  STEP: creating a watch on configmaps with a certain label @ 09/04/24 19:20:26.899
  STEP: creating a new configmap @ 09/04/24 19:20:26.901
  STEP: modifying the configmap once @ 09/04/24 19:20:26.904
  STEP: changing the label value of the configmap @ 09/04/24 19:20:26.912
  STEP: Expecting to observe a delete notification for the watched object @ 09/04/24 19:20:26.92
  I0904 19:20:26.920174 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3867  eedc1bd1-b658-4c01-8e5b-600897e941de 39636 0 2024-09-04 19:20:26 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-04 19:20:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 19:20:26.920331 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3867  eedc1bd1-b658-4c01-8e5b-600897e941de 39637 0 2024-09-04 19:20:26 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-04 19:20:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 19:20:26.920416 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3867  eedc1bd1-b658-4c01-8e5b-600897e941de 39638 0 2024-09-04 19:20:26 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-04 19:20:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 09/04/24 19:20:26.92
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 09/04/24 19:20:26.927
  E0904 19:20:27.047568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:28.047842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:29.048027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:30.048130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:31.048759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:32.049034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:33.049672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:34.049601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:35.049679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:36.050649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 09/04/24 19:20:36.927
  STEP: modifying the configmap a third time @ 09/04/24 19:20:36.938
  STEP: deleting the configmap @ 09/04/24 19:20:36.949
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 09/04/24 19:20:36.955
  I0904 19:20:36.955761 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3867  eedc1bd1-b658-4c01-8e5b-600897e941de 39704 0 2024-09-04 19:20:26 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-04 19:20:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 19:20:36.955922 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3867  eedc1bd1-b658-4c01-8e5b-600897e941de 39705 0 2024-09-04 19:20:26 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-04 19:20:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 19:20:36.955987 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3867  eedc1bd1-b658-4c01-8e5b-600897e941de 39706 0 2024-09-04 19:20:26 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-04 19:20:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0904 19:20:36.956069 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3867" for this suite. @ 09/04/24 19:20:36.96
• [10.095 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 09/04/24 19:20:36.969
  I0904 19:20:36.969485 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename namespaces @ 09/04/24 19:20:36.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:36.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:36.993
  STEP: Creating namespace "e2e-ns-rtzgf" @ 09/04/24 19:20:36.996
  I0904 19:20:37.014549 19 namespace.go:411] Namespace "e2e-ns-rtzgf-6680" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-rtzgf-6680" @ 09/04/24 19:20:37.014
  I0904 19:20:37.024109 19 namespace.go:434] Namespace "e2e-ns-rtzgf-6680" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-rtzgf-6680" @ 09/04/24 19:20:37.024
  I0904 19:20:37.032391 19 namespace.go:463] Namespace "e2e-ns-rtzgf-6680" has []v1.FinalizerName{"kubernetes"}
  I0904 19:20:37.032553 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-583" for this suite. @ 09/04/24 19:20:37.038
  STEP: Destroying namespace "e2e-ns-rtzgf-6680" for this suite. @ 09/04/24 19:20:37.046
  E0904 19:20:37.051239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [0.084 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 09/04/24 19:20:37.053
  I0904 19:20:37.053402 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/04/24 19:20:37.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:37.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:37.076
  STEP: creating the policy @ 09/04/24 19:20:37.085
  STEP: waiting until the marker is denied @ 09/04/24 19:20:37.108
  STEP: testing a replicated Deployment to be allowed @ 09/04/24 19:20:37.617
  STEP: testing a non-replicated ReplicaSet not to be denied @ 09/04/24 19:20:37.632
  I0904 19:20:37.696994 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-4364" for this suite. @ 09/04/24 19:20:37.7
• [0.654 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 09/04/24 19:20:37.707
  I0904 19:20:37.707327 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename var-expansion @ 09/04/24 19:20:37.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:37.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:37.728
  STEP: Creating a pod to test env composition @ 09/04/24 19:20:37.732
  E0904 19:20:38.051908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:39.052190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:40.052569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:41.052713      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:20:41.761
  I0904 19:20:41.765699 19 output.go:196] Trying to get logs from node ip-172-31-7-223 pod var-expansion-086680a0-fea0-4239-bcfe-cddf155e5b70 container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 19:20:41.785
  I0904 19:20:41.804301 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3656" for this suite. @ 09/04/24 19:20:41.807
• [4.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 09/04/24 19:20:41.813
  I0904 19:20:41.813738 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:20:41.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:41.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:41.834
  STEP: Creating projection with secret that has name projected-secret-test-map-8b1df4e4-0606-4099-b4e1-40a3b6072c4e @ 09/04/24 19:20:41.838
  STEP: Creating a pod to test consume secrets @ 09/04/24 19:20:41.841
  E0904 19:20:42.052763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:43.052862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:44.053614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:45.053706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:20:45.864
  I0904 19:20:45.867719 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-secrets-456938e4-81e7-420e-803c-3c6d0416a332 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 19:20:45.873
  I0904 19:20:45.889988 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-105" for this suite. @ 09/04/24 19:20:45.893
• [4.088 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1530
  STEP: Creating a kubernetes client @ 09/04/24 19:20:45.901
  I0904 19:20:45.901432 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 19:20:45.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:45.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:45.922
  STEP: creating Agnhost RC @ 09/04/24 19:20:45.925
  I0904 19:20:45.925369 19 kubectl.go:1537] namespace kubectl-4539
  I0904 19:20:45.925430 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-4539 create -f -'
  I0904 19:20:46.004484 19 builder.go:146] stderr: ""
  I0904 19:20:46.004535 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/04/24 19:20:46.004
  E0904 19:20:46.054667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:20:47.010028 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0904 19:20:47.010058 19 framework.go:733] Found 1 / 1
  I0904 19:20:47.010070 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0904 19:20:47.015131 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0904 19:20:47.015149 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0904 19:20:47.015156 19 kubectl.go:1544] wait on agnhost-primary startup in kubectl-4539 
  I0904 19:20:47.015244 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-4539 logs agnhost-primary-vg9bp agnhost-primary'
  E0904 19:20:47.055495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:20:47.064574 19 builder.go:146] stderr: ""
  I0904 19:20:47.064599 19 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 09/04/24 19:20:47.064
  I0904 19:20:47.064758 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-4539 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0904 19:20:47.122772 19 builder.go:146] stderr: ""
  I0904 19:20:47.122809 19 builder.go:147] stdout: "service/rm2 exposed\n"
  I0904 19:20:47.126576 19 utils.go:1203] Service rm2 in namespace kubectl-4539 found.
  E0904 19:20:48.055751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:49.055862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: exposing service @ 09/04/24 19:20:49.135
  I0904 19:20:49.135447 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-4539 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0904 19:20:49.192280 19 builder.go:146] stderr: ""
  I0904 19:20:49.192312 19 builder.go:147] stdout: "service/rm3 exposed\n"
  I0904 19:20:49.196448 19 utils.go:1203] Service rm3 in namespace kubectl-4539 found.
  E0904 19:20:50.056507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:51.056699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:20:51.204867 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4539" for this suite. @ 09/04/24 19:20:51.209
• [5.317 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:246
  STEP: Creating a kubernetes client @ 09/04/24 19:20:51.218
  I0904 19:20:51.218222 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename dns @ 09/04/24 19:20:51.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:51.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:51.238
  STEP: Creating a test headless service @ 09/04/24 19:20:51.241
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2678.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2678.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 09/04/24 19:20:51.248
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2678.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2678.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 09/04/24 19:20:51.248
  STEP: creating a pod to probe DNS @ 09/04/24 19:20:51.248
  STEP: submitting the pod to kubernetes @ 09/04/24 19:20:51.248
  E0904 19:20:52.056830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:53.056935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/04/24 19:20:53.274
  STEP: looking for the results for each expected name from probers @ 09/04/24 19:20:53.278
  I0904 19:20:53.296383 19 dns_common.go:527] DNS probes using dns-2678/dns-test-6849ce97-40ae-4d54-8eec-90dfd053d34f succeeded

  STEP: deleting the pod @ 09/04/24 19:20:53.296
  STEP: deleting the test headless service @ 09/04/24 19:20:53.309
  I0904 19:20:53.324761 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2678" for this suite. @ 09/04/24 19:20:53.328
• [2.117 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 09/04/24 19:20:53.335
  I0904 19:20:53.335878 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename containers @ 09/04/24 19:20:53.336
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:53.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:53.355
  STEP: Creating a pod to test override command @ 09/04/24 19:20:53.359
  E0904 19:20:54.057035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:55.057251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:20:55.373
  I0904 19:20:55.376318 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod client-containers-6223054d-6147-4080-8695-38cb3317c7d2 container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 19:20:55.383
  I0904 19:20:55.399796 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8232" for this suite. @ 09/04/24 19:20:55.403
• [2.074 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 09/04/24 19:20:55.41
  I0904 19:20:55.410154 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename security-context-test @ 09/04/24 19:20:55.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:55.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:55.43
  E0904 19:20:56.057314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:57.057366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:58.057622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:20:59.057718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:20:59.456221 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7432" for this suite. @ 09/04/24 19:20:59.459
• [4.057 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:760
  STEP: Creating a kubernetes client @ 09/04/24 19:20:59.467
  I0904 19:20:59.467676 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 19:20:59.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:20:59.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:20:59.601
  STEP: creating service endpoint-test2 in namespace services-5635 @ 09/04/24 19:20:59.604
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5635 to expose endpoints map[] @ 09/04/24 19:20:59.618
  I0904 19:20:59.628025 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-5635 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-5635 @ 09/04/24 19:20:59.628
  E0904 19:21:00.058612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:01.058696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5635 to expose endpoints map[pod1:[80]] @ 09/04/24 19:21:01.65
  I0904 19:21:01.662565 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-5635 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 09/04/24 19:21:01.662
  I0904 19:21:01.662707 19 resource.go:361] Creating new exec pod
  E0904 19:21:02.059081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:03.059177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:04.060074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:21:04.679891 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5635 exec execpodfsmqg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0904 19:21:04.776398 19 builder.go:146] stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0904 19:21:04.776436 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 19:21:04.776556 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5635 exec execpodfsmqg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.71 80'
  I0904 19:21:04.863242 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.71 80\nConnection to 10.152.183.71 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0904 19:21:04.863283 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-5635 @ 09/04/24 19:21:04.863
  E0904 19:21:05.060580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:06.060679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5635 to expose endpoints map[pod1:[80] pod2:[80]] @ 09/04/24 19:21:06.886
  I0904 19:21:06.901384 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-5635 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 09/04/24 19:21:06.901
  E0904 19:21:07.061144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:21:07.902272 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5635 exec execpodfsmqg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0904 19:21:07.987360 19 builder.go:146] stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0904 19:21:07.987396 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 19:21:07.987501 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5635 exec execpodfsmqg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.71 80'
  E0904 19:21:08.061900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:21:08.083330 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.71 80\nConnection to 10.152.183.71 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0904 19:21:08.083368 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-5635 @ 09/04/24 19:21:08.083
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5635 to expose endpoints map[pod2:[80]] @ 09/04/24 19:21:08.098
  E0904 19:21:09.062729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:21:09.122825 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-5635 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 09/04/24 19:21:09.122
  E0904 19:21:10.062848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:21:10.123121 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5635 exec execpodfsmqg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0904 19:21:10.213445 19 builder.go:146] stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0904 19:21:10.213505 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0904 19:21:10.213636 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=services-5635 exec execpodfsmqg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.71 80'
  I0904 19:21:10.300669 19 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.71 80\n+ echo hostName\nConnection to 10.152.183.71 80 port [tcp/http] succeeded!\n"
  I0904 19:21:10.300722 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-5635 @ 09/04/24 19:21:10.3
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5635 to expose endpoints map[] @ 09/04/24 19:21:10.316
  I0904 19:21:10.329689 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-5635 exposes endpoints map[]
  I0904 19:21:10.350633 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5635" for this suite. @ 09/04/24 19:21:10.354
• [10.894 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 09/04/24 19:21:10.362
  I0904 19:21:10.362234 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 19:21:10.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:21:10.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:21:10.381
  STEP: Creating a pod to test downward api env vars @ 09/04/24 19:21:10.384
  E0904 19:21:11.063753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:12.063839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:13.063972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:14.064081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:21:14.406
  I0904 19:21:14.410454 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downward-api-defdcf12-eda9-4da0-b193-9347ff51d215 container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 19:21:14.422
  I0904 19:21:14.439934 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-474" for this suite. @ 09/04/24 19:21:14.443
• [4.088 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 09/04/24 19:21:14.45
  I0904 19:21:14.450466 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sched-pred @ 09/04/24 19:21:14.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:21:14.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:21:14.469
  I0904 19:21:14.472482 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0904 19:21:14.478811 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I0904 19:21:14.481182 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-21-169 before test
  I0904 19:21:14.491601 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-d6dp4 from ingress-nginx-kubernetes-worker started at 2024-09-04 18:53:47 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.491617 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:21:14.491623 19 predicates.go:957] calico-node-2rjpm from kube-system started at 2024-09-04 17:55:30 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.491628 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:21:14.491633 19 predicates.go:957] execpodfsmqg from services-5635 started at 2024-09-04 19:21:01 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.491637 19 predicates.go:959] 	Container agnhost-container ready: true, restart count 0
  I0904 19:21:14.491642 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-09-04 17:58:02 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.491646 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0904 19:21:14.491651 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-zslmr from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:21:14.491656 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:21:14.491660 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0904 19:21:14.491665 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-40-239 before test
  I0904 19:21:14.514590 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-n2qsn from ingress-nginx-kubernetes-worker started at 2024-09-04 17:47:19 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.514635 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:21:14.514641 19 predicates.go:957] calico-node-kswsn from kube-system started at 2024-09-04 17:55:51 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.514668 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:21:14.514774 19 predicates.go:957] sonobuoy-e2e-job-7c4b682519124aad from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:21:14.514799 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0904 19:21:14.514804 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:21:14.514879 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-lk4m4 from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:21:14.514940 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:21:14.514976 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0904 19:21:14.514982 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-7-223 before test
  I0904 19:21:14.524649 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-z5zrp from ingress-nginx-kubernetes-worker started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.524663 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0904 19:21:14.524670 19 predicates.go:957] calico-node-bc9bt from kube-system started at 2024-09-04 17:55:40 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.524694 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0904 19:21:14.524700 19 predicates.go:957] coredns-5b4857d7c8-brh4s from kube-system started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.524704 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0904 19:21:14.524709 19 predicates.go:957] kube-state-metrics-5d7bdccd49-77shl from kube-system started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.524714 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 0
  I0904 19:21:14.524719 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-v8zbg from kube-system started at 2024-09-04 17:46:10 +0000 UTC (2 container statuses recorded)
  I0904 19:21:14.524723 19 predicates.go:959] 	Container metrics-server ready: true, restart count 0
  I0904 19:21:14.524728 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I0904 19:21:14.524732 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-lr685 from kubernetes-dashboard started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.524737 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I0904 19:21:14.524741 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-862w2 from kubernetes-dashboard started at 2024-09-04 17:46:10 +0000 UTC (1 container statuses recorded)
  I0904 19:21:14.524759 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 0
  I0904 19:21:14.524765 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-05cf3b834db94fab-wh7sc from sonobuoy started at 2024-09-04 17:58:04 +0000 UTC (2 container statuses recorded)
  I0904 19:21:14.524770 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0904 19:21:14.524775 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/04/24 19:21:14.524
  E0904 19:21:15.064195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:16.064477      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/04/24 19:21:16.558
  STEP: Trying to apply a random label on the found node. @ 09/04/24 19:21:16.575
  STEP: verifying the node has the label kubernetes.io/e2e-e9c6c470-460b-4bab-b0f4-d9ed730eb0e6 95 @ 09/04/24 19:21:16.585
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 09/04/24 19:21:16.588
  E0904 19:21:17.065479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:18.065609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.21.169 on the node which pod4 resides and expect not scheduled @ 09/04/24 19:21:18.605
  E0904 19:21:19.065715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:20.065824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:21.066408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:22.066695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:23.067598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:24.067698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:25.067812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:26.067931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:27.068988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:28.069145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:29.069840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:30.069906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:31.070658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:32.070785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:33.071429      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:34.071629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:35.071746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:36.071955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:37.072063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:38.072143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:39.072987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:40.073089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:41.073206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:42.073428      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:43.073547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:44.073610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:45.074702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:46.074793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:47.074927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:48.075004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:49.075115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:50.075239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:51.075997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:52.076212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:53.077133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:54.077217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:55.078096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:56.078692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:57.078865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:58.079025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:21:59.079138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:00.079230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:01.079335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:02.079392      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:03.079460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:04.079565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:05.080344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:06.080410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:07.081187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:08.082065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:09.082183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:10.082283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:11.083185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:12.083260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:13.084140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:14.084345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:15.085170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:16.085353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:17.085418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:18.085621      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:19.086550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:20.086704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:21.087319      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:22.087423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:23.088358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:24.088557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:25.089324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:26.089482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:27.089617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:28.089710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:29.090441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:30.090556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:31.091015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:32.091254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:33.092064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:34.092325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:35.092853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:36.093084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:37.093663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:38.093992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:39.094663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:40.094773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:41.095360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:42.095545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:43.095975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:44.096168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:45.096382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:46.096617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:47.097110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:48.097380      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:49.097589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:50.098664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:51.098979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:52.099197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:53.099295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:54.099412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:55.099940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:56.100132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:57.101019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:58.101085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:22:59.101523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:00.101609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:01.102019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:02.102671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:03.103284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:04.103464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:05.103888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:06.104001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:07.105023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:08.105276      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:09.105912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:10.106686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:11.107241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:12.108032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:13.108440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:14.108546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:15.108939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:16.109026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:17.109057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:18.109305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:19.109548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:20.109609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:21.110207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:22.111149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:23.111655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:24.111844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:25.112139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:26.112259      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:27.113110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:28.113440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:29.113872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:30.113982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:31.114412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:32.114507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:33.114924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:34.115031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:35.115752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:36.115866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:37.116384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:38.116476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:39.117261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:40.117384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:41.117493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:42.117608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:43.118018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:44.118117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:45.118669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:46.118719      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:47.119044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:48.119138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:49.119661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:50.120332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:51.121362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:52.121508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:53.121702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:54.122670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:55.123364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:56.124137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:57.124552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:58.124870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:23:59.125758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:00.125874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:01.126658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:02.126761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:03.126789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:04.126974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:05.127890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:06.127998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:07.128025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:08.128134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:09.128735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:10.128989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:11.129647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:12.129761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:13.130052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:14.130766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:15.131696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:16.131851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:17.132742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:18.133014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:19.133511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:20.133611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:21.133814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:22.134694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:23.135623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:24.135793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:25.136429      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:26.136617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:27.137093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:28.138178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:29.138517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:30.139060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:31.139415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:32.139691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:33.140309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:34.140490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:35.140865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:36.141085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:37.142092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:38.143139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:39.143289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:40.143639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:41.143843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:42.144009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:43.144090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:44.144263      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:45.144379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:46.144473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:47.144671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:48.145063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:49.145284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:50.145609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:51.145696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:52.145824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:53.145895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:54.145999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:55.146077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:56.146161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:57.146257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:58.146652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:24:59.146715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:00.146844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:01.146937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:02.147050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:03.147132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:04.147250      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:05.147365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:06.147478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:07.147675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:08.147749      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:09.147960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:10.148032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:11.148135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:12.148569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:13.148676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:14.149680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:15.150660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:16.150831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:17.151831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:18.151923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:19.152029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:20.152070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:21.152150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:22.152234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:23.152261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:24.152350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:25.152466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:26.152530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:27.152626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:28.152731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:29.152837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:30.152919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:31.153112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:32.153202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:33.154151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:34.154694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:35.154807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:36.154897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:37.154982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:38.155128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:39.155636      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:40.155745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:41.155851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:42.156242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:43.156341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:44.156478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:45.156585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:46.157588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:47.157668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:48.158692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:49.158890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:50.159515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:51.159614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:52.160460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:53.160592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:54.161297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:55.161512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:56.161619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:57.161716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:58.162704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:25:59.162796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:00.163229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:01.163449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:02.164344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:03.164450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:04.164530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:05.165510      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:06.165617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:07.165699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:08.165801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:09.165898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:10.165996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:11.166692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:12.166790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:13.167106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:14.167221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:15.167301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:16.167438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:17.167696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:18.167804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-e9c6c470-460b-4bab-b0f4-d9ed730eb0e6 off the node ip-172-31-21-169 @ 09/04/24 19:26:18.614
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-e9c6c470-460b-4bab-b0f4-d9ed730eb0e6 @ 09/04/24 19:26:18.627
  I0904 19:26:18.630679 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-451" for this suite. @ 09/04/24 19:26:18.636
• [304.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 09/04/24 19:26:18.642
  I0904 19:26:18.642763 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/04/24 19:26:18.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:26:18.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:26:18.663
  I0904 19:26:18.669518 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-755" for this suite. @ 09/04/24 19:26:18.673
• [0.037 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 09/04/24 19:26:18.68
  I0904 19:26:18.680334 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:26:18.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:26:18.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:26:18.697
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 19:26:18.701
  E0904 19:26:19.168200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:20.168463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:21.169511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:22.169593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:26:22.722
  I0904 19:26:22.726069 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod downwardapi-volume-a792e172-1164-49e4-8a33-d66403d147ed container client-container: <nil>
  STEP: delete the pod @ 09/04/24 19:26:22.744
  I0904 19:26:22.758827 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5095" for this suite. @ 09/04/24 19:26:22.762
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 09/04/24 19:26:22.769
  I0904 19:26:22.769781 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename chunking @ 09/04/24 19:26:22.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:26:22.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:26:22.786
  STEP: creating a large number of resources @ 09/04/24 19:26:22.79
  E0904 19:26:23.170514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:24.170856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:25.171197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:26.171304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:27.171329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:28.171758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:29.172415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:30.173226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:31.173914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:32.174235      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:33.175015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:34.175907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:35.175975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:36.176222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:37.176370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:38.176669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:39.176871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:40.177734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 09/04/24 19:26:40.476
  I0904 19:26:40.526036 19 chunking.go:163] Retrieved 40/40 results with rv 41495 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 09/04/24 19:26:40.526
  E0904 19:26:41.178697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:42.179744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:43.179827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:44.179941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:45.180050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:46.180132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:47.180227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:48.180303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:49.180475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:50.180575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:51.180773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:52.181285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:53.182157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:54.182261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:55.182675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:56.182850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:57.183102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:58.183291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:26:59.183565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:00.183681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:27:00.529504 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:27:01.184195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:02.184456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:03.184783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:04.184991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:05.185178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:06.185378      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:07.185584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:08.185610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:09.185712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:10.186667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:11.186861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:12.187060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:13.187159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:14.187400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:15.187626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:16.187798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:17.188001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:18.188225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:19.188445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:20.188645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:27:20.532473 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:27:21.189147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:22.189339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:23.189588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:24.189692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:25.190655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:26.190838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:27.191348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:28.191454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:29.191576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:30.191767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:31.191971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:32.192226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:33.192328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:34.192526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:35.192739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:36.192908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:37.193083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:38.193143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:39.193330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:40.193548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:27:40.533316 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:27:41.193614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:42.194666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:43.194772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:44.194979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:45.195160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:46.195361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:47.195556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:48.195870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:49.196051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:50.196248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:51.196425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:52.196635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:53.196917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:54.197021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:55.197212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:56.197397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:57.197607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:58.198648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:27:59.199398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:00.199663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:28:00.532187 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:28:01.199760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:02.199852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:03.200774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:04.200874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:05.201050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:06.201242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:07.201480      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:08.201585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:09.202678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:10.202877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:11.203074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:12.203258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:13.203630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:14.203743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:15.203853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:16.204037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:17.204229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:18.204373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:19.204484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:20.204658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:28:20.532483 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:28:21.204786      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:22.204976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:23.205211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:24.205416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:25.205598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:26.206696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:27.206793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:28.207055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:29.207243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:30.207359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:31.207562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:32.207847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:33.208658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:34.208816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:35.208930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:36.209174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:37.209778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:38.209906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:39.210674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:40.211165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:28:40.530861 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:28:41.211274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:42.211469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:43.211908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:44.212152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:45.212347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:46.212518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:47.212625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:48.212927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:49.213121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:50.213278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:51.213500      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:52.213595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:53.214664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:54.214825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:55.215111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:56.215271      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:57.215475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:58.215779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:28:59.215951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:00.216133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:29:00.532370 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:29:01.217103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:02.217226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:03.217552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:04.217586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:05.217617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:06.218650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:07.218819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:08.219173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:09.219282      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:10.219465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:11.219635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:12.219723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:13.220095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:14.220528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:15.220629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:16.221043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:17.221156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:18.221480      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:19.221598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:20.222679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:29:20.532590 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:29:21.223256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:22.223445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:23.223844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:24.223952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:25.224491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:26.224608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:27.224800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:28.225122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:29.225222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:30.225332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:31.225539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:32.225616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:33.226671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:34.226768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:35.226933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:36.227114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:37.227228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:38.227469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:39.227586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:40.227763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:29:40.531788 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:29:41.228473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:42.228640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:43.228744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:44.228837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:45.229001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:46.229100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:47.229270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:48.229367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:49.229492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:50.229589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:51.229703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:52.230655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:53.230995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:54.231167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:55.231336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:56.231498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:57.231586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:58.231686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:29:59.231781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:00.231970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:30:00.531601 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:30:01.232331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:02.232508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:03.232620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:04.232789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:05.232893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:06.233091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:07.233269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:08.233550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:09.233614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:10.234650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:11.234816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:12.234911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:13.235155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:14.235356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:15.235529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:16.235722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:17.235891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:18.236859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:19.236964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:20.237073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:30:20.531047 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:30:21.237598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:22.237788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:23.237876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:24.238672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:25.239511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:26.239625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:27.239742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:28.240028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:29.240461      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:30.240651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:31.240833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:32.241108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:33.241221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:34.241422      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:35.241597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:36.241679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:37.242665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:38.242767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:39.242954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:40.243129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:30:40.532275 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:30:41.244053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:42.244242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:43.244357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:44.244590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:45.244684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:46.244856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:47.245041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:48.245154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:49.245267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:50.245438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:51.245593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:52.246667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:53.247025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:54.247148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:55.247333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:56.247506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:57.247689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:58.247989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:30:59.248097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:00.248286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:31:00.532107 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:31:01.248396      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:02.248588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:03.248907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:04.249595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:05.249682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:06.250707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:07.250804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:08.250912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:09.251108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:10.251266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:11.251446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:12.251624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:13.251896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:14.252085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:15.252287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:16.252472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:17.252669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:18.252760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:19.252874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:20.253033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:31:20.531996 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:31:21.253591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:22.254667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:23.254945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:24.255181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:25.255293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:26.255475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:27.255672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:28.255944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:29.256157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:30.256286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:31.256331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:32.256499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:33.256613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:34.256754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:35.256847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:36.257019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:37.257224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:38.257437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:39.257598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:40.257623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:31:40.532485 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:31:41.258652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:42.258752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:43.258844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:44.259496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:45.259596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:46.260265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:47.260893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:48.261114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:49.261308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:50.261538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:51.261612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:52.261712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:53.262671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:54.262847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:55.263024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:56.263188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:57.263362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:58.263468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:31:59.263646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:00.263922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:32:00.530619 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:32:01.264333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:02.264524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:03.264868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:04.265030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:05.265221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:06.265703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:07.266716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:08.267085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:09.267252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:10.267673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:11.267780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:12.267884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:13.268023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:14.268211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:15.268389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:16.268574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:17.268688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:18.268832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:19.269012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:20.269189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:32:20.531809 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:32:21.269304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:22.269407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:23.269601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:24.269737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:25.269826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:26.269917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:27.270955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:28.271175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:29.271300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:30.271372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:31.271523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:32.271849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:33.271789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:34.271978      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:35.272190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:36.272350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:37.272546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:38.272986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:39.273160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:40.273349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:32:40.530815 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:32:41.273492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:42.273597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:43.274668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:44.274863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:45.275042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:46.275176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:47.275361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:48.275679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:49.275856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:50.276026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:51.276122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:52.276300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:53.276498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:54.276694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:55.276811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:56.276992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:57.277169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:58.277425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:32:59.277588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:00.277687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:33:00.532777 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:33:01.278561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:02.278729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:03.278843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:04.279007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:05.279254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:06.279531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:07.279629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:08.279726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:09.280777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:10.280881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:11.280966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:12.281357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:13.281587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:14.281686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:15.282675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:16.282848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:17.283042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:18.283278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:19.283466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:20.283626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:33:20.532344 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:33:21.284137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:22.284249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:23.284466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:24.284709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:25.284906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:26.285081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:27.285190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:28.285238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:29.285410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:30.285583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:31.285614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:32.286673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:33.286768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:34.286934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:35.287041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:36.287740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:37.287923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:38.288147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:39.288332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:40.288381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:33:40.531089 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:33:41.288853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:42.289034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:43.289287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:44.289399      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:45.289585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:46.289674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:47.290668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:48.290753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:49.290859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:50.291019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:51.291112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:52.291268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:53.291364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:54.291452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:55.291611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:56.291765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:57.291968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:58.292194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:33:59.292314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:00.292447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:34:00.532435 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:34:01.292539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:02.292743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:03.292839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:04.293010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:05.293199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:06.293377      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:07.293584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:08.293626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:09.294703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:10.294811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:11.294990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:12.295103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:13.295483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:14.295666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:15.295868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:16.296615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:17.296789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:18.296919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:19.297105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:20.297264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:34:20.531110 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:34:21.297580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:22.297615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:23.298655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:24.298777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:25.298879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:26.299063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:27.300075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:28.300231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:29.300344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:30.300520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:31.300731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:32.301005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:33.301285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:34.301363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:35.301597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:36.301615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:37.301713      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:38.302666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:39.302840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:40.302995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:34:40.532007 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:34:41.303793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:42.303906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:43.304179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:44.304331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:45.304491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:46.304782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:47.305574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:48.305670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:49.305774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:50.306693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:51.307725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:52.307824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:53.308112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:54.308324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:55.308489      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:56.308593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:57.308763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:58.309139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:34:59.309303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:00.309388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:35:00.531756 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:35:01.309592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:02.309617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:03.310675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:04.310779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:05.311077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:06.311170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:07.311341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:08.311656      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:09.311818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:10.312117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:11.312264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:12.312359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:13.312726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:14.312994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:15.313173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:16.313376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:17.313592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:18.313686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:19.314706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:20.314817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:35:20.532095 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:35:21.316309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:22.316497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:23.316611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:24.316775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:25.316971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:26.317131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:27.318163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:28.318233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:29.318330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:30.318661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:31.318752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:32.318863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:33.319230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:34.319330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:35.319430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:36.319998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:37.320097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:38.321158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:39.321275      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:40.321480      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:35:40.531891 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDE0OTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0904 19:35:41.321594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:42.322649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:43.322790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:44.322876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:45.323046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:46.323239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:47.323405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:48.323747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:49.323998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:50.324272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:51.324839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:52.325015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:53.325161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:54.325355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:55.325581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:56.325611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:57.325712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:58.325815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:35:59.326664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:00.326856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:00.530444 19 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0904 19:36:00.530476 19 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 09/04/24 19:36:00.53
  STEP: retrieving all remaining pages @ 09/04/24 19:36:00.535
  I0904 19:36:00.539362 19 chunking.go:221] Retrieved 40/40 results with rv 42559 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDI1NTksInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  I0904 19:36:00.542913 19 chunking.go:221] Retrieved 40/40 results with rv 42559 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDI1NTksInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  I0904 19:36:00.547311 19 chunking.go:221] Retrieved 40/40 results with rv 42559 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDI1NTksInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  I0904 19:36:00.551552 19 chunking.go:221] Retrieved 40/40 results with rv 42559 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDI1NTksInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  I0904 19:36:00.555090 19 chunking.go:221] Retrieved 40/40 results with rv 42559 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDI1NTksInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  I0904 19:36:00.559260 19 chunking.go:221] Retrieved 40/40 results with rv 42559 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDI1NTksInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  I0904 19:36:00.563419 19 chunking.go:221] Retrieved 40/40 results with rv 42559 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDI1NTksInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  I0904 19:36:00.567005 19 chunking.go:221] Retrieved 40/40 results with rv 42559 and continue 
  I0904 19:36:00.567204 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-4194" for this suite. @ 09/04/24 19:36:00.571
• [577.811 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 09/04/24 19:36:00.58
  I0904 19:36:00.580969 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename csistoragecapacity @ 09/04/24 19:36:00.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:00.608
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:00.614
  STEP: getting /apis @ 09/04/24 19:36:00.618
  STEP: getting /apis/storage.k8s.io @ 09/04/24 19:36:00.622
  STEP: getting /apis/storage.k8s.io/v1 @ 09/04/24 19:36:00.624
  STEP: creating @ 09/04/24 19:36:00.625
  STEP: watching @ 09/04/24 19:36:00.65
  I0904 19:36:00.650484 19 csistoragecapacity.go:143] starting watch
  STEP: getting @ 09/04/24 19:36:00.66
  STEP: listing in namespace @ 09/04/24 19:36:00.663
  STEP: listing across namespaces @ 09/04/24 19:36:00.668
  STEP: patching @ 09/04/24 19:36:00.673
  STEP: updating @ 09/04/24 19:36:00.679
  I0904 19:36:00.688011 19 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0904 19:36:00.688134 19 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 09/04/24 19:36:00.688
  STEP: deleting a collection @ 09/04/24 19:36:00.704
  I0904 19:36:00.722892 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-9500" for this suite. @ 09/04/24 19:36:00.728
• [0.158 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 09/04/24 19:36:00.742
  I0904 19:36:00.742920 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 19:36:00.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:00.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:00.764
  STEP: creating the pod @ 09/04/24 19:36:00.769
  STEP: submitting the pod to kubernetes @ 09/04/24 19:36:00.769
  STEP: verifying QOS class is set on the pod @ 09/04/24 19:36:00.779
  I0904 19:36:00.784322 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4406" for this suite. @ 09/04/24 19:36:00.795
• [0.062 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 09/04/24 19:36:00.805
  I0904 19:36:00.805543 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename sysctl @ 09/04/24 19:36:00.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:00.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:00.839
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 09/04/24 19:36:00.843
  STEP: Watching for error events or started pod @ 09/04/24 19:36:00.854
  E0904 19:36:01.327979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:02.328046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 09/04/24 19:36:02.86
  E0904 19:36:03.328199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:04.328294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 09/04/24 19:36:04.873
  STEP: Getting logs from the pod @ 09/04/24 19:36:04.873
  STEP: Checking that the sysctl is actually updated @ 09/04/24 19:36:04.893
  I0904 19:36:04.893393 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9800" for this suite. @ 09/04/24 19:36:04.898
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:940
  STEP: Creating a kubernetes client @ 09/04/24 19:36:04.904
  I0904 19:36:04.904415 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename resourcequota @ 09/04/24 19:36:04.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:04.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:04.928
  STEP: Creating a ResourceQuota @ 09/04/24 19:36:04.931
  STEP: Getting a ResourceQuota @ 09/04/24 19:36:04.936
  STEP: Updating a ResourceQuota @ 09/04/24 19:36:04.941
  STEP: Verifying a ResourceQuota was modified @ 09/04/24 19:36:04.948
  STEP: Deleting a ResourceQuota @ 09/04/24 19:36:04.957
  STEP: Verifying the deleted ResourceQuota @ 09/04/24 19:36:04.966
  I0904 19:36:04.973323 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7451" for this suite. @ 09/04/24 19:36:04.977
• [0.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 09/04/24 19:36:04.985
  I0904 19:36:04.985847 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename subpath @ 09/04/24 19:36:04.986
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:05.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:05.012
  STEP: Setting up data @ 09/04/24 19:36:05.023
  STEP: Creating pod pod-subpath-test-downwardapi-brqs @ 09/04/24 19:36:05.034
  STEP: Creating a pod to test atomic-volume-subpath @ 09/04/24 19:36:05.034
  E0904 19:36:05.328417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:06.328521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:07.329167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:08.329401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:09.330399      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:10.330474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:11.331411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:12.331479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:13.331597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:14.331682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:15.332048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:16.332149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:17.332708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:18.333027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:19.334070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:20.334676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:21.334812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:22.334863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:23.334994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:24.335095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:25.336071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:26.336187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:27.337218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:28.337487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:36:29.111
  I0904 19:36:29.115855 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-subpath-test-downwardapi-brqs container test-container-subpath-downwardapi-brqs: <nil>
  STEP: delete the pod @ 09/04/24 19:36:29.123
  STEP: Deleting pod pod-subpath-test-downwardapi-brqs @ 09/04/24 19:36:29.143
  I0904 19:36:29.143248 19 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-brqs" in namespace "subpath-3769"
  I0904 19:36:29.145962 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3769" for this suite. @ 09/04/24 19:36:29.148
• [24.168 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 09/04/24 19:36:29.154
  I0904 19:36:29.154326 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename endpointslice @ 09/04/24 19:36:29.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:29.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:29.176
  E0904 19:36:29.338371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:30.338483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 09/04/24 19:36:31.261
  STEP: referencing matching pods with named port @ 09/04/24 19:36:31.267
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 09/04/24 19:36:31.274
  STEP: recreating EndpointSlices after they've been deleted @ 09/04/24 19:36:31.281
  I0904 19:36:31.300930 19 endpointslice.go:938] EndpointSlice for Service endpointslice-4210/example-named-port not found
  E0904 19:36:31.339091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:32.339385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:33.306710 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4210" for this suite. @ 09/04/24 19:36:33.311
• [4.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 09/04/24 19:36:33.318
  I0904 19:36:33.318979 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:36:33.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:33.336
  E0904 19:36:33.339779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:33.34
  STEP: Creating the pod @ 09/04/24 19:36:33.343
  E0904 19:36:34.339956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:35.340405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:35.897332 19 pod_client.go:173] Successfully updated pod "labelsupdate9377ec0b-54f5-48fc-bb50-c5517d1996e2"
  E0904 19:36:36.341376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:37.341494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:37.919296 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6646" for this suite. @ 09/04/24 19:36:37.924
• [4.613 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 09/04/24 19:36:37.931
  I0904 19:36:37.931826 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename security-context-test @ 09/04/24 19:36:37.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:37.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:37.949
  E0904 19:36:38.341560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:39.341639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:40.341734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:41.342475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:41.984782 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9708" for this suite. @ 09/04/24 19:36:41.989
• [4.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 09/04/24 19:36:41.996
  I0904 19:36:41.996975 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename proxy @ 09/04/24 19:36:41.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:42.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:42.017
  STEP: starting an echo server on multiple ports @ 09/04/24 19:36:42.029
  STEP: creating replication controller proxy-service-qffvp in namespace proxy-9813 @ 09/04/24 19:36:42.03
  I0904 19:36:42.040298      19 runners.go:193] Created replication controller with name: proxy-service-qffvp, namespace: proxy-9813, replica count: 1
  E0904 19:36:42.342964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:43.090579      19 runners.go:193] proxy-service-qffvp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0904 19:36:43.343026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:44.090714      19 runners.go:193] proxy-service-qffvp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0904 19:36:44.095762 19 proxy.go:230] setup took 2.074886603s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 09/04/24 19:36:44.095
  I0904 19:36:44.102194 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 6.116188ms)
  I0904 19:36:44.102784 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.789999ms)
  I0904 19:36:44.102792 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 6.876427ms)
  I0904 19:36:44.102805 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 6.753691ms)
  I0904 19:36:44.103668 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 7.571379ms)
  I0904 19:36:44.104245 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 8.08409ms)
  I0904 19:36:44.104343 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 8.460782ms)
  I0904 19:36:44.104371 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 8.361978ms)
  I0904 19:36:44.104541 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 8.352438ms)
  I0904 19:36:44.104904 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 8.757439ms)
  I0904 19:36:44.105508 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 9.536886ms)
  I0904 19:36:44.105914 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 9.879539ms)
  I0904 19:36:44.105927 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 9.75638ms)
  I0904 19:36:44.105975 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 10.022161ms)
  I0904 19:36:44.107121 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 11.010432ms)
  I0904 19:36:44.107121 19 proxy.go:558] (0) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 10.990836ms)
  I0904 19:36:44.112614 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 5.345648ms)
  I0904 19:36:44.112750 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 5.504915ms)
  I0904 19:36:44.112761 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 5.400653ms)
  I0904 19:36:44.113144 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 5.938752ms)
  I0904 19:36:44.113241 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 5.956763ms)
  I0904 19:36:44.113346 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 5.955579ms)
  I0904 19:36:44.113354 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 5.923622ms)
  I0904 19:36:44.113433 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 6.236737ms)
  I0904 19:36:44.113442 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 6.022523ms)
  I0904 19:36:44.114237 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.830978ms)
  I0904 19:36:44.114566 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 7.12ms)
  I0904 19:36:44.114566 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 7.256088ms)
  I0904 19:36:44.114761 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 7.415326ms)
  I0904 19:36:44.114831 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 7.458336ms)
  I0904 19:36:44.114838 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 7.509451ms)
  I0904 19:36:44.115753 19 proxy.go:558] (1) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 8.289625ms)
  I0904 19:36:44.119635 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 3.852038ms)
  I0904 19:36:44.119818 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 4.04774ms)
  I0904 19:36:44.120664 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 4.628636ms)
  I0904 19:36:44.121642 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 5.691114ms)
  I0904 19:36:44.121640 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 5.545186ms)
  I0904 19:36:44.121670 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 5.703012ms)
  I0904 19:36:44.121707 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 5.637622ms)
  I0904 19:36:44.122091 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 6.011152ms)
  I0904 19:36:44.122402 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 6.468279ms)
  I0904 19:36:44.122631 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 6.746916ms)
  I0904 19:36:44.122940 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 6.938444ms)
  I0904 19:36:44.123234 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 7.186634ms)
  I0904 19:36:44.123538 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 7.626503ms)
  I0904 19:36:44.123731 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 7.717563ms)
  I0904 19:36:44.123851 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 7.8682ms)
  I0904 19:36:44.124109 19 proxy.go:558] (2) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 7.995926ms)
  I0904 19:36:44.129125 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 4.701947ms)
  I0904 19:36:44.129710 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 5.508439ms)
  I0904 19:36:44.130267 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 5.824846ms)
  I0904 19:36:44.130394 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 6.055383ms)
  I0904 19:36:44.130559 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.048159ms)
  I0904 19:36:44.130695 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 6.375582ms)
  I0904 19:36:44.131132 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 6.756301ms)
  I0904 19:36:44.131239 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 7.097245ms)
  I0904 19:36:44.131615 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 7.126036ms)
  I0904 19:36:44.131615 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 7.366351ms)
  I0904 19:36:44.131667 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 7.541124ms)
  I0904 19:36:44.131933 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 7.661257ms)
  I0904 19:36:44.132011 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 7.717038ms)
  I0904 19:36:44.132251 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 7.894557ms)
  I0904 19:36:44.132498 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 8.033915ms)
  I0904 19:36:44.132843 19 proxy.go:558] (3) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 8.446277ms)
  I0904 19:36:44.136253 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 3.326673ms)
  I0904 19:36:44.137296 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 4.284283ms)
  I0904 19:36:44.138966 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 6.005597ms)
  I0904 19:36:44.139485 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 6.588207ms)
  I0904 19:36:44.139488 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.442886ms)
  I0904 19:36:44.139898 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 6.920911ms)
  I0904 19:36:44.139898 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 6.824801ms)
  I0904 19:36:44.140510 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 7.514164ms)
  I0904 19:36:44.140509 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 7.648104ms)
  I0904 19:36:44.140647 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 7.525972ms)
  I0904 19:36:44.140648 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 7.587552ms)
  I0904 19:36:44.140883 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 7.851102ms)
  I0904 19:36:44.141507 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 8.370035ms)
  I0904 19:36:44.142027 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 8.939846ms)
  I0904 19:36:44.142045 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 8.943901ms)
  I0904 19:36:44.142672 19 proxy.go:558] (4) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 9.523388ms)
  I0904 19:36:44.147167 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 4.326926ms)
  I0904 19:36:44.147339 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 4.648413ms)
  I0904 19:36:44.147339 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 4.530271ms)
  I0904 19:36:44.148327 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 5.534335ms)
  I0904 19:36:44.148568 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 5.634202ms)
  I0904 19:36:44.148797 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 5.814413ms)
  I0904 19:36:44.149299 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 6.437391ms)
  I0904 19:36:44.150403 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 7.438452ms)
  I0904 19:36:44.150466 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 7.544522ms)
  I0904 19:36:44.150523 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 7.575087ms)
  I0904 19:36:44.150533 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 7.709831ms)
  I0904 19:36:44.150674 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 7.91818ms)
  I0904 19:36:44.150704 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 7.971967ms)
  I0904 19:36:44.152122 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 9.229967ms)
  I0904 19:36:44.152121 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 9.244225ms)
  I0904 19:36:44.152260 19 proxy.go:558] (5) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 9.353183ms)
  I0904 19:36:44.165031 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 12.540661ms)
  I0904 19:36:44.165047 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 12.58688ms)
  I0904 19:36:44.165060 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 12.511977ms)
  I0904 19:36:44.165068 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 12.685982ms)
  I0904 19:36:44.168147 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 15.615699ms)
  I0904 19:36:44.168592 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 16.146244ms)
  I0904 19:36:44.169611 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 17.182454ms)
  I0904 19:36:44.169632 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 17.131754ms)
  I0904 19:36:44.169644 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 17.336513ms)
  I0904 19:36:44.171873 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 19.399123ms)
  I0904 19:36:44.172319 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 19.967901ms)
  I0904 19:36:44.172464 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 20.053611ms)
  I0904 19:36:44.172482 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 20.15261ms)
  I0904 19:36:44.172502 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 19.990546ms)
  I0904 19:36:44.172812 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 20.24871ms)
  I0904 19:36:44.173132 19 proxy.go:558] (6) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 20.76254ms)
  I0904 19:36:44.179493 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 6.059758ms)
  I0904 19:36:44.179492 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 6.299812ms)
  I0904 19:36:44.180740 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 7.471902ms)
  I0904 19:36:44.181242 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 7.908827ms)
  I0904 19:36:44.181242 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 8.063193ms)
  I0904 19:36:44.182061 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 8.819483ms)
  I0904 19:36:44.182061 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 8.706665ms)
  I0904 19:36:44.183205 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 9.897187ms)
  I0904 19:36:44.183217 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 9.726412ms)
  I0904 19:36:44.183421 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 10.054145ms)
  I0904 19:36:44.183455 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 10.003121ms)
  I0904 19:36:44.183466 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 10.183767ms)
  I0904 19:36:44.183475 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 10.090431ms)
  I0904 19:36:44.184010 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 10.593814ms)
  I0904 19:36:44.184283 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 10.882566ms)
  I0904 19:36:44.184479 19 proxy.go:558] (7) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 11.002809ms)
  I0904 19:36:44.188861 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 4.341745ms)
  I0904 19:36:44.190359 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 5.47039ms)
  I0904 19:36:44.191681 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 6.955373ms)
  I0904 19:36:44.191681 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 6.86606ms)
  I0904 19:36:44.192492 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 7.79934ms)
  I0904 19:36:44.193071 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 8.40224ms)
  I0904 19:36:44.194275 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 9.482546ms)
  I0904 19:36:44.194339 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 9.72134ms)
  I0904 19:36:44.194703 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 9.925798ms)
  I0904 19:36:44.194784 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 9.915525ms)
  I0904 19:36:44.194796 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 10.039286ms)
  I0904 19:36:44.195287 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 10.538619ms)
  I0904 19:36:44.195289 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 10.45647ms)
  I0904 19:36:44.195509 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 10.657506ms)
  I0904 19:36:44.196043 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 11.45674ms)
  I0904 19:36:44.197009 19 proxy.go:558] (8) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 12.367918ms)
  I0904 19:36:44.202040 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 4.993044ms)
  I0904 19:36:44.203513 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 6.168585ms)
  I0904 19:36:44.206243 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 9.129858ms)
  I0904 19:36:44.206475 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 9.246071ms)
  I0904 19:36:44.207773 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 10.44502ms)
  I0904 19:36:44.208001 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 10.835564ms)
  I0904 19:36:44.208004 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 10.730617ms)
  I0904 19:36:44.208616 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 11.357571ms)
  I0904 19:36:44.208764 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 11.681413ms)
  I0904 19:36:44.209320 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 12.14019ms)
  I0904 19:36:44.209340 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 12.130012ms)
  I0904 19:36:44.209553 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 12.358076ms)
  I0904 19:36:44.209832 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 12.543582ms)
  I0904 19:36:44.210646 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 13.513256ms)
  I0904 19:36:44.211117 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 13.806134ms)
  I0904 19:36:44.211668 19 proxy.go:558] (9) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 14.42422ms)
  I0904 19:36:44.217641 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 5.884378ms)
  I0904 19:36:44.218111 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 6.308637ms)
  I0904 19:36:44.219607 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 7.660207ms)
  I0904 19:36:44.220762 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 8.905854ms)
  I0904 19:36:44.220819 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 8.914653ms)
  I0904 19:36:44.220768 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 9.063231ms)
  I0904 19:36:44.222123 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 10.30128ms)
  I0904 19:36:44.222123 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 10.287855ms)
  I0904 19:36:44.222140 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 10.146652ms)
  I0904 19:36:44.222306 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 10.372404ms)
  I0904 19:36:44.222603 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 10.640939ms)
  I0904 19:36:44.223246 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 11.267483ms)
  I0904 19:36:44.223719 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 11.846338ms)
  I0904 19:36:44.224210 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 12.199148ms)
  I0904 19:36:44.224210 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 12.29326ms)
  I0904 19:36:44.224440 19 proxy.go:558] (10) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 12.55009ms)
  I0904 19:36:44.230752 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 6.248487ms)
  I0904 19:36:44.232552 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 7.825668ms)
  I0904 19:36:44.232582 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 7.795185ms)
  I0904 19:36:44.232552 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 7.940253ms)
  I0904 19:36:44.234256 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 9.55464ms)
  I0904 19:36:44.234295 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 9.702628ms)
  I0904 19:36:44.234460 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 9.702902ms)
  I0904 19:36:44.234581 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 10.058318ms)
  I0904 19:36:44.234597 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 9.821384ms)
  I0904 19:36:44.235357 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 10.793461ms)
  I0904 19:36:44.235518 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 10.836811ms)
  I0904 19:36:44.235548 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 10.742855ms)
  I0904 19:36:44.236182 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 11.60368ms)
  I0904 19:36:44.236200 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 11.460418ms)
  I0904 19:36:44.236460 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 11.798891ms)
  I0904 19:36:44.236656 19 proxy.go:558] (11) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 12.017331ms)
  I0904 19:36:44.241882 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 5.165855ms)
  I0904 19:36:44.242050 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 5.336044ms)
  I0904 19:36:44.243105 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.1827ms)
  I0904 19:36:44.243730 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 6.875164ms)
  I0904 19:36:44.244339 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 7.557704ms)
  I0904 19:36:44.244797 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 8.032708ms)
  I0904 19:36:44.245502 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 8.595943ms)
  I0904 19:36:44.246037 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 9.203901ms)
  I0904 19:36:44.247008 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 10.034153ms)
  I0904 19:36:44.247010 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 10.121297ms)
  I0904 19:36:44.247237 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 10.240448ms)
  I0904 19:36:44.247249 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 10.310591ms)
  I0904 19:36:44.247593 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 10.638652ms)
  I0904 19:36:44.248203 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 11.391415ms)
  I0904 19:36:44.248520 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 11.647069ms)
  I0904 19:36:44.248776 19 proxy.go:558] (12) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 11.980645ms)
  I0904 19:36:44.254893 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 5.856978ms)
  I0904 19:36:44.256495 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 7.51687ms)
  I0904 19:36:44.256566 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 7.667145ms)
  I0904 19:36:44.256643 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 7.847649ms)
  I0904 19:36:44.256671 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 7.808202ms)
  I0904 19:36:44.257928 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 8.973265ms)
  I0904 19:36:44.258006 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 8.987572ms)
  I0904 19:36:44.258410 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 9.352901ms)
  I0904 19:36:44.258415 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 9.330686ms)
  I0904 19:36:44.258564 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 9.627053ms)
  I0904 19:36:44.258644 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 9.812945ms)
  I0904 19:36:44.258644 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 9.651345ms)
  I0904 19:36:44.259047 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 10.12499ms)
  I0904 19:36:44.259561 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 10.460553ms)
  I0904 19:36:44.259793 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 10.675699ms)
  I0904 19:36:44.260006 19 proxy.go:558] (13) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 11.000526ms)
  I0904 19:36:44.265128 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 5.064558ms)
  I0904 19:36:44.265152 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 5.120573ms)
  I0904 19:36:44.265685 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 5.536834ms)
  I0904 19:36:44.266698 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.415248ms)
  I0904 19:36:44.267572 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 7.333607ms)
  I0904 19:36:44.268586 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 8.375434ms)
  I0904 19:36:44.268978 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 8.725359ms)
  I0904 19:36:44.269953 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 9.727125ms)
  I0904 19:36:44.270010 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 9.908056ms)
  I0904 19:36:44.270061 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 9.765214ms)
  I0904 19:36:44.270434 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 10.167748ms)
  I0904 19:36:44.270519 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 10.323676ms)
  I0904 19:36:44.270931 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 10.615284ms)
  I0904 19:36:44.271248 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 11.069291ms)
  I0904 19:36:44.271276 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 11.111374ms)
  I0904 19:36:44.271301 19 proxy.go:558] (14) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 11.199208ms)
  I0904 19:36:44.278231 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 6.827804ms)
  I0904 19:36:44.279659 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 8.193643ms)
  I0904 19:36:44.279659 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 8.058305ms)
  I0904 19:36:44.280211 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 8.625649ms)
  I0904 19:36:44.282272 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 10.736195ms)
  I0904 19:36:44.282272 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 10.607601ms)
  I0904 19:36:44.282765 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 11.291845ms)
  I0904 19:36:44.282766 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 11.150409ms)
  I0904 19:36:44.282825 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 11.444554ms)
  I0904 19:36:44.283947 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 12.265304ms)
  I0904 19:36:44.283993 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 12.42335ms)
  I0904 19:36:44.284006 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 12.455156ms)
  I0904 19:36:44.284433 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 12.920338ms)
  I0904 19:36:44.284476 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 12.84728ms)
  I0904 19:36:44.284901 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 13.409076ms)
  I0904 19:36:44.284923 19 proxy.go:558] (15) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 13.27679ms)
  I0904 19:36:44.289781 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 4.761329ms)
  I0904 19:36:44.291917 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 6.875698ms)
  I0904 19:36:44.292187 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 7.051332ms)
  I0904 19:36:44.293200 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 8.081972ms)
  I0904 19:36:44.293441 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 8.470746ms)
  I0904 19:36:44.293918 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 8.687048ms)
  I0904 19:36:44.293937 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 8.870848ms)
  I0904 19:36:44.295235 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 10.083088ms)
  I0904 19:36:44.295289 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 10.043481ms)
  I0904 19:36:44.295299 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 10.084452ms)
  I0904 19:36:44.295491 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 10.291085ms)
  I0904 19:36:44.295537 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 10.262896ms)
  I0904 19:36:44.296206 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 11.040327ms)
  I0904 19:36:44.296205 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 11.101074ms)
  I0904 19:36:44.296464 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 11.284285ms)
  I0904 19:36:44.296659 19 proxy.go:558] (16) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 11.400121ms)
  I0904 19:36:44.301648 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 4.928892ms)
  I0904 19:36:44.302766 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 5.937937ms)
  I0904 19:36:44.303335 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.356905ms)
  I0904 19:36:44.303882 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 7.194779ms)
  I0904 19:36:44.304816 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 8.036969ms)
  I0904 19:36:44.305886 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 9.041145ms)
  I0904 19:36:44.305913 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 8.948928ms)
  I0904 19:36:44.306285 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 9.538488ms)
  I0904 19:36:44.307244 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 10.444237ms)
  I0904 19:36:44.307633 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 10.74818ms)
  I0904 19:36:44.307633 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 10.734328ms)
  I0904 19:36:44.307715 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 10.766043ms)
  I0904 19:36:44.308453 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 11.581134ms)
  I0904 19:36:44.308557 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 11.638896ms)
  I0904 19:36:44.308791 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 11.856578ms)
  I0904 19:36:44.309107 19 proxy.go:558] (17) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 12.249619ms)
  I0904 19:36:44.313285 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 4.072942ms)
  I0904 19:36:44.314630 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 5.402416ms)
  I0904 19:36:44.314638 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 5.224374ms)
  I0904 19:36:44.315656 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 6.271461ms)
  I0904 19:36:44.316146 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 7.019874ms)
  I0904 19:36:44.316146 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 6.817288ms)
  I0904 19:36:44.316344 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 6.917206ms)
  I0904 19:36:44.316355 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.985315ms)
  I0904 19:36:44.316797 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 7.455178ms)
  I0904 19:36:44.316951 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 7.764922ms)
  I0904 19:36:44.316962 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 7.702782ms)
  I0904 19:36:44.317187 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 7.906446ms)
  I0904 19:36:44.317470 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 8.070228ms)
  I0904 19:36:44.317748 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 8.449208ms)
  I0904 19:36:44.318032 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 8.717951ms)
  I0904 19:36:44.318542 19 proxy.go:558] (18) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 9.18479ms)
  I0904 19:36:44.322066 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:162/proxy/: bar (200; 3.465359ms)
  I0904 19:36:44.322333 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq/proxy/rewriteme">test</a> (200; 3.76416ms)
  I0904 19:36:44.323244 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:1080/proxy/rewriteme">... (200; 4.616967ms)
  I0904 19:36:44.323384 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:462/proxy/: tls qux (200; 4.614842ms)
  I0904 19:36:44.323784 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:460/proxy/: tls baz (200; 4.979647ms)
  I0904 19:36:44.323870 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:162/proxy/: bar (200; 5.225386ms)
  I0904 19:36:44.324485 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:1080/proxy/rewriteme">test<... (200; 5.608017ms)
  I0904 19:36:44.324520 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/proxy-service-qffvp-sttlq:160/proxy/: foo (200; 5.737107ms)
  I0904 19:36:44.324903 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/: <a href="/api/v1/namespaces/proxy-9813/pods/https:proxy-service-qffvp-sttlq:443/proxy/tlsrewritem... (200; 6.184818ms)
  I0904 19:36:44.325332 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname1/proxy/: foo (200; 6.514956ms)
  I0904 19:36:44.325347 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/pods/http:proxy-service-qffvp-sttlq:160/proxy/: foo (200; 6.615358ms)
  I0904 19:36:44.325683 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname1/proxy/: tls baz (200; 6.992792ms)
  I0904 19:36:44.325819 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/services/https:proxy-service-qffvp:tlsportname2/proxy/: tls qux (200; 6.968587ms)
  I0904 19:36:44.326159 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname1/proxy/: foo (200; 7.408148ms)
  I0904 19:36:44.326581 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/services/http:proxy-service-qffvp:portname2/proxy/: bar (200; 7.74624ms)
  I0904 19:36:44.326768 19 proxy.go:558] (19) /api/v1/namespaces/proxy-9813/services/proxy-service-qffvp:portname2/proxy/: bar (200; 7.90264ms)
  STEP: deleting ReplicationController proxy-service-qffvp in namespace proxy-9813, will wait for the garbage collector to delete the pods @ 09/04/24 19:36:44.326
  E0904 19:36:44.343723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:44.388439 19 resources.go:139] Deleting ReplicationController proxy-service-qffvp took: 8.560632ms
  I0904 19:36:44.489166 19 resources.go:163] Terminating ReplicationController proxy-service-qffvp pods took: 100.709638ms
  E0904 19:36:45.343951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:46.344856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:46.589770 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-9813" for this suite. @ 09/04/24 19:36:46.594
• [4.605 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:878
  STEP: Creating a kubernetes client @ 09/04/24 19:36:46.601
  I0904 19:36:46.601944 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 19:36:46.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:46.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:46.621
  STEP: validating api versions @ 09/04/24 19:36:46.624
  I0904 19:36:46.624972 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-2516 api-versions'
  I0904 19:36:46.664693 19 builder.go:146] stderr: ""
  I0904 19:36:46.664739 19 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I0904 19:36:46.664908 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2516" for this suite. @ 09/04/24 19:36:46.669
• [0.076 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:337
  STEP: Creating a kubernetes client @ 09/04/24 19:36:46.677
  I0904 19:36:46.677883 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename security-context @ 09/04/24 19:36:46.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:46.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:46.698
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 09/04/24 19:36:46.704
  E0904 19:36:47.345914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:48.346273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:36:48.72
  I0904 19:36:48.724737 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod security-context-0bed54b2-0a08-47a9-9411-19c8443eb0d6 container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:36:48.73
  I0904 19:36:48.746759 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-2339" for this suite. @ 09/04/24 19:36:48.75
• [2.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:298
  STEP: Creating a kubernetes client @ 09/04/24 19:36:48.757
  I0904 19:36:48.757841 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:36:48.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:48.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:48.78
  STEP: Setting up server cert @ 09/04/24 19:36:48.808
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:36:48.914
  STEP: Deploying the webhook pod @ 09/04/24 19:36:48.923
  STEP: Wait for the deployment to be ready @ 09/04/24 19:36:48.936
  I0904 19:36:48.976492 19 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0904 19:36:49.347105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:50.347208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:36:50.989
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:36:51
  E0904 19:36:51.347293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:36:52.001077 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 09/04/24 19:36:52.008
  STEP: Creating a custom resource definition that should be denied by the webhook @ 09/04/24 19:36:52.022
  I0904 19:36:52.022267 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:36:52.078155 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5455" for this suite. @ 09/04/24 19:36:52.083
  STEP: Destroying namespace "webhook-markers-2798" for this suite. @ 09/04/24 19:36:52.09
• [3.338 seconds]
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 09/04/24 19:36:52.096
  I0904 19:36:52.096394 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename subjectreview @ 09/04/24 19:36:52.096
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:52.113
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:52.116
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-6771" @ 09/04/24 19:36:52.12
  I0904 19:36:52.125163 19 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-6771:e2e"
  I0904 19:36:52.125190 19 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-6771"}
  I0904 19:36:52.125196 19 subjectreviews.go:71] saUID: "ec1c9842-4251-4cce-9b3c-28f1de724660"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-6771:e2e" @ 09/04/24 19:36:52.125
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-6771:e2e" @ 09/04/24 19:36:52.125
  I0904 19:36:52.127254 19 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-6771:e2e" api 'list' configmaps in "subjectreview-6771" namespace @ 09/04/24 19:36:52.127
  I0904 19:36:52.129092 19 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-6771:e2e" @ 09/04/24 19:36:52.129
  I0904 19:36:52.131067 19 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0904 19:36:52.131082 19 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0904 19:36:52.131209 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-6771" for this suite. @ 09/04/24 19:36:52.135
• [0.045 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 09/04/24 19:36:52.141
  I0904 19:36:52.141372 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/04/24 19:36:52.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:52.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:52.164
  STEP: fetching the /apis discovery document @ 09/04/24 19:36:52.167
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 09/04/24 19:36:52.169
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 09/04/24 19:36:52.169
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 09/04/24 19:36:52.169
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 09/04/24 19:36:52.17
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 09/04/24 19:36:52.17
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 09/04/24 19:36:52.171
  I0904 19:36:52.172015 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-759" for this suite. @ 09/04/24 19:36:52.175
• [0.046 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 09/04/24 19:36:52.187
  I0904 19:36:52.187796 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 19:36:52.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:52.206
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:52.209
  STEP: Creating secret with name secret-test-b3abb0da-0b14-4899-96a1-e50ba7f9757b @ 09/04/24 19:36:52.212
  STEP: Creating a pod to test consume secrets @ 09/04/24 19:36:52.216
  E0904 19:36:52.348085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:53.348178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:54.349129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:55.349186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:36:56.241
  I0904 19:36:56.246173 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-secrets-5e404593-7c44-49c8-b073-92cbc9ab4681 container secret-env-test: <nil>
  STEP: delete the pod @ 09/04/24 19:36:56.252
  I0904 19:36:56.271718 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5233" for this suite. @ 09/04/24 19:36:56.276
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 09/04/24 19:36:56.283
  I0904 19:36:56.283110 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir-wrapper @ 09/04/24 19:36:56.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:56.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:56.304
  E0904 19:36:56.349733      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:36:57.349821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 09/04/24 19:36:58.339
  STEP: Cleaning up the configmap @ 09/04/24 19:36:58.345
  E0904 19:36:58.350049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Cleaning up the pod @ 09/04/24 19:36:58.351
  I0904 19:36:58.361529 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-4755" for this suite. @ 09/04/24 19:36:58.364
• [2.088 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 09/04/24 19:36:58.371
  I0904 19:36:58.371571 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:36:58.372
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:36:58.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:36:58.389
  STEP: Creating projection with secret that has name projected-secret-test-e0ce64b2-46c0-4a9b-98df-d28faa41940d @ 09/04/24 19:36:58.393
  STEP: Creating a pod to test consume secrets @ 09/04/24 19:36:58.397
  E0904 19:36:59.350792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:00.350891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:01.352011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:02.352070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:37:02.421
  I0904 19:37:02.425958 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-projected-secrets-0c696b45-adb7-43f0-9df4-6c4b07018b2f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 19:37:02.434
  I0904 19:37:02.454110 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7553" for this suite. @ 09/04/24 19:37:02.458
• [4.094 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1858
  STEP: Creating a kubernetes client @ 09/04/24 19:37:02.466
  I0904 19:37:02.466070 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 19:37:02.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:37:02.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:37:02.487
  STEP: Starting the proxy @ 09/04/24 19:37:02.49
  I0904 19:37:02.491072 19 util.go:585] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-4458 proxy --unix-socket=/tmp/kubectl-proxy-unix704551006/test'
  STEP: retrieving proxy /api/ output @ 09/04/24 19:37:02.52
  I0904 19:37:02.521064 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4458" for this suite. @ 09/04/24 19:37:02.525
• [0.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 09/04/24 19:37:02.533
  I0904 19:37:02.533648 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir-wrapper @ 09/04/24 19:37:02.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:37:02.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:37:02.552
  STEP: Creating 50 configmaps @ 09/04/24 19:37:02.556
  STEP: Creating RC which spawns configmap-volume pods @ 09/04/24 19:37:02.788
  I0904 19:37:02.928774 19 resource.go:87] Pod name wrapped-volume-race-bd8379b7-5408-42a8-befb-5f0a39eaf3f1: Found 3 pods out of 5
  E0904 19:37:03.352875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:04.353138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:05.353433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:06.353662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:07.354695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:37:07.936868 19 resource.go:87] Pod name wrapped-volume-race-bd8379b7-5408-42a8-befb-5f0a39eaf3f1: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/04/24 19:37:07.936
  STEP: Creating RC which spawns configmap-volume pods @ 09/04/24 19:37:07.959
  I0904 19:37:07.973924 19 resource.go:87] Pod name wrapped-volume-race-f7116cae-a631-4da5-be13-64775359362c: Found 0 pods out of 5
  E0904 19:37:08.355516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:09.355634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:10.355729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:11.358823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:12.357980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:37:12.981417 19 resource.go:87] Pod name wrapped-volume-race-f7116cae-a631-4da5-be13-64775359362c: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/04/24 19:37:12.981
  STEP: Creating RC which spawns configmap-volume pods @ 09/04/24 19:37:13.002
  I0904 19:37:13.016595 19 resource.go:87] Pod name wrapped-volume-race-2f786f7e-4085-4002-8a99-feae50418867: Found 0 pods out of 5
  E0904 19:37:13.358106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:14.358209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:15.358269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:16.358365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:17.358501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:37:18.027973 19 resource.go:87] Pod name wrapped-volume-race-2f786f7e-4085-4002-8a99-feae50418867: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/04/24 19:37:18.028
  STEP: deleting ReplicationController wrapped-volume-race-2f786f7e-4085-4002-8a99-feae50418867 in namespace emptydir-wrapper-9649, will wait for the garbage collector to delete the pods @ 09/04/24 19:37:18.053
  I0904 19:37:18.125309 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-2f786f7e-4085-4002-8a99-feae50418867 took: 16.943918ms
  I0904 19:37:18.326266 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-2f786f7e-4085-4002-8a99-feae50418867 pods took: 200.954335ms
  E0904 19:37:18.359528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-f7116cae-a631-4da5-be13-64775359362c in namespace emptydir-wrapper-9649, will wait for the garbage collector to delete the pods @ 09/04/24 19:37:19.226
  I0904 19:37:19.291013 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-f7116cae-a631-4da5-be13-64775359362c took: 9.625053ms
  E0904 19:37:19.359643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:37:19.391888 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-f7116cae-a631-4da5-be13-64775359362c pods took: 100.856606ms
  E0904 19:37:20.360474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-bd8379b7-5408-42a8-befb-5f0a39eaf3f1 in namespace emptydir-wrapper-9649, will wait for the garbage collector to delete the pods @ 09/04/24 19:37:20.892
  I0904 19:37:20.955545 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-bd8379b7-5408-42a8-befb-5f0a39eaf3f1 took: 8.977488ms
  I0904 19:37:21.056239 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-bd8379b7-5408-42a8-befb-5f0a39eaf3f1 pods took: 100.68638ms
  E0904 19:37:21.360998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:22.361081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 09/04/24 19:37:22.756
  I0904 19:37:23.058571 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-9649" for this suite. @ 09/04/24 19:37:23.062
• [20.534 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 09/04/24 19:37:23.068
  I0904 19:37:23.068330 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 19:37:23.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:37:23.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:37:23.088
  I0904 19:37:23.092294 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:37:23.361759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:24.362496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/04/24 19:37:24.389
  I0904 19:37:24.389343 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4005 --namespace=crd-publish-openapi-4005 create -f -'
  E0904 19:37:25.362787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:26.362971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:37:26.456388 19 builder.go:146] stderr: ""
  I0904 19:37:26.456440 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1999-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0904 19:37:26.456493 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4005 --namespace=crd-publish-openapi-4005 delete e2e-test-crd-publish-openapi-1999-crds test-cr'
  I0904 19:37:26.507644 19 builder.go:146] stderr: ""
  I0904 19:37:26.507693 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1999-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I0904 19:37:26.507785 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4005 --namespace=crd-publish-openapi-4005 apply -f -'
  I0904 19:37:26.569935 19 builder.go:146] stderr: ""
  I0904 19:37:26.569984 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1999-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0904 19:37:26.570023 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4005 --namespace=crd-publish-openapi-4005 delete e2e-test-crd-publish-openapi-1999-crds test-cr'
  I0904 19:37:26.616550 19 builder.go:146] stderr: ""
  I0904 19:37:26.616584 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1999-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 09/04/24 19:37:26.616
  I0904 19:37:26.616649 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-4005 explain e2e-test-crd-publish-openapi-1999-crds'
  I0904 19:37:26.655716 19 builder.go:146] stderr: ""
  I0904 19:37:26.655770 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-1999-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0904 19:37:27.363218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:37:27.970340 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4005" for this suite. @ 09/04/24 19:37:27.977
• [4.916 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 09/04/24 19:37:27.984
  I0904 19:37:27.984710 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 19:37:27.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:37:28.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:37:28.006
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 09/04/24 19:37:28.009
  E0904 19:37:28.363323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:29.363411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:30.363542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:31.363793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:37:32.034
  I0904 19:37:32.037743 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-59148d69-3277-4562-85e8-9a5175870cde container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:37:32.049
  I0904 19:37:32.065900 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4416" for this suite. @ 09/04/24 19:37:32.069
• [4.093 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 09/04/24 19:37:32.077
  I0904 19:37:32.077404 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename var-expansion @ 09/04/24 19:37:32.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:37:32.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:37:32.099
  STEP: Creating a pod to test substitution in container's args @ 09/04/24 19:37:32.102
  E0904 19:37:32.363850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:33.363957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:34.364433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:35.364600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:37:36.129
  I0904 19:37:36.132953 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod var-expansion-1caa723b-78fb-4e0c-8995-b99531265256 container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 19:37:36.138
  I0904 19:37:36.158338 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8257" for this suite. @ 09/04/24 19:37:36.163
• [4.093 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 09/04/24 19:37:36.17
  I0904 19:37:36.170565 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:37:36.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:37:36.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:37:36.195
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-6f25f1a2-4d37-424b-bd48-dd181f208cab @ 09/04/24 19:37:36.202
  STEP: Creating the pod @ 09/04/24 19:37:36.209
  E0904 19:37:36.365565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:37.365640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-6f25f1a2-4d37-424b-bd48-dd181f208cab @ 09/04/24 19:37:38.238
  STEP: waiting to observe update in volume @ 09/04/24 19:37:38.243
  E0904 19:37:38.366660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:39.366788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:40.367406      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:41.368099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:42.369127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:43.369238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:44.370075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:45.370712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:46.370963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:47.371057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:48.371516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:49.371619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:50.372500      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:51.373052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:52.373671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:53.374739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:54.375008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:55.375687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:56.375895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:57.376020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:58.376273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:37:59.376480      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:00.376660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:01.376934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:02.377869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:03.378652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:04.379257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:05.379355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:06.380099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:07.380871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:08.381691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:09.382689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:10.382962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:11.383058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:12.383230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:13.384252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:14.384447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:15.384571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:16.384647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:17.385528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:18.385639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:19.385731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:20.385829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:21.385911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:22.386001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:23.386111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:24.386195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:25.386304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:26.386702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:27.386990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:28.387091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:29.387201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:30.387307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:31.387390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:32.387516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:33.388512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:34.388624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:35.388717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:36.389025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:37.389165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:38.389921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:39.390120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:40.390210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:41.390575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:42.390582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:43.390681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:44.390787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:45.390903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:46.391107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:47.391223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:48.391317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:49.391453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:50.391542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:51.391603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:52.391786      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:53.391929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:54.392041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:55.393023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:56.393124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:57.393234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:58.393348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:38:59.393627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:00.394691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:01.395785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:02.395863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:39:02.613728 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4336" for this suite. @ 09/04/24 19:39:02.617
• [86.455 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:52
  STEP: Creating a kubernetes client @ 09/04/24 19:39:02.625
  I0904 19:39:02.625326 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename dns @ 09/04/24 19:39:02.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:02.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:02.65
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 09/04/24 19:39:02.654
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 09/04/24 19:39:02.654
  STEP: creating a pod to probe DNS @ 09/04/24 19:39:02.654
  STEP: submitting the pod to kubernetes @ 09/04/24 19:39:02.654
  E0904 19:39:03.396616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:04.396826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/04/24 19:39:04.673
  STEP: looking for the results for each expected name from probers @ 09/04/24 19:39:04.678
  I0904 19:39:04.699495 19 dns_common.go:527] DNS probes using dns-4458/dns-test-40a42a1f-335f-46f6-bdd3-057cb0c232c1 succeeded

  STEP: deleting the pod @ 09/04/24 19:39:04.699
  I0904 19:39:04.714949 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4458" for this suite. @ 09/04/24 19:39:04.719
• [2.101 seconds]
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 09/04/24 19:39:04.726
  I0904 19:39:04.726582 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename downward-api @ 09/04/24 19:39:04.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:04.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:04.747
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 19:39:04.75
  E0904 19:39:05.397785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:06.398694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:07.398814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:08.398889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:39:08.776
  I0904 19:39:08.780536 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod downwardapi-volume-40586c4b-4bc6-4a32-afb7-b59d33256bfd container client-container: <nil>
  STEP: delete the pod @ 09/04/24 19:39:08.791
  I0904 19:39:08.807294 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9986" for this suite. @ 09/04/24 19:39:08.81
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 09/04/24 19:39:08.818
  I0904 19:39:08.818664 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename secrets @ 09/04/24 19:39:08.819
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:08.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:08.84
  STEP: Creating secret with name secret-test-54813338-0d54-4cdd-82ba-06713e29fb03 @ 09/04/24 19:39:08.843
  STEP: Creating a pod to test consume secrets @ 09/04/24 19:39:08.848
  E0904 19:39:09.399013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:10.399098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:11.399176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:12.399286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:39:12.869
  I0904 19:39:12.873219 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-secrets-e64735f3-f53e-4bba-949e-e154dbbf3bb1 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 19:39:12.88
  I0904 19:39:12.894531 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6410" for this suite. @ 09/04/24 19:39:12.898
• [4.087 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 09/04/24 19:39:12.905
  I0904 19:39:12.905737 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename podtemplate @ 09/04/24 19:39:12.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:12.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:12.926
  STEP: Create a pod template @ 09/04/24 19:39:12.93
  STEP: Replace a pod template @ 09/04/24 19:39:12.934
  I0904 19:39:12.943890 19 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0904 19:39:12.944068 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-6883" for this suite. @ 09/04/24 19:39:12.947
• [0.048 seconds]
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 09/04/24 19:39:12.953
  I0904 19:39:12.953983 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename server-version @ 09/04/24 19:39:12.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:12.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:12.974
  STEP: Request ServerVersion @ 09/04/24 19:39:12.977
  STEP: Confirm major version @ 09/04/24 19:39:12.979
  I0904 19:39:12.979355 19 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 09/04/24 19:39:12.979
  I0904 19:39:12.979384 19 server_version.go:58] cleanMinorVersion: 31
  I0904 19:39:12.979390 19 server_version.go:62] Minor version: 31
  I0904 19:39:12.979448 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-2152" for this suite. @ 09/04/24 19:39:12.983
• [0.036 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:351
  STEP: Creating a kubernetes client @ 09/04/24 19:39:12.989
  I0904 19:39:12.989840 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename disruption @ 09/04/24 19:39:12.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:13.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:13.01
  STEP: Creating a pdb that targets all three pods in a test replica set @ 09/04/24 19:39:13.013
  STEP: Waiting for the pdb to be processed @ 09/04/24 19:39:13.018
  E0904 19:39:13.399993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:14.400085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 09/04/24 19:39:15.029
  STEP: Waiting for all pods to be running @ 09/04/24 19:39:15.029
  I0904 19:39:15.033206 19 disruption.go:680] pods: 0 < 3
  E0904 19:39:15.400469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:16.400572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 09/04/24 19:39:17.035
  STEP: Updating the pdb to allow a pod to be evicted @ 09/04/24 19:39:17.047
  STEP: Waiting for the pdb to be processed @ 09/04/24 19:39:17.055
  E0904 19:39:17.400630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:18.401007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 09/04/24 19:39:19.061
  STEP: Waiting for all pods to be running @ 09/04/24 19:39:19.061
  STEP: Waiting for the pdb to observed all healthy pods @ 09/04/24 19:39:19.065
  STEP: Patching the pdb to disallow a pod to be evicted @ 09/04/24 19:39:19.094
  STEP: Waiting for the pdb to be processed @ 09/04/24 19:39:19.12
  E0904 19:39:19.401841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:20.401928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 09/04/24 19:39:21.125
  STEP: locating a running pod @ 09/04/24 19:39:21.13
  STEP: Deleting the pdb to allow a pod to be evicted @ 09/04/24 19:39:21.139
  STEP: Waiting for the pdb to be deleted @ 09/04/24 19:39:21.146
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 09/04/24 19:39:21.149
  STEP: Waiting for all pods to be running @ 09/04/24 19:39:21.149
  I0904 19:39:21.168572 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6501" for this suite. @ 09/04/24 19:39:21.172
• [8.192 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 09/04/24 19:39:21.181
  I0904 19:39:21.181570 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 19:39:21.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:21.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:21.202
  STEP: Creating configMap with name configmap-test-volume-f00abc98-7675-4b5e-b4ee-ebab222ec558 @ 09/04/24 19:39:21.206
  STEP: Creating a pod to test consume configMaps @ 09/04/24 19:39:21.212
  E0904 19:39:21.402222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:22.402331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:23.403093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:24.403180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:39:25.237
  I0904 19:39:25.241518 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod pod-configmaps-7ce0ed41-3449-4ff8-9968-8604bc72f9af container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 19:39:25.248
  I0904 19:39:25.265060 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9920" for this suite. @ 09/04/24 19:39:25.268
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 09/04/24 19:39:25.275
  I0904 19:39:25.275220 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 19:39:25.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:25.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:25.295
  STEP: Create a pod @ 09/04/24 19:39:25.299
  E0904 19:39:25.403263      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:26.403400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching /status @ 09/04/24 19:39:27.319
  I0904 19:39:27.327574 19 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0904 19:39:27.327679 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5452" for this suite. @ 09/04/24 19:39:27.331
• [2.064 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:193
  STEP: Creating a kubernetes client @ 09/04/24 19:39:27.339
  I0904 19:39:27.339383 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename dns @ 09/04/24 19:39:27.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:27.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:27.362
  STEP: Creating a test headless service @ 09/04/24 19:39:27.365
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4277 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4277;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4277 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4277;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4277.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4277.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4277.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4277.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4277.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4277.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4277.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4277.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4277.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4277.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4277.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4277.svc;check="$$(dig +notcp +noall +answer +search 176.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.176_udp@PTR;check="$$(dig +tcp +noall +answer +search 176.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.176_tcp@PTR;sleep 1; done
   @ 09/04/24 19:39:27.384
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4277 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4277;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4277 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4277;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4277.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4277.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4277.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4277.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4277.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4277.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4277.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4277.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4277.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4277.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4277.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4277.svc;check="$$(dig +notcp +noall +answer +search 176.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.176_udp@PTR;check="$$(dig +tcp +noall +answer +search 176.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.176_tcp@PTR;sleep 1; done
   @ 09/04/24 19:39:27.384
  STEP: creating a pod to probe DNS @ 09/04/24 19:39:27.384
  STEP: submitting the pod to kubernetes @ 09/04/24 19:39:27.384
  E0904 19:39:27.404270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:28.404595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:29.405071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/04/24 19:39:29.405
  STEP: looking for the results for each expected name from probers @ 09/04/24 19:39:29.409
  I0904 19:39:29.414845 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.419240 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.424534 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-4277 from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.429233 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-4277 from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.433392 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-4277.svc from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.438596 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-4277.svc from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.442733 19 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4277.svc from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.446846 19 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4277.svc from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.470689 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.474974 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.479797 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-4277 from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.484302 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-4277 from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.488435 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-4277.svc from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.493765 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-4277.svc from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.497973 19 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4277.svc from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.501736 19 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4277.svc from pod dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d: the server could not find the requested resource (get pods dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d)
  I0904 19:39:29.520504 19 dns_common.go:489] Lookups using dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4277 wheezy_tcp@dns-test-service.dns-4277 wheezy_udp@dns-test-service.dns-4277.svc wheezy_tcp@dns-test-service.dns-4277.svc wheezy_udp@_http._tcp.dns-test-service.dns-4277.svc wheezy_tcp@_http._tcp.dns-test-service.dns-4277.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4277 jessie_tcp@dns-test-service.dns-4277 jessie_udp@dns-test-service.dns-4277.svc jessie_tcp@dns-test-service.dns-4277.svc jessie_udp@_http._tcp.dns-test-service.dns-4277.svc jessie_tcp@_http._tcp.dns-test-service.dns-4277.svc]

  I0904 19:39:29.527460 19 dns_common.go:495] Pod client logs for webserver: 
  I0904 19:39:29.534332 19 dns_common.go:495] Pod client logs for querier: 
  I0904 19:39:29.541302 19 dns_common.go:495] Pod client logs for jessie-querier: 
  E0904 19:39:30.405272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:31.405381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:32.405612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:33.405698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:34.405800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:39:34.536956 19 dns_common.go:527] DNS probes using dns-4277/dns-test-fe2a3ae9-8188-4dc1-9309-cf10b095131d succeeded

  STEP: deleting the pod @ 09/04/24 19:39:34.537
  STEP: deleting the test service @ 09/04/24 19:39:34.554
  STEP: deleting the test headless service @ 09/04/24 19:39:34.578
  I0904 19:39:34.597999 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4277" for this suite. @ 09/04/24 19:39:34.602
• [7.428 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 09/04/24 19:39:34.767
  I0904 19:39:34.767213 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:39:34.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:34.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:34.793
  STEP: Creating configMap with name configmap-projected-all-test-volume-064ac6dc-aa63-4b84-833a-2f58a168fe37 @ 09/04/24 19:39:34.799
  STEP: Creating secret with name secret-projected-all-test-volume-326bdcee-d41a-4810-aea9-31d8d2c86cdb @ 09/04/24 19:39:34.804
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 09/04/24 19:39:34.81
  E0904 19:39:35.405899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:36.406685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:37.406779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:38.406869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:39:38.84
  I0904 19:39:38.844191 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod projected-volume-439b290a-92f8-4262-af36-62550fe6e848 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 09/04/24 19:39:38.852
  I0904 19:39:38.871793 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7370" for this suite. @ 09/04/24 19:39:38.876
• [4.115 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 09/04/24 19:39:38.882
  I0904 19:39:38.882603 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 19:39:38.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:38.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:38.902
  STEP: Creating configMap that has name configmap-test-emptyKey-a62c43c8-3ae9-47bf-bab9-ca1fd23ee361 @ 09/04/24 19:39:38.905
  I0904 19:39:38.907510 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5399" for this suite. @ 09/04/24 19:39:38.91
• [0.035 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:620
  STEP: Creating a kubernetes client @ 09/04/24 19:39:38.917
  I0904 19:39:38.917473 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename field-validation @ 09/04/24 19:39:38.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:38.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:38.941
  I0904 19:39:38.945345 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:39:39.407632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:40.407688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:41.407772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W0904 19:39:41.480081      19 warnings.go:70] unknown field "alpha"
  W0904 19:39:41.480098      19 warnings.go:70] unknown field "beta"
  W0904 19:39:41.480101      19 warnings.go:70] unknown field "delta"
  W0904 19:39:41.480104      19 warnings.go:70] unknown field "epsilon"
  W0904 19:39:41.480106      19 warnings.go:70] unknown field "gamma"
  I0904 19:39:42.028242 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2707" for this suite. @ 09/04/24 19:39:42.033
• [3.124 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 09/04/24 19:39:42.041
  I0904 19:39:42.041943 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename daemonsets @ 09/04/24 19:39:42.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:42.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:42.065
  STEP: Creating a simple DaemonSet "daemon-set" @ 09/04/24 19:39:42.087
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/04/24 19:39:42.093
  I0904 19:39:42.096526 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:39:42.096608 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:39:42.100322 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 19:39:42.100343 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 19:39:42.408830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:39:43.099284 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:39:43.099332 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:39:43.102781 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 19:39:43.102800 19 fixtures.go:130] Node ip-172-31-7-223 is running 0 daemon pod, expected 1
  E0904 19:39:43.409122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:39:44.098392 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:39:44.098475 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:39:44.102443 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 19:39:44.102462 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 09/04/24 19:39:44.105
  I0904 19:39:44.119550 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:39:44.119633 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:39:44.123063 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 19:39:44.123080 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 09/04/24 19:39:44.123
  E0904 19:39:44.409779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting DaemonSet "daemon-set" @ 09/04/24 19:39:45.131
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-223, will wait for the garbage collector to delete the pods @ 09/04/24 19:39:45.132
  I0904 19:39:45.193589 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.475493ms
  I0904 19:39:45.293963 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.3682ms
  E0904 19:39:45.410448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:46.411283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:39:46.897954 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 19:39:46.897989 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0904 19:39:46.901360 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"45280"},"items":null}

  I0904 19:39:46.905158 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"45280"},"items":null}

  I0904 19:39:46.919727 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-223" for this suite. @ 09/04/24 19:39:46.923
• [4.887 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 09/04/24 19:39:46.929
  I0904 19:39:46.929056 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename container-probe @ 09/04/24 19:39:46.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:39:46.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:39:46.949
  E0904 19:39:47.412343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:48.413326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:49.413485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:50.414437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:51.414520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:52.414628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:53.415397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:54.416384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:55.417064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:56.417775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:57.417868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:58.418346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:39:59.418741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:00.419275      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:01.420147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:02.421223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:03.422274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:04.422876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:05.423488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:06.424179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:07.424259      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:08.424374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:09.425435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:10.426067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:11.426145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:12.427072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:13.427988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:14.428100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:15.429175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:16.430184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:17.430638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:18.431697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:19.432497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:20.432598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:21.433437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:22.433636      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:23.434532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:24.435594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:25.435743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:26.436574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:27.436962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:28.437368      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:29.437482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:30.437893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:31.437980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:32.438596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:33.438687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:34.439091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:35.439824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:36.440734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:37.440867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:38.441474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:39.442000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:40.442274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:41.443250      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:42.444008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:43.444853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:44.444938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:45.445245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:46.445895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:40:46.971495 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-73" for this suite. @ 09/04/24 19:40:46.975
• [60.054 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:335
  STEP: Creating a kubernetes client @ 09/04/24 19:40:46.982
  I0904 19:40:46.982854 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename statefulset @ 09/04/24 19:40:46.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:40:47.001
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:40:47.004
  STEP: Creating service test in namespace statefulset-8093 @ 09/04/24 19:40:47.008
  STEP: Creating a new StatefulSet @ 09/04/24 19:40:47.015
  I0904 19:40:47.027496 19 wait.go:40] Found 0 stateful pods, waiting for 3
  E0904 19:40:47.446048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:48.446377      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:49.446717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:50.446927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:51.447008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:52.447209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:53.447382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:54.447683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:55.447780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:56.447859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:40:57.027770 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0904 19:40:57.027804 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0904 19:40:57.027811 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 09/04/24 19:40:57.04
  I0904 19:40:57.051834 19 statefulset.go:2507] Updating stateful set ss2
  STEP: Creating a new revision @ 09/04/24 19:40:57.051
  E0904 19:40:57.448678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:58.448797      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:40:59.448898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:00.449150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:01.449234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:02.449365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:03.449440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:04.449667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:05.450703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:06.450951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 09/04/24 19:41:07.061
  STEP: Performing a canary update @ 09/04/24 19:41:07.061
  I0904 19:41:07.070871 19 statefulset.go:2507] Updating stateful set ss2
  I0904 19:41:07.079632 19 wait.go:74] Waiting for Pod statefulset-8093/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0904 19:41:07.451067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:08.451361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:09.451497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:10.451603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:11.451677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:12.451784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:13.451921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:14.452041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:15.452113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:16.452209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 09/04/24 19:41:17.082
  I0904 19:41:17.116346 19 wait.go:40] Found 1 stateful pods, waiting for 3
  E0904 19:41:17.452792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:18.452892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:19.452994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:20.453071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:21.453284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:22.453513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:23.453627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:24.453659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:25.454662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:26.454757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:41:27.118651 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0904 19:41:27.118685 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0904 19:41:27.118692 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 09/04/24 19:41:27.126
  I0904 19:41:27.136952 19 statefulset.go:2507] Updating stateful set ss2
  I0904 19:41:27.145937 19 wait.go:74] Waiting for Pod statefulset-8093/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0904 19:41:27.455300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:28.455575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:29.455583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:30.455568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:31.455770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:32.455862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:33.455974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:34.456161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:35.456385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:36.456581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:41:37.157115 19 statefulset.go:2507] Updating stateful set ss2
  I0904 19:41:37.164265 19 wait.go:56] Waiting for StatefulSet statefulset-8093/ss2 to complete update
  I0904 19:41:37.164362 19 wait.go:63] Waiting for Pod statefulset-8093/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0904 19:41:37.456682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:38.457271      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:39.457369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:40.457503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:41.457599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:42.457811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:43.457882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:44.458674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:45.458871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:46.459739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:41:47.166095 19 statefulset.go:138] Deleting all statefulset in ns statefulset-8093
  I0904 19:41:47.169346 19 rest.go:150] Scaling statefulset ss2 to 0
  E0904 19:41:47.460617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:48.460694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:49.460821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:50.461028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:51.461746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:52.462357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:53.462467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:54.462578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:55.462774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:56.463074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:41:57.186194 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0904 19:41:57.189622 19 rest.go:88] Deleting statefulset ss2
  I0904 19:41:57.203484 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8093" for this suite. @ 09/04/24 19:41:57.207
• [70.232 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:119
  STEP: Creating a kubernetes client @ 09/04/24 19:41:57.214
  I0904 19:41:57.214746 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename dns @ 09/04/24 19:41:57.215
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:41:57.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:41:57.235
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6984.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6984.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 09/04/24 19:41:57.238
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6984.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6984.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 09/04/24 19:41:57.238
  STEP: creating a pod to probe /etc/hosts @ 09/04/24 19:41:57.238
  STEP: submitting the pod to kubernetes @ 09/04/24 19:41:57.238
  E0904 19:41:57.464159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:41:58.464558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/04/24 19:41:59.257
  STEP: looking for the results for each expected name from probers @ 09/04/24 19:41:59.261
  I0904 19:41:59.279327 19 dns_common.go:527] DNS probes using dns-6984/dns-test-22f7aa39-4019-47b9-be42-d198e98f075d succeeded

  STEP: deleting the pod @ 09/04/24 19:41:59.279
  I0904 19:41:59.294527 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6984" for this suite. @ 09/04/24 19:41:59.298
• [2.090 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1833
  STEP: Creating a kubernetes client @ 09/04/24 19:41:59.304
  I0904 19:41:59.304539 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 19:41:59.305
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:41:59.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:41:59.336
  STEP: starting the proxy server @ 09/04/24 19:41:59.339
  I0904 19:41:59.339839 19 util.go:585] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-2326 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 09/04/24 19:41:59.367
  I0904 19:41:59.373903 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0904 19:41:59.374844 19 kubectl.go:2224] kubectl proxy stdout: Starting to serve on 127.0.0.1:39295

  I0904 19:41:59.374866 19 kubectl.go:2229] kubectl proxy stderr: W0904 19:41:59.367737     788 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-2326" for this suite. @ 09/04/24 19:41:59.378
• [0.080 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 09/04/24 19:41:59.384
  I0904 19:41:59.384833 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubelet-test @ 09/04/24 19:41:59.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:41:59.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:41:59.406
  E0904 19:41:59.465198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:00.465334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:42:01.449525 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3575" for this suite. @ 09/04/24 19:42:01.455
• [2.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:863
  STEP: Creating a kubernetes client @ 09/04/24 19:42:01.461
  I0904 19:42:01.461882 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:42:01.462
  E0904 19:42:01.466021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:42:01.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:42:01.484
  STEP: Setting up server cert @ 09/04/24 19:42:01.51
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:42:01.678
  STEP: Deploying the webhook pod @ 09/04/24 19:42:01.688
  STEP: Wait for the deployment to be ready @ 09/04/24 19:42:01.702
  I0904 19:42:01.709552 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:42:02.466713      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:03.466801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:42:03.724
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:42:03.736
  E0904 19:42:04.467814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:42:04.737205 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 09/04/24 19:42:04.746
  STEP: create the configmap with a random name @ 09/04/24 19:42:04.764
  STEP: verify the configmap is mutated @ 09/04/24 19:42:04.776
  STEP: create the configmap with 'skip-me' name @ 09/04/24 19:42:04.776
  I0904 19:42:04.830711 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9726" for this suite. @ 09/04/24 19:42:04.835
  STEP: Destroying namespace "webhook-markers-3573" for this suite. @ 09/04/24 19:42:04.842
• [3.386 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 09/04/24 19:42:04.847
  I0904 19:42:04.847982 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename runtimeclass @ 09/04/24 19:42:04.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:42:04.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:42:04.871
  I0904 19:42:04.880752 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9194" for this suite. @ 09/04/24 19:42:04.885
• [0.044 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1365
  STEP: Creating a kubernetes client @ 09/04/24 19:42:04.891
  I0904 19:42:04.891891 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 19:42:04.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:42:04.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:42:04.917
  STEP: validating cluster-info @ 09/04/24 19:42:04.921
  I0904 19:42:04.921196 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-5602 cluster-info'
  I0904 19:42:04.961849 19 builder.go:146] stderr: ""
  I0904 19:42:04.961893 19 builder.go:147] stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0904 19:42:04.961995 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5602" for this suite. @ 09/04/24 19:42:04.966
• [0.083 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 09/04/24 19:42:04.975
  I0904 19:42:04.975464 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename configmap @ 09/04/24 19:42:04.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:42:04.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:42:04.998
  STEP: Creating configMap with name configmap-test-volume-map-5bb3aa3e-5ce1-473c-ad01-09d857593be2 @ 09/04/24 19:42:05.001
  STEP: Creating a pod to test consume configMaps @ 09/04/24 19:42:05.006
  E0904 19:42:05.468816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:06.469084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:07.469165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:08.470044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:42:09.035
  I0904 19:42:09.039341 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-configmaps-775d2d86-600d-4026-b128-1c803c479eac container agnhost-container: <nil>
  STEP: delete the pod @ 09/04/24 19:42:09.057
  I0904 19:42:09.075584 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1950" for this suite. @ 09/04/24 19:42:09.079
• [4.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 09/04/24 19:42:09.087
  I0904 19:42:09.087570 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pod-network-test @ 09/04/24 19:42:09.088
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:42:09.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:42:09.112
  STEP: Performing setup for networking test in namespace pod-network-test-2042 @ 09/04/24 19:42:09.116
  STEP: creating a selector @ 09/04/24 19:42:09.116
  STEP: Creating the service pods in kubernetes @ 09/04/24 19:42:09.116
  I0904 19:42:09.116145 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0904 19:42:09.471020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:10.471181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:11.471663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:12.471778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:13.471849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:14.472116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:15.472672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:16.472801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:17.473337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:18.473407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:19.474293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:20.474693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/04/24 19:42:21.202
  E0904 19:42:21.475568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:22.475648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:42:23.223511 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0904 19:42:23.223540 19 networking.go:42] Breadth first check of 192.168.146.180 on host 172.31.21.169...
  I0904 19:42:23.227294 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.104.136:9080/dial?request=hostname&protocol=http&host=192.168.146.180&port=8083&tries=1'] Namespace:pod-network-test-2042 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:42:23.227314 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:42:23.227743 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:42:23.227785 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2042/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.104.136%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.146.180%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0904 19:42:23.287257 19 utils.go:356] Waiting for responses: map[]
  I0904 19:42:23.287319 19 utils.go:360] reached 192.168.146.180 after 0/1 tries
  I0904 19:42:23.287328 19 networking.go:42] Breadth first check of 192.168.104.135 on host 172.31.40.239...
  I0904 19:42:23.292921 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.104.136:9080/dial?request=hostname&protocol=http&host=192.168.104.135&port=8083&tries=1'] Namespace:pod-network-test-2042 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:42:23.292942 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:42:23.293327 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:42:23.293403 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2042/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.104.136%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.104.135%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0904 19:42:23.348305 19 utils.go:356] Waiting for responses: map[]
  I0904 19:42:23.348332 19 utils.go:360] reached 192.168.104.135 after 0/1 tries
  I0904 19:42:23.348341 19 networking.go:42] Breadth first check of 192.168.243.60 on host 172.31.7.223...
  I0904 19:42:23.352929 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.104.136:9080/dial?request=hostname&protocol=http&host=192.168.243.60&port=8083&tries=1'] Namespace:pod-network-test-2042 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:42:23.352950 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:42:23.353346 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:42:23.353412 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2042/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.104.136%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.243.60%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0904 19:42:23.406499 19 utils.go:356] Waiting for responses: map[]
  I0904 19:42:23.406533 19 utils.go:360] reached 192.168.243.60 after 0/1 tries
  I0904 19:42:23.406541 19 networking.go:53] Going to retry 0 out of 3 pods....
  I0904 19:42:23.406708 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2042" for this suite. @ 09/04/24 19:42:23.41
• [14.329 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 09/04/24 19:42:23.417
  I0904 19:42:23.417128 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/04/24 19:42:23.417
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:42:23.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:42:23.441
  I0904 19:42:23.445104 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:42:23.476043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:24.476273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:25.477222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:26.477894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:42:26.501591 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-407" for this suite. @ 09/04/24 19:42:26.506
• [3.097 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 09/04/24 19:42:26.514
  I0904 19:42:26.514183 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename gc @ 09/04/24 19:42:26.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:42:26.531
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:42:26.535
  STEP: create the rc @ 09/04/24 19:42:26.542
  W0904 19:42:26.547962      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0904 19:42:27.478269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:28.479937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:29.480870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:30.482630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:31.485192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:32.485740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 09/04/24 19:42:32.552
  STEP: wait for the rc to be deleted @ 09/04/24 19:42:32.563
  E0904 19:42:33.486451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:34.486762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:35.486850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:36.486963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:37.487077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 09/04/24 19:42:37.569
  E0904 19:42:38.487166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:39.488221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:40.488506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:41.488626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:42.488728      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:43.488819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:44.488934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:45.489049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:46.489125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:47.489514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:48.489608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:49.489712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:50.490677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:51.490870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:52.491113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:53.491843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:54.492403      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:55.492504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:56.493031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:57.493305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:58.493576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:42:59.493640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:00.493713      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:01.494674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:02.494741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:03.494882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:04.494998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:05.495053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:06.495152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:07.495289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/04/24 19:43:07.579
  W0904 19:43:07.584210      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0904 19:43:07.584237 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0904 19:43:07.584280 19 delete.go:95] Deleting pod "simpletest.rc-252hb" in namespace "gc-1112"
  I0904 19:43:07.596588 19 delete.go:95] Deleting pod "simpletest.rc-2794q" in namespace "gc-1112"
  I0904 19:43:07.606971 19 delete.go:95] Deleting pod "simpletest.rc-2kclf" in namespace "gc-1112"
  I0904 19:43:07.619602 19 delete.go:95] Deleting pod "simpletest.rc-2r48m" in namespace "gc-1112"
  I0904 19:43:07.631767 19 delete.go:95] Deleting pod "simpletest.rc-2tsvh" in namespace "gc-1112"
  I0904 19:43:07.645248 19 delete.go:95] Deleting pod "simpletest.rc-48n94" in namespace "gc-1112"
  I0904 19:43:07.656515 19 delete.go:95] Deleting pod "simpletest.rc-4db6q" in namespace "gc-1112"
  I0904 19:43:07.669573 19 delete.go:95] Deleting pod "simpletest.rc-4rwl4" in namespace "gc-1112"
  I0904 19:43:07.679826 19 delete.go:95] Deleting pod "simpletest.rc-4tk2r" in namespace "gc-1112"
  I0904 19:43:07.690029 19 delete.go:95] Deleting pod "simpletest.rc-58sv2" in namespace "gc-1112"
  I0904 19:43:07.703050 19 delete.go:95] Deleting pod "simpletest.rc-5nwqw" in namespace "gc-1112"
  I0904 19:43:07.716887 19 delete.go:95] Deleting pod "simpletest.rc-62x7b" in namespace "gc-1112"
  I0904 19:43:07.733728 19 delete.go:95] Deleting pod "simpletest.rc-6b9f5" in namespace "gc-1112"
  I0904 19:43:07.747447 19 delete.go:95] Deleting pod "simpletest.rc-6dgxh" in namespace "gc-1112"
  I0904 19:43:07.757081 19 delete.go:95] Deleting pod "simpletest.rc-6nzbf" in namespace "gc-1112"
  I0904 19:43:07.769693 19 delete.go:95] Deleting pod "simpletest.rc-6xbpt" in namespace "gc-1112"
  I0904 19:43:07.781847 19 delete.go:95] Deleting pod "simpletest.rc-6z5qm" in namespace "gc-1112"
  I0904 19:43:07.796369 19 delete.go:95] Deleting pod "simpletest.rc-7cgkl" in namespace "gc-1112"
  I0904 19:43:07.812133 19 delete.go:95] Deleting pod "simpletest.rc-7hhtv" in namespace "gc-1112"
  I0904 19:43:07.824270 19 delete.go:95] Deleting pod "simpletest.rc-7xn8v" in namespace "gc-1112"
  I0904 19:43:07.839566 19 delete.go:95] Deleting pod "simpletest.rc-82r98" in namespace "gc-1112"
  I0904 19:43:07.863734 19 delete.go:95] Deleting pod "simpletest.rc-88cbz" in namespace "gc-1112"
  I0904 19:43:07.877738 19 delete.go:95] Deleting pod "simpletest.rc-8kdj9" in namespace "gc-1112"
  I0904 19:43:07.891776 19 delete.go:95] Deleting pod "simpletest.rc-8ncff" in namespace "gc-1112"
  I0904 19:43:07.904127 19 delete.go:95] Deleting pod "simpletest.rc-8pxxn" in namespace "gc-1112"
  I0904 19:43:07.921711 19 delete.go:95] Deleting pod "simpletest.rc-8w2hb" in namespace "gc-1112"
  I0904 19:43:07.933722 19 delete.go:95] Deleting pod "simpletest.rc-95mtk" in namespace "gc-1112"
  I0904 19:43:07.946976 19 delete.go:95] Deleting pod "simpletest.rc-9cxr4" in namespace "gc-1112"
  I0904 19:43:07.960600 19 delete.go:95] Deleting pod "simpletest.rc-9lnqj" in namespace "gc-1112"
  I0904 19:43:07.971157 19 delete.go:95] Deleting pod "simpletest.rc-bbv9c" in namespace "gc-1112"
  I0904 19:43:07.982883 19 delete.go:95] Deleting pod "simpletest.rc-bmfr4" in namespace "gc-1112"
  I0904 19:43:07.998188 19 delete.go:95] Deleting pod "simpletest.rc-bnrmh" in namespace "gc-1112"
  I0904 19:43:08.010871 19 delete.go:95] Deleting pod "simpletest.rc-bnvdx" in namespace "gc-1112"
  I0904 19:43:08.025783 19 delete.go:95] Deleting pod "simpletest.rc-chlkb" in namespace "gc-1112"
  I0904 19:43:08.042524 19 delete.go:95] Deleting pod "simpletest.rc-clpd6" in namespace "gc-1112"
  I0904 19:43:08.056131 19 delete.go:95] Deleting pod "simpletest.rc-cqjx4" in namespace "gc-1112"
  I0904 19:43:08.068188 19 delete.go:95] Deleting pod "simpletest.rc-d4j67" in namespace "gc-1112"
  I0904 19:43:08.080157 19 delete.go:95] Deleting pod "simpletest.rc-dt8cp" in namespace "gc-1112"
  I0904 19:43:08.091825 19 delete.go:95] Deleting pod "simpletest.rc-f94nl" in namespace "gc-1112"
  I0904 19:43:08.111942 19 delete.go:95] Deleting pod "simpletest.rc-fc288" in namespace "gc-1112"
  I0904 19:43:08.121568 19 delete.go:95] Deleting pod "simpletest.rc-fjrrr" in namespace "gc-1112"
  I0904 19:43:08.141900 19 delete.go:95] Deleting pod "simpletest.rc-g9vcn" in namespace "gc-1112"
  I0904 19:43:08.153784 19 delete.go:95] Deleting pod "simpletest.rc-gl7hq" in namespace "gc-1112"
  I0904 19:43:08.167864 19 delete.go:95] Deleting pod "simpletest.rc-glxpv" in namespace "gc-1112"
  I0904 19:43:08.179841 19 delete.go:95] Deleting pod "simpletest.rc-glzlm" in namespace "gc-1112"
  I0904 19:43:08.193867 19 delete.go:95] Deleting pod "simpletest.rc-gvwjh" in namespace "gc-1112"
  I0904 19:43:08.205238 19 delete.go:95] Deleting pod "simpletest.rc-hp682" in namespace "gc-1112"
  I0904 19:43:08.218599 19 delete.go:95] Deleting pod "simpletest.rc-hrpkr" in namespace "gc-1112"
  I0904 19:43:08.233431 19 delete.go:95] Deleting pod "simpletest.rc-hvmnc" in namespace "gc-1112"
  I0904 19:43:08.250528 19 delete.go:95] Deleting pod "simpletest.rc-hzngs" in namespace "gc-1112"
  I0904 19:43:08.266582 19 delete.go:95] Deleting pod "simpletest.rc-j96bt" in namespace "gc-1112"
  I0904 19:43:08.280214 19 delete.go:95] Deleting pod "simpletest.rc-jhznv" in namespace "gc-1112"
  I0904 19:43:08.297911 19 delete.go:95] Deleting pod "simpletest.rc-jlv9d" in namespace "gc-1112"
  I0904 19:43:08.312226 19 delete.go:95] Deleting pod "simpletest.rc-jm6ns" in namespace "gc-1112"
  I0904 19:43:08.328439 19 delete.go:95] Deleting pod "simpletest.rc-jn456" in namespace "gc-1112"
  I0904 19:43:08.349667 19 delete.go:95] Deleting pod "simpletest.rc-jq5m9" in namespace "gc-1112"
  I0904 19:43:08.377202 19 delete.go:95] Deleting pod "simpletest.rc-jsbdb" in namespace "gc-1112"
  I0904 19:43:08.415076 19 delete.go:95] Deleting pod "simpletest.rc-jv4ps" in namespace "gc-1112"
  I0904 19:43:08.429974 19 delete.go:95] Deleting pod "simpletest.rc-k5nv7" in namespace "gc-1112"
  I0904 19:43:08.444953 19 delete.go:95] Deleting pod "simpletest.rc-kq4cg" in namespace "gc-1112"
  I0904 19:43:08.459186 19 delete.go:95] Deleting pod "simpletest.rc-kvjhc" in namespace "gc-1112"
  I0904 19:43:08.472002 19 delete.go:95] Deleting pod "simpletest.rc-lfjsk" in namespace "gc-1112"
  I0904 19:43:08.485570 19 delete.go:95] Deleting pod "simpletest.rc-lgrlh" in namespace "gc-1112"
  E0904 19:43:08.495957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:43:08.498313 19 delete.go:95] Deleting pod "simpletest.rc-mtldc" in namespace "gc-1112"
  I0904 19:43:08.511805 19 delete.go:95] Deleting pod "simpletest.rc-mvrcg" in namespace "gc-1112"
  I0904 19:43:08.524389 19 delete.go:95] Deleting pod "simpletest.rc-nfgg5" in namespace "gc-1112"
  I0904 19:43:08.537215 19 delete.go:95] Deleting pod "simpletest.rc-nlj66" in namespace "gc-1112"
  I0904 19:43:08.548963 19 delete.go:95] Deleting pod "simpletest.rc-nm6v5" in namespace "gc-1112"
  I0904 19:43:08.581713 19 delete.go:95] Deleting pod "simpletest.rc-nrhq2" in namespace "gc-1112"
  I0904 19:43:08.634738 19 delete.go:95] Deleting pod "simpletest.rc-nwk68" in namespace "gc-1112"
  I0904 19:43:08.692365 19 delete.go:95] Deleting pod "simpletest.rc-pbzps" in namespace "gc-1112"
  I0904 19:43:08.733482 19 delete.go:95] Deleting pod "simpletest.rc-pm8sh" in namespace "gc-1112"
  I0904 19:43:08.782388 19 delete.go:95] Deleting pod "simpletest.rc-pnksz" in namespace "gc-1112"
  I0904 19:43:08.832749 19 delete.go:95] Deleting pod "simpletest.rc-qj86t" in namespace "gc-1112"
  I0904 19:43:08.888672 19 delete.go:95] Deleting pod "simpletest.rc-ql4cw" in namespace "gc-1112"
  I0904 19:43:08.938771 19 delete.go:95] Deleting pod "simpletest.rc-qqdjn" in namespace "gc-1112"
  I0904 19:43:09.012675 19 delete.go:95] Deleting pod "simpletest.rc-qqz5j" in namespace "gc-1112"
  I0904 19:43:09.076566 19 delete.go:95] Deleting pod "simpletest.rc-qvrqp" in namespace "gc-1112"
  I0904 19:43:09.091715 19 delete.go:95] Deleting pod "simpletest.rc-r4vh5" in namespace "gc-1112"
  I0904 19:43:09.315086 19 delete.go:95] Deleting pod "simpletest.rc-r7k4k" in namespace "gc-1112"
  I0904 19:43:09.348737 19 delete.go:95] Deleting pod "simpletest.rc-rpfpj" in namespace "gc-1112"
  I0904 19:43:09.395712 19 delete.go:95] Deleting pod "simpletest.rc-s4dxw" in namespace "gc-1112"
  I0904 19:43:09.408224 19 delete.go:95] Deleting pod "simpletest.rc-schdz" in namespace "gc-1112"
  I0904 19:43:09.423181 19 delete.go:95] Deleting pod "simpletest.rc-slszk" in namespace "gc-1112"
  I0904 19:43:09.437740 19 delete.go:95] Deleting pod "simpletest.rc-t7zlz" in namespace "gc-1112"
  I0904 19:43:09.454857 19 delete.go:95] Deleting pod "simpletest.rc-tlql5" in namespace "gc-1112"
  I0904 19:43:09.498951 19 delete.go:95] Deleting pod "simpletest.rc-v5wh6" in namespace "gc-1112"
  E0904 19:43:09.499164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:43:09.541664 19 delete.go:95] Deleting pod "simpletest.rc-wfrxt" in namespace "gc-1112"
  I0904 19:43:09.585332 19 delete.go:95] Deleting pod "simpletest.rc-wg2rm" in namespace "gc-1112"
  I0904 19:43:09.636830 19 delete.go:95] Deleting pod "simpletest.rc-wld75" in namespace "gc-1112"
  I0904 19:43:09.710190 19 delete.go:95] Deleting pod "simpletest.rc-wnxg8" in namespace "gc-1112"
  I0904 19:43:09.738383 19 delete.go:95] Deleting pod "simpletest.rc-wqzs2" in namespace "gc-1112"
  I0904 19:43:09.785144 19 delete.go:95] Deleting pod "simpletest.rc-xk8ls" in namespace "gc-1112"
  I0904 19:43:09.833426 19 delete.go:95] Deleting pod "simpletest.rc-xmvdl" in namespace "gc-1112"
  I0904 19:43:09.885854 19 delete.go:95] Deleting pod "simpletest.rc-xpdft" in namespace "gc-1112"
  I0904 19:43:09.935029 19 delete.go:95] Deleting pod "simpletest.rc-xsng2" in namespace "gc-1112"
  I0904 19:43:09.986543 19 delete.go:95] Deleting pod "simpletest.rc-xvb4g" in namespace "gc-1112"
  I0904 19:43:10.045692 19 delete.go:95] Deleting pod "simpletest.rc-zh2mp" in namespace "gc-1112"
  I0904 19:43:10.083230 19 delete.go:95] Deleting pod "simpletest.rc-ztq9q" in namespace "gc-1112"
  I0904 19:43:10.136066 19 delete.go:95] Deleting pod "simpletest.rc-zv7bf" in namespace "gc-1112"
  I0904 19:43:10.188575 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1112" for this suite. @ 09/04/24 19:43:10.225
• [43.769 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:368
  STEP: Creating a kubernetes client @ 09/04/24 19:43:10.283
  I0904 19:43:10.283118 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:43:10.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:43:10.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:43:10.311
  STEP: Setting up server cert @ 09/04/24 19:43:10.344
  E0904 19:43:10.501811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:43:11.053
  STEP: Deploying the webhook pod @ 09/04/24 19:43:11.079
  STEP: Wait for the deployment to be ready @ 09/04/24 19:43:11.099
  I0904 19:43:11.120786 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:43:11.505857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:12.506698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:43:13.133263 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 4, 19, 43, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 19, 43, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 4, 19, 43, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 4, 19, 43, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5b9c4f9645\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0904 19:43:13.507763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:14.507875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:43:15.137
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:43:15.146
  E0904 19:43:15.508454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:43:16.146698 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 09/04/24 19:43:16.154
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/04/24 19:43:16.154
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 09/04/24 19:43:16.168
  E0904 19:43:16.508506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 09/04/24 19:43:17.179
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/04/24 19:43:17.179
  E0904 19:43:17.509129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 09/04/24 19:43:18.209
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/04/24 19:43:18.209
  E0904 19:43:18.509702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:19.509913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:20.510017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:21.510109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:22.510162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 09/04/24 19:43:23.242
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/04/24 19:43:23.242
  E0904 19:43:23.510279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:24.510648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:25.510826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:26.510916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:27.510988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:43:28.328485 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3713" for this suite. @ 09/04/24 19:43:28.332
  STEP: Destroying namespace "webhook-markers-187" for this suite. @ 09/04/24 19:43:28.338
• [18.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 09/04/24 19:43:28.348
  I0904 19:43:28.348238 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/04/24 19:43:28.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:43:28.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:43:28.37
  I0904 19:43:28.374209 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:43:28.511077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:29.511495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:30.511602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:43:31.427629 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-9999" for this suite. @ 09/04/24 19:43:31.431
• [3.092 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:569
  STEP: Creating a kubernetes client @ 09/04/24 19:43:31.44
  I0904 19:43:31.440436 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:43:31.44
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:43:31.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:43:31.464
  STEP: Setting up server cert @ 09/04/24 19:43:31.492
  E0904 19:43:31.511906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:43:31.694
  STEP: Deploying the webhook pod @ 09/04/24 19:43:31.699
  STEP: Wait for the deployment to be ready @ 09/04/24 19:43:31.711
  I0904 19:43:31.719491 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:43:32.512089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:33.512161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:43:33.731
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:43:33.74
  E0904 19:43:34.512268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:43:34.741642 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 09/04/24 19:43:34.815
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/04/24 19:43:34.853
  STEP: Deleting the collection of validation webhooks @ 09/04/24 19:43:34.875
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/04/24 19:43:34.923
  I0904 19:43:34.966678 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7098" for this suite. @ 09/04/24 19:43:34.971
  STEP: Destroying namespace "webhook-markers-5070" for this suite. @ 09/04/24 19:43:34.977
• [3.548 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:62
  STEP: Creating a kubernetes client @ 09/04/24 19:43:34.988
  I0904 19:43:34.988995 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename field-validation @ 09/04/24 19:43:34.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:43:35.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:43:35.011
  STEP: apply creating a deployment @ 09/04/24 19:43:35.014
  I0904 19:43:35.028584 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6433" for this suite. @ 09/04/24 19:43:35.032
• [0.051 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 09/04/24 19:43:35.04
  I0904 19:43:35.040424 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-watch @ 09/04/24 19:43:35.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:43:35.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:43:35.06
  I0904 19:43:35.064127 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:43:35.513229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:36.513949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:37.514021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 09/04/24 19:43:37.6
  I0904 19:43:37.605256 19 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-04T19:43:37Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-04T19:43:37Z]] name:name1 resourceVersion:49098 uid:796ea1ba-73c3-435f-af09-0f830145bf9d] num:map[num1:9223372036854775807 num2:1000000]]}
  E0904 19:43:38.514695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:39.514823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:40.515027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:41.515117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:42.515339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:43.515674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:44.515832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:45.516020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:46.516244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:47.516448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 09/04/24 19:43:47.605
  I0904 19:43:47.613225 19 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-04T19:43:47Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-04T19:43:47Z]] name:name2 resourceVersion:49142 uid:12b81fcf-4727-4ccb-ab01-f71b4f784d51] num:map[num1:9223372036854775807 num2:1000000]]}
  E0904 19:43:48.516550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:49.516750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:50.516939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:51.517098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:52.517285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:53.517584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:54.517689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:55.517846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:56.518672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:57.518782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 09/04/24 19:43:57.614
  I0904 19:43:57.621253 19 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-04T19:43:37Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-04T19:43:57Z]] name:name1 resourceVersion:49162 uid:796ea1ba-73c3-435f-af09-0f830145bf9d] num:map[num1:9223372036854775807 num2:1000000]]}
  E0904 19:43:58.519725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:43:59.519839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:00.520831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:01.520916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:02.521081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:03.521361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:04.521554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:05.521616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:06.522675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:07.522851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 09/04/24 19:44:07.622
  I0904 19:44:07.628932 19 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-04T19:43:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-04T19:44:07Z]] name:name2 resourceVersion:49182 uid:12b81fcf-4727-4ccb-ab01-f71b4f784d51] num:map[num1:9223372036854775807 num2:1000000]]}
  E0904 19:44:08.522956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:09.523236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:10.523454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:11.523607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:12.523777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:13.523892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:14.524086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:15.524274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:16.524468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:17.524645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 09/04/24 19:44:17.629
  I0904 19:44:17.639242 19 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-04T19:43:37Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-04T19:43:57Z]] name:name1 resourceVersion:49202 uid:796ea1ba-73c3-435f-af09-0f830145bf9d] num:map[num1:9223372036854775807 num2:1000000]]}
  E0904 19:44:18.525120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:19.525233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:20.525492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:21.525638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:22.526675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:23.526776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:24.526872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:25.527085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:26.527268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:27.527434      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 09/04/24 19:44:27.639
  I0904 19:44:27.648894 19 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-04T19:43:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-04T19:44:07Z]] name:name2 resourceVersion:49222 uid:12b81fcf-4727-4ccb-ab01-f71b4f784d51] num:map[num1:9223372036854775807 num2:1000000]]}
  E0904 19:44:28.528063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:29.528200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:30.528400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:31.528966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:32.529063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:33.529381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:34.529509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:35.529604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:36.530653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:37.530836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:44:38.164902 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-3621" for this suite. @ 09/04/24 19:44:38.169
• [63.136 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 09/04/24 19:44:38.176
  I0904 19:44:38.177004 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename svcaccounts @ 09/04/24 19:44:38.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:44:38.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:44:38.202
  I0904 19:44:38.211847 19 service_accounts.go:754] Got root ca configmap in namespace "svcaccounts-9346"
  I0904 19:44:38.217946 19 service_accounts.go:757] Deleted root ca configmap in namespace "svcaccounts-9346"
  E0904 19:44:38.531404      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 09/04/24 19:44:38.718
  I0904 19:44:38.723547 19 service_accounts.go:771] Recreated root ca configmap in namespace "svcaccounts-9346"
  I0904 19:44:38.728664 19 service_accounts.go:782] Updated root ca configmap in namespace "svcaccounts-9346"
  STEP: waiting for the root ca configmap reconciled @ 09/04/24 19:44:39.229
  I0904 19:44:39.234778 19 service_accounts.go:800] Reconciled root ca configmap in namespace "svcaccounts-9346"
  I0904 19:44:39.234971 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9346" for this suite. @ 09/04/24 19:44:39.239
• [1.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3393
  STEP: Creating a kubernetes client @ 09/04/24 19:44:39.246
  I0904 19:44:39.246838 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename services @ 09/04/24 19:44:39.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:44:39.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:44:39.267
  STEP: creating a Service @ 09/04/24 19:44:39.274
  STEP: watching for the Service to be added @ 09/04/24 19:44:39.289
  I0904 19:44:39.291709 19 service.go:3445] Found Service test-service-6hk84 in namespace services-8950 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 31468}]
  I0904 19:44:39.292013 19 service.go:3452] Service test-service-6hk84 created
  STEP: Getting /status @ 09/04/24 19:44:39.292
  I0904 19:44:39.297006 19 service.go:3463] Service test-service-6hk84 has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 09/04/24 19:44:39.297
  STEP: watching for the Service to be patched @ 09/04/24 19:44:39.303
  I0904 19:44:39.304914 19 service.go:3486] observed Service test-service-6hk84 in namespace services-8950 with annotations: map[] & LoadBalancer: {[]}
  I0904 19:44:39.304943 19 service.go:3489] Found Service test-service-6hk84 in namespace services-8950 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc001249850 []}]}
  I0904 19:44:39.304951 19 service.go:3496] Service test-service-6hk84 has service status patched
  STEP: updating the ServiceStatus @ 09/04/24 19:44:39.304
  I0904 19:44:39.315336 19 service.go:3516] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 09/04/24 19:44:39.315
  I0904 19:44:39.317059 19 service.go:3527] Observed Service test-service-6hk84 in namespace services-8950 with annotations: map[] & Conditions: []
  I0904 19:44:39.317197 19 service.go:3538] Observed Service test-service-6hk84 in namespace services-8950 with annotations: map[patchedstatus:true] & Conditions: []
  I0904 19:44:39.317250 19 service.go:3534] Found Service test-service-6hk84 in namespace services-8950 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0904 19:44:39.317313 19 service.go:3545] Service test-service-6hk84 has service status updated
  STEP: patching the service @ 09/04/24 19:44:39.317
  STEP: watching for the Service to be patched @ 09/04/24 19:44:39.325
  I0904 19:44:39.327275 19 service.go:3568] observed Service test-service-6hk84 in namespace services-8950 with labels: map[test-service-static:true]
  I0904 19:44:39.327293 19 service.go:3568] observed Service test-service-6hk84 in namespace services-8950 with labels: map[test-service-static:true]
  I0904 19:44:39.327374 19 service.go:3568] observed Service test-service-6hk84 in namespace services-8950 with labels: map[test-service-static:true]
  I0904 19:44:39.329112 19 service.go:3571] Found Service test-service-6hk84 in namespace services-8950 with labels: map[test-service:patched test-service-static:true]
  I0904 19:44:39.329123 19 service.go:3578] Service test-service-6hk84 patched
  STEP: deleting the service @ 09/04/24 19:44:39.329
  STEP: watching for the Service to be deleted @ 09/04/24 19:44:39.344
  I0904 19:44:39.346397 19 service.go:3602] Observed event: ADDED
  I0904 19:44:39.346459 19 service.go:3602] Observed event: MODIFIED
  I0904 19:44:39.346471 19 service.go:3602] Observed event: MODIFIED
  I0904 19:44:39.346517 19 service.go:3602] Observed event: MODIFIED
  I0904 19:44:39.346601 19 service.go:3598] Found Service test-service-6hk84 in namespace services-8950 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0904 19:44:39.346662 19 service.go:3607] Service test-service-6hk84 deleted
  I0904 19:44:39.346789 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8950" for this suite. @ 09/04/24 19:44:39.35
• [0.111 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:329
  STEP: Creating a kubernetes client @ 09/04/24 19:44:39.358
  I0904 19:44:39.358185 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename webhook @ 09/04/24 19:44:39.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:44:39.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:44:39.385
  STEP: Setting up server cert @ 09/04/24 19:44:39.423
  E0904 19:44:39.531436      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/04/24 19:44:39.651
  STEP: Deploying the webhook pod @ 09/04/24 19:44:39.661
  STEP: Wait for the deployment to be ready @ 09/04/24 19:44:39.672
  I0904 19:44:39.679773 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0904 19:44:40.532322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:41.532732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/04/24 19:44:41.693
  STEP: Verifying the service has paired with the endpoint @ 09/04/24 19:44:41.703
  E0904 19:44:42.532740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:44:42.704258 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0904 19:44:42.712891 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-455-crds.webhook.example.com via the AdmissionRegistration API @ 09/04/24 19:44:43.224
  STEP: Creating a custom resource that should be mutated by the webhook @ 09/04/24 19:44:43.237
  E0904 19:44:43.533608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:44.533684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:45.534169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:44:45.828369 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1744" for this suite. @ 09/04/24 19:44:45.833
  STEP: Destroying namespace "webhook-markers-504" for this suite. @ 09/04/24 19:44:45.841
• [6.491 seconds]
------------------------------
S
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 09/04/24 19:44:45.849
  I0904 19:44:45.849629 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename containers @ 09/04/24 19:44:45.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:44:45.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:44:45.868
  E0904 19:44:46.534698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:47.535766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:44:47.900904 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4540" for this suite. @ 09/04/24 19:44:47.905
• [2.062 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 09/04/24 19:44:47.911
  I0904 19:44:47.911719 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename emptydir @ 09/04/24 19:44:47.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:44:47.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:44:47.934
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 09/04/24 19:44:47.94
  E0904 19:44:48.536601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:49.536807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:50.536911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:51.537969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:44:51.963
  I0904 19:44:51.967570 19 output.go:196] Trying to get logs from node ip-172-31-40-239 pod pod-650b47d4-d61e-4cc5-9bf5-43ce3f3d299b container test-container: <nil>
  STEP: delete the pod @ 09/04/24 19:44:51.978
  I0904 19:44:52.088615 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3644" for this suite. @ 09/04/24 19:44:52.093
• [4.188 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1791
  STEP: Creating a kubernetes client @ 09/04/24 19:44:52.1
  I0904 19:44:52.100384 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 19:44:52.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:44:52.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:44:52.12
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/04/24 19:44:52.123
  I0904 19:44:52.124094 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9145 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0904 19:44:52.180383 19 builder.go:146] stderr: ""
  I0904 19:44:52.180420 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 09/04/24 19:44:52.18
  E0904 19:44:52.538614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:53.539408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:54.539434      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:55.539506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:56.539602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 09/04/24 19:44:57.231
  I0904 19:44:57.231477 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9145 get pod e2e-test-httpd-pod -o json'
  I0904 19:44:57.271969 19 builder.go:146] stderr: ""
  I0904 19:44:57.272075 19 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-09-04T19:44:52Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9145\",\n        \"resourceVersion\": \"49467\",\n        \"uid\": \"03e570aa-3ae9-442c-8db8-85ac4eca0b05\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-tf6mw\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-21-169\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-tf6mw\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-04T19:44:52Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-04T19:44:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-04T19:44:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-04T19:44:52Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-04T19:44:52Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://3641450001badc6c16612cb815c1885372945c78e424268cd1e6edceb8f39aef\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-09-04T19:44:52Z\"\n                    }\n                },\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-tf6mw\",\n                        \"readOnly\": true,\n                        \"recursiveReadOnly\": \"Disabled\"\n                    }\n                ]\n            }\n        ],\n        \"hostIP\": \"172.31.21.169\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.31.21.169\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.146.167\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.146.167\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-09-04T19:44:52Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 09/04/24 19:44:57.272
  I0904 19:44:57.272187 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9145 replace -f -'
  I0904 19:44:57.348343 19 builder.go:146] stderr: ""
  I0904 19:44:57.348384 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 09/04/24 19:44:57.348
  I0904 19:44:57.352426 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9145 delete pods e2e-test-httpd-pod'
  E0904 19:44:57.540195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:44:58.540450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:44:58.966813 19 builder.go:146] stderr: ""
  I0904 19:44:58.966847 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0904 19:44:58.966954 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9145" for this suite. @ 09/04/24 19:44:58.971
• [6.878 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 09/04/24 19:44:58.978
  I0904 19:44:58.978490 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename var-expansion @ 09/04/24 19:44:58.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:44:58.996
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:44:58.999
  STEP: Creating a pod to test substitution in container's command @ 09/04/24 19:44:59.002
  E0904 19:44:59.540533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:00.540634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:01.540735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:02.540831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:45:03.025
  I0904 19:45:03.029897 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod var-expansion-0de8222a-d9fd-4478-a921-49ad16ece275 container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 19:45:03.036
  I0904 19:45:03.056397 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-35" for this suite. @ 09/04/24 19:45:03.06
• [4.090 seconds]
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 09/04/24 19:45:03.068
  I0904 19:45:03.069004 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename init-container @ 09/04/24 19:45:03.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:45:03.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:45:03.09
  STEP: creating the pod @ 09/04/24 19:45:03.094
  I0904 19:45:03.094474 19 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0904 19:45:03.541746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:04.542678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:05.542785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:06.122281 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-650" for this suite. @ 09/04/24 19:45:06.126
• [3.063 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 09/04/24 19:45:06.132
  I0904 19:45:06.132377 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename var-expansion @ 09/04/24 19:45:06.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:45:06.149
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:45:06.152
  STEP: Creating a pod to test substitution in volume subpath @ 09/04/24 19:45:06.155
  E0904 19:45:06.543393      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:07.543460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:45:08.171
  I0904 19:45:08.175440 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod var-expansion-a4e45fe3-9d49-450d-8ce1-71121c877265 container dapi-container: <nil>
  STEP: delete the pod @ 09/04/24 19:45:08.181
  I0904 19:45:08.195643 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5005" for this suite. @ 09/04/24 19:45:08.199
• [2.074 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 09/04/24 19:45:08.206
  I0904 19:45:08.206151 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename daemonsets @ 09/04/24 19:45:08.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:45:08.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:45:08.228
  STEP: Creating simple DaemonSet "daemon-set" @ 09/04/24 19:45:08.254
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/04/24 19:45:08.26
  I0904 19:45:08.267031 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:08.267065 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:08.269951 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 19:45:08.269973 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 19:45:08.544462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:09.266147 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:09.266192 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:09.269662 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 19:45:09.269682 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 09/04/24 19:45:09.272
  I0904 19:45:09.287153 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:09.287192 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:09.290177 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 19:45:09.290192 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 19:45:09.544547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:10.289056 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:10.289108 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:10.292868 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0904 19:45:10.292882 19 fixtures.go:130] Node ip-172-31-21-169 is running 0 daemon pod, expected 1
  E0904 19:45:10.545236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:11.290310 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-29-199 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:11.290370 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-79-72 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0904 19:45:11.295948 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0904 19:45:11.296208 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/04/24 19:45:11.301
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8976, will wait for the garbage collector to delete the pods @ 09/04/24 19:45:11.301
  I0904 19:45:11.363566 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.79605ms
  I0904 19:45:11.464003 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.431619ms
  E0904 19:45:11.546271      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:12.546331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:13.070016 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0904 19:45:13.070062 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0904 19:45:13.073851 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"49749"},"items":null}

  I0904 19:45:13.077117 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"49749"},"items":null}

  I0904 19:45:13.090922 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8976" for this suite. @ 09/04/24 19:45:13.095
• [4.896 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 09/04/24 19:45:13.101
  I0904 19:45:13.102027 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pods @ 09/04/24 19:45:13.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:45:13.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:45:13.12
  STEP: creating a Pod with a static label @ 09/04/24 19:45:13.132
  STEP: watching for Pod to be ready @ 09/04/24 19:45:13.14
  I0904 19:45:13.142686 19 pods.go:945] observed Pod pod-test in namespace pods-7815 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0904 19:45:13.146816 19 pods.go:945] observed Pod pod-test in namespace pods-7815 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  }]
  I0904 19:45:13.168384 19 pods.go:945] observed Pod pod-test in namespace pods-7815 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  }]
  E0904 19:45:13.546717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:13.996176 19 pods.go:948] Found Pod pod-test in namespace pods-7815 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-04 19:45:13 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 09/04/24 19:45:14
  STEP: getting the Pod and ensuring that it's patched @ 09/04/24 19:45:14.01
  STEP: replacing the Pod's status Ready condition to False @ 09/04/24 19:45:14.014
  STEP: check the Pod again to ensure its Ready conditions are False @ 09/04/24 19:45:14.025
  STEP: deleting the Pod via a Collection with a LabelSelector @ 09/04/24 19:45:14.025
  STEP: watching for the Pod to be deleted @ 09/04/24 19:45:14.034
  I0904 19:45:14.036604 19 pods.go:1058] observed event type MODIFIED
  E0904 19:45:14.547553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:15.547811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:15.999931 19 pods.go:1058] observed event type MODIFIED
  I0904 19:45:16.149242 19 pods.go:1058] observed event type MODIFIED
  E0904 19:45:16.548819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:17.010716 19 pods.go:1058] observed event type MODIFIED
  I0904 19:45:17.016261 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7815" for this suite. @ 09/04/24 19:45:17.019
• [3.924 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 09/04/24 19:45:17.026
  I0904 19:45:17.026473 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename projected @ 09/04/24 19:45:17.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:45:17.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:45:17.048
  STEP: Creating a pod to test downward API volume plugin @ 09/04/24 19:45:17.052
  E0904 19:45:17.549683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:18.549811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:19.550674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:20.550751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/04/24 19:45:21.078
  I0904 19:45:21.082778 19 output.go:196] Trying to get logs from node ip-172-31-21-169 pod downwardapi-volume-b8352536-1496-43f6-8a58-ad9668a1bc2d container client-container: <nil>
  STEP: delete the pod @ 09/04/24 19:45:21.089
  I0904 19:45:21.107082 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5487" for this suite. @ 09/04/24 19:45:21.111
• [4.091 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 09/04/24 19:45:21.117
  I0904 19:45:21.117836 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename pod-network-test @ 09/04/24 19:45:21.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:45:21.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:45:21.137
  STEP: Performing setup for networking test in namespace pod-network-test-3047 @ 09/04/24 19:45:21.141
  STEP: creating a selector @ 09/04/24 19:45:21.141
  STEP: Creating the service pods in kubernetes @ 09/04/24 19:45:21.141
  I0904 19:45:21.141417 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0904 19:45:21.551347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:22.551397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:23.552371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:24.552504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:25.553129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:26.553209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:27.553985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:28.554085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:29.554177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:30.554283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:31.554697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:32.554811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/04/24 19:45:33.223
  E0904 19:45:33.554891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:34.555014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:35.255657 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0904 19:45:35.255688 19 utils.go:496] Going to poll 192.168.146.147 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0904 19:45:35.259481 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.146.147:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3047 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:45:35.259499 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:45:35.259863 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:45:35.259954 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3047/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.146.147%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0904 19:45:35.319006 19 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0904 19:45:35.319088 19 utils.go:496] Going to poll 192.168.104.175 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0904 19:45:35.324068 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.104.175:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3047 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:45:35.324087 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:45:35.324442 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:45:35.324479 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3047/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.104.175%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0904 19:45:35.380399 19 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0904 19:45:35.380446 19 utils.go:496] Going to poll 192.168.243.21 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0904 19:45:35.385180 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.243.21:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3047 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0904 19:45:35.385200 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  I0904 19:45:35.385597 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I0904 19:45:35.385634 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3047/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.243.21%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0904 19:45:35.450331 19 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I0904 19:45:35.450463 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3047" for this suite. @ 09/04/24 19:45:35.455
• [14.345 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 09/04/24 19:45:35.462
  I0904 19:45:35.462451 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/04/24 19:45:35.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:45:35.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:45:35.485
  I0904 19:45:35.490220 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  E0904 19:45:35.555842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:36.556193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 09/04/24 19:45:36.793
  I0904 19:45:36.793432 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 create -f -'
  E0904 19:45:37.556631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:38.556716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:38.861756 19 builder.go:146] stderr: ""
  I0904 19:45:38.861807 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0904 19:45:38.861857 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 delete e2e-test-crd-publish-openapi-1516-crds test-foo'
  I0904 19:45:38.920079 19 builder.go:146] stderr: ""
  I0904 19:45:38.920118 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I0904 19:45:38.920159 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 apply -f -'
  I0904 19:45:38.973437 19 builder.go:146] stderr: ""
  I0904 19:45:38.973502 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0904 19:45:38.973538 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 delete e2e-test-crd-publish-openapi-1516-crds test-foo'
  I0904 19:45:39.019389 19 builder.go:146] stderr: ""
  I0904 19:45:39.019424 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 09/04/24 19:45:39.019
  I0904 19:45:39.019579 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 create -f -'
  I0904 19:45:39.060449 19 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 09/04/24 19:45:39.06
  I0904 19:45:39.060657 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 create -f -'
  I0904 19:45:39.101019 19 builder.go:135] rc: 1
  I0904 19:45:39.101101 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 apply -f -'
  I0904 19:45:39.149214 19 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 09/04/24 19:45:39.149
  I0904 19:45:39.149351 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 create -f -'
  I0904 19:45:39.190951 19 builder.go:135] rc: 1
  I0904 19:45:39.191059 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 --namespace=crd-publish-openapi-5192 apply -f -'
  I0904 19:45:39.238151 19 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 09/04/24 19:45:39.238
  I0904 19:45:39.238253 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 explain e2e-test-crd-publish-openapi-1516-crds'
  I0904 19:45:39.276161 19 builder.go:146] stderr: ""
  I0904 19:45:39.276202 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1516-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 09/04/24 19:45:39.276
  I0904 19:45:39.276468 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 explain e2e-test-crd-publish-openapi-1516-crds.metadata'
  I0904 19:45:39.314975 19 builder.go:146] stderr: ""
  I0904 19:45:39.315091 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1516-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0904 19:45:39.315284 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 explain e2e-test-crd-publish-openapi-1516-crds.spec'
  I0904 19:45:39.353390 19 builder.go:146] stderr: ""
  I0904 19:45:39.353425 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1516-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0904 19:45:39.353536 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 explain e2e-test-crd-publish-openapi-1516-crds.spec.bars'
  I0904 19:45:39.391185 19 builder.go:146] stderr: ""
  I0904 19:45:39.391221 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1516-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 09/04/24 19:45:39.391
  I0904 19:45:39.391409 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=crd-publish-openapi-5192 explain e2e-test-crd-publish-openapi-1516-crds.spec.bars2'
  I0904 19:45:39.428947 19 builder.go:135] rc: 1
  E0904 19:45:39.557759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:40.557755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:40.780052 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5192" for this suite. @ 09/04/24 19:45:40.787
• [5.331 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:350
  STEP: Creating a kubernetes client @ 09/04/24 19:45:40.793
  I0904 19:45:40.793684 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2700138808
  STEP: Building a namespace api object, basename kubectl @ 09/04/24 19:45:40.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/04/24 19:45:40.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/04/24 19:45:40.814
  STEP: creating a replication controller @ 09/04/24 19:45:40.817
  I0904 19:45:40.817973 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 create -f -'
  I0904 19:45:40.899251 19 builder.go:146] stderr: ""
  I0904 19:45:40.899283 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/04/24 19:45:40.899
  I0904 19:45:40.899420 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0904 19:45:40.944366 19 builder.go:146] stderr: ""
  I0904 19:45:40.944397 19 builder.go:147] stdout: "update-demo-nautilus-2j66j update-demo-nautilus-h69th "
  I0904 19:45:40.944438 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-2j66j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:45:40.985522 19 builder.go:146] stderr: ""
  I0904 19:45:40.985552 19 builder.go:147] stdout: ""
  I0904 19:45:40.985561 19 kubectl.go:2502] update-demo-nautilus-2j66j is created but not running
  E0904 19:45:41.557894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:42.558328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:43.558372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:44.558514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0904 19:45:45.558712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:45.986372 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0904 19:45:46.029088 19 builder.go:146] stderr: ""
  I0904 19:45:46.029124 19 builder.go:147] stdout: "update-demo-nautilus-2j66j update-demo-nautilus-h69th "
  I0904 19:45:46.029162 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-2j66j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:45:46.067850 19 builder.go:146] stderr: ""
  I0904 19:45:46.067883 19 builder.go:147] stdout: "true"
  I0904 19:45:46.067919 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-2j66j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0904 19:45:46.107368 19 builder.go:146] stderr: ""
  I0904 19:45:46.107400 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0904 19:45:46.107410 19 kubectl.go:2393] validating pod update-demo-nautilus-2j66j
  I0904 19:45:46.113420 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0904 19:45:46.113484 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0904 19:45:46.113553 19 kubectl.go:2520] update-demo-nautilus-2j66j is verified up and running
  I0904 19:45:46.113601 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-h69th -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:45:46.155844 19 builder.go:146] stderr: ""
  I0904 19:45:46.155867 19 builder.go:147] stdout: "true"
  I0904 19:45:46.155900 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-h69th -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0904 19:45:46.195456 19 builder.go:146] stderr: ""
  I0904 19:45:46.195480 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0904 19:45:46.195489 19 kubectl.go:2393] validating pod update-demo-nautilus-h69th
  I0904 19:45:46.200553 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0904 19:45:46.200638 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0904 19:45:46.200652 19 kubectl.go:2520] update-demo-nautilus-h69th is verified up and running
  STEP: scaling down the replication controller @ 09/04/24 19:45:46.2
  I0904 19:45:46.201401 19 kubectl.go:319] scanned /root for discovery docs: <nil>
  I0904 19:45:46.201430 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0904 19:45:46.559080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:47.259750 19 builder.go:146] stderr: ""
  I0904 19:45:47.259797 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/04/24 19:45:47.259
  I0904 19:45:47.259880 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0904 19:45:47.300313 19 builder.go:146] stderr: ""
  I0904 19:45:47.300363 19 builder.go:147] stdout: "update-demo-nautilus-2j66j "
  I0904 19:45:47.300409 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-2j66j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:45:47.339996 19 builder.go:146] stderr: ""
  I0904 19:45:47.340040 19 builder.go:147] stdout: "true"
  I0904 19:45:47.340074 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-2j66j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0904 19:45:47.377659 19 builder.go:146] stderr: ""
  I0904 19:45:47.377688 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0904 19:45:47.377697 19 kubectl.go:2393] validating pod update-demo-nautilus-2j66j
  I0904 19:45:47.382623 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0904 19:45:47.382660 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0904 19:45:47.382681 19 kubectl.go:2520] update-demo-nautilus-2j66j is verified up and running
  STEP: scaling up the replication controller @ 09/04/24 19:45:47.382
  I0904 19:45:47.383360 19 kubectl.go:319] scanned /root for discovery docs: <nil>
  I0904 19:45:47.383390 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0904 19:45:47.559852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:48.444969 19 builder.go:146] stderr: ""
  I0904 19:45:48.445006 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/04/24 19:45:48.445
  I0904 19:45:48.445141 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0904 19:45:48.487131 19 builder.go:146] stderr: ""
  I0904 19:45:48.487178 19 builder.go:147] stdout: "update-demo-nautilus-2j66j update-demo-nautilus-5rw2d "
  I0904 19:45:48.487218 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-2j66j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:45:48.527505 19 builder.go:146] stderr: ""
  I0904 19:45:48.527538 19 builder.go:147] stdout: "true"
  I0904 19:45:48.527581 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-2j66j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0904 19:45:48.559869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0904 19:45:48.567028 19 builder.go:146] stderr: ""
  I0904 19:45:48.567056 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0904 19:45:48.567067 19 kubectl.go:2393] validating pod update-demo-nautilus-2j66j
  I0904 19:45:48.572738 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0904 19:45:48.572784 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0904 19:45:48.572795 19 kubectl.go:2520] update-demo-nautilus-2j66j is verified up and running
  I0904 19:45:48.572839 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-5rw2d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0904 19:45:48.611312 19 builder.go:146] stderr: ""
  I0904 19:45:48.611349 19 builder.go:147] stdout: "true"
  I0904 19:45:48.611379 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods update-demo-nautilus-5rw2d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0904 19:45:48.650681 19 builder.go:146] stderr: ""
  I0904 19:45:48.650734 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0904 19:45:48.650744 19 kubectl.go:2393] validating pod update-demo-nautilus-5rw2d
  I0904 19:45:48.657301 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0904 19:45:48.657395 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0904 19:45:48.657412 19 kubectl.go:2520] update-demo-nautilus-5rw2d is verified up and running
  STEP: using delete to clean up resources @ 09/04/24 19:45:48.657
  I0904 19:45:48.657556 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 delete --grace-period=0 --force -f -'
  I0904 19:45:48.703302 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0904 19:45:48.703326 19 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0904 19:45:48.703359 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get rc,svc -l name=update-demo --no-headers'
  I0904 19:45:48.760741 19 builder.go:146] stderr: "No resources found in kubectl-9153 namespace.\n"
  I0904 19:45:48.760780 19 builder.go:147] stdout: ""
  I0904 19:45:48.760817 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2700138808 --namespace=kubectl-9153 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0904 19:45:48.814568 19 builder.go:146] stderr: ""
  I0904 19:45:48.814604 19 builder.go:147] stdout: ""
  I0904 19:45:48.814757 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9153" for this suite. @ 09/04/24 19:45:48.818
• [8.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0904 19:45:48.824179 19 suites.go:34] Running AfterSuite actions on node 1
  I0904 19:45:48.824193 19 util.go:607] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:158
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:612
[ReportAfterSuite] PASSED [0.067 seconds]
------------------------------

Ran 404 of 6603 Specs in 6455.973 seconds
SUCCESS! -- 404 Passed | 0 Failed | 0 Pending | 6199 Skipped
PASS

Ginkgo ran 1 suite in 1h47m36.707322349s
Test Suite Passed
