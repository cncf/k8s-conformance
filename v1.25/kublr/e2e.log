I1129 11:26:42.637757      22 e2e.go:116] Starting e2e run "282b770b-3805-4cbc-9692-d81e0f561fad" on Ginkgo node 1
Nov 29 11:26:42.650: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1669721202 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Nov 29 11:26:42.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 11:26:42.753: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E1129 11:26:42.753429      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
E1129 11:26:42.753429      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Nov 29 11:26:42.768: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 29 11:26:42.798: INFO: 30 / 30 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 29 11:26:42.798: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Nov 29 11:26:42.798: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 29 11:26:42.802: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Nov 29 11:26:42.802: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Nov 29 11:26:42.802: INFO: e2e test version: v1.25.4
Nov 29 11:26:42.803: INFO: kube-apiserver version: v1.25.4
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Nov 29 11:26:42.803: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 11:26:42.808: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.056 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov 29 11:26:42.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 11:26:42.753: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    E1129 11:26:42.753429      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
    Nov 29 11:26:42.768: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Nov 29 11:26:42.798: INFO: 30 / 30 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Nov 29 11:26:42.798: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
    Nov 29 11:26:42.798: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Nov 29 11:26:42.802: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
    Nov 29 11:26:42.802: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
    Nov 29 11:26:42.802: INFO: e2e test version: v1.25.4
    Nov 29 11:26:42.803: INFO: kube-apiserver version: v1.25.4
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov 29 11:26:42.803: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 11:26:42.808: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:26:42.835
Nov 29 11:26:42.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename var-expansion 11/29/22 11:26:42.836
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:26:42.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:26:42.852
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Nov 29 11:26:42.863: INFO: Waiting up to 2m0s for pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae" in namespace "var-expansion-2988" to be "container 0 failed with reason CreateContainerConfigError"
Nov 29 11:26:42.866: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.155597ms
Nov 29 11:26:44.869: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006005878s
Nov 29 11:26:46.871: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008174152s
Nov 29 11:26:48.869: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006635269s
Nov 29 11:26:48.869: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov 29 11:26:48.869: INFO: Deleting pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae" in namespace "var-expansion-2988"
Nov 29 11:26:48.873: INFO: Wait up to 5m0s for pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 29 11:26:50.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2988" for this suite. 11/29/22 11:26:50.882
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":1,"skipped":27,"failed":0}
------------------------------
• [SLOW TEST] [8.051 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:26:42.835
    Nov 29 11:26:42.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename var-expansion 11/29/22 11:26:42.836
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:26:42.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:26:42.852
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Nov 29 11:26:42.863: INFO: Waiting up to 2m0s for pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae" in namespace "var-expansion-2988" to be "container 0 failed with reason CreateContainerConfigError"
    Nov 29 11:26:42.866: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.155597ms
    Nov 29 11:26:44.869: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006005878s
    Nov 29 11:26:46.871: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008174152s
    Nov 29 11:26:48.869: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006635269s
    Nov 29 11:26:48.869: INFO: Pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov 29 11:26:48.869: INFO: Deleting pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae" in namespace "var-expansion-2988"
    Nov 29 11:26:48.873: INFO: Wait up to 5m0s for pod "var-expansion-8f32e59a-83aa-4411-bf94-059fb9415cae" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 29 11:26:50.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2988" for this suite. 11/29/22 11:26:50.882
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:26:50.886
Nov 29 11:26:50.886: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:26:50.887
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:26:50.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:26:50.898
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 11/29/22 11:26:50.9
Nov 29 11:26:50.905: INFO: Waiting up to 5m0s for pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e" in namespace "projected-1358" to be "Succeeded or Failed"
Nov 29 11:26:50.908: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.188851ms
Nov 29 11:26:52.912: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006204179s
Nov 29 11:26:54.913: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00739831s
Nov 29 11:26:56.911: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.005761649s
Nov 29 11:26:58.922: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017060951s
Nov 29 11:27:00.912: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006267881s
Nov 29 11:27:02.911: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.005159851s
STEP: Saw pod success 11/29/22 11:27:02.911
Nov 29 11:27:02.911: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e" satisfied condition "Succeeded or Failed"
Nov 29 11:27:02.913: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e container client-container: <nil>
STEP: delete the pod 11/29/22 11:27:02.918
Nov 29 11:27:02.924: INFO: Waiting for pod downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e to disappear
Nov 29 11:27:02.926: INFO: Pod downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 11:27:02.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1358" for this suite. 11/29/22 11:27:02.93
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":2,"skipped":29,"failed":0}
------------------------------
• [SLOW TEST] [12.048 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:26:50.886
    Nov 29 11:26:50.886: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:26:50.887
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:26:50.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:26:50.898
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 11/29/22 11:26:50.9
    Nov 29 11:26:50.905: INFO: Waiting up to 5m0s for pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e" in namespace "projected-1358" to be "Succeeded or Failed"
    Nov 29 11:26:50.908: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.188851ms
    Nov 29 11:26:52.912: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006204179s
    Nov 29 11:26:54.913: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00739831s
    Nov 29 11:26:56.911: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.005761649s
    Nov 29 11:26:58.922: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017060951s
    Nov 29 11:27:00.912: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006267881s
    Nov 29 11:27:02.911: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.005159851s
    STEP: Saw pod success 11/29/22 11:27:02.911
    Nov 29 11:27:02.911: INFO: Pod "downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e" satisfied condition "Succeeded or Failed"
    Nov 29 11:27:02.913: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e container client-container: <nil>
    STEP: delete the pod 11/29/22 11:27:02.918
    Nov 29 11:27:02.924: INFO: Waiting for pod downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e to disappear
    Nov 29 11:27:02.926: INFO: Pod downwardapi-volume-49e0b362-ec0b-49eb-a91e-604d4566506e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 11:27:02.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1358" for this suite. 11/29/22 11:27:02.93
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:27:02.934
Nov 29 11:27:02.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename job 11/29/22 11:27:02.935
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:02.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:02.945
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 11/29/22 11:27:02.947
STEP: Ensuring job reaches completions 11/29/22 11:27:02.951
STEP: Ensuring pods with index for job exist 11/29/22 11:27:10.956
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 29 11:27:10.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2564" for this suite. 11/29/22 11:27:10.962
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":3,"skipped":31,"failed":0}
------------------------------
• [SLOW TEST] [8.031 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:27:02.934
    Nov 29 11:27:02.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename job 11/29/22 11:27:02.935
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:02.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:02.945
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 11/29/22 11:27:02.947
    STEP: Ensuring job reaches completions 11/29/22 11:27:02.951
    STEP: Ensuring pods with index for job exist 11/29/22 11:27:10.956
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 29 11:27:10.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2564" for this suite. 11/29/22 11:27:10.962
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:27:10.967
Nov 29 11:27:10.967: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sysctl 11/29/22 11:27:10.968
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:10.979
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:10.982
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 11/29/22 11:27:10.984
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 29 11:27:10.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-1255" for this suite. 11/29/22 11:27:10.99
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":4,"skipped":94,"failed":0}
------------------------------
• [0.025 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:27:10.967
    Nov 29 11:27:10.967: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sysctl 11/29/22 11:27:10.968
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:10.979
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:10.982
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 11/29/22 11:27:10.984
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 29 11:27:10.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-1255" for this suite. 11/29/22 11:27:10.99
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:27:10.993
Nov 29 11:27:10.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 11:27:10.994
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:11.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:11.004
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/29/22 11:27:11.007
Nov 29 11:27:11.012: INFO: Waiting up to 5m0s for pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3" in namespace "emptydir-6205" to be "Succeeded or Failed"
Nov 29 11:27:11.014: INFO: Pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.515358ms
Nov 29 11:27:13.018: INFO: Pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006177429s
Nov 29 11:27:15.018: INFO: Pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006718304s
STEP: Saw pod success 11/29/22 11:27:15.019
Nov 29 11:27:15.019: INFO: Pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3" satisfied condition "Succeeded or Failed"
Nov 29 11:27:15.021: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-29bb5e10-ce61-4586-8643-a6d73a247cc3 container test-container: <nil>
STEP: delete the pod 11/29/22 11:27:15.032
Nov 29 11:27:15.036: INFO: Waiting for pod pod-29bb5e10-ce61-4586-8643-a6d73a247cc3 to disappear
Nov 29 11:27:15.038: INFO: Pod pod-29bb5e10-ce61-4586-8643-a6d73a247cc3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 11:27:15.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6205" for this suite. 11/29/22 11:27:15.041
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":5,"skipped":99,"failed":0}
------------------------------
• [4.051 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:27:10.993
    Nov 29 11:27:10.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 11:27:10.994
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:11.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:11.004
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/29/22 11:27:11.007
    Nov 29 11:27:11.012: INFO: Waiting up to 5m0s for pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3" in namespace "emptydir-6205" to be "Succeeded or Failed"
    Nov 29 11:27:11.014: INFO: Pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.515358ms
    Nov 29 11:27:13.018: INFO: Pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006177429s
    Nov 29 11:27:15.018: INFO: Pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006718304s
    STEP: Saw pod success 11/29/22 11:27:15.019
    Nov 29 11:27:15.019: INFO: Pod "pod-29bb5e10-ce61-4586-8643-a6d73a247cc3" satisfied condition "Succeeded or Failed"
    Nov 29 11:27:15.021: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-29bb5e10-ce61-4586-8643-a6d73a247cc3 container test-container: <nil>
    STEP: delete the pod 11/29/22 11:27:15.032
    Nov 29 11:27:15.036: INFO: Waiting for pod pod-29bb5e10-ce61-4586-8643-a6d73a247cc3 to disappear
    Nov 29 11:27:15.038: INFO: Pod pod-29bb5e10-ce61-4586-8643-a6d73a247cc3 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 11:27:15.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6205" for this suite. 11/29/22 11:27:15.041
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:27:15.045
Nov 29 11:27:15.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 11:27:15.046
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:15.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:15.056
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/29/22 11:27:15.058
Nov 29 11:27:15.059: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/29/22 11:27:27.593
Nov 29 11:27:27.594: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 11:27:31.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:27:41.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3813" for this suite. 11/29/22 11:27:41.315
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":6,"skipped":122,"failed":0}
------------------------------
• [SLOW TEST] [26.273 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:27:15.045
    Nov 29 11:27:15.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 11:27:15.046
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:15.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:15.056
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/29/22 11:27:15.058
    Nov 29 11:27:15.059: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/29/22 11:27:27.593
    Nov 29 11:27:27.594: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 11:27:31.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:27:41.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3813" for this suite. 11/29/22 11:27:41.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:27:41.32
Nov 29 11:27:41.320: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 11:27:41.321
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:41.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:41.334
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 11/29/22 11:27:41.336
Nov 29 11:27:41.341: INFO: Waiting up to 5m0s for pod "pod-023c0f32-db76-4676-9804-5455beddf106" in namespace "emptydir-6843" to be "Succeeded or Failed"
Nov 29 11:27:41.343: INFO: Pod "pod-023c0f32-db76-4676-9804-5455beddf106": Phase="Pending", Reason="", readiness=false. Elapsed: 2.157441ms
Nov 29 11:27:43.346: INFO: Pod "pod-023c0f32-db76-4676-9804-5455beddf106": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005649397s
Nov 29 11:27:45.348: INFO: Pod "pod-023c0f32-db76-4676-9804-5455beddf106": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007259592s
STEP: Saw pod success 11/29/22 11:27:45.348
Nov 29 11:27:45.349: INFO: Pod "pod-023c0f32-db76-4676-9804-5455beddf106" satisfied condition "Succeeded or Failed"
Nov 29 11:27:45.352: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-023c0f32-db76-4676-9804-5455beddf106 container test-container: <nil>
STEP: delete the pod 11/29/22 11:27:45.357
Nov 29 11:27:45.363: INFO: Waiting for pod pod-023c0f32-db76-4676-9804-5455beddf106 to disappear
Nov 29 11:27:45.365: INFO: Pod pod-023c0f32-db76-4676-9804-5455beddf106 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 11:27:45.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6843" for this suite. 11/29/22 11:27:45.369
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":7,"skipped":193,"failed":0}
------------------------------
• [4.052 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:27:41.32
    Nov 29 11:27:41.320: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 11:27:41.321
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:41.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:41.334
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/29/22 11:27:41.336
    Nov 29 11:27:41.341: INFO: Waiting up to 5m0s for pod "pod-023c0f32-db76-4676-9804-5455beddf106" in namespace "emptydir-6843" to be "Succeeded or Failed"
    Nov 29 11:27:41.343: INFO: Pod "pod-023c0f32-db76-4676-9804-5455beddf106": Phase="Pending", Reason="", readiness=false. Elapsed: 2.157441ms
    Nov 29 11:27:43.346: INFO: Pod "pod-023c0f32-db76-4676-9804-5455beddf106": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005649397s
    Nov 29 11:27:45.348: INFO: Pod "pod-023c0f32-db76-4676-9804-5455beddf106": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007259592s
    STEP: Saw pod success 11/29/22 11:27:45.348
    Nov 29 11:27:45.349: INFO: Pod "pod-023c0f32-db76-4676-9804-5455beddf106" satisfied condition "Succeeded or Failed"
    Nov 29 11:27:45.352: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-023c0f32-db76-4676-9804-5455beddf106 container test-container: <nil>
    STEP: delete the pod 11/29/22 11:27:45.357
    Nov 29 11:27:45.363: INFO: Waiting for pod pod-023c0f32-db76-4676-9804-5455beddf106 to disappear
    Nov 29 11:27:45.365: INFO: Pod pod-023c0f32-db76-4676-9804-5455beddf106 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 11:27:45.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6843" for this suite. 11/29/22 11:27:45.369
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:27:45.374
Nov 29 11:27:45.374: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename job 11/29/22 11:27:45.375
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:45.383
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:45.385
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 11/29/22 11:27:45.389
STEP: Ensuring active pods == parallelism 11/29/22 11:27:45.392
STEP: delete a job 11/29/22 11:27:47.396
STEP: deleting Job.batch foo in namespace job-5308, will wait for the garbage collector to delete the pods 11/29/22 11:27:47.396
Nov 29 11:27:47.453: INFO: Deleting Job.batch foo took: 3.698122ms
Nov 29 11:27:47.554: INFO: Terminating Job.batch foo pods took: 100.829572ms
STEP: Ensuring job was deleted 11/29/22 11:28:20.155
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 29 11:28:20.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5308" for this suite. 11/29/22 11:28:20.161
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":8,"skipped":235,"failed":0}
------------------------------
• [SLOW TEST] [34.791 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:27:45.374
    Nov 29 11:27:45.374: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename job 11/29/22 11:27:45.375
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:27:45.383
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:27:45.385
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 11/29/22 11:27:45.389
    STEP: Ensuring active pods == parallelism 11/29/22 11:27:45.392
    STEP: delete a job 11/29/22 11:27:47.396
    STEP: deleting Job.batch foo in namespace job-5308, will wait for the garbage collector to delete the pods 11/29/22 11:27:47.396
    Nov 29 11:27:47.453: INFO: Deleting Job.batch foo took: 3.698122ms
    Nov 29 11:27:47.554: INFO: Terminating Job.batch foo pods took: 100.829572ms
    STEP: Ensuring job was deleted 11/29/22 11:28:20.155
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 29 11:28:20.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5308" for this suite. 11/29/22 11:28:20.161
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:28:20.167
Nov 29 11:28:20.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-probe 11/29/22 11:28:20.167
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:28:20.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:28:20.178
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec in namespace container-probe-8151 11/29/22 11:28:20.18
Nov 29 11:28:20.184: INFO: Waiting up to 5m0s for pod "liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec" in namespace "container-probe-8151" to be "not pending"
Nov 29 11:28:20.192: INFO: Pod "liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec": Phase="Pending", Reason="", readiness=false. Elapsed: 7.548056ms
Nov 29 11:28:22.195: INFO: Pod "liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec": Phase="Running", Reason="", readiness=true. Elapsed: 2.010644683s
Nov 29 11:28:22.195: INFO: Pod "liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec" satisfied condition "not pending"
Nov 29 11:28:22.195: INFO: Started pod liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec in namespace container-probe-8151
STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 11:28:22.195
Nov 29 11:28:22.197: INFO: Initial restart count of pod liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec is 0
Nov 29 11:28:42.239: INFO: Restart count of pod container-probe-8151/liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec is now 1 (20.041874924s elapsed)
STEP: deleting the pod 11/29/22 11:28:42.239
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 29 11:28:42.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8151" for this suite. 11/29/22 11:28:42.258
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":9,"skipped":259,"failed":0}
------------------------------
• [SLOW TEST] [22.095 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:28:20.167
    Nov 29 11:28:20.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-probe 11/29/22 11:28:20.167
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:28:20.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:28:20.178
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec in namespace container-probe-8151 11/29/22 11:28:20.18
    Nov 29 11:28:20.184: INFO: Waiting up to 5m0s for pod "liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec" in namespace "container-probe-8151" to be "not pending"
    Nov 29 11:28:20.192: INFO: Pod "liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec": Phase="Pending", Reason="", readiness=false. Elapsed: 7.548056ms
    Nov 29 11:28:22.195: INFO: Pod "liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec": Phase="Running", Reason="", readiness=true. Elapsed: 2.010644683s
    Nov 29 11:28:22.195: INFO: Pod "liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec" satisfied condition "not pending"
    Nov 29 11:28:22.195: INFO: Started pod liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec in namespace container-probe-8151
    STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 11:28:22.195
    Nov 29 11:28:22.197: INFO: Initial restart count of pod liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec is 0
    Nov 29 11:28:42.239: INFO: Restart count of pod container-probe-8151/liveness-d9ae11ec-c5cd-4cb4-ba7f-bbdb7c4915ec is now 1 (20.041874924s elapsed)
    STEP: deleting the pod 11/29/22 11:28:42.239
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 29 11:28:42.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8151" for this suite. 11/29/22 11:28:42.258
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:28:42.264
Nov 29 11:28:42.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename endpointslice 11/29/22 11:28:42.265
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:28:42.272
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:28:42.275
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 11/29/22 11:28:47.338
STEP: referencing matching pods with named port 11/29/22 11:28:52.343
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/29/22 11:28:57.35
STEP: recreating EndpointSlices after they've been deleted 11/29/22 11:29:02.356
Nov 29 11:29:02.376: INFO: EndpointSlice for Service endpointslice-5124/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 29 11:29:12.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5124" for this suite. 11/29/22 11:29:12.394
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":10,"skipped":322,"failed":0}
------------------------------
• [SLOW TEST] [30.133 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:28:42.264
    Nov 29 11:28:42.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename endpointslice 11/29/22 11:28:42.265
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:28:42.272
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:28:42.275
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 11/29/22 11:28:47.338
    STEP: referencing matching pods with named port 11/29/22 11:28:52.343
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/29/22 11:28:57.35
    STEP: recreating EndpointSlices after they've been deleted 11/29/22 11:29:02.356
    Nov 29 11:29:02.376: INFO: EndpointSlice for Service endpointslice-5124/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 29 11:29:12.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5124" for this suite. 11/29/22 11:29:12.394
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:29:12.398
Nov 29 11:29:12.398: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename watch 11/29/22 11:29:12.399
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:29:12.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:29:12.413
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 11/29/22 11:29:12.415
STEP: creating a new configmap 11/29/22 11:29:12.416
STEP: modifying the configmap once 11/29/22 11:29:12.418
STEP: changing the label value of the configmap 11/29/22 11:29:12.421
STEP: Expecting to observe a delete notification for the watched object 11/29/22 11:29:12.424
Nov 29 11:29:12.424: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5752 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 11:29:12.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5753 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 11:29:12.425: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5754 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 11/29/22 11:29:12.425
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/29/22 11:29:12.429
STEP: changing the label value of the configmap back 11/29/22 11:29:22.429
STEP: modifying the configmap a third time 11/29/22 11:29:22.436
STEP: deleting the configmap 11/29/22 11:29:22.44
STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/29/22 11:29:22.445
Nov 29 11:29:22.445: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5812 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 11:29:22.445: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5813 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 11:29:22.445: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5815 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 29 11:29:22.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-461" for this suite. 11/29/22 11:29:22.448
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":11,"skipped":370,"failed":0}
------------------------------
• [SLOW TEST] [10.054 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:29:12.398
    Nov 29 11:29:12.398: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename watch 11/29/22 11:29:12.399
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:29:12.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:29:12.413
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 11/29/22 11:29:12.415
    STEP: creating a new configmap 11/29/22 11:29:12.416
    STEP: modifying the configmap once 11/29/22 11:29:12.418
    STEP: changing the label value of the configmap 11/29/22 11:29:12.421
    STEP: Expecting to observe a delete notification for the watched object 11/29/22 11:29:12.424
    Nov 29 11:29:12.424: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5752 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 11:29:12.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5753 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 11:29:12.425: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5754 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 11/29/22 11:29:12.425
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/29/22 11:29:12.429
    STEP: changing the label value of the configmap back 11/29/22 11:29:22.429
    STEP: modifying the configmap a third time 11/29/22 11:29:22.436
    STEP: deleting the configmap 11/29/22 11:29:22.44
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/29/22 11:29:22.445
    Nov 29 11:29:22.445: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5812 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 11:29:22.445: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5813 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 11:29:22.445: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-461  b31b478d-8184-40a4-a107-ef45af2d1e15 5815 0 2022-11-29 11:29:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-29 11:29:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 29 11:29:22.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-461" for this suite. 11/29/22 11:29:22.448
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:29:22.452
Nov 29 11:29:22.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 11:29:22.453
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:29:22.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:29:22.465
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Nov 29 11:29:22.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/29/22 11:29:24.768
Nov 29 11:29:24.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 --namespace=crd-publish-openapi-7677 create -f -'
Nov 29 11:29:25.424: INFO: stderr: ""
Nov 29 11:29:25.424: INFO: stdout: "e2e-test-crd-publish-openapi-6541-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 29 11:29:25.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 --namespace=crd-publish-openapi-7677 delete e2e-test-crd-publish-openapi-6541-crds test-cr'
Nov 29 11:29:25.503: INFO: stderr: ""
Nov 29 11:29:25.503: INFO: stdout: "e2e-test-crd-publish-openapi-6541-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov 29 11:29:25.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 --namespace=crd-publish-openapi-7677 apply -f -'
Nov 29 11:29:25.775: INFO: stderr: ""
Nov 29 11:29:25.775: INFO: stdout: "e2e-test-crd-publish-openapi-6541-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 29 11:29:25.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 --namespace=crd-publish-openapi-7677 delete e2e-test-crd-publish-openapi-6541-crds test-cr'
Nov 29 11:29:25.861: INFO: stderr: ""
Nov 29 11:29:25.861: INFO: stdout: "e2e-test-crd-publish-openapi-6541-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/29/22 11:29:25.861
Nov 29 11:29:25.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 explain e2e-test-crd-publish-openapi-6541-crds'
Nov 29 11:29:26.164: INFO: stderr: ""
Nov 29 11:29:26.164: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6541-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:29:29.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7677" for this suite. 11/29/22 11:29:29.497
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":12,"skipped":372,"failed":0}
------------------------------
• [SLOW TEST] [7.048 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:29:22.452
    Nov 29 11:29:22.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 11:29:22.453
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:29:22.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:29:22.465
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Nov 29 11:29:22.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/29/22 11:29:24.768
    Nov 29 11:29:24.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 --namespace=crd-publish-openapi-7677 create -f -'
    Nov 29 11:29:25.424: INFO: stderr: ""
    Nov 29 11:29:25.424: INFO: stdout: "e2e-test-crd-publish-openapi-6541-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov 29 11:29:25.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 --namespace=crd-publish-openapi-7677 delete e2e-test-crd-publish-openapi-6541-crds test-cr'
    Nov 29 11:29:25.503: INFO: stderr: ""
    Nov 29 11:29:25.503: INFO: stdout: "e2e-test-crd-publish-openapi-6541-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Nov 29 11:29:25.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 --namespace=crd-publish-openapi-7677 apply -f -'
    Nov 29 11:29:25.775: INFO: stderr: ""
    Nov 29 11:29:25.775: INFO: stdout: "e2e-test-crd-publish-openapi-6541-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov 29 11:29:25.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 --namespace=crd-publish-openapi-7677 delete e2e-test-crd-publish-openapi-6541-crds test-cr'
    Nov 29 11:29:25.861: INFO: stderr: ""
    Nov 29 11:29:25.861: INFO: stdout: "e2e-test-crd-publish-openapi-6541-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/29/22 11:29:25.861
    Nov 29 11:29:25.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-7677 explain e2e-test-crd-publish-openapi-6541-crds'
    Nov 29 11:29:26.164: INFO: stderr: ""
    Nov 29 11:29:26.164: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6541-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:29:29.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7677" for this suite. 11/29/22 11:29:29.497
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:29:29.501
Nov 29 11:29:29.501: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename disruption 11/29/22 11:29:29.502
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:29:29.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:29:29.512
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 11/29/22 11:29:29.519
STEP: Waiting for all pods to be running 11/29/22 11:29:31.542
Nov 29 11:29:31.550: INFO: running pods: 0 < 3
Nov 29 11:29:33.553: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 29 11:29:35.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-243" for this suite. 11/29/22 11:29:35.558
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":13,"skipped":384,"failed":0}
------------------------------
• [SLOW TEST] [6.061 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:29:29.501
    Nov 29 11:29:29.501: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename disruption 11/29/22 11:29:29.502
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:29:29.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:29:29.512
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 11/29/22 11:29:29.519
    STEP: Waiting for all pods to be running 11/29/22 11:29:31.542
    Nov 29 11:29:31.550: INFO: running pods: 0 < 3
    Nov 29 11:29:33.553: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 29 11:29:35.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-243" for this suite. 11/29/22 11:29:35.558
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:29:35.562
Nov 29 11:29:35.563: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename statefulset 11/29/22 11:29:35.563
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:29:35.573
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:29:35.575
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3889 11/29/22 11:29:35.578
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-3889 11/29/22 11:29:35.581
Nov 29 11:29:35.589: INFO: Found 0 stateful pods, waiting for 1
Nov 29 11:29:45.594: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Nov 29 11:29:55.595: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 11/29/22 11:29:55.602
STEP: updating a scale subresource 11/29/22 11:29:55.605
STEP: verifying the statefulset Spec.Replicas was modified 11/29/22 11:29:55.608
STEP: Patch a scale subresource 11/29/22 11:29:55.612
STEP: verifying the statefulset Spec.Replicas was modified 11/29/22 11:29:55.617
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 29 11:29:55.621: INFO: Deleting all statefulset in ns statefulset-3889
Nov 29 11:29:55.623: INFO: Scaling statefulset ss to 0
Nov 29 11:30:15.640: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 11:30:15.643: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 29 11:30:15.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3889" for this suite. 11/29/22 11:30:15.655
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":14,"skipped":389,"failed":0}
------------------------------
• [SLOW TEST] [40.096 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:29:35.562
    Nov 29 11:29:35.563: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename statefulset 11/29/22 11:29:35.563
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:29:35.573
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:29:35.575
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3889 11/29/22 11:29:35.578
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-3889 11/29/22 11:29:35.581
    Nov 29 11:29:35.589: INFO: Found 0 stateful pods, waiting for 1
    Nov 29 11:29:45.594: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    Nov 29 11:29:55.595: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 11/29/22 11:29:55.602
    STEP: updating a scale subresource 11/29/22 11:29:55.605
    STEP: verifying the statefulset Spec.Replicas was modified 11/29/22 11:29:55.608
    STEP: Patch a scale subresource 11/29/22 11:29:55.612
    STEP: verifying the statefulset Spec.Replicas was modified 11/29/22 11:29:55.617
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 29 11:29:55.621: INFO: Deleting all statefulset in ns statefulset-3889
    Nov 29 11:29:55.623: INFO: Scaling statefulset ss to 0
    Nov 29 11:30:15.640: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 11:30:15.643: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 29 11:30:15.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3889" for this suite. 11/29/22 11:30:15.655
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:15.66
Nov 29 11:30:15.660: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 11:30:15.661
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:15.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:15.675
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-90158cc8-ac50-4788-9bf8-0b6d8b87d1b9 11/29/22 11:30:15.677
STEP: Creating a pod to test consume configMaps 11/29/22 11:30:15.68
Nov 29 11:30:15.684: INFO: Waiting up to 5m0s for pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c" in namespace "configmap-1518" to be "Succeeded or Failed"
Nov 29 11:30:15.687: INFO: Pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.125738ms
Nov 29 11:30:17.690: INFO: Pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005827392s
Nov 29 11:30:19.694: INFO: Pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010006216s
STEP: Saw pod success 11/29/22 11:30:19.694
Nov 29 11:30:19.695: INFO: Pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c" satisfied condition "Succeeded or Failed"
Nov 29 11:30:19.698: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c container agnhost-container: <nil>
STEP: delete the pod 11/29/22 11:30:19.703
Nov 29 11:30:19.711: INFO: Waiting for pod pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c to disappear
Nov 29 11:30:19.713: INFO: Pod pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 11:30:19.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1518" for this suite. 11/29/22 11:30:19.716
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":15,"skipped":403,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:15.66
    Nov 29 11:30:15.660: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 11:30:15.661
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:15.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:15.675
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-90158cc8-ac50-4788-9bf8-0b6d8b87d1b9 11/29/22 11:30:15.677
    STEP: Creating a pod to test consume configMaps 11/29/22 11:30:15.68
    Nov 29 11:30:15.684: INFO: Waiting up to 5m0s for pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c" in namespace "configmap-1518" to be "Succeeded or Failed"
    Nov 29 11:30:15.687: INFO: Pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.125738ms
    Nov 29 11:30:17.690: INFO: Pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005827392s
    Nov 29 11:30:19.694: INFO: Pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010006216s
    STEP: Saw pod success 11/29/22 11:30:19.694
    Nov 29 11:30:19.695: INFO: Pod "pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c" satisfied condition "Succeeded or Failed"
    Nov 29 11:30:19.698: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 11:30:19.703
    Nov 29 11:30:19.711: INFO: Waiting for pod pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c to disappear
    Nov 29 11:30:19.713: INFO: Pod pod-configmaps-29a3e61b-6f9b-4e3c-b024-3da23556b34c no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 11:30:19.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1518" for this suite. 11/29/22 11:30:19.716
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:19.721
Nov 29 11:30:19.721: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename deployment 11/29/22 11:30:19.722
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:19.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:19.73
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Nov 29 11:30:19.732: INFO: Creating deployment "test-recreate-deployment"
Nov 29 11:30:19.736: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 29 11:30:19.754: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov 29 11:30:21.760: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 29 11:30:21.762: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 29 11:30:21.767: INFO: Updating deployment test-recreate-deployment
Nov 29 11:30:21.767: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 29 11:30:21.830: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4478  2cb8854c-de0a-484f-aa33-dfb0072d9491 6199 2 2022-11-29 11:30:19 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00326b9f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-29 11:30:21 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-29 11:30:21 +0000 UTC,LastTransitionTime:2022-11-29 11:30:19 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov 29 11:30:21.833: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-4478  6b8a93c4-52b0-4e79-bd17-a3e4c659bbbb 6196 1 2022-11-29 11:30:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 2cb8854c-de0a-484f-aa33-dfb0072d9491 0xc0032e8170 0xc0032e8171}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cb8854c-de0a-484f-aa33-dfb0072d9491\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032e8258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 29 11:30:21.833: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 29 11:30:21.833: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-4478  9d586db9-a354-4398-882c-43d7c6c2ef88 6187 2 2022-11-29 11:30:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 2cb8854c-de0a-484f-aa33-dfb0072d9491 0xc0032e8007 0xc0032e8008}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cb8854c-de0a-484f-aa33-dfb0072d9491\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032e80e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 29 11:30:21.835: INFO: Pod "test-recreate-deployment-9d58999df-f88zb" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-f88zb test-recreate-deployment-9d58999df- deployment-4478  9cfae445-56a4-4564-9081-0e7265a4d5f1 6198 0 2022-11-29 11:30:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 6b8a93c4-52b0-4e79-bd17-a3e4c659bbbb 0xc0032e8ae0 0xc0032e8ae1}] [] [{kube-controller-manager Update v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6b8a93c4-52b0-4e79-bd17-a3e4c659bbbb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2gkhh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2gkhh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 11:30:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 29 11:30:21.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4478" for this suite. 11/29/22 11:30:21.839
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":16,"skipped":422,"failed":0}
------------------------------
• [2.125 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:19.721
    Nov 29 11:30:19.721: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename deployment 11/29/22 11:30:19.722
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:19.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:19.73
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Nov 29 11:30:19.732: INFO: Creating deployment "test-recreate-deployment"
    Nov 29 11:30:19.736: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Nov 29 11:30:19.754: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Nov 29 11:30:21.760: INFO: Waiting deployment "test-recreate-deployment" to complete
    Nov 29 11:30:21.762: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Nov 29 11:30:21.767: INFO: Updating deployment test-recreate-deployment
    Nov 29 11:30:21.767: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 29 11:30:21.830: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-4478  2cb8854c-de0a-484f-aa33-dfb0072d9491 6199 2 2022-11-29 11:30:19 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00326b9f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-29 11:30:21 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-29 11:30:21 +0000 UTC,LastTransitionTime:2022-11-29 11:30:19 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Nov 29 11:30:21.833: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-4478  6b8a93c4-52b0-4e79-bd17-a3e4c659bbbb 6196 1 2022-11-29 11:30:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 2cb8854c-de0a-484f-aa33-dfb0072d9491 0xc0032e8170 0xc0032e8171}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cb8854c-de0a-484f-aa33-dfb0072d9491\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032e8258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 11:30:21.833: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Nov 29 11:30:21.833: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-4478  9d586db9-a354-4398-882c-43d7c6c2ef88 6187 2 2022-11-29 11:30:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 2cb8854c-de0a-484f-aa33-dfb0072d9491 0xc0032e8007 0xc0032e8008}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cb8854c-de0a-484f-aa33-dfb0072d9491\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032e80e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 11:30:21.835: INFO: Pod "test-recreate-deployment-9d58999df-f88zb" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-f88zb test-recreate-deployment-9d58999df- deployment-4478  9cfae445-56a4-4564-9081-0e7265a4d5f1 6198 0 2022-11-29 11:30:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 6b8a93c4-52b0-4e79-bd17-a3e4c659bbbb 0xc0032e8ae0 0xc0032e8ae1}] [] [{kube-controller-manager Update v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6b8a93c4-52b0-4e79-bd17-a3e4c659bbbb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 11:30:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2gkhh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2gkhh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 11:30:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 29 11:30:21.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4478" for this suite. 11/29/22 11:30:21.839
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:21.848
Nov 29 11:30:21.848: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename runtimeclass 11/29/22 11:30:21.849
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:21.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:21.86
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Nov 29 11:30:21.870: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-6708 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 29 11:30:21.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6708" for this suite. 11/29/22 11:30:21.882
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":17,"skipped":436,"failed":0}
------------------------------
• [0.044 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:21.848
    Nov 29 11:30:21.848: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename runtimeclass 11/29/22 11:30:21.849
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:21.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:21.86
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Nov 29 11:30:21.870: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-6708 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 29 11:30:21.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6708" for this suite. 11/29/22 11:30:21.882
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:21.893
Nov 29 11:30:21.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:30:21.894
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:21.901
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:21.904
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 11/29/22 11:30:21.906
Nov 29 11:30:21.911: INFO: Waiting up to 5m0s for pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa" in namespace "projected-254" to be "running and ready"
Nov 29 11:30:21.916: INFO: Pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.688765ms
Nov 29 11:30:21.916: INFO: The phase of Pod labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:30:23.919: INFO: Pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa": Phase="Running", Reason="", readiness=true. Elapsed: 2.00815594s
Nov 29 11:30:23.919: INFO: The phase of Pod labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa is Running (Ready = true)
Nov 29 11:30:23.919: INFO: Pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa" satisfied condition "running and ready"
Nov 29 11:30:24.434: INFO: Successfully updated pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 11:30:28.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-254" for this suite. 11/29/22 11:30:28.458
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":18,"skipped":450,"failed":0}
------------------------------
• [SLOW TEST] [6.568 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:21.893
    Nov 29 11:30:21.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:30:21.894
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:21.901
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:21.904
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 11/29/22 11:30:21.906
    Nov 29 11:30:21.911: INFO: Waiting up to 5m0s for pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa" in namespace "projected-254" to be "running and ready"
    Nov 29 11:30:21.916: INFO: Pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.688765ms
    Nov 29 11:30:21.916: INFO: The phase of Pod labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:30:23.919: INFO: Pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa": Phase="Running", Reason="", readiness=true. Elapsed: 2.00815594s
    Nov 29 11:30:23.919: INFO: The phase of Pod labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa is Running (Ready = true)
    Nov 29 11:30:23.919: INFO: Pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa" satisfied condition "running and ready"
    Nov 29 11:30:24.434: INFO: Successfully updated pod "labelsupdatefdf8da64-4a09-4ce6-8de7-816f795aa4aa"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 11:30:28.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-254" for this suite. 11/29/22 11:30:28.458
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:28.462
Nov 29 11:30:28.462: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename deployment 11/29/22 11:30:28.463
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:28.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:28.475
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Nov 29 11:30:28.477: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 29 11:30:28.483: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 29 11:30:33.489: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/29/22 11:30:33.489
Nov 29 11:30:33.490: INFO: Creating deployment "test-rolling-update-deployment"
Nov 29 11:30:33.492: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 29 11:30:33.508: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 29 11:30:35.513: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 29 11:30:35.515: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 29 11:30:35.521: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5240  1f1c58bf-4f02-4663-9cc1-58ea574c18ae 6348 1 2022-11-29 11:30:33 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-29 11:30:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003510278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-29 11:30:33 +0000 UTC,LastTransitionTime:2022-11-29 11:30:33 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-29 11:30:34 +0000 UTC,LastTransitionTime:2022-11-29 11:30:33 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 29 11:30:35.523: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-5240  7f5851b0-9931-4063-a39d-85b2cddbed51 6338 1 2022-11-29 11:30:33 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 1f1c58bf-4f02-4663-9cc1-58ea574c18ae 0xc0034294b7 0xc0034294b8}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:30:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f1c58bf-4f02-4663-9cc1-58ea574c18ae\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034296d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 29 11:30:35.523: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 29 11:30:35.523: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5240  5595ff13-8074-4092-8635-ae046aba5073 6347 2 2022-11-29 11:30:28 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 1f1c58bf-4f02-4663-9cc1-58ea574c18ae 0xc0034292df 0xc003429310}] [] [{e2e.test Update apps/v1 2022-11-29 11:30:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f1c58bf-4f02-4663-9cc1-58ea574c18ae\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003429428 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 29 11:30:35.525: INFO: Pod "test-rolling-update-deployment-78f575d8ff-vsjv2" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-vsjv2 test-rolling-update-deployment-78f575d8ff- deployment-5240  027e13a0-5c6f-4ebf-9459-7fc0f66d3dc8 6337 0 2022-11-29 11:30:33 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:cd47fd401dd60cc48223528d11620b68b4b40785ac76ed552da028cc20317041 cni.projectcalico.org/podIP:100.96.2.21/32 cni.projectcalico.org/podIPs:100.96.2.21/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 7f5851b0-9931-4063-a39d-85b2cddbed51 0xc003429ee7 0xc003429ee8}] [] [{calico Update v1 2022-11-29 11:30:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 11:30:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7f5851b0-9931-4063-a39d-85b2cddbed51\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g8wz5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g8wz5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.21,StartTime:2022-11-29 11:30:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 11:30:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://93a368206d3eb5672090124cfc4f8379d15bd9eb0f2f846adf9615bb72fae18a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 29 11:30:35.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5240" for this suite. 11/29/22 11:30:35.528
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":19,"skipped":468,"failed":0}
------------------------------
• [SLOW TEST] [7.069 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:28.462
    Nov 29 11:30:28.462: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename deployment 11/29/22 11:30:28.463
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:28.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:28.475
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Nov 29 11:30:28.477: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Nov 29 11:30:28.483: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 29 11:30:33.489: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/29/22 11:30:33.489
    Nov 29 11:30:33.490: INFO: Creating deployment "test-rolling-update-deployment"
    Nov 29 11:30:33.492: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Nov 29 11:30:33.508: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Nov 29 11:30:35.513: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Nov 29 11:30:35.515: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 29 11:30:35.521: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5240  1f1c58bf-4f02-4663-9cc1-58ea574c18ae 6348 1 2022-11-29 11:30:33 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-29 11:30:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003510278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-29 11:30:33 +0000 UTC,LastTransitionTime:2022-11-29 11:30:33 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-29 11:30:34 +0000 UTC,LastTransitionTime:2022-11-29 11:30:33 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 29 11:30:35.523: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-5240  7f5851b0-9931-4063-a39d-85b2cddbed51 6338 1 2022-11-29 11:30:33 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 1f1c58bf-4f02-4663-9cc1-58ea574c18ae 0xc0034294b7 0xc0034294b8}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:30:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f1c58bf-4f02-4663-9cc1-58ea574c18ae\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034296d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 11:30:35.523: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Nov 29 11:30:35.523: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5240  5595ff13-8074-4092-8635-ae046aba5073 6347 2 2022-11-29 11:30:28 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 1f1c58bf-4f02-4663-9cc1-58ea574c18ae 0xc0034292df 0xc003429310}] [] [{e2e.test Update apps/v1 2022-11-29 11:30:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f1c58bf-4f02-4663-9cc1-58ea574c18ae\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003429428 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 11:30:35.525: INFO: Pod "test-rolling-update-deployment-78f575d8ff-vsjv2" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-vsjv2 test-rolling-update-deployment-78f575d8ff- deployment-5240  027e13a0-5c6f-4ebf-9459-7fc0f66d3dc8 6337 0 2022-11-29 11:30:33 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:cd47fd401dd60cc48223528d11620b68b4b40785ac76ed552da028cc20317041 cni.projectcalico.org/podIP:100.96.2.21/32 cni.projectcalico.org/podIPs:100.96.2.21/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 7f5851b0-9931-4063-a39d-85b2cddbed51 0xc003429ee7 0xc003429ee8}] [] [{calico Update v1 2022-11-29 11:30:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 11:30:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7f5851b0-9931-4063-a39d-85b2cddbed51\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 11:30:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g8wz5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g8wz5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:30:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.21,StartTime:2022-11-29 11:30:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 11:30:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://93a368206d3eb5672090124cfc4f8379d15bd9eb0f2f846adf9615bb72fae18a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 29 11:30:35.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5240" for this suite. 11/29/22 11:30:35.528
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:35.532
Nov 29 11:30:35.532: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename namespaces 11/29/22 11:30:35.533
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:35.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:35.543
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 11/29/22 11:30:35.545
STEP: patching the Namespace 11/29/22 11:30:35.553
STEP: get the Namespace and ensuring it has the label 11/29/22 11:30:35.557
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 29 11:30:35.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9786" for this suite. 11/29/22 11:30:35.563
STEP: Destroying namespace "nspatchtest-9cd0badc-2b97-4a33-a02a-213158ed6247-1085" for this suite. 11/29/22 11:30:35.566
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":20,"skipped":474,"failed":0}
------------------------------
• [0.037 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:35.532
    Nov 29 11:30:35.532: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename namespaces 11/29/22 11:30:35.533
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:35.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:35.543
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 11/29/22 11:30:35.545
    STEP: patching the Namespace 11/29/22 11:30:35.553
    STEP: get the Namespace and ensuring it has the label 11/29/22 11:30:35.557
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 11:30:35.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-9786" for this suite. 11/29/22 11:30:35.563
    STEP: Destroying namespace "nspatchtest-9cd0badc-2b97-4a33-a02a-213158ed6247-1085" for this suite. 11/29/22 11:30:35.566
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:35.57
Nov 29 11:30:35.570: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 11:30:35.571
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:35.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:35.581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 11:30:35.59
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 11:30:36.564
STEP: Deploying the webhook pod 11/29/22 11:30:36.568
STEP: Wait for the deployment to be ready 11/29/22 11:30:36.58
Nov 29 11:30:36.593: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 29 11:30:38.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:30:40.612: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:30:42.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:30:44.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:30:46.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/29/22 11:30:48.604
STEP: Verifying the service has paired with the endpoint 11/29/22 11:30:48.611
Nov 29 11:30:49.611: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/29/22 11:30:49.614
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/29/22 11:30:49.629
STEP: Creating a dummy validating-webhook-configuration object 11/29/22 11:30:49.639
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/29/22 11:30:49.852
STEP: Creating a dummy mutating-webhook-configuration object 11/29/22 11:30:49.856
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/29/22 11:30:49.863
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:30:49.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3401" for this suite. 11/29/22 11:30:49.88
STEP: Destroying namespace "webhook-3401-markers" for this suite. 11/29/22 11:30:49.888
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":21,"skipped":476,"failed":0}
------------------------------
• [SLOW TEST] [14.374 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:35.57
    Nov 29 11:30:35.570: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 11:30:35.571
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:35.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:35.581
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 11:30:35.59
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 11:30:36.564
    STEP: Deploying the webhook pod 11/29/22 11:30:36.568
    STEP: Wait for the deployment to be ready 11/29/22 11:30:36.58
    Nov 29 11:30:36.593: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 29 11:30:38.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:30:40.612: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:30:42.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:30:44.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:30:46.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 30, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/29/22 11:30:48.604
    STEP: Verifying the service has paired with the endpoint 11/29/22 11:30:48.611
    Nov 29 11:30:49.611: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/29/22 11:30:49.614
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/29/22 11:30:49.629
    STEP: Creating a dummy validating-webhook-configuration object 11/29/22 11:30:49.639
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/29/22 11:30:49.852
    STEP: Creating a dummy mutating-webhook-configuration object 11/29/22 11:30:49.856
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/29/22 11:30:49.863
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:30:49.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3401" for this suite. 11/29/22 11:30:49.88
    STEP: Destroying namespace "webhook-3401-markers" for this suite. 11/29/22 11:30:49.888
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:49.945
Nov 29 11:30:49.945: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename namespaces 11/29/22 11:30:49.947
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:49.956
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:49.959
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 11/29/22 11:30:49.963
Nov 29 11:30:49.966: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 11/29/22 11:30:49.966
Nov 29 11:30:49.970: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 11/29/22 11:30:49.97
Nov 29 11:30:49.976: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 29 11:30:49.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8483" for this suite. 11/29/22 11:30:49.979
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":22,"skipped":501,"failed":0}
------------------------------
• [0.037 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:49.945
    Nov 29 11:30:49.945: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename namespaces 11/29/22 11:30:49.947
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:49.956
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:49.959
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 11/29/22 11:30:49.963
    Nov 29 11:30:49.966: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 11/29/22 11:30:49.966
    Nov 29 11:30:49.970: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 11/29/22 11:30:49.97
    Nov 29 11:30:49.976: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 11:30:49.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8483" for this suite. 11/29/22 11:30:49.979
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:49.984
Nov 29 11:30:49.984: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename runtimeclass 11/29/22 11:30:49.985
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:49.992
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:49.994
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Nov 29 11:30:50.004: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-483 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 29 11:30:50.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-483" for this suite. 11/29/22 11:30:50.017
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":23,"skipped":509,"failed":0}
------------------------------
• [0.036 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:49.984
    Nov 29 11:30:49.984: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename runtimeclass 11/29/22 11:30:49.985
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:49.992
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:49.994
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Nov 29 11:30:50.004: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-483 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 29 11:30:50.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-483" for this suite. 11/29/22 11:30:50.017
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:30:50.022
Nov 29 11:30:50.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename statefulset 11/29/22 11:30:50.023
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:50.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:50.033
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1068 11/29/22 11:30:50.035
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-1068 11/29/22 11:30:50.041
Nov 29 11:30:50.049: INFO: Found 0 stateful pods, waiting for 1
Nov 29 11:31:00.053: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 11/29/22 11:31:00.056
STEP: Getting /status 11/29/22 11:31:00.062
Nov 29 11:31:00.066: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 11/29/22 11:31:00.066
Nov 29 11:31:00.071: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 11/29/22 11:31:00.071
Nov 29 11:31:00.072: INFO: Observed &StatefulSet event: ADDED
Nov 29 11:31:00.072: INFO: Found Statefulset ss in namespace statefulset-1068 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 29 11:31:00.072: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 11/29/22 11:31:00.072
Nov 29 11:31:00.073: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 29 11:31:00.076: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 11/29/22 11:31:00.076
Nov 29 11:31:00.078: INFO: Observed &StatefulSet event: ADDED
Nov 29 11:31:00.078: INFO: Observed Statefulset ss in namespace statefulset-1068 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 29 11:31:00.078: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 29 11:31:00.079: INFO: Deleting all statefulset in ns statefulset-1068
Nov 29 11:31:00.080: INFO: Scaling statefulset ss to 0
Nov 29 11:31:10.092: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 11:31:10.095: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 29 11:31:10.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1068" for this suite. 11/29/22 11:31:10.116
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":24,"skipped":523,"failed":0}
------------------------------
• [SLOW TEST] [20.097 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:30:50.022
    Nov 29 11:30:50.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename statefulset 11/29/22 11:30:50.023
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:30:50.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:30:50.033
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1068 11/29/22 11:30:50.035
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-1068 11/29/22 11:30:50.041
    Nov 29 11:30:50.049: INFO: Found 0 stateful pods, waiting for 1
    Nov 29 11:31:00.053: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 11/29/22 11:31:00.056
    STEP: Getting /status 11/29/22 11:31:00.062
    Nov 29 11:31:00.066: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 11/29/22 11:31:00.066
    Nov 29 11:31:00.071: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 11/29/22 11:31:00.071
    Nov 29 11:31:00.072: INFO: Observed &StatefulSet event: ADDED
    Nov 29 11:31:00.072: INFO: Found Statefulset ss in namespace statefulset-1068 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 29 11:31:00.072: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 11/29/22 11:31:00.072
    Nov 29 11:31:00.073: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 29 11:31:00.076: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 11/29/22 11:31:00.076
    Nov 29 11:31:00.078: INFO: Observed &StatefulSet event: ADDED
    Nov 29 11:31:00.078: INFO: Observed Statefulset ss in namespace statefulset-1068 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 29 11:31:00.078: INFO: Observed &StatefulSet event: MODIFIED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 29 11:31:00.079: INFO: Deleting all statefulset in ns statefulset-1068
    Nov 29 11:31:00.080: INFO: Scaling statefulset ss to 0
    Nov 29 11:31:10.092: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 11:31:10.095: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 29 11:31:10.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1068" for this suite. 11/29/22 11:31:10.116
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:31:10.119
Nov 29 11:31:10.119: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename statefulset 11/29/22 11:31:10.12
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:31:10.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:31:10.136
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3706 11/29/22 11:31:10.138
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 11/29/22 11:31:10.142
Nov 29 11:31:10.149: INFO: Found 0 stateful pods, waiting for 3
Nov 29 11:31:20.154: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:31:20.154: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:31:20.154: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 29 11:31:30.153: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:31:30.154: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:31:30.154: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/29/22 11:31:30.16
Nov 29 11:31:30.177: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/29/22 11:31:30.177
STEP: Not applying an update when the partition is greater than the number of replicas 11/29/22 11:31:40.187
STEP: Performing a canary update 11/29/22 11:31:40.187
Nov 29 11:31:40.204: INFO: Updating stateful set ss2
Nov 29 11:31:40.209: INFO: Waiting for Pod statefulset-3706/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 11/29/22 11:31:50.218
Nov 29 11:31:50.349: INFO: Found 2 stateful pods, waiting for 3
Nov 29 11:32:00.356: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:32:00.356: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:32:00.356: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 11/29/22 11:32:00.361
Nov 29 11:32:00.379: INFO: Updating stateful set ss2
Nov 29 11:32:00.392: INFO: Waiting for Pod statefulset-3706/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Nov 29 11:32:10.418: INFO: Updating stateful set ss2
Nov 29 11:32:10.447: INFO: Waiting for StatefulSet statefulset-3706/ss2 to complete update
Nov 29 11:32:10.447: INFO: Waiting for Pod statefulset-3706/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Nov 29 11:32:20.454: INFO: Waiting for StatefulSet statefulset-3706/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 29 11:32:30.459: INFO: Deleting all statefulset in ns statefulset-3706
Nov 29 11:32:30.462: INFO: Scaling statefulset ss2 to 0
Nov 29 11:32:40.475: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 11:32:40.477: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 29 11:32:40.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3706" for this suite. 11/29/22 11:32:40.489
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":25,"skipped":528,"failed":0}
------------------------------
• [SLOW TEST] [90.373 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:31:10.119
    Nov 29 11:31:10.119: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename statefulset 11/29/22 11:31:10.12
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:31:10.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:31:10.136
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3706 11/29/22 11:31:10.138
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 11/29/22 11:31:10.142
    Nov 29 11:31:10.149: INFO: Found 0 stateful pods, waiting for 3
    Nov 29 11:31:20.154: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:31:20.154: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:31:20.154: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
    Nov 29 11:31:30.153: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:31:30.154: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:31:30.154: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/29/22 11:31:30.16
    Nov 29 11:31:30.177: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/29/22 11:31:30.177
    STEP: Not applying an update when the partition is greater than the number of replicas 11/29/22 11:31:40.187
    STEP: Performing a canary update 11/29/22 11:31:40.187
    Nov 29 11:31:40.204: INFO: Updating stateful set ss2
    Nov 29 11:31:40.209: INFO: Waiting for Pod statefulset-3706/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 11/29/22 11:31:50.218
    Nov 29 11:31:50.349: INFO: Found 2 stateful pods, waiting for 3
    Nov 29 11:32:00.356: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:32:00.356: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:32:00.356: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 11/29/22 11:32:00.361
    Nov 29 11:32:00.379: INFO: Updating stateful set ss2
    Nov 29 11:32:00.392: INFO: Waiting for Pod statefulset-3706/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Nov 29 11:32:10.418: INFO: Updating stateful set ss2
    Nov 29 11:32:10.447: INFO: Waiting for StatefulSet statefulset-3706/ss2 to complete update
    Nov 29 11:32:10.447: INFO: Waiting for Pod statefulset-3706/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Nov 29 11:32:20.454: INFO: Waiting for StatefulSet statefulset-3706/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 29 11:32:30.459: INFO: Deleting all statefulset in ns statefulset-3706
    Nov 29 11:32:30.462: INFO: Scaling statefulset ss2 to 0
    Nov 29 11:32:40.475: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 11:32:40.477: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 29 11:32:40.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3706" for this suite. 11/29/22 11:32:40.489
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:32:40.495
Nov 29 11:32:40.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 11:32:40.496
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:40.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:40.517
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Nov 29 11:32:40.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/29/22 11:32:42.838
Nov 29 11:32:42.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 create -f -'
Nov 29 11:32:43.796: INFO: stderr: ""
Nov 29 11:32:43.796: INFO: stdout: "e2e-test-crd-publish-openapi-9933-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 29 11:32:43.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 delete e2e-test-crd-publish-openapi-9933-crds test-foo'
Nov 29 11:32:43.875: INFO: stderr: ""
Nov 29 11:32:43.875: INFO: stdout: "e2e-test-crd-publish-openapi-9933-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov 29 11:32:43.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 apply -f -'
Nov 29 11:32:44.156: INFO: stderr: ""
Nov 29 11:32:44.156: INFO: stdout: "e2e-test-crd-publish-openapi-9933-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 29 11:32:44.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 delete e2e-test-crd-publish-openapi-9933-crds test-foo'
Nov 29 11:32:44.232: INFO: stderr: ""
Nov 29 11:32:44.232: INFO: stdout: "e2e-test-crd-publish-openapi-9933-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/29/22 11:32:44.232
Nov 29 11:32:44.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 create -f -'
Nov 29 11:32:44.495: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/29/22 11:32:44.495
Nov 29 11:32:44.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 create -f -'
Nov 29 11:32:44.810: INFO: rc: 1
Nov 29 11:32:44.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 apply -f -'
Nov 29 11:32:45.236: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/29/22 11:32:45.236
Nov 29 11:32:45.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 create -f -'
Nov 29 11:32:45.496: INFO: rc: 1
Nov 29 11:32:45.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 apply -f -'
Nov 29 11:32:45.786: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 11/29/22 11:32:45.786
Nov 29 11:32:45.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds'
Nov 29 11:32:46.056: INFO: stderr: ""
Nov 29 11:32:46.056: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9933-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 11/29/22 11:32:46.056
Nov 29 11:32:46.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds.metadata'
Nov 29 11:32:46.350: INFO: stderr: ""
Nov 29 11:32:46.350: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9933-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov 29 11:32:46.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds.spec'
Nov 29 11:32:46.594: INFO: stderr: ""
Nov 29 11:32:46.594: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9933-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov 29 11:32:46.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds.spec.bars'
Nov 29 11:32:46.854: INFO: stderr: ""
Nov 29 11:32:46.854: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9933-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/29/22 11:32:46.855
Nov 29 11:32:46.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds.spec.bars2'
Nov 29 11:32:47.140: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:32:49.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9627" for this suite. 11/29/22 11:32:49.602
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":26,"skipped":588,"failed":0}
------------------------------
• [SLOW TEST] [9.110 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:32:40.495
    Nov 29 11:32:40.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 11:32:40.496
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:40.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:40.517
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Nov 29 11:32:40.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/29/22 11:32:42.838
    Nov 29 11:32:42.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 create -f -'
    Nov 29 11:32:43.796: INFO: stderr: ""
    Nov 29 11:32:43.796: INFO: stdout: "e2e-test-crd-publish-openapi-9933-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov 29 11:32:43.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 delete e2e-test-crd-publish-openapi-9933-crds test-foo'
    Nov 29 11:32:43.875: INFO: stderr: ""
    Nov 29 11:32:43.875: INFO: stdout: "e2e-test-crd-publish-openapi-9933-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Nov 29 11:32:43.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 apply -f -'
    Nov 29 11:32:44.156: INFO: stderr: ""
    Nov 29 11:32:44.156: INFO: stdout: "e2e-test-crd-publish-openapi-9933-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov 29 11:32:44.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 delete e2e-test-crd-publish-openapi-9933-crds test-foo'
    Nov 29 11:32:44.232: INFO: stderr: ""
    Nov 29 11:32:44.232: INFO: stdout: "e2e-test-crd-publish-openapi-9933-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/29/22 11:32:44.232
    Nov 29 11:32:44.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 create -f -'
    Nov 29 11:32:44.495: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/29/22 11:32:44.495
    Nov 29 11:32:44.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 create -f -'
    Nov 29 11:32:44.810: INFO: rc: 1
    Nov 29 11:32:44.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 apply -f -'
    Nov 29 11:32:45.236: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/29/22 11:32:45.236
    Nov 29 11:32:45.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 create -f -'
    Nov 29 11:32:45.496: INFO: rc: 1
    Nov 29 11:32:45.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 --namespace=crd-publish-openapi-9627 apply -f -'
    Nov 29 11:32:45.786: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 11/29/22 11:32:45.786
    Nov 29 11:32:45.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds'
    Nov 29 11:32:46.056: INFO: stderr: ""
    Nov 29 11:32:46.056: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9933-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 11/29/22 11:32:46.056
    Nov 29 11:32:46.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds.metadata'
    Nov 29 11:32:46.350: INFO: stderr: ""
    Nov 29 11:32:46.350: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9933-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Nov 29 11:32:46.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds.spec'
    Nov 29 11:32:46.594: INFO: stderr: ""
    Nov 29 11:32:46.594: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9933-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Nov 29 11:32:46.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds.spec.bars'
    Nov 29 11:32:46.854: INFO: stderr: ""
    Nov 29 11:32:46.854: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9933-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/29/22 11:32:46.855
    Nov 29 11:32:46.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-9627 explain e2e-test-crd-publish-openapi-9933-crds.spec.bars2'
    Nov 29 11:32:47.140: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:32:49.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9627" for this suite. 11/29/22 11:32:49.602
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:32:49.605
Nov 29 11:32:49.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 11:32:49.607
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:49.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:49.617
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/29/22 11:32:49.619
Nov 29 11:32:49.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4535 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov 29 11:32:49.686: INFO: stderr: ""
Nov 29 11:32:49.686: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 11/29/22 11:32:49.686
STEP: verifying the pod e2e-test-httpd-pod was created 11/29/22 11:32:54.737
Nov 29 11:32:54.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4535 get pod e2e-test-httpd-pod -o json'
Nov 29 11:32:54.808: INFO: stderr: ""
Nov 29 11:32:54.808: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"d40ac24c316c07e3cf33b0503e79ff73925ae84c7518febfd875ed4b9d979dcb\",\n            \"cni.projectcalico.org/podIP\": \"100.96.2.25/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.96.2.25/32\"\n        },\n        \"creationTimestamp\": \"2022-11-29T11:32:49Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4535\",\n        \"resourceVersion\": \"7159\",\n        \"uid\": \"94f38647-a080-4a7a-a418-79611a89ffb6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-kgj5l\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"dvi-7336-1669718118-vsp1-group1-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-kgj5l\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-29T11:32:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-29T11:32:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-29T11:32:50Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-29T11:32:49Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://e6cbc788a962de41f14091507527bfb765ab3ec481ff4f8f62dbcb9756253f67\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-29T11:32:50Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.8.22\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.2.25\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.96.2.25\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-29T11:32:49Z\"\n    }\n}\n"
STEP: replace the image in the pod 11/29/22 11:32:54.808
Nov 29 11:32:54.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4535 replace -f -'
Nov 29 11:32:55.597: INFO: stderr: ""
Nov 29 11:32:55.597: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/29/22 11:32:55.597
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Nov 29 11:32:55.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4535 delete pods e2e-test-httpd-pod'
Nov 29 11:32:57.797: INFO: stderr: ""
Nov 29 11:32:57.797: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 11:32:57.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4535" for this suite. 11/29/22 11:32:57.8
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":27,"skipped":595,"failed":0}
------------------------------
• [SLOW TEST] [8.198 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:32:49.605
    Nov 29 11:32:49.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 11:32:49.607
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:49.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:49.617
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/29/22 11:32:49.619
    Nov 29 11:32:49.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4535 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov 29 11:32:49.686: INFO: stderr: ""
    Nov 29 11:32:49.686: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 11/29/22 11:32:49.686
    STEP: verifying the pod e2e-test-httpd-pod was created 11/29/22 11:32:54.737
    Nov 29 11:32:54.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4535 get pod e2e-test-httpd-pod -o json'
    Nov 29 11:32:54.808: INFO: stderr: ""
    Nov 29 11:32:54.808: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"d40ac24c316c07e3cf33b0503e79ff73925ae84c7518febfd875ed4b9d979dcb\",\n            \"cni.projectcalico.org/podIP\": \"100.96.2.25/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.96.2.25/32\"\n        },\n        \"creationTimestamp\": \"2022-11-29T11:32:49Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4535\",\n        \"resourceVersion\": \"7159\",\n        \"uid\": \"94f38647-a080-4a7a-a418-79611a89ffb6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-kgj5l\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"dvi-7336-1669718118-vsp1-group1-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-kgj5l\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-29T11:32:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-29T11:32:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-29T11:32:50Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-29T11:32:49Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://e6cbc788a962de41f14091507527bfb765ab3ec481ff4f8f62dbcb9756253f67\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-29T11:32:50Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.8.22\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.2.25\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.96.2.25\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-29T11:32:49Z\"\n    }\n}\n"
    STEP: replace the image in the pod 11/29/22 11:32:54.808
    Nov 29 11:32:54.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4535 replace -f -'
    Nov 29 11:32:55.597: INFO: stderr: ""
    Nov 29 11:32:55.597: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/29/22 11:32:55.597
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Nov 29 11:32:55.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4535 delete pods e2e-test-httpd-pod'
    Nov 29 11:32:57.797: INFO: stderr: ""
    Nov 29 11:32:57.797: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 11:32:57.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4535" for this suite. 11/29/22 11:32:57.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:32:57.805
Nov 29 11:32:57.805: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename podtemplate 11/29/22 11:32:57.805
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:57.813
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:57.815
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 29 11:32:57.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-3077" for this suite. 11/29/22 11:32:57.854
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":28,"skipped":604,"failed":0}
------------------------------
• [0.053 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:32:57.805
    Nov 29 11:32:57.805: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename podtemplate 11/29/22 11:32:57.805
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:57.813
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:57.815
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 29 11:32:57.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-3077" for this suite. 11/29/22 11:32:57.854
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:32:57.858
Nov 29 11:32:57.858: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 11:32:57.859
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:57.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:57.873
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 11/29/22 11:32:57.876
STEP: waiting for available Endpoint 11/29/22 11:32:57.878
STEP: listing all Endpoints 11/29/22 11:32:57.88
STEP: updating the Endpoint 11/29/22 11:32:57.882
STEP: fetching the Endpoint 11/29/22 11:32:57.885
STEP: patching the Endpoint 11/29/22 11:32:57.887
STEP: fetching the Endpoint 11/29/22 11:32:57.892
STEP: deleting the Endpoint by Collection 11/29/22 11:32:57.894
STEP: waiting for Endpoint deletion 11/29/22 11:32:57.897
STEP: fetching the Endpoint 11/29/22 11:32:57.898
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 11:32:57.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-661" for this suite. 11/29/22 11:32:57.903
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":29,"skipped":632,"failed":0}
------------------------------
• [0.048 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:32:57.858
    Nov 29 11:32:57.858: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 11:32:57.859
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:57.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:57.873
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 11/29/22 11:32:57.876
    STEP: waiting for available Endpoint 11/29/22 11:32:57.878
    STEP: listing all Endpoints 11/29/22 11:32:57.88
    STEP: updating the Endpoint 11/29/22 11:32:57.882
    STEP: fetching the Endpoint 11/29/22 11:32:57.885
    STEP: patching the Endpoint 11/29/22 11:32:57.887
    STEP: fetching the Endpoint 11/29/22 11:32:57.892
    STEP: deleting the Endpoint by Collection 11/29/22 11:32:57.894
    STEP: waiting for Endpoint deletion 11/29/22 11:32:57.897
    STEP: fetching the Endpoint 11/29/22 11:32:57.898
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 11:32:57.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-661" for this suite. 11/29/22 11:32:57.903
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:32:57.91
Nov 29 11:32:57.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 11:32:57.911
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:57.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:57.928
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/29/22 11:32:57.931
Nov 29 11:32:57.938: INFO: Waiting up to 5m0s for pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c" in namespace "emptydir-9216" to be "Succeeded or Failed"
Nov 29 11:32:57.942: INFO: Pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.054494ms
Nov 29 11:32:59.945: INFO: Pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c": Phase="Running", Reason="", readiness=false. Elapsed: 2.006761183s
Nov 29 11:33:01.947: INFO: Pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008605666s
STEP: Saw pod success 11/29/22 11:33:01.947
Nov 29 11:33:01.947: INFO: Pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c" satisfied condition "Succeeded or Failed"
Nov 29 11:33:01.950: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-07210de6-90b1-4a46-8362-0ca3e16b657c container test-container: <nil>
STEP: delete the pod 11/29/22 11:33:01.956
Nov 29 11:33:01.962: INFO: Waiting for pod pod-07210de6-90b1-4a46-8362-0ca3e16b657c to disappear
Nov 29 11:33:01.964: INFO: Pod pod-07210de6-90b1-4a46-8362-0ca3e16b657c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 11:33:01.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9216" for this suite. 11/29/22 11:33:01.967
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":30,"skipped":665,"failed":0}
------------------------------
• [4.060 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:32:57.91
    Nov 29 11:32:57.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 11:32:57.911
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:32:57.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:32:57.928
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/29/22 11:32:57.931
    Nov 29 11:32:57.938: INFO: Waiting up to 5m0s for pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c" in namespace "emptydir-9216" to be "Succeeded or Failed"
    Nov 29 11:32:57.942: INFO: Pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.054494ms
    Nov 29 11:32:59.945: INFO: Pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c": Phase="Running", Reason="", readiness=false. Elapsed: 2.006761183s
    Nov 29 11:33:01.947: INFO: Pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008605666s
    STEP: Saw pod success 11/29/22 11:33:01.947
    Nov 29 11:33:01.947: INFO: Pod "pod-07210de6-90b1-4a46-8362-0ca3e16b657c" satisfied condition "Succeeded or Failed"
    Nov 29 11:33:01.950: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-07210de6-90b1-4a46-8362-0ca3e16b657c container test-container: <nil>
    STEP: delete the pod 11/29/22 11:33:01.956
    Nov 29 11:33:01.962: INFO: Waiting for pod pod-07210de6-90b1-4a46-8362-0ca3e16b657c to disappear
    Nov 29 11:33:01.964: INFO: Pod pod-07210de6-90b1-4a46-8362-0ca3e16b657c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 11:33:01.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9216" for this suite. 11/29/22 11:33:01.967
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:33:01.97
Nov 29 11:33:01.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 11:33:01.971
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:01.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:01.98
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-5253 11/29/22 11:33:01.982
STEP: creating service affinity-clusterip-transition in namespace services-5253 11/29/22 11:33:01.982
STEP: creating replication controller affinity-clusterip-transition in namespace services-5253 11/29/22 11:33:01.987
I1129 11:33:01.992543      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-5253, replica count: 3
I1129 11:33:05.043080      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 11:33:08.043855      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 11:33:11.045960      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 11:33:14.046147      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 11:33:14.052: INFO: Creating new exec pod
Nov 29 11:33:14.057: INFO: Waiting up to 5m0s for pod "execpod-affinityzjrqf" in namespace "services-5253" to be "running"
Nov 29 11:33:14.059: INFO: Pod "execpod-affinityzjrqf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037389ms
Nov 29 11:33:16.064: INFO: Pod "execpod-affinityzjrqf": Phase="Running", Reason="", readiness=true. Elapsed: 2.006523199s
Nov 29 11:33:16.064: INFO: Pod "execpod-affinityzjrqf" satisfied condition "running"
Nov 29 11:33:17.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Nov 29 11:33:17.196: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Nov 29 11:33:17.196: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:33:17.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.71.140.169 80'
Nov 29 11:33:17.313: INFO: stderr: "+ nc -v -t -w 2 100.71.140.169 80\n+ echo hostName\nConnection to 100.71.140.169 80 port [tcp/http] succeeded!\n"
Nov 29 11:33:17.314: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:33:17.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.71.140.169:80/ ; done'
Nov 29 11:33:17.503: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n"
Nov 29 11:33:17.503: INFO: stdout: "\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8"
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.71.140.169:80/ ; done'
Nov 29 11:33:47.704: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n"
Nov 29 11:33:47.704: INFO: stdout: "\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-w6z89\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-w6z89\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-w6z89\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-7l295"
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-w6z89
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-w6z89
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-w6z89
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
Nov 29 11:33:47.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.71.140.169:80/ ; done'
Nov 29 11:33:47.914: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n"
Nov 29 11:33:47.914: INFO: stdout: "\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8"
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
Nov 29 11:33:47.914: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-5253, will wait for the garbage collector to delete the pods 11/29/22 11:33:47.922
Nov 29 11:33:47.979: INFO: Deleting ReplicationController affinity-clusterip-transition took: 4.001918ms
Nov 29 11:33:48.080: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.372763ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 11:33:50.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5253" for this suite. 11/29/22 11:33:50.494
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":31,"skipped":672,"failed":0}
------------------------------
• [SLOW TEST] [48.526 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:33:01.97
    Nov 29 11:33:01.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 11:33:01.971
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:01.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:01.98
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-5253 11/29/22 11:33:01.982
    STEP: creating service affinity-clusterip-transition in namespace services-5253 11/29/22 11:33:01.982
    STEP: creating replication controller affinity-clusterip-transition in namespace services-5253 11/29/22 11:33:01.987
    I1129 11:33:01.992543      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-5253, replica count: 3
    I1129 11:33:05.043080      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 11:33:08.043855      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 11:33:11.045960      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 11:33:14.046147      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 11:33:14.052: INFO: Creating new exec pod
    Nov 29 11:33:14.057: INFO: Waiting up to 5m0s for pod "execpod-affinityzjrqf" in namespace "services-5253" to be "running"
    Nov 29 11:33:14.059: INFO: Pod "execpod-affinityzjrqf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037389ms
    Nov 29 11:33:16.064: INFO: Pod "execpod-affinityzjrqf": Phase="Running", Reason="", readiness=true. Elapsed: 2.006523199s
    Nov 29 11:33:16.064: INFO: Pod "execpod-affinityzjrqf" satisfied condition "running"
    Nov 29 11:33:17.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Nov 29 11:33:17.196: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Nov 29 11:33:17.196: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:33:17.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.71.140.169 80'
    Nov 29 11:33:17.313: INFO: stderr: "+ nc -v -t -w 2 100.71.140.169 80\n+ echo hostName\nConnection to 100.71.140.169 80 port [tcp/http] succeeded!\n"
    Nov 29 11:33:17.314: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:33:17.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.71.140.169:80/ ; done'
    Nov 29 11:33:17.503: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n"
    Nov 29 11:33:17.503: INFO: stdout: "\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8"
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:17.503: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.71.140.169:80/ ; done'
    Nov 29 11:33:47.704: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n"
    Nov 29 11:33:47.704: INFO: stdout: "\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-w6z89\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-w6z89\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-w6z89\naffinity-clusterip-transition-7l295\naffinity-clusterip-transition-7l295"
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-w6z89
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-w6z89
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-w6z89
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.704: INFO: Received response from host: affinity-clusterip-transition-7l295
    Nov 29 11:33:47.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5253 exec execpod-affinityzjrqf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.71.140.169:80/ ; done'
    Nov 29 11:33:47.914: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.140.169:80/\n"
    Nov 29 11:33:47.914: INFO: stdout: "\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8\naffinity-clusterip-transition-t4sr8"
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Received response from host: affinity-clusterip-transition-t4sr8
    Nov 29 11:33:47.914: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-5253, will wait for the garbage collector to delete the pods 11/29/22 11:33:47.922
    Nov 29 11:33:47.979: INFO: Deleting ReplicationController affinity-clusterip-transition took: 4.001918ms
    Nov 29 11:33:48.080: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.372763ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 11:33:50.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5253" for this suite. 11/29/22 11:33:50.494
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:33:50.497
Nov 29 11:33:50.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:33:50.498
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:50.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:50.508
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 11/29/22 11:33:50.51
Nov 29 11:33:50.514: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9" in namespace "projected-8298" to be "Succeeded or Failed"
Nov 29 11:33:50.518: INFO: Pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.511012ms
Nov 29 11:33:52.521: INFO: Pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006921002s
Nov 29 11:33:54.522: INFO: Pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007651642s
STEP: Saw pod success 11/29/22 11:33:54.522
Nov 29 11:33:54.522: INFO: Pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9" satisfied condition "Succeeded or Failed"
Nov 29 11:33:54.524: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9 container client-container: <nil>
STEP: delete the pod 11/29/22 11:33:54.527
Nov 29 11:33:54.533: INFO: Waiting for pod downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9 to disappear
Nov 29 11:33:54.535: INFO: Pod downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 11:33:54.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8298" for this suite. 11/29/22 11:33:54.538
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":32,"skipped":674,"failed":0}
------------------------------
• [4.049 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:33:50.497
    Nov 29 11:33:50.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:33:50.498
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:50.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:50.508
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 11/29/22 11:33:50.51
    Nov 29 11:33:50.514: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9" in namespace "projected-8298" to be "Succeeded or Failed"
    Nov 29 11:33:50.518: INFO: Pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.511012ms
    Nov 29 11:33:52.521: INFO: Pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006921002s
    Nov 29 11:33:54.522: INFO: Pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007651642s
    STEP: Saw pod success 11/29/22 11:33:54.522
    Nov 29 11:33:54.522: INFO: Pod "downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9" satisfied condition "Succeeded or Failed"
    Nov 29 11:33:54.524: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9 container client-container: <nil>
    STEP: delete the pod 11/29/22 11:33:54.527
    Nov 29 11:33:54.533: INFO: Waiting for pod downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9 to disappear
    Nov 29 11:33:54.535: INFO: Pod downwardapi-volume-c44a22e3-3f05-43c0-bbe8-b1e55fa7a1e9 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 11:33:54.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8298" for this suite. 11/29/22 11:33:54.538
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:33:54.547
Nov 29 11:33:54.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:33:54.548
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:54.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:54.558
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Nov 29 11:33:54.567: INFO: Waiting up to 5m0s for pod "pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4" in namespace "svcaccounts-4768" to be "running"
Nov 29 11:33:54.570: INFO: Pod "pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.634506ms
Nov 29 11:33:56.574: INFO: Pod "pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006827875s
Nov 29 11:33:56.574: INFO: Pod "pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4" satisfied condition "running"
STEP: reading a file in the container 11/29/22 11:33:56.574
Nov 29 11:33:56.574: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4768 pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 11/29/22 11:33:56.693
Nov 29 11:33:56.693: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4768 pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 11/29/22 11:33:56.818
Nov 29 11:33:56.819: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4768 pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Nov 29 11:33:56.936: INFO: Got root ca configmap in namespace "svcaccounts-4768"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 29 11:33:56.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4768" for this suite. 11/29/22 11:33:56.942
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":33,"skipped":685,"failed":0}
------------------------------
• [2.399 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:33:54.547
    Nov 29 11:33:54.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:33:54.548
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:54.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:54.558
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Nov 29 11:33:54.567: INFO: Waiting up to 5m0s for pod "pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4" in namespace "svcaccounts-4768" to be "running"
    Nov 29 11:33:54.570: INFO: Pod "pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.634506ms
    Nov 29 11:33:56.574: INFO: Pod "pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006827875s
    Nov 29 11:33:56.574: INFO: Pod "pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4" satisfied condition "running"
    STEP: reading a file in the container 11/29/22 11:33:56.574
    Nov 29 11:33:56.574: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4768 pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 11/29/22 11:33:56.693
    Nov 29 11:33:56.693: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4768 pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 11/29/22 11:33:56.818
    Nov 29 11:33:56.819: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4768 pod-service-account-a24c3e1e-b08b-4248-8e5d-8dfe23ffd6b4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Nov 29 11:33:56.936: INFO: Got root ca configmap in namespace "svcaccounts-4768"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 29 11:33:56.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4768" for this suite. 11/29/22 11:33:56.942
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:33:56.948
Nov 29 11:33:56.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 11:33:56.949
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:56.957
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:56.959
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-10c8bc35-9194-4d04-b8cb-41a2969c8baa 11/29/22 11:33:56.961
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 29 11:33:56.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4467" for this suite. 11/29/22 11:33:56.966
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":34,"skipped":716,"failed":0}
------------------------------
• [0.024 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:33:56.948
    Nov 29 11:33:56.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 11:33:56.949
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:56.957
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:56.959
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-10c8bc35-9194-4d04-b8cb-41a2969c8baa 11/29/22 11:33:56.961
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 11:33:56.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4467" for this suite. 11/29/22 11:33:56.966
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:33:56.974
Nov 29 11:33:56.974: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename statefulset 11/29/22 11:33:56.975
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:56.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:56.986
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4849 11/29/22 11:33:56.988
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Nov 29 11:33:57.000: INFO: Found 0 stateful pods, waiting for 1
Nov 29 11:34:07.005: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 11/29/22 11:34:07.009
W1129 11:34:07.013069      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 29 11:34:07.016: INFO: Found 1 stateful pods, waiting for 2
Nov 29 11:34:17.020: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:34:17.020: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 11/29/22 11:34:17.024
STEP: Delete all of the StatefulSets 11/29/22 11:34:17.026
STEP: Verify that StatefulSets have been deleted 11/29/22 11:34:17.03
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 29 11:34:17.042: INFO: Deleting all statefulset in ns statefulset-4849
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 29 11:34:17.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4849" for this suite. 11/29/22 11:34:17.057
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":35,"skipped":758,"failed":0}
------------------------------
• [SLOW TEST] [20.087 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:33:56.974
    Nov 29 11:33:56.974: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename statefulset 11/29/22 11:33:56.975
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:33:56.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:33:56.986
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4849 11/29/22 11:33:56.988
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Nov 29 11:33:57.000: INFO: Found 0 stateful pods, waiting for 1
    Nov 29 11:34:07.005: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 11/29/22 11:34:07.009
    W1129 11:34:07.013069      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 29 11:34:07.016: INFO: Found 1 stateful pods, waiting for 2
    Nov 29 11:34:17.020: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:34:17.020: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 11/29/22 11:34:17.024
    STEP: Delete all of the StatefulSets 11/29/22 11:34:17.026
    STEP: Verify that StatefulSets have been deleted 11/29/22 11:34:17.03
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 29 11:34:17.042: INFO: Deleting all statefulset in ns statefulset-4849
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 29 11:34:17.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4849" for this suite. 11/29/22 11:34:17.057
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:34:17.062
Nov 29 11:34:17.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 11:34:17.063
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:34:17.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:34:17.074
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 11/29/22 11:34:17.077
Nov 29 11:34:17.082: INFO: Waiting up to 5m0s for pod "pod-68810ed1-9b34-450e-be1f-409efdd49716" in namespace "emptydir-2726" to be "Succeeded or Failed"
Nov 29 11:34:17.146: INFO: Pod "pod-68810ed1-9b34-450e-be1f-409efdd49716": Phase="Pending", Reason="", readiness=false. Elapsed: 64.220945ms
Nov 29 11:34:19.154: INFO: Pod "pod-68810ed1-9b34-450e-be1f-409efdd49716": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071776662s
Nov 29 11:34:21.150: INFO: Pod "pod-68810ed1-9b34-450e-be1f-409efdd49716": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06823382s
STEP: Saw pod success 11/29/22 11:34:21.15
Nov 29 11:34:21.150: INFO: Pod "pod-68810ed1-9b34-450e-be1f-409efdd49716" satisfied condition "Succeeded or Failed"
Nov 29 11:34:21.152: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-1 pod pod-68810ed1-9b34-450e-be1f-409efdd49716 container test-container: <nil>
STEP: delete the pod 11/29/22 11:34:21.158
Nov 29 11:34:21.163: INFO: Waiting for pod pod-68810ed1-9b34-450e-be1f-409efdd49716 to disappear
Nov 29 11:34:21.165: INFO: Pod pod-68810ed1-9b34-450e-be1f-409efdd49716 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 11:34:21.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2726" for this suite. 11/29/22 11:34:21.168
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":36,"skipped":763,"failed":0}
------------------------------
• [4.109 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:34:17.062
    Nov 29 11:34:17.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 11:34:17.063
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:34:17.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:34:17.074
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/29/22 11:34:17.077
    Nov 29 11:34:17.082: INFO: Waiting up to 5m0s for pod "pod-68810ed1-9b34-450e-be1f-409efdd49716" in namespace "emptydir-2726" to be "Succeeded or Failed"
    Nov 29 11:34:17.146: INFO: Pod "pod-68810ed1-9b34-450e-be1f-409efdd49716": Phase="Pending", Reason="", readiness=false. Elapsed: 64.220945ms
    Nov 29 11:34:19.154: INFO: Pod "pod-68810ed1-9b34-450e-be1f-409efdd49716": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071776662s
    Nov 29 11:34:21.150: INFO: Pod "pod-68810ed1-9b34-450e-be1f-409efdd49716": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06823382s
    STEP: Saw pod success 11/29/22 11:34:21.15
    Nov 29 11:34:21.150: INFO: Pod "pod-68810ed1-9b34-450e-be1f-409efdd49716" satisfied condition "Succeeded or Failed"
    Nov 29 11:34:21.152: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-1 pod pod-68810ed1-9b34-450e-be1f-409efdd49716 container test-container: <nil>
    STEP: delete the pod 11/29/22 11:34:21.158
    Nov 29 11:34:21.163: INFO: Waiting for pod pod-68810ed1-9b34-450e-be1f-409efdd49716 to disappear
    Nov 29 11:34:21.165: INFO: Pod pod-68810ed1-9b34-450e-be1f-409efdd49716 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 11:34:21.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2726" for this suite. 11/29/22 11:34:21.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:34:21.173
Nov 29 11:34:21.173: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename certificates 11/29/22 11:34:21.174
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:34:21.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:34:21.185
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 11/29/22 11:34:22.057
STEP: getting /apis/certificates.k8s.io 11/29/22 11:34:22.059
STEP: getting /apis/certificates.k8s.io/v1 11/29/22 11:34:22.06
STEP: creating 11/29/22 11:34:22.061
STEP: getting 11/29/22 11:34:22.07
STEP: listing 11/29/22 11:34:22.072
STEP: watching 11/29/22 11:34:22.074
Nov 29 11:34:22.074: INFO: starting watch
STEP: patching 11/29/22 11:34:22.074
STEP: updating 11/29/22 11:34:22.079
Nov 29 11:34:22.082: INFO: waiting for watch events with expected annotations
Nov 29 11:34:22.082: INFO: saw patched and updated annotations
STEP: getting /approval 11/29/22 11:34:22.082
STEP: patching /approval 11/29/22 11:34:22.085
STEP: updating /approval 11/29/22 11:34:22.089
STEP: getting /status 11/29/22 11:34:22.093
STEP: patching /status 11/29/22 11:34:22.098
STEP: updating /status 11/29/22 11:34:22.102
STEP: deleting 11/29/22 11:34:22.106
STEP: deleting a collection 11/29/22 11:34:22.116
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:34:22.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-4860" for this suite. 11/29/22 11:34:22.128
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":37,"skipped":780,"failed":0}
------------------------------
• [0.958 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:34:21.173
    Nov 29 11:34:21.173: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename certificates 11/29/22 11:34:21.174
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:34:21.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:34:21.185
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 11/29/22 11:34:22.057
    STEP: getting /apis/certificates.k8s.io 11/29/22 11:34:22.059
    STEP: getting /apis/certificates.k8s.io/v1 11/29/22 11:34:22.06
    STEP: creating 11/29/22 11:34:22.061
    STEP: getting 11/29/22 11:34:22.07
    STEP: listing 11/29/22 11:34:22.072
    STEP: watching 11/29/22 11:34:22.074
    Nov 29 11:34:22.074: INFO: starting watch
    STEP: patching 11/29/22 11:34:22.074
    STEP: updating 11/29/22 11:34:22.079
    Nov 29 11:34:22.082: INFO: waiting for watch events with expected annotations
    Nov 29 11:34:22.082: INFO: saw patched and updated annotations
    STEP: getting /approval 11/29/22 11:34:22.082
    STEP: patching /approval 11/29/22 11:34:22.085
    STEP: updating /approval 11/29/22 11:34:22.089
    STEP: getting /status 11/29/22 11:34:22.093
    STEP: patching /status 11/29/22 11:34:22.098
    STEP: updating /status 11/29/22 11:34:22.102
    STEP: deleting 11/29/22 11:34:22.106
    STEP: deleting a collection 11/29/22 11:34:22.116
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:34:22.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-4860" for this suite. 11/29/22 11:34:22.128
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:34:22.138
Nov 29 11:34:22.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename gc 11/29/22 11:34:22.139
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:34:22.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:34:22.149
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 11/29/22 11:34:22.154
STEP: delete the rc 11/29/22 11:34:27.363
STEP: wait for the rc to be deleted 11/29/22 11:34:27.466
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/29/22 11:34:32.491
STEP: Gathering metrics 11/29/22 11:35:02.502
W1129 11:35:02.510728      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 29 11:35:02.510: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov 29 11:35:02.510: INFO: Deleting pod "simpletest.rc-2nmj4" in namespace "gc-9211"
Nov 29 11:35:02.517: INFO: Deleting pod "simpletest.rc-2vlhc" in namespace "gc-9211"
Nov 29 11:35:02.523: INFO: Deleting pod "simpletest.rc-2vlzk" in namespace "gc-9211"
Nov 29 11:35:02.533: INFO: Deleting pod "simpletest.rc-46chb" in namespace "gc-9211"
Nov 29 11:35:02.545: INFO: Deleting pod "simpletest.rc-4mzls" in namespace "gc-9211"
Nov 29 11:35:02.565: INFO: Deleting pod "simpletest.rc-4rdq6" in namespace "gc-9211"
Nov 29 11:35:02.615: INFO: Deleting pod "simpletest.rc-4wph7" in namespace "gc-9211"
Nov 29 11:35:02.672: INFO: Deleting pod "simpletest.rc-5k8dk" in namespace "gc-9211"
Nov 29 11:35:02.780: INFO: Deleting pod "simpletest.rc-5lsrb" in namespace "gc-9211"
Nov 29 11:35:02.950: INFO: Deleting pod "simpletest.rc-6vw4t" in namespace "gc-9211"
Nov 29 11:35:03.058: INFO: Deleting pod "simpletest.rc-6x6jt" in namespace "gc-9211"
Nov 29 11:35:03.197: INFO: Deleting pod "simpletest.rc-72xc9" in namespace "gc-9211"
Nov 29 11:35:03.228: INFO: Deleting pod "simpletest.rc-77kfl" in namespace "gc-9211"
Nov 29 11:35:03.247: INFO: Deleting pod "simpletest.rc-77mhh" in namespace "gc-9211"
Nov 29 11:35:03.265: INFO: Deleting pod "simpletest.rc-7mslh" in namespace "gc-9211"
Nov 29 11:35:03.308: INFO: Deleting pod "simpletest.rc-7nnlx" in namespace "gc-9211"
Nov 29 11:35:03.330: INFO: Deleting pod "simpletest.rc-847n7" in namespace "gc-9211"
Nov 29 11:35:03.509: INFO: Deleting pod "simpletest.rc-85gt5" in namespace "gc-9211"
Nov 29 11:35:03.587: INFO: Deleting pod "simpletest.rc-8nbck" in namespace "gc-9211"
Nov 29 11:35:03.709: INFO: Deleting pod "simpletest.rc-8q8nr" in namespace "gc-9211"
Nov 29 11:35:04.349: INFO: Deleting pod "simpletest.rc-8t72d" in namespace "gc-9211"
Nov 29 11:35:04.409: INFO: Deleting pod "simpletest.rc-8tz6d" in namespace "gc-9211"
Nov 29 11:35:04.473: INFO: Deleting pod "simpletest.rc-9wmq9" in namespace "gc-9211"
Nov 29 11:35:04.739: INFO: Deleting pod "simpletest.rc-9xgkj" in namespace "gc-9211"
Nov 29 11:35:04.832: INFO: Deleting pod "simpletest.rc-b48mb" in namespace "gc-9211"
Nov 29 11:35:04.972: INFO: Deleting pod "simpletest.rc-bbzph" in namespace "gc-9211"
Nov 29 11:35:05.477: INFO: Deleting pod "simpletest.rc-bgkp5" in namespace "gc-9211"
Nov 29 11:35:05.666: INFO: Deleting pod "simpletest.rc-bgl5h" in namespace "gc-9211"
Nov 29 11:35:05.719: INFO: Deleting pod "simpletest.rc-bst6p" in namespace "gc-9211"
Nov 29 11:35:06.051: INFO: Deleting pod "simpletest.rc-bwcbr" in namespace "gc-9211"
Nov 29 11:35:06.238: INFO: Deleting pod "simpletest.rc-c225k" in namespace "gc-9211"
Nov 29 11:35:06.332: INFO: Deleting pod "simpletest.rc-cn4vj" in namespace "gc-9211"
Nov 29 11:35:07.022: INFO: Deleting pod "simpletest.rc-cvhhf" in namespace "gc-9211"
Nov 29 11:35:07.224: INFO: Deleting pod "simpletest.rc-d44d6" in namespace "gc-9211"
Nov 29 11:35:07.302: INFO: Deleting pod "simpletest.rc-db9mr" in namespace "gc-9211"
Nov 29 11:35:07.441: INFO: Deleting pod "simpletest.rc-dphzr" in namespace "gc-9211"
Nov 29 11:35:07.598: INFO: Deleting pod "simpletest.rc-dx45q" in namespace "gc-9211"
Nov 29 11:35:07.952: INFO: Deleting pod "simpletest.rc-f2qtb" in namespace "gc-9211"
Nov 29 11:35:08.638: INFO: Deleting pod "simpletest.rc-ff56s" in namespace "gc-9211"
Nov 29 11:35:08.758: INFO: Deleting pod "simpletest.rc-fwc2b" in namespace "gc-9211"
Nov 29 11:35:08.895: INFO: Deleting pod "simpletest.rc-gjm5z" in namespace "gc-9211"
Nov 29 11:35:08.975: INFO: Deleting pod "simpletest.rc-glwdl" in namespace "gc-9211"
Nov 29 11:35:09.125: INFO: Deleting pod "simpletest.rc-gv5dp" in namespace "gc-9211"
Nov 29 11:35:09.623: INFO: Deleting pod "simpletest.rc-h45b6" in namespace "gc-9211"
Nov 29 11:35:09.959: INFO: Deleting pod "simpletest.rc-h8bk9" in namespace "gc-9211"
Nov 29 11:35:10.573: INFO: Deleting pod "simpletest.rc-hcfch" in namespace "gc-9211"
Nov 29 11:35:10.648: INFO: Deleting pod "simpletest.rc-hdrnw" in namespace "gc-9211"
Nov 29 11:35:10.772: INFO: Deleting pod "simpletest.rc-hpjrw" in namespace "gc-9211"
Nov 29 11:35:11.384: INFO: Deleting pod "simpletest.rc-hxn2s" in namespace "gc-9211"
Nov 29 11:35:11.561: INFO: Deleting pod "simpletest.rc-jh5v8" in namespace "gc-9211"
Nov 29 11:35:11.691: INFO: Deleting pod "simpletest.rc-jjq89" in namespace "gc-9211"
Nov 29 11:35:12.001: INFO: Deleting pod "simpletest.rc-jqp9m" in namespace "gc-9211"
Nov 29 11:35:12.257: INFO: Deleting pod "simpletest.rc-jt597" in namespace "gc-9211"
Nov 29 11:35:12.338: INFO: Deleting pod "simpletest.rc-jxsvs" in namespace "gc-9211"
Nov 29 11:35:12.864: INFO: Deleting pod "simpletest.rc-kdld4" in namespace "gc-9211"
Nov 29 11:35:13.262: INFO: Deleting pod "simpletest.rc-kdxhd" in namespace "gc-9211"
Nov 29 11:35:14.025: INFO: Deleting pod "simpletest.rc-kjhkv" in namespace "gc-9211"
Nov 29 11:35:14.499: INFO: Deleting pod "simpletest.rc-kp29v" in namespace "gc-9211"
Nov 29 11:35:14.996: INFO: Deleting pod "simpletest.rc-kp6p6" in namespace "gc-9211"
Nov 29 11:35:15.273: INFO: Deleting pod "simpletest.rc-krt7j" in namespace "gc-9211"
Nov 29 11:35:15.467: INFO: Deleting pod "simpletest.rc-llckj" in namespace "gc-9211"
Nov 29 11:35:15.760: INFO: Deleting pod "simpletest.rc-lnfps" in namespace "gc-9211"
Nov 29 11:35:16.275: INFO: Deleting pod "simpletest.rc-lq97f" in namespace "gc-9211"
Nov 29 11:35:16.570: INFO: Deleting pod "simpletest.rc-m95fw" in namespace "gc-9211"
Nov 29 11:35:16.948: INFO: Deleting pod "simpletest.rc-mp87n" in namespace "gc-9211"
Nov 29 11:35:17.091: INFO: Deleting pod "simpletest.rc-mw5v8" in namespace "gc-9211"
Nov 29 11:35:17.793: INFO: Deleting pod "simpletest.rc-nc225" in namespace "gc-9211"
Nov 29 11:35:18.006: INFO: Deleting pod "simpletest.rc-ngkvb" in namespace "gc-9211"
Nov 29 11:35:18.116: INFO: Deleting pod "simpletest.rc-nqn9m" in namespace "gc-9211"
Nov 29 11:35:18.370: INFO: Deleting pod "simpletest.rc-qc9vm" in namespace "gc-9211"
Nov 29 11:35:18.431: INFO: Deleting pod "simpletest.rc-qfwfq" in namespace "gc-9211"
Nov 29 11:35:18.866: INFO: Deleting pod "simpletest.rc-qhczm" in namespace "gc-9211"
Nov 29 11:35:19.026: INFO: Deleting pod "simpletest.rc-qlgtx" in namespace "gc-9211"
Nov 29 11:35:19.242: INFO: Deleting pod "simpletest.rc-qwmkz" in namespace "gc-9211"
Nov 29 11:35:19.480: INFO: Deleting pod "simpletest.rc-rghdv" in namespace "gc-9211"
Nov 29 11:35:19.566: INFO: Deleting pod "simpletest.rc-rkvjs" in namespace "gc-9211"
Nov 29 11:35:19.763: INFO: Deleting pod "simpletest.rc-rqktt" in namespace "gc-9211"
Nov 29 11:35:20.176: INFO: Deleting pod "simpletest.rc-rvj57" in namespace "gc-9211"
Nov 29 11:35:20.344: INFO: Deleting pod "simpletest.rc-rwk2w" in namespace "gc-9211"
Nov 29 11:35:20.739: INFO: Deleting pod "simpletest.rc-s9mml" in namespace "gc-9211"
Nov 29 11:35:20.917: INFO: Deleting pod "simpletest.rc-sd785" in namespace "gc-9211"
Nov 29 11:35:21.141: INFO: Deleting pod "simpletest.rc-sjfwp" in namespace "gc-9211"
Nov 29 11:35:21.567: INFO: Deleting pod "simpletest.rc-ssd4q" in namespace "gc-9211"
Nov 29 11:35:21.763: INFO: Deleting pod "simpletest.rc-sthr9" in namespace "gc-9211"
Nov 29 11:35:22.107: INFO: Deleting pod "simpletest.rc-t8dql" in namespace "gc-9211"
Nov 29 11:35:22.403: INFO: Deleting pod "simpletest.rc-tgc6t" in namespace "gc-9211"
Nov 29 11:35:23.046: INFO: Deleting pod "simpletest.rc-tvzls" in namespace "gc-9211"
Nov 29 11:35:23.265: INFO: Deleting pod "simpletest.rc-vw269" in namespace "gc-9211"
Nov 29 11:35:23.409: INFO: Deleting pod "simpletest.rc-w4z8v" in namespace "gc-9211"
Nov 29 11:35:23.932: INFO: Deleting pod "simpletest.rc-wmgt9" in namespace "gc-9211"
Nov 29 11:35:24.259: INFO: Deleting pod "simpletest.rc-wp629" in namespace "gc-9211"
Nov 29 11:35:24.642: INFO: Deleting pod "simpletest.rc-x2jrx" in namespace "gc-9211"
Nov 29 11:35:25.160: INFO: Deleting pod "simpletest.rc-x5dfv" in namespace "gc-9211"
Nov 29 11:35:25.526: INFO: Deleting pod "simpletest.rc-xbjsn" in namespace "gc-9211"
Nov 29 11:35:25.773: INFO: Deleting pod "simpletest.rc-xlkr4" in namespace "gc-9211"
Nov 29 11:35:25.860: INFO: Deleting pod "simpletest.rc-xs56k" in namespace "gc-9211"
Nov 29 11:35:26.017: INFO: Deleting pod "simpletest.rc-xt5zs" in namespace "gc-9211"
Nov 29 11:35:26.069: INFO: Deleting pod "simpletest.rc-z8vn5" in namespace "gc-9211"
Nov 29 11:35:26.766: INFO: Deleting pod "simpletest.rc-z982z" in namespace "gc-9211"
Nov 29 11:35:26.970: INFO: Deleting pod "simpletest.rc-zstvn" in namespace "gc-9211"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 29 11:35:27.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9211" for this suite. 11/29/22 11:35:28.003
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":38,"skipped":800,"failed":0}
------------------------------
• [SLOW TEST] [65.880 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:34:22.138
    Nov 29 11:34:22.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename gc 11/29/22 11:34:22.139
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:34:22.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:34:22.149
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 11/29/22 11:34:22.154
    STEP: delete the rc 11/29/22 11:34:27.363
    STEP: wait for the rc to be deleted 11/29/22 11:34:27.466
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/29/22 11:34:32.491
    STEP: Gathering metrics 11/29/22 11:35:02.502
    W1129 11:35:02.510728      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 29 11:35:02.510: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov 29 11:35:02.510: INFO: Deleting pod "simpletest.rc-2nmj4" in namespace "gc-9211"
    Nov 29 11:35:02.517: INFO: Deleting pod "simpletest.rc-2vlhc" in namespace "gc-9211"
    Nov 29 11:35:02.523: INFO: Deleting pod "simpletest.rc-2vlzk" in namespace "gc-9211"
    Nov 29 11:35:02.533: INFO: Deleting pod "simpletest.rc-46chb" in namespace "gc-9211"
    Nov 29 11:35:02.545: INFO: Deleting pod "simpletest.rc-4mzls" in namespace "gc-9211"
    Nov 29 11:35:02.565: INFO: Deleting pod "simpletest.rc-4rdq6" in namespace "gc-9211"
    Nov 29 11:35:02.615: INFO: Deleting pod "simpletest.rc-4wph7" in namespace "gc-9211"
    Nov 29 11:35:02.672: INFO: Deleting pod "simpletest.rc-5k8dk" in namespace "gc-9211"
    Nov 29 11:35:02.780: INFO: Deleting pod "simpletest.rc-5lsrb" in namespace "gc-9211"
    Nov 29 11:35:02.950: INFO: Deleting pod "simpletest.rc-6vw4t" in namespace "gc-9211"
    Nov 29 11:35:03.058: INFO: Deleting pod "simpletest.rc-6x6jt" in namespace "gc-9211"
    Nov 29 11:35:03.197: INFO: Deleting pod "simpletest.rc-72xc9" in namespace "gc-9211"
    Nov 29 11:35:03.228: INFO: Deleting pod "simpletest.rc-77kfl" in namespace "gc-9211"
    Nov 29 11:35:03.247: INFO: Deleting pod "simpletest.rc-77mhh" in namespace "gc-9211"
    Nov 29 11:35:03.265: INFO: Deleting pod "simpletest.rc-7mslh" in namespace "gc-9211"
    Nov 29 11:35:03.308: INFO: Deleting pod "simpletest.rc-7nnlx" in namespace "gc-9211"
    Nov 29 11:35:03.330: INFO: Deleting pod "simpletest.rc-847n7" in namespace "gc-9211"
    Nov 29 11:35:03.509: INFO: Deleting pod "simpletest.rc-85gt5" in namespace "gc-9211"
    Nov 29 11:35:03.587: INFO: Deleting pod "simpletest.rc-8nbck" in namespace "gc-9211"
    Nov 29 11:35:03.709: INFO: Deleting pod "simpletest.rc-8q8nr" in namespace "gc-9211"
    Nov 29 11:35:04.349: INFO: Deleting pod "simpletest.rc-8t72d" in namespace "gc-9211"
    Nov 29 11:35:04.409: INFO: Deleting pod "simpletest.rc-8tz6d" in namespace "gc-9211"
    Nov 29 11:35:04.473: INFO: Deleting pod "simpletest.rc-9wmq9" in namespace "gc-9211"
    Nov 29 11:35:04.739: INFO: Deleting pod "simpletest.rc-9xgkj" in namespace "gc-9211"
    Nov 29 11:35:04.832: INFO: Deleting pod "simpletest.rc-b48mb" in namespace "gc-9211"
    Nov 29 11:35:04.972: INFO: Deleting pod "simpletest.rc-bbzph" in namespace "gc-9211"
    Nov 29 11:35:05.477: INFO: Deleting pod "simpletest.rc-bgkp5" in namespace "gc-9211"
    Nov 29 11:35:05.666: INFO: Deleting pod "simpletest.rc-bgl5h" in namespace "gc-9211"
    Nov 29 11:35:05.719: INFO: Deleting pod "simpletest.rc-bst6p" in namespace "gc-9211"
    Nov 29 11:35:06.051: INFO: Deleting pod "simpletest.rc-bwcbr" in namespace "gc-9211"
    Nov 29 11:35:06.238: INFO: Deleting pod "simpletest.rc-c225k" in namespace "gc-9211"
    Nov 29 11:35:06.332: INFO: Deleting pod "simpletest.rc-cn4vj" in namespace "gc-9211"
    Nov 29 11:35:07.022: INFO: Deleting pod "simpletest.rc-cvhhf" in namespace "gc-9211"
    Nov 29 11:35:07.224: INFO: Deleting pod "simpletest.rc-d44d6" in namespace "gc-9211"
    Nov 29 11:35:07.302: INFO: Deleting pod "simpletest.rc-db9mr" in namespace "gc-9211"
    Nov 29 11:35:07.441: INFO: Deleting pod "simpletest.rc-dphzr" in namespace "gc-9211"
    Nov 29 11:35:07.598: INFO: Deleting pod "simpletest.rc-dx45q" in namespace "gc-9211"
    Nov 29 11:35:07.952: INFO: Deleting pod "simpletest.rc-f2qtb" in namespace "gc-9211"
    Nov 29 11:35:08.638: INFO: Deleting pod "simpletest.rc-ff56s" in namespace "gc-9211"
    Nov 29 11:35:08.758: INFO: Deleting pod "simpletest.rc-fwc2b" in namespace "gc-9211"
    Nov 29 11:35:08.895: INFO: Deleting pod "simpletest.rc-gjm5z" in namespace "gc-9211"
    Nov 29 11:35:08.975: INFO: Deleting pod "simpletest.rc-glwdl" in namespace "gc-9211"
    Nov 29 11:35:09.125: INFO: Deleting pod "simpletest.rc-gv5dp" in namespace "gc-9211"
    Nov 29 11:35:09.623: INFO: Deleting pod "simpletest.rc-h45b6" in namespace "gc-9211"
    Nov 29 11:35:09.959: INFO: Deleting pod "simpletest.rc-h8bk9" in namespace "gc-9211"
    Nov 29 11:35:10.573: INFO: Deleting pod "simpletest.rc-hcfch" in namespace "gc-9211"
    Nov 29 11:35:10.648: INFO: Deleting pod "simpletest.rc-hdrnw" in namespace "gc-9211"
    Nov 29 11:35:10.772: INFO: Deleting pod "simpletest.rc-hpjrw" in namespace "gc-9211"
    Nov 29 11:35:11.384: INFO: Deleting pod "simpletest.rc-hxn2s" in namespace "gc-9211"
    Nov 29 11:35:11.561: INFO: Deleting pod "simpletest.rc-jh5v8" in namespace "gc-9211"
    Nov 29 11:35:11.691: INFO: Deleting pod "simpletest.rc-jjq89" in namespace "gc-9211"
    Nov 29 11:35:12.001: INFO: Deleting pod "simpletest.rc-jqp9m" in namespace "gc-9211"
    Nov 29 11:35:12.257: INFO: Deleting pod "simpletest.rc-jt597" in namespace "gc-9211"
    Nov 29 11:35:12.338: INFO: Deleting pod "simpletest.rc-jxsvs" in namespace "gc-9211"
    Nov 29 11:35:12.864: INFO: Deleting pod "simpletest.rc-kdld4" in namespace "gc-9211"
    Nov 29 11:35:13.262: INFO: Deleting pod "simpletest.rc-kdxhd" in namespace "gc-9211"
    Nov 29 11:35:14.025: INFO: Deleting pod "simpletest.rc-kjhkv" in namespace "gc-9211"
    Nov 29 11:35:14.499: INFO: Deleting pod "simpletest.rc-kp29v" in namespace "gc-9211"
    Nov 29 11:35:14.996: INFO: Deleting pod "simpletest.rc-kp6p6" in namespace "gc-9211"
    Nov 29 11:35:15.273: INFO: Deleting pod "simpletest.rc-krt7j" in namespace "gc-9211"
    Nov 29 11:35:15.467: INFO: Deleting pod "simpletest.rc-llckj" in namespace "gc-9211"
    Nov 29 11:35:15.760: INFO: Deleting pod "simpletest.rc-lnfps" in namespace "gc-9211"
    Nov 29 11:35:16.275: INFO: Deleting pod "simpletest.rc-lq97f" in namespace "gc-9211"
    Nov 29 11:35:16.570: INFO: Deleting pod "simpletest.rc-m95fw" in namespace "gc-9211"
    Nov 29 11:35:16.948: INFO: Deleting pod "simpletest.rc-mp87n" in namespace "gc-9211"
    Nov 29 11:35:17.091: INFO: Deleting pod "simpletest.rc-mw5v8" in namespace "gc-9211"
    Nov 29 11:35:17.793: INFO: Deleting pod "simpletest.rc-nc225" in namespace "gc-9211"
    Nov 29 11:35:18.006: INFO: Deleting pod "simpletest.rc-ngkvb" in namespace "gc-9211"
    Nov 29 11:35:18.116: INFO: Deleting pod "simpletest.rc-nqn9m" in namespace "gc-9211"
    Nov 29 11:35:18.370: INFO: Deleting pod "simpletest.rc-qc9vm" in namespace "gc-9211"
    Nov 29 11:35:18.431: INFO: Deleting pod "simpletest.rc-qfwfq" in namespace "gc-9211"
    Nov 29 11:35:18.866: INFO: Deleting pod "simpletest.rc-qhczm" in namespace "gc-9211"
    Nov 29 11:35:19.026: INFO: Deleting pod "simpletest.rc-qlgtx" in namespace "gc-9211"
    Nov 29 11:35:19.242: INFO: Deleting pod "simpletest.rc-qwmkz" in namespace "gc-9211"
    Nov 29 11:35:19.480: INFO: Deleting pod "simpletest.rc-rghdv" in namespace "gc-9211"
    Nov 29 11:35:19.566: INFO: Deleting pod "simpletest.rc-rkvjs" in namespace "gc-9211"
    Nov 29 11:35:19.763: INFO: Deleting pod "simpletest.rc-rqktt" in namespace "gc-9211"
    Nov 29 11:35:20.176: INFO: Deleting pod "simpletest.rc-rvj57" in namespace "gc-9211"
    Nov 29 11:35:20.344: INFO: Deleting pod "simpletest.rc-rwk2w" in namespace "gc-9211"
    Nov 29 11:35:20.739: INFO: Deleting pod "simpletest.rc-s9mml" in namespace "gc-9211"
    Nov 29 11:35:20.917: INFO: Deleting pod "simpletest.rc-sd785" in namespace "gc-9211"
    Nov 29 11:35:21.141: INFO: Deleting pod "simpletest.rc-sjfwp" in namespace "gc-9211"
    Nov 29 11:35:21.567: INFO: Deleting pod "simpletest.rc-ssd4q" in namespace "gc-9211"
    Nov 29 11:35:21.763: INFO: Deleting pod "simpletest.rc-sthr9" in namespace "gc-9211"
    Nov 29 11:35:22.107: INFO: Deleting pod "simpletest.rc-t8dql" in namespace "gc-9211"
    Nov 29 11:35:22.403: INFO: Deleting pod "simpletest.rc-tgc6t" in namespace "gc-9211"
    Nov 29 11:35:23.046: INFO: Deleting pod "simpletest.rc-tvzls" in namespace "gc-9211"
    Nov 29 11:35:23.265: INFO: Deleting pod "simpletest.rc-vw269" in namespace "gc-9211"
    Nov 29 11:35:23.409: INFO: Deleting pod "simpletest.rc-w4z8v" in namespace "gc-9211"
    Nov 29 11:35:23.932: INFO: Deleting pod "simpletest.rc-wmgt9" in namespace "gc-9211"
    Nov 29 11:35:24.259: INFO: Deleting pod "simpletest.rc-wp629" in namespace "gc-9211"
    Nov 29 11:35:24.642: INFO: Deleting pod "simpletest.rc-x2jrx" in namespace "gc-9211"
    Nov 29 11:35:25.160: INFO: Deleting pod "simpletest.rc-x5dfv" in namespace "gc-9211"
    Nov 29 11:35:25.526: INFO: Deleting pod "simpletest.rc-xbjsn" in namespace "gc-9211"
    Nov 29 11:35:25.773: INFO: Deleting pod "simpletest.rc-xlkr4" in namespace "gc-9211"
    Nov 29 11:35:25.860: INFO: Deleting pod "simpletest.rc-xs56k" in namespace "gc-9211"
    Nov 29 11:35:26.017: INFO: Deleting pod "simpletest.rc-xt5zs" in namespace "gc-9211"
    Nov 29 11:35:26.069: INFO: Deleting pod "simpletest.rc-z8vn5" in namespace "gc-9211"
    Nov 29 11:35:26.766: INFO: Deleting pod "simpletest.rc-z982z" in namespace "gc-9211"
    Nov 29 11:35:26.970: INFO: Deleting pod "simpletest.rc-zstvn" in namespace "gc-9211"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 29 11:35:27.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9211" for this suite. 11/29/22 11:35:28.003
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:35:28.019
Nov 29 11:35:28.019: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 11:35:28.02
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:28.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:28.078
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-b7ee4cd4-2385-454a-b65b-473187143719 11/29/22 11:35:28.081
STEP: Creating a pod to test consume configMaps 11/29/22 11:35:28.096
Nov 29 11:35:28.270: INFO: Waiting up to 5m0s for pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a" in namespace "configmap-4454" to be "Succeeded or Failed"
Nov 29 11:35:28.413: INFO: Pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a": Phase="Pending", Reason="", readiness=false. Elapsed: 142.076969ms
Nov 29 11:35:30.416: INFO: Pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.145177691s
Nov 29 11:35:32.417: INFO: Pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.146838905s
STEP: Saw pod success 11/29/22 11:35:32.417
Nov 29 11:35:32.418: INFO: Pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a" satisfied condition "Succeeded or Failed"
Nov 29 11:35:32.420: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a container agnhost-container: <nil>
STEP: delete the pod 11/29/22 11:35:32.423
Nov 29 11:35:32.428: INFO: Waiting for pod pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a to disappear
Nov 29 11:35:32.432: INFO: Pod pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 11:35:32.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4454" for this suite. 11/29/22 11:35:32.436
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":39,"skipped":802,"failed":0}
------------------------------
• [4.419 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:35:28.019
    Nov 29 11:35:28.019: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 11:35:28.02
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:28.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:28.078
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-b7ee4cd4-2385-454a-b65b-473187143719 11/29/22 11:35:28.081
    STEP: Creating a pod to test consume configMaps 11/29/22 11:35:28.096
    Nov 29 11:35:28.270: INFO: Waiting up to 5m0s for pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a" in namespace "configmap-4454" to be "Succeeded or Failed"
    Nov 29 11:35:28.413: INFO: Pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a": Phase="Pending", Reason="", readiness=false. Elapsed: 142.076969ms
    Nov 29 11:35:30.416: INFO: Pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.145177691s
    Nov 29 11:35:32.417: INFO: Pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.146838905s
    STEP: Saw pod success 11/29/22 11:35:32.417
    Nov 29 11:35:32.418: INFO: Pod "pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a" satisfied condition "Succeeded or Failed"
    Nov 29 11:35:32.420: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 11:35:32.423
    Nov 29 11:35:32.428: INFO: Waiting for pod pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a to disappear
    Nov 29 11:35:32.432: INFO: Pod pod-configmaps-0abad01d-cd44-4333-bb4c-35558e22877a no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 11:35:32.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4454" for this suite. 11/29/22 11:35:32.436
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:35:32.44
Nov 29 11:35:32.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 11:35:32.441
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:32.448
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:32.451
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-58aee6cc-84f9-4622-ba3d-1b1c7a8557e8 11/29/22 11:35:32.456
STEP: Creating the pod 11/29/22 11:35:32.458
Nov 29 11:35:32.464: INFO: Waiting up to 5m0s for pod "pod-configmaps-4eefa5bb-8fbe-45df-a974-ba1e44b13907" in namespace "configmap-556" to be "running"
Nov 29 11:35:32.467: INFO: Pod "pod-configmaps-4eefa5bb-8fbe-45df-a974-ba1e44b13907": Phase="Pending", Reason="", readiness=false. Elapsed: 3.383931ms
Nov 29 11:35:34.471: INFO: Pod "pod-configmaps-4eefa5bb-8fbe-45df-a974-ba1e44b13907": Phase="Running", Reason="", readiness=false. Elapsed: 2.007649289s
Nov 29 11:35:34.471: INFO: Pod "pod-configmaps-4eefa5bb-8fbe-45df-a974-ba1e44b13907" satisfied condition "running"
STEP: Waiting for pod with text data 11/29/22 11:35:34.471
STEP: Waiting for pod with binary data 11/29/22 11:35:34.475
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 11:35:34.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-556" for this suite. 11/29/22 11:35:34.482
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":40,"skipped":815,"failed":0}
------------------------------
• [2.045 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:35:32.44
    Nov 29 11:35:32.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 11:35:32.441
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:32.448
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:32.451
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-58aee6cc-84f9-4622-ba3d-1b1c7a8557e8 11/29/22 11:35:32.456
    STEP: Creating the pod 11/29/22 11:35:32.458
    Nov 29 11:35:32.464: INFO: Waiting up to 5m0s for pod "pod-configmaps-4eefa5bb-8fbe-45df-a974-ba1e44b13907" in namespace "configmap-556" to be "running"
    Nov 29 11:35:32.467: INFO: Pod "pod-configmaps-4eefa5bb-8fbe-45df-a974-ba1e44b13907": Phase="Pending", Reason="", readiness=false. Elapsed: 3.383931ms
    Nov 29 11:35:34.471: INFO: Pod "pod-configmaps-4eefa5bb-8fbe-45df-a974-ba1e44b13907": Phase="Running", Reason="", readiness=false. Elapsed: 2.007649289s
    Nov 29 11:35:34.471: INFO: Pod "pod-configmaps-4eefa5bb-8fbe-45df-a974-ba1e44b13907" satisfied condition "running"
    STEP: Waiting for pod with text data 11/29/22 11:35:34.471
    STEP: Waiting for pod with binary data 11/29/22 11:35:34.475
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 11:35:34.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-556" for this suite. 11/29/22 11:35:34.482
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:35:34.486
Nov 29 11:35:34.486: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename namespaces 11/29/22 11:35:34.487
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:34.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:34.511
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 11/29/22 11:35:34.513
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:34.521
STEP: Creating a service in the namespace 11/29/22 11:35:34.524
STEP: Deleting the namespace 11/29/22 11:35:34.535
STEP: Waiting for the namespace to be removed. 11/29/22 11:35:34.544
STEP: Recreating the namespace 11/29/22 11:35:40.548
STEP: Verifying there is no service in the namespace 11/29/22 11:35:40.557
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 29 11:35:40.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4057" for this suite. 11/29/22 11:35:40.57
STEP: Destroying namespace "nsdeletetest-4482" for this suite. 11/29/22 11:35:40.572
Nov 29 11:35:40.575: INFO: Namespace nsdeletetest-4482 was already deleted
STEP: Destroying namespace "nsdeletetest-1753" for this suite. 11/29/22 11:35:40.575
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":41,"skipped":838,"failed":0}
------------------------------
• [SLOW TEST] [6.091 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:35:34.486
    Nov 29 11:35:34.486: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename namespaces 11/29/22 11:35:34.487
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:34.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:34.511
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 11/29/22 11:35:34.513
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:34.521
    STEP: Creating a service in the namespace 11/29/22 11:35:34.524
    STEP: Deleting the namespace 11/29/22 11:35:34.535
    STEP: Waiting for the namespace to be removed. 11/29/22 11:35:34.544
    STEP: Recreating the namespace 11/29/22 11:35:40.548
    STEP: Verifying there is no service in the namespace 11/29/22 11:35:40.557
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 11:35:40.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4057" for this suite. 11/29/22 11:35:40.57
    STEP: Destroying namespace "nsdeletetest-4482" for this suite. 11/29/22 11:35:40.572
    Nov 29 11:35:40.575: INFO: Namespace nsdeletetest-4482 was already deleted
    STEP: Destroying namespace "nsdeletetest-1753" for this suite. 11/29/22 11:35:40.575
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:35:40.579
Nov 29 11:35:40.579: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubelet-test 11/29/22 11:35:40.58
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:40.589
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:40.591
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Nov 29 11:35:40.597: INFO: Waiting up to 5m0s for pod "busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505" in namespace "kubelet-test-5530" to be "running and ready"
Nov 29 11:35:40.600: INFO: Pod "busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304662ms
Nov 29 11:35:40.600: INFO: The phase of Pod busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:35:42.603: INFO: Pod "busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505": Phase="Running", Reason="", readiness=true. Elapsed: 2.005299494s
Nov 29 11:35:42.603: INFO: The phase of Pod busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505 is Running (Ready = true)
Nov 29 11:35:42.603: INFO: Pod "busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 29 11:35:42.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5530" for this suite. 11/29/22 11:35:42.612
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":42,"skipped":848,"failed":0}
------------------------------
• [2.036 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:35:40.579
    Nov 29 11:35:40.579: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubelet-test 11/29/22 11:35:40.58
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:40.589
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:40.591
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Nov 29 11:35:40.597: INFO: Waiting up to 5m0s for pod "busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505" in namespace "kubelet-test-5530" to be "running and ready"
    Nov 29 11:35:40.600: INFO: Pod "busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304662ms
    Nov 29 11:35:40.600: INFO: The phase of Pod busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:35:42.603: INFO: Pod "busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505": Phase="Running", Reason="", readiness=true. Elapsed: 2.005299494s
    Nov 29 11:35:42.603: INFO: The phase of Pod busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505 is Running (Ready = true)
    Nov 29 11:35:42.603: INFO: Pod "busybox-scheduling-0739b6e0-2d5d-4b0b-b6c9-16b600b80505" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 29 11:35:42.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5530" for this suite. 11/29/22 11:35:42.612
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:35:42.619
Nov 29 11:35:42.620: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 11:35:42.62
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:42.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:42.63
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 11:35:42.639
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 11:35:42.889
STEP: Deploying the webhook pod 11/29/22 11:35:42.893
STEP: Wait for the deployment to be ready 11/29/22 11:35:42.901
Nov 29 11:35:42.909: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 11:35:44.917
STEP: Verifying the service has paired with the endpoint 11/29/22 11:35:44.93
Nov 29 11:35:45.931: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/29/22 11:35:45.934
Nov 29 11:35:55.945: INFO: Waiting for webhook configuration to be ready...
STEP: create a namespace for the webhook 11/29/22 11:35:56.055
STEP: create a configmap should be unconditionally rejected by the webhook 11/29/22 11:35:56.059
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:35:56.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4387" for this suite. 11/29/22 11:35:56.09
STEP: Destroying namespace "webhook-4387-markers" for this suite. 11/29/22 11:35:56.095
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":43,"skipped":878,"failed":0}
------------------------------
• [SLOW TEST] [13.511 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:35:42.619
    Nov 29 11:35:42.620: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 11:35:42.62
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:42.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:42.63
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 11:35:42.639
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 11:35:42.889
    STEP: Deploying the webhook pod 11/29/22 11:35:42.893
    STEP: Wait for the deployment to be ready 11/29/22 11:35:42.901
    Nov 29 11:35:42.909: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 11:35:44.917
    STEP: Verifying the service has paired with the endpoint 11/29/22 11:35:44.93
    Nov 29 11:35:45.931: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/29/22 11:35:45.934
    Nov 29 11:35:55.945: INFO: Waiting for webhook configuration to be ready...
    STEP: create a namespace for the webhook 11/29/22 11:35:56.055
    STEP: create a configmap should be unconditionally rejected by the webhook 11/29/22 11:35:56.059
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:35:56.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4387" for this suite. 11/29/22 11:35:56.09
    STEP: Destroying namespace "webhook-4387-markers" for this suite. 11/29/22 11:35:56.095
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:35:56.134
Nov 29 11:35:56.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename gc 11/29/22 11:35:56.135
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:56.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:56.146
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 11/29/22 11:35:56.149
STEP: Wait for the Deployment to create new ReplicaSet 11/29/22 11:35:56.152
STEP: delete the deployment 11/29/22 11:35:56.66
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/29/22 11:35:56.663
STEP: Gathering metrics 11/29/22 11:35:57.188
W1129 11:35:57.196994      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 29 11:35:57.197: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 29 11:35:57.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5137" for this suite. 11/29/22 11:35:57.199
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":44,"skipped":920,"failed":0}
------------------------------
• [1.069 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:35:56.134
    Nov 29 11:35:56.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename gc 11/29/22 11:35:56.135
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:56.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:56.146
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 11/29/22 11:35:56.149
    STEP: Wait for the Deployment to create new ReplicaSet 11/29/22 11:35:56.152
    STEP: delete the deployment 11/29/22 11:35:56.66
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/29/22 11:35:56.663
    STEP: Gathering metrics 11/29/22 11:35:57.188
    W1129 11:35:57.196994      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 29 11:35:57.197: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 29 11:35:57.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5137" for this suite. 11/29/22 11:35:57.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:35:57.205
Nov 29 11:35:57.205: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:35:57.206
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:57.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:57.216
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Nov 29 11:35:57.226: INFO: created pod
Nov 29 11:35:57.226: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-9336" to be "Succeeded or Failed"
Nov 29 11:35:57.228: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02867ms
Nov 29 11:35:59.231: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004808486s
Nov 29 11:36:01.241: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015030938s
STEP: Saw pod success 11/29/22 11:36:01.241
Nov 29 11:36:01.241: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Nov 29 11:36:31.243: INFO: polling logs
Nov 29 11:36:31.248: INFO: Pod logs: 
I1129 11:35:57.951719       1 log.go:195] OK: Got token
I1129 11:35:57.951754       1 log.go:195] validating with in-cluster discovery
I1129 11:35:57.952051       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I1129 11:35:57.952078       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-9336:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1669722357, NotBefore:1669721757, IssuedAt:1669721757, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9336", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d40714dc-bbe1-4d6b-8c28-4c6f4c419749"}}}
I1129 11:35:57.961871       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I1129 11:35:57.967678       1 log.go:195] OK: Validated signature on JWT
I1129 11:35:57.967776       1 log.go:195] OK: Got valid claims from token!
I1129 11:35:57.967799       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-9336:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1669722357, NotBefore:1669721757, IssuedAt:1669721757, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9336", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d40714dc-bbe1-4d6b-8c28-4c6f4c419749"}}}

Nov 29 11:36:31.248: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 29 11:36:31.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9336" for this suite. 11/29/22 11:36:31.254
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":45,"skipped":926,"failed":0}
------------------------------
• [SLOW TEST] [34.053 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:35:57.205
    Nov 29 11:35:57.205: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:35:57.206
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:35:57.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:35:57.216
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Nov 29 11:35:57.226: INFO: created pod
    Nov 29 11:35:57.226: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-9336" to be "Succeeded or Failed"
    Nov 29 11:35:57.228: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02867ms
    Nov 29 11:35:59.231: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004808486s
    Nov 29 11:36:01.241: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015030938s
    STEP: Saw pod success 11/29/22 11:36:01.241
    Nov 29 11:36:01.241: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Nov 29 11:36:31.243: INFO: polling logs
    Nov 29 11:36:31.248: INFO: Pod logs: 
    I1129 11:35:57.951719       1 log.go:195] OK: Got token
    I1129 11:35:57.951754       1 log.go:195] validating with in-cluster discovery
    I1129 11:35:57.952051       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I1129 11:35:57.952078       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-9336:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1669722357, NotBefore:1669721757, IssuedAt:1669721757, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9336", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d40714dc-bbe1-4d6b-8c28-4c6f4c419749"}}}
    I1129 11:35:57.961871       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I1129 11:35:57.967678       1 log.go:195] OK: Validated signature on JWT
    I1129 11:35:57.967776       1 log.go:195] OK: Got valid claims from token!
    I1129 11:35:57.967799       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-9336:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1669722357, NotBefore:1669721757, IssuedAt:1669721757, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9336", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d40714dc-bbe1-4d6b-8c28-4c6f4c419749"}}}

    Nov 29 11:36:31.248: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 29 11:36:31.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9336" for this suite. 11/29/22 11:36:31.254
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:36:31.262
Nov 29 11:36:31.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-lifecycle-hook 11/29/22 11:36:31.263
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:31.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:31.274
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/29/22 11:36:31.278
Nov 29 11:36:31.282: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-73" to be "running and ready"
Nov 29 11:36:31.285: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.39317ms
Nov 29 11:36:31.285: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:36:33.291: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008801661s
Nov 29 11:36:33.291: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 29 11:36:33.291: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 11/29/22 11:36:33.294
Nov 29 11:36:33.299: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-73" to be "running and ready"
Nov 29 11:36:33.302: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.847946ms
Nov 29 11:36:33.302: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:36:35.306: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006707595s
Nov 29 11:36:35.306: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:36:37.306: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.007306519s
Nov 29 11:36:37.306: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Nov 29 11:36:37.306: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/29/22 11:36:37.31
STEP: delete the pod with lifecycle hook 11/29/22 11:36:37.315
Nov 29 11:36:37.320: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 29 11:36:37.325: INFO: Pod pod-with-poststart-http-hook still exists
Nov 29 11:36:39.326: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 29 11:36:39.332: INFO: Pod pod-with-poststart-http-hook still exists
Nov 29 11:36:41.325: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 29 11:36:41.328: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 29 11:36:41.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-73" for this suite. 11/29/22 11:36:41.334
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":46,"skipped":953,"failed":0}
------------------------------
• [SLOW TEST] [10.075 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:36:31.262
    Nov 29 11:36:31.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/29/22 11:36:31.263
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:31.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:31.274
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/29/22 11:36:31.278
    Nov 29 11:36:31.282: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-73" to be "running and ready"
    Nov 29 11:36:31.285: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.39317ms
    Nov 29 11:36:31.285: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:36:33.291: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008801661s
    Nov 29 11:36:33.291: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 29 11:36:33.291: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 11/29/22 11:36:33.294
    Nov 29 11:36:33.299: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-73" to be "running and ready"
    Nov 29 11:36:33.302: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.847946ms
    Nov 29 11:36:33.302: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:36:35.306: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006707595s
    Nov 29 11:36:35.306: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:36:37.306: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.007306519s
    Nov 29 11:36:37.306: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Nov 29 11:36:37.306: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/29/22 11:36:37.31
    STEP: delete the pod with lifecycle hook 11/29/22 11:36:37.315
    Nov 29 11:36:37.320: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 29 11:36:37.325: INFO: Pod pod-with-poststart-http-hook still exists
    Nov 29 11:36:39.326: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 29 11:36:39.332: INFO: Pod pod-with-poststart-http-hook still exists
    Nov 29 11:36:41.325: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 29 11:36:41.328: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 29 11:36:41.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-73" for this suite. 11/29/22 11:36:41.334
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:36:41.339
Nov 29 11:36:41.339: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replicaset 11/29/22 11:36:41.34
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:41.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:41.358
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Nov 29 11:36:41.360: INFO: Creating ReplicaSet my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69
Nov 29 11:36:41.366: INFO: Pod name my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69: Found 0 pods out of 1
Nov 29 11:36:46.373: INFO: Pod name my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69: Found 1 pods out of 1
Nov 29 11:36:46.373: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69" is running
Nov 29 11:36:46.373: INFO: Waiting up to 5m0s for pod "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc" in namespace "replicaset-1333" to be "running"
Nov 29 11:36:46.376: INFO: Pod "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc": Phase="Running", Reason="", readiness=true. Elapsed: 2.713431ms
Nov 29 11:36:46.376: INFO: Pod "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc" satisfied condition "running"
Nov 29 11:36:46.376: INFO: Pod "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 11:36:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 11:36:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 11:36:42 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 11:36:41 +0000 UTC Reason: Message:}])
Nov 29 11:36:46.376: INFO: Trying to dial the pod
Nov 29 11:36:51.386: INFO: Controller my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69: Got expected result from replica 1 [my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc]: "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 29 11:36:51.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1333" for this suite. 11/29/22 11:36:51.389
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":47,"skipped":985,"failed":0}
------------------------------
• [SLOW TEST] [10.054 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:36:41.339
    Nov 29 11:36:41.339: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replicaset 11/29/22 11:36:41.34
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:41.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:41.358
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Nov 29 11:36:41.360: INFO: Creating ReplicaSet my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69
    Nov 29 11:36:41.366: INFO: Pod name my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69: Found 0 pods out of 1
    Nov 29 11:36:46.373: INFO: Pod name my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69: Found 1 pods out of 1
    Nov 29 11:36:46.373: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69" is running
    Nov 29 11:36:46.373: INFO: Waiting up to 5m0s for pod "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc" in namespace "replicaset-1333" to be "running"
    Nov 29 11:36:46.376: INFO: Pod "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc": Phase="Running", Reason="", readiness=true. Elapsed: 2.713431ms
    Nov 29 11:36:46.376: INFO: Pod "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc" satisfied condition "running"
    Nov 29 11:36:46.376: INFO: Pod "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 11:36:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 11:36:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 11:36:42 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 11:36:41 +0000 UTC Reason: Message:}])
    Nov 29 11:36:46.376: INFO: Trying to dial the pod
    Nov 29 11:36:51.386: INFO: Controller my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69: Got expected result from replica 1 [my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc]: "my-hostname-basic-312b4165-1c1c-4f66-b005-975eff257a69-c8lpc", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 29 11:36:51.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1333" for this suite. 11/29/22 11:36:51.389
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:36:51.394
Nov 29 11:36:51.394: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename disruption 11/29/22 11:36:51.395
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:51.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:51.408
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:36:51.411
Nov 29 11:36:51.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename disruption-2 11/29/22 11:36:51.412
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:51.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:51.422
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 11/29/22 11:36:51.426
STEP: Waiting for the pdb to be processed 11/29/22 11:36:51.435
STEP: Waiting for the pdb to be processed 11/29/22 11:36:51.444
STEP: listing a collection of PDBs across all namespaces 11/29/22 11:36:51.447
STEP: listing a collection of PDBs in namespace disruption-6390 11/29/22 11:36:51.451
STEP: deleting a collection of PDBs 11/29/22 11:36:51.453
STEP: Waiting for the PDB collection to be deleted 11/29/22 11:36:51.458
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Nov 29 11:36:51.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-327" for this suite. 11/29/22 11:36:51.462
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 29 11:36:51.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6390" for this suite. 11/29/22 11:36:51.469
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":48,"skipped":996,"failed":0}
------------------------------
• [0.078 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:36:51.394
    Nov 29 11:36:51.394: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename disruption 11/29/22 11:36:51.395
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:51.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:51.408
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:36:51.411
    Nov 29 11:36:51.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename disruption-2 11/29/22 11:36:51.412
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:51.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:51.422
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 11/29/22 11:36:51.426
    STEP: Waiting for the pdb to be processed 11/29/22 11:36:51.435
    STEP: Waiting for the pdb to be processed 11/29/22 11:36:51.444
    STEP: listing a collection of PDBs across all namespaces 11/29/22 11:36:51.447
    STEP: listing a collection of PDBs in namespace disruption-6390 11/29/22 11:36:51.451
    STEP: deleting a collection of PDBs 11/29/22 11:36:51.453
    STEP: Waiting for the PDB collection to be deleted 11/29/22 11:36:51.458
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Nov 29 11:36:51.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-327" for this suite. 11/29/22 11:36:51.462
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 29 11:36:51.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6390" for this suite. 11/29/22 11:36:51.469
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:36:51.473
Nov 29 11:36:51.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:36:51.474
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:51.487
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:51.49
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 11/29/22 11:36:51.492
Nov 29 11:36:51.497: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d" in namespace "projected-7384" to be "Succeeded or Failed"
Nov 29 11:36:51.500: INFO: Pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.325923ms
Nov 29 11:36:53.503: INFO: Pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d": Phase="Running", Reason="", readiness=false. Elapsed: 2.006249472s
Nov 29 11:36:55.503: INFO: Pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006451563s
STEP: Saw pod success 11/29/22 11:36:55.503
Nov 29 11:36:55.503: INFO: Pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d" satisfied condition "Succeeded or Failed"
Nov 29 11:36:55.505: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d container client-container: <nil>
STEP: delete the pod 11/29/22 11:36:55.509
Nov 29 11:36:55.516: INFO: Waiting for pod downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d to disappear
Nov 29 11:36:55.518: INFO: Pod downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 11:36:55.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7384" for this suite. 11/29/22 11:36:55.522
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":49,"skipped":1017,"failed":0}
------------------------------
• [4.052 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:36:51.473
    Nov 29 11:36:51.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:36:51.474
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:51.487
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:51.49
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 11/29/22 11:36:51.492
    Nov 29 11:36:51.497: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d" in namespace "projected-7384" to be "Succeeded or Failed"
    Nov 29 11:36:51.500: INFO: Pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.325923ms
    Nov 29 11:36:53.503: INFO: Pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d": Phase="Running", Reason="", readiness=false. Elapsed: 2.006249472s
    Nov 29 11:36:55.503: INFO: Pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006451563s
    STEP: Saw pod success 11/29/22 11:36:55.503
    Nov 29 11:36:55.503: INFO: Pod "downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d" satisfied condition "Succeeded or Failed"
    Nov 29 11:36:55.505: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d container client-container: <nil>
    STEP: delete the pod 11/29/22 11:36:55.509
    Nov 29 11:36:55.516: INFO: Waiting for pod downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d to disappear
    Nov 29 11:36:55.518: INFO: Pod downwardapi-volume-5b1e7a0f-13fb-453e-bd60-69c45108594d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 11:36:55.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7384" for this suite. 11/29/22 11:36:55.522
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:36:55.529
Nov 29 11:36:55.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 11:36:55.53
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:55.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:55.541
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-2929 11/29/22 11:36:55.543
STEP: creating service affinity-nodeport in namespace services-2929 11/29/22 11:36:55.543
STEP: creating replication controller affinity-nodeport in namespace services-2929 11/29/22 11:36:55.552
I1129 11:36:55.556797      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-2929, replica count: 3
I1129 11:36:58.607853      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 11:36:58.620: INFO: Creating new exec pod
Nov 29 11:36:58.623: INFO: Waiting up to 5m0s for pod "execpod-affinityp6tzs" in namespace "services-2929" to be "running"
Nov 29 11:36:58.625: INFO: Pod "execpod-affinityp6tzs": Phase="Pending", Reason="", readiness=false. Elapsed: 1.873833ms
Nov 29 11:37:00.627: INFO: Pod "execpod-affinityp6tzs": Phase="Running", Reason="", readiness=true. Elapsed: 2.004085117s
Nov 29 11:37:00.627: INFO: Pod "execpod-affinityp6tzs" satisfied condition "running"
Nov 29 11:37:01.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 29 11:37:01.779: INFO: rc: 1
Nov 29 11:37:01.779: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport 80
nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 11:37:02.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 29 11:37:02.899: INFO: rc: 1
Nov 29 11:37:02.899: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport 80
nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 11:37:03.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 29 11:37:03.905: INFO: rc: 1
Nov 29 11:37:03.905: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport 80
nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 11:37:04.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 29 11:37:04.906: INFO: rc: 1
Nov 29 11:37:04.906: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport 80
nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 11:37:05.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 29 11:37:05.897: INFO: rc: 1
Nov 29 11:37:05.897: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport 80
nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 11:37:06.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 29 11:37:06.999: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Nov 29 11:37:06.999: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:37:06.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.68.44.44 80'
Nov 29 11:37:07.137: INFO: stderr: "+ + nc -vecho -t -w 2 100.68.44.44 hostName 80\n\nConnection to 100.68.44.44 80 port [tcp/http] succeeded!\n"
Nov 29 11:37:07.137: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:37:07.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.155 31075'
Nov 29 11:37:07.270: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.155 31075\nConnection to 192.168.8.155 31075 port [tcp/*] succeeded!\n"
Nov 29 11:37:07.270: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:37:07.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.22 31075'
Nov 29 11:37:07.394: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.22 31075\nConnection to 192.168.8.22 31075 port [tcp/*] succeeded!\n"
Nov 29 11:37:07.394: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:37:07.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:31075/ ; done'
Nov 29 11:37:07.583: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n"
Nov 29 11:37:07.583: INFO: stdout: "\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh"
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
Nov 29 11:37:07.583: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-2929, will wait for the garbage collector to delete the pods 11/29/22 11:37:07.591
Nov 29 11:37:07.650: INFO: Deleting ReplicationController affinity-nodeport took: 6.174269ms
Nov 29 11:37:07.751: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.007311ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 11:37:09.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2929" for this suite. 11/29/22 11:37:09.572
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":50,"skipped":1077,"failed":0}
------------------------------
• [SLOW TEST] [14.046 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:36:55.529
    Nov 29 11:36:55.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 11:36:55.53
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:36:55.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:36:55.541
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-2929 11/29/22 11:36:55.543
    STEP: creating service affinity-nodeport in namespace services-2929 11/29/22 11:36:55.543
    STEP: creating replication controller affinity-nodeport in namespace services-2929 11/29/22 11:36:55.552
    I1129 11:36:55.556797      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-2929, replica count: 3
    I1129 11:36:58.607853      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 11:36:58.620: INFO: Creating new exec pod
    Nov 29 11:36:58.623: INFO: Waiting up to 5m0s for pod "execpod-affinityp6tzs" in namespace "services-2929" to be "running"
    Nov 29 11:36:58.625: INFO: Pod "execpod-affinityp6tzs": Phase="Pending", Reason="", readiness=false. Elapsed: 1.873833ms
    Nov 29 11:37:00.627: INFO: Pod "execpod-affinityp6tzs": Phase="Running", Reason="", readiness=true. Elapsed: 2.004085117s
    Nov 29 11:37:00.627: INFO: Pod "execpod-affinityp6tzs" satisfied condition "running"
    Nov 29 11:37:01.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 29 11:37:01.779: INFO: rc: 1
    Nov 29 11:37:01.779: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport 80
    nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 11:37:02.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 29 11:37:02.899: INFO: rc: 1
    Nov 29 11:37:02.899: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport 80
    nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 11:37:03.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 29 11:37:03.905: INFO: rc: 1
    Nov 29 11:37:03.905: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport 80
    nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 11:37:04.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 29 11:37:04.906: INFO: rc: 1
    Nov 29 11:37:04.906: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport 80
    nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 11:37:05.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 29 11:37:05.897: INFO: rc: 1
    Nov 29 11:37:05.897: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport 80
    nc: connect to affinity-nodeport port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 11:37:06.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 29 11:37:06.999: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Nov 29 11:37:06.999: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:37:06.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.68.44.44 80'
    Nov 29 11:37:07.137: INFO: stderr: "+ + nc -vecho -t -w 2 100.68.44.44 hostName 80\n\nConnection to 100.68.44.44 80 port [tcp/http] succeeded!\n"
    Nov 29 11:37:07.137: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:37:07.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.155 31075'
    Nov 29 11:37:07.270: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.155 31075\nConnection to 192.168.8.155 31075 port [tcp/*] succeeded!\n"
    Nov 29 11:37:07.270: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:37:07.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.22 31075'
    Nov 29 11:37:07.394: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.22 31075\nConnection to 192.168.8.22 31075 port [tcp/*] succeeded!\n"
    Nov 29 11:37:07.394: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:37:07.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2929 exec execpod-affinityp6tzs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:31075/ ; done'
    Nov 29 11:37:07.583: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:31075/\n"
    Nov 29 11:37:07.583: INFO: stdout: "\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh\naffinity-nodeport-mddwh"
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Received response from host: affinity-nodeport-mddwh
    Nov 29 11:37:07.583: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-2929, will wait for the garbage collector to delete the pods 11/29/22 11:37:07.591
    Nov 29 11:37:07.650: INFO: Deleting ReplicationController affinity-nodeport took: 6.174269ms
    Nov 29 11:37:07.751: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.007311ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 11:37:09.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2929" for this suite. 11/29/22 11:37:09.572
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:37:09.576
Nov 29 11:37:09.576: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 11:37:09.576
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:09.59
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:09.592
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-9580 11/29/22 11:37:09.594
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[] 11/29/22 11:37:09.611
Nov 29 11:37:09.621: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9580 11/29/22 11:37:09.621
Nov 29 11:37:09.626: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9580" to be "running and ready"
Nov 29 11:37:09.628: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10211ms
Nov 29 11:37:09.628: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:37:11.632: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005797202s
Nov 29 11:37:11.632: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 29 11:37:11.632: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[pod1:[100]] 11/29/22 11:37:11.634
Nov 29 11:37:11.642: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-9580 11/29/22 11:37:11.642
Nov 29 11:37:11.646: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9580" to be "running and ready"
Nov 29 11:37:11.655: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.662927ms
Nov 29 11:37:11.655: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:37:13.659: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012986252s
Nov 29 11:37:13.659: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 29 11:37:13.659: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[pod1:[100] pod2:[101]] 11/29/22 11:37:13.664
Nov 29 11:37:13.680: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 11/29/22 11:37:13.68
Nov 29 11:37:13.680: INFO: Creating new exec pod
Nov 29 11:37:13.683: INFO: Waiting up to 5m0s for pod "execpodnh648" in namespace "services-9580" to be "running"
Nov 29 11:37:13.687: INFO: Pod "execpodnh648": Phase="Pending", Reason="", readiness=false. Elapsed: 3.451586ms
Nov 29 11:37:15.691: INFO: Pod "execpodnh648": Phase="Running", Reason="", readiness=true. Elapsed: 2.007290851s
Nov 29 11:37:15.691: INFO: Pod "execpodnh648" satisfied condition "running"
Nov 29 11:37:16.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-9580 exec execpodnh648 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Nov 29 11:37:16.829: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Nov 29 11:37:16.829: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:37:16.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-9580 exec execpodnh648 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.92.242 80'
Nov 29 11:37:16.962: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.92.242 80\nConnection to 100.65.92.242 80 port [tcp/http] succeeded!\n"
Nov 29 11:37:16.962: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:37:16.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-9580 exec execpodnh648 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Nov 29 11:37:17.118: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Nov 29 11:37:17.118: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 11:37:17.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-9580 exec execpodnh648 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.92.242 81'
Nov 29 11:37:17.253: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.92.242 81\nConnection to 100.65.92.242 81 port [tcp/*] succeeded!\n"
Nov 29 11:37:17.253: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-9580 11/29/22 11:37:17.253
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[pod2:[101]] 11/29/22 11:37:17.259
Nov 29 11:37:18.279: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-9580 11/29/22 11:37:18.279
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[] 11/29/22 11:37:18.289
Nov 29 11:37:18.301: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 11:37:18.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9580" for this suite. 11/29/22 11:37:18.337
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":51,"skipped":1093,"failed":0}
------------------------------
• [SLOW TEST] [8.766 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:37:09.576
    Nov 29 11:37:09.576: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 11:37:09.576
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:09.59
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:09.592
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-9580 11/29/22 11:37:09.594
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[] 11/29/22 11:37:09.611
    Nov 29 11:37:09.621: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-9580 11/29/22 11:37:09.621
    Nov 29 11:37:09.626: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9580" to be "running and ready"
    Nov 29 11:37:09.628: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10211ms
    Nov 29 11:37:09.628: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:37:11.632: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005797202s
    Nov 29 11:37:11.632: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 29 11:37:11.632: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[pod1:[100]] 11/29/22 11:37:11.634
    Nov 29 11:37:11.642: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-9580 11/29/22 11:37:11.642
    Nov 29 11:37:11.646: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9580" to be "running and ready"
    Nov 29 11:37:11.655: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.662927ms
    Nov 29 11:37:11.655: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:37:13.659: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012986252s
    Nov 29 11:37:13.659: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 29 11:37:13.659: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[pod1:[100] pod2:[101]] 11/29/22 11:37:13.664
    Nov 29 11:37:13.680: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 11/29/22 11:37:13.68
    Nov 29 11:37:13.680: INFO: Creating new exec pod
    Nov 29 11:37:13.683: INFO: Waiting up to 5m0s for pod "execpodnh648" in namespace "services-9580" to be "running"
    Nov 29 11:37:13.687: INFO: Pod "execpodnh648": Phase="Pending", Reason="", readiness=false. Elapsed: 3.451586ms
    Nov 29 11:37:15.691: INFO: Pod "execpodnh648": Phase="Running", Reason="", readiness=true. Elapsed: 2.007290851s
    Nov 29 11:37:15.691: INFO: Pod "execpodnh648" satisfied condition "running"
    Nov 29 11:37:16.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-9580 exec execpodnh648 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Nov 29 11:37:16.829: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Nov 29 11:37:16.829: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:37:16.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-9580 exec execpodnh648 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.92.242 80'
    Nov 29 11:37:16.962: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.92.242 80\nConnection to 100.65.92.242 80 port [tcp/http] succeeded!\n"
    Nov 29 11:37:16.962: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:37:16.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-9580 exec execpodnh648 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Nov 29 11:37:17.118: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Nov 29 11:37:17.118: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 11:37:17.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-9580 exec execpodnh648 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.92.242 81'
    Nov 29 11:37:17.253: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.92.242 81\nConnection to 100.65.92.242 81 port [tcp/*] succeeded!\n"
    Nov 29 11:37:17.253: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-9580 11/29/22 11:37:17.253
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[pod2:[101]] 11/29/22 11:37:17.259
    Nov 29 11:37:18.279: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-9580 11/29/22 11:37:18.279
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9580 to expose endpoints map[] 11/29/22 11:37:18.289
    Nov 29 11:37:18.301: INFO: successfully validated that service multi-endpoint-test in namespace services-9580 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 11:37:18.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9580" for this suite. 11/29/22 11:37:18.337
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:37:18.344
Nov 29 11:37:18.344: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename dns 11/29/22 11:37:18.345
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:18.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:18.389
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-542.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-542.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 11/29/22 11:37:18.393
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-542.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-542.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 11/29/22 11:37:18.393
STEP: creating a pod to probe /etc/hosts 11/29/22 11:37:18.393
STEP: submitting the pod to kubernetes 11/29/22 11:37:18.393
Nov 29 11:37:18.403: INFO: Waiting up to 15m0s for pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8" in namespace "dns-542" to be "running"
Nov 29 11:37:18.410: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.084408ms
Nov 29 11:37:20.413: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010163874s
Nov 29 11:37:22.416: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012273164s
Nov 29 11:37:24.413: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009940595s
Nov 29 11:37:26.415: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011592677s
Nov 29 11:37:28.413: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.009797958s
Nov 29 11:37:30.435: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031983852s
Nov 29 11:37:32.882: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.478398229s
Nov 29 11:37:34.414: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.010310432s
Nov 29 11:37:36.414: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.011017586s
Nov 29 11:37:38.414: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Running", Reason="", readiness=true. Elapsed: 20.011006052s
Nov 29 11:37:38.414: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8" satisfied condition "running"
STEP: retrieving the pod 11/29/22 11:37:38.414
STEP: looking for the results for each expected name from probers 11/29/22 11:37:38.417
Nov 29 11:37:38.428: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-542/dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8: the server could not find the requested resource (get pods dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8)
Nov 29 11:37:38.428: INFO: Lookups using dns-542/dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8 failed for: [jessie_hosts@dns-querier-1]

Nov 29 11:37:43.441: INFO: DNS probes using dns-542/dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8 succeeded

STEP: deleting the pod 11/29/22 11:37:43.441
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 29 11:37:43.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-542" for this suite. 11/29/22 11:37:43.456
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":52,"skipped":1114,"failed":0}
------------------------------
• [SLOW TEST] [25.117 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:37:18.344
    Nov 29 11:37:18.344: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename dns 11/29/22 11:37:18.345
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:18.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:18.389
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-542.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-542.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     11/29/22 11:37:18.393
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-542.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-542.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     11/29/22 11:37:18.393
    STEP: creating a pod to probe /etc/hosts 11/29/22 11:37:18.393
    STEP: submitting the pod to kubernetes 11/29/22 11:37:18.393
    Nov 29 11:37:18.403: INFO: Waiting up to 15m0s for pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8" in namespace "dns-542" to be "running"
    Nov 29 11:37:18.410: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.084408ms
    Nov 29 11:37:20.413: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010163874s
    Nov 29 11:37:22.416: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012273164s
    Nov 29 11:37:24.413: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009940595s
    Nov 29 11:37:26.415: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011592677s
    Nov 29 11:37:28.413: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.009797958s
    Nov 29 11:37:30.435: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031983852s
    Nov 29 11:37:32.882: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.478398229s
    Nov 29 11:37:34.414: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.010310432s
    Nov 29 11:37:36.414: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.011017586s
    Nov 29 11:37:38.414: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8": Phase="Running", Reason="", readiness=true. Elapsed: 20.011006052s
    Nov 29 11:37:38.414: INFO: Pod "dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 11:37:38.414
    STEP: looking for the results for each expected name from probers 11/29/22 11:37:38.417
    Nov 29 11:37:38.428: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-542/dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8: the server could not find the requested resource (get pods dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8)
    Nov 29 11:37:38.428: INFO: Lookups using dns-542/dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8 failed for: [jessie_hosts@dns-querier-1]

    Nov 29 11:37:43.441: INFO: DNS probes using dns-542/dns-test-e0a4e5a8-237c-4f51-9d9b-053d621d8ea8 succeeded

    STEP: deleting the pod 11/29/22 11:37:43.441
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 29 11:37:43.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-542" for this suite. 11/29/22 11:37:43.456
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:37:43.462
Nov 29 11:37:43.462: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 11:37:43.463
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:43.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:43.474
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-1324/configmap-test-4493b11c-2c32-4327-b3c6-2cfe9d8184b1 11/29/22 11:37:43.476
STEP: Creating a pod to test consume configMaps 11/29/22 11:37:43.479
Nov 29 11:37:43.516: INFO: Waiting up to 5m0s for pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088" in namespace "configmap-1324" to be "Succeeded or Failed"
Nov 29 11:37:43.520: INFO: Pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380205ms
Nov 29 11:37:45.524: INFO: Pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007666704s
Nov 29 11:37:47.523: INFO: Pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006287166s
STEP: Saw pod success 11/29/22 11:37:47.523
Nov 29 11:37:47.523: INFO: Pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088" satisfied condition "Succeeded or Failed"
Nov 29 11:37:47.525: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088 container env-test: <nil>
STEP: delete the pod 11/29/22 11:37:47.529
Nov 29 11:37:47.534: INFO: Waiting for pod pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088 to disappear
Nov 29 11:37:47.537: INFO: Pod pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 11:37:47.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1324" for this suite. 11/29/22 11:37:47.54
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":53,"skipped":1142,"failed":0}
------------------------------
• [4.080 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:37:43.462
    Nov 29 11:37:43.462: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 11:37:43.463
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:43.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:43.474
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-1324/configmap-test-4493b11c-2c32-4327-b3c6-2cfe9d8184b1 11/29/22 11:37:43.476
    STEP: Creating a pod to test consume configMaps 11/29/22 11:37:43.479
    Nov 29 11:37:43.516: INFO: Waiting up to 5m0s for pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088" in namespace "configmap-1324" to be "Succeeded or Failed"
    Nov 29 11:37:43.520: INFO: Pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380205ms
    Nov 29 11:37:45.524: INFO: Pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007666704s
    Nov 29 11:37:47.523: INFO: Pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006287166s
    STEP: Saw pod success 11/29/22 11:37:47.523
    Nov 29 11:37:47.523: INFO: Pod "pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088" satisfied condition "Succeeded or Failed"
    Nov 29 11:37:47.525: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088 container env-test: <nil>
    STEP: delete the pod 11/29/22 11:37:47.529
    Nov 29 11:37:47.534: INFO: Waiting for pod pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088 to disappear
    Nov 29 11:37:47.537: INFO: Pod pod-configmaps-fa0cc6ff-92d5-4ba2-93dc-e65f6ce7b088 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 11:37:47.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1324" for this suite. 11/29/22 11:37:47.54
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:37:47.543
Nov 29 11:37:47.543: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 11:37:47.544
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:47.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:47.556
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2061 11/29/22 11:37:47.558
STEP: changing the ExternalName service to type=ClusterIP 11/29/22 11:37:47.56
STEP: creating replication controller externalname-service in namespace services-2061 11/29/22 11:37:47.569
I1129 11:37:47.573740      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-2061, replica count: 2
I1129 11:37:50.624131      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 11:37:50.624: INFO: Creating new exec pod
Nov 29 11:37:50.627: INFO: Waiting up to 5m0s for pod "execpods6wmp" in namespace "services-2061" to be "running"
Nov 29 11:37:50.632: INFO: Pod "execpods6wmp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.680439ms
Nov 29 11:37:52.639: INFO: Pod "execpods6wmp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011360347s
Nov 29 11:37:52.639: INFO: Pod "execpods6wmp" satisfied condition "running"
Nov 29 11:37:53.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2061 exec execpods6wmp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 29 11:37:53.757: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 29 11:37:53.757: INFO: stdout: ""
Nov 29 11:37:54.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2061 exec execpods6wmp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 29 11:37:54.877: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 29 11:37:54.877: INFO: stdout: ""
Nov 29 11:37:55.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2061 exec execpods6wmp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 29 11:37:55.885: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 29 11:37:55.885: INFO: stdout: "externalname-service-psr6c"
Nov 29 11:37:55.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2061 exec execpods6wmp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.99.121 80'
Nov 29 11:37:56.004: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.99.121 80\nConnection to 100.67.99.121 80 port [tcp/http] succeeded!\n"
Nov 29 11:37:56.004: INFO: stdout: "externalname-service-psr6c"
Nov 29 11:37:56.004: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 11:37:56.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2061" for this suite. 11/29/22 11:37:56.02
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":54,"skipped":1160,"failed":0}
------------------------------
• [SLOW TEST] [8.480 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:37:47.543
    Nov 29 11:37:47.543: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 11:37:47.544
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:47.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:47.556
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-2061 11/29/22 11:37:47.558
    STEP: changing the ExternalName service to type=ClusterIP 11/29/22 11:37:47.56
    STEP: creating replication controller externalname-service in namespace services-2061 11/29/22 11:37:47.569
    I1129 11:37:47.573740      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-2061, replica count: 2
    I1129 11:37:50.624131      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 11:37:50.624: INFO: Creating new exec pod
    Nov 29 11:37:50.627: INFO: Waiting up to 5m0s for pod "execpods6wmp" in namespace "services-2061" to be "running"
    Nov 29 11:37:50.632: INFO: Pod "execpods6wmp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.680439ms
    Nov 29 11:37:52.639: INFO: Pod "execpods6wmp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011360347s
    Nov 29 11:37:52.639: INFO: Pod "execpods6wmp" satisfied condition "running"
    Nov 29 11:37:53.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2061 exec execpods6wmp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 29 11:37:53.757: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 29 11:37:53.757: INFO: stdout: ""
    Nov 29 11:37:54.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2061 exec execpods6wmp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 29 11:37:54.877: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 29 11:37:54.877: INFO: stdout: ""
    Nov 29 11:37:55.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2061 exec execpods6wmp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 29 11:37:55.885: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 29 11:37:55.885: INFO: stdout: "externalname-service-psr6c"
    Nov 29 11:37:55.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-2061 exec execpods6wmp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.99.121 80'
    Nov 29 11:37:56.004: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.99.121 80\nConnection to 100.67.99.121 80 port [tcp/http] succeeded!\n"
    Nov 29 11:37:56.004: INFO: stdout: "externalname-service-psr6c"
    Nov 29 11:37:56.004: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 11:37:56.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2061" for this suite. 11/29/22 11:37:56.02
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:37:56.024
Nov 29 11:37:56.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 11:37:56.025
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:56.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:56.035
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 11/29/22 11:37:56.037
Nov 29 11:37:56.041: INFO: Waiting up to 5m0s for pod "pod-08d555d2-1726-43fa-9820-969f12c30c49" in namespace "emptydir-736" to be "Succeeded or Failed"
Nov 29 11:37:56.043: INFO: Pod "pod-08d555d2-1726-43fa-9820-969f12c30c49": Phase="Pending", Reason="", readiness=false. Elapsed: 1.931506ms
Nov 29 11:37:58.046: INFO: Pod "pod-08d555d2-1726-43fa-9820-969f12c30c49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005226386s
Nov 29 11:38:00.046: INFO: Pod "pod-08d555d2-1726-43fa-9820-969f12c30c49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005596392s
STEP: Saw pod success 11/29/22 11:38:00.046
Nov 29 11:38:00.047: INFO: Pod "pod-08d555d2-1726-43fa-9820-969f12c30c49" satisfied condition "Succeeded or Failed"
Nov 29 11:38:00.048: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-08d555d2-1726-43fa-9820-969f12c30c49 container test-container: <nil>
STEP: delete the pod 11/29/22 11:38:00.052
Nov 29 11:38:00.060: INFO: Waiting for pod pod-08d555d2-1726-43fa-9820-969f12c30c49 to disappear
Nov 29 11:38:00.062: INFO: Pod pod-08d555d2-1726-43fa-9820-969f12c30c49 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 11:38:00.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-736" for this suite. 11/29/22 11:38:00.065
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":55,"skipped":1174,"failed":0}
------------------------------
• [4.045 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:37:56.024
    Nov 29 11:37:56.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 11:37:56.025
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:37:56.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:37:56.035
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/29/22 11:37:56.037
    Nov 29 11:37:56.041: INFO: Waiting up to 5m0s for pod "pod-08d555d2-1726-43fa-9820-969f12c30c49" in namespace "emptydir-736" to be "Succeeded or Failed"
    Nov 29 11:37:56.043: INFO: Pod "pod-08d555d2-1726-43fa-9820-969f12c30c49": Phase="Pending", Reason="", readiness=false. Elapsed: 1.931506ms
    Nov 29 11:37:58.046: INFO: Pod "pod-08d555d2-1726-43fa-9820-969f12c30c49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005226386s
    Nov 29 11:38:00.046: INFO: Pod "pod-08d555d2-1726-43fa-9820-969f12c30c49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005596392s
    STEP: Saw pod success 11/29/22 11:38:00.046
    Nov 29 11:38:00.047: INFO: Pod "pod-08d555d2-1726-43fa-9820-969f12c30c49" satisfied condition "Succeeded or Failed"
    Nov 29 11:38:00.048: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-08d555d2-1726-43fa-9820-969f12c30c49 container test-container: <nil>
    STEP: delete the pod 11/29/22 11:38:00.052
    Nov 29 11:38:00.060: INFO: Waiting for pod pod-08d555d2-1726-43fa-9820-969f12c30c49 to disappear
    Nov 29 11:38:00.062: INFO: Pod pod-08d555d2-1726-43fa-9820-969f12c30c49 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 11:38:00.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-736" for this suite. 11/29/22 11:38:00.065
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:38:00.069
Nov 29 11:38:00.069: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 11:38:00.069
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:00.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:00.081
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 11/29/22 11:38:00.083
Nov 29 11:38:00.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-3276 create -f -'
Nov 29 11:38:00.306: INFO: stderr: ""
Nov 29 11:38:00.306: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/29/22 11:38:00.306
Nov 29 11:38:01.311: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 11:38:01.311: INFO: Found 0 / 1
Nov 29 11:38:02.310: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 11:38:02.310: INFO: Found 1 / 1
Nov 29 11:38:02.310: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 11/29/22 11:38:02.31
Nov 29 11:38:02.319: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 11:38:02.319: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 29 11:38:02.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-3276 patch pod agnhost-primary-wjnd4 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 29 11:38:02.396: INFO: stderr: ""
Nov 29 11:38:02.396: INFO: stdout: "pod/agnhost-primary-wjnd4 patched\n"
STEP: checking annotations 11/29/22 11:38:02.396
Nov 29 11:38:02.401: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 11:38:02.401: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 11:38:02.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3276" for this suite. 11/29/22 11:38:02.403
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":56,"skipped":1176,"failed":0}
------------------------------
• [2.338 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:38:00.069
    Nov 29 11:38:00.069: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 11:38:00.069
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:00.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:00.081
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 11/29/22 11:38:00.083
    Nov 29 11:38:00.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-3276 create -f -'
    Nov 29 11:38:00.306: INFO: stderr: ""
    Nov 29 11:38:00.306: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/29/22 11:38:00.306
    Nov 29 11:38:01.311: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 11:38:01.311: INFO: Found 0 / 1
    Nov 29 11:38:02.310: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 11:38:02.310: INFO: Found 1 / 1
    Nov 29 11:38:02.310: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 11/29/22 11:38:02.31
    Nov 29 11:38:02.319: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 11:38:02.319: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 29 11:38:02.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-3276 patch pod agnhost-primary-wjnd4 -p {"metadata":{"annotations":{"x":"y"}}}'
    Nov 29 11:38:02.396: INFO: stderr: ""
    Nov 29 11:38:02.396: INFO: stdout: "pod/agnhost-primary-wjnd4 patched\n"
    STEP: checking annotations 11/29/22 11:38:02.396
    Nov 29 11:38:02.401: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 11:38:02.401: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 11:38:02.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3276" for this suite. 11/29/22 11:38:02.403
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:38:02.407
Nov 29 11:38:02.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:38:02.408
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:02.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:02.419
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 11/29/22 11:38:02.422
Nov 29 11:38:02.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348" in namespace "projected-8974" to be "Succeeded or Failed"
Nov 29 11:38:02.433: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348": Phase="Pending", Reason="", readiness=false. Elapsed: 4.141425ms
Nov 29 11:38:04.437: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348": Phase="Running", Reason="", readiness=true. Elapsed: 2.008510626s
Nov 29 11:38:06.437: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348": Phase="Running", Reason="", readiness=false. Elapsed: 4.008192908s
Nov 29 11:38:08.436: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006945871s
STEP: Saw pod success 11/29/22 11:38:08.436
Nov 29 11:38:08.436: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348" satisfied condition "Succeeded or Failed"
Nov 29 11:38:08.438: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348 container client-container: <nil>
STEP: delete the pod 11/29/22 11:38:08.444
Nov 29 11:38:08.450: INFO: Waiting for pod downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348 to disappear
Nov 29 11:38:08.451: INFO: Pod downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 11:38:08.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8974" for this suite. 11/29/22 11:38:08.455
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":57,"skipped":1180,"failed":0}
------------------------------
• [SLOW TEST] [6.051 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:38:02.407
    Nov 29 11:38:02.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:38:02.408
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:02.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:02.419
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 11/29/22 11:38:02.422
    Nov 29 11:38:02.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348" in namespace "projected-8974" to be "Succeeded or Failed"
    Nov 29 11:38:02.433: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348": Phase="Pending", Reason="", readiness=false. Elapsed: 4.141425ms
    Nov 29 11:38:04.437: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348": Phase="Running", Reason="", readiness=true. Elapsed: 2.008510626s
    Nov 29 11:38:06.437: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348": Phase="Running", Reason="", readiness=false. Elapsed: 4.008192908s
    Nov 29 11:38:08.436: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006945871s
    STEP: Saw pod success 11/29/22 11:38:08.436
    Nov 29 11:38:08.436: INFO: Pod "downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348" satisfied condition "Succeeded or Failed"
    Nov 29 11:38:08.438: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348 container client-container: <nil>
    STEP: delete the pod 11/29/22 11:38:08.444
    Nov 29 11:38:08.450: INFO: Waiting for pod downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348 to disappear
    Nov 29 11:38:08.451: INFO: Pod downwardapi-volume-8c807770-2c9c-4df9-b8f0-07f117ec0348 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 11:38:08.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8974" for this suite. 11/29/22 11:38:08.455
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:38:08.458
Nov 29 11:38:08.458: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 11:38:08.459
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:08.467
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:08.469
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 11/29/22 11:38:08.471
Nov 29 11:38:08.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 create -f -'
Nov 29 11:38:08.703: INFO: stderr: ""
Nov 29 11:38:08.704: INFO: stdout: "pod/pause created\n"
Nov 29 11:38:08.704: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 29 11:38:08.704: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6414" to be "running and ready"
Nov 29 11:38:08.706: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092317ms
Nov 29 11:38:08.706: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'dvi-7336-1669718118-vsp1-group1-2' to be 'Running' but was 'Pending'
Nov 29 11:38:10.709: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004888469s
Nov 29 11:38:10.709: INFO: Pod "pause" satisfied condition "running and ready"
Nov 29 11:38:10.709: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 11/29/22 11:38:10.709
Nov 29 11:38:10.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 label pods pause testing-label=testing-label-value'
Nov 29 11:38:10.778: INFO: stderr: ""
Nov 29 11:38:10.778: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 11/29/22 11:38:10.778
Nov 29 11:38:10.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 get pod pause -L testing-label'
Nov 29 11:38:10.839: INFO: stderr: ""
Nov 29 11:38:10.839: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 11/29/22 11:38:10.839
Nov 29 11:38:10.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 label pods pause testing-label-'
Nov 29 11:38:10.908: INFO: stderr: ""
Nov 29 11:38:10.908: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 11/29/22 11:38:10.908
Nov 29 11:38:10.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 get pod pause -L testing-label'
Nov 29 11:38:10.966: INFO: stderr: ""
Nov 29 11:38:10.966: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 11/29/22 11:38:10.966
Nov 29 11:38:10.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 delete --grace-period=0 --force -f -'
Nov 29 11:38:11.034: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 11:38:11.034: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 29 11:38:11.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 get rc,svc -l name=pause --no-headers'
Nov 29 11:38:11.106: INFO: stderr: "No resources found in kubectl-6414 namespace.\n"
Nov 29 11:38:11.106: INFO: stdout: ""
Nov 29 11:38:11.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 29 11:38:11.170: INFO: stderr: ""
Nov 29 11:38:11.170: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 11:38:11.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6414" for this suite. 11/29/22 11:38:11.174
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":58,"skipped":1185,"failed":0}
------------------------------
• [2.719 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:38:08.458
    Nov 29 11:38:08.458: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 11:38:08.459
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:08.467
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:08.469
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 11/29/22 11:38:08.471
    Nov 29 11:38:08.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 create -f -'
    Nov 29 11:38:08.703: INFO: stderr: ""
    Nov 29 11:38:08.704: INFO: stdout: "pod/pause created\n"
    Nov 29 11:38:08.704: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Nov 29 11:38:08.704: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6414" to be "running and ready"
    Nov 29 11:38:08.706: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092317ms
    Nov 29 11:38:08.706: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'dvi-7336-1669718118-vsp1-group1-2' to be 'Running' but was 'Pending'
    Nov 29 11:38:10.709: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004888469s
    Nov 29 11:38:10.709: INFO: Pod "pause" satisfied condition "running and ready"
    Nov 29 11:38:10.709: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 11/29/22 11:38:10.709
    Nov 29 11:38:10.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 label pods pause testing-label=testing-label-value'
    Nov 29 11:38:10.778: INFO: stderr: ""
    Nov 29 11:38:10.778: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 11/29/22 11:38:10.778
    Nov 29 11:38:10.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 get pod pause -L testing-label'
    Nov 29 11:38:10.839: INFO: stderr: ""
    Nov 29 11:38:10.839: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 11/29/22 11:38:10.839
    Nov 29 11:38:10.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 label pods pause testing-label-'
    Nov 29 11:38:10.908: INFO: stderr: ""
    Nov 29 11:38:10.908: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 11/29/22 11:38:10.908
    Nov 29 11:38:10.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 get pod pause -L testing-label'
    Nov 29 11:38:10.966: INFO: stderr: ""
    Nov 29 11:38:10.966: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 11/29/22 11:38:10.966
    Nov 29 11:38:10.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 delete --grace-period=0 --force -f -'
    Nov 29 11:38:11.034: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 11:38:11.034: INFO: stdout: "pod \"pause\" force deleted\n"
    Nov 29 11:38:11.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 get rc,svc -l name=pause --no-headers'
    Nov 29 11:38:11.106: INFO: stderr: "No resources found in kubectl-6414 namespace.\n"
    Nov 29 11:38:11.106: INFO: stdout: ""
    Nov 29 11:38:11.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6414 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 29 11:38:11.170: INFO: stderr: ""
    Nov 29 11:38:11.170: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 11:38:11.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6414" for this suite. 11/29/22 11:38:11.174
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:38:11.179
Nov 29 11:38:11.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubelet-test 11/29/22 11:38:11.179
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:11.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:11.191
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 11/29/22 11:38:11.198
Nov 29 11:38:11.199: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33" in namespace "kubelet-test-6092" to be "completed"
Nov 29 11:38:11.201: INFO: Pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.618355ms
Nov 29 11:38:13.204: INFO: Pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005540398s
Nov 29 11:38:15.204: INFO: Pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005853282s
Nov 29 11:38:15.205: INFO: Pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 29 11:38:15.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6092" for this suite. 11/29/22 11:38:15.213
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":59,"skipped":1205,"failed":0}
------------------------------
• [4.038 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:38:11.179
    Nov 29 11:38:11.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubelet-test 11/29/22 11:38:11.179
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:11.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:11.191
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 11/29/22 11:38:11.198
    Nov 29 11:38:11.199: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33" in namespace "kubelet-test-6092" to be "completed"
    Nov 29 11:38:11.201: INFO: Pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.618355ms
    Nov 29 11:38:13.204: INFO: Pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005540398s
    Nov 29 11:38:15.204: INFO: Pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005853282s
    Nov 29 11:38:15.205: INFO: Pod "agnhost-host-aliases9338c70c-41a3-4ef5-b2ac-037ae25cce33" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 29 11:38:15.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6092" for this suite. 11/29/22 11:38:15.213
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:38:15.22
Nov 29 11:38:15.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename cronjob 11/29/22 11:38:15.221
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:15.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:15.233
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 11/29/22 11:38:15.236
STEP: Ensuring no jobs are scheduled 11/29/22 11:38:15.239
STEP: Ensuring no job exists by listing jobs explicitly 11/29/22 11:43:15.244
STEP: Removing cronjob 11/29/22 11:43:15.246
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 29 11:43:15.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5154" for this suite. 11/29/22 11:43:15.251
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":60,"skipped":1232,"failed":0}
------------------------------
• [SLOW TEST] [300.034 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:38:15.22
    Nov 29 11:38:15.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename cronjob 11/29/22 11:38:15.221
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:38:15.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:38:15.233
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 11/29/22 11:38:15.236
    STEP: Ensuring no jobs are scheduled 11/29/22 11:38:15.239
    STEP: Ensuring no job exists by listing jobs explicitly 11/29/22 11:43:15.244
    STEP: Removing cronjob 11/29/22 11:43:15.246
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 29 11:43:15.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5154" for this suite. 11/29/22 11:43:15.251
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:43:15.257
Nov 29 11:43:15.257: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename limitrange 11/29/22 11:43:15.258
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:15.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:15.269
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 11/29/22 11:43:15.271
STEP: Setting up watch 11/29/22 11:43:15.271
STEP: Submitting a LimitRange 11/29/22 11:43:15.373
STEP: Verifying LimitRange creation was observed 11/29/22 11:43:15.379
STEP: Fetching the LimitRange to ensure it has proper values 11/29/22 11:43:15.379
Nov 29 11:43:15.454: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 29 11:43:15.454: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 11/29/22 11:43:15.454
STEP: Ensuring Pod has resource requirements applied from LimitRange 11/29/22 11:43:15.466
Nov 29 11:43:15.470: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 29 11:43:15.470: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 11/29/22 11:43:15.47
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/29/22 11:43:15.55
Nov 29 11:43:15.554: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Nov 29 11:43:15.554: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 11/29/22 11:43:15.554
STEP: Failing to create a Pod with more than max resources 11/29/22 11:43:15.556
STEP: Updating a LimitRange 11/29/22 11:43:15.558
STEP: Verifying LimitRange updating is effective 11/29/22 11:43:15.567
STEP: Creating a Pod with less than former min resources 11/29/22 11:43:17.57
STEP: Failing to create a Pod with more than max resources 11/29/22 11:43:17.575
STEP: Deleting a LimitRange 11/29/22 11:43:17.577
STEP: Verifying the LimitRange was deleted 11/29/22 11:43:17.582
Nov 29 11:43:22.587: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 11/29/22 11:43:22.587
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Nov 29 11:43:22.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-8947" for this suite. 11/29/22 11:43:22.597
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":61,"skipped":1241,"failed":0}
------------------------------
• [SLOW TEST] [7.344 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:43:15.257
    Nov 29 11:43:15.257: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename limitrange 11/29/22 11:43:15.258
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:15.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:15.269
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 11/29/22 11:43:15.271
    STEP: Setting up watch 11/29/22 11:43:15.271
    STEP: Submitting a LimitRange 11/29/22 11:43:15.373
    STEP: Verifying LimitRange creation was observed 11/29/22 11:43:15.379
    STEP: Fetching the LimitRange to ensure it has proper values 11/29/22 11:43:15.379
    Nov 29 11:43:15.454: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov 29 11:43:15.454: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 11/29/22 11:43:15.454
    STEP: Ensuring Pod has resource requirements applied from LimitRange 11/29/22 11:43:15.466
    Nov 29 11:43:15.470: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov 29 11:43:15.470: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 11/29/22 11:43:15.47
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/29/22 11:43:15.55
    Nov 29 11:43:15.554: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Nov 29 11:43:15.554: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 11/29/22 11:43:15.554
    STEP: Failing to create a Pod with more than max resources 11/29/22 11:43:15.556
    STEP: Updating a LimitRange 11/29/22 11:43:15.558
    STEP: Verifying LimitRange updating is effective 11/29/22 11:43:15.567
    STEP: Creating a Pod with less than former min resources 11/29/22 11:43:17.57
    STEP: Failing to create a Pod with more than max resources 11/29/22 11:43:17.575
    STEP: Deleting a LimitRange 11/29/22 11:43:17.577
    STEP: Verifying the LimitRange was deleted 11/29/22 11:43:17.582
    Nov 29 11:43:22.587: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 11/29/22 11:43:22.587
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Nov 29 11:43:22.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-8947" for this suite. 11/29/22 11:43:22.597
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:43:22.605
Nov 29 11:43:22.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename deployment 11/29/22 11:43:22.606
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:22.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:22.618
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Nov 29 11:43:22.621: INFO: Creating simple deployment test-new-deployment
Nov 29 11:43:22.629: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
STEP: getting scale subresource 11/29/22 11:43:24.638
STEP: updating a scale subresource 11/29/22 11:43:24.64
STEP: verifying the deployment Spec.Replicas was modified 11/29/22 11:43:24.643
STEP: Patch a scale subresource 11/29/22 11:43:24.646
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 29 11:43:24.666: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-3784  61b92e2c-8c9b-49ef-802d-5d5e1f650ebc 11772 3 2022-11-29 11:43:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-29 11:43:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032e6958 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-29 11:43:24 +0000 UTC,LastTransitionTime:2022-11-29 11:43:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-29 11:43:24 +0000 UTC,LastTransitionTime:2022-11-29 11:43:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 29 11:43:24.671: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-3784  48b507f1-0c3d-4de4-a5cf-e1bbf7510b18 11776 2 2022-11-29 11:43:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 61b92e2c-8c9b-49ef-802d-5d5e1f650ebc 0xc0045112f7 0xc0045112f8}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"61b92e2c-8c9b-49ef-802d-5d5e1f650ebc\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004511388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 29 11:43:24.674: INFO: Pod "test-new-deployment-845c8977d9-7w9bs" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-7w9bs test-new-deployment-845c8977d9- deployment-3784  d8f977c5-f708-4ea0-ba82-3f87677510d0 11765 0 2022-11-29 11:43:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3315ad57398d5865d09eda7734f0f218e177f5086481958a01d135b5fcd1bc17 cni.projectcalico.org/podIP:100.96.2.76/32 cni.projectcalico.org/podIPs:100.96.2.76/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 48b507f1-0c3d-4de4-a5cf-e1bbf7510b18 0xc0045117c7 0xc0045117c8}] [] [{kube-controller-manager Update v1 2022-11-29 11:43:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48b507f1-0c3d-4de4-a5cf-e1bbf7510b18\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 11:43:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.76\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cmbxd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cmbxd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.76,StartTime:2022-11-29 11:43:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 11:43:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3ddadcfc37f269f5a50c17e582a6679e8604ebb3f216c8f323ba3e00413b5d40,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.76,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 11:43:24.674: INFO: Pod "test-new-deployment-845c8977d9-lnm6c" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-lnm6c test-new-deployment-845c8977d9- deployment-3784  97955145-f77d-4392-aca3-6ee2406fe6a8 11777 0 2022-11-29 11:43:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 48b507f1-0c3d-4de4-a5cf-e1bbf7510b18 0xc0045119c0 0xc0045119c1}] [] [{kube-controller-manager Update v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48b507f1-0c3d-4de4-a5cf-e1bbf7510b18\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vbwmf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vbwmf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 29 11:43:24.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3784" for this suite. 11/29/22 11:43:24.678
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":62,"skipped":1305,"failed":0}
------------------------------
• [2.084 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:43:22.605
    Nov 29 11:43:22.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename deployment 11/29/22 11:43:22.606
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:22.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:22.618
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Nov 29 11:43:22.621: INFO: Creating simple deployment test-new-deployment
    Nov 29 11:43:22.629: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
    STEP: getting scale subresource 11/29/22 11:43:24.638
    STEP: updating a scale subresource 11/29/22 11:43:24.64
    STEP: verifying the deployment Spec.Replicas was modified 11/29/22 11:43:24.643
    STEP: Patch a scale subresource 11/29/22 11:43:24.646
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 29 11:43:24.666: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-3784  61b92e2c-8c9b-49ef-802d-5d5e1f650ebc 11772 3 2022-11-29 11:43:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-29 11:43:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032e6958 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-29 11:43:24 +0000 UTC,LastTransitionTime:2022-11-29 11:43:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-29 11:43:24 +0000 UTC,LastTransitionTime:2022-11-29 11:43:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 29 11:43:24.671: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-3784  48b507f1-0c3d-4de4-a5cf-e1bbf7510b18 11776 2 2022-11-29 11:43:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 61b92e2c-8c9b-49ef-802d-5d5e1f650ebc 0xc0045112f7 0xc0045112f8}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"61b92e2c-8c9b-49ef-802d-5d5e1f650ebc\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004511388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 11:43:24.674: INFO: Pod "test-new-deployment-845c8977d9-7w9bs" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-7w9bs test-new-deployment-845c8977d9- deployment-3784  d8f977c5-f708-4ea0-ba82-3f87677510d0 11765 0 2022-11-29 11:43:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3315ad57398d5865d09eda7734f0f218e177f5086481958a01d135b5fcd1bc17 cni.projectcalico.org/podIP:100.96.2.76/32 cni.projectcalico.org/podIPs:100.96.2.76/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 48b507f1-0c3d-4de4-a5cf-e1bbf7510b18 0xc0045117c7 0xc0045117c8}] [] [{kube-controller-manager Update v1 2022-11-29 11:43:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48b507f1-0c3d-4de4-a5cf-e1bbf7510b18\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 11:43:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.76\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cmbxd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cmbxd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.76,StartTime:2022-11-29 11:43:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 11:43:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3ddadcfc37f269f5a50c17e582a6679e8604ebb3f216c8f323ba3e00413b5d40,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.76,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 11:43:24.674: INFO: Pod "test-new-deployment-845c8977d9-lnm6c" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-lnm6c test-new-deployment-845c8977d9- deployment-3784  97955145-f77d-4392-aca3-6ee2406fe6a8 11777 0 2022-11-29 11:43:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 48b507f1-0c3d-4de4-a5cf-e1bbf7510b18 0xc0045119c0 0xc0045119c1}] [] [{kube-controller-manager Update v1 2022-11-29 11:43:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48b507f1-0c3d-4de4-a5cf-e1bbf7510b18\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vbwmf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vbwmf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:43:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 29 11:43:24.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3784" for this suite. 11/29/22 11:43:24.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:43:24.69
Nov 29 11:43:24.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:43:24.691
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:24.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:24.708
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-c3d434dd-1d5c-4900-8e89-be4fdef36f5e 11/29/22 11:43:24.71
STEP: Creating a pod to test consume configMaps 11/29/22 11:43:24.715
Nov 29 11:43:24.726: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74" in namespace "projected-5745" to be "Succeeded or Failed"
Nov 29 11:43:24.733: INFO: Pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74": Phase="Pending", Reason="", readiness=false. Elapsed: 6.8983ms
Nov 29 11:43:26.737: INFO: Pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010504106s
Nov 29 11:43:28.736: INFO: Pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010310813s
STEP: Saw pod success 11/29/22 11:43:28.736
Nov 29 11:43:28.736: INFO: Pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74" satisfied condition "Succeeded or Failed"
Nov 29 11:43:28.738: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 11:43:28.745
Nov 29 11:43:28.753: INFO: Waiting for pod pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74 to disappear
Nov 29 11:43:28.755: INFO: Pod pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 11:43:28.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5745" for this suite. 11/29/22 11:43:28.759
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":63,"skipped":1319,"failed":0}
------------------------------
• [4.072 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:43:24.69
    Nov 29 11:43:24.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:43:24.691
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:24.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:24.708
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-c3d434dd-1d5c-4900-8e89-be4fdef36f5e 11/29/22 11:43:24.71
    STEP: Creating a pod to test consume configMaps 11/29/22 11:43:24.715
    Nov 29 11:43:24.726: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74" in namespace "projected-5745" to be "Succeeded or Failed"
    Nov 29 11:43:24.733: INFO: Pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74": Phase="Pending", Reason="", readiness=false. Elapsed: 6.8983ms
    Nov 29 11:43:26.737: INFO: Pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010504106s
    Nov 29 11:43:28.736: INFO: Pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010310813s
    STEP: Saw pod success 11/29/22 11:43:28.736
    Nov 29 11:43:28.736: INFO: Pod "pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74" satisfied condition "Succeeded or Failed"
    Nov 29 11:43:28.738: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 11:43:28.745
    Nov 29 11:43:28.753: INFO: Waiting for pod pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74 to disappear
    Nov 29 11:43:28.755: INFO: Pod pod-projected-configmaps-c09eef37-cf9b-4b41-9eba-19a900e80e74 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 11:43:28.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5745" for this suite. 11/29/22 11:43:28.759
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:43:28.765
Nov 29 11:43:28.765: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:43:28.766
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:28.774
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:28.775
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Nov 29 11:43:28.786: INFO: created pod pod-service-account-defaultsa
Nov 29 11:43:28.786: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 29 11:43:28.790: INFO: created pod pod-service-account-mountsa
Nov 29 11:43:28.790: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 29 11:43:28.796: INFO: created pod pod-service-account-nomountsa
Nov 29 11:43:28.796: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 29 11:43:28.801: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 29 11:43:28.801: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 29 11:43:28.806: INFO: created pod pod-service-account-mountsa-mountspec
Nov 29 11:43:28.806: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 29 11:43:28.814: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 29 11:43:28.814: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 29 11:43:28.818: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 29 11:43:28.818: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 29 11:43:28.826: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 29 11:43:28.826: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 29 11:43:28.844: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 29 11:43:28.844: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 29 11:43:28.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6441" for this suite. 11/29/22 11:43:28.851
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":64,"skipped":1342,"failed":0}
------------------------------
• [0.097 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:43:28.765
    Nov 29 11:43:28.765: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:43:28.766
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:28.774
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:28.775
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Nov 29 11:43:28.786: INFO: created pod pod-service-account-defaultsa
    Nov 29 11:43:28.786: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Nov 29 11:43:28.790: INFO: created pod pod-service-account-mountsa
    Nov 29 11:43:28.790: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Nov 29 11:43:28.796: INFO: created pod pod-service-account-nomountsa
    Nov 29 11:43:28.796: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Nov 29 11:43:28.801: INFO: created pod pod-service-account-defaultsa-mountspec
    Nov 29 11:43:28.801: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Nov 29 11:43:28.806: INFO: created pod pod-service-account-mountsa-mountspec
    Nov 29 11:43:28.806: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Nov 29 11:43:28.814: INFO: created pod pod-service-account-nomountsa-mountspec
    Nov 29 11:43:28.814: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Nov 29 11:43:28.818: INFO: created pod pod-service-account-defaultsa-nomountspec
    Nov 29 11:43:28.818: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Nov 29 11:43:28.826: INFO: created pod pod-service-account-mountsa-nomountspec
    Nov 29 11:43:28.826: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Nov 29 11:43:28.844: INFO: created pod pod-service-account-nomountsa-nomountspec
    Nov 29 11:43:28.844: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 29 11:43:28.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6441" for this suite. 11/29/22 11:43:28.851
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:43:28.863
Nov 29 11:43:28.863: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename subpath 11/29/22 11:43:28.864
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:28.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:28.881
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/29/22 11:43:28.884
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-d5r5 11/29/22 11:43:28.89
STEP: Creating a pod to test atomic-volume-subpath 11/29/22 11:43:28.891
Nov 29 11:43:28.897: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-d5r5" in namespace "subpath-1604" to be "Succeeded or Failed"
Nov 29 11:43:28.900: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.677189ms
Nov 29 11:43:30.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005684705s
Nov 29 11:43:32.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 4.005551828s
Nov 29 11:43:34.904: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 6.006557644s
Nov 29 11:43:36.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 8.006401558s
Nov 29 11:43:38.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 10.006052735s
Nov 29 11:43:40.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 12.006063035s
Nov 29 11:43:42.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 14.00636093s
Nov 29 11:43:44.904: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 16.007144219s
Nov 29 11:43:46.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 18.00590069s
Nov 29 11:43:48.904: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 20.006645216s
Nov 29 11:43:50.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 22.005965883s
Nov 29 11:43:52.904: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=false. Elapsed: 24.006685213s
Nov 29 11:43:54.905: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.007803413s
STEP: Saw pod success 11/29/22 11:43:54.905
Nov 29 11:43:54.905: INFO: Pod "pod-subpath-test-projected-d5r5" satisfied condition "Succeeded or Failed"
Nov 29 11:43:54.907: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-subpath-test-projected-d5r5 container test-container-subpath-projected-d5r5: <nil>
STEP: delete the pod 11/29/22 11:43:54.911
Nov 29 11:43:54.918: INFO: Waiting for pod pod-subpath-test-projected-d5r5 to disappear
Nov 29 11:43:54.921: INFO: Pod pod-subpath-test-projected-d5r5 no longer exists
STEP: Deleting pod pod-subpath-test-projected-d5r5 11/29/22 11:43:54.921
Nov 29 11:43:54.922: INFO: Deleting pod "pod-subpath-test-projected-d5r5" in namespace "subpath-1604"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 29 11:43:54.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1604" for this suite. 11/29/22 11:43:54.926
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":65,"skipped":1360,"failed":0}
------------------------------
• [SLOW TEST] [26.066 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:43:28.863
    Nov 29 11:43:28.863: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename subpath 11/29/22 11:43:28.864
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:28.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:28.881
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/29/22 11:43:28.884
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-d5r5 11/29/22 11:43:28.89
    STEP: Creating a pod to test atomic-volume-subpath 11/29/22 11:43:28.891
    Nov 29 11:43:28.897: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-d5r5" in namespace "subpath-1604" to be "Succeeded or Failed"
    Nov 29 11:43:28.900: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.677189ms
    Nov 29 11:43:30.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005684705s
    Nov 29 11:43:32.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 4.005551828s
    Nov 29 11:43:34.904: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 6.006557644s
    Nov 29 11:43:36.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 8.006401558s
    Nov 29 11:43:38.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 10.006052735s
    Nov 29 11:43:40.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 12.006063035s
    Nov 29 11:43:42.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 14.00636093s
    Nov 29 11:43:44.904: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 16.007144219s
    Nov 29 11:43:46.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 18.00590069s
    Nov 29 11:43:48.904: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 20.006645216s
    Nov 29 11:43:50.903: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=true. Elapsed: 22.005965883s
    Nov 29 11:43:52.904: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Running", Reason="", readiness=false. Elapsed: 24.006685213s
    Nov 29 11:43:54.905: INFO: Pod "pod-subpath-test-projected-d5r5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.007803413s
    STEP: Saw pod success 11/29/22 11:43:54.905
    Nov 29 11:43:54.905: INFO: Pod "pod-subpath-test-projected-d5r5" satisfied condition "Succeeded or Failed"
    Nov 29 11:43:54.907: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-subpath-test-projected-d5r5 container test-container-subpath-projected-d5r5: <nil>
    STEP: delete the pod 11/29/22 11:43:54.911
    Nov 29 11:43:54.918: INFO: Waiting for pod pod-subpath-test-projected-d5r5 to disappear
    Nov 29 11:43:54.921: INFO: Pod pod-subpath-test-projected-d5r5 no longer exists
    STEP: Deleting pod pod-subpath-test-projected-d5r5 11/29/22 11:43:54.921
    Nov 29 11:43:54.922: INFO: Deleting pod "pod-subpath-test-projected-d5r5" in namespace "subpath-1604"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 29 11:43:54.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1604" for this suite. 11/29/22 11:43:54.926
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:43:54.929
Nov 29 11:43:54.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 11:43:54.93
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:54.953
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:54.955
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-5692/secret-test-2027ee8f-7002-40bf-93a2-538cf2330929 11/29/22 11:43:54.959
STEP: Creating a pod to test consume secrets 11/29/22 11:43:54.961
Nov 29 11:43:54.967: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3" in namespace "secrets-5692" to be "Succeeded or Failed"
Nov 29 11:43:54.969: INFO: Pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.175245ms
Nov 29 11:43:56.973: INFO: Pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006162979s
Nov 29 11:43:58.973: INFO: Pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006035875s
STEP: Saw pod success 11/29/22 11:43:58.973
Nov 29 11:43:58.973: INFO: Pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3" satisfied condition "Succeeded or Failed"
Nov 29 11:43:58.976: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3 container env-test: <nil>
STEP: delete the pod 11/29/22 11:43:58.98
Nov 29 11:43:58.986: INFO: Waiting for pod pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3 to disappear
Nov 29 11:43:58.988: INFO: Pod pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 29 11:43:58.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5692" for this suite. 11/29/22 11:43:58.991
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":66,"skipped":1371,"failed":0}
------------------------------
• [4.065 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:43:54.929
    Nov 29 11:43:54.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 11:43:54.93
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:54.953
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:54.955
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-5692/secret-test-2027ee8f-7002-40bf-93a2-538cf2330929 11/29/22 11:43:54.959
    STEP: Creating a pod to test consume secrets 11/29/22 11:43:54.961
    Nov 29 11:43:54.967: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3" in namespace "secrets-5692" to be "Succeeded or Failed"
    Nov 29 11:43:54.969: INFO: Pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.175245ms
    Nov 29 11:43:56.973: INFO: Pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006162979s
    Nov 29 11:43:58.973: INFO: Pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006035875s
    STEP: Saw pod success 11/29/22 11:43:58.973
    Nov 29 11:43:58.973: INFO: Pod "pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3" satisfied condition "Succeeded or Failed"
    Nov 29 11:43:58.976: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3 container env-test: <nil>
    STEP: delete the pod 11/29/22 11:43:58.98
    Nov 29 11:43:58.986: INFO: Waiting for pod pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3 to disappear
    Nov 29 11:43:58.988: INFO: Pod pod-configmaps-fd82ad50-d25b-4a71-8ff7-cc0e0701c1d3 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 11:43:58.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5692" for this suite. 11/29/22 11:43:58.991
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:43:58.994
Nov 29 11:43:58.994: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename deployment 11/29/22 11:43:58.995
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:59.003
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:59.005
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Nov 29 11:43:59.019: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 29 11:44:04.023: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/29/22 11:44:04.023
Nov 29 11:44:04.023: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/29/22 11:44:04.032
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 29 11:44:06.046: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-677  72513056-4033-4841-bdba-69112bdb3f09 12124 1 2022-11-29 11:44:03 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-29 11:44:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:44:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003239208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-29 11:44:04 +0000 UTC,LastTransitionTime:2022-11-29 11:44:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-11-29 11:44:05 +0000 UTC,LastTransitionTime:2022-11-29 11:44:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 29 11:44:06.050: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-677  54dd8c36-8065-45d9-8a07-0f1d23f6f44a 12114 1 2022-11-29 11:44:03 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 72513056-4033-4841-bdba-69112bdb3f09 0xc0029b6417 0xc0029b6418}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:44:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72513056-4033-4841-bdba-69112bdb3f09\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:44:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029b64c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 29 11:44:06.052: INFO: Pod "test-cleanup-deployment-69cb9c5497-rl5v7" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-rl5v7 test-cleanup-deployment-69cb9c5497- deployment-677  3db27943-1f06-47b5-a078-025c8db2254d 12113 0 2022-11-29 11:44:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:b23c2a662edab0083bfb7eef09d5e90190d5e4e2d014ed3752cc62265803b2b8 cni.projectcalico.org/podIP:100.96.3.38/32 cni.projectcalico.org/podIPs:100.96.3.38/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 54dd8c36-8065-45d9-8a07-0f1d23f6f44a 0xc003311d77 0xc003311d78}] [] [{calico Update v1 2022-11-29 11:44:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 11:44:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54dd8c36-8065-45d9-8a07-0f1d23f6f44a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 11:44:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.38\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jns8n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jns8n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:44:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:44:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:44:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:44:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:100.96.3.38,StartTime:2022-11-29 11:44:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 11:44:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://c2218364ee0a2d6b6a864159ff259d8ff494411510900f706e3392d32407a172,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.38,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 29 11:44:06.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-677" for this suite. 11/29/22 11:44:06.055
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":67,"skipped":1372,"failed":0}
------------------------------
• [SLOW TEST] [7.066 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:43:58.994
    Nov 29 11:43:58.994: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename deployment 11/29/22 11:43:58.995
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:43:59.003
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:43:59.005
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Nov 29 11:43:59.019: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Nov 29 11:44:04.023: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/29/22 11:44:04.023
    Nov 29 11:44:04.023: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/29/22 11:44:04.032
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 29 11:44:06.046: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-677  72513056-4033-4841-bdba-69112bdb3f09 12124 1 2022-11-29 11:44:03 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-29 11:44:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:44:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003239208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-29 11:44:04 +0000 UTC,LastTransitionTime:2022-11-29 11:44:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-11-29 11:44:05 +0000 UTC,LastTransitionTime:2022-11-29 11:44:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 29 11:44:06.050: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-677  54dd8c36-8065-45d9-8a07-0f1d23f6f44a 12114 1 2022-11-29 11:44:03 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 72513056-4033-4841-bdba-69112bdb3f09 0xc0029b6417 0xc0029b6418}] [] [{kube-controller-manager Update apps/v1 2022-11-29 11:44:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72513056-4033-4841-bdba-69112bdb3f09\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 11:44:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029b64c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 11:44:06.052: INFO: Pod "test-cleanup-deployment-69cb9c5497-rl5v7" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-rl5v7 test-cleanup-deployment-69cb9c5497- deployment-677  3db27943-1f06-47b5-a078-025c8db2254d 12113 0 2022-11-29 11:44:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:b23c2a662edab0083bfb7eef09d5e90190d5e4e2d014ed3752cc62265803b2b8 cni.projectcalico.org/podIP:100.96.3.38/32 cni.projectcalico.org/podIPs:100.96.3.38/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 54dd8c36-8065-45d9-8a07-0f1d23f6f44a 0xc003311d77 0xc003311d78}] [] [{calico Update v1 2022-11-29 11:44:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 11:44:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54dd8c36-8065-45d9-8a07-0f1d23f6f44a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 11:44:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.38\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jns8n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jns8n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:44:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:44:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:44:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 11:44:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:100.96.3.38,StartTime:2022-11-29 11:44:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 11:44:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://c2218364ee0a2d6b6a864159ff259d8ff494411510900f706e3392d32407a172,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.38,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 29 11:44:06.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-677" for this suite. 11/29/22 11:44:06.055
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:44:06.06
Nov 29 11:44:06.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename runtimeclass 11/29/22 11:44:06.061
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:06.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:06.07
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-6126-delete-me 11/29/22 11:44:06.074
STEP: Waiting for the RuntimeClass to disappear 11/29/22 11:44:06.077
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 29 11:44:06.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6126" for this suite. 11/29/22 11:44:06.085
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":68,"skipped":1375,"failed":0}
------------------------------
• [0.030 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:44:06.06
    Nov 29 11:44:06.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename runtimeclass 11/29/22 11:44:06.061
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:06.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:06.07
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-6126-delete-me 11/29/22 11:44:06.074
    STEP: Waiting for the RuntimeClass to disappear 11/29/22 11:44:06.077
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 29 11:44:06.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6126" for this suite. 11/29/22 11:44:06.085
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:44:06.091
Nov 29 11:44:06.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:44:06.091
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:06.108
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:06.111
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-005aabe4-6f3e-463b-ad91-611d01dcd72a 11/29/22 11:44:06.113
STEP: Creating secret with name secret-projected-all-test-volume-3ceab73f-60c6-4a85-8107-28d32de8b9f0 11/29/22 11:44:06.116
STEP: Creating a pod to test Check all projections for projected volume plugin 11/29/22 11:44:06.119
Nov 29 11:44:06.123: INFO: Waiting up to 5m0s for pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48" in namespace "projected-9684" to be "Succeeded or Failed"
Nov 29 11:44:06.126: INFO: Pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.967652ms
Nov 29 11:44:08.130: INFO: Pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00629651s
Nov 29 11:44:10.129: INFO: Pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006061017s
STEP: Saw pod success 11/29/22 11:44:10.129
Nov 29 11:44:10.130: INFO: Pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48" satisfied condition "Succeeded or Failed"
Nov 29 11:44:10.132: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48 container projected-all-volume-test: <nil>
STEP: delete the pod 11/29/22 11:44:10.136
Nov 29 11:44:10.142: INFO: Waiting for pod projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48 to disappear
Nov 29 11:44:10.145: INFO: Pod projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Nov 29 11:44:10.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9684" for this suite. 11/29/22 11:44:10.148
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":69,"skipped":1387,"failed":0}
------------------------------
• [4.060 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:44:06.091
    Nov 29 11:44:06.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:44:06.091
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:06.108
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:06.111
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-005aabe4-6f3e-463b-ad91-611d01dcd72a 11/29/22 11:44:06.113
    STEP: Creating secret with name secret-projected-all-test-volume-3ceab73f-60c6-4a85-8107-28d32de8b9f0 11/29/22 11:44:06.116
    STEP: Creating a pod to test Check all projections for projected volume plugin 11/29/22 11:44:06.119
    Nov 29 11:44:06.123: INFO: Waiting up to 5m0s for pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48" in namespace "projected-9684" to be "Succeeded or Failed"
    Nov 29 11:44:06.126: INFO: Pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.967652ms
    Nov 29 11:44:08.130: INFO: Pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00629651s
    Nov 29 11:44:10.129: INFO: Pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006061017s
    STEP: Saw pod success 11/29/22 11:44:10.129
    Nov 29 11:44:10.130: INFO: Pod "projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48" satisfied condition "Succeeded or Failed"
    Nov 29 11:44:10.132: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48 container projected-all-volume-test: <nil>
    STEP: delete the pod 11/29/22 11:44:10.136
    Nov 29 11:44:10.142: INFO: Waiting for pod projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48 to disappear
    Nov 29 11:44:10.145: INFO: Pod projected-volume-81b02464-71c3-47d6-a098-e80e9d9cbc48 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Nov 29 11:44:10.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9684" for this suite. 11/29/22 11:44:10.148
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:44:10.151
Nov 29 11:44:10.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename init-container 11/29/22 11:44:10.152
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:10.161
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:10.162
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 11/29/22 11:44:10.164
Nov 29 11:44:10.164: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 29 11:44:13.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1946" for this suite. 11/29/22 11:44:13.178
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":70,"skipped":1389,"failed":0}
------------------------------
• [3.031 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:44:10.151
    Nov 29 11:44:10.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename init-container 11/29/22 11:44:10.152
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:10.161
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:10.162
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 11/29/22 11:44:10.164
    Nov 29 11:44:10.164: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 29 11:44:13.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1946" for this suite. 11/29/22 11:44:13.178
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:44:13.182
Nov 29 11:44:13.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replicaset 11/29/22 11:44:13.183
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:13.193
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:13.196
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 11/29/22 11:44:13.198
STEP: Verify that the required pods have come up 11/29/22 11:44:13.202
Nov 29 11:44:13.212: INFO: Pod name sample-pod: Found 0 pods out of 3
Nov 29 11:44:18.219: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 11/29/22 11:44:18.219
Nov 29 11:44:18.224: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 11/29/22 11:44:18.224
STEP: DeleteCollection of the ReplicaSets 11/29/22 11:44:18.227
STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/29/22 11:44:18.233
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 29 11:44:18.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3932" for this suite. 11/29/22 11:44:18.24
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":71,"skipped":1392,"failed":0}
------------------------------
• [SLOW TEST] [5.074 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:44:13.182
    Nov 29 11:44:13.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replicaset 11/29/22 11:44:13.183
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:13.193
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:13.196
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 11/29/22 11:44:13.198
    STEP: Verify that the required pods have come up 11/29/22 11:44:13.202
    Nov 29 11:44:13.212: INFO: Pod name sample-pod: Found 0 pods out of 3
    Nov 29 11:44:18.219: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 11/29/22 11:44:18.219
    Nov 29 11:44:18.224: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 11/29/22 11:44:18.224
    STEP: DeleteCollection of the ReplicaSets 11/29/22 11:44:18.227
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/29/22 11:44:18.233
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 29 11:44:18.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3932" for this suite. 11/29/22 11:44:18.24
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:44:18.257
Nov 29 11:44:18.257: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename subpath 11/29/22 11:44:18.258
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:18.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:18.275
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/29/22 11:44:18.277
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-tgzc 11/29/22 11:44:18.287
STEP: Creating a pod to test atomic-volume-subpath 11/29/22 11:44:18.287
Nov 29 11:44:18.294: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-tgzc" in namespace "subpath-5550" to be "Succeeded or Failed"
Nov 29 11:44:18.300: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.061021ms
Nov 29 11:44:20.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 2.009042828s
Nov 29 11:44:22.305: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 4.011286971s
Nov 29 11:44:24.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 6.009606115s
Nov 29 11:44:26.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 8.009129768s
Nov 29 11:44:28.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 10.009135955s
Nov 29 11:44:30.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 12.00888964s
Nov 29 11:44:32.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 14.009011368s
Nov 29 11:44:34.304: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 16.010083969s
Nov 29 11:44:36.304: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 18.009809098s
Nov 29 11:44:38.302: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 20.008713336s
Nov 29 11:44:40.305: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=false. Elapsed: 22.010974937s
Nov 29 11:44:42.304: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.010214955s
STEP: Saw pod success 11/29/22 11:44:42.304
Nov 29 11:44:42.304: INFO: Pod "pod-subpath-test-secret-tgzc" satisfied condition "Succeeded or Failed"
Nov 29 11:44:42.307: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-1 pod pod-subpath-test-secret-tgzc container test-container-subpath-secret-tgzc: <nil>
STEP: delete the pod 11/29/22 11:44:42.316
Nov 29 11:44:42.335: INFO: Waiting for pod pod-subpath-test-secret-tgzc to disappear
Nov 29 11:44:42.338: INFO: Pod pod-subpath-test-secret-tgzc no longer exists
STEP: Deleting pod pod-subpath-test-secret-tgzc 11/29/22 11:44:42.338
Nov 29 11:44:42.338: INFO: Deleting pod "pod-subpath-test-secret-tgzc" in namespace "subpath-5550"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 29 11:44:42.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5550" for this suite. 11/29/22 11:44:42.344
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":72,"skipped":1393,"failed":0}
------------------------------
• [SLOW TEST] [24.091 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:44:18.257
    Nov 29 11:44:18.257: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename subpath 11/29/22 11:44:18.258
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:18.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:18.275
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/29/22 11:44:18.277
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-tgzc 11/29/22 11:44:18.287
    STEP: Creating a pod to test atomic-volume-subpath 11/29/22 11:44:18.287
    Nov 29 11:44:18.294: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-tgzc" in namespace "subpath-5550" to be "Succeeded or Failed"
    Nov 29 11:44:18.300: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.061021ms
    Nov 29 11:44:20.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 2.009042828s
    Nov 29 11:44:22.305: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 4.011286971s
    Nov 29 11:44:24.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 6.009606115s
    Nov 29 11:44:26.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 8.009129768s
    Nov 29 11:44:28.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 10.009135955s
    Nov 29 11:44:30.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 12.00888964s
    Nov 29 11:44:32.303: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 14.009011368s
    Nov 29 11:44:34.304: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 16.010083969s
    Nov 29 11:44:36.304: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 18.009809098s
    Nov 29 11:44:38.302: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=true. Elapsed: 20.008713336s
    Nov 29 11:44:40.305: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Running", Reason="", readiness=false. Elapsed: 22.010974937s
    Nov 29 11:44:42.304: INFO: Pod "pod-subpath-test-secret-tgzc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.010214955s
    STEP: Saw pod success 11/29/22 11:44:42.304
    Nov 29 11:44:42.304: INFO: Pod "pod-subpath-test-secret-tgzc" satisfied condition "Succeeded or Failed"
    Nov 29 11:44:42.307: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-1 pod pod-subpath-test-secret-tgzc container test-container-subpath-secret-tgzc: <nil>
    STEP: delete the pod 11/29/22 11:44:42.316
    Nov 29 11:44:42.335: INFO: Waiting for pod pod-subpath-test-secret-tgzc to disappear
    Nov 29 11:44:42.338: INFO: Pod pod-subpath-test-secret-tgzc no longer exists
    STEP: Deleting pod pod-subpath-test-secret-tgzc 11/29/22 11:44:42.338
    Nov 29 11:44:42.338: INFO: Deleting pod "pod-subpath-test-secret-tgzc" in namespace "subpath-5550"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 29 11:44:42.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5550" for this suite. 11/29/22 11:44:42.344
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:44:42.348
Nov 29 11:44:42.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 11:44:42.349
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:42.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:42.36
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 11/29/22 11:44:42.363
STEP: Creating a ResourceQuota 11/29/22 11:44:47.368
STEP: Ensuring resource quota status is calculated 11/29/22 11:44:47.37
STEP: Creating a Pod that fits quota 11/29/22 11:44:49.375
STEP: Ensuring ResourceQuota status captures the pod usage 11/29/22 11:44:49.383
STEP: Not allowing a pod to be created that exceeds remaining quota 11/29/22 11:44:51.387
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/29/22 11:44:51.39
STEP: Ensuring a pod cannot update its resource requirements 11/29/22 11:44:51.394
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/29/22 11:44:51.399
STEP: Deleting the pod 11/29/22 11:44:53.403
STEP: Ensuring resource quota status released the pod usage 11/29/22 11:44:53.408
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 11:44:55.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2418" for this suite. 11/29/22 11:44:55.417
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":73,"skipped":1401,"failed":0}
------------------------------
• [SLOW TEST] [13.073 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:44:42.348
    Nov 29 11:44:42.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 11:44:42.349
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:42.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:42.36
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 11/29/22 11:44:42.363
    STEP: Creating a ResourceQuota 11/29/22 11:44:47.368
    STEP: Ensuring resource quota status is calculated 11/29/22 11:44:47.37
    STEP: Creating a Pod that fits quota 11/29/22 11:44:49.375
    STEP: Ensuring ResourceQuota status captures the pod usage 11/29/22 11:44:49.383
    STEP: Not allowing a pod to be created that exceeds remaining quota 11/29/22 11:44:51.387
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/29/22 11:44:51.39
    STEP: Ensuring a pod cannot update its resource requirements 11/29/22 11:44:51.394
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/29/22 11:44:51.399
    STEP: Deleting the pod 11/29/22 11:44:53.403
    STEP: Ensuring resource quota status released the pod usage 11/29/22 11:44:53.408
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 11:44:55.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2418" for this suite. 11/29/22 11:44:55.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:44:55.423
Nov 29 11:44:55.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 11:44:55.424
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:55.432
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:55.435
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 11/29/22 11:44:55.437
STEP: Creating a ResourceQuota 11/29/22 11:45:00.44
STEP: Ensuring resource quota status is calculated 11/29/22 11:45:00.443
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 11:45:02.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7498" for this suite. 11/29/22 11:45:02.455
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":74,"skipped":1427,"failed":0}
------------------------------
• [SLOW TEST] [7.035 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:44:55.423
    Nov 29 11:44:55.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 11:44:55.424
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:44:55.432
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:44:55.435
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 11/29/22 11:44:55.437
    STEP: Creating a ResourceQuota 11/29/22 11:45:00.44
    STEP: Ensuring resource quota status is calculated 11/29/22 11:45:00.443
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 11:45:02.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7498" for this suite. 11/29/22 11:45:02.455
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:45:02.459
Nov 29 11:45:02.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename statefulset 11/29/22 11:45:02.46
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:45:02.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:45:02.474
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7067 11/29/22 11:45:02.476
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 11/29/22 11:45:02.48
STEP: Creating stateful set ss in namespace statefulset-7067 11/29/22 11:45:02.486
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7067 11/29/22 11:45:02.489
Nov 29 11:45:02.495: INFO: Found 0 stateful pods, waiting for 1
Nov 29 11:45:12.500: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/29/22 11:45:12.5
Nov 29 11:45:12.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 11:45:12.655: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 11:45:12.655: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 11:45:12.655: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 11:45:12.658: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 29 11:45:22.661: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 29 11:45:22.661: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 11:45:22.681: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999654s
Nov 29 11:45:23.684: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988851634s
Nov 29 11:45:24.688: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984926596s
Nov 29 11:45:25.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.980927272s
Nov 29 11:45:26.695: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.977934263s
Nov 29 11:45:27.698: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.974944836s
Nov 29 11:45:28.701: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.971845307s
Nov 29 11:45:29.704: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.968544888s
Nov 29 11:45:30.708: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964892149s
Nov 29 11:45:31.712: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.856343ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7067 11/29/22 11:45:32.712
Nov 29 11:45:32.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 11:45:32.836: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 29 11:45:32.836: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 11:45:32.836: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 29 11:45:32.838: INFO: Found 1 stateful pods, waiting for 3
Nov 29 11:45:42.845: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:45:42.845: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 11:45:42.845: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 11/29/22 11:45:42.845
STEP: Scale down will halt with unhealthy stateful pod 11/29/22 11:45:42.845
Nov 29 11:45:42.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 11:45:42.989: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 11:45:42.989: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 11:45:42.989: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 11:45:42.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 11:45:43.143: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 11:45:43.143: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 11:45:43.143: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 11:45:43.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 11:45:43.298: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 11:45:43.298: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 11:45:43.298: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 11:45:43.298: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 11:45:43.301: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 29 11:45:53.306: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 29 11:45:53.306: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 29 11:45:53.306: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 29 11:45:53.313: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999738s
Nov 29 11:45:54.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998005839s
Nov 29 11:45:55.320: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994627242s
Nov 29 11:45:56.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.99107555s
Nov 29 11:45:57.331: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985979748s
Nov 29 11:45:58.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979210946s
Nov 29 11:45:59.341: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973367045s
Nov 29 11:46:00.345: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969988616s
Nov 29 11:46:01.349: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966000901s
Nov 29 11:46:02.353: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.542162ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7067 11/29/22 11:46:03.353
Nov 29 11:46:03.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 11:46:03.518: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 29 11:46:03.518: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 11:46:03.518: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 29 11:46:03.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 11:46:03.659: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 29 11:46:03.659: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 11:46:03.659: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 29 11:46:03.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 11:46:03.792: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 29 11:46:03.792: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 11:46:03.792: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 29 11:46:03.792: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 11/29/22 11:46:13.806
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 29 11:46:13.807: INFO: Deleting all statefulset in ns statefulset-7067
Nov 29 11:46:13.809: INFO: Scaling statefulset ss to 0
Nov 29 11:46:13.816: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 11:46:13.817: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 29 11:46:13.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7067" for this suite. 11/29/22 11:46:13.829
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":75,"skipped":1432,"failed":0}
------------------------------
• [SLOW TEST] [71.372 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:45:02.459
    Nov 29 11:45:02.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename statefulset 11/29/22 11:45:02.46
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:45:02.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:45:02.474
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7067 11/29/22 11:45:02.476
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 11/29/22 11:45:02.48
    STEP: Creating stateful set ss in namespace statefulset-7067 11/29/22 11:45:02.486
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7067 11/29/22 11:45:02.489
    Nov 29 11:45:02.495: INFO: Found 0 stateful pods, waiting for 1
    Nov 29 11:45:12.500: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/29/22 11:45:12.5
    Nov 29 11:45:12.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 11:45:12.655: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 11:45:12.655: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 11:45:12.655: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 11:45:12.658: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov 29 11:45:22.661: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 29 11:45:22.661: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 11:45:22.681: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999654s
    Nov 29 11:45:23.684: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988851634s
    Nov 29 11:45:24.688: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984926596s
    Nov 29 11:45:25.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.980927272s
    Nov 29 11:45:26.695: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.977934263s
    Nov 29 11:45:27.698: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.974944836s
    Nov 29 11:45:28.701: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.971845307s
    Nov 29 11:45:29.704: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.968544888s
    Nov 29 11:45:30.708: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964892149s
    Nov 29 11:45:31.712: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.856343ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7067 11/29/22 11:45:32.712
    Nov 29 11:45:32.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 11:45:32.836: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 29 11:45:32.836: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 11:45:32.836: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 29 11:45:32.838: INFO: Found 1 stateful pods, waiting for 3
    Nov 29 11:45:42.845: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:45:42.845: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 11:45:42.845: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 11/29/22 11:45:42.845
    STEP: Scale down will halt with unhealthy stateful pod 11/29/22 11:45:42.845
    Nov 29 11:45:42.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 11:45:42.989: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 11:45:42.989: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 11:45:42.989: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 11:45:42.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 11:45:43.143: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 11:45:43.143: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 11:45:43.143: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 11:45:43.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 11:45:43.298: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 11:45:43.298: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 11:45:43.298: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 11:45:43.298: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 11:45:43.301: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Nov 29 11:45:53.306: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 29 11:45:53.306: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov 29 11:45:53.306: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov 29 11:45:53.313: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999738s
    Nov 29 11:45:54.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998005839s
    Nov 29 11:45:55.320: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994627242s
    Nov 29 11:45:56.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.99107555s
    Nov 29 11:45:57.331: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985979748s
    Nov 29 11:45:58.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979210946s
    Nov 29 11:45:59.341: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973367045s
    Nov 29 11:46:00.345: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969988616s
    Nov 29 11:46:01.349: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966000901s
    Nov 29 11:46:02.353: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.542162ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7067 11/29/22 11:46:03.353
    Nov 29 11:46:03.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 11:46:03.518: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 29 11:46:03.518: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 11:46:03.518: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 29 11:46:03.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 11:46:03.659: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 29 11:46:03.659: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 11:46:03.659: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 29 11:46:03.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-7067 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 11:46:03.792: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 29 11:46:03.792: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 11:46:03.792: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 29 11:46:03.792: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 11/29/22 11:46:13.806
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 29 11:46:13.807: INFO: Deleting all statefulset in ns statefulset-7067
    Nov 29 11:46:13.809: INFO: Scaling statefulset ss to 0
    Nov 29 11:46:13.816: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 11:46:13.817: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 29 11:46:13.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7067" for this suite. 11/29/22 11:46:13.829
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:46:13.832
Nov 29 11:46:13.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 11:46:13.833
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:13.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:13.842
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Nov 29 11:46:13.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/29/22 11:46:17.675
Nov 29 11:46:17.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 --namespace=crd-publish-openapi-6574 create -f -'
Nov 29 11:46:18.586: INFO: stderr: ""
Nov 29 11:46:18.586: INFO: stdout: "e2e-test-crd-publish-openapi-9563-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 29 11:46:18.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 --namespace=crd-publish-openapi-6574 delete e2e-test-crd-publish-openapi-9563-crds test-cr'
Nov 29 11:46:18.665: INFO: stderr: ""
Nov 29 11:46:18.665: INFO: stdout: "e2e-test-crd-publish-openapi-9563-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov 29 11:46:18.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 --namespace=crd-publish-openapi-6574 apply -f -'
Nov 29 11:46:19.003: INFO: stderr: ""
Nov 29 11:46:19.003: INFO: stdout: "e2e-test-crd-publish-openapi-9563-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 29 11:46:19.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 --namespace=crd-publish-openapi-6574 delete e2e-test-crd-publish-openapi-9563-crds test-cr'
Nov 29 11:46:19.083: INFO: stderr: ""
Nov 29 11:46:19.083: INFO: stdout: "e2e-test-crd-publish-openapi-9563-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/29/22 11:46:19.083
Nov 29 11:46:19.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 explain e2e-test-crd-publish-openapi-9563-crds'
Nov 29 11:46:19.389: INFO: stderr: ""
Nov 29 11:46:19.389: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9563-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:46:22.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6574" for this suite. 11/29/22 11:46:22.689
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":76,"skipped":1463,"failed":0}
------------------------------
• [SLOW TEST] [8.860 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:46:13.832
    Nov 29 11:46:13.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 11:46:13.833
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:13.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:13.842
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Nov 29 11:46:13.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/29/22 11:46:17.675
    Nov 29 11:46:17.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 --namespace=crd-publish-openapi-6574 create -f -'
    Nov 29 11:46:18.586: INFO: stderr: ""
    Nov 29 11:46:18.586: INFO: stdout: "e2e-test-crd-publish-openapi-9563-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov 29 11:46:18.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 --namespace=crd-publish-openapi-6574 delete e2e-test-crd-publish-openapi-9563-crds test-cr'
    Nov 29 11:46:18.665: INFO: stderr: ""
    Nov 29 11:46:18.665: INFO: stdout: "e2e-test-crd-publish-openapi-9563-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Nov 29 11:46:18.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 --namespace=crd-publish-openapi-6574 apply -f -'
    Nov 29 11:46:19.003: INFO: stderr: ""
    Nov 29 11:46:19.003: INFO: stdout: "e2e-test-crd-publish-openapi-9563-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov 29 11:46:19.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 --namespace=crd-publish-openapi-6574 delete e2e-test-crd-publish-openapi-9563-crds test-cr'
    Nov 29 11:46:19.083: INFO: stderr: ""
    Nov 29 11:46:19.083: INFO: stdout: "e2e-test-crd-publish-openapi-9563-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/29/22 11:46:19.083
    Nov 29 11:46:19.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-6574 explain e2e-test-crd-publish-openapi-9563-crds'
    Nov 29 11:46:19.389: INFO: stderr: ""
    Nov 29 11:46:19.389: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9563-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:46:22.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6574" for this suite. 11/29/22 11:46:22.689
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:46:22.694
Nov 29 11:46:22.695: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename runtimeclass 11/29/22 11:46:22.695
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:22.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:22.706
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 29 11:46:22.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2355" for this suite. 11/29/22 11:46:22.716
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":77,"skipped":1493,"failed":0}
------------------------------
• [0.025 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:46:22.694
    Nov 29 11:46:22.695: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename runtimeclass 11/29/22 11:46:22.695
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:22.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:22.706
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 29 11:46:22.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2355" for this suite. 11/29/22 11:46:22.716
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:46:22.72
Nov 29 11:46:22.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 11:46:22.721
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:22.727
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:22.73
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 11/29/22 11:46:22.732
STEP: Creating a ResourceQuota 11/29/22 11:46:27.737
STEP: Ensuring resource quota status is calculated 11/29/22 11:46:27.744
STEP: Creating a ReplicationController 11/29/22 11:46:29.749
STEP: Ensuring resource quota status captures replication controller creation 11/29/22 11:46:29.757
STEP: Deleting a ReplicationController 11/29/22 11:46:31.761
STEP: Ensuring resource quota status released usage 11/29/22 11:46:31.764
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 11:46:33.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2402" for this suite. 11/29/22 11:46:33.771
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":78,"skipped":1503,"failed":0}
------------------------------
• [SLOW TEST] [11.054 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:46:22.72
    Nov 29 11:46:22.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 11:46:22.721
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:22.727
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:22.73
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 11/29/22 11:46:22.732
    STEP: Creating a ResourceQuota 11/29/22 11:46:27.737
    STEP: Ensuring resource quota status is calculated 11/29/22 11:46:27.744
    STEP: Creating a ReplicationController 11/29/22 11:46:29.749
    STEP: Ensuring resource quota status captures replication controller creation 11/29/22 11:46:29.757
    STEP: Deleting a ReplicationController 11/29/22 11:46:31.761
    STEP: Ensuring resource quota status released usage 11/29/22 11:46:31.764
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 11:46:33.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2402" for this suite. 11/29/22 11:46:33.771
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:46:33.776
Nov 29 11:46:33.776: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:46:33.777
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:33.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:33.795
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 11/29/22 11:46:33.797
Nov 29 11:46:33.801: INFO: Waiting up to 5m0s for pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c" in namespace "projected-8731" to be "Succeeded or Failed"
Nov 29 11:46:33.804: INFO: Pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.687815ms
Nov 29 11:46:35.808: INFO: Pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006482201s
Nov 29 11:46:37.807: INFO: Pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005974675s
STEP: Saw pod success 11/29/22 11:46:37.807
Nov 29 11:46:37.808: INFO: Pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c" satisfied condition "Succeeded or Failed"
Nov 29 11:46:37.810: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c container client-container: <nil>
STEP: delete the pod 11/29/22 11:46:37.814
Nov 29 11:46:37.819: INFO: Waiting for pod downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c to disappear
Nov 29 11:46:37.823: INFO: Pod downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 11:46:37.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8731" for this suite. 11/29/22 11:46:37.825
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":79,"skipped":1539,"failed":0}
------------------------------
• [4.052 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:46:33.776
    Nov 29 11:46:33.776: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:46:33.777
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:33.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:33.795
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 11/29/22 11:46:33.797
    Nov 29 11:46:33.801: INFO: Waiting up to 5m0s for pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c" in namespace "projected-8731" to be "Succeeded or Failed"
    Nov 29 11:46:33.804: INFO: Pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.687815ms
    Nov 29 11:46:35.808: INFO: Pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006482201s
    Nov 29 11:46:37.807: INFO: Pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005974675s
    STEP: Saw pod success 11/29/22 11:46:37.807
    Nov 29 11:46:37.808: INFO: Pod "downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c" satisfied condition "Succeeded or Failed"
    Nov 29 11:46:37.810: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c container client-container: <nil>
    STEP: delete the pod 11/29/22 11:46:37.814
    Nov 29 11:46:37.819: INFO: Waiting for pod downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c to disappear
    Nov 29 11:46:37.823: INFO: Pod downwardapi-volume-600f8b58-c547-4754-834b-a111f779e56c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 11:46:37.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8731" for this suite. 11/29/22 11:46:37.825
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:46:37.829
Nov 29 11:46:37.829: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 11:46:37.83
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:37.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:37.839
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 11/29/22 11:46:37.841
Nov 29 11:46:37.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 create -f -'
Nov 29 11:46:38.721: INFO: stderr: ""
Nov 29 11:46:38.722: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/29/22 11:46:38.722
Nov 29 11:46:38.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 11:46:38.785: INFO: stderr: ""
Nov 29 11:46:38.785: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
Nov 29 11:46:38.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:46:38.850: INFO: stderr: ""
Nov 29 11:46:38.850: INFO: stdout: ""
Nov 29 11:46:38.850: INFO: update-demo-nautilus-6bdp9 is created but not running
Nov 29 11:46:43.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 11:46:43.916: INFO: stderr: ""
Nov 29 11:46:43.916: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
Nov 29 11:46:43.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:46:43.975: INFO: stderr: ""
Nov 29 11:46:43.975: INFO: stdout: ""
Nov 29 11:46:43.975: INFO: update-demo-nautilus-6bdp9 is created but not running
Nov 29 11:46:48.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 11:46:49.208: INFO: stderr: ""
Nov 29 11:46:49.208: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
Nov 29 11:46:49.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:46:49.267: INFO: stderr: ""
Nov 29 11:46:49.267: INFO: stdout: ""
Nov 29 11:46:49.267: INFO: update-demo-nautilus-6bdp9 is created but not running
Nov 29 11:46:54.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 11:46:54.342: INFO: stderr: ""
Nov 29 11:46:54.342: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
Nov 29 11:46:54.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:46:54.408: INFO: stderr: ""
Nov 29 11:46:54.408: INFO: stdout: "true"
Nov 29 11:46:54.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 11:46:54.473: INFO: stderr: ""
Nov 29 11:46:54.473: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 11:46:54.473: INFO: validating pod update-demo-nautilus-6bdp9
Nov 29 11:46:54.477: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 11:46:54.477: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 11:46:54.477: INFO: update-demo-nautilus-6bdp9 is verified up and running
Nov 29 11:46:54.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-k8rwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:46:54.550: INFO: stderr: ""
Nov 29 11:46:54.550: INFO: stdout: ""
Nov 29 11:46:54.550: INFO: update-demo-nautilus-k8rwf is created but not running
Nov 29 11:46:59.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 11:46:59.615: INFO: stderr: ""
Nov 29 11:46:59.615: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
Nov 29 11:46:59.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:46:59.673: INFO: stderr: ""
Nov 29 11:46:59.673: INFO: stdout: "true"
Nov 29 11:46:59.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 11:46:59.735: INFO: stderr: ""
Nov 29 11:46:59.735: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 11:46:59.735: INFO: validating pod update-demo-nautilus-6bdp9
Nov 29 11:46:59.738: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 11:46:59.738: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 11:46:59.738: INFO: update-demo-nautilus-6bdp9 is verified up and running
Nov 29 11:46:59.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-k8rwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:46:59.803: INFO: stderr: ""
Nov 29 11:46:59.803: INFO: stdout: "true"
Nov 29 11:46:59.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-k8rwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 11:46:59.860: INFO: stderr: ""
Nov 29 11:46:59.860: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 11:46:59.860: INFO: validating pod update-demo-nautilus-k8rwf
Nov 29 11:46:59.863: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 11:46:59.863: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 11:46:59.863: INFO: update-demo-nautilus-k8rwf is verified up and running
STEP: scaling down the replication controller 11/29/22 11:46:59.863
Nov 29 11:46:59.865: INFO: scanned /root for discovery docs: <nil>
Nov 29 11:46:59.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Nov 29 11:47:00.955: INFO: stderr: ""
Nov 29 11:47:00.955: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/29/22 11:47:00.955
Nov 29 11:47:00.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 11:47:01.027: INFO: stderr: ""
Nov 29 11:47:01.027: INFO: stdout: "update-demo-nautilus-6bdp9 "
Nov 29 11:47:01.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:47:01.097: INFO: stderr: ""
Nov 29 11:47:01.097: INFO: stdout: "true"
Nov 29 11:47:01.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 11:47:01.163: INFO: stderr: ""
Nov 29 11:47:01.163: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 11:47:01.163: INFO: validating pod update-demo-nautilus-6bdp9
Nov 29 11:47:01.165: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 11:47:01.166: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 11:47:01.166: INFO: update-demo-nautilus-6bdp9 is verified up and running
STEP: scaling up the replication controller 11/29/22 11:47:01.166
Nov 29 11:47:01.167: INFO: scanned /root for discovery docs: <nil>
Nov 29 11:47:01.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Nov 29 11:47:02.258: INFO: stderr: ""
Nov 29 11:47:02.258: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/29/22 11:47:02.258
Nov 29 11:47:02.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 11:47:02.321: INFO: stderr: ""
Nov 29 11:47:02.321: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-zhc4j "
Nov 29 11:47:02.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:47:02.384: INFO: stderr: ""
Nov 29 11:47:02.384: INFO: stdout: "true"
Nov 29 11:47:02.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 11:47:02.457: INFO: stderr: ""
Nov 29 11:47:02.457: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 11:47:02.457: INFO: validating pod update-demo-nautilus-6bdp9
Nov 29 11:47:02.460: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 11:47:02.460: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 11:47:02.460: INFO: update-demo-nautilus-6bdp9 is verified up and running
Nov 29 11:47:02.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-zhc4j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:47:02.525: INFO: stderr: ""
Nov 29 11:47:02.525: INFO: stdout: ""
Nov 29 11:47:02.525: INFO: update-demo-nautilus-zhc4j is created but not running
Nov 29 11:47:07.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 11:47:07.593: INFO: stderr: ""
Nov 29 11:47:07.593: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-zhc4j "
Nov 29 11:47:07.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:47:07.661: INFO: stderr: ""
Nov 29 11:47:07.661: INFO: stdout: "true"
Nov 29 11:47:07.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 11:47:07.725: INFO: stderr: ""
Nov 29 11:47:07.725: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 11:47:07.725: INFO: validating pod update-demo-nautilus-6bdp9
Nov 29 11:47:07.728: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 11:47:07.728: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 11:47:07.728: INFO: update-demo-nautilus-6bdp9 is verified up and running
Nov 29 11:47:07.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-zhc4j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 11:47:07.791: INFO: stderr: ""
Nov 29 11:47:07.791: INFO: stdout: "true"
Nov 29 11:47:07.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-zhc4j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 11:47:07.857: INFO: stderr: ""
Nov 29 11:47:07.857: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 11:47:07.857: INFO: validating pod update-demo-nautilus-zhc4j
Nov 29 11:47:07.861: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 11:47:07.861: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 11:47:07.861: INFO: update-demo-nautilus-zhc4j is verified up and running
STEP: using delete to clean up resources 11/29/22 11:47:07.861
Nov 29 11:47:07.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 delete --grace-period=0 --force -f -'
Nov 29 11:47:07.925: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 11:47:07.925: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 29 11:47:07.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get rc,svc -l name=update-demo --no-headers'
Nov 29 11:47:07.997: INFO: stderr: "No resources found in kubectl-5138 namespace.\n"
Nov 29 11:47:07.997: INFO: stdout: ""
Nov 29 11:47:07.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 29 11:47:08.076: INFO: stderr: ""
Nov 29 11:47:08.076: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 11:47:08.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5138" for this suite. 11/29/22 11:47:08.081
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":80,"skipped":1541,"failed":0}
------------------------------
• [SLOW TEST] [30.256 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:46:37.829
    Nov 29 11:46:37.829: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 11:46:37.83
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:46:37.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:46:37.839
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 11/29/22 11:46:37.841
    Nov 29 11:46:37.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 create -f -'
    Nov 29 11:46:38.721: INFO: stderr: ""
    Nov 29 11:46:38.722: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/29/22 11:46:38.722
    Nov 29 11:46:38.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 11:46:38.785: INFO: stderr: ""
    Nov 29 11:46:38.785: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
    Nov 29 11:46:38.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:46:38.850: INFO: stderr: ""
    Nov 29 11:46:38.850: INFO: stdout: ""
    Nov 29 11:46:38.850: INFO: update-demo-nautilus-6bdp9 is created but not running
    Nov 29 11:46:43.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 11:46:43.916: INFO: stderr: ""
    Nov 29 11:46:43.916: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
    Nov 29 11:46:43.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:46:43.975: INFO: stderr: ""
    Nov 29 11:46:43.975: INFO: stdout: ""
    Nov 29 11:46:43.975: INFO: update-demo-nautilus-6bdp9 is created but not running
    Nov 29 11:46:48.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 11:46:49.208: INFO: stderr: ""
    Nov 29 11:46:49.208: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
    Nov 29 11:46:49.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:46:49.267: INFO: stderr: ""
    Nov 29 11:46:49.267: INFO: stdout: ""
    Nov 29 11:46:49.267: INFO: update-demo-nautilus-6bdp9 is created but not running
    Nov 29 11:46:54.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 11:46:54.342: INFO: stderr: ""
    Nov 29 11:46:54.342: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
    Nov 29 11:46:54.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:46:54.408: INFO: stderr: ""
    Nov 29 11:46:54.408: INFO: stdout: "true"
    Nov 29 11:46:54.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 11:46:54.473: INFO: stderr: ""
    Nov 29 11:46:54.473: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 11:46:54.473: INFO: validating pod update-demo-nautilus-6bdp9
    Nov 29 11:46:54.477: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 11:46:54.477: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 11:46:54.477: INFO: update-demo-nautilus-6bdp9 is verified up and running
    Nov 29 11:46:54.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-k8rwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:46:54.550: INFO: stderr: ""
    Nov 29 11:46:54.550: INFO: stdout: ""
    Nov 29 11:46:54.550: INFO: update-demo-nautilus-k8rwf is created but not running
    Nov 29 11:46:59.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 11:46:59.615: INFO: stderr: ""
    Nov 29 11:46:59.615: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-k8rwf "
    Nov 29 11:46:59.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:46:59.673: INFO: stderr: ""
    Nov 29 11:46:59.673: INFO: stdout: "true"
    Nov 29 11:46:59.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 11:46:59.735: INFO: stderr: ""
    Nov 29 11:46:59.735: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 11:46:59.735: INFO: validating pod update-demo-nautilus-6bdp9
    Nov 29 11:46:59.738: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 11:46:59.738: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 11:46:59.738: INFO: update-demo-nautilus-6bdp9 is verified up and running
    Nov 29 11:46:59.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-k8rwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:46:59.803: INFO: stderr: ""
    Nov 29 11:46:59.803: INFO: stdout: "true"
    Nov 29 11:46:59.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-k8rwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 11:46:59.860: INFO: stderr: ""
    Nov 29 11:46:59.860: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 11:46:59.860: INFO: validating pod update-demo-nautilus-k8rwf
    Nov 29 11:46:59.863: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 11:46:59.863: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 11:46:59.863: INFO: update-demo-nautilus-k8rwf is verified up and running
    STEP: scaling down the replication controller 11/29/22 11:46:59.863
    Nov 29 11:46:59.865: INFO: scanned /root for discovery docs: <nil>
    Nov 29 11:46:59.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Nov 29 11:47:00.955: INFO: stderr: ""
    Nov 29 11:47:00.955: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/29/22 11:47:00.955
    Nov 29 11:47:00.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 11:47:01.027: INFO: stderr: ""
    Nov 29 11:47:01.027: INFO: stdout: "update-demo-nautilus-6bdp9 "
    Nov 29 11:47:01.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:47:01.097: INFO: stderr: ""
    Nov 29 11:47:01.097: INFO: stdout: "true"
    Nov 29 11:47:01.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 11:47:01.163: INFO: stderr: ""
    Nov 29 11:47:01.163: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 11:47:01.163: INFO: validating pod update-demo-nautilus-6bdp9
    Nov 29 11:47:01.165: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 11:47:01.166: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 11:47:01.166: INFO: update-demo-nautilus-6bdp9 is verified up and running
    STEP: scaling up the replication controller 11/29/22 11:47:01.166
    Nov 29 11:47:01.167: INFO: scanned /root for discovery docs: <nil>
    Nov 29 11:47:01.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Nov 29 11:47:02.258: INFO: stderr: ""
    Nov 29 11:47:02.258: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/29/22 11:47:02.258
    Nov 29 11:47:02.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 11:47:02.321: INFO: stderr: ""
    Nov 29 11:47:02.321: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-zhc4j "
    Nov 29 11:47:02.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:47:02.384: INFO: stderr: ""
    Nov 29 11:47:02.384: INFO: stdout: "true"
    Nov 29 11:47:02.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 11:47:02.457: INFO: stderr: ""
    Nov 29 11:47:02.457: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 11:47:02.457: INFO: validating pod update-demo-nautilus-6bdp9
    Nov 29 11:47:02.460: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 11:47:02.460: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 11:47:02.460: INFO: update-demo-nautilus-6bdp9 is verified up and running
    Nov 29 11:47:02.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-zhc4j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:47:02.525: INFO: stderr: ""
    Nov 29 11:47:02.525: INFO: stdout: ""
    Nov 29 11:47:02.525: INFO: update-demo-nautilus-zhc4j is created but not running
    Nov 29 11:47:07.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 11:47:07.593: INFO: stderr: ""
    Nov 29 11:47:07.593: INFO: stdout: "update-demo-nautilus-6bdp9 update-demo-nautilus-zhc4j "
    Nov 29 11:47:07.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:47:07.661: INFO: stderr: ""
    Nov 29 11:47:07.661: INFO: stdout: "true"
    Nov 29 11:47:07.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-6bdp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 11:47:07.725: INFO: stderr: ""
    Nov 29 11:47:07.725: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 11:47:07.725: INFO: validating pod update-demo-nautilus-6bdp9
    Nov 29 11:47:07.728: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 11:47:07.728: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 11:47:07.728: INFO: update-demo-nautilus-6bdp9 is verified up and running
    Nov 29 11:47:07.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-zhc4j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 11:47:07.791: INFO: stderr: ""
    Nov 29 11:47:07.791: INFO: stdout: "true"
    Nov 29 11:47:07.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods update-demo-nautilus-zhc4j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 11:47:07.857: INFO: stderr: ""
    Nov 29 11:47:07.857: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 11:47:07.857: INFO: validating pod update-demo-nautilus-zhc4j
    Nov 29 11:47:07.861: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 11:47:07.861: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 11:47:07.861: INFO: update-demo-nautilus-zhc4j is verified up and running
    STEP: using delete to clean up resources 11/29/22 11:47:07.861
    Nov 29 11:47:07.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 delete --grace-period=0 --force -f -'
    Nov 29 11:47:07.925: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 11:47:07.925: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov 29 11:47:07.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get rc,svc -l name=update-demo --no-headers'
    Nov 29 11:47:07.997: INFO: stderr: "No resources found in kubectl-5138 namespace.\n"
    Nov 29 11:47:07.997: INFO: stdout: ""
    Nov 29 11:47:07.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-5138 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 29 11:47:08.076: INFO: stderr: ""
    Nov 29 11:47:08.076: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 11:47:08.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5138" for this suite. 11/29/22 11:47:08.081
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:47:08.085
Nov 29 11:47:08.085: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 11:47:08.086
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:08.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:08.097
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 11:47:08.123
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 11:47:08.488
STEP: Deploying the webhook pod 11/29/22 11:47:08.493
STEP: Wait for the deployment to be ready 11/29/22 11:47:08.5
Nov 29 11:47:08.513: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 11:47:10.52
STEP: Verifying the service has paired with the endpoint 11/29/22 11:47:10.531
Nov 29 11:47:11.532: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/29/22 11:47:11.534
STEP: Registering slow webhook via the AdmissionRegistration API 11/29/22 11:47:11.534
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/29/22 11:47:11.544
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/29/22 11:47:12.552
STEP: Registering slow webhook via the AdmissionRegistration API 11/29/22 11:47:12.552
STEP: Having no error when timeout is longer than webhook latency 11/29/22 11:47:13.778
STEP: Registering slow webhook via the AdmissionRegistration API 11/29/22 11:47:13.779
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/29/22 11:47:18.803
STEP: Registering slow webhook via the AdmissionRegistration API 11/29/22 11:47:18.803
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:47:23.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7115" for this suite. 11/29/22 11:47:23.827
STEP: Destroying namespace "webhook-7115-markers" for this suite. 11/29/22 11:47:23.831
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":81,"skipped":1543,"failed":0}
------------------------------
• [SLOW TEST] [15.781 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:47:08.085
    Nov 29 11:47:08.085: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 11:47:08.086
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:08.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:08.097
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 11:47:08.123
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 11:47:08.488
    STEP: Deploying the webhook pod 11/29/22 11:47:08.493
    STEP: Wait for the deployment to be ready 11/29/22 11:47:08.5
    Nov 29 11:47:08.513: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 11:47:10.52
    STEP: Verifying the service has paired with the endpoint 11/29/22 11:47:10.531
    Nov 29 11:47:11.532: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/29/22 11:47:11.534
    STEP: Registering slow webhook via the AdmissionRegistration API 11/29/22 11:47:11.534
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/29/22 11:47:11.544
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/29/22 11:47:12.552
    STEP: Registering slow webhook via the AdmissionRegistration API 11/29/22 11:47:12.552
    STEP: Having no error when timeout is longer than webhook latency 11/29/22 11:47:13.778
    STEP: Registering slow webhook via the AdmissionRegistration API 11/29/22 11:47:13.779
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/29/22 11:47:18.803
    STEP: Registering slow webhook via the AdmissionRegistration API 11/29/22 11:47:18.803
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:47:23.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7115" for this suite. 11/29/22 11:47:23.827
    STEP: Destroying namespace "webhook-7115-markers" for this suite. 11/29/22 11:47:23.831
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:47:23.868
Nov 29 11:47:23.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 11:47:23.869
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:23.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:23.901
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 11/29/22 11:47:23.903
STEP: Getting a ResourceQuota 11/29/22 11:47:23.908
STEP: Updating a ResourceQuota 11/29/22 11:47:23.912
STEP: Verifying a ResourceQuota was modified 11/29/22 11:47:23.914
STEP: Deleting a ResourceQuota 11/29/22 11:47:23.922
STEP: Verifying the deleted ResourceQuota 11/29/22 11:47:23.925
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 11:47:23.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4875" for this suite. 11/29/22 11:47:23.931
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":82,"skipped":1563,"failed":0}
------------------------------
• [0.066 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:47:23.868
    Nov 29 11:47:23.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 11:47:23.869
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:23.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:23.901
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 11/29/22 11:47:23.903
    STEP: Getting a ResourceQuota 11/29/22 11:47:23.908
    STEP: Updating a ResourceQuota 11/29/22 11:47:23.912
    STEP: Verifying a ResourceQuota was modified 11/29/22 11:47:23.914
    STEP: Deleting a ResourceQuota 11/29/22 11:47:23.922
    STEP: Verifying the deleted ResourceQuota 11/29/22 11:47:23.925
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 11:47:23.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4875" for this suite. 11/29/22 11:47:23.931
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:47:23.935
Nov 29 11:47:23.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename daemonsets 11/29/22 11:47:23.936
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:23.948
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:23.954
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 11/29/22 11:47:23.976
STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 11:47:23.98
Nov 29 11:47:23.987: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 11:47:23.987: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 11:47:24.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 11:47:24.994: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 11:47:25.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:25.995: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 11:47:26.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:26.994: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 11:47:27.995: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:27.995: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 11:47:29.006: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:29.006: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 11:47:29.999: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:29.999: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 11:47:30.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:30.994: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 11:47:31.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:31.994: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 11:47:32.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:32.994: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 11:47:33.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 11:47:33.994: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 11/29/22 11:47:33.996
Nov 29 11:47:34.011: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:34.011: INFO: Node dvi-7336-1669718118-vsp1-group1-1 is running 0 daemon pod, expected 1
Nov 29 11:47:35.019: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:35.019: INFO: Node dvi-7336-1669718118-vsp1-group1-1 is running 0 daemon pod, expected 1
Nov 29 11:47:36.018: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 11:47:36.018: INFO: Node dvi-7336-1669718118-vsp1-group1-1 is running 0 daemon pod, expected 1
Nov 29 11:47:37.019: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 11:47:37.019: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/29/22 11:47:37.021
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7943, will wait for the garbage collector to delete the pods 11/29/22 11:47:37.021
Nov 29 11:47:37.077: INFO: Deleting DaemonSet.extensions daemon-set took: 3.01921ms
Nov 29 11:47:37.278: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.736316ms
Nov 29 11:47:39.582: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 11:47:39.582: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 29 11:47:39.584: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13362"},"items":null}

Nov 29 11:47:39.586: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13362"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 29 11:47:39.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7943" for this suite. 11/29/22 11:47:39.606
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":83,"skipped":1599,"failed":0}
------------------------------
• [SLOW TEST] [15.674 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:47:23.935
    Nov 29 11:47:23.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename daemonsets 11/29/22 11:47:23.936
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:23.948
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:23.954
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 11/29/22 11:47:23.976
    STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 11:47:23.98
    Nov 29 11:47:23.987: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 11:47:23.987: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:24.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 11:47:24.994: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:25.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:25.995: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:26.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:26.994: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:27.995: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:27.995: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:29.006: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:29.006: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:29.999: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:29.999: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:30.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:30.994: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:31.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:31.994: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:32.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:32.994: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 11:47:33.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 11:47:33.994: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 11/29/22 11:47:33.996
    Nov 29 11:47:34.011: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:34.011: INFO: Node dvi-7336-1669718118-vsp1-group1-1 is running 0 daemon pod, expected 1
    Nov 29 11:47:35.019: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:35.019: INFO: Node dvi-7336-1669718118-vsp1-group1-1 is running 0 daemon pod, expected 1
    Nov 29 11:47:36.018: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 11:47:36.018: INFO: Node dvi-7336-1669718118-vsp1-group1-1 is running 0 daemon pod, expected 1
    Nov 29 11:47:37.019: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 11:47:37.019: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/29/22 11:47:37.021
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7943, will wait for the garbage collector to delete the pods 11/29/22 11:47:37.021
    Nov 29 11:47:37.077: INFO: Deleting DaemonSet.extensions daemon-set took: 3.01921ms
    Nov 29 11:47:37.278: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.736316ms
    Nov 29 11:47:39.582: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 11:47:39.582: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 29 11:47:39.584: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13362"},"items":null}

    Nov 29 11:47:39.586: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13362"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 11:47:39.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7943" for this suite. 11/29/22 11:47:39.606
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:47:39.612
Nov 29 11:47:39.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:47:39.614
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:39.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:39.625
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 11/29/22 11:47:39.627
STEP: watching for the ServiceAccount to be added 11/29/22 11:47:39.633
STEP: patching the ServiceAccount 11/29/22 11:47:39.634
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/29/22 11:47:39.64
STEP: deleting the ServiceAccount 11/29/22 11:47:39.644
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 29 11:47:39.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4746" for this suite. 11/29/22 11:47:39.66
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":84,"skipped":1629,"failed":0}
------------------------------
• [0.052 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:47:39.612
    Nov 29 11:47:39.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:47:39.614
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:39.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:39.625
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 11/29/22 11:47:39.627
    STEP: watching for the ServiceAccount to be added 11/29/22 11:47:39.633
    STEP: patching the ServiceAccount 11/29/22 11:47:39.634
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/29/22 11:47:39.64
    STEP: deleting the ServiceAccount 11/29/22 11:47:39.644
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 29 11:47:39.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4746" for this suite. 11/29/22 11:47:39.66
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:47:39.664
Nov 29 11:47:39.665: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-probe 11/29/22 11:47:39.665
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:39.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:39.675
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1 in namespace container-probe-1416 11/29/22 11:47:39.677
Nov 29 11:47:39.682: INFO: Waiting up to 5m0s for pod "test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1" in namespace "container-probe-1416" to be "not pending"
Nov 29 11:47:39.685: INFO: Pod "test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.762485ms
Nov 29 11:47:41.689: INFO: Pod "test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1": Phase="Running", Reason="", readiness=true. Elapsed: 2.006558855s
Nov 29 11:47:41.689: INFO: Pod "test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1" satisfied condition "not pending"
Nov 29 11:47:41.689: INFO: Started pod test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1 in namespace container-probe-1416
STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 11:47:41.689
Nov 29 11:47:41.691: INFO: Initial restart count of pod test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1 is 0
STEP: deleting the pod 11/29/22 11:51:42.179
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 29 11:51:42.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1416" for this suite. 11/29/22 11:51:42.201
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":85,"skipped":1635,"failed":0}
------------------------------
• [SLOW TEST] [242.542 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:47:39.664
    Nov 29 11:47:39.665: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-probe 11/29/22 11:47:39.665
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:47:39.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:47:39.675
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1 in namespace container-probe-1416 11/29/22 11:47:39.677
    Nov 29 11:47:39.682: INFO: Waiting up to 5m0s for pod "test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1" in namespace "container-probe-1416" to be "not pending"
    Nov 29 11:47:39.685: INFO: Pod "test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.762485ms
    Nov 29 11:47:41.689: INFO: Pod "test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1": Phase="Running", Reason="", readiness=true. Elapsed: 2.006558855s
    Nov 29 11:47:41.689: INFO: Pod "test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1" satisfied condition "not pending"
    Nov 29 11:47:41.689: INFO: Started pod test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1 in namespace container-probe-1416
    STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 11:47:41.689
    Nov 29 11:47:41.691: INFO: Initial restart count of pod test-webserver-3f64eb9f-b27d-4a71-acc1-f9ccc41d5ec1 is 0
    STEP: deleting the pod 11/29/22 11:51:42.179
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 29 11:51:42.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1416" for this suite. 11/29/22 11:51:42.201
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:51:42.209
Nov 29 11:51:42.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 11:51:42.21
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:51:42.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:51:42.228
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-df1e85f5-770b-4c08-9714-27e82be0f9d1 11/29/22 11:51:42.234
STEP: Creating the pod 11/29/22 11:51:42.236
Nov 29 11:51:42.241: INFO: Waiting up to 5m0s for pod "pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8" in namespace "configmap-8503" to be "running and ready"
Nov 29 11:51:42.251: INFO: Pod "pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.965523ms
Nov 29 11:51:42.251: INFO: The phase of Pod pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:51:44.255: INFO: Pod "pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.014202235s
Nov 29 11:51:44.255: INFO: The phase of Pod pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8 is Running (Ready = true)
Nov 29 11:51:44.255: INFO: Pod "pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-df1e85f5-770b-4c08-9714-27e82be0f9d1 11/29/22 11:51:44.263
STEP: waiting to observe update in volume 11/29/22 11:51:44.266
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 11:53:06.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8503" for this suite. 11/29/22 11:53:06.569
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":86,"skipped":1676,"failed":0}
------------------------------
• [SLOW TEST] [84.363 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:51:42.209
    Nov 29 11:51:42.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 11:51:42.21
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:51:42.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:51:42.228
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-df1e85f5-770b-4c08-9714-27e82be0f9d1 11/29/22 11:51:42.234
    STEP: Creating the pod 11/29/22 11:51:42.236
    Nov 29 11:51:42.241: INFO: Waiting up to 5m0s for pod "pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8" in namespace "configmap-8503" to be "running and ready"
    Nov 29 11:51:42.251: INFO: Pod "pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.965523ms
    Nov 29 11:51:42.251: INFO: The phase of Pod pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:51:44.255: INFO: Pod "pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.014202235s
    Nov 29 11:51:44.255: INFO: The phase of Pod pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8 is Running (Ready = true)
    Nov 29 11:51:44.255: INFO: Pod "pod-configmaps-e9661b50-b1c6-49dd-8983-70f0a18271e8" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-df1e85f5-770b-4c08-9714-27e82be0f9d1 11/29/22 11:51:44.263
    STEP: waiting to observe update in volume 11/29/22 11:51:44.266
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 11:53:06.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8503" for this suite. 11/29/22 11:53:06.569
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:53:06.573
Nov 29 11:53:06.573: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename containers 11/29/22 11:53:06.574
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:53:06.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:53:06.584
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 11/29/22 11:53:06.586
Nov 29 11:53:06.590: INFO: Waiting up to 5m0s for pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673" in namespace "containers-9944" to be "Succeeded or Failed"
Nov 29 11:53:06.592: INFO: Pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673": Phase="Pending", Reason="", readiness=false. Elapsed: 1.936357ms
Nov 29 11:53:08.594: INFO: Pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004811942s
Nov 29 11:53:10.596: INFO: Pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006390245s
STEP: Saw pod success 11/29/22 11:53:10.596
Nov 29 11:53:10.596: INFO: Pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673" satisfied condition "Succeeded or Failed"
Nov 29 11:53:10.600: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod client-containers-59115bdb-e366-4601-b39d-74cae4e17673 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 11:53:10.606
Nov 29 11:53:10.612: INFO: Waiting for pod client-containers-59115bdb-e366-4601-b39d-74cae4e17673 to disappear
Nov 29 11:53:10.614: INFO: Pod client-containers-59115bdb-e366-4601-b39d-74cae4e17673 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 29 11:53:10.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9944" for this suite. 11/29/22 11:53:10.617
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":87,"skipped":1700,"failed":0}
------------------------------
• [4.047 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:53:06.573
    Nov 29 11:53:06.573: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename containers 11/29/22 11:53:06.574
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:53:06.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:53:06.584
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 11/29/22 11:53:06.586
    Nov 29 11:53:06.590: INFO: Waiting up to 5m0s for pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673" in namespace "containers-9944" to be "Succeeded or Failed"
    Nov 29 11:53:06.592: INFO: Pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673": Phase="Pending", Reason="", readiness=false. Elapsed: 1.936357ms
    Nov 29 11:53:08.594: INFO: Pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004811942s
    Nov 29 11:53:10.596: INFO: Pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006390245s
    STEP: Saw pod success 11/29/22 11:53:10.596
    Nov 29 11:53:10.596: INFO: Pod "client-containers-59115bdb-e366-4601-b39d-74cae4e17673" satisfied condition "Succeeded or Failed"
    Nov 29 11:53:10.600: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod client-containers-59115bdb-e366-4601-b39d-74cae4e17673 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 11:53:10.606
    Nov 29 11:53:10.612: INFO: Waiting for pod client-containers-59115bdb-e366-4601-b39d-74cae4e17673 to disappear
    Nov 29 11:53:10.614: INFO: Pod client-containers-59115bdb-e366-4601-b39d-74cae4e17673 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 29 11:53:10.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-9944" for this suite. 11/29/22 11:53:10.617
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:53:10.621
Nov 29 11:53:10.621: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename gc 11/29/22 11:53:10.622
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:53:10.631
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:53:10.633
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 11/29/22 11:53:10.64
STEP: create the rc2 11/29/22 11:53:10.643
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/29/22 11:53:15.822
STEP: delete the rc simpletest-rc-to-be-deleted 11/29/22 11:53:25.177
STEP: wait for the rc to be deleted 11/29/22 11:53:25.232
Nov 29 11:53:30.848: INFO: 67 pods remaining
Nov 29 11:53:30.848: INFO: 67 pods has nil DeletionTimestamp
Nov 29 11:53:30.848: INFO: 
STEP: Gathering metrics 11/29/22 11:53:35.24
W1129 11:53:35.249860      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 29 11:53:35.249: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov 29 11:53:35.249: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kcdv" in namespace "gc-7964"
Nov 29 11:53:35.364: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kt5z" in namespace "gc-7964"
Nov 29 11:53:35.638: INFO: Deleting pod "simpletest-rc-to-be-deleted-4955v" in namespace "gc-7964"
Nov 29 11:53:36.015: INFO: Deleting pod "simpletest-rc-to-be-deleted-4gdxl" in namespace "gc-7964"
Nov 29 11:53:36.248: INFO: Deleting pod "simpletest-rc-to-be-deleted-4l4t9" in namespace "gc-7964"
Nov 29 11:53:36.701: INFO: Deleting pod "simpletest-rc-to-be-deleted-4q7tb" in namespace "gc-7964"
Nov 29 11:53:36.804: INFO: Deleting pod "simpletest-rc-to-be-deleted-55bx8" in namespace "gc-7964"
Nov 29 11:53:36.912: INFO: Deleting pod "simpletest-rc-to-be-deleted-5cl2t" in namespace "gc-7964"
Nov 29 11:53:37.243: INFO: Deleting pod "simpletest-rc-to-be-deleted-5d66z" in namespace "gc-7964"
Nov 29 11:53:37.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dd9s" in namespace "gc-7964"
Nov 29 11:53:37.633: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jz4f" in namespace "gc-7964"
Nov 29 11:53:37.780: INFO: Deleting pod "simpletest-rc-to-be-deleted-5nl7w" in namespace "gc-7964"
Nov 29 11:53:38.195: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mq99" in namespace "gc-7964"
Nov 29 11:53:38.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-6zspl" in namespace "gc-7964"
Nov 29 11:53:39.033: INFO: Deleting pod "simpletest-rc-to-be-deleted-7mfwr" in namespace "gc-7964"
Nov 29 11:53:39.150: INFO: Deleting pod "simpletest-rc-to-be-deleted-7z8wd" in namespace "gc-7964"
Nov 29 11:53:39.224: INFO: Deleting pod "simpletest-rc-to-be-deleted-96lb8" in namespace "gc-7964"
Nov 29 11:53:39.297: INFO: Deleting pod "simpletest-rc-to-be-deleted-99p4c" in namespace "gc-7964"
Nov 29 11:53:40.050: INFO: Deleting pod "simpletest-rc-to-be-deleted-9glhl" in namespace "gc-7964"
Nov 29 11:53:40.852: INFO: Deleting pod "simpletest-rc-to-be-deleted-9wbvw" in namespace "gc-7964"
Nov 29 11:53:41.225: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbkbc" in namespace "gc-7964"
Nov 29 11:53:41.591: INFO: Deleting pod "simpletest-rc-to-be-deleted-brw7v" in namespace "gc-7964"
Nov 29 11:53:41.924: INFO: Deleting pod "simpletest-rc-to-be-deleted-c58dv" in namespace "gc-7964"
Nov 29 11:53:42.156: INFO: Deleting pod "simpletest-rc-to-be-deleted-ccj9g" in namespace "gc-7964"
Nov 29 11:53:42.384: INFO: Deleting pod "simpletest-rc-to-be-deleted-ccqxn" in namespace "gc-7964"
Nov 29 11:53:42.687: INFO: Deleting pod "simpletest-rc-to-be-deleted-cm9qx" in namespace "gc-7964"
Nov 29 11:53:42.894: INFO: Deleting pod "simpletest-rc-to-be-deleted-cqn5w" in namespace "gc-7964"
Nov 29 11:53:43.548: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddmnz" in namespace "gc-7964"
Nov 29 11:53:43.784: INFO: Deleting pod "simpletest-rc-to-be-deleted-dlhwv" in namespace "gc-7964"
Nov 29 11:53:44.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-dqkgb" in namespace "gc-7964"
Nov 29 11:53:44.714: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzkxl" in namespace "gc-7964"
Nov 29 11:53:45.001: INFO: Deleting pod "simpletest-rc-to-be-deleted-f57dg" in namespace "gc-7964"
Nov 29 11:53:45.629: INFO: Deleting pod "simpletest-rc-to-be-deleted-fb9m6" in namespace "gc-7964"
Nov 29 11:53:46.208: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftzkv" in namespace "gc-7964"
Nov 29 11:53:46.771: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfjmw" in namespace "gc-7964"
Nov 29 11:53:46.902: INFO: Deleting pod "simpletest-rc-to-be-deleted-gjzmg" in namespace "gc-7964"
Nov 29 11:53:47.506: INFO: Deleting pod "simpletest-rc-to-be-deleted-gx8kf" in namespace "gc-7964"
Nov 29 11:53:48.253: INFO: Deleting pod "simpletest-rc-to-be-deleted-h2l85" in namespace "gc-7964"
Nov 29 11:53:48.492: INFO: Deleting pod "simpletest-rc-to-be-deleted-h8pjw" in namespace "gc-7964"
Nov 29 11:53:48.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-h9gqs" in namespace "gc-7964"
Nov 29 11:53:49.243: INFO: Deleting pod "simpletest-rc-to-be-deleted-hk4hj" in namespace "gc-7964"
Nov 29 11:53:50.231: INFO: Deleting pod "simpletest-rc-to-be-deleted-hm8fn" in namespace "gc-7964"
Nov 29 11:53:50.492: INFO: Deleting pod "simpletest-rc-to-be-deleted-htg8h" in namespace "gc-7964"
Nov 29 11:53:51.051: INFO: Deleting pod "simpletest-rc-to-be-deleted-jc9zz" in namespace "gc-7964"
Nov 29 11:53:51.236: INFO: Deleting pod "simpletest-rc-to-be-deleted-jjvqg" in namespace "gc-7964"
Nov 29 11:53:51.458: INFO: Deleting pod "simpletest-rc-to-be-deleted-jlb46" in namespace "gc-7964"
Nov 29 11:53:51.861: INFO: Deleting pod "simpletest-rc-to-be-deleted-jnmqj" in namespace "gc-7964"
Nov 29 11:53:52.008: INFO: Deleting pod "simpletest-rc-to-be-deleted-k5p94" in namespace "gc-7964"
Nov 29 11:53:52.071: INFO: Deleting pod "simpletest-rc-to-be-deleted-kdd26" in namespace "gc-7964"
Nov 29 11:53:52.624: INFO: Deleting pod "simpletest-rc-to-be-deleted-kjhw8" in namespace "gc-7964"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 29 11:53:53.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7964" for this suite. 11/29/22 11:53:53.377
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":88,"skipped":1708,"failed":0}
------------------------------
• [SLOW TEST] [43.035 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:53:10.621
    Nov 29 11:53:10.621: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename gc 11/29/22 11:53:10.622
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:53:10.631
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:53:10.633
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 11/29/22 11:53:10.64
    STEP: create the rc2 11/29/22 11:53:10.643
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/29/22 11:53:15.822
    STEP: delete the rc simpletest-rc-to-be-deleted 11/29/22 11:53:25.177
    STEP: wait for the rc to be deleted 11/29/22 11:53:25.232
    Nov 29 11:53:30.848: INFO: 67 pods remaining
    Nov 29 11:53:30.848: INFO: 67 pods has nil DeletionTimestamp
    Nov 29 11:53:30.848: INFO: 
    STEP: Gathering metrics 11/29/22 11:53:35.24
    W1129 11:53:35.249860      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 29 11:53:35.249: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov 29 11:53:35.249: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kcdv" in namespace "gc-7964"
    Nov 29 11:53:35.364: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kt5z" in namespace "gc-7964"
    Nov 29 11:53:35.638: INFO: Deleting pod "simpletest-rc-to-be-deleted-4955v" in namespace "gc-7964"
    Nov 29 11:53:36.015: INFO: Deleting pod "simpletest-rc-to-be-deleted-4gdxl" in namespace "gc-7964"
    Nov 29 11:53:36.248: INFO: Deleting pod "simpletest-rc-to-be-deleted-4l4t9" in namespace "gc-7964"
    Nov 29 11:53:36.701: INFO: Deleting pod "simpletest-rc-to-be-deleted-4q7tb" in namespace "gc-7964"
    Nov 29 11:53:36.804: INFO: Deleting pod "simpletest-rc-to-be-deleted-55bx8" in namespace "gc-7964"
    Nov 29 11:53:36.912: INFO: Deleting pod "simpletest-rc-to-be-deleted-5cl2t" in namespace "gc-7964"
    Nov 29 11:53:37.243: INFO: Deleting pod "simpletest-rc-to-be-deleted-5d66z" in namespace "gc-7964"
    Nov 29 11:53:37.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dd9s" in namespace "gc-7964"
    Nov 29 11:53:37.633: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jz4f" in namespace "gc-7964"
    Nov 29 11:53:37.780: INFO: Deleting pod "simpletest-rc-to-be-deleted-5nl7w" in namespace "gc-7964"
    Nov 29 11:53:38.195: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mq99" in namespace "gc-7964"
    Nov 29 11:53:38.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-6zspl" in namespace "gc-7964"
    Nov 29 11:53:39.033: INFO: Deleting pod "simpletest-rc-to-be-deleted-7mfwr" in namespace "gc-7964"
    Nov 29 11:53:39.150: INFO: Deleting pod "simpletest-rc-to-be-deleted-7z8wd" in namespace "gc-7964"
    Nov 29 11:53:39.224: INFO: Deleting pod "simpletest-rc-to-be-deleted-96lb8" in namespace "gc-7964"
    Nov 29 11:53:39.297: INFO: Deleting pod "simpletest-rc-to-be-deleted-99p4c" in namespace "gc-7964"
    Nov 29 11:53:40.050: INFO: Deleting pod "simpletest-rc-to-be-deleted-9glhl" in namespace "gc-7964"
    Nov 29 11:53:40.852: INFO: Deleting pod "simpletest-rc-to-be-deleted-9wbvw" in namespace "gc-7964"
    Nov 29 11:53:41.225: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbkbc" in namespace "gc-7964"
    Nov 29 11:53:41.591: INFO: Deleting pod "simpletest-rc-to-be-deleted-brw7v" in namespace "gc-7964"
    Nov 29 11:53:41.924: INFO: Deleting pod "simpletest-rc-to-be-deleted-c58dv" in namespace "gc-7964"
    Nov 29 11:53:42.156: INFO: Deleting pod "simpletest-rc-to-be-deleted-ccj9g" in namespace "gc-7964"
    Nov 29 11:53:42.384: INFO: Deleting pod "simpletest-rc-to-be-deleted-ccqxn" in namespace "gc-7964"
    Nov 29 11:53:42.687: INFO: Deleting pod "simpletest-rc-to-be-deleted-cm9qx" in namespace "gc-7964"
    Nov 29 11:53:42.894: INFO: Deleting pod "simpletest-rc-to-be-deleted-cqn5w" in namespace "gc-7964"
    Nov 29 11:53:43.548: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddmnz" in namespace "gc-7964"
    Nov 29 11:53:43.784: INFO: Deleting pod "simpletest-rc-to-be-deleted-dlhwv" in namespace "gc-7964"
    Nov 29 11:53:44.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-dqkgb" in namespace "gc-7964"
    Nov 29 11:53:44.714: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzkxl" in namespace "gc-7964"
    Nov 29 11:53:45.001: INFO: Deleting pod "simpletest-rc-to-be-deleted-f57dg" in namespace "gc-7964"
    Nov 29 11:53:45.629: INFO: Deleting pod "simpletest-rc-to-be-deleted-fb9m6" in namespace "gc-7964"
    Nov 29 11:53:46.208: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftzkv" in namespace "gc-7964"
    Nov 29 11:53:46.771: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfjmw" in namespace "gc-7964"
    Nov 29 11:53:46.902: INFO: Deleting pod "simpletest-rc-to-be-deleted-gjzmg" in namespace "gc-7964"
    Nov 29 11:53:47.506: INFO: Deleting pod "simpletest-rc-to-be-deleted-gx8kf" in namespace "gc-7964"
    Nov 29 11:53:48.253: INFO: Deleting pod "simpletest-rc-to-be-deleted-h2l85" in namespace "gc-7964"
    Nov 29 11:53:48.492: INFO: Deleting pod "simpletest-rc-to-be-deleted-h8pjw" in namespace "gc-7964"
    Nov 29 11:53:48.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-h9gqs" in namespace "gc-7964"
    Nov 29 11:53:49.243: INFO: Deleting pod "simpletest-rc-to-be-deleted-hk4hj" in namespace "gc-7964"
    Nov 29 11:53:50.231: INFO: Deleting pod "simpletest-rc-to-be-deleted-hm8fn" in namespace "gc-7964"
    Nov 29 11:53:50.492: INFO: Deleting pod "simpletest-rc-to-be-deleted-htg8h" in namespace "gc-7964"
    Nov 29 11:53:51.051: INFO: Deleting pod "simpletest-rc-to-be-deleted-jc9zz" in namespace "gc-7964"
    Nov 29 11:53:51.236: INFO: Deleting pod "simpletest-rc-to-be-deleted-jjvqg" in namespace "gc-7964"
    Nov 29 11:53:51.458: INFO: Deleting pod "simpletest-rc-to-be-deleted-jlb46" in namespace "gc-7964"
    Nov 29 11:53:51.861: INFO: Deleting pod "simpletest-rc-to-be-deleted-jnmqj" in namespace "gc-7964"
    Nov 29 11:53:52.008: INFO: Deleting pod "simpletest-rc-to-be-deleted-k5p94" in namespace "gc-7964"
    Nov 29 11:53:52.071: INFO: Deleting pod "simpletest-rc-to-be-deleted-kdd26" in namespace "gc-7964"
    Nov 29 11:53:52.624: INFO: Deleting pod "simpletest-rc-to-be-deleted-kjhw8" in namespace "gc-7964"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 29 11:53:53.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7964" for this suite. 11/29/22 11:53:53.377
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:53:53.659
Nov 29 11:53:53.659: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 11:53:53.66
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:53:54.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:53:54.178
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 11/29/22 11:53:54.18
Nov 29 11:53:54.415: INFO: Waiting up to 5m0s for pod "downward-api-567522b1-8144-490e-9687-50021819310a" in namespace "downward-api-5349" to be "Succeeded or Failed"
Nov 29 11:53:55.209: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 793.85056ms
Nov 29 11:53:57.377: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.962251061s
Nov 29 11:53:59.451: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.036087891s
Nov 29 11:54:01.291: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.876332369s
Nov 29 11:54:03.594: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.179175977s
Nov 29 11:54:05.672: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.257094985s
Nov 29 11:54:07.637: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.221562421s
Nov 29 11:54:09.853: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.438096031s
Nov 29 11:54:11.223: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.808142345s
Nov 29 11:54:13.364: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.948640482s
Nov 29 11:54:15.214: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.799438758s
Nov 29 11:54:17.216: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.800547367s
Nov 29 11:54:19.330: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.915111931s
Nov 29 11:54:21.252: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Running", Reason="", readiness=true. Elapsed: 26.836598576s
Nov 29 11:54:23.212: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Running", Reason="", readiness=false. Elapsed: 28.797042741s
Nov 29 11:54:25.212: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.79694511s
STEP: Saw pod success 11/29/22 11:54:25.212
Nov 29 11:54:25.212: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a" satisfied condition "Succeeded or Failed"
Nov 29 11:54:25.217: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downward-api-567522b1-8144-490e-9687-50021819310a container dapi-container: <nil>
STEP: delete the pod 11/29/22 11:54:25.221
Nov 29 11:54:25.228: INFO: Waiting for pod downward-api-567522b1-8144-490e-9687-50021819310a to disappear
Nov 29 11:54:25.230: INFO: Pod downward-api-567522b1-8144-490e-9687-50021819310a no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 29 11:54:25.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5349" for this suite. 11/29/22 11:54:25.232
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":89,"skipped":1760,"failed":0}
------------------------------
• [SLOW TEST] [31.576 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:53:53.659
    Nov 29 11:53:53.659: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 11:53:53.66
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:53:54.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:53:54.178
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 11/29/22 11:53:54.18
    Nov 29 11:53:54.415: INFO: Waiting up to 5m0s for pod "downward-api-567522b1-8144-490e-9687-50021819310a" in namespace "downward-api-5349" to be "Succeeded or Failed"
    Nov 29 11:53:55.209: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 793.85056ms
    Nov 29 11:53:57.377: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.962251061s
    Nov 29 11:53:59.451: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.036087891s
    Nov 29 11:54:01.291: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.876332369s
    Nov 29 11:54:03.594: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.179175977s
    Nov 29 11:54:05.672: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.257094985s
    Nov 29 11:54:07.637: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.221562421s
    Nov 29 11:54:09.853: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.438096031s
    Nov 29 11:54:11.223: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.808142345s
    Nov 29 11:54:13.364: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.948640482s
    Nov 29 11:54:15.214: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.799438758s
    Nov 29 11:54:17.216: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.800547367s
    Nov 29 11:54:19.330: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.915111931s
    Nov 29 11:54:21.252: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Running", Reason="", readiness=true. Elapsed: 26.836598576s
    Nov 29 11:54:23.212: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Running", Reason="", readiness=false. Elapsed: 28.797042741s
    Nov 29 11:54:25.212: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.79694511s
    STEP: Saw pod success 11/29/22 11:54:25.212
    Nov 29 11:54:25.212: INFO: Pod "downward-api-567522b1-8144-490e-9687-50021819310a" satisfied condition "Succeeded or Failed"
    Nov 29 11:54:25.217: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downward-api-567522b1-8144-490e-9687-50021819310a container dapi-container: <nil>
    STEP: delete the pod 11/29/22 11:54:25.221
    Nov 29 11:54:25.228: INFO: Waiting for pod downward-api-567522b1-8144-490e-9687-50021819310a to disappear
    Nov 29 11:54:25.230: INFO: Pod downward-api-567522b1-8144-490e-9687-50021819310a no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 29 11:54:25.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5349" for this suite. 11/29/22 11:54:25.232
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:54:25.235
Nov 29 11:54:25.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 11:54:25.236
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:54:25.244
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:54:25.246
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 11/29/22 11:54:25.249
Nov 29 11:54:25.253: INFO: Waiting up to 5m0s for pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f" in namespace "downward-api-9371" to be "Succeeded or Failed"
Nov 29 11:54:25.256: INFO: Pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.904374ms
Nov 29 11:54:27.259: INFO: Pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005986257s
Nov 29 11:54:29.269: INFO: Pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014993033s
STEP: Saw pod success 11/29/22 11:54:29.269
Nov 29 11:54:29.269: INFO: Pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f" satisfied condition "Succeeded or Failed"
Nov 29 11:54:29.270: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f container dapi-container: <nil>
STEP: delete the pod 11/29/22 11:54:29.274
Nov 29 11:54:29.327: INFO: Waiting for pod downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f to disappear
Nov 29 11:54:29.335: INFO: Pod downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 29 11:54:29.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9371" for this suite. 11/29/22 11:54:29.339
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":90,"skipped":1768,"failed":0}
------------------------------
• [4.108 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:54:25.235
    Nov 29 11:54:25.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 11:54:25.236
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:54:25.244
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:54:25.246
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 11/29/22 11:54:25.249
    Nov 29 11:54:25.253: INFO: Waiting up to 5m0s for pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f" in namespace "downward-api-9371" to be "Succeeded or Failed"
    Nov 29 11:54:25.256: INFO: Pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.904374ms
    Nov 29 11:54:27.259: INFO: Pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005986257s
    Nov 29 11:54:29.269: INFO: Pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014993033s
    STEP: Saw pod success 11/29/22 11:54:29.269
    Nov 29 11:54:29.269: INFO: Pod "downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f" satisfied condition "Succeeded or Failed"
    Nov 29 11:54:29.270: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f container dapi-container: <nil>
    STEP: delete the pod 11/29/22 11:54:29.274
    Nov 29 11:54:29.327: INFO: Waiting for pod downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f to disappear
    Nov 29 11:54:29.335: INFO: Pod downward-api-d9cf1b2e-a7ef-4305-a8fe-7ead90bc876f no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 29 11:54:29.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9371" for this suite. 11/29/22 11:54:29.339
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:54:29.345
Nov 29 11:54:29.345: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-preemption 11/29/22 11:54:29.346
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:54:29.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:54:29.358
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 29 11:54:29.369: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 29 11:55:29.403: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:55:29.405
Nov 29 11:55:29.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-preemption-path 11/29/22 11:55:29.406
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:55:29.414
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:55:29.416
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 11/29/22 11:55:29.418
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/29/22 11:55:29.418
Nov 29 11:55:29.423: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-5693" to be "running"
Nov 29 11:55:29.425: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48358ms
Nov 29 11:55:31.430: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.007023599s
Nov 29 11:55:31.430: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/29/22 11:55:31.432
Nov 29 11:55:31.439: INFO: found a healthy node: dvi-7336-1669718118-vsp1-group1-2
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Nov 29 11:55:39.508: INFO: pods created so far: [1 1 1]
Nov 29 11:55:39.508: INFO: length of pods created so far: 3
Nov 29 11:55:43.516: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Nov 29 11:55:50.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-5693" for this suite. 11/29/22 11:55:50.523
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 29 11:55:50.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2003" for this suite. 11/29/22 11:55:50.551
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":91,"skipped":1790,"failed":0}
------------------------------
• [SLOW TEST] [81.252 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:54:29.345
    Nov 29 11:54:29.345: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-preemption 11/29/22 11:54:29.346
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:54:29.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:54:29.358
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 29 11:54:29.369: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 29 11:55:29.403: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:55:29.405
    Nov 29 11:55:29.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-preemption-path 11/29/22 11:55:29.406
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:55:29.414
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:55:29.416
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 11/29/22 11:55:29.418
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/29/22 11:55:29.418
    Nov 29 11:55:29.423: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-5693" to be "running"
    Nov 29 11:55:29.425: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48358ms
    Nov 29 11:55:31.430: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.007023599s
    Nov 29 11:55:31.430: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/29/22 11:55:31.432
    Nov 29 11:55:31.439: INFO: found a healthy node: dvi-7336-1669718118-vsp1-group1-2
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Nov 29 11:55:39.508: INFO: pods created so far: [1 1 1]
    Nov 29 11:55:39.508: INFO: length of pods created so far: 3
    Nov 29 11:55:43.516: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Nov 29 11:55:50.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-5693" for this suite. 11/29/22 11:55:50.523
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 11:55:50.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-2003" for this suite. 11/29/22 11:55:50.551
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:55:50.598
Nov 29 11:55:50.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 11:55:50.6
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:55:50.613
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:55:50.616
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-1bccda77-59d6-4ae6-903e-c28148491d6f 11/29/22 11:55:50.619
STEP: Creating a pod to test consume configMaps 11/29/22 11:55:50.621
Nov 29 11:55:50.625: INFO: Waiting up to 5m0s for pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90" in namespace "configmap-4626" to be "Succeeded or Failed"
Nov 29 11:55:50.628: INFO: Pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90": Phase="Pending", Reason="", readiness=false. Elapsed: 3.046729ms
Nov 29 11:55:52.633: INFO: Pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008055362s
Nov 29 11:55:54.632: INFO: Pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006846549s
STEP: Saw pod success 11/29/22 11:55:54.632
Nov 29 11:55:54.632: INFO: Pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90" satisfied condition "Succeeded or Failed"
Nov 29 11:55:54.634: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 11:55:54.64
Nov 29 11:55:54.648: INFO: Waiting for pod pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90 to disappear
Nov 29 11:55:54.654: INFO: Pod pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 11:55:54.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4626" for this suite. 11/29/22 11:55:54.658
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":92,"skipped":1793,"failed":0}
------------------------------
• [4.063 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:55:50.598
    Nov 29 11:55:50.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 11:55:50.6
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:55:50.613
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:55:50.616
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-1bccda77-59d6-4ae6-903e-c28148491d6f 11/29/22 11:55:50.619
    STEP: Creating a pod to test consume configMaps 11/29/22 11:55:50.621
    Nov 29 11:55:50.625: INFO: Waiting up to 5m0s for pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90" in namespace "configmap-4626" to be "Succeeded or Failed"
    Nov 29 11:55:50.628: INFO: Pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90": Phase="Pending", Reason="", readiness=false. Elapsed: 3.046729ms
    Nov 29 11:55:52.633: INFO: Pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008055362s
    Nov 29 11:55:54.632: INFO: Pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006846549s
    STEP: Saw pod success 11/29/22 11:55:54.632
    Nov 29 11:55:54.632: INFO: Pod "pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90" satisfied condition "Succeeded or Failed"
    Nov 29 11:55:54.634: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 11:55:54.64
    Nov 29 11:55:54.648: INFO: Waiting for pod pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90 to disappear
    Nov 29 11:55:54.654: INFO: Pod pod-configmaps-b465c9e9-ab15-4822-b947-e001d030cb90 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 11:55:54.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4626" for this suite. 11/29/22 11:55:54.658
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:55:54.662
Nov 29 11:55:54.662: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubelet-test 11/29/22 11:55:54.664
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:55:54.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:55:54.675
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 29 11:55:54.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1147" for this suite. 11/29/22 11:55:54.693
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":93,"skipped":1796,"failed":0}
------------------------------
• [0.034 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:55:54.662
    Nov 29 11:55:54.662: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubelet-test 11/29/22 11:55:54.664
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:55:54.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:55:54.675
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 29 11:55:54.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-1147" for this suite. 11/29/22 11:55:54.693
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:55:54.697
Nov 29 11:55:54.697: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename var-expansion 11/29/22 11:55:54.698
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:55:54.708
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:55:54.711
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 11/29/22 11:55:54.713
Nov 29 11:55:54.725: INFO: Waiting up to 2m0s for pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" in namespace "var-expansion-3452" to be "running"
Nov 29 11:55:54.728: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 3.00593ms
Nov 29 11:55:56.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006697939s
Nov 29 11:55:58.737: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011900368s
Nov 29 11:56:00.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006513718s
Nov 29 11:56:02.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00680858s
Nov 29 11:56:04.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006043528s
Nov 29 11:56:06.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008044419s
Nov 29 11:56:08.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 14.005963786s
Nov 29 11:56:10.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006787656s
Nov 29 11:56:12.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 18.00832086s
Nov 29 11:56:14.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 20.006265122s
Nov 29 11:56:16.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 22.006261585s
Nov 29 11:56:18.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 24.006291114s
Nov 29 11:56:20.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 26.005732067s
Nov 29 11:56:22.735: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 28.009695285s
Nov 29 11:56:24.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 30.007978759s
Nov 29 11:56:26.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 32.00740548s
Nov 29 11:56:28.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 34.00628374s
Nov 29 11:56:30.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 36.006810602s
Nov 29 11:56:32.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 38.007292138s
Nov 29 11:56:34.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 40.007692326s
Nov 29 11:56:36.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 42.007664484s
Nov 29 11:56:38.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 44.006268174s
Nov 29 11:56:40.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 46.007678314s
Nov 29 11:56:42.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007286367s
Nov 29 11:56:44.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 50.00734776s
Nov 29 11:56:46.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 52.006061362s
Nov 29 11:56:48.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 54.007804209s
Nov 29 11:56:50.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 56.00732422s
Nov 29 11:56:52.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 58.008240591s
Nov 29 11:56:54.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.008029448s
Nov 29 11:56:56.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.006185101s
Nov 29 11:56:58.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.006168624s
Nov 29 11:57:00.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.006593113s
Nov 29 11:57:02.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.005789341s
Nov 29 11:57:04.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.006510818s
Nov 29 11:57:06.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.006012004s
Nov 29 11:57:08.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.006352287s
Nov 29 11:57:10.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.00702906s
Nov 29 11:57:12.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.006376878s
Nov 29 11:57:14.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.006708351s
Nov 29 11:57:16.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.006001811s
Nov 29 11:57:18.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.007691848s
Nov 29 11:57:20.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.008133019s
Nov 29 11:57:22.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.005999555s
Nov 29 11:57:24.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.006638408s
Nov 29 11:57:26.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.006558867s
Nov 29 11:57:28.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.00607725s
Nov 29 11:57:30.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.006411756s
Nov 29 11:57:32.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.006607535s
Nov 29 11:57:34.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.007035105s
Nov 29 11:57:36.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.006506023s
Nov 29 11:57:38.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.005818371s
Nov 29 11:57:40.735: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.010177228s
Nov 29 11:57:42.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.006965173s
Nov 29 11:57:44.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.006594275s
Nov 29 11:57:46.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.008398148s
Nov 29 11:57:48.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.007110711s
Nov 29 11:57:50.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007607616s
Nov 29 11:57:52.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.006086579s
Nov 29 11:57:54.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.007697755s
Nov 29 11:57:54.735: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.0100787s
STEP: updating the pod 11/29/22 11:57:54.735
Nov 29 11:57:55.244: INFO: Successfully updated pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99"
STEP: waiting for pod running 11/29/22 11:57:55.244
Nov 29 11:57:55.244: INFO: Waiting up to 2m0s for pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" in namespace "var-expansion-3452" to be "running"
Nov 29 11:57:55.252: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.503635ms
Nov 29 11:57:57.256: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Running", Reason="", readiness=true. Elapsed: 2.012396176s
Nov 29 11:57:57.256: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" satisfied condition "running"
STEP: deleting the pod gracefully 11/29/22 11:57:57.256
Nov 29 11:57:57.257: INFO: Deleting pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" in namespace "var-expansion-3452"
Nov 29 11:57:57.261: INFO: Wait up to 5m0s for pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 29 11:58:29.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3452" for this suite. 11/29/22 11:58:29.274
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":94,"skipped":1797,"failed":0}
------------------------------
• [SLOW TEST] [154.581 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:55:54.697
    Nov 29 11:55:54.697: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename var-expansion 11/29/22 11:55:54.698
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:55:54.708
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:55:54.711
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 11/29/22 11:55:54.713
    Nov 29 11:55:54.725: INFO: Waiting up to 2m0s for pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" in namespace "var-expansion-3452" to be "running"
    Nov 29 11:55:54.728: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 3.00593ms
    Nov 29 11:55:56.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006697939s
    Nov 29 11:55:58.737: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011900368s
    Nov 29 11:56:00.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006513718s
    Nov 29 11:56:02.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00680858s
    Nov 29 11:56:04.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006043528s
    Nov 29 11:56:06.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008044419s
    Nov 29 11:56:08.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 14.005963786s
    Nov 29 11:56:10.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006787656s
    Nov 29 11:56:12.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 18.00832086s
    Nov 29 11:56:14.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 20.006265122s
    Nov 29 11:56:16.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 22.006261585s
    Nov 29 11:56:18.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 24.006291114s
    Nov 29 11:56:20.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 26.005732067s
    Nov 29 11:56:22.735: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 28.009695285s
    Nov 29 11:56:24.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 30.007978759s
    Nov 29 11:56:26.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 32.00740548s
    Nov 29 11:56:28.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 34.00628374s
    Nov 29 11:56:30.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 36.006810602s
    Nov 29 11:56:32.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 38.007292138s
    Nov 29 11:56:34.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 40.007692326s
    Nov 29 11:56:36.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 42.007664484s
    Nov 29 11:56:38.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 44.006268174s
    Nov 29 11:56:40.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 46.007678314s
    Nov 29 11:56:42.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007286367s
    Nov 29 11:56:44.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 50.00734776s
    Nov 29 11:56:46.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 52.006061362s
    Nov 29 11:56:48.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 54.007804209s
    Nov 29 11:56:50.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 56.00732422s
    Nov 29 11:56:52.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 58.008240591s
    Nov 29 11:56:54.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.008029448s
    Nov 29 11:56:56.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.006185101s
    Nov 29 11:56:58.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.006168624s
    Nov 29 11:57:00.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.006593113s
    Nov 29 11:57:02.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.005789341s
    Nov 29 11:57:04.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.006510818s
    Nov 29 11:57:06.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.006012004s
    Nov 29 11:57:08.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.006352287s
    Nov 29 11:57:10.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.00702906s
    Nov 29 11:57:12.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.006376878s
    Nov 29 11:57:14.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.006708351s
    Nov 29 11:57:16.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.006001811s
    Nov 29 11:57:18.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.007691848s
    Nov 29 11:57:20.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.008133019s
    Nov 29 11:57:22.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.005999555s
    Nov 29 11:57:24.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.006638408s
    Nov 29 11:57:26.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.006558867s
    Nov 29 11:57:28.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.00607725s
    Nov 29 11:57:30.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.006411756s
    Nov 29 11:57:32.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.006607535s
    Nov 29 11:57:34.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.007035105s
    Nov 29 11:57:36.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.006506023s
    Nov 29 11:57:38.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.005818371s
    Nov 29 11:57:40.735: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.010177228s
    Nov 29 11:57:42.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.006965173s
    Nov 29 11:57:44.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.006594275s
    Nov 29 11:57:46.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.008398148s
    Nov 29 11:57:48.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.007110711s
    Nov 29 11:57:50.732: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007607616s
    Nov 29 11:57:52.731: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.006086579s
    Nov 29 11:57:54.733: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.007697755s
    Nov 29 11:57:54.735: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.0100787s
    STEP: updating the pod 11/29/22 11:57:54.735
    Nov 29 11:57:55.244: INFO: Successfully updated pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99"
    STEP: waiting for pod running 11/29/22 11:57:55.244
    Nov 29 11:57:55.244: INFO: Waiting up to 2m0s for pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" in namespace "var-expansion-3452" to be "running"
    Nov 29 11:57:55.252: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.503635ms
    Nov 29 11:57:57.256: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99": Phase="Running", Reason="", readiness=true. Elapsed: 2.012396176s
    Nov 29 11:57:57.256: INFO: Pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" satisfied condition "running"
    STEP: deleting the pod gracefully 11/29/22 11:57:57.256
    Nov 29 11:57:57.257: INFO: Deleting pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" in namespace "var-expansion-3452"
    Nov 29 11:57:57.261: INFO: Wait up to 5m0s for pod "var-expansion-f45bb2ee-3409-4de0-8189-1c490dfc4e99" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 29 11:58:29.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3452" for this suite. 11/29/22 11:58:29.274
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:29.282
Nov 29 11:58:29.282: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 11:58:29.282
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:29.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:29.294
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 11/29/22 11:58:29.296
Nov 29 11:58:29.300: INFO: Waiting up to 5m0s for pod "pod-r8lx4" in namespace "pods-9474" to be "running"
Nov 29 11:58:29.302: INFO: Pod "pod-r8lx4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070853ms
Nov 29 11:58:31.306: INFO: Pod "pod-r8lx4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006151004s
Nov 29 11:58:31.306: INFO: Pod "pod-r8lx4" satisfied condition "running"
STEP: patching /status 11/29/22 11:58:31.306
Nov 29 11:58:31.314: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 11:58:31.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9474" for this suite. 11/29/22 11:58:31.324
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":95,"skipped":1842,"failed":0}
------------------------------
• [2.047 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:29.282
    Nov 29 11:58:29.282: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 11:58:29.282
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:29.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:29.294
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 11/29/22 11:58:29.296
    Nov 29 11:58:29.300: INFO: Waiting up to 5m0s for pod "pod-r8lx4" in namespace "pods-9474" to be "running"
    Nov 29 11:58:29.302: INFO: Pod "pod-r8lx4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070853ms
    Nov 29 11:58:31.306: INFO: Pod "pod-r8lx4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006151004s
    Nov 29 11:58:31.306: INFO: Pod "pod-r8lx4" satisfied condition "running"
    STEP: patching /status 11/29/22 11:58:31.306
    Nov 29 11:58:31.314: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 11:58:31.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9474" for this suite. 11/29/22 11:58:31.324
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:31.329
Nov 29 11:58:31.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 11:58:31.33
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:31.339
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:31.341
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 11/29/22 11:58:31.343
Nov 29 11:58:31.347: INFO: Waiting up to 5m0s for pod "pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e" in namespace "pods-2699" to be "running and ready"
Nov 29 11:58:31.350: INFO: Pod "pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48711ms
Nov 29 11:58:31.350: INFO: The phase of Pod pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:58:33.353: INFO: Pod "pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e": Phase="Running", Reason="", readiness=true. Elapsed: 2.006124042s
Nov 29 11:58:33.353: INFO: The phase of Pod pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e is Running (Ready = true)
Nov 29 11:58:33.353: INFO: Pod "pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e" satisfied condition "running and ready"
Nov 29 11:58:33.358: INFO: Pod pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e has hostIP: 192.168.8.111
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 11:58:33.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2699" for this suite. 11/29/22 11:58:33.361
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":96,"skipped":1858,"failed":0}
------------------------------
• [2.036 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:31.329
    Nov 29 11:58:31.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 11:58:31.33
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:31.339
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:31.341
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 11/29/22 11:58:31.343
    Nov 29 11:58:31.347: INFO: Waiting up to 5m0s for pod "pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e" in namespace "pods-2699" to be "running and ready"
    Nov 29 11:58:31.350: INFO: Pod "pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48711ms
    Nov 29 11:58:31.350: INFO: The phase of Pod pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:58:33.353: INFO: Pod "pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e": Phase="Running", Reason="", readiness=true. Elapsed: 2.006124042s
    Nov 29 11:58:33.353: INFO: The phase of Pod pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e is Running (Ready = true)
    Nov 29 11:58:33.353: INFO: Pod "pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e" satisfied condition "running and ready"
    Nov 29 11:58:33.358: INFO: Pod pod-hostip-645fa1dd-c167-43cc-b710-4bcb15c8e05e has hostIP: 192.168.8.111
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 11:58:33.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2699" for this suite. 11/29/22 11:58:33.361
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:33.366
Nov 29 11:58:33.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 11:58:33.366
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:33.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:33.379
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 11/29/22 11:58:33.381
Nov 29 11:58:33.386: INFO: Waiting up to 5m0s for pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30" in namespace "emptydir-394" to be "Succeeded or Failed"
Nov 29 11:58:33.399: INFO: Pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30": Phase="Pending", Reason="", readiness=false. Elapsed: 12.941281ms
Nov 29 11:58:35.401: INFO: Pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30": Phase="Running", Reason="", readiness=false. Elapsed: 2.015570624s
Nov 29 11:58:37.403: INFO: Pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017337825s
STEP: Saw pod success 11/29/22 11:58:37.403
Nov 29 11:58:37.403: INFO: Pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30" satisfied condition "Succeeded or Failed"
Nov 29 11:58:37.405: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30 container test-container: <nil>
STEP: delete the pod 11/29/22 11:58:37.419
Nov 29 11:58:37.427: INFO: Waiting for pod pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30 to disappear
Nov 29 11:58:37.429: INFO: Pod pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 11:58:37.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-394" for this suite. 11/29/22 11:58:37.433
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":97,"skipped":1869,"failed":0}
------------------------------
• [4.071 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:33.366
    Nov 29 11:58:33.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 11:58:33.366
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:33.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:33.379
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 11/29/22 11:58:33.381
    Nov 29 11:58:33.386: INFO: Waiting up to 5m0s for pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30" in namespace "emptydir-394" to be "Succeeded or Failed"
    Nov 29 11:58:33.399: INFO: Pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30": Phase="Pending", Reason="", readiness=false. Elapsed: 12.941281ms
    Nov 29 11:58:35.401: INFO: Pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30": Phase="Running", Reason="", readiness=false. Elapsed: 2.015570624s
    Nov 29 11:58:37.403: INFO: Pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017337825s
    STEP: Saw pod success 11/29/22 11:58:37.403
    Nov 29 11:58:37.403: INFO: Pod "pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30" satisfied condition "Succeeded or Failed"
    Nov 29 11:58:37.405: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30 container test-container: <nil>
    STEP: delete the pod 11/29/22 11:58:37.419
    Nov 29 11:58:37.427: INFO: Waiting for pod pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30 to disappear
    Nov 29 11:58:37.429: INFO: Pod pod-42798e51-0ce8-44d3-8649-6c6bbdf47d30 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 11:58:37.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-394" for this suite. 11/29/22 11:58:37.433
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:37.44
Nov 29 11:58:37.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 11:58:37.441
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:37.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:37.458
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-af5b3c3f-c457-4fbd-b7a6-cb94aaef9bb3 11/29/22 11:58:37.46
STEP: Creating a pod to test consume configMaps 11/29/22 11:58:37.463
Nov 29 11:58:37.467: INFO: Waiting up to 5m0s for pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8" in namespace "configmap-8733" to be "Succeeded or Failed"
Nov 29 11:58:37.469: INFO: Pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037411ms
Nov 29 11:58:39.472: INFO: Pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004906912s
Nov 29 11:58:41.473: INFO: Pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005975772s
STEP: Saw pod success 11/29/22 11:58:41.473
Nov 29 11:58:41.473: INFO: Pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8" satisfied condition "Succeeded or Failed"
Nov 29 11:58:41.475: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 11:58:41.479
Nov 29 11:58:41.484: INFO: Waiting for pod pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8 to disappear
Nov 29 11:58:41.486: INFO: Pod pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 11:58:41.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8733" for this suite. 11/29/22 11:58:41.489
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":98,"skipped":1924,"failed":0}
------------------------------
• [4.052 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:37.44
    Nov 29 11:58:37.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 11:58:37.441
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:37.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:37.458
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-af5b3c3f-c457-4fbd-b7a6-cb94aaef9bb3 11/29/22 11:58:37.46
    STEP: Creating a pod to test consume configMaps 11/29/22 11:58:37.463
    Nov 29 11:58:37.467: INFO: Waiting up to 5m0s for pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8" in namespace "configmap-8733" to be "Succeeded or Failed"
    Nov 29 11:58:37.469: INFO: Pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037411ms
    Nov 29 11:58:39.472: INFO: Pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004906912s
    Nov 29 11:58:41.473: INFO: Pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005975772s
    STEP: Saw pod success 11/29/22 11:58:41.473
    Nov 29 11:58:41.473: INFO: Pod "pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8" satisfied condition "Succeeded or Failed"
    Nov 29 11:58:41.475: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 11:58:41.479
    Nov 29 11:58:41.484: INFO: Waiting for pod pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8 to disappear
    Nov 29 11:58:41.486: INFO: Pod pod-configmaps-246d3e48-c04e-4559-ba2f-c9dadd0a9bb8 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 11:58:41.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8733" for this suite. 11/29/22 11:58:41.489
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:41.492
Nov 29 11:58:41.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename endpointslice 11/29/22 11:58:41.493
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:41.502
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:41.504
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 11/29/22 11:58:41.506
STEP: getting /apis/discovery.k8s.io 11/29/22 11:58:41.507
STEP: getting /apis/discovery.k8s.iov1 11/29/22 11:58:41.508
STEP: creating 11/29/22 11:58:41.509
STEP: getting 11/29/22 11:58:41.518
STEP: listing 11/29/22 11:58:41.52
STEP: watching 11/29/22 11:58:41.522
Nov 29 11:58:41.522: INFO: starting watch
STEP: cluster-wide listing 11/29/22 11:58:41.522
STEP: cluster-wide watching 11/29/22 11:58:41.524
Nov 29 11:58:41.524: INFO: starting watch
STEP: patching 11/29/22 11:58:41.525
STEP: updating 11/29/22 11:58:41.527
Nov 29 11:58:41.532: INFO: waiting for watch events with expected annotations
Nov 29 11:58:41.532: INFO: saw patched and updated annotations
STEP: deleting 11/29/22 11:58:41.532
STEP: deleting a collection 11/29/22 11:58:41.539
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 29 11:58:41.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2877" for this suite. 11/29/22 11:58:41.548
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":99,"skipped":1934,"failed":0}
------------------------------
• [0.059 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:41.492
    Nov 29 11:58:41.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename endpointslice 11/29/22 11:58:41.493
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:41.502
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:41.504
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 11/29/22 11:58:41.506
    STEP: getting /apis/discovery.k8s.io 11/29/22 11:58:41.507
    STEP: getting /apis/discovery.k8s.iov1 11/29/22 11:58:41.508
    STEP: creating 11/29/22 11:58:41.509
    STEP: getting 11/29/22 11:58:41.518
    STEP: listing 11/29/22 11:58:41.52
    STEP: watching 11/29/22 11:58:41.522
    Nov 29 11:58:41.522: INFO: starting watch
    STEP: cluster-wide listing 11/29/22 11:58:41.522
    STEP: cluster-wide watching 11/29/22 11:58:41.524
    Nov 29 11:58:41.524: INFO: starting watch
    STEP: patching 11/29/22 11:58:41.525
    STEP: updating 11/29/22 11:58:41.527
    Nov 29 11:58:41.532: INFO: waiting for watch events with expected annotations
    Nov 29 11:58:41.532: INFO: saw patched and updated annotations
    STEP: deleting 11/29/22 11:58:41.532
    STEP: deleting a collection 11/29/22 11:58:41.539
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 29 11:58:41.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2877" for this suite. 11/29/22 11:58:41.548
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:41.553
Nov 29 11:58:41.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 11:58:41.554
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:41.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:41.564
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-862d24c2-9690-4978-99d6-e73d433a9614 11/29/22 11:58:41.566
STEP: Creating a pod to test consume configMaps 11/29/22 11:58:41.573
Nov 29 11:58:41.577: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181" in namespace "projected-7569" to be "Succeeded or Failed"
Nov 29 11:58:41.581: INFO: Pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181": Phase="Pending", Reason="", readiness=false. Elapsed: 3.218955ms
Nov 29 11:58:43.584: INFO: Pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006300922s
Nov 29 11:58:45.585: INFO: Pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007497792s
STEP: Saw pod success 11/29/22 11:58:45.585
Nov 29 11:58:45.585: INFO: Pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181" satisfied condition "Succeeded or Failed"
Nov 29 11:58:45.587: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 11:58:45.591
Nov 29 11:58:45.597: INFO: Waiting for pod pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181 to disappear
Nov 29 11:58:45.599: INFO: Pod pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 11:58:45.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7569" for this suite. 11/29/22 11:58:45.602
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":100,"skipped":1936,"failed":0}
------------------------------
• [4.053 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:41.553
    Nov 29 11:58:41.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 11:58:41.554
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:41.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:41.564
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-862d24c2-9690-4978-99d6-e73d433a9614 11/29/22 11:58:41.566
    STEP: Creating a pod to test consume configMaps 11/29/22 11:58:41.573
    Nov 29 11:58:41.577: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181" in namespace "projected-7569" to be "Succeeded or Failed"
    Nov 29 11:58:41.581: INFO: Pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181": Phase="Pending", Reason="", readiness=false. Elapsed: 3.218955ms
    Nov 29 11:58:43.584: INFO: Pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006300922s
    Nov 29 11:58:45.585: INFO: Pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007497792s
    STEP: Saw pod success 11/29/22 11:58:45.585
    Nov 29 11:58:45.585: INFO: Pod "pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181" satisfied condition "Succeeded or Failed"
    Nov 29 11:58:45.587: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 11:58:45.591
    Nov 29 11:58:45.597: INFO: Waiting for pod pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181 to disappear
    Nov 29 11:58:45.599: INFO: Pod pod-projected-configmaps-d9774a52-80e5-42ef-b3d4-bec1c7fd0181 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 11:58:45.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7569" for this suite. 11/29/22 11:58:45.602
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:45.606
Nov 29 11:58:45.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename watch 11/29/22 11:58:45.607
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:45.617
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:45.618
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 11/29/22 11:58:45.62
STEP: creating a new configmap 11/29/22 11:58:45.621
STEP: modifying the configmap once 11/29/22 11:58:45.624
STEP: closing the watch once it receives two notifications 11/29/22 11:58:45.628
Nov 29 11:58:45.628: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8796  42c57bf8-faf2-42d5-8179-49f59d336c07 16721 0 2022-11-29 11:58:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-29 11:58:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 11:58:45.628: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8796  42c57bf8-faf2-42d5-8179-49f59d336c07 16722 0 2022-11-29 11:58:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-29 11:58:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 11/29/22 11:58:45.628
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/29/22 11:58:45.633
STEP: deleting the configmap 11/29/22 11:58:45.634
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/29/22 11:58:45.636
Nov 29 11:58:45.636: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8796  42c57bf8-faf2-42d5-8179-49f59d336c07 16723 0 2022-11-29 11:58:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-29 11:58:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 11:58:45.637: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8796  42c57bf8-faf2-42d5-8179-49f59d336c07 16724 0 2022-11-29 11:58:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-29 11:58:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 29 11:58:45.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8796" for this suite. 11/29/22 11:58:45.64
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":101,"skipped":1939,"failed":0}
------------------------------
• [0.037 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:45.606
    Nov 29 11:58:45.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename watch 11/29/22 11:58:45.607
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:45.617
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:45.618
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 11/29/22 11:58:45.62
    STEP: creating a new configmap 11/29/22 11:58:45.621
    STEP: modifying the configmap once 11/29/22 11:58:45.624
    STEP: closing the watch once it receives two notifications 11/29/22 11:58:45.628
    Nov 29 11:58:45.628: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8796  42c57bf8-faf2-42d5-8179-49f59d336c07 16721 0 2022-11-29 11:58:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-29 11:58:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 11:58:45.628: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8796  42c57bf8-faf2-42d5-8179-49f59d336c07 16722 0 2022-11-29 11:58:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-29 11:58:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 11/29/22 11:58:45.628
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/29/22 11:58:45.633
    STEP: deleting the configmap 11/29/22 11:58:45.634
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/29/22 11:58:45.636
    Nov 29 11:58:45.636: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8796  42c57bf8-faf2-42d5-8179-49f59d336c07 16723 0 2022-11-29 11:58:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-29 11:58:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 11:58:45.637: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8796  42c57bf8-faf2-42d5-8179-49f59d336c07 16724 0 2022-11-29 11:58:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-29 11:58:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 29 11:58:45.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8796" for this suite. 11/29/22 11:58:45.64
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:45.644
Nov 29 11:58:45.644: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename var-expansion 11/29/22 11:58:45.644
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:45.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:45.653
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 11/29/22 11:58:45.655
Nov 29 11:58:45.660: INFO: Waiting up to 5m0s for pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87" in namespace "var-expansion-2998" to be "Succeeded or Failed"
Nov 29 11:58:45.663: INFO: Pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.72846ms
Nov 29 11:58:47.667: INFO: Pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006290733s
Nov 29 11:58:49.667: INFO: Pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006678901s
STEP: Saw pod success 11/29/22 11:58:49.667
Nov 29 11:58:49.667: INFO: Pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87" satisfied condition "Succeeded or Failed"
Nov 29 11:58:49.669: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87 container dapi-container: <nil>
STEP: delete the pod 11/29/22 11:58:49.673
Nov 29 11:58:49.680: INFO: Waiting for pod var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87 to disappear
Nov 29 11:58:49.682: INFO: Pod var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 29 11:58:49.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2998" for this suite. 11/29/22 11:58:49.685
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":102,"skipped":1950,"failed":0}
------------------------------
• [4.046 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:45.644
    Nov 29 11:58:45.644: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename var-expansion 11/29/22 11:58:45.644
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:45.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:45.653
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 11/29/22 11:58:45.655
    Nov 29 11:58:45.660: INFO: Waiting up to 5m0s for pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87" in namespace "var-expansion-2998" to be "Succeeded or Failed"
    Nov 29 11:58:45.663: INFO: Pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.72846ms
    Nov 29 11:58:47.667: INFO: Pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006290733s
    Nov 29 11:58:49.667: INFO: Pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006678901s
    STEP: Saw pod success 11/29/22 11:58:49.667
    Nov 29 11:58:49.667: INFO: Pod "var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87" satisfied condition "Succeeded or Failed"
    Nov 29 11:58:49.669: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87 container dapi-container: <nil>
    STEP: delete the pod 11/29/22 11:58:49.673
    Nov 29 11:58:49.680: INFO: Waiting for pod var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87 to disappear
    Nov 29 11:58:49.682: INFO: Pod var-expansion-c53c81de-dd64-4481-b731-3ef26f97cd87 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 29 11:58:49.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2998" for this suite. 11/29/22 11:58:49.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:58:49.69
Nov 29 11:58:49.691: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename aggregator 11/29/22 11:58:49.691
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:49.7
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:49.703
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Nov 29 11:58:49.706: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 11/29/22 11:58:49.706
Nov 29 11:58:50.124: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov 29 11:58:52.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:58:54.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:58:56.159: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:58:58.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:00.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:02.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:04.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:06.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:08.159: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:10.161: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:12.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:14.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:16.161: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 11:59:18.284: INFO: Waited 121.901307ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 11/29/22 11:59:18.359
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/29/22 11:59:18.362
STEP: List APIServices 11/29/22 11:59:18.367
Nov 29 11:59:18.372: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Nov 29 11:59:18.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6716" for this suite. 11/29/22 11:59:18.88
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":103,"skipped":1955,"failed":0}
------------------------------
• [SLOW TEST] [29.193 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:58:49.69
    Nov 29 11:58:49.691: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename aggregator 11/29/22 11:58:49.691
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:58:49.7
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:58:49.703
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Nov 29 11:58:49.706: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 11/29/22 11:58:49.706
    Nov 29 11:58:50.124: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Nov 29 11:58:52.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:58:54.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:58:56.159: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:58:58.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:00.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:02.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:04.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:06.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:08.159: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:10.161: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:12.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:14.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:16.161: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 11, 58, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 11:59:18.284: INFO: Waited 121.901307ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 11/29/22 11:59:18.359
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/29/22 11:59:18.362
    STEP: List APIServices 11/29/22 11:59:18.367
    Nov 29 11:59:18.372: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Nov 29 11:59:18.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-6716" for this suite. 11/29/22 11:59:18.88
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:18.884
Nov 29 11:59:18.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubelet-test 11/29/22 11:59:18.886
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:18.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:18.898
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Nov 29 11:59:18.906: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1" in namespace "kubelet-test-5822" to be "running and ready"
Nov 29 11:59:18.912: INFO: Pod "busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.612323ms
Nov 29 11:59:18.912: INFO: The phase of Pod busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:59:20.915: INFO: Pod "busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009043078s
Nov 29 11:59:20.915: INFO: The phase of Pod busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1 is Running (Ready = true)
Nov 29 11:59:20.915: INFO: Pod "busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 29 11:59:20.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5822" for this suite. 11/29/22 11:59:20.924
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":104,"skipped":1974,"failed":0}
------------------------------
• [2.044 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:18.884
    Nov 29 11:59:18.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubelet-test 11/29/22 11:59:18.886
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:18.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:18.898
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Nov 29 11:59:18.906: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1" in namespace "kubelet-test-5822" to be "running and ready"
    Nov 29 11:59:18.912: INFO: Pod "busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.612323ms
    Nov 29 11:59:18.912: INFO: The phase of Pod busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:59:20.915: INFO: Pod "busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009043078s
    Nov 29 11:59:20.915: INFO: The phase of Pod busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1 is Running (Ready = true)
    Nov 29 11:59:20.915: INFO: Pod "busybox-readonly-fsed8ec23e-4bec-4ff8-be67-f3455e249da1" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 29 11:59:20.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5822" for this suite. 11/29/22 11:59:20.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:20.929
Nov 29 11:59:20.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 11:59:20.93
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:20.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:20.939
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 11:59:20.949
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 11:59:21.682
STEP: Deploying the webhook pod 11/29/22 11:59:21.686
STEP: Wait for the deployment to be ready 11/29/22 11:59:21.693
Nov 29 11:59:21.701: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 11:59:23.707
STEP: Verifying the service has paired with the endpoint 11/29/22 11:59:23.713
Nov 29 11:59:24.713: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Nov 29 11:59:24.716: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2224-crds.webhook.example.com via the AdmissionRegistration API 11/29/22 11:59:25.224
Nov 29 11:59:27.463: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook 11/29/22 11:59:27.575
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:59:28.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8299" for this suite. 11/29/22 11:59:28.314
STEP: Destroying namespace "webhook-8299-markers" for this suite. 11/29/22 11:59:28.317
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":105,"skipped":1984,"failed":0}
------------------------------
• [SLOW TEST] [7.420 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:20.929
    Nov 29 11:59:20.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 11:59:20.93
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:20.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:20.939
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 11:59:20.949
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 11:59:21.682
    STEP: Deploying the webhook pod 11/29/22 11:59:21.686
    STEP: Wait for the deployment to be ready 11/29/22 11:59:21.693
    Nov 29 11:59:21.701: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 11:59:23.707
    STEP: Verifying the service has paired with the endpoint 11/29/22 11:59:23.713
    Nov 29 11:59:24.713: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Nov 29 11:59:24.716: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2224-crds.webhook.example.com via the AdmissionRegistration API 11/29/22 11:59:25.224
    Nov 29 11:59:27.463: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource that should be mutated by the webhook 11/29/22 11:59:27.575
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:59:28.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8299" for this suite. 11/29/22 11:59:28.314
    STEP: Destroying namespace "webhook-8299-markers" for this suite. 11/29/22 11:59:28.317
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:28.35
Nov 29 11:59:28.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 11:59:28.351
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:28.365
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:28.368
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-67 11/29/22 11:59:28.37
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/29/22 11:59:28.383
STEP: creating service externalsvc in namespace services-67 11/29/22 11:59:28.383
STEP: creating replication controller externalsvc in namespace services-67 11/29/22 11:59:28.425
I1129 11:59:28.429092      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-67, replica count: 2
I1129 11:59:31.479953      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 11/29/22 11:59:31.482
Nov 29 11:59:31.498: INFO: Creating new exec pod
Nov 29 11:59:31.504: INFO: Waiting up to 5m0s for pod "execpodj8snm" in namespace "services-67" to be "running"
Nov 29 11:59:31.507: INFO: Pod "execpodj8snm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.631749ms
Nov 29 11:59:33.509: INFO: Pod "execpodj8snm": Phase="Running", Reason="", readiness=true. Elapsed: 2.005161001s
Nov 29 11:59:33.509: INFO: Pod "execpodj8snm" satisfied condition "running"
Nov 29 11:59:33.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-67 exec execpodj8snm -- /bin/sh -x -c nslookup clusterip-service.services-67.svc.cluster.local'
Nov 29 11:59:33.686: INFO: stderr: "+ nslookup clusterip-service.services-67.svc.cluster.local\n"
Nov 29 11:59:33.686: INFO: stdout: ";; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\nServer:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nclusterip-service.services-67.svc.cluster.local\tcanonical name = externalsvc.services-67.svc.cluster.local.\nName:\texternalsvc.services-67.svc.cluster.local\nAddress: 100.70.22.164\n;; Got recursion not available from 169.254.20.10, trying next server\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-67, will wait for the garbage collector to delete the pods 11/29/22 11:59:33.686
Nov 29 11:59:33.764: INFO: Deleting ReplicationController externalsvc took: 3.216665ms
Nov 29 11:59:33.865: INFO: Terminating ReplicationController externalsvc pods took: 100.781065ms
Nov 29 11:59:35.487: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 11:59:35.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-67" for this suite. 11/29/22 11:59:35.501
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":106,"skipped":1996,"failed":0}
------------------------------
• [SLOW TEST] [7.155 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:28.35
    Nov 29 11:59:28.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 11:59:28.351
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:28.365
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:28.368
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-67 11/29/22 11:59:28.37
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/29/22 11:59:28.383
    STEP: creating service externalsvc in namespace services-67 11/29/22 11:59:28.383
    STEP: creating replication controller externalsvc in namespace services-67 11/29/22 11:59:28.425
    I1129 11:59:28.429092      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-67, replica count: 2
    I1129 11:59:31.479953      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 11/29/22 11:59:31.482
    Nov 29 11:59:31.498: INFO: Creating new exec pod
    Nov 29 11:59:31.504: INFO: Waiting up to 5m0s for pod "execpodj8snm" in namespace "services-67" to be "running"
    Nov 29 11:59:31.507: INFO: Pod "execpodj8snm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.631749ms
    Nov 29 11:59:33.509: INFO: Pod "execpodj8snm": Phase="Running", Reason="", readiness=true. Elapsed: 2.005161001s
    Nov 29 11:59:33.509: INFO: Pod "execpodj8snm" satisfied condition "running"
    Nov 29 11:59:33.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-67 exec execpodj8snm -- /bin/sh -x -c nslookup clusterip-service.services-67.svc.cluster.local'
    Nov 29 11:59:33.686: INFO: stderr: "+ nslookup clusterip-service.services-67.svc.cluster.local\n"
    Nov 29 11:59:33.686: INFO: stdout: ";; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\nServer:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nclusterip-service.services-67.svc.cluster.local\tcanonical name = externalsvc.services-67.svc.cluster.local.\nName:\texternalsvc.services-67.svc.cluster.local\nAddress: 100.70.22.164\n;; Got recursion not available from 169.254.20.10, trying next server\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-67, will wait for the garbage collector to delete the pods 11/29/22 11:59:33.686
    Nov 29 11:59:33.764: INFO: Deleting ReplicationController externalsvc took: 3.216665ms
    Nov 29 11:59:33.865: INFO: Terminating ReplicationController externalsvc pods took: 100.781065ms
    Nov 29 11:59:35.487: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 11:59:35.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-67" for this suite. 11/29/22 11:59:35.501
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:35.506
Nov 29 11:59:35.506: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 11:59:35.507
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:35.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:35.519
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 11/29/22 11:59:35.521
Nov 29 11:59:35.526: INFO: Waiting up to 5m0s for pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774" in namespace "downward-api-1020" to be "Succeeded or Failed"
Nov 29 11:59:35.530: INFO: Pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774": Phase="Pending", Reason="", readiness=false. Elapsed: 3.863378ms
Nov 29 11:59:37.535: INFO: Pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774": Phase="Running", Reason="", readiness=false. Elapsed: 2.008925671s
Nov 29 11:59:39.533: INFO: Pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007469107s
STEP: Saw pod success 11/29/22 11:59:39.534
Nov 29 11:59:39.534: INFO: Pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774" satisfied condition "Succeeded or Failed"
Nov 29 11:59:39.537: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774 container dapi-container: <nil>
STEP: delete the pod 11/29/22 11:59:39.542
Nov 29 11:59:39.550: INFO: Waiting for pod downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774 to disappear
Nov 29 11:59:39.552: INFO: Pod downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 29 11:59:39.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1020" for this suite. 11/29/22 11:59:39.555
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":107,"skipped":2018,"failed":0}
------------------------------
• [4.053 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:35.506
    Nov 29 11:59:35.506: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 11:59:35.507
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:35.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:35.519
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 11/29/22 11:59:35.521
    Nov 29 11:59:35.526: INFO: Waiting up to 5m0s for pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774" in namespace "downward-api-1020" to be "Succeeded or Failed"
    Nov 29 11:59:35.530: INFO: Pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774": Phase="Pending", Reason="", readiness=false. Elapsed: 3.863378ms
    Nov 29 11:59:37.535: INFO: Pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774": Phase="Running", Reason="", readiness=false. Elapsed: 2.008925671s
    Nov 29 11:59:39.533: INFO: Pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007469107s
    STEP: Saw pod success 11/29/22 11:59:39.534
    Nov 29 11:59:39.534: INFO: Pod "downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774" satisfied condition "Succeeded or Failed"
    Nov 29 11:59:39.537: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774 container dapi-container: <nil>
    STEP: delete the pod 11/29/22 11:59:39.542
    Nov 29 11:59:39.550: INFO: Waiting for pod downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774 to disappear
    Nov 29 11:59:39.552: INFO: Pod downward-api-add1427d-ad35-46b5-a1ad-40ad82cee774 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 29 11:59:39.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1020" for this suite. 11/29/22 11:59:39.555
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:39.56
Nov 29 11:59:39.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 11:59:39.561
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:39.567
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:39.569
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 11/29/22 11:59:39.571
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/29/22 11:59:39.572
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/29/22 11:59:39.572
STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/29/22 11:59:39.572
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/29/22 11:59:39.573
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/29/22 11:59:39.573
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/29/22 11:59:39.573
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 11:59:39.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3601" for this suite. 11/29/22 11:59:39.576
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":108,"skipped":2023,"failed":0}
------------------------------
• [0.019 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:39.56
    Nov 29 11:59:39.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 11:59:39.561
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:39.567
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:39.569
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 11/29/22 11:59:39.571
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/29/22 11:59:39.572
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/29/22 11:59:39.572
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/29/22 11:59:39.572
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/29/22 11:59:39.573
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/29/22 11:59:39.573
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/29/22 11:59:39.573
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 11:59:39.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3601" for this suite. 11/29/22 11:59:39.576
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:39.58
Nov 29 11:59:39.581: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename disruption 11/29/22 11:59:39.581
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:39.591
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:39.595
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 11/29/22 11:59:39.601
STEP: Updating PodDisruptionBudget status 11/29/22 11:59:41.607
STEP: Waiting for all pods to be running 11/29/22 11:59:41.614
Nov 29 11:59:41.620: INFO: running pods: 0 < 1
STEP: locating a running pod 11/29/22 11:59:43.623
STEP: Waiting for the pdb to be processed 11/29/22 11:59:43.632
STEP: Patching PodDisruptionBudget status 11/29/22 11:59:43.636
STEP: Waiting for the pdb to be processed 11/29/22 11:59:43.641
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 29 11:59:43.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6068" for this suite. 11/29/22 11:59:43.645
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":109,"skipped":2056,"failed":0}
------------------------------
• [4.068 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:39.58
    Nov 29 11:59:39.581: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename disruption 11/29/22 11:59:39.581
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:39.591
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:39.595
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 11/29/22 11:59:39.601
    STEP: Updating PodDisruptionBudget status 11/29/22 11:59:41.607
    STEP: Waiting for all pods to be running 11/29/22 11:59:41.614
    Nov 29 11:59:41.620: INFO: running pods: 0 < 1
    STEP: locating a running pod 11/29/22 11:59:43.623
    STEP: Waiting for the pdb to be processed 11/29/22 11:59:43.632
    STEP: Patching PodDisruptionBudget status 11/29/22 11:59:43.636
    STEP: Waiting for the pdb to be processed 11/29/22 11:59:43.641
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 29 11:59:43.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6068" for this suite. 11/29/22 11:59:43.645
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:43.649
Nov 29 11:59:43.649: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:59:43.649
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:43.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:43.659
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Nov 29 11:59:43.663: INFO: Got root ca configmap in namespace "svcaccounts-8232"
Nov 29 11:59:43.666: INFO: Deleted root ca configmap in namespace "svcaccounts-8232"
STEP: waiting for a new root ca configmap created 11/29/22 11:59:44.167
Nov 29 11:59:44.169: INFO: Recreated root ca configmap in namespace "svcaccounts-8232"
Nov 29 11:59:44.172: INFO: Updated root ca configmap in namespace "svcaccounts-8232"
STEP: waiting for the root ca configmap reconciled 11/29/22 11:59:44.673
Nov 29 11:59:44.752: INFO: Reconciled root ca configmap in namespace "svcaccounts-8232"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 29 11:59:44.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8232" for this suite. 11/29/22 11:59:44.757
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":110,"skipped":2059,"failed":0}
------------------------------
• [1.112 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:43.649
    Nov 29 11:59:43.649: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename svcaccounts 11/29/22 11:59:43.649
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:43.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:43.659
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Nov 29 11:59:43.663: INFO: Got root ca configmap in namespace "svcaccounts-8232"
    Nov 29 11:59:43.666: INFO: Deleted root ca configmap in namespace "svcaccounts-8232"
    STEP: waiting for a new root ca configmap created 11/29/22 11:59:44.167
    Nov 29 11:59:44.169: INFO: Recreated root ca configmap in namespace "svcaccounts-8232"
    Nov 29 11:59:44.172: INFO: Updated root ca configmap in namespace "svcaccounts-8232"
    STEP: waiting for the root ca configmap reconciled 11/29/22 11:59:44.673
    Nov 29 11:59:44.752: INFO: Reconciled root ca configmap in namespace "svcaccounts-8232"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 29 11:59:44.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8232" for this suite. 11/29/22 11:59:44.757
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:44.762
Nov 29 11:59:44.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replication-controller 11/29/22 11:59:44.762
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:44.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:44.773
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 11/29/22 11:59:44.788
STEP: waiting for RC to be added 11/29/22 11:59:44.791
STEP: waiting for available Replicas 11/29/22 11:59:44.791
STEP: patching ReplicationController 11/29/22 11:59:46.424
STEP: waiting for RC to be modified 11/29/22 11:59:46.435
STEP: patching ReplicationController status 11/29/22 11:59:46.435
STEP: waiting for RC to be modified 11/29/22 11:59:46.439
STEP: waiting for available Replicas 11/29/22 11:59:46.439
STEP: fetching ReplicationController status 11/29/22 11:59:46.443
STEP: patching ReplicationController scale 11/29/22 11:59:46.452
STEP: waiting for RC to be modified 11/29/22 11:59:46.457
STEP: waiting for ReplicationController's scale to be the max amount 11/29/22 11:59:46.457
STEP: fetching ReplicationController; ensuring that it's patched 11/29/22 11:59:47.579
STEP: updating ReplicationController status 11/29/22 11:59:47.581
STEP: waiting for RC to be modified 11/29/22 11:59:47.588
STEP: listing all ReplicationControllers 11/29/22 11:59:47.588
STEP: checking that ReplicationController has expected values 11/29/22 11:59:47.593
STEP: deleting ReplicationControllers by collection 11/29/22 11:59:47.593
STEP: waiting for ReplicationController to have a DELETED watchEvent 11/29/22 11:59:47.597
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 29 11:59:47.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2814" for this suite. 11/29/22 11:59:47.635
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":111,"skipped":2080,"failed":0}
------------------------------
• [2.877 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:44.762
    Nov 29 11:59:44.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replication-controller 11/29/22 11:59:44.762
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:44.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:44.773
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 11/29/22 11:59:44.788
    STEP: waiting for RC to be added 11/29/22 11:59:44.791
    STEP: waiting for available Replicas 11/29/22 11:59:44.791
    STEP: patching ReplicationController 11/29/22 11:59:46.424
    STEP: waiting for RC to be modified 11/29/22 11:59:46.435
    STEP: patching ReplicationController status 11/29/22 11:59:46.435
    STEP: waiting for RC to be modified 11/29/22 11:59:46.439
    STEP: waiting for available Replicas 11/29/22 11:59:46.439
    STEP: fetching ReplicationController status 11/29/22 11:59:46.443
    STEP: patching ReplicationController scale 11/29/22 11:59:46.452
    STEP: waiting for RC to be modified 11/29/22 11:59:46.457
    STEP: waiting for ReplicationController's scale to be the max amount 11/29/22 11:59:46.457
    STEP: fetching ReplicationController; ensuring that it's patched 11/29/22 11:59:47.579
    STEP: updating ReplicationController status 11/29/22 11:59:47.581
    STEP: waiting for RC to be modified 11/29/22 11:59:47.588
    STEP: listing all ReplicationControllers 11/29/22 11:59:47.588
    STEP: checking that ReplicationController has expected values 11/29/22 11:59:47.593
    STEP: deleting ReplicationControllers by collection 11/29/22 11:59:47.593
    STEP: waiting for ReplicationController to have a DELETED watchEvent 11/29/22 11:59:47.597
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 29 11:59:47.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2814" for this suite. 11/29/22 11:59:47.635
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:47.638
Nov 29 11:59:47.639: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename proxy 11/29/22 11:59:47.639
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:47.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:47.65
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Nov 29 11:59:47.652: INFO: Creating pod...
Nov 29 11:59:47.656: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7008" to be "running"
Nov 29 11:59:47.659: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 3.16814ms
Nov 29 11:59:49.663: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.006751951s
Nov 29 11:59:49.663: INFO: Pod "agnhost" satisfied condition "running"
Nov 29 11:59:49.663: INFO: Creating service...
Nov 29 11:59:49.670: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/DELETE
Nov 29 11:59:49.676: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 29 11:59:49.676: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/GET
Nov 29 11:59:49.678: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov 29 11:59:49.678: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/HEAD
Nov 29 11:59:49.680: INFO: http.Client request:HEAD | StatusCode:200
Nov 29 11:59:49.680: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/OPTIONS
Nov 29 11:59:49.682: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 29 11:59:49.682: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/PATCH
Nov 29 11:59:49.684: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 29 11:59:49.684: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/POST
Nov 29 11:59:49.687: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 29 11:59:49.687: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/PUT
Nov 29 11:59:49.689: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 29 11:59:49.689: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/DELETE
Nov 29 11:59:49.691: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 29 11:59:49.691: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/GET
Nov 29 11:59:49.693: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov 29 11:59:49.693: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/HEAD
Nov 29 11:59:49.695: INFO: http.Client request:HEAD | StatusCode:200
Nov 29 11:59:49.695: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/OPTIONS
Nov 29 11:59:49.697: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 29 11:59:49.697: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/PATCH
Nov 29 11:59:49.698: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 29 11:59:49.698: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/POST
Nov 29 11:59:49.701: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 29 11:59:49.701: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/PUT
Nov 29 11:59:49.703: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 29 11:59:49.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7008" for this suite. 11/29/22 11:59:49.706
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":112,"skipped":2083,"failed":0}
------------------------------
• [2.070 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:47.638
    Nov 29 11:59:47.639: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename proxy 11/29/22 11:59:47.639
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:47.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:47.65
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Nov 29 11:59:47.652: INFO: Creating pod...
    Nov 29 11:59:47.656: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7008" to be "running"
    Nov 29 11:59:47.659: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 3.16814ms
    Nov 29 11:59:49.663: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.006751951s
    Nov 29 11:59:49.663: INFO: Pod "agnhost" satisfied condition "running"
    Nov 29 11:59:49.663: INFO: Creating service...
    Nov 29 11:59:49.670: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/DELETE
    Nov 29 11:59:49.676: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 29 11:59:49.676: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/GET
    Nov 29 11:59:49.678: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov 29 11:59:49.678: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/HEAD
    Nov 29 11:59:49.680: INFO: http.Client request:HEAD | StatusCode:200
    Nov 29 11:59:49.680: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/OPTIONS
    Nov 29 11:59:49.682: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 29 11:59:49.682: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/PATCH
    Nov 29 11:59:49.684: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 29 11:59:49.684: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/POST
    Nov 29 11:59:49.687: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 29 11:59:49.687: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/pods/agnhost/proxy/some/path/with/PUT
    Nov 29 11:59:49.689: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 29 11:59:49.689: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/DELETE
    Nov 29 11:59:49.691: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 29 11:59:49.691: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/GET
    Nov 29 11:59:49.693: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov 29 11:59:49.693: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/HEAD
    Nov 29 11:59:49.695: INFO: http.Client request:HEAD | StatusCode:200
    Nov 29 11:59:49.695: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/OPTIONS
    Nov 29 11:59:49.697: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 29 11:59:49.697: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/PATCH
    Nov 29 11:59:49.698: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 29 11:59:49.698: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/POST
    Nov 29 11:59:49.701: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 29 11:59:49.701: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-7008/services/test-service/proxy/some/path/with/PUT
    Nov 29 11:59:49.703: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 29 11:59:49.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-7008" for this suite. 11/29/22 11:59:49.706
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:49.709
Nov 29 11:59:49.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 11:59:49.71
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:49.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:49.72
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/29/22 11:59:49.722
Nov 29 11:59:49.728: INFO: Waiting up to 5m0s for pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1" in namespace "emptydir-9550" to be "Succeeded or Failed"
Nov 29 11:59:49.731: INFO: Pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.725424ms
Nov 29 11:59:51.734: INFO: Pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006114563s
Nov 29 11:59:53.734: INFO: Pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005988895s
STEP: Saw pod success 11/29/22 11:59:53.734
Nov 29 11:59:53.734: INFO: Pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1" satisfied condition "Succeeded or Failed"
Nov 29 11:59:53.738: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1 container test-container: <nil>
STEP: delete the pod 11/29/22 11:59:53.751
Nov 29 11:59:53.756: INFO: Waiting for pod pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1 to disappear
Nov 29 11:59:53.758: INFO: Pod pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 11:59:53.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9550" for this suite. 11/29/22 11:59:53.761
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":113,"skipped":2090,"failed":0}
------------------------------
• [4.058 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:49.709
    Nov 29 11:59:49.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 11:59:49.71
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:49.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:49.72
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/29/22 11:59:49.722
    Nov 29 11:59:49.728: INFO: Waiting up to 5m0s for pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1" in namespace "emptydir-9550" to be "Succeeded or Failed"
    Nov 29 11:59:49.731: INFO: Pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.725424ms
    Nov 29 11:59:51.734: INFO: Pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006114563s
    Nov 29 11:59:53.734: INFO: Pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005988895s
    STEP: Saw pod success 11/29/22 11:59:53.734
    Nov 29 11:59:53.734: INFO: Pod "pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1" satisfied condition "Succeeded or Failed"
    Nov 29 11:59:53.738: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1 container test-container: <nil>
    STEP: delete the pod 11/29/22 11:59:53.751
    Nov 29 11:59:53.756: INFO: Waiting for pod pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1 to disappear
    Nov 29 11:59:53.758: INFO: Pod pod-d3f9a89e-4a55-4df9-8e15-94366a5ec1b1 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 11:59:53.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9550" for this suite. 11/29/22 11:59:53.761
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:53.768
Nov 29 11:59:53.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename cronjob 11/29/22 11:59:53.769
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:53.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:53.793
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 11/29/22 11:59:53.795
STEP: creating 11/29/22 11:59:53.795
STEP: getting 11/29/22 11:59:53.797
STEP: listing 11/29/22 11:59:53.801
STEP: watching 11/29/22 11:59:53.803
Nov 29 11:59:53.803: INFO: starting watch
STEP: cluster-wide listing 11/29/22 11:59:53.804
STEP: cluster-wide watching 11/29/22 11:59:53.806
Nov 29 11:59:53.806: INFO: starting watch
STEP: patching 11/29/22 11:59:53.807
STEP: updating 11/29/22 11:59:53.811
Nov 29 11:59:53.815: INFO: waiting for watch events with expected annotations
Nov 29 11:59:53.815: INFO: saw patched and updated annotations
STEP: patching /status 11/29/22 11:59:53.816
STEP: updating /status 11/29/22 11:59:53.819
STEP: get /status 11/29/22 11:59:53.824
STEP: deleting 11/29/22 11:59:53.826
STEP: deleting a collection 11/29/22 11:59:53.832
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 29 11:59:53.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7076" for this suite. 11/29/22 11:59:53.842
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":114,"skipped":2090,"failed":0}
------------------------------
• [0.078 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:53.768
    Nov 29 11:59:53.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename cronjob 11/29/22 11:59:53.769
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:53.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:53.793
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 11/29/22 11:59:53.795
    STEP: creating 11/29/22 11:59:53.795
    STEP: getting 11/29/22 11:59:53.797
    STEP: listing 11/29/22 11:59:53.801
    STEP: watching 11/29/22 11:59:53.803
    Nov 29 11:59:53.803: INFO: starting watch
    STEP: cluster-wide listing 11/29/22 11:59:53.804
    STEP: cluster-wide watching 11/29/22 11:59:53.806
    Nov 29 11:59:53.806: INFO: starting watch
    STEP: patching 11/29/22 11:59:53.807
    STEP: updating 11/29/22 11:59:53.811
    Nov 29 11:59:53.815: INFO: waiting for watch events with expected annotations
    Nov 29 11:59:53.815: INFO: saw patched and updated annotations
    STEP: patching /status 11/29/22 11:59:53.816
    STEP: updating /status 11/29/22 11:59:53.819
    STEP: get /status 11/29/22 11:59:53.824
    STEP: deleting 11/29/22 11:59:53.826
    STEP: deleting a collection 11/29/22 11:59:53.832
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 29 11:59:53.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7076" for this suite. 11/29/22 11:59:53.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:53.85
Nov 29 11:59:53.850: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 11:59:53.851
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:53.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:53.861
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 11/29/22 11:59:53.864
Nov 29 11:59:53.875: INFO: Waiting up to 5m0s for pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef" in namespace "downward-api-5759" to be "running and ready"
Nov 29 11:59:53.877: INFO: Pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076088ms
Nov 29 11:59:53.877: INFO: The phase of Pod labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef is Pending, waiting for it to be Running (with Ready = true)
Nov 29 11:59:55.880: INFO: Pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef": Phase="Running", Reason="", readiness=true. Elapsed: 2.004964576s
Nov 29 11:59:55.880: INFO: The phase of Pod labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef is Running (Ready = true)
Nov 29 11:59:55.880: INFO: Pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef" satisfied condition "running and ready"
Nov 29 11:59:56.395: INFO: Successfully updated pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 11:59:58.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5759" for this suite. 11/29/22 11:59:58.412
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":115,"skipped":2201,"failed":0}
------------------------------
• [4.565 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:53.85
    Nov 29 11:59:53.850: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 11:59:53.851
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:53.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:53.861
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 11/29/22 11:59:53.864
    Nov 29 11:59:53.875: INFO: Waiting up to 5m0s for pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef" in namespace "downward-api-5759" to be "running and ready"
    Nov 29 11:59:53.877: INFO: Pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076088ms
    Nov 29 11:59:53.877: INFO: The phase of Pod labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 11:59:55.880: INFO: Pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef": Phase="Running", Reason="", readiness=true. Elapsed: 2.004964576s
    Nov 29 11:59:55.880: INFO: The phase of Pod labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef is Running (Ready = true)
    Nov 29 11:59:55.880: INFO: Pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef" satisfied condition "running and ready"
    Nov 29 11:59:56.395: INFO: Successfully updated pod "labelsupdatee0de28c2-853e-42b5-8d93-6d80d5a57bef"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 11:59:58.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5759" for this suite. 11/29/22 11:59:58.412
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 11:59:58.417
Nov 29 11:59:58.417: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 11:59:58.418
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:58.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:58.429
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-3479 11/29/22 11:59:58.431
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[] 11/29/22 11:59:58.439
Nov 29 11:59:58.445: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-3479 11/29/22 11:59:58.445
Nov 29 11:59:58.449: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3479" to be "running and ready"
Nov 29 11:59:58.455: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.520411ms
Nov 29 11:59:58.455: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:00:00.457: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008181438s
Nov 29 12:00:00.457: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 29 12:00:00.457: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[pod1:[80]] 11/29/22 12:00:00.459
Nov 29 12:00:00.465: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 11/29/22 12:00:00.465
Nov 29 12:00:00.466: INFO: Creating new exec pod
Nov 29 12:00:00.468: INFO: Waiting up to 5m0s for pod "execpodsbm4l" in namespace "services-3479" to be "running"
Nov 29 12:00:00.471: INFO: Pod "execpodsbm4l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.874742ms
Nov 29 12:00:02.475: INFO: Pod "execpodsbm4l": Phase="Running", Reason="", readiness=true. Elapsed: 2.006594241s
Nov 29 12:00:02.475: INFO: Pod "execpodsbm4l" satisfied condition "running"
Nov 29 12:00:03.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 29 12:00:05.608: INFO: rc: 1
Nov 29 12:00:05.608: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 endpoint-test2 80
nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:00:06.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 29 12:00:06.739: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 29 12:00:06.739: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:00:06.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.255.220 80'
Nov 29 12:00:06.860: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.255.220 80\nConnection to 100.65.255.220 80 port [tcp/http] succeeded!\n"
Nov 29 12:00:06.860: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-3479 11/29/22 12:00:06.861
Nov 29 12:00:06.864: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3479" to be "running and ready"
Nov 29 12:00:06.868: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.35161ms
Nov 29 12:00:06.868: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:00:08.871: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.006742929s
Nov 29 12:00:08.871: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 29 12:00:08.871: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[pod1:[80] pod2:[80]] 11/29/22 12:00:08.873
Nov 29 12:00:08.879: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 11/29/22 12:00:08.879
Nov 29 12:00:09.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 29 12:00:10.007: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 29 12:00:10.007: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:00:10.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.255.220 80'
Nov 29 12:00:10.130: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.255.220 80\nConnection to 100.65.255.220 80 port [tcp/http] succeeded!\n"
Nov 29 12:00:10.130: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-3479 11/29/22 12:00:10.13
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[pod2:[80]] 11/29/22 12:00:10.14
Nov 29 12:00:10.147: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 11/29/22 12:00:10.148
Nov 29 12:00:11.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 29 12:00:13.268: INFO: rc: 1
Nov 29 12:00:13.268: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
Command stdout:

stderr:
+ + nc -v -t -w 2 endpoint-test2 80echo
 hostName
nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:00:14.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 29 12:00:15.416: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 29 12:00:15.416: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:00:15.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.255.220 80'
Nov 29 12:00:15.560: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.255.220 80\nConnection to 100.65.255.220 80 port [tcp/http] succeeded!\n"
Nov 29 12:00:15.560: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-3479 11/29/22 12:00:15.56
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[] 11/29/22 12:00:15.574
Nov 29 12:00:15.581: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:00:15.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3479" for this suite. 11/29/22 12:00:15.6
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":116,"skipped":2215,"failed":0}
------------------------------
• [SLOW TEST] [17.188 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 11:59:58.417
    Nov 29 11:59:58.417: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 11:59:58.418
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 11:59:58.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 11:59:58.429
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-3479 11/29/22 11:59:58.431
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[] 11/29/22 11:59:58.439
    Nov 29 11:59:58.445: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-3479 11/29/22 11:59:58.445
    Nov 29 11:59:58.449: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3479" to be "running and ready"
    Nov 29 11:59:58.455: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.520411ms
    Nov 29 11:59:58.455: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:00:00.457: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008181438s
    Nov 29 12:00:00.457: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 29 12:00:00.457: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[pod1:[80]] 11/29/22 12:00:00.459
    Nov 29 12:00:00.465: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 11/29/22 12:00:00.465
    Nov 29 12:00:00.466: INFO: Creating new exec pod
    Nov 29 12:00:00.468: INFO: Waiting up to 5m0s for pod "execpodsbm4l" in namespace "services-3479" to be "running"
    Nov 29 12:00:00.471: INFO: Pod "execpodsbm4l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.874742ms
    Nov 29 12:00:02.475: INFO: Pod "execpodsbm4l": Phase="Running", Reason="", readiness=true. Elapsed: 2.006594241s
    Nov 29 12:00:02.475: INFO: Pod "execpodsbm4l" satisfied condition "running"
    Nov 29 12:00:03.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 29 12:00:05.608: INFO: rc: 1
    Nov 29 12:00:05.608: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 endpoint-test2 80
    nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:00:06.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 29 12:00:06.739: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 29 12:00:06.739: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:00:06.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.255.220 80'
    Nov 29 12:00:06.860: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.255.220 80\nConnection to 100.65.255.220 80 port [tcp/http] succeeded!\n"
    Nov 29 12:00:06.860: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-3479 11/29/22 12:00:06.861
    Nov 29 12:00:06.864: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3479" to be "running and ready"
    Nov 29 12:00:06.868: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.35161ms
    Nov 29 12:00:06.868: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:00:08.871: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.006742929s
    Nov 29 12:00:08.871: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 29 12:00:08.871: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[pod1:[80] pod2:[80]] 11/29/22 12:00:08.873
    Nov 29 12:00:08.879: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 11/29/22 12:00:08.879
    Nov 29 12:00:09.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 29 12:00:10.007: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 29 12:00:10.007: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:00:10.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.255.220 80'
    Nov 29 12:00:10.130: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.255.220 80\nConnection to 100.65.255.220 80 port [tcp/http] succeeded!\n"
    Nov 29 12:00:10.130: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-3479 11/29/22 12:00:10.13
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[pod2:[80]] 11/29/22 12:00:10.14
    Nov 29 12:00:10.147: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 11/29/22 12:00:10.148
    Nov 29 12:00:11.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 29 12:00:13.268: INFO: rc: 1
    Nov 29 12:00:13.268: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
    Command stdout:

    stderr:
    + + nc -v -t -w 2 endpoint-test2 80echo
     hostName
    nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:00:14.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 29 12:00:15.416: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 29 12:00:15.416: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:00:15.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-3479 exec execpodsbm4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.255.220 80'
    Nov 29 12:00:15.560: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.255.220 80\nConnection to 100.65.255.220 80 port [tcp/http] succeeded!\n"
    Nov 29 12:00:15.560: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-3479 11/29/22 12:00:15.56
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3479 to expose endpoints map[] 11/29/22 12:00:15.574
    Nov 29 12:00:15.581: INFO: successfully validated that service endpoint-test2 in namespace services-3479 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:00:15.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3479" for this suite. 11/29/22 12:00:15.6
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:00:15.606
Nov 29 12:00:15.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename daemonsets 11/29/22 12:00:15.607
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:15.62
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:15.623
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Nov 29 12:00:15.646: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 11/29/22 12:00:15.649
Nov 29 12:00:15.658: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:15.658: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 11/29/22 12:00:15.658
Nov 29 12:00:15.679: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:15.679: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
Nov 29 12:00:16.682: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:16.682: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
Nov 29 12:00:17.683: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 29 12:00:17.683: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 11/29/22 12:00:17.685
Nov 29 12:00:17.716: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 29 12:00:17.716: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Nov 29 12:00:18.720: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:18.720: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/29/22 12:00:18.72
Nov 29 12:00:18.728: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:18.728: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
Nov 29 12:00:19.732: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:19.732: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
Nov 29 12:00:20.731: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:20.731: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
Nov 29 12:00:21.731: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:21.731: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
Nov 29 12:00:22.731: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 29 12:00:22.731: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:00:22.734
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6014, will wait for the garbage collector to delete the pods 11/29/22 12:00:22.734
Nov 29 12:00:22.789: INFO: Deleting DaemonSet.extensions daemon-set took: 2.749283ms
Nov 29 12:00:22.890: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.917003ms
Nov 29 12:00:25.493: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:00:25.493: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 29 12:00:25.496: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17642"},"items":null}

Nov 29 12:00:25.498: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17642"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:00:25.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6014" for this suite. 11/29/22 12:00:25.521
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":117,"skipped":2238,"failed":0}
------------------------------
• [SLOW TEST] [9.918 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:00:15.606
    Nov 29 12:00:15.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename daemonsets 11/29/22 12:00:15.607
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:15.62
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:15.623
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Nov 29 12:00:15.646: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 11/29/22 12:00:15.649
    Nov 29 12:00:15.658: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:15.658: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 11/29/22 12:00:15.658
    Nov 29 12:00:15.679: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:15.679: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
    Nov 29 12:00:16.682: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:16.682: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
    Nov 29 12:00:17.683: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 29 12:00:17.683: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 11/29/22 12:00:17.685
    Nov 29 12:00:17.716: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 29 12:00:17.716: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Nov 29 12:00:18.720: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:18.720: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/29/22 12:00:18.72
    Nov 29 12:00:18.728: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:18.728: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
    Nov 29 12:00:19.732: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:19.732: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
    Nov 29 12:00:20.731: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:20.731: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
    Nov 29 12:00:21.731: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:21.731: INFO: Node dvi-7336-1669718118-vsp1-group1-2 is running 0 daemon pod, expected 1
    Nov 29 12:00:22.731: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 29 12:00:22.731: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:00:22.734
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6014, will wait for the garbage collector to delete the pods 11/29/22 12:00:22.734
    Nov 29 12:00:22.789: INFO: Deleting DaemonSet.extensions daemon-set took: 2.749283ms
    Nov 29 12:00:22.890: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.917003ms
    Nov 29 12:00:25.493: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:00:25.493: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 29 12:00:25.496: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17642"},"items":null}

    Nov 29 12:00:25.498: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17642"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:00:25.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6014" for this suite. 11/29/22 12:00:25.521
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:00:25.525
Nov 29 12:00:25.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 12:00:25.526
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:25.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:25.538
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 11/29/22 12:00:25.543
STEP: submitting the pod to kubernetes 11/29/22 12:00:25.543
STEP: verifying QOS class is set on the pod 11/29/22 12:00:25.552
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Nov 29 12:00:25.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9156" for this suite. 11/29/22 12:00:25.56
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":118,"skipped":2252,"failed":0}
------------------------------
• [0.039 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:00:25.525
    Nov 29 12:00:25.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 12:00:25.526
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:25.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:25.538
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 11/29/22 12:00:25.543
    STEP: submitting the pod to kubernetes 11/29/22 12:00:25.543
    STEP: verifying QOS class is set on the pod 11/29/22 12:00:25.552
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Nov 29 12:00:25.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9156" for this suite. 11/29/22 12:00:25.56
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:00:25.567
Nov 29 12:00:25.567: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:00:25.568
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:25.576
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:25.579
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:00:25.581
Nov 29 12:00:25.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994" in namespace "downward-api-806" to be "Succeeded or Failed"
Nov 29 12:00:25.589: INFO: Pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994": Phase="Pending", Reason="", readiness=false. Elapsed: 3.608092ms
Nov 29 12:00:27.593: INFO: Pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007610491s
Nov 29 12:00:29.593: INFO: Pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006760734s
STEP: Saw pod success 11/29/22 12:00:29.593
Nov 29 12:00:29.593: INFO: Pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994" satisfied condition "Succeeded or Failed"
Nov 29 12:00:29.595: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994 container client-container: <nil>
STEP: delete the pod 11/29/22 12:00:29.599
Nov 29 12:00:29.606: INFO: Waiting for pod downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994 to disappear
Nov 29 12:00:29.609: INFO: Pod downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:00:29.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-806" for this suite. 11/29/22 12:00:29.617
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":119,"skipped":2261,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:00:25.567
    Nov 29 12:00:25.567: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:00:25.568
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:25.576
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:25.579
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:00:25.581
    Nov 29 12:00:25.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994" in namespace "downward-api-806" to be "Succeeded or Failed"
    Nov 29 12:00:25.589: INFO: Pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994": Phase="Pending", Reason="", readiness=false. Elapsed: 3.608092ms
    Nov 29 12:00:27.593: INFO: Pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007610491s
    Nov 29 12:00:29.593: INFO: Pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006760734s
    STEP: Saw pod success 11/29/22 12:00:29.593
    Nov 29 12:00:29.593: INFO: Pod "downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994" satisfied condition "Succeeded or Failed"
    Nov 29 12:00:29.595: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:00:29.599
    Nov 29 12:00:29.606: INFO: Waiting for pod downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994 to disappear
    Nov 29 12:00:29.609: INFO: Pod downwardapi-volume-2fce53ce-4091-4690-b4b9-9b3999255994 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:00:29.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-806" for this suite. 11/29/22 12:00:29.617
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:00:29.627
Nov 29 12:00:29.627: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename security-context-test 11/29/22 12:00:29.628
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:29.642
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:29.646
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Nov 29 12:00:29.740: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07" in namespace "security-context-test-9521" to be "Succeeded or Failed"
Nov 29 12:00:29.750: INFO: Pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07": Phase="Pending", Reason="", readiness=false. Elapsed: 9.049201ms
Nov 29 12:00:31.753: INFO: Pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012202668s
Nov 29 12:00:33.752: INFO: Pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011868755s
Nov 29 12:00:33.752: INFO: Pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 29 12:00:33.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9521" for this suite. 11/29/22 12:00:33.756
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":120,"skipped":2272,"failed":0}
------------------------------
• [4.132 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:00:29.627
    Nov 29 12:00:29.627: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename security-context-test 11/29/22 12:00:29.628
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:29.642
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:29.646
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Nov 29 12:00:29.740: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07" in namespace "security-context-test-9521" to be "Succeeded or Failed"
    Nov 29 12:00:29.750: INFO: Pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07": Phase="Pending", Reason="", readiness=false. Elapsed: 9.049201ms
    Nov 29 12:00:31.753: INFO: Pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012202668s
    Nov 29 12:00:33.752: INFO: Pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011868755s
    Nov 29 12:00:33.752: INFO: Pod "busybox-readonly-false-26f836cf-ac75-48be-9af8-dac638e07e07" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 29 12:00:33.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9521" for this suite. 11/29/22 12:00:33.756
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:00:33.759
Nov 29 12:00:33.760: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename security-context 11/29/22 12:00:33.76
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:33.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:33.772
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/29/22 12:00:33.774
Nov 29 12:00:33.779: INFO: Waiting up to 5m0s for pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6" in namespace "security-context-3268" to be "Succeeded or Failed"
Nov 29 12:00:33.783: INFO: Pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.536447ms
Nov 29 12:00:35.787: INFO: Pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007517323s
Nov 29 12:00:37.786: INFO: Pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007304929s
STEP: Saw pod success 11/29/22 12:00:37.786
Nov 29 12:00:37.786: INFO: Pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6" satisfied condition "Succeeded or Failed"
Nov 29 12:00:37.788: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6 container test-container: <nil>
STEP: delete the pod 11/29/22 12:00:37.792
Nov 29 12:00:37.798: INFO: Waiting for pod security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6 to disappear
Nov 29 12:00:37.801: INFO: Pod security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 29 12:00:37.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3268" for this suite. 11/29/22 12:00:37.804
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":121,"skipped":2277,"failed":0}
------------------------------
• [4.048 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:00:33.759
    Nov 29 12:00:33.760: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename security-context 11/29/22 12:00:33.76
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:33.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:33.772
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/29/22 12:00:33.774
    Nov 29 12:00:33.779: INFO: Waiting up to 5m0s for pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6" in namespace "security-context-3268" to be "Succeeded or Failed"
    Nov 29 12:00:33.783: INFO: Pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.536447ms
    Nov 29 12:00:35.787: INFO: Pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007517323s
    Nov 29 12:00:37.786: INFO: Pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007304929s
    STEP: Saw pod success 11/29/22 12:00:37.786
    Nov 29 12:00:37.786: INFO: Pod "security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6" satisfied condition "Succeeded or Failed"
    Nov 29 12:00:37.788: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6 container test-container: <nil>
    STEP: delete the pod 11/29/22 12:00:37.792
    Nov 29 12:00:37.798: INFO: Waiting for pod security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6 to disappear
    Nov 29 12:00:37.801: INFO: Pod security-context-ad273d3e-62c2-4695-826e-3d02d5fc02f6 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 29 12:00:37.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-3268" for this suite. 11/29/22 12:00:37.804
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:00:37.809
Nov 29 12:00:37.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:00:37.809
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:37.817
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:37.819
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-df38a834-c63c-49a5-8ab5-6d7363672ed5 11/29/22 12:00:37.821
STEP: Creating a pod to test consume secrets 11/29/22 12:00:37.824
Nov 29 12:00:37.828: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6" in namespace "projected-794" to be "Succeeded or Failed"
Nov 29 12:00:37.839: INFO: Pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.368356ms
Nov 29 12:00:39.842: INFO: Pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014032056s
Nov 29 12:00:41.843: INFO: Pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015021865s
STEP: Saw pod success 11/29/22 12:00:41.843
Nov 29 12:00:41.843: INFO: Pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6" satisfied condition "Succeeded or Failed"
Nov 29 12:00:41.845: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6 container secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:00:41.849
Nov 29 12:00:41.854: INFO: Waiting for pod pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6 to disappear
Nov 29 12:00:41.856: INFO: Pod pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 29 12:00:41.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-794" for this suite. 11/29/22 12:00:41.859
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":122,"skipped":2293,"failed":0}
------------------------------
• [4.054 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:00:37.809
    Nov 29 12:00:37.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:00:37.809
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:37.817
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:37.819
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-df38a834-c63c-49a5-8ab5-6d7363672ed5 11/29/22 12:00:37.821
    STEP: Creating a pod to test consume secrets 11/29/22 12:00:37.824
    Nov 29 12:00:37.828: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6" in namespace "projected-794" to be "Succeeded or Failed"
    Nov 29 12:00:37.839: INFO: Pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.368356ms
    Nov 29 12:00:39.842: INFO: Pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014032056s
    Nov 29 12:00:41.843: INFO: Pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015021865s
    STEP: Saw pod success 11/29/22 12:00:41.843
    Nov 29 12:00:41.843: INFO: Pod "pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6" satisfied condition "Succeeded or Failed"
    Nov 29 12:00:41.845: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6 container secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:00:41.849
    Nov 29 12:00:41.854: INFO: Waiting for pod pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6 to disappear
    Nov 29 12:00:41.856: INFO: Pod pod-projected-secrets-b6847d0c-ff22-4170-8d07-1ce6c8bf32c6 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 29 12:00:41.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-794" for this suite. 11/29/22 12:00:41.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:00:41.864
Nov 29 12:00:41.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename containers 11/29/22 12:00:41.865
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:41.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:41.877
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Nov 29 12:00:41.883: INFO: Waiting up to 5m0s for pod "client-containers-aa77c8a6-f0b0-485b-bc43-d25cfe3ac26e" in namespace "containers-9945" to be "running"
Nov 29 12:00:41.886: INFO: Pod "client-containers-aa77c8a6-f0b0-485b-bc43-d25cfe3ac26e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.372469ms
Nov 29 12:00:43.889: INFO: Pod "client-containers-aa77c8a6-f0b0-485b-bc43-d25cfe3ac26e": Phase="Running", Reason="", readiness=true. Elapsed: 2.006245288s
Nov 29 12:00:43.889: INFO: Pod "client-containers-aa77c8a6-f0b0-485b-bc43-d25cfe3ac26e" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 29 12:00:43.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9945" for this suite. 11/29/22 12:00:43.897
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":123,"skipped":2325,"failed":0}
------------------------------
• [2.043 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:00:41.864
    Nov 29 12:00:41.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename containers 11/29/22 12:00:41.865
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:41.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:41.877
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Nov 29 12:00:41.883: INFO: Waiting up to 5m0s for pod "client-containers-aa77c8a6-f0b0-485b-bc43-d25cfe3ac26e" in namespace "containers-9945" to be "running"
    Nov 29 12:00:41.886: INFO: Pod "client-containers-aa77c8a6-f0b0-485b-bc43-d25cfe3ac26e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.372469ms
    Nov 29 12:00:43.889: INFO: Pod "client-containers-aa77c8a6-f0b0-485b-bc43-d25cfe3ac26e": Phase="Running", Reason="", readiness=true. Elapsed: 2.006245288s
    Nov 29 12:00:43.889: INFO: Pod "client-containers-aa77c8a6-f0b0-485b-bc43-d25cfe3ac26e" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 29 12:00:43.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-9945" for this suite. 11/29/22 12:00:43.897
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:00:43.914
Nov 29 12:00:43.915: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir-wrapper 11/29/22 12:00:43.916
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:43.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:43.928
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 11/29/22 12:00:43.931
STEP: Creating RC which spawns configmap-volume pods 11/29/22 12:00:44.171
Nov 29 12:00:44.295: INFO: Pod name wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/29/22 12:00:44.295
Nov 29 12:00:44.295: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:00:44.320: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.696494ms
Nov 29 12:00:46.323: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02839902s
Nov 29 12:00:48.324: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028675875s
Nov 29 12:00:50.324: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.028852599s
Nov 29 12:00:52.324: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02911725s
Nov 29 12:00:54.323: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.027997981s
Nov 29 12:00:56.325: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.029803513s
Nov 29 12:00:58.324: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.028749301s
Nov 29 12:01:00.343: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.048551779s
Nov 29 12:01:02.325: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Running", Reason="", readiness=true. Elapsed: 18.029939419s
Nov 29 12:01:02.325: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb" satisfied condition "running"
Nov 29 12:01:02.325: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-bxvgw" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:02.329: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-bxvgw": Phase="Running", Reason="", readiness=true. Elapsed: 4.569775ms
Nov 29 12:01:02.330: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-bxvgw" satisfied condition "running"
Nov 29 12:01:02.330: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-gsz5d" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:02.332: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-gsz5d": Phase="Running", Reason="", readiness=true. Elapsed: 2.308465ms
Nov 29 12:01:02.332: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-gsz5d" satisfied condition "running"
Nov 29 12:01:02.332: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-h886q" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:02.334: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-h886q": Phase="Running", Reason="", readiness=true. Elapsed: 2.217661ms
Nov 29 12:01:02.334: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-h886q" satisfied condition "running"
Nov 29 12:01:02.334: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-tc6rj" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:02.336: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-tc6rj": Phase="Running", Reason="", readiness=true. Elapsed: 2.216595ms
Nov 29 12:01:02.336: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-tc6rj" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db in namespace emptydir-wrapper-7818, will wait for the garbage collector to delete the pods 11/29/22 12:01:02.336
Nov 29 12:01:02.394: INFO: Deleting ReplicationController wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db took: 5.01555ms
Nov 29 12:01:02.494: INFO: Terminating ReplicationController wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db pods took: 100.740544ms
STEP: Creating RC which spawns configmap-volume pods 11/29/22 12:01:05.199
Nov 29 12:01:05.216: INFO: Pod name wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed: Found 0 pods out of 5
Nov 29 12:01:10.222: INFO: Pod name wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/29/22 12:01:10.222
Nov 29 12:01:10.222: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:10.224: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.286217ms
Nov 29 12:01:12.227: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00545522s
Nov 29 12:01:14.230: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007849252s
Nov 29 12:01:16.243: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021265022s
Nov 29 12:01:18.229: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007399645s
Nov 29 12:01:20.230: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Running", Reason="", readiness=true. Elapsed: 10.008142809s
Nov 29 12:01:20.230: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2" satisfied condition "running"
Nov 29 12:01:20.230: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-c55k5" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:20.233: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-c55k5": Phase="Running", Reason="", readiness=true. Elapsed: 2.74256ms
Nov 29 12:01:20.233: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-c55k5" satisfied condition "running"
Nov 29 12:01:20.233: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-mcxrc" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:20.235: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-mcxrc": Phase="Running", Reason="", readiness=true. Elapsed: 2.374169ms
Nov 29 12:01:20.235: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-mcxrc" satisfied condition "running"
Nov 29 12:01:20.235: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-ttkj7" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:20.237: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-ttkj7": Phase="Running", Reason="", readiness=true. Elapsed: 1.855751ms
Nov 29 12:01:20.237: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-ttkj7" satisfied condition "running"
Nov 29 12:01:20.237: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-xb8bq" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:20.240: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-xb8bq": Phase="Running", Reason="", readiness=true. Elapsed: 3.057158ms
Nov 29 12:01:20.240: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-xb8bq" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed in namespace emptydir-wrapper-7818, will wait for the garbage collector to delete the pods 11/29/22 12:01:20.24
Nov 29 12:01:20.298: INFO: Deleting ReplicationController wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed took: 4.077807ms
Nov 29 12:01:20.398: INFO: Terminating ReplicationController wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed pods took: 100.669112ms
STEP: Creating RC which spawns configmap-volume pods 11/29/22 12:01:23.003
Nov 29 12:01:23.019: INFO: Pod name wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79: Found 0 pods out of 5
Nov 29 12:01:28.025: INFO: Pod name wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/29/22 12:01:28.025
Nov 29 12:01:28.025: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:28.028: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.996678ms
Nov 29 12:01:30.032: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006607757s
Nov 29 12:01:32.032: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007216603s
Nov 29 12:01:34.032: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006461721s
Nov 29 12:01:36.046: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021187072s
Nov 29 12:01:38.033: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Running", Reason="", readiness=true. Elapsed: 10.00771118s
Nov 29 12:01:38.033: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl" satisfied condition "running"
Nov 29 12:01:38.033: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-fjzfc" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:38.036: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-fjzfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.723734ms
Nov 29 12:01:38.036: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-fjzfc" satisfied condition "running"
Nov 29 12:01:38.036: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-mrbm6" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:38.038: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-mrbm6": Phase="Running", Reason="", readiness=true. Elapsed: 2.813601ms
Nov 29 12:01:38.038: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-mrbm6" satisfied condition "running"
Nov 29 12:01:38.039: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-r8k2h" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:38.041: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-r8k2h": Phase="Running", Reason="", readiness=true. Elapsed: 2.917722ms
Nov 29 12:01:38.041: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-r8k2h" satisfied condition "running"
Nov 29 12:01:38.041: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-xx2ck" in namespace "emptydir-wrapper-7818" to be "running"
Nov 29 12:01:38.044: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-xx2ck": Phase="Running", Reason="", readiness=true. Elapsed: 2.790863ms
Nov 29 12:01:38.044: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-xx2ck" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79 in namespace emptydir-wrapper-7818, will wait for the garbage collector to delete the pods 11/29/22 12:01:38.044
Nov 29 12:01:38.102: INFO: Deleting ReplicationController wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79 took: 4.522968ms
Nov 29 12:01:38.202: INFO: Terminating ReplicationController wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79 pods took: 100.194081ms
STEP: Cleaning up the configMaps 11/29/22 12:01:41.502
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov 29 12:01:41.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7818" for this suite. 11/29/22 12:01:41.658
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":124,"skipped":2361,"failed":0}
------------------------------
• [SLOW TEST] [57.746 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:00:43.914
    Nov 29 12:00:43.915: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir-wrapper 11/29/22 12:00:43.916
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:00:43.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:00:43.928
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 11/29/22 12:00:43.931
    STEP: Creating RC which spawns configmap-volume pods 11/29/22 12:00:44.171
    Nov 29 12:00:44.295: INFO: Pod name wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/29/22 12:00:44.295
    Nov 29 12:00:44.295: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:00:44.320: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.696494ms
    Nov 29 12:00:46.323: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02839902s
    Nov 29 12:00:48.324: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028675875s
    Nov 29 12:00:50.324: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.028852599s
    Nov 29 12:00:52.324: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02911725s
    Nov 29 12:00:54.323: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.027997981s
    Nov 29 12:00:56.325: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.029803513s
    Nov 29 12:00:58.324: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.028749301s
    Nov 29 12:01:00.343: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.048551779s
    Nov 29 12:01:02.325: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb": Phase="Running", Reason="", readiness=true. Elapsed: 18.029939419s
    Nov 29 12:01:02.325: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-b9tpb" satisfied condition "running"
    Nov 29 12:01:02.325: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-bxvgw" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:02.329: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-bxvgw": Phase="Running", Reason="", readiness=true. Elapsed: 4.569775ms
    Nov 29 12:01:02.330: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-bxvgw" satisfied condition "running"
    Nov 29 12:01:02.330: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-gsz5d" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:02.332: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-gsz5d": Phase="Running", Reason="", readiness=true. Elapsed: 2.308465ms
    Nov 29 12:01:02.332: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-gsz5d" satisfied condition "running"
    Nov 29 12:01:02.332: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-h886q" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:02.334: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-h886q": Phase="Running", Reason="", readiness=true. Elapsed: 2.217661ms
    Nov 29 12:01:02.334: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-h886q" satisfied condition "running"
    Nov 29 12:01:02.334: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-tc6rj" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:02.336: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-tc6rj": Phase="Running", Reason="", readiness=true. Elapsed: 2.216595ms
    Nov 29 12:01:02.336: INFO: Pod "wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db-tc6rj" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db in namespace emptydir-wrapper-7818, will wait for the garbage collector to delete the pods 11/29/22 12:01:02.336
    Nov 29 12:01:02.394: INFO: Deleting ReplicationController wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db took: 5.01555ms
    Nov 29 12:01:02.494: INFO: Terminating ReplicationController wrapped-volume-race-ff500b3b-2177-4333-af07-66792f7f05db pods took: 100.740544ms
    STEP: Creating RC which spawns configmap-volume pods 11/29/22 12:01:05.199
    Nov 29 12:01:05.216: INFO: Pod name wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed: Found 0 pods out of 5
    Nov 29 12:01:10.222: INFO: Pod name wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/29/22 12:01:10.222
    Nov 29 12:01:10.222: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:10.224: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.286217ms
    Nov 29 12:01:12.227: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00545522s
    Nov 29 12:01:14.230: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007849252s
    Nov 29 12:01:16.243: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021265022s
    Nov 29 12:01:18.229: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007399645s
    Nov 29 12:01:20.230: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2": Phase="Running", Reason="", readiness=true. Elapsed: 10.008142809s
    Nov 29 12:01:20.230: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-8ngm2" satisfied condition "running"
    Nov 29 12:01:20.230: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-c55k5" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:20.233: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-c55k5": Phase="Running", Reason="", readiness=true. Elapsed: 2.74256ms
    Nov 29 12:01:20.233: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-c55k5" satisfied condition "running"
    Nov 29 12:01:20.233: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-mcxrc" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:20.235: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-mcxrc": Phase="Running", Reason="", readiness=true. Elapsed: 2.374169ms
    Nov 29 12:01:20.235: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-mcxrc" satisfied condition "running"
    Nov 29 12:01:20.235: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-ttkj7" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:20.237: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-ttkj7": Phase="Running", Reason="", readiness=true. Elapsed: 1.855751ms
    Nov 29 12:01:20.237: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-ttkj7" satisfied condition "running"
    Nov 29 12:01:20.237: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-xb8bq" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:20.240: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-xb8bq": Phase="Running", Reason="", readiness=true. Elapsed: 3.057158ms
    Nov 29 12:01:20.240: INFO: Pod "wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed-xb8bq" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed in namespace emptydir-wrapper-7818, will wait for the garbage collector to delete the pods 11/29/22 12:01:20.24
    Nov 29 12:01:20.298: INFO: Deleting ReplicationController wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed took: 4.077807ms
    Nov 29 12:01:20.398: INFO: Terminating ReplicationController wrapped-volume-race-f28aa1d5-c8e3-40f0-b8a8-8744b8cca8ed pods took: 100.669112ms
    STEP: Creating RC which spawns configmap-volume pods 11/29/22 12:01:23.003
    Nov 29 12:01:23.019: INFO: Pod name wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79: Found 0 pods out of 5
    Nov 29 12:01:28.025: INFO: Pod name wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/29/22 12:01:28.025
    Nov 29 12:01:28.025: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:28.028: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.996678ms
    Nov 29 12:01:30.032: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006607757s
    Nov 29 12:01:32.032: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007216603s
    Nov 29 12:01:34.032: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006461721s
    Nov 29 12:01:36.046: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021187072s
    Nov 29 12:01:38.033: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl": Phase="Running", Reason="", readiness=true. Elapsed: 10.00771118s
    Nov 29 12:01:38.033: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-c56sl" satisfied condition "running"
    Nov 29 12:01:38.033: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-fjzfc" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:38.036: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-fjzfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.723734ms
    Nov 29 12:01:38.036: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-fjzfc" satisfied condition "running"
    Nov 29 12:01:38.036: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-mrbm6" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:38.038: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-mrbm6": Phase="Running", Reason="", readiness=true. Elapsed: 2.813601ms
    Nov 29 12:01:38.038: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-mrbm6" satisfied condition "running"
    Nov 29 12:01:38.039: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-r8k2h" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:38.041: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-r8k2h": Phase="Running", Reason="", readiness=true. Elapsed: 2.917722ms
    Nov 29 12:01:38.041: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-r8k2h" satisfied condition "running"
    Nov 29 12:01:38.041: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-xx2ck" in namespace "emptydir-wrapper-7818" to be "running"
    Nov 29 12:01:38.044: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-xx2ck": Phase="Running", Reason="", readiness=true. Elapsed: 2.790863ms
    Nov 29 12:01:38.044: INFO: Pod "wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79-xx2ck" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79 in namespace emptydir-wrapper-7818, will wait for the garbage collector to delete the pods 11/29/22 12:01:38.044
    Nov 29 12:01:38.102: INFO: Deleting ReplicationController wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79 took: 4.522968ms
    Nov 29 12:01:38.202: INFO: Terminating ReplicationController wrapped-volume-race-1f9978d0-57d4-4e86-8468-3d2fdb06fe79 pods took: 100.194081ms
    STEP: Cleaning up the configMaps 11/29/22 12:01:41.502
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov 29 12:01:41.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-7818" for this suite. 11/29/22 12:01:41.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:01:41.66
Nov 29 12:01:41.661: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename disruption 11/29/22 12:01:41.661
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:41.668
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:41.671
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 11/29/22 12:01:41.672
STEP: Waiting for the pdb to be processed 11/29/22 12:01:41.675
STEP: updating the pdb 11/29/22 12:01:43.68
STEP: Waiting for the pdb to be processed 11/29/22 12:01:43.685
STEP: patching the pdb 11/29/22 12:01:43.693
STEP: Waiting for the pdb to be processed 11/29/22 12:01:43.698
STEP: Waiting for the pdb to be deleted 11/29/22 12:01:45.708
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 29 12:01:45.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5041" for this suite. 11/29/22 12:01:45.714
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":125,"skipped":2368,"failed":0}
------------------------------
• [4.056 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:01:41.66
    Nov 29 12:01:41.661: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename disruption 11/29/22 12:01:41.661
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:41.668
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:41.671
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 11/29/22 12:01:41.672
    STEP: Waiting for the pdb to be processed 11/29/22 12:01:41.675
    STEP: updating the pdb 11/29/22 12:01:43.68
    STEP: Waiting for the pdb to be processed 11/29/22 12:01:43.685
    STEP: patching the pdb 11/29/22 12:01:43.693
    STEP: Waiting for the pdb to be processed 11/29/22 12:01:43.698
    STEP: Waiting for the pdb to be deleted 11/29/22 12:01:45.708
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 29 12:01:45.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5041" for this suite. 11/29/22 12:01:45.714
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:01:45.72
Nov 29 12:01:45.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename job 11/29/22 12:01:45.721
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:45.731
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:45.733
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 11/29/22 12:01:45.735
STEP: Ensure pods equal to paralellism count is attached to the job 11/29/22 12:01:45.738
STEP: patching /status 11/29/22 12:01:47.741
STEP: updating /status 11/29/22 12:01:47.746
STEP: get /status 11/29/22 12:01:47.752
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 29 12:01:47.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6109" for this suite. 11/29/22 12:01:47.758
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":126,"skipped":2384,"failed":0}
------------------------------
• [2.044 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:01:45.72
    Nov 29 12:01:45.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename job 11/29/22 12:01:45.721
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:45.731
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:45.733
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 11/29/22 12:01:45.735
    STEP: Ensure pods equal to paralellism count is attached to the job 11/29/22 12:01:45.738
    STEP: patching /status 11/29/22 12:01:47.741
    STEP: updating /status 11/29/22 12:01:47.746
    STEP: get /status 11/29/22 12:01:47.752
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 29 12:01:47.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6109" for this suite. 11/29/22 12:01:47.758
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:01:47.768
Nov 29 12:01:47.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:01:47.769
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:47.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:47.782
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:01:47.791
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:01:48.323
STEP: Deploying the webhook pod 11/29/22 12:01:48.328
STEP: Wait for the deployment to be ready 11/29/22 12:01:48.334
Nov 29 12:01:48.339: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:01:50.347
STEP: Verifying the service has paired with the endpoint 11/29/22 12:01:50.354
Nov 29 12:01:51.354: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Nov 29 12:01:51.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5731-crds.webhook.example.com via the AdmissionRegistration API 11/29/22 12:01:51.865
STEP: Creating a custom resource while v1 is storage version 11/29/22 12:01:51.876
STEP: Patching Custom Resource Definition to set v2 as storage 11/29/22 12:01:54.264
STEP: Patching the custom resource while v2 is storage version 11/29/22 12:01:54.277
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:01:54.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9019" for this suite. 11/29/22 12:01:54.81
STEP: Destroying namespace "webhook-9019-markers" for this suite. 11/29/22 12:01:54.843
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":127,"skipped":2420,"failed":0}
------------------------------
• [SLOW TEST] [7.284 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:01:47.768
    Nov 29 12:01:47.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:01:47.769
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:47.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:47.782
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:01:47.791
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:01:48.323
    STEP: Deploying the webhook pod 11/29/22 12:01:48.328
    STEP: Wait for the deployment to be ready 11/29/22 12:01:48.334
    Nov 29 12:01:48.339: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:01:50.347
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:01:50.354
    Nov 29 12:01:51.354: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Nov 29 12:01:51.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5731-crds.webhook.example.com via the AdmissionRegistration API 11/29/22 12:01:51.865
    STEP: Creating a custom resource while v1 is storage version 11/29/22 12:01:51.876
    STEP: Patching Custom Resource Definition to set v2 as storage 11/29/22 12:01:54.264
    STEP: Patching the custom resource while v2 is storage version 11/29/22 12:01:54.277
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:01:54.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9019" for this suite. 11/29/22 12:01:54.81
    STEP: Destroying namespace "webhook-9019-markers" for this suite. 11/29/22 12:01:54.843
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:01:55.057
Nov 29 12:01:55.057: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 12:01:55.058
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:55.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:55.07
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 11/29/22 12:01:55.073
Nov 29 12:01:55.078: INFO: Waiting up to 5m0s for pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f" in namespace "emptydir-1244" to be "Succeeded or Failed"
Nov 29 12:01:55.081: INFO: Pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.115207ms
Nov 29 12:01:57.084: INFO: Pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006225939s
Nov 29 12:01:59.084: INFO: Pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005991741s
STEP: Saw pod success 11/29/22 12:01:59.084
Nov 29 12:01:59.084: INFO: Pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f" satisfied condition "Succeeded or Failed"
Nov 29 12:01:59.086: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f container test-container: <nil>
STEP: delete the pod 11/29/22 12:01:59.091
Nov 29 12:01:59.096: INFO: Waiting for pod pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f to disappear
Nov 29 12:01:59.098: INFO: Pod pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 12:01:59.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1244" for this suite. 11/29/22 12:01:59.101
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":128,"skipped":2423,"failed":0}
------------------------------
• [4.050 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:01:55.057
    Nov 29 12:01:55.057: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 12:01:55.058
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:55.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:55.07
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/29/22 12:01:55.073
    Nov 29 12:01:55.078: INFO: Waiting up to 5m0s for pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f" in namespace "emptydir-1244" to be "Succeeded or Failed"
    Nov 29 12:01:55.081: INFO: Pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.115207ms
    Nov 29 12:01:57.084: INFO: Pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006225939s
    Nov 29 12:01:59.084: INFO: Pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005991741s
    STEP: Saw pod success 11/29/22 12:01:59.084
    Nov 29 12:01:59.084: INFO: Pod "pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f" satisfied condition "Succeeded or Failed"
    Nov 29 12:01:59.086: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f container test-container: <nil>
    STEP: delete the pod 11/29/22 12:01:59.091
    Nov 29 12:01:59.096: INFO: Waiting for pod pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f to disappear
    Nov 29 12:01:59.098: INFO: Pod pod-f68b05aa-b552-4d5b-8601-55fc614ddc9f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 12:01:59.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1244" for this suite. 11/29/22 12:01:59.101
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:01:59.108
Nov 29 12:01:59.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename security-context 11/29/22 12:01:59.108
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:59.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:59.118
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/29/22 12:01:59.12
Nov 29 12:01:59.124: INFO: Waiting up to 5m0s for pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8" in namespace "security-context-7050" to be "Succeeded or Failed"
Nov 29 12:01:59.131: INFO: Pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.031863ms
Nov 29 12:02:01.135: INFO: Pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011169175s
Nov 29 12:02:03.133: INFO: Pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00951544s
STEP: Saw pod success 11/29/22 12:02:03.133
Nov 29 12:02:03.133: INFO: Pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8" satisfied condition "Succeeded or Failed"
Nov 29 12:02:03.137: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod security-context-0d32f92b-f917-4029-b838-691aa65ee1c8 container test-container: <nil>
STEP: delete the pod 11/29/22 12:02:03.15
Nov 29 12:02:03.229: INFO: Waiting for pod security-context-0d32f92b-f917-4029-b838-691aa65ee1c8 to disappear
Nov 29 12:02:03.237: INFO: Pod security-context-0d32f92b-f917-4029-b838-691aa65ee1c8 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 29 12:02:03.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7050" for this suite. 11/29/22 12:02:03.241
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":129,"skipped":2472,"failed":0}
------------------------------
• [4.138 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:01:59.108
    Nov 29 12:01:59.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename security-context 11/29/22 12:01:59.108
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:01:59.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:01:59.118
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/29/22 12:01:59.12
    Nov 29 12:01:59.124: INFO: Waiting up to 5m0s for pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8" in namespace "security-context-7050" to be "Succeeded or Failed"
    Nov 29 12:01:59.131: INFO: Pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.031863ms
    Nov 29 12:02:01.135: INFO: Pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011169175s
    Nov 29 12:02:03.133: INFO: Pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00951544s
    STEP: Saw pod success 11/29/22 12:02:03.133
    Nov 29 12:02:03.133: INFO: Pod "security-context-0d32f92b-f917-4029-b838-691aa65ee1c8" satisfied condition "Succeeded or Failed"
    Nov 29 12:02:03.137: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod security-context-0d32f92b-f917-4029-b838-691aa65ee1c8 container test-container: <nil>
    STEP: delete the pod 11/29/22 12:02:03.15
    Nov 29 12:02:03.229: INFO: Waiting for pod security-context-0d32f92b-f917-4029-b838-691aa65ee1c8 to disappear
    Nov 29 12:02:03.237: INFO: Pod security-context-0d32f92b-f917-4029-b838-691aa65ee1c8 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 29 12:02:03.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-7050" for this suite. 11/29/22 12:02:03.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:02:03.246
Nov 29 12:02:03.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:02:03.247
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:02:03.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:02:03.269
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:02:03.274
Nov 29 12:02:03.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60" in namespace "projected-7759" to be "Succeeded or Failed"
Nov 29 12:02:03.282: INFO: Pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60": Phase="Pending", Reason="", readiness=false. Elapsed: 3.737371ms
Nov 29 12:02:05.286: INFO: Pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007271624s
Nov 29 12:02:07.287: INFO: Pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008118817s
STEP: Saw pod success 11/29/22 12:02:07.287
Nov 29 12:02:07.287: INFO: Pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60" satisfied condition "Succeeded or Failed"
Nov 29 12:02:07.289: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60 container client-container: <nil>
STEP: delete the pod 11/29/22 12:02:07.293
Nov 29 12:02:07.298: INFO: Waiting for pod downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60 to disappear
Nov 29 12:02:07.300: INFO: Pod downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 12:02:07.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7759" for this suite. 11/29/22 12:02:07.304
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":130,"skipped":2477,"failed":0}
------------------------------
• [4.061 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:02:03.246
    Nov 29 12:02:03.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:02:03.247
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:02:03.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:02:03.269
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:02:03.274
    Nov 29 12:02:03.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60" in namespace "projected-7759" to be "Succeeded or Failed"
    Nov 29 12:02:03.282: INFO: Pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60": Phase="Pending", Reason="", readiness=false. Elapsed: 3.737371ms
    Nov 29 12:02:05.286: INFO: Pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007271624s
    Nov 29 12:02:07.287: INFO: Pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008118817s
    STEP: Saw pod success 11/29/22 12:02:07.287
    Nov 29 12:02:07.287: INFO: Pod "downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60" satisfied condition "Succeeded or Failed"
    Nov 29 12:02:07.289: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:02:07.293
    Nov 29 12:02:07.298: INFO: Waiting for pod downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60 to disappear
    Nov 29 12:02:07.300: INFO: Pod downwardapi-volume-16daa475-01c7-4f49-8b78-71857cf39c60 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 12:02:07.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7759" for this suite. 11/29/22 12:02:07.304
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:02:07.307
Nov 29 12:02:07.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename statefulset 11/29/22 12:02:07.308
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:02:07.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:02:07.317
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9103 11/29/22 12:02:07.32
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 11/29/22 12:02:07.324
Nov 29 12:02:07.332: INFO: Found 0 stateful pods, waiting for 3
Nov 29 12:02:17.336: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 12:02:17.336: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 12:02:17.336: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 12:02:17.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-9103 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 12:02:17.476: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 12:02:17.476: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 12:02:17.476: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/29/22 12:02:27.489
Nov 29 12:02:27.505: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/29/22 12:02:27.505
STEP: Updating Pods in reverse ordinal order 11/29/22 12:02:37.517
Nov 29 12:02:37.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-9103 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 12:02:37.647: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 29 12:02:37.647: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 12:02:37.647: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 11/29/22 12:02:47.661
Nov 29 12:02:47.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-9103 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 12:02:47.805: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 12:02:47.805: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 12:02:47.805: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 12:02:57.835: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 11/29/22 12:03:07.847
Nov 29 12:03:07.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-9103 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 12:03:07.968: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 29 12:03:07.968: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 12:03:07.968: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 29 12:03:17.982: INFO: Deleting all statefulset in ns statefulset-9103
Nov 29 12:03:17.984: INFO: Scaling statefulset ss2 to 0
Nov 29 12:03:28.017: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 12:03:28.019: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 29 12:03:28.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9103" for this suite. 11/29/22 12:03:28.033
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":131,"skipped":2484,"failed":0}
------------------------------
• [SLOW TEST] [80.730 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:02:07.307
    Nov 29 12:02:07.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename statefulset 11/29/22 12:02:07.308
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:02:07.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:02:07.317
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9103 11/29/22 12:02:07.32
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 11/29/22 12:02:07.324
    Nov 29 12:02:07.332: INFO: Found 0 stateful pods, waiting for 3
    Nov 29 12:02:17.336: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 12:02:17.336: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 12:02:17.336: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 12:02:17.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-9103 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 12:02:17.476: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 12:02:17.476: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 12:02:17.476: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/29/22 12:02:27.489
    Nov 29 12:02:27.505: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/29/22 12:02:27.505
    STEP: Updating Pods in reverse ordinal order 11/29/22 12:02:37.517
    Nov 29 12:02:37.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-9103 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 12:02:37.647: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 29 12:02:37.647: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 12:02:37.647: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 11/29/22 12:02:47.661
    Nov 29 12:02:47.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-9103 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 12:02:47.805: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 12:02:47.805: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 12:02:47.805: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 12:02:57.835: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 11/29/22 12:03:07.847
    Nov 29 12:03:07.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-9103 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 12:03:07.968: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 29 12:03:07.968: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 12:03:07.968: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 29 12:03:17.982: INFO: Deleting all statefulset in ns statefulset-9103
    Nov 29 12:03:17.984: INFO: Scaling statefulset ss2 to 0
    Nov 29 12:03:28.017: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 12:03:28.019: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 29 12:03:28.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9103" for this suite. 11/29/22 12:03:28.033
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:03:28.038
Nov 29 12:03:28.038: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:03:28.039
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:03:28.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:03:28.049
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5856 11/29/22 12:03:28.056
STEP: changing the ExternalName service to type=NodePort 11/29/22 12:03:28.061
STEP: creating replication controller externalname-service in namespace services-5856 11/29/22 12:03:28.081
I1129 12:03:28.087301      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5856, replica count: 2
I1129 12:03:31.139060      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 12:03:31.139: INFO: Creating new exec pod
Nov 29 12:03:31.146: INFO: Waiting up to 5m0s for pod "execpod4zr9g" in namespace "services-5856" to be "running"
Nov 29 12:03:31.158: INFO: Pod "execpod4zr9g": Phase="Pending", Reason="", readiness=false. Elapsed: 12.024441ms
Nov 29 12:03:33.161: INFO: Pod "execpod4zr9g": Phase="Running", Reason="", readiness=true. Elapsed: 2.015103634s
Nov 29 12:03:33.161: INFO: Pod "execpod4zr9g" satisfied condition "running"
Nov 29 12:03:34.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 29 12:03:34.299: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 29 12:03:34.299: INFO: stdout: ""
Nov 29 12:03:35.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 29 12:03:35.433: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 29 12:03:35.433: INFO: stdout: "externalname-service-fm89h"
Nov 29 12:03:35.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.208.128 80'
Nov 29 12:03:35.550: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.208.128 80\nConnection to 100.65.208.128 80 port [tcp/http] succeeded!\n"
Nov 29 12:03:35.550: INFO: stdout: "externalname-service-fm89h"
Nov 29 12:03:35.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.111 31121'
Nov 29 12:03:35.671: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.111 31121\nConnection to 192.168.8.111 31121 port [tcp/*] succeeded!\n"
Nov 29 12:03:35.671: INFO: stdout: "externalname-service-fm89h"
Nov 29 12:03:35.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.35 31121'
Nov 29 12:03:35.788: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.35 31121\nConnection to 192.168.8.35 31121 port [tcp/*] succeeded!\n"
Nov 29 12:03:35.788: INFO: stdout: "externalname-service-fm89h"
Nov 29 12:03:35.788: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:03:35.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5856" for this suite. 11/29/22 12:03:35.819
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":132,"skipped":2484,"failed":0}
------------------------------
• [SLOW TEST] [7.785 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:03:28.038
    Nov 29 12:03:28.038: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:03:28.039
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:03:28.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:03:28.049
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-5856 11/29/22 12:03:28.056
    STEP: changing the ExternalName service to type=NodePort 11/29/22 12:03:28.061
    STEP: creating replication controller externalname-service in namespace services-5856 11/29/22 12:03:28.081
    I1129 12:03:28.087301      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5856, replica count: 2
    I1129 12:03:31.139060      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 12:03:31.139: INFO: Creating new exec pod
    Nov 29 12:03:31.146: INFO: Waiting up to 5m0s for pod "execpod4zr9g" in namespace "services-5856" to be "running"
    Nov 29 12:03:31.158: INFO: Pod "execpod4zr9g": Phase="Pending", Reason="", readiness=false. Elapsed: 12.024441ms
    Nov 29 12:03:33.161: INFO: Pod "execpod4zr9g": Phase="Running", Reason="", readiness=true. Elapsed: 2.015103634s
    Nov 29 12:03:33.161: INFO: Pod "execpod4zr9g" satisfied condition "running"
    Nov 29 12:03:34.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 29 12:03:34.299: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 29 12:03:34.299: INFO: stdout: ""
    Nov 29 12:03:35.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 29 12:03:35.433: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 29 12:03:35.433: INFO: stdout: "externalname-service-fm89h"
    Nov 29 12:03:35.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.208.128 80'
    Nov 29 12:03:35.550: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.208.128 80\nConnection to 100.65.208.128 80 port [tcp/http] succeeded!\n"
    Nov 29 12:03:35.550: INFO: stdout: "externalname-service-fm89h"
    Nov 29 12:03:35.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.111 31121'
    Nov 29 12:03:35.671: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.111 31121\nConnection to 192.168.8.111 31121 port [tcp/*] succeeded!\n"
    Nov 29 12:03:35.671: INFO: stdout: "externalname-service-fm89h"
    Nov 29 12:03:35.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5856 exec execpod4zr9g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.35 31121'
    Nov 29 12:03:35.788: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.35 31121\nConnection to 192.168.8.35 31121 port [tcp/*] succeeded!\n"
    Nov 29 12:03:35.788: INFO: stdout: "externalname-service-fm89h"
    Nov 29 12:03:35.788: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:03:35.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5856" for this suite. 11/29/22 12:03:35.819
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:03:35.826
Nov 29 12:03:35.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-probe 11/29/22 12:03:35.827
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:03:35.834
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:03:35.836
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Nov 29 12:03:35.842: INFO: Waiting up to 5m0s for pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e" in namespace "container-probe-914" to be "running and ready"
Nov 29 12:03:35.845: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.186907ms
Nov 29 12:03:35.845: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:03:37.848: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 2.005700729s
Nov 29 12:03:37.848: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:39.850: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 4.007454808s
Nov 29 12:03:39.850: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:41.848: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 6.005967483s
Nov 29 12:03:41.848: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:43.848: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 8.005700873s
Nov 29 12:03:43.848: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:45.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 10.007153112s
Nov 29 12:03:45.849: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:47.848: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 12.006121411s
Nov 29 12:03:47.848: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:49.850: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 14.007869228s
Nov 29 12:03:49.850: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:51.851: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 16.008689435s
Nov 29 12:03:51.851: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:53.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 18.006679898s
Nov 29 12:03:53.849: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:55.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 20.006664311s
Nov 29 12:03:55.849: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
Nov 29 12:03:57.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=true. Elapsed: 22.006900699s
Nov 29 12:03:57.849: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = true)
Nov 29 12:03:57.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e" satisfied condition "running and ready"
Nov 29 12:03:57.851: INFO: Container started at 2022-11-29 12:03:36 +0000 UTC, pod became ready at 2022-11-29 12:03:56 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 29 12:03:57.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-914" for this suite. 11/29/22 12:03:57.855
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":133,"skipped":2567,"failed":0}
------------------------------
• [SLOW TEST] [22.032 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:03:35.826
    Nov 29 12:03:35.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-probe 11/29/22 12:03:35.827
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:03:35.834
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:03:35.836
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Nov 29 12:03:35.842: INFO: Waiting up to 5m0s for pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e" in namespace "container-probe-914" to be "running and ready"
    Nov 29 12:03:35.845: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.186907ms
    Nov 29 12:03:35.845: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:03:37.848: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 2.005700729s
    Nov 29 12:03:37.848: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:39.850: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 4.007454808s
    Nov 29 12:03:39.850: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:41.848: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 6.005967483s
    Nov 29 12:03:41.848: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:43.848: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 8.005700873s
    Nov 29 12:03:43.848: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:45.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 10.007153112s
    Nov 29 12:03:45.849: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:47.848: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 12.006121411s
    Nov 29 12:03:47.848: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:49.850: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 14.007869228s
    Nov 29 12:03:49.850: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:51.851: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 16.008689435s
    Nov 29 12:03:51.851: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:53.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 18.006679898s
    Nov 29 12:03:53.849: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:55.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=false. Elapsed: 20.006664311s
    Nov 29 12:03:55.849: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = false)
    Nov 29 12:03:57.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e": Phase="Running", Reason="", readiness=true. Elapsed: 22.006900699s
    Nov 29 12:03:57.849: INFO: The phase of Pod test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e is Running (Ready = true)
    Nov 29 12:03:57.849: INFO: Pod "test-webserver-86da53c2-ea33-4ea3-9fbc-5cbf05c3537e" satisfied condition "running and ready"
    Nov 29 12:03:57.851: INFO: Container started at 2022-11-29 12:03:36 +0000 UTC, pod became ready at 2022-11-29 12:03:56 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 29 12:03:57.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-914" for this suite. 11/29/22 12:03:57.855
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:03:57.861
Nov 29 12:03:57.861: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:03:57.862
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:03:57.879
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:03:57.881
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:03:57.895
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:03:58.316
STEP: Deploying the webhook pod 11/29/22 12:03:58.321
STEP: Wait for the deployment to be ready 11/29/22 12:03:58.333
Nov 29 12:03:58.344: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:04:00.353
STEP: Verifying the service has paired with the endpoint 11/29/22 12:04:00.359
Nov 29 12:04:01.360: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 11/29/22 12:04:01.362
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/29/22 12:04:01.363
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/29/22 12:04:01.363
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/29/22 12:04:01.363
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/29/22 12:04:01.364
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/29/22 12:04:01.364
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/29/22 12:04:01.365
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:04:01.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3226" for this suite. 11/29/22 12:04:01.368
STEP: Destroying namespace "webhook-3226-markers" for this suite. 11/29/22 12:04:01.372
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":134,"skipped":2585,"failed":0}
------------------------------
• [3.538 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:03:57.861
    Nov 29 12:03:57.861: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:03:57.862
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:03:57.879
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:03:57.881
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:03:57.895
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:03:58.316
    STEP: Deploying the webhook pod 11/29/22 12:03:58.321
    STEP: Wait for the deployment to be ready 11/29/22 12:03:58.333
    Nov 29 12:03:58.344: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:04:00.353
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:04:00.359
    Nov 29 12:04:01.360: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 11/29/22 12:04:01.362
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/29/22 12:04:01.363
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/29/22 12:04:01.363
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/29/22 12:04:01.363
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/29/22 12:04:01.364
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/29/22 12:04:01.364
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/29/22 12:04:01.365
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:04:01.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3226" for this suite. 11/29/22 12:04:01.368
    STEP: Destroying namespace "webhook-3226-markers" for this suite. 11/29/22 12:04:01.372
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:01.4
Nov 29 12:04:01.400: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:04:01.401
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:01.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:01.416
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:04:01.418
Nov 29 12:04:01.423: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc" in namespace "projected-7551" to be "Succeeded or Failed"
Nov 29 12:04:01.426: INFO: Pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.025623ms
Nov 29 12:04:03.429: INFO: Pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006138778s
Nov 29 12:04:05.428: INFO: Pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005757055s
STEP: Saw pod success 11/29/22 12:04:05.428
Nov 29 12:04:05.428: INFO: Pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc" satisfied condition "Succeeded or Failed"
Nov 29 12:04:05.431: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc container client-container: <nil>
STEP: delete the pod 11/29/22 12:04:05.444
Nov 29 12:04:05.451: INFO: Waiting for pod downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc to disappear
Nov 29 12:04:05.453: INFO: Pod downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 12:04:05.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7551" for this suite. 11/29/22 12:04:05.456
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":135,"skipped":2586,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:01.4
    Nov 29 12:04:01.400: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:04:01.401
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:01.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:01.416
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:04:01.418
    Nov 29 12:04:01.423: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc" in namespace "projected-7551" to be "Succeeded or Failed"
    Nov 29 12:04:01.426: INFO: Pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.025623ms
    Nov 29 12:04:03.429: INFO: Pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006138778s
    Nov 29 12:04:05.428: INFO: Pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005757055s
    STEP: Saw pod success 11/29/22 12:04:05.428
    Nov 29 12:04:05.428: INFO: Pod "downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc" satisfied condition "Succeeded or Failed"
    Nov 29 12:04:05.431: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc container client-container: <nil>
    STEP: delete the pod 11/29/22 12:04:05.444
    Nov 29 12:04:05.451: INFO: Waiting for pod downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc to disappear
    Nov 29 12:04:05.453: INFO: Pod downwardapi-volume-94ed7899-7372-462e-9efc-92e686153bcc no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 12:04:05.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7551" for this suite. 11/29/22 12:04:05.456
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:05.46
Nov 29 12:04:05.460: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename proxy 11/29/22 12:04:05.461
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:05.474
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:05.476
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 11/29/22 12:04:05.488
STEP: creating replication controller proxy-service-w72kh in namespace proxy-1928 11/29/22 12:04:05.488
I1129 12:04:05.493569      22 runners.go:193] Created replication controller with name: proxy-service-w72kh, namespace: proxy-1928, replica count: 1
I1129 12:04:06.545306      22 runners.go:193] proxy-service-w72kh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:04:07.545457      22 runners.go:193] proxy-service-w72kh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1129 12:04:08.545623      22 runners.go:193] proxy-service-w72kh Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 12:04:08.548: INFO: setup took 3.069287795s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/29/22 12:04:08.548
Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.126333ms)
Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 6.122854ms)
Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 6.270574ms)
Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.27238ms)
Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 6.358981ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 9.685029ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 9.97119ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 10.248874ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 9.934516ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 10.087322ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 10.252657ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 10.54849ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 10.621202ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 10.407733ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 10.485861ms)
Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 10.539209ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.762783ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.780881ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.147672ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.922765ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.166327ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 6.130693ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 6.314784ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.549978ms)
Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 6.400988ms)
Nov 29 12:04:08.566: INFO: (1) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 7.049917ms)
Nov 29 12:04:08.566: INFO: (1) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.464947ms)
Nov 29 12:04:08.566: INFO: (1) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.599422ms)
Nov 29 12:04:08.566: INFO: (1) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.74621ms)
Nov 29 12:04:08.567: INFO: (1) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.852148ms)
Nov 29 12:04:08.567: INFO: (1) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.966148ms)
Nov 29 12:04:08.567: INFO: (1) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.846229ms)
Nov 29 12:04:08.576: INFO: (2) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 8.736029ms)
Nov 29 12:04:08.578: INFO: (2) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 10.908938ms)
Nov 29 12:04:08.578: INFO: (2) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 11.121622ms)
Nov 29 12:04:08.578: INFO: (2) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 11.41048ms)
Nov 29 12:04:08.585: INFO: (2) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 17.585581ms)
Nov 29 12:04:08.585: INFO: (2) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 17.662812ms)
Nov 29 12:04:08.585: INFO: (2) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 17.859245ms)
Nov 29 12:04:08.585: INFO: (2) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 18.276739ms)
Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 19.201657ms)
Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 19.229722ms)
Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 19.307123ms)
Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 19.541125ms)
Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 19.528351ms)
Nov 29 12:04:08.587: INFO: (2) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 20.152092ms)
Nov 29 12:04:08.587: INFO: (2) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 20.10946ms)
Nov 29 12:04:08.588: INFO: (2) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 21.148614ms)
Nov 29 12:04:08.637: INFO: (3) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 48.684886ms)
Nov 29 12:04:08.643: INFO: (3) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 54.513677ms)
Nov 29 12:04:08.643: INFO: (3) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 54.66714ms)
Nov 29 12:04:08.644: INFO: (3) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 55.196867ms)
Nov 29 12:04:08.644: INFO: (3) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 55.372146ms)
Nov 29 12:04:08.646: INFO: (3) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 57.645592ms)
Nov 29 12:04:08.646: INFO: (3) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 57.93051ms)
Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 58.143856ms)
Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 58.263996ms)
Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 58.256463ms)
Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 58.195908ms)
Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 58.421514ms)
Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 58.541285ms)
Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 58.972736ms)
Nov 29 12:04:08.648: INFO: (3) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 59.317047ms)
Nov 29 12:04:08.648: INFO: (3) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 59.357012ms)
Nov 29 12:04:08.663: INFO: (4) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 15.254209ms)
Nov 29 12:04:08.663: INFO: (4) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 15.307114ms)
Nov 29 12:04:08.663: INFO: (4) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 15.218703ms)
Nov 29 12:04:08.664: INFO: (4) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 15.658107ms)
Nov 29 12:04:08.734: INFO: (4) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 86.117424ms)
Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 87.163056ms)
Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 87.359316ms)
Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 87.31354ms)
Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 87.433267ms)
Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 87.292085ms)
Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 87.406248ms)
Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 87.475086ms)
Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 87.44297ms)
Nov 29 12:04:08.736: INFO: (4) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 87.939725ms)
Nov 29 12:04:08.736: INFO: (4) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 88.039824ms)
Nov 29 12:04:08.736: INFO: (4) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 88.065858ms)
Nov 29 12:04:08.750: INFO: (5) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 14.060566ms)
Nov 29 12:04:08.750: INFO: (5) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 14.003252ms)
Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 14.877693ms)
Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 15.029631ms)
Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 15.102481ms)
Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 15.269238ms)
Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 14.994849ms)
Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 15.020581ms)
Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 15.293511ms)
Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 15.057709ms)
Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 19.900164ms)
Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 19.890182ms)
Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 19.597974ms)
Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 19.835042ms)
Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 19.748401ms)
Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 19.936768ms)
Nov 29 12:04:08.762: INFO: (6) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.591977ms)
Nov 29 12:04:08.762: INFO: (6) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.954986ms)
Nov 29 12:04:08.762: INFO: (6) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.176933ms)
Nov 29 12:04:08.762: INFO: (6) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.892341ms)
Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 6.300158ms)
Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 6.329725ms)
Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 6.193998ms)
Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 6.449596ms)
Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.34056ms)
Nov 29 12:04:08.764: INFO: (6) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.966686ms)
Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 9.048924ms)
Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 9.223544ms)
Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 9.430299ms)
Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 9.411368ms)
Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 9.787875ms)
Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 9.923971ms)
Nov 29 12:04:08.838: INFO: (7) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 72.134376ms)
Nov 29 12:04:08.839: INFO: (7) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 72.768039ms)
Nov 29 12:04:08.839: INFO: (7) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 72.70193ms)
Nov 29 12:04:08.839: INFO: (7) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 72.773817ms)
Nov 29 12:04:08.839: INFO: (7) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 73.056721ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 73.46822ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 73.352918ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 73.485059ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 73.578053ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 73.799786ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 73.843538ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 73.882282ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 73.973373ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 74.090141ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 74.077374ms)
Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 73.984893ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.923581ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.795638ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.24889ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.314746ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.279622ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.53535ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.256082ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 5.548109ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.496272ms)
Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.229244ms)
Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.08466ms)
Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.130021ms)
Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.303866ms)
Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.404682ms)
Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.380052ms)
Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.540894ms)
Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 3.859212ms)
Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 3.906633ms)
Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.511939ms)
Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 4.114606ms)
Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.235857ms)
Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.407612ms)
Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 4.486539ms)
Nov 29 12:04:08.854: INFO: (9) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.075658ms)
Nov 29 12:04:08.854: INFO: (9) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.936378ms)
Nov 29 12:04:08.854: INFO: (9) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.067879ms)
Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 6.045744ms)
Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 5.997967ms)
Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 6.3304ms)
Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 6.40657ms)
Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 6.294167ms)
Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 6.857019ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.389915ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.478903ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.394454ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.751147ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.934718ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.950506ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 5.926655ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 6.075505ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.95574ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.015214ms)
Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.774499ms)
Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.347719ms)
Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.32233ms)
Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.266405ms)
Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.215432ms)
Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.556255ms)
Nov 29 12:04:08.867: INFO: (11) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 3.943446ms)
Nov 29 12:04:08.867: INFO: (11) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.07708ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.634961ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.611555ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.682834ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 4.766013ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 4.791033ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 4.850602ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 4.771797ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.788282ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 5.100543ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.096974ms)
Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.052178ms)
Nov 29 12:04:08.869: INFO: (11) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 5.899811ms)
Nov 29 12:04:08.870: INFO: (11) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 6.256111ms)
Nov 29 12:04:08.870: INFO: (11) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 6.341753ms)
Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 3.582926ms)
Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 3.68415ms)
Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 3.82565ms)
Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 4.599341ms)
Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.277832ms)
Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.301117ms)
Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 4.234803ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 4.448628ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.889491ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.010777ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 4.889277ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 4.954395ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 5.002396ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 4.657379ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.381192ms)
Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.712491ms)
Nov 29 12:04:08.880: INFO: (13) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.737621ms)
Nov 29 12:04:08.880: INFO: (13) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.861154ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.091235ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.796757ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.165827ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.188716ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.169608ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.322109ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.363573ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.568665ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 5.548431ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 5.462853ms)
Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 5.646742ms)
Nov 29 12:04:08.883: INFO: (13) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 6.975744ms)
Nov 29 12:04:08.883: INFO: (13) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.040511ms)
Nov 29 12:04:08.883: INFO: (13) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.133811ms)
Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 4.311086ms)
Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.113722ms)
Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.27484ms)
Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.196557ms)
Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.355453ms)
Nov 29 12:04:08.888: INFO: (14) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.611462ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 51.289914ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 51.399438ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 51.419045ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 51.20904ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 51.159991ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 51.259298ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 51.283854ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 51.300483ms)
Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 51.518862ms)
Nov 29 12:04:08.937: INFO: (14) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 53.874056ms)
Nov 29 12:04:08.942: INFO: (15) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.939251ms)
Nov 29 12:04:08.942: INFO: (15) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.363815ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.326385ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.536698ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.614953ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.977142ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.826508ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.751104ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.875217ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 6.050231ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 5.917474ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 6.017091ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 6.018761ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 6.274827ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 6.239163ms)
Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 6.429372ms)
Nov 29 12:04:08.947: INFO: (16) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 3.816205ms)
Nov 29 12:04:08.948: INFO: (16) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.235749ms)
Nov 29 12:04:08.948: INFO: (16) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.227173ms)
Nov 29 12:04:08.948: INFO: (16) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 4.413182ms)
Nov 29 12:04:08.948: INFO: (16) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 4.699777ms)
Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.030733ms)
Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.945439ms)
Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.360707ms)
Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.495692ms)
Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.356361ms)
Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.445923ms)
Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.697216ms)
Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.653825ms)
Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.908675ms)
Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 8.030758ms)
Nov 29 12:04:08.952: INFO: (16) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.996945ms)
Nov 29 12:04:08.958: INFO: (17) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.295078ms)
Nov 29 12:04:08.958: INFO: (17) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.304194ms)
Nov 29 12:04:08.958: INFO: (17) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 5.50045ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 6.435021ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.618223ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.746592ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 6.925849ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 6.963817ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.922764ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 6.762719ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 6.794052ms)
Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.261331ms)
Nov 29 12:04:08.960: INFO: (17) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.381655ms)
Nov 29 12:04:08.960: INFO: (17) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.294897ms)
Nov 29 12:04:08.960: INFO: (17) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.338317ms)
Nov 29 12:04:08.960: INFO: (17) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.687717ms)
Nov 29 12:04:08.965: INFO: (18) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.635101ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.911609ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.060872ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.040795ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.037016ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.399687ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.376539ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.430417ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.672166ms)
Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 5.487007ms)
Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.135388ms)
Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.885296ms)
Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.76179ms)
Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.949992ms)
Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 8.026555ms)
Nov 29 12:04:08.969: INFO: (18) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 8.25524ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 3.864149ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 3.94794ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 4.01469ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.273612ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.147816ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 4.179692ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.275369ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.35029ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.42256ms)
Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.343816ms)
Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 6.152869ms)
Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 6.505478ms)
Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 6.243486ms)
Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 6.363856ms)
Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 6.425052ms)
Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 6.562623ms)
STEP: deleting ReplicationController proxy-service-w72kh in namespace proxy-1928, will wait for the garbage collector to delete the pods 11/29/22 12:04:08.975
Nov 29 12:04:09.032: INFO: Deleting ReplicationController proxy-service-w72kh took: 4.548348ms
Nov 29 12:04:09.133: INFO: Terminating ReplicationController proxy-service-w72kh pods took: 100.28927ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 29 12:04:10.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1928" for this suite. 11/29/22 12:04:10.942
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":136,"skipped":2598,"failed":0}
------------------------------
• [SLOW TEST] [5.486 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:05.46
    Nov 29 12:04:05.460: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename proxy 11/29/22 12:04:05.461
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:05.474
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:05.476
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 11/29/22 12:04:05.488
    STEP: creating replication controller proxy-service-w72kh in namespace proxy-1928 11/29/22 12:04:05.488
    I1129 12:04:05.493569      22 runners.go:193] Created replication controller with name: proxy-service-w72kh, namespace: proxy-1928, replica count: 1
    I1129 12:04:06.545306      22 runners.go:193] proxy-service-w72kh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:04:07.545457      22 runners.go:193] proxy-service-w72kh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I1129 12:04:08.545623      22 runners.go:193] proxy-service-w72kh Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 12:04:08.548: INFO: setup took 3.069287795s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/29/22 12:04:08.548
    Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.126333ms)
    Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 6.122854ms)
    Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 6.270574ms)
    Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.27238ms)
    Nov 29 12:04:08.554: INFO: (0) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 6.358981ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 9.685029ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 9.97119ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 10.248874ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 9.934516ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 10.087322ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 10.252657ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 10.54849ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 10.621202ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 10.407733ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 10.485861ms)
    Nov 29 12:04:08.558: INFO: (0) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 10.539209ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.762783ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.780881ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.147672ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.922765ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.166327ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 6.130693ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 6.314784ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.549978ms)
    Nov 29 12:04:08.565: INFO: (1) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 6.400988ms)
    Nov 29 12:04:08.566: INFO: (1) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 7.049917ms)
    Nov 29 12:04:08.566: INFO: (1) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.464947ms)
    Nov 29 12:04:08.566: INFO: (1) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.599422ms)
    Nov 29 12:04:08.566: INFO: (1) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.74621ms)
    Nov 29 12:04:08.567: INFO: (1) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.852148ms)
    Nov 29 12:04:08.567: INFO: (1) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.966148ms)
    Nov 29 12:04:08.567: INFO: (1) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.846229ms)
    Nov 29 12:04:08.576: INFO: (2) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 8.736029ms)
    Nov 29 12:04:08.578: INFO: (2) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 10.908938ms)
    Nov 29 12:04:08.578: INFO: (2) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 11.121622ms)
    Nov 29 12:04:08.578: INFO: (2) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 11.41048ms)
    Nov 29 12:04:08.585: INFO: (2) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 17.585581ms)
    Nov 29 12:04:08.585: INFO: (2) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 17.662812ms)
    Nov 29 12:04:08.585: INFO: (2) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 17.859245ms)
    Nov 29 12:04:08.585: INFO: (2) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 18.276739ms)
    Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 19.201657ms)
    Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 19.229722ms)
    Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 19.307123ms)
    Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 19.541125ms)
    Nov 29 12:04:08.586: INFO: (2) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 19.528351ms)
    Nov 29 12:04:08.587: INFO: (2) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 20.152092ms)
    Nov 29 12:04:08.587: INFO: (2) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 20.10946ms)
    Nov 29 12:04:08.588: INFO: (2) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 21.148614ms)
    Nov 29 12:04:08.637: INFO: (3) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 48.684886ms)
    Nov 29 12:04:08.643: INFO: (3) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 54.513677ms)
    Nov 29 12:04:08.643: INFO: (3) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 54.66714ms)
    Nov 29 12:04:08.644: INFO: (3) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 55.196867ms)
    Nov 29 12:04:08.644: INFO: (3) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 55.372146ms)
    Nov 29 12:04:08.646: INFO: (3) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 57.645592ms)
    Nov 29 12:04:08.646: INFO: (3) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 57.93051ms)
    Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 58.143856ms)
    Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 58.263996ms)
    Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 58.256463ms)
    Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 58.195908ms)
    Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 58.421514ms)
    Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 58.541285ms)
    Nov 29 12:04:08.647: INFO: (3) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 58.972736ms)
    Nov 29 12:04:08.648: INFO: (3) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 59.317047ms)
    Nov 29 12:04:08.648: INFO: (3) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 59.357012ms)
    Nov 29 12:04:08.663: INFO: (4) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 15.254209ms)
    Nov 29 12:04:08.663: INFO: (4) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 15.307114ms)
    Nov 29 12:04:08.663: INFO: (4) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 15.218703ms)
    Nov 29 12:04:08.664: INFO: (4) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 15.658107ms)
    Nov 29 12:04:08.734: INFO: (4) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 86.117424ms)
    Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 87.163056ms)
    Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 87.359316ms)
    Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 87.31354ms)
    Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 87.433267ms)
    Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 87.292085ms)
    Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 87.406248ms)
    Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 87.475086ms)
    Nov 29 12:04:08.735: INFO: (4) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 87.44297ms)
    Nov 29 12:04:08.736: INFO: (4) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 87.939725ms)
    Nov 29 12:04:08.736: INFO: (4) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 88.039824ms)
    Nov 29 12:04:08.736: INFO: (4) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 88.065858ms)
    Nov 29 12:04:08.750: INFO: (5) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 14.060566ms)
    Nov 29 12:04:08.750: INFO: (5) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 14.003252ms)
    Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 14.877693ms)
    Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 15.029631ms)
    Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 15.102481ms)
    Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 15.269238ms)
    Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 14.994849ms)
    Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 15.020581ms)
    Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 15.293511ms)
    Nov 29 12:04:08.751: INFO: (5) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 15.057709ms)
    Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 19.900164ms)
    Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 19.890182ms)
    Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 19.597974ms)
    Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 19.835042ms)
    Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 19.748401ms)
    Nov 29 12:04:08.756: INFO: (5) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 19.936768ms)
    Nov 29 12:04:08.762: INFO: (6) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.591977ms)
    Nov 29 12:04:08.762: INFO: (6) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.954986ms)
    Nov 29 12:04:08.762: INFO: (6) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.176933ms)
    Nov 29 12:04:08.762: INFO: (6) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.892341ms)
    Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 6.300158ms)
    Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 6.329725ms)
    Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 6.193998ms)
    Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 6.449596ms)
    Nov 29 12:04:08.763: INFO: (6) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.34056ms)
    Nov 29 12:04:08.764: INFO: (6) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.966686ms)
    Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 9.048924ms)
    Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 9.223544ms)
    Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 9.430299ms)
    Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 9.411368ms)
    Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 9.787875ms)
    Nov 29 12:04:08.766: INFO: (6) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 9.923971ms)
    Nov 29 12:04:08.838: INFO: (7) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 72.134376ms)
    Nov 29 12:04:08.839: INFO: (7) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 72.768039ms)
    Nov 29 12:04:08.839: INFO: (7) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 72.70193ms)
    Nov 29 12:04:08.839: INFO: (7) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 72.773817ms)
    Nov 29 12:04:08.839: INFO: (7) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 73.056721ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 73.46822ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 73.352918ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 73.485059ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 73.578053ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 73.799786ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 73.843538ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 73.882282ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 73.973373ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 74.090141ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 74.077374ms)
    Nov 29 12:04:08.840: INFO: (7) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 73.984893ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.923581ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.795638ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.24889ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.314746ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.279622ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.53535ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.256082ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 5.548109ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.496272ms)
    Nov 29 12:04:08.846: INFO: (8) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.229244ms)
    Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.08466ms)
    Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.130021ms)
    Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.303866ms)
    Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.404682ms)
    Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.380052ms)
    Nov 29 12:04:08.848: INFO: (8) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.540894ms)
    Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 3.859212ms)
    Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 3.906633ms)
    Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.511939ms)
    Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 4.114606ms)
    Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.235857ms)
    Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.407612ms)
    Nov 29 12:04:08.853: INFO: (9) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 4.486539ms)
    Nov 29 12:04:08.854: INFO: (9) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.075658ms)
    Nov 29 12:04:08.854: INFO: (9) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.936378ms)
    Nov 29 12:04:08.854: INFO: (9) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.067879ms)
    Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 6.045744ms)
    Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 5.997967ms)
    Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 6.3304ms)
    Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 6.40657ms)
    Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 6.294167ms)
    Nov 29 12:04:08.855: INFO: (9) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 6.857019ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.389915ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.478903ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.394454ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.751147ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.934718ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.950506ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 5.926655ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 6.075505ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.95574ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.015214ms)
    Nov 29 12:04:08.861: INFO: (10) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.774499ms)
    Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.347719ms)
    Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.32233ms)
    Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.266405ms)
    Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.215432ms)
    Nov 29 12:04:08.863: INFO: (10) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.556255ms)
    Nov 29 12:04:08.867: INFO: (11) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 3.943446ms)
    Nov 29 12:04:08.867: INFO: (11) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.07708ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.634961ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.611555ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.682834ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 4.766013ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 4.791033ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 4.850602ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 4.771797ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.788282ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 5.100543ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.096974ms)
    Nov 29 12:04:08.868: INFO: (11) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.052178ms)
    Nov 29 12:04:08.869: INFO: (11) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 5.899811ms)
    Nov 29 12:04:08.870: INFO: (11) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 6.256111ms)
    Nov 29 12:04:08.870: INFO: (11) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 6.341753ms)
    Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 3.582926ms)
    Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 3.68415ms)
    Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 3.82565ms)
    Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 4.599341ms)
    Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.277832ms)
    Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.301117ms)
    Nov 29 12:04:08.874: INFO: (12) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 4.234803ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 4.448628ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.889491ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.010777ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 4.889277ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 4.954395ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 5.002396ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 4.657379ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.381192ms)
    Nov 29 12:04:08.875: INFO: (12) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.712491ms)
    Nov 29 12:04:08.880: INFO: (13) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.737621ms)
    Nov 29 12:04:08.880: INFO: (13) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.861154ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.091235ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.796757ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.165827ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.188716ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.169608ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.322109ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.363573ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.568665ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 5.548431ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 5.462853ms)
    Nov 29 12:04:08.881: INFO: (13) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 5.646742ms)
    Nov 29 12:04:08.883: INFO: (13) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 6.975744ms)
    Nov 29 12:04:08.883: INFO: (13) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.040511ms)
    Nov 29 12:04:08.883: INFO: (13) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.133811ms)
    Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 4.311086ms)
    Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.113722ms)
    Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.27484ms)
    Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 4.196557ms)
    Nov 29 12:04:08.887: INFO: (14) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.355453ms)
    Nov 29 12:04:08.888: INFO: (14) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.611462ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 51.289914ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 51.399438ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 51.419045ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 51.20904ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 51.159991ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 51.259298ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 51.283854ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 51.300483ms)
    Nov 29 12:04:08.934: INFO: (14) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 51.518862ms)
    Nov 29 12:04:08.937: INFO: (14) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 53.874056ms)
    Nov 29 12:04:08.942: INFO: (15) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.939251ms)
    Nov 29 12:04:08.942: INFO: (15) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.363815ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.326385ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.536698ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.614953ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.977142ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.826508ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.751104ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.875217ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 6.050231ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 5.917474ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 6.017091ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 6.018761ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 6.274827ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 6.239163ms)
    Nov 29 12:04:08.943: INFO: (15) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 6.429372ms)
    Nov 29 12:04:08.947: INFO: (16) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 3.816205ms)
    Nov 29 12:04:08.948: INFO: (16) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.235749ms)
    Nov 29 12:04:08.948: INFO: (16) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.227173ms)
    Nov 29 12:04:08.948: INFO: (16) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 4.413182ms)
    Nov 29 12:04:08.948: INFO: (16) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 4.699777ms)
    Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.030733ms)
    Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.945439ms)
    Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.360707ms)
    Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.495692ms)
    Nov 29 12:04:08.949: INFO: (16) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 5.356361ms)
    Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.445923ms)
    Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.697216ms)
    Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.653825ms)
    Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.908675ms)
    Nov 29 12:04:08.951: INFO: (16) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 8.030758ms)
    Nov 29 12:04:08.952: INFO: (16) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.996945ms)
    Nov 29 12:04:08.958: INFO: (17) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.295078ms)
    Nov 29 12:04:08.958: INFO: (17) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.304194ms)
    Nov 29 12:04:08.958: INFO: (17) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 5.50045ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 6.435021ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.618223ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 6.746592ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 6.925849ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 6.963817ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 6.922764ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 6.762719ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 6.794052ms)
    Nov 29 12:04:08.959: INFO: (17) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.261331ms)
    Nov 29 12:04:08.960: INFO: (17) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 7.381655ms)
    Nov 29 12:04:08.960: INFO: (17) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 7.294897ms)
    Nov 29 12:04:08.960: INFO: (17) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.338317ms)
    Nov 29 12:04:08.960: INFO: (17) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.687717ms)
    Nov 29 12:04:08.965: INFO: (18) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.635101ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.911609ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 5.060872ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 5.040795ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.037016ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 5.399687ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 5.376539ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 5.430417ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 5.672166ms)
    Nov 29 12:04:08.966: INFO: (18) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 5.487007ms)
    Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 7.135388ms)
    Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 7.885296ms)
    Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 7.76179ms)
    Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 7.949992ms)
    Nov 29 12:04:08.968: INFO: (18) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 8.026555ms)
    Nov 29 12:04:08.969: INFO: (18) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 8.25524ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:1080/proxy/rewriteme">... (200; 3.864149ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z/proxy/rewriteme">test</a> (200; 3.94794ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:1080/proxy/rewriteme">test<... (200; 4.01469ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.273612ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.147816ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/: <a href="/api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:443/proxy/tlsrewritem... (200; 4.179692ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/http:proxy-service-w72kh-46d5z:162/proxy/: bar (200; 4.275369ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:460/proxy/: tls baz (200; 4.35029ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/proxy-service-w72kh-46d5z:160/proxy/: foo (200; 4.42256ms)
    Nov 29 12:04:08.973: INFO: (19) /api/v1/namespaces/proxy-1928/pods/https:proxy-service-w72kh-46d5z:462/proxy/: tls qux (200; 4.343816ms)
    Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname1/proxy/: foo (200; 6.152869ms)
    Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/proxy-service-w72kh:portname2/proxy/: bar (200; 6.505478ms)
    Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname1/proxy/: foo (200; 6.243486ms)
    Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/http:proxy-service-w72kh:portname2/proxy/: bar (200; 6.363856ms)
    Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname2/proxy/: tls qux (200; 6.425052ms)
    Nov 29 12:04:08.975: INFO: (19) /api/v1/namespaces/proxy-1928/services/https:proxy-service-w72kh:tlsportname1/proxy/: tls baz (200; 6.562623ms)
    STEP: deleting ReplicationController proxy-service-w72kh in namespace proxy-1928, will wait for the garbage collector to delete the pods 11/29/22 12:04:08.975
    Nov 29 12:04:09.032: INFO: Deleting ReplicationController proxy-service-w72kh took: 4.548348ms
    Nov 29 12:04:09.133: INFO: Terminating ReplicationController proxy-service-w72kh pods took: 100.28927ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 29 12:04:10.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1928" for this suite. 11/29/22 12:04:10.942
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:10.954
Nov 29 12:04:10.954: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-lifecycle-hook 11/29/22 12:04:10.955
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:10.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:10.972
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/29/22 12:04:10.979
Nov 29 12:04:10.984: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3244" to be "running and ready"
Nov 29 12:04:10.986: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115502ms
Nov 29 12:04:10.986: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:04:12.989: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.005120255s
Nov 29 12:04:12.989: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 29 12:04:12.989: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 11/29/22 12:04:12.991
Nov 29 12:04:12.994: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-3244" to be "running and ready"
Nov 29 12:04:12.998: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.266046ms
Nov 29 12:04:12.998: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:04:15.001: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.007011546s
Nov 29 12:04:15.002: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Nov 29 12:04:15.002: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/29/22 12:04:15.003
STEP: delete the pod with lifecycle hook 11/29/22 12:04:15.007
Nov 29 12:04:15.011: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 29 12:04:15.013: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 29 12:04:17.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 29 12:04:17.017: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 29 12:04:17.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3244" for this suite. 11/29/22 12:04:17.02
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":137,"skipped":2680,"failed":0}
------------------------------
• [SLOW TEST] [6.069 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:10.954
    Nov 29 12:04:10.954: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/29/22 12:04:10.955
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:10.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:10.972
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/29/22 12:04:10.979
    Nov 29 12:04:10.984: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3244" to be "running and ready"
    Nov 29 12:04:10.986: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115502ms
    Nov 29 12:04:10.986: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:04:12.989: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.005120255s
    Nov 29 12:04:12.989: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 29 12:04:12.989: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 11/29/22 12:04:12.991
    Nov 29 12:04:12.994: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-3244" to be "running and ready"
    Nov 29 12:04:12.998: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.266046ms
    Nov 29 12:04:12.998: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:04:15.001: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.007011546s
    Nov 29 12:04:15.002: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Nov 29 12:04:15.002: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/29/22 12:04:15.003
    STEP: delete the pod with lifecycle hook 11/29/22 12:04:15.007
    Nov 29 12:04:15.011: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 29 12:04:15.013: INFO: Pod pod-with-poststart-exec-hook still exists
    Nov 29 12:04:17.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 29 12:04:17.017: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 29 12:04:17.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3244" for this suite. 11/29/22 12:04:17.02
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:17.023
Nov 29 12:04:17.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 12:04:17.023
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:17.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:17.031
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 11/29/22 12:04:17.033
STEP: setting up watch 11/29/22 12:04:17.034
STEP: submitting the pod to kubernetes 11/29/22 12:04:17.136
STEP: verifying the pod is in kubernetes 11/29/22 12:04:17.141
STEP: verifying pod creation was observed 11/29/22 12:04:17.144
Nov 29 12:04:17.144: INFO: Waiting up to 5m0s for pod "pod-submit-remove-95f526a0-1b8d-4543-ab17-9dea9ac93c62" in namespace "pods-7083" to be "running"
Nov 29 12:04:17.146: INFO: Pod "pod-submit-remove-95f526a0-1b8d-4543-ab17-9dea9ac93c62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.676104ms
Nov 29 12:04:19.150: INFO: Pod "pod-submit-remove-95f526a0-1b8d-4543-ab17-9dea9ac93c62": Phase="Running", Reason="", readiness=true. Elapsed: 2.006822882s
Nov 29 12:04:19.150: INFO: Pod "pod-submit-remove-95f526a0-1b8d-4543-ab17-9dea9ac93c62" satisfied condition "running"
STEP: deleting the pod gracefully 11/29/22 12:04:19.153
STEP: verifying pod deletion was observed 11/29/22 12:04:19.174
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 12:04:21.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7083" for this suite. 11/29/22 12:04:21.961
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":138,"skipped":2681,"failed":0}
------------------------------
• [4.942 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:17.023
    Nov 29 12:04:17.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 12:04:17.023
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:17.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:17.031
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 11/29/22 12:04:17.033
    STEP: setting up watch 11/29/22 12:04:17.034
    STEP: submitting the pod to kubernetes 11/29/22 12:04:17.136
    STEP: verifying the pod is in kubernetes 11/29/22 12:04:17.141
    STEP: verifying pod creation was observed 11/29/22 12:04:17.144
    Nov 29 12:04:17.144: INFO: Waiting up to 5m0s for pod "pod-submit-remove-95f526a0-1b8d-4543-ab17-9dea9ac93c62" in namespace "pods-7083" to be "running"
    Nov 29 12:04:17.146: INFO: Pod "pod-submit-remove-95f526a0-1b8d-4543-ab17-9dea9ac93c62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.676104ms
    Nov 29 12:04:19.150: INFO: Pod "pod-submit-remove-95f526a0-1b8d-4543-ab17-9dea9ac93c62": Phase="Running", Reason="", readiness=true. Elapsed: 2.006822882s
    Nov 29 12:04:19.150: INFO: Pod "pod-submit-remove-95f526a0-1b8d-4543-ab17-9dea9ac93c62" satisfied condition "running"
    STEP: deleting the pod gracefully 11/29/22 12:04:19.153
    STEP: verifying pod deletion was observed 11/29/22 12:04:19.174
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 12:04:21.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7083" for this suite. 11/29/22 12:04:21.961
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:21.965
Nov 29 12:04:21.966: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 12:04:21.966
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:21.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:21.982
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Nov 29 12:04:21.985: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:04:28.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1874" for this suite. 11/29/22 12:04:28.365
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":139,"skipped":2688,"failed":0}
------------------------------
• [SLOW TEST] [6.403 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:21.965
    Nov 29 12:04:21.966: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 12:04:21.966
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:21.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:21.982
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Nov 29 12:04:21.985: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:04:28.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1874" for this suite. 11/29/22 12:04:28.365
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:28.368
Nov 29 12:04:28.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-runtime 11/29/22 12:04:28.369
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:28.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:28.383
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 11/29/22 12:04:28.387
STEP: wait for the container to reach Failed 11/29/22 12:04:28.393
STEP: get the container status 11/29/22 12:04:32.416
STEP: the container should be terminated 11/29/22 12:04:32.418
STEP: the termination message should be set 11/29/22 12:04:32.418
Nov 29 12:04:32.418: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/29/22 12:04:32.418
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 29 12:04:32.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-852" for this suite. 11/29/22 12:04:32.427
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":140,"skipped":2691,"failed":0}
------------------------------
• [4.062 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:28.368
    Nov 29 12:04:28.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-runtime 11/29/22 12:04:28.369
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:28.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:28.383
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 11/29/22 12:04:28.387
    STEP: wait for the container to reach Failed 11/29/22 12:04:28.393
    STEP: get the container status 11/29/22 12:04:32.416
    STEP: the container should be terminated 11/29/22 12:04:32.418
    STEP: the termination message should be set 11/29/22 12:04:32.418
    Nov 29 12:04:32.418: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/29/22 12:04:32.418
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 29 12:04:32.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-852" for this suite. 11/29/22 12:04:32.427
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:32.433
Nov 29 12:04:32.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename endpointslice 11/29/22 12:04:32.433
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:32.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:32.443
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 29 12:04:34.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6164" for this suite. 11/29/22 12:04:34.49
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":141,"skipped":2729,"failed":0}
------------------------------
• [2.061 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:32.433
    Nov 29 12:04:32.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename endpointslice 11/29/22 12:04:32.433
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:32.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:32.443
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 29 12:04:34.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6164" for this suite. 11/29/22 12:04:34.49
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:34.494
Nov 29 12:04:34.494: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename containers 11/29/22 12:04:34.495
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:34.504
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:34.507
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 11/29/22 12:04:34.509
Nov 29 12:04:34.514: INFO: Waiting up to 5m0s for pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09" in namespace "containers-2664" to be "Succeeded or Failed"
Nov 29 12:04:34.518: INFO: Pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090394ms
Nov 29 12:04:36.522: INFO: Pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008554629s
Nov 29 12:04:38.521: INFO: Pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007146286s
STEP: Saw pod success 11/29/22 12:04:38.521
Nov 29 12:04:38.521: INFO: Pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09" satisfied condition "Succeeded or Failed"
Nov 29 12:04:38.523: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:04:38.526
Nov 29 12:04:38.532: INFO: Waiting for pod client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09 to disappear
Nov 29 12:04:38.533: INFO: Pod client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 29 12:04:38.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2664" for this suite. 11/29/22 12:04:38.536
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":142,"skipped":2731,"failed":0}
------------------------------
• [4.045 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:34.494
    Nov 29 12:04:34.494: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename containers 11/29/22 12:04:34.495
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:34.504
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:34.507
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 11/29/22 12:04:34.509
    Nov 29 12:04:34.514: INFO: Waiting up to 5m0s for pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09" in namespace "containers-2664" to be "Succeeded or Failed"
    Nov 29 12:04:34.518: INFO: Pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090394ms
    Nov 29 12:04:36.522: INFO: Pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008554629s
    Nov 29 12:04:38.521: INFO: Pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007146286s
    STEP: Saw pod success 11/29/22 12:04:38.521
    Nov 29 12:04:38.521: INFO: Pod "client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09" satisfied condition "Succeeded or Failed"
    Nov 29 12:04:38.523: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:04:38.526
    Nov 29 12:04:38.532: INFO: Waiting for pod client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09 to disappear
    Nov 29 12:04:38.533: INFO: Pod client-containers-712ecf2d-e49d-4204-9f19-ebe4ade95e09 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 29 12:04:38.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-2664" for this suite. 11/29/22 12:04:38.536
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:38.54
Nov 29 12:04:38.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-runtime 11/29/22 12:04:38.541
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:38.548
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:38.55
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 11/29/22 12:04:38.552
STEP: wait for the container to reach Succeeded 11/29/22 12:04:38.556
STEP: get the container status 11/29/22 12:04:42.569
STEP: the container should be terminated 11/29/22 12:04:42.572
STEP: the termination message should be set 11/29/22 12:04:42.572
Nov 29 12:04:42.572: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 11/29/22 12:04:42.572
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 29 12:04:42.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4027" for this suite. 11/29/22 12:04:42.587
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":143,"skipped":2740,"failed":0}
------------------------------
• [4.051 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:38.54
    Nov 29 12:04:38.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-runtime 11/29/22 12:04:38.541
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:38.548
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:38.55
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 11/29/22 12:04:38.552
    STEP: wait for the container to reach Succeeded 11/29/22 12:04:38.556
    STEP: get the container status 11/29/22 12:04:42.569
    STEP: the container should be terminated 11/29/22 12:04:42.572
    STEP: the termination message should be set 11/29/22 12:04:42.572
    Nov 29 12:04:42.572: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 11/29/22 12:04:42.572
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 29 12:04:42.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4027" for this suite. 11/29/22 12:04:42.587
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:42.595
Nov 29 12:04:42.595: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:04:42.597
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:42.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:42.607
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:04:42.609
Nov 29 12:04:42.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288" in namespace "projected-7280" to be "Succeeded or Failed"
Nov 29 12:04:42.616: INFO: Pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288": Phase="Pending", Reason="", readiness=false. Elapsed: 1.754576ms
Nov 29 12:04:44.619: INFO: Pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004878022s
Nov 29 12:04:46.620: INFO: Pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005893241s
STEP: Saw pod success 11/29/22 12:04:46.62
Nov 29 12:04:46.620: INFO: Pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288" satisfied condition "Succeeded or Failed"
Nov 29 12:04:46.622: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288 container client-container: <nil>
STEP: delete the pod 11/29/22 12:04:46.626
Nov 29 12:04:46.637: INFO: Waiting for pod downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288 to disappear
Nov 29 12:04:46.639: INFO: Pod downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 12:04:46.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7280" for this suite. 11/29/22 12:04:46.642
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":144,"skipped":2766,"failed":0}
------------------------------
• [4.050 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:42.595
    Nov 29 12:04:42.595: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:04:42.597
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:42.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:42.607
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:04:42.609
    Nov 29 12:04:42.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288" in namespace "projected-7280" to be "Succeeded or Failed"
    Nov 29 12:04:42.616: INFO: Pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288": Phase="Pending", Reason="", readiness=false. Elapsed: 1.754576ms
    Nov 29 12:04:44.619: INFO: Pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004878022s
    Nov 29 12:04:46.620: INFO: Pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005893241s
    STEP: Saw pod success 11/29/22 12:04:46.62
    Nov 29 12:04:46.620: INFO: Pod "downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288" satisfied condition "Succeeded or Failed"
    Nov 29 12:04:46.622: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:04:46.626
    Nov 29 12:04:46.637: INFO: Waiting for pod downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288 to disappear
    Nov 29 12:04:46.639: INFO: Pod downwardapi-volume-901eee40-470a-4937-95a1-0c63c82a6288 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 12:04:46.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7280" for this suite. 11/29/22 12:04:46.642
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:46.646
Nov 29 12:04:46.646: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:04:46.647
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:46.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:46.656
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-12c28d16-5596-4657-8c32-2c07aac83159 11/29/22 12:04:46.658
STEP: Creating a pod to test consume secrets 11/29/22 12:04:46.66
Nov 29 12:04:46.664: INFO: Waiting up to 5m0s for pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757" in namespace "secrets-5319" to be "Succeeded or Failed"
Nov 29 12:04:46.667: INFO: Pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757": Phase="Pending", Reason="", readiness=false. Elapsed: 3.137983ms
Nov 29 12:04:48.669: INFO: Pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005755528s
Nov 29 12:04:50.671: INFO: Pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007049611s
STEP: Saw pod success 11/29/22 12:04:50.671
Nov 29 12:04:50.671: INFO: Pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757" satisfied condition "Succeeded or Failed"
Nov 29 12:04:50.673: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757 container secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:04:50.677
Nov 29 12:04:50.692: INFO: Waiting for pod pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757 to disappear
Nov 29 12:04:50.694: INFO: Pod pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:04:50.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5319" for this suite. 11/29/22 12:04:50.697
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":145,"skipped":2786,"failed":0}
------------------------------
• [4.055 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:46.646
    Nov 29 12:04:46.646: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:04:46.647
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:46.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:46.656
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-12c28d16-5596-4657-8c32-2c07aac83159 11/29/22 12:04:46.658
    STEP: Creating a pod to test consume secrets 11/29/22 12:04:46.66
    Nov 29 12:04:46.664: INFO: Waiting up to 5m0s for pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757" in namespace "secrets-5319" to be "Succeeded or Failed"
    Nov 29 12:04:46.667: INFO: Pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757": Phase="Pending", Reason="", readiness=false. Elapsed: 3.137983ms
    Nov 29 12:04:48.669: INFO: Pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005755528s
    Nov 29 12:04:50.671: INFO: Pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007049611s
    STEP: Saw pod success 11/29/22 12:04:50.671
    Nov 29 12:04:50.671: INFO: Pod "pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757" satisfied condition "Succeeded or Failed"
    Nov 29 12:04:50.673: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757 container secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:04:50.677
    Nov 29 12:04:50.692: INFO: Waiting for pod pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757 to disappear
    Nov 29 12:04:50.694: INFO: Pod pod-secrets-8c64924c-97dc-4c5c-8501-ea2079378757 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:04:50.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5319" for this suite. 11/29/22 12:04:50.697
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:50.7
Nov 29 12:04:50.700: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:04:50.701
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:50.709
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:50.712
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 11/29/22 12:04:50.714
STEP: listing secrets in all namespaces to ensure that there are more than zero 11/29/22 12:04:50.716
STEP: patching the secret 11/29/22 12:04:50.718
STEP: deleting the secret using a LabelSelector 11/29/22 12:04:50.723
STEP: listing secrets in all namespaces, searching for label name and value in patch 11/29/22 12:04:50.726
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:04:50.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-649" for this suite. 11/29/22 12:04:50.73
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":146,"skipped":2790,"failed":0}
------------------------------
• [0.032 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:50.7
    Nov 29 12:04:50.700: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:04:50.701
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:50.709
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:50.712
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 11/29/22 12:04:50.714
    STEP: listing secrets in all namespaces to ensure that there are more than zero 11/29/22 12:04:50.716
    STEP: patching the secret 11/29/22 12:04:50.718
    STEP: deleting the secret using a LabelSelector 11/29/22 12:04:50.723
    STEP: listing secrets in all namespaces, searching for label name and value in patch 11/29/22 12:04:50.726
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:04:50.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-649" for this suite. 11/29/22 12:04:50.73
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:50.733
Nov 29 12:04:50.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:04:50.734
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:50.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:50.742
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-21436a5b-a8ce-4b29-b606-d268e8dbff7d 11/29/22 12:04:50.747
STEP: Creating a pod to test consume configMaps 11/29/22 12:04:50.75
Nov 29 12:04:50.754: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15" in namespace "projected-8364" to be "Succeeded or Failed"
Nov 29 12:04:50.758: INFO: Pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15": Phase="Pending", Reason="", readiness=false. Elapsed: 3.637562ms
Nov 29 12:04:52.761: INFO: Pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006524993s
Nov 29 12:04:54.762: INFO: Pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008125696s
STEP: Saw pod success 11/29/22 12:04:54.762
Nov 29 12:04:54.763: INFO: Pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15" satisfied condition "Succeeded or Failed"
Nov 29 12:04:54.766: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:04:54.771
Nov 29 12:04:54.781: INFO: Waiting for pod pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15 to disappear
Nov 29 12:04:54.784: INFO: Pod pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 12:04:54.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8364" for this suite. 11/29/22 12:04:54.788
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":147,"skipped":2791,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:50.733
    Nov 29 12:04:50.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:04:50.734
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:50.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:50.742
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-21436a5b-a8ce-4b29-b606-d268e8dbff7d 11/29/22 12:04:50.747
    STEP: Creating a pod to test consume configMaps 11/29/22 12:04:50.75
    Nov 29 12:04:50.754: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15" in namespace "projected-8364" to be "Succeeded or Failed"
    Nov 29 12:04:50.758: INFO: Pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15": Phase="Pending", Reason="", readiness=false. Elapsed: 3.637562ms
    Nov 29 12:04:52.761: INFO: Pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006524993s
    Nov 29 12:04:54.762: INFO: Pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008125696s
    STEP: Saw pod success 11/29/22 12:04:54.762
    Nov 29 12:04:54.763: INFO: Pod "pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15" satisfied condition "Succeeded or Failed"
    Nov 29 12:04:54.766: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:04:54.771
    Nov 29 12:04:54.781: INFO: Waiting for pod pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15 to disappear
    Nov 29 12:04:54.784: INFO: Pod pod-projected-configmaps-9f56ca86-95ff-4f98-8077-378abdd7da15 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 12:04:54.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8364" for this suite. 11/29/22 12:04:54.788
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:54.798
Nov 29 12:04:54.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replicaset 11/29/22 12:04:54.799
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:54.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:54.812
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/29/22 12:04:54.814
Nov 29 12:04:54.819: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-1956" to be "running and ready"
Nov 29 12:04:54.821: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 1.945158ms
Nov 29 12:04:54.821: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:04:56.824: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.004522501s
Nov 29 12:04:56.824: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Nov 29 12:04:56.824: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 11/29/22 12:04:56.826
STEP: Then the orphan pod is adopted 11/29/22 12:04:56.828
STEP: When the matched label of one of its pods change 11/29/22 12:04:57.843
Nov 29 12:04:57.845: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 11/29/22 12:04:57.851
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 29 12:04:58.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1956" for this suite. 11/29/22 12:04:58.86
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":148,"skipped":2791,"failed":0}
------------------------------
• [4.065 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:54.798
    Nov 29 12:04:54.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replicaset 11/29/22 12:04:54.799
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:54.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:54.812
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/29/22 12:04:54.814
    Nov 29 12:04:54.819: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-1956" to be "running and ready"
    Nov 29 12:04:54.821: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 1.945158ms
    Nov 29 12:04:54.821: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:04:56.824: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.004522501s
    Nov 29 12:04:56.824: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Nov 29 12:04:56.824: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 11/29/22 12:04:56.826
    STEP: Then the orphan pod is adopted 11/29/22 12:04:56.828
    STEP: When the matched label of one of its pods change 11/29/22 12:04:57.843
    Nov 29 12:04:57.845: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/29/22 12:04:57.851
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 29 12:04:58.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1956" for this suite. 11/29/22 12:04:58.86
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:58.863
Nov 29 12:04:58.863: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename gc 11/29/22 12:04:58.864
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:58.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:58.881
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 11/29/22 12:04:58.883
STEP: Wait for the Deployment to create new ReplicaSet 11/29/22 12:04:58.886
STEP: delete the deployment 11/29/22 12:04:59.392
STEP: wait for all rs to be garbage collected 11/29/22 12:04:59.397
STEP: expected 0 rs, got 1 rs 11/29/22 12:04:59.401
STEP: expected 0 pods, got 2 pods 11/29/22 12:04:59.403
STEP: Gathering metrics 11/29/22 12:04:59.909
W1129 12:04:59.918018      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 29 12:04:59.918: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 29 12:04:59.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4776" for this suite. 11/29/22 12:04:59.921
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":149,"skipped":2793,"failed":0}
------------------------------
• [1.061 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:58.863
    Nov 29 12:04:58.863: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename gc 11/29/22 12:04:58.864
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:58.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:58.881
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 11/29/22 12:04:58.883
    STEP: Wait for the Deployment to create new ReplicaSet 11/29/22 12:04:58.886
    STEP: delete the deployment 11/29/22 12:04:59.392
    STEP: wait for all rs to be garbage collected 11/29/22 12:04:59.397
    STEP: expected 0 rs, got 1 rs 11/29/22 12:04:59.401
    STEP: expected 0 pods, got 2 pods 11/29/22 12:04:59.403
    STEP: Gathering metrics 11/29/22 12:04:59.909
    W1129 12:04:59.918018      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 29 12:04:59.918: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 29 12:04:59.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4776" for this suite. 11/29/22 12:04:59.921
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:04:59.924
Nov 29 12:04:59.925: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:04:59.925
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:59.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:59.939
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 11/29/22 12:04:59.941
Nov 29 12:04:59.947: INFO: Waiting up to 5m0s for pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce" in namespace "downward-api-6687" to be "Succeeded or Failed"
Nov 29 12:04:59.950: INFO: Pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.977877ms
Nov 29 12:05:01.954: INFO: Pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006450183s
Nov 29 12:05:03.953: INFO: Pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005319311s
STEP: Saw pod success 11/29/22 12:05:03.953
Nov 29 12:05:03.953: INFO: Pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce" satisfied condition "Succeeded or Failed"
Nov 29 12:05:03.957: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce container dapi-container: <nil>
STEP: delete the pod 11/29/22 12:05:03.975
Nov 29 12:05:03.995: INFO: Waiting for pod downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce to disappear
Nov 29 12:05:04.002: INFO: Pod downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 29 12:05:04.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6687" for this suite. 11/29/22 12:05:04.005
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":150,"skipped":2793,"failed":0}
------------------------------
• [4.084 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:04:59.924
    Nov 29 12:04:59.925: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:04:59.925
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:04:59.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:04:59.939
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 11/29/22 12:04:59.941
    Nov 29 12:04:59.947: INFO: Waiting up to 5m0s for pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce" in namespace "downward-api-6687" to be "Succeeded or Failed"
    Nov 29 12:04:59.950: INFO: Pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.977877ms
    Nov 29 12:05:01.954: INFO: Pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006450183s
    Nov 29 12:05:03.953: INFO: Pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005319311s
    STEP: Saw pod success 11/29/22 12:05:03.953
    Nov 29 12:05:03.953: INFO: Pod "downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce" satisfied condition "Succeeded or Failed"
    Nov 29 12:05:03.957: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce container dapi-container: <nil>
    STEP: delete the pod 11/29/22 12:05:03.975
    Nov 29 12:05:03.995: INFO: Waiting for pod downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce to disappear
    Nov 29 12:05:04.002: INFO: Pod downward-api-9d92d8c8-12eb-46a8-ab99-c1e12032dbce no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 29 12:05:04.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6687" for this suite. 11/29/22 12:05:04.005
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:05:04.008
Nov 29 12:05:04.009: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 12:05:04.009
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:04.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:04.024
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Nov 29 12:05:04.027: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/29/22 12:05:08.34
Nov 29 12:05:08.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 --namespace=crd-publish-openapi-4235 create -f -'
Nov 29 12:05:09.192: INFO: stderr: ""
Nov 29 12:05:09.192: INFO: stdout: "e2e-test-crd-publish-openapi-837-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 29 12:05:09.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 --namespace=crd-publish-openapi-4235 delete e2e-test-crd-publish-openapi-837-crds test-cr'
Nov 29 12:05:09.259: INFO: stderr: ""
Nov 29 12:05:09.259: INFO: stdout: "e2e-test-crd-publish-openapi-837-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov 29 12:05:09.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 --namespace=crd-publish-openapi-4235 apply -f -'
Nov 29 12:05:09.541: INFO: stderr: ""
Nov 29 12:05:09.541: INFO: stdout: "e2e-test-crd-publish-openapi-837-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 29 12:05:09.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 --namespace=crd-publish-openapi-4235 delete e2e-test-crd-publish-openapi-837-crds test-cr'
Nov 29 12:05:09.610: INFO: stderr: ""
Nov 29 12:05:09.610: INFO: stdout: "e2e-test-crd-publish-openapi-837-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 11/29/22 12:05:09.61
Nov 29 12:05:09.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 explain e2e-test-crd-publish-openapi-837-crds'
Nov 29 12:05:09.891: INFO: stderr: ""
Nov 29 12:05:09.891: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-837-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:05:13.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4235" for this suite. 11/29/22 12:05:13.178
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":151,"skipped":2796,"failed":0}
------------------------------
• [SLOW TEST] [9.181 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:05:04.008
    Nov 29 12:05:04.009: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 12:05:04.009
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:04.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:04.024
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Nov 29 12:05:04.027: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/29/22 12:05:08.34
    Nov 29 12:05:08.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 --namespace=crd-publish-openapi-4235 create -f -'
    Nov 29 12:05:09.192: INFO: stderr: ""
    Nov 29 12:05:09.192: INFO: stdout: "e2e-test-crd-publish-openapi-837-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov 29 12:05:09.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 --namespace=crd-publish-openapi-4235 delete e2e-test-crd-publish-openapi-837-crds test-cr'
    Nov 29 12:05:09.259: INFO: stderr: ""
    Nov 29 12:05:09.259: INFO: stdout: "e2e-test-crd-publish-openapi-837-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Nov 29 12:05:09.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 --namespace=crd-publish-openapi-4235 apply -f -'
    Nov 29 12:05:09.541: INFO: stderr: ""
    Nov 29 12:05:09.541: INFO: stdout: "e2e-test-crd-publish-openapi-837-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov 29 12:05:09.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 --namespace=crd-publish-openapi-4235 delete e2e-test-crd-publish-openapi-837-crds test-cr'
    Nov 29 12:05:09.610: INFO: stderr: ""
    Nov 29 12:05:09.610: INFO: stdout: "e2e-test-crd-publish-openapi-837-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 11/29/22 12:05:09.61
    Nov 29 12:05:09.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=crd-publish-openapi-4235 explain e2e-test-crd-publish-openapi-837-crds'
    Nov 29 12:05:09.891: INFO: stderr: ""
    Nov 29 12:05:09.891: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-837-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:05:13.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4235" for this suite. 11/29/22 12:05:13.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:05:13.191
Nov 29 12:05:13.191: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:05:13.192
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:13.2
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:13.204
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:05:13.214
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:05:14.075
STEP: Deploying the webhook pod 11/29/22 12:05:14.144
STEP: Wait for the deployment to be ready 11/29/22 12:05:14.161
Nov 29 12:05:14.168: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:05:16.176
STEP: Verifying the service has paired with the endpoint 11/29/22 12:05:16.182
Nov 29 12:05:17.182: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 11/29/22 12:05:17.215
STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:05:17.245
STEP: Deleting the collection of validation webhooks 11/29/22 12:05:17.47
STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:05:17.486
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:05:17.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6276" for this suite. 11/29/22 12:05:17.494
STEP: Destroying namespace "webhook-6276-markers" for this suite. 11/29/22 12:05:17.497
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":152,"skipped":2813,"failed":0}
------------------------------
• [4.329 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:05:13.191
    Nov 29 12:05:13.191: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:05:13.192
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:13.2
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:13.204
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:05:13.214
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:05:14.075
    STEP: Deploying the webhook pod 11/29/22 12:05:14.144
    STEP: Wait for the deployment to be ready 11/29/22 12:05:14.161
    Nov 29 12:05:14.168: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:05:16.176
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:05:16.182
    Nov 29 12:05:17.182: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 11/29/22 12:05:17.215
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:05:17.245
    STEP: Deleting the collection of validation webhooks 11/29/22 12:05:17.47
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:05:17.486
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:05:17.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6276" for this suite. 11/29/22 12:05:17.494
    STEP: Destroying namespace "webhook-6276-markers" for this suite. 11/29/22 12:05:17.497
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:05:17.523
Nov 29 12:05:17.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 12:05:17.524
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:17.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:17.552
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 11/29/22 12:05:17.555
Nov 29 12:05:17.560: INFO: created test-pod-1
Nov 29 12:05:17.565: INFO: created test-pod-2
Nov 29 12:05:17.569: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 11/29/22 12:05:17.569
Nov 29 12:05:17.570: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-4972' to be running and ready
Nov 29 12:05:17.578: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 29 12:05:17.578: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 29 12:05:17.578: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 29 12:05:17.578: INFO: 0 / 3 pods in namespace 'pods-4972' are running and ready (0 seconds elapsed)
Nov 29 12:05:17.578: INFO: expected 0 pod replicas in namespace 'pods-4972', 0 are Running and Ready.
Nov 29 12:05:17.578: INFO: POD         NODE                               PHASE    GRACE  CONDITIONS
Nov 29 12:05:17.578: INFO: test-pod-1  dvi-7336-1669718118-vsp1-group1-2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC  }]
Nov 29 12:05:17.578: INFO: test-pod-2  dvi-7336-1669718118-vsp1-group1-2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC  }]
Nov 29 12:05:17.578: INFO: test-pod-3  dvi-7336-1669718118-vsp1-group1-0  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC  }]
Nov 29 12:05:17.578: INFO: 
Nov 29 12:05:19.589: INFO: 3 / 3 pods in namespace 'pods-4972' are running and ready (2 seconds elapsed)
Nov 29 12:05:19.589: INFO: expected 0 pod replicas in namespace 'pods-4972', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 11/29/22 12:05:19.612
Nov 29 12:05:19.615: INFO: Pod quantity 3 is different from expected quantity 0
Nov 29 12:05:20.618: INFO: Pod quantity 3 is different from expected quantity 0
Nov 29 12:05:21.619: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 12:05:22.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4972" for this suite. 11/29/22 12:05:22.622
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":153,"skipped":2857,"failed":0}
------------------------------
• [SLOW TEST] [5.113 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:05:17.523
    Nov 29 12:05:17.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 12:05:17.524
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:17.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:17.552
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 11/29/22 12:05:17.555
    Nov 29 12:05:17.560: INFO: created test-pod-1
    Nov 29 12:05:17.565: INFO: created test-pod-2
    Nov 29 12:05:17.569: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 11/29/22 12:05:17.569
    Nov 29 12:05:17.570: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-4972' to be running and ready
    Nov 29 12:05:17.578: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 29 12:05:17.578: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 29 12:05:17.578: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 29 12:05:17.578: INFO: 0 / 3 pods in namespace 'pods-4972' are running and ready (0 seconds elapsed)
    Nov 29 12:05:17.578: INFO: expected 0 pod replicas in namespace 'pods-4972', 0 are Running and Ready.
    Nov 29 12:05:17.578: INFO: POD         NODE                               PHASE    GRACE  CONDITIONS
    Nov 29 12:05:17.578: INFO: test-pod-1  dvi-7336-1669718118-vsp1-group1-2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC  }]
    Nov 29 12:05:17.578: INFO: test-pod-2  dvi-7336-1669718118-vsp1-group1-2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC  }]
    Nov 29 12:05:17.578: INFO: test-pod-3  dvi-7336-1669718118-vsp1-group1-0  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:05:17 +0000 UTC  }]
    Nov 29 12:05:17.578: INFO: 
    Nov 29 12:05:19.589: INFO: 3 / 3 pods in namespace 'pods-4972' are running and ready (2 seconds elapsed)
    Nov 29 12:05:19.589: INFO: expected 0 pod replicas in namespace 'pods-4972', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 11/29/22 12:05:19.612
    Nov 29 12:05:19.615: INFO: Pod quantity 3 is different from expected quantity 0
    Nov 29 12:05:20.618: INFO: Pod quantity 3 is different from expected quantity 0
    Nov 29 12:05:21.619: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 12:05:22.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4972" for this suite. 11/29/22 12:05:22.622
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:05:22.637
Nov 29 12:05:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 12:05:22.638
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:22.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:22.649
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Nov 29 12:05:22.654: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: creating the pod 11/29/22 12:05:22.655
STEP: submitting the pod to kubernetes 11/29/22 12:05:22.655
Nov 29 12:05:22.659: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0" in namespace "pods-1748" to be "running and ready"
Nov 29 12:05:22.665: INFO: Pod "pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.790216ms
Nov 29 12:05:22.666: INFO: The phase of Pod pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:05:24.669: INFO: Pod "pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.010781282s
Nov 29 12:05:24.670: INFO: The phase of Pod pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0 is Running (Ready = true)
Nov 29 12:05:24.670: INFO: Pod "pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 12:05:24.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1748" for this suite. 11/29/22 12:05:24.746
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":154,"skipped":2865,"failed":0}
------------------------------
• [2.113 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:05:22.637
    Nov 29 12:05:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 12:05:22.638
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:22.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:22.649
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Nov 29 12:05:22.654: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: creating the pod 11/29/22 12:05:22.655
    STEP: submitting the pod to kubernetes 11/29/22 12:05:22.655
    Nov 29 12:05:22.659: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0" in namespace "pods-1748" to be "running and ready"
    Nov 29 12:05:22.665: INFO: Pod "pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.790216ms
    Nov 29 12:05:22.666: INFO: The phase of Pod pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:05:24.669: INFO: Pod "pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.010781282s
    Nov 29 12:05:24.670: INFO: The phase of Pod pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0 is Running (Ready = true)
    Nov 29 12:05:24.670: INFO: Pod "pod-exec-websocket-0f0a3adb-5f0d-4ee9-a6bf-2c7c3455e3d0" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 12:05:24.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1748" for this suite. 11/29/22 12:05:24.746
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:05:24.75
Nov 29 12:05:24.750: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replicaset 11/29/22 12:05:24.751
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:24.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:24.764
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Nov 29 12:05:24.776: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 29 12:05:29.785: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/29/22 12:05:29.785
STEP: Scaling up "test-rs" replicaset  11/29/22 12:05:29.785
Nov 29 12:05:29.792: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 11/29/22 12:05:29.792
W1129 12:05:29.796700      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 29 12:05:29.798: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 1, AvailableReplicas 1
Nov 29 12:05:29.813: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 1, AvailableReplicas 1
Nov 29 12:05:29.820: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 1, AvailableReplicas 1
Nov 29 12:05:29.825: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 1, AvailableReplicas 1
Nov 29 12:05:31.133: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 2, AvailableReplicas 2
Nov 29 12:05:31.193: INFO: observed Replicaset test-rs in namespace replicaset-7886 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 29 12:05:31.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7886" for this suite. 11/29/22 12:05:31.197
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":155,"skipped":2865,"failed":0}
------------------------------
• [SLOW TEST] [6.450 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:05:24.75
    Nov 29 12:05:24.750: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replicaset 11/29/22 12:05:24.751
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:24.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:24.764
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Nov 29 12:05:24.776: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 29 12:05:29.785: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/29/22 12:05:29.785
    STEP: Scaling up "test-rs" replicaset  11/29/22 12:05:29.785
    Nov 29 12:05:29.792: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 11/29/22 12:05:29.792
    W1129 12:05:29.796700      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 29 12:05:29.798: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 1, AvailableReplicas 1
    Nov 29 12:05:29.813: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 1, AvailableReplicas 1
    Nov 29 12:05:29.820: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 1, AvailableReplicas 1
    Nov 29 12:05:29.825: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 1, AvailableReplicas 1
    Nov 29 12:05:31.133: INFO: observed ReplicaSet test-rs in namespace replicaset-7886 with ReadyReplicas 2, AvailableReplicas 2
    Nov 29 12:05:31.193: INFO: observed Replicaset test-rs in namespace replicaset-7886 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 29 12:05:31.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7886" for this suite. 11/29/22 12:05:31.197
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:05:31.2
Nov 29 12:05:31.200: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:05:31.201
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:31.211
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:31.213
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 11/29/22 12:05:31.216
Nov 29 12:05:31.221: INFO: Waiting up to 5m0s for pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647" in namespace "downward-api-1739" to be "running and ready"
Nov 29 12:05:31.227: INFO: Pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647": Phase="Pending", Reason="", readiness=false. Elapsed: 5.954957ms
Nov 29 12:05:31.227: INFO: The phase of Pod annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:05:33.232: INFO: Pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647": Phase="Running", Reason="", readiness=true. Elapsed: 2.010877839s
Nov 29 12:05:33.232: INFO: The phase of Pod annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647 is Running (Ready = true)
Nov 29 12:05:33.232: INFO: Pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647" satisfied condition "running and ready"
Nov 29 12:05:33.747: INFO: Successfully updated pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:05:37.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1739" for this suite. 11/29/22 12:05:37.765
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":156,"skipped":2871,"failed":0}
------------------------------
• [SLOW TEST] [6.570 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:05:31.2
    Nov 29 12:05:31.200: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:05:31.201
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:31.211
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:31.213
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 11/29/22 12:05:31.216
    Nov 29 12:05:31.221: INFO: Waiting up to 5m0s for pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647" in namespace "downward-api-1739" to be "running and ready"
    Nov 29 12:05:31.227: INFO: Pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647": Phase="Pending", Reason="", readiness=false. Elapsed: 5.954957ms
    Nov 29 12:05:31.227: INFO: The phase of Pod annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:05:33.232: INFO: Pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647": Phase="Running", Reason="", readiness=true. Elapsed: 2.010877839s
    Nov 29 12:05:33.232: INFO: The phase of Pod annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647 is Running (Ready = true)
    Nov 29 12:05:33.232: INFO: Pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647" satisfied condition "running and ready"
    Nov 29 12:05:33.747: INFO: Successfully updated pod "annotationupdate1be55e87-212c-4975-a1f5-9cacb57f2647"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:05:37.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1739" for this suite. 11/29/22 12:05:37.765
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:05:37.771
Nov 29 12:05:37.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename dns 11/29/22 12:05:37.772
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:37.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:37.782
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 11/29/22 12:05:37.784
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local;sleep 1; done
 11/29/22 12:05:37.787
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local;sleep 1; done
 11/29/22 12:05:37.787
STEP: creating a pod to probe DNS 11/29/22 12:05:37.787
STEP: submitting the pod to kubernetes 11/29/22 12:05:37.787
Nov 29 12:05:37.796: INFO: Waiting up to 15m0s for pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3" in namespace "dns-4759" to be "running"
Nov 29 12:05:37.799: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.689312ms
Nov 29 12:05:39.802: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006397226s
Nov 29 12:05:41.802: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006221702s
Nov 29 12:05:43.802: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.005967665s
Nov 29 12:05:45.802: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006276215s
Nov 29 12:05:47.821: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.024706115s
Nov 29 12:05:49.803: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.007473703s
Nov 29 12:05:51.803: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.006788489s
Nov 29 12:05:53.801: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.005503073s
Nov 29 12:05:55.803: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Running", Reason="", readiness=true. Elapsed: 18.007607752s
Nov 29 12:05:55.803: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3" satisfied condition "running"
STEP: retrieving the pod 11/29/22 12:05:55.803
STEP: looking for the results for each expected name from probers 11/29/22 12:05:55.806
Nov 29 12:05:55.809: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:05:55.812: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:05:55.815: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:05:55.817: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:05:55.820: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:05:55.822: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:05:55.825: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:05:55.827: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:05:55.827: INFO: Lookups using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local]

Nov 29 12:06:00.834: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:00.837: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:00.839: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:00.841: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:00.844: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:00.846: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:00.848: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:00.850: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:00.850: INFO: Lookups using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local]

Nov 29 12:06:05.832: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:05.835: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:05.837: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:05.844: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:05.846: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:05.849: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:05.852: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:05.854: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:05.854: INFO: Lookups using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local]

Nov 29 12:06:10.833: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:10.836: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:10.839: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:10.841: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
Nov 29 12:06:10.852: INFO: Lookups using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local]

Nov 29 12:06:15.852: INFO: DNS probes using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 succeeded

STEP: deleting the pod 11/29/22 12:06:15.852
STEP: deleting the test headless service 11/29/22 12:06:15.864
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 29 12:06:15.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4759" for this suite. 11/29/22 12:06:15.879
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":157,"skipped":2887,"failed":0}
------------------------------
• [SLOW TEST] [38.112 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:05:37.771
    Nov 29 12:05:37.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename dns 11/29/22 12:05:37.772
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:05:37.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:05:37.782
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 11/29/22 12:05:37.784
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local;sleep 1; done
     11/29/22 12:05:37.787
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4759.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local;sleep 1; done
     11/29/22 12:05:37.787
    STEP: creating a pod to probe DNS 11/29/22 12:05:37.787
    STEP: submitting the pod to kubernetes 11/29/22 12:05:37.787
    Nov 29 12:05:37.796: INFO: Waiting up to 15m0s for pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3" in namespace "dns-4759" to be "running"
    Nov 29 12:05:37.799: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.689312ms
    Nov 29 12:05:39.802: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006397226s
    Nov 29 12:05:41.802: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006221702s
    Nov 29 12:05:43.802: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.005967665s
    Nov 29 12:05:45.802: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006276215s
    Nov 29 12:05:47.821: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.024706115s
    Nov 29 12:05:49.803: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.007473703s
    Nov 29 12:05:51.803: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.006788489s
    Nov 29 12:05:53.801: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.005503073s
    Nov 29 12:05:55.803: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3": Phase="Running", Reason="", readiness=true. Elapsed: 18.007607752s
    Nov 29 12:05:55.803: INFO: Pod "dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 12:05:55.803
    STEP: looking for the results for each expected name from probers 11/29/22 12:05:55.806
    Nov 29 12:05:55.809: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:05:55.812: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:05:55.815: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:05:55.817: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:05:55.820: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:05:55.822: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:05:55.825: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:05:55.827: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:05:55.827: INFO: Lookups using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local]

    Nov 29 12:06:00.834: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:00.837: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:00.839: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:00.841: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:00.844: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:00.846: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:00.848: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:00.850: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:00.850: INFO: Lookups using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local]

    Nov 29 12:06:05.832: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:05.835: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:05.837: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:05.844: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:05.846: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:05.849: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:05.852: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:05.854: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:05.854: INFO: Lookups using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local jessie_udp@dns-test-service-2.dns-4759.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4759.svc.cluster.local]

    Nov 29 12:06:10.833: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:10.836: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:10.839: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:10.841: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local from pod dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3: the server could not find the requested resource (get pods dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3)
    Nov 29 12:06:10.852: INFO: Lookups using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4759.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4759.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4759.svc.cluster.local]

    Nov 29 12:06:15.852: INFO: DNS probes using dns-4759/dns-test-fb854da0-8f43-4dae-bcff-a954969d0db3 succeeded

    STEP: deleting the pod 11/29/22 12:06:15.852
    STEP: deleting the test headless service 11/29/22 12:06:15.864
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 29 12:06:15.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4759" for this suite. 11/29/22 12:06:15.879
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:06:15.884
Nov 29 12:06:15.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:06:15.885
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:06:15.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:06:15.898
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:06:15.901
Nov 29 12:06:15.906: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b" in namespace "downward-api-2638" to be "Succeeded or Failed"
Nov 29 12:06:15.908: INFO: Pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.197193ms
Nov 29 12:06:17.912: INFO: Pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006107642s
Nov 29 12:06:19.911: INFO: Pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005137769s
STEP: Saw pod success 11/29/22 12:06:19.911
Nov 29 12:06:19.911: INFO: Pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b" satisfied condition "Succeeded or Failed"
Nov 29 12:06:19.913: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b container client-container: <nil>
STEP: delete the pod 11/29/22 12:06:19.917
Nov 29 12:06:19.923: INFO: Waiting for pod downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b to disappear
Nov 29 12:06:19.925: INFO: Pod downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:06:19.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2638" for this suite. 11/29/22 12:06:19.929
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":158,"skipped":2922,"failed":0}
------------------------------
• [4.048 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:06:15.884
    Nov 29 12:06:15.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:06:15.885
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:06:15.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:06:15.898
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:06:15.901
    Nov 29 12:06:15.906: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b" in namespace "downward-api-2638" to be "Succeeded or Failed"
    Nov 29 12:06:15.908: INFO: Pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.197193ms
    Nov 29 12:06:17.912: INFO: Pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006107642s
    Nov 29 12:06:19.911: INFO: Pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005137769s
    STEP: Saw pod success 11/29/22 12:06:19.911
    Nov 29 12:06:19.911: INFO: Pod "downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b" satisfied condition "Succeeded or Failed"
    Nov 29 12:06:19.913: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b container client-container: <nil>
    STEP: delete the pod 11/29/22 12:06:19.917
    Nov 29 12:06:19.923: INFO: Waiting for pod downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b to disappear
    Nov 29 12:06:19.925: INFO: Pod downwardapi-volume-ddd59715-3100-48bb-8600-c782ae96c98b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:06:19.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2638" for this suite. 11/29/22 12:06:19.929
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:06:19.934
Nov 29 12:06:19.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pod-network-test 11/29/22 12:06:19.934
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:06:19.942
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:06:19.944
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-3195 11/29/22 12:06:19.947
STEP: creating a selector 11/29/22 12:06:19.947
STEP: Creating the service pods in kubernetes 11/29/22 12:06:19.947
Nov 29 12:06:19.947: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 29 12:06:19.977: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3195" to be "running and ready"
Nov 29 12:06:19.982: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.406645ms
Nov 29 12:06:19.982: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:06:21.985: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.007517757s
Nov 29 12:06:21.985: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:06:23.986: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.008596061s
Nov 29 12:06:23.986: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:06:25.985: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.007490972s
Nov 29 12:06:25.985: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:06:28.007: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.029578343s
Nov 29 12:06:28.007: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:06:29.985: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.00751105s
Nov 29 12:06:29.985: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:06:31.986: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.008988319s
Nov 29 12:06:31.987: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 29 12:06:31.987: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 29 12:06:31.988: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3195" to be "running and ready"
Nov 29 12:06:31.990: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 1.463776ms
Nov 29 12:06:31.990: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 29 12:06:31.990: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 29 12:06:31.991: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3195" to be "running and ready"
Nov 29 12:06:31.993: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 1.567579ms
Nov 29 12:06:31.993: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 29 12:06:31.993: INFO: Pod "netserver-2" satisfied condition "running and ready"
Nov 29 12:06:31.994: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-3195" to be "running and ready"
Nov 29 12:06:31.996: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 1.526134ms
Nov 29 12:06:31.996: INFO: The phase of Pod netserver-3 is Running (Ready = false)
Nov 29 12:06:33.999: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 2.005028942s
Nov 29 12:06:33.999: INFO: The phase of Pod netserver-3 is Running (Ready = false)
Nov 29 12:06:36.000: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 4.005580752s
Nov 29 12:06:36.000: INFO: The phase of Pod netserver-3 is Running (Ready = false)
Nov 29 12:06:37.999: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 6.004402527s
Nov 29 12:06:37.999: INFO: The phase of Pod netserver-3 is Running (Ready = false)
Nov 29 12:06:40.001: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 8.006386176s
Nov 29 12:06:40.001: INFO: The phase of Pod netserver-3 is Running (Ready = false)
Nov 29 12:06:42.000: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 10.005277953s
Nov 29 12:06:42.000: INFO: The phase of Pod netserver-3 is Running (Ready = true)
Nov 29 12:06:42.000: INFO: Pod "netserver-3" satisfied condition "running and ready"
STEP: Creating test pods 11/29/22 12:06:42.002
Nov 29 12:06:42.004: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3195" to be "running"
Nov 29 12:06:42.006: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 1.846787ms
Nov 29 12:06:44.009: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.004976149s
Nov 29 12:06:44.009: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 29 12:06:44.011: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
Nov 29 12:06:44.011: INFO: Breadth first check of 100.96.1.100 on host 192.168.8.111...
Nov 29 12:06:44.013: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.179:9080/dial?request=hostname&protocol=udp&host=100.96.1.100&port=8081&tries=1'] Namespace:pod-network-test-3195 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:06:44.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:06:44.013: INFO: ExecWithOptions: Clientset creation
Nov 29 12:06:44.014: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-3195/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.1.100%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 29 12:06:44.072: INFO: Waiting for responses: map[]
Nov 29 12:06:44.072: INFO: reached 100.96.1.100 after 0/1 tries
Nov 29 12:06:44.072: INFO: Breadth first check of 100.96.3.79 on host 192.168.8.35...
Nov 29 12:06:44.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.179:9080/dial?request=hostname&protocol=udp&host=100.96.3.79&port=8081&tries=1'] Namespace:pod-network-test-3195 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:06:44.082: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:06:44.083: INFO: ExecWithOptions: Clientset creation
Nov 29 12:06:44.083: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-3195/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.3.79%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 29 12:06:44.140: INFO: Waiting for responses: map[]
Nov 29 12:06:44.140: INFO: reached 100.96.3.79 after 0/1 tries
Nov 29 12:06:44.140: INFO: Breadth first check of 100.96.2.178 on host 192.168.8.22...
Nov 29 12:06:44.142: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.179:9080/dial?request=hostname&protocol=udp&host=100.96.2.178&port=8081&tries=1'] Namespace:pod-network-test-3195 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:06:44.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:06:44.142: INFO: ExecWithOptions: Clientset creation
Nov 29 12:06:44.142: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-3195/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.2.178%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 29 12:06:44.206: INFO: Waiting for responses: map[]
Nov 29 12:06:44.206: INFO: reached 100.96.2.178 after 0/1 tries
Nov 29 12:06:44.206: INFO: Breadth first check of 100.96.0.68 on host 192.168.8.155...
Nov 29 12:06:44.209: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.179:9080/dial?request=hostname&protocol=udp&host=100.96.0.68&port=8081&tries=1'] Namespace:pod-network-test-3195 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:06:44.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:06:44.209: INFO: ExecWithOptions: Clientset creation
Nov 29 12:06:44.209: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-3195/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.0.68%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 29 12:06:44.268: INFO: Waiting for responses: map[]
Nov 29 12:06:44.269: INFO: reached 100.96.0.68 after 0/1 tries
Nov 29 12:06:44.269: INFO: Going to retry 0 out of 4 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 29 12:06:44.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3195" for this suite. 11/29/22 12:06:44.273
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":159,"skipped":2926,"failed":0}
------------------------------
• [SLOW TEST] [24.342 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:06:19.934
    Nov 29 12:06:19.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pod-network-test 11/29/22 12:06:19.934
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:06:19.942
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:06:19.944
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-3195 11/29/22 12:06:19.947
    STEP: creating a selector 11/29/22 12:06:19.947
    STEP: Creating the service pods in kubernetes 11/29/22 12:06:19.947
    Nov 29 12:06:19.947: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 29 12:06:19.977: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3195" to be "running and ready"
    Nov 29 12:06:19.982: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.406645ms
    Nov 29 12:06:19.982: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:06:21.985: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.007517757s
    Nov 29 12:06:21.985: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:06:23.986: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.008596061s
    Nov 29 12:06:23.986: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:06:25.985: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.007490972s
    Nov 29 12:06:25.985: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:06:28.007: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.029578343s
    Nov 29 12:06:28.007: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:06:29.985: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.00751105s
    Nov 29 12:06:29.985: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:06:31.986: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.008988319s
    Nov 29 12:06:31.987: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 29 12:06:31.987: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 29 12:06:31.988: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3195" to be "running and ready"
    Nov 29 12:06:31.990: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 1.463776ms
    Nov 29 12:06:31.990: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 29 12:06:31.990: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 29 12:06:31.991: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3195" to be "running and ready"
    Nov 29 12:06:31.993: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 1.567579ms
    Nov 29 12:06:31.993: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 29 12:06:31.993: INFO: Pod "netserver-2" satisfied condition "running and ready"
    Nov 29 12:06:31.994: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-3195" to be "running and ready"
    Nov 29 12:06:31.996: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 1.526134ms
    Nov 29 12:06:31.996: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    Nov 29 12:06:33.999: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 2.005028942s
    Nov 29 12:06:33.999: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    Nov 29 12:06:36.000: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 4.005580752s
    Nov 29 12:06:36.000: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    Nov 29 12:06:37.999: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 6.004402527s
    Nov 29 12:06:37.999: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    Nov 29 12:06:40.001: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 8.006386176s
    Nov 29 12:06:40.001: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    Nov 29 12:06:42.000: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 10.005277953s
    Nov 29 12:06:42.000: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    Nov 29 12:06:42.000: INFO: Pod "netserver-3" satisfied condition "running and ready"
    STEP: Creating test pods 11/29/22 12:06:42.002
    Nov 29 12:06:42.004: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3195" to be "running"
    Nov 29 12:06:42.006: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 1.846787ms
    Nov 29 12:06:44.009: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.004976149s
    Nov 29 12:06:44.009: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 29 12:06:44.011: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
    Nov 29 12:06:44.011: INFO: Breadth first check of 100.96.1.100 on host 192.168.8.111...
    Nov 29 12:06:44.013: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.179:9080/dial?request=hostname&protocol=udp&host=100.96.1.100&port=8081&tries=1'] Namespace:pod-network-test-3195 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:06:44.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:06:44.013: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:06:44.014: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-3195/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.1.100%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 29 12:06:44.072: INFO: Waiting for responses: map[]
    Nov 29 12:06:44.072: INFO: reached 100.96.1.100 after 0/1 tries
    Nov 29 12:06:44.072: INFO: Breadth first check of 100.96.3.79 on host 192.168.8.35...
    Nov 29 12:06:44.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.179:9080/dial?request=hostname&protocol=udp&host=100.96.3.79&port=8081&tries=1'] Namespace:pod-network-test-3195 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:06:44.082: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:06:44.083: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:06:44.083: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-3195/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.3.79%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 29 12:06:44.140: INFO: Waiting for responses: map[]
    Nov 29 12:06:44.140: INFO: reached 100.96.3.79 after 0/1 tries
    Nov 29 12:06:44.140: INFO: Breadth first check of 100.96.2.178 on host 192.168.8.22...
    Nov 29 12:06:44.142: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.179:9080/dial?request=hostname&protocol=udp&host=100.96.2.178&port=8081&tries=1'] Namespace:pod-network-test-3195 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:06:44.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:06:44.142: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:06:44.142: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-3195/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.2.178%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 29 12:06:44.206: INFO: Waiting for responses: map[]
    Nov 29 12:06:44.206: INFO: reached 100.96.2.178 after 0/1 tries
    Nov 29 12:06:44.206: INFO: Breadth first check of 100.96.0.68 on host 192.168.8.155...
    Nov 29 12:06:44.209: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.179:9080/dial?request=hostname&protocol=udp&host=100.96.0.68&port=8081&tries=1'] Namespace:pod-network-test-3195 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:06:44.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:06:44.209: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:06:44.209: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-3195/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.179%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.0.68%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 29 12:06:44.268: INFO: Waiting for responses: map[]
    Nov 29 12:06:44.269: INFO: reached 100.96.0.68 after 0/1 tries
    Nov 29 12:06:44.269: INFO: Going to retry 0 out of 4 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 29 12:06:44.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3195" for this suite. 11/29/22 12:06:44.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:06:44.277
Nov 29 12:06:44.277: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:06:44.278
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:06:44.286
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:06:44.288
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-16381d0e-8253-4f23-9f8d-c65a81d7a027 11/29/22 12:06:44.29
STEP: Creating a pod to test consume secrets 11/29/22 12:06:44.293
Nov 29 12:06:44.297: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88" in namespace "projected-1145" to be "Succeeded or Failed"
Nov 29 12:06:44.299: INFO: Pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046849ms
Nov 29 12:06:46.303: INFO: Pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005403082s
Nov 29 12:06:48.303: INFO: Pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005787235s
STEP: Saw pod success 11/29/22 12:06:48.303
Nov 29 12:06:48.303: INFO: Pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88" satisfied condition "Succeeded or Failed"
Nov 29 12:06:48.306: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:06:48.309
Nov 29 12:06:48.316: INFO: Waiting for pod pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88 to disappear
Nov 29 12:06:48.319: INFO: Pod pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 29 12:06:48.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1145" for this suite. 11/29/22 12:06:48.322
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":160,"skipped":2957,"failed":0}
------------------------------
• [4.049 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:06:44.277
    Nov 29 12:06:44.277: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:06:44.278
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:06:44.286
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:06:44.288
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-16381d0e-8253-4f23-9f8d-c65a81d7a027 11/29/22 12:06:44.29
    STEP: Creating a pod to test consume secrets 11/29/22 12:06:44.293
    Nov 29 12:06:44.297: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88" in namespace "projected-1145" to be "Succeeded or Failed"
    Nov 29 12:06:44.299: INFO: Pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046849ms
    Nov 29 12:06:46.303: INFO: Pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005403082s
    Nov 29 12:06:48.303: INFO: Pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005787235s
    STEP: Saw pod success 11/29/22 12:06:48.303
    Nov 29 12:06:48.303: INFO: Pod "pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88" satisfied condition "Succeeded or Failed"
    Nov 29 12:06:48.306: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:06:48.309
    Nov 29 12:06:48.316: INFO: Waiting for pod pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88 to disappear
    Nov 29 12:06:48.319: INFO: Pod pod-projected-secrets-229ced03-3b70-4dad-9429-b5debec92d88 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 29 12:06:48.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1145" for this suite. 11/29/22 12:06:48.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:06:48.327
Nov 29 12:06:48.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-pred 11/29/22 12:06:48.328
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:06:48.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:06:48.344
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 29 12:06:48.346: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 29 12:06:48.352: INFO: Waiting for terminating namespaces to be deleted...
Nov 29 12:06:48.354: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-0 before test
Nov 29 12:06:48.359: INFO: canal-wsz7n from kube-system started at 2022-11-29 11:01:45 +0000 UTC (3 container statuses recorded)
Nov 29 12:06:48.359: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:06:48.359: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:06:48.359: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:06:48.359: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.359: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:06:48.359: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.359: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:06:48.359: INFO: kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.359: INFO: 	Container main ready: true, restart count 0
Nov 29 12:06:48.359: INFO: node-local-dns-hqwqq from kube-system started at 2022-11-29 11:01:45 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.359: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:06:48.360: INFO: netserver-0 from pod-network-test-3195 started at 2022-11-29 12:06:20 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.360: INFO: 	Container webserver ready: true, restart count 0
Nov 29 12:06:48.360: INFO: sonobuoy from sonobuoy started at 2022-11-29 11:25:29 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.360: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 29 12:06:48.360: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:06:48.360: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:06:48.360: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:06:48.360: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-1 before test
Nov 29 12:06:48.366: INFO: canal-f2ndl from kube-system started at 2022-11-29 11:02:00 +0000 UTC (3 container statuses recorded)
Nov 29 12:06:48.366: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:06:48.366: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:06:48.366: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:06:48.366: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.366: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:06:48.366: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.366: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:06:48.366: INFO: kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.366: INFO: 	Container main ready: true, restart count 0
Nov 29 12:06:48.367: INFO: node-local-dns-wwm5j from kube-system started at 2022-11-29 11:02:00 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.367: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:06:48.367: INFO: netserver-1 from pod-network-test-3195 started at 2022-11-29 12:06:19 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.367: INFO: 	Container webserver ready: true, restart count 0
Nov 29 12:06:48.367: INFO: sonobuoy-e2e-job-2558967603d841e7 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:06:48.367: INFO: 	Container e2e ready: true, restart count 0
Nov 29 12:06:48.367: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:06:48.367: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk from sonobuoy started at 2022-11-29 11:25:37 +0000 UTC (2 container statuses recorded)
Nov 29 12:06:48.367: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:06:48.367: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:06:48.367: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-2 before test
Nov 29 12:06:48.373: INFO: canal-xwmmp from kube-system started at 2022-11-29 11:01:59 +0000 UTC (3 container statuses recorded)
Nov 29 12:06:48.373: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:06:48.373: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:06:48.373: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:06:48.373: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.373: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:06:48.373: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.373: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:06:48.373: INFO: kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.373: INFO: 	Container main ready: true, restart count 0
Nov 29 12:06:48.373: INFO: node-local-dns-rf4vc from kube-system started at 2022-11-29 11:01:59 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.373: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:06:48.373: INFO: netserver-2 from pod-network-test-3195 started at 2022-11-29 12:06:19 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.373: INFO: 	Container webserver ready: true, restart count 0
Nov 29 12:06:48.373: INFO: test-container-pod from pod-network-test-3195 started at 2022-11-29 12:06:41 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.374: INFO: 	Container webserver ready: true, restart count 0
Nov 29 12:06:48.374: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:06:48.374: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:06:48.374: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:06:48.374: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-master-0 before test
Nov 29 12:06:48.382: INFO: calico-kube-controllers-5c9848945f-6wztn from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 29 12:06:48.382: INFO: canal-5j97l from kube-system started at 2022-11-29 10:49:25 +0000 UTC (3 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:06:48.382: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:06:48.382: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:06:48.382: INFO: coredns-5cbcf9db85-hbrbr from kube-system started at 2022-11-29 11:01:49 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container coredns ready: true, restart count 0
Nov 29 12:06:48.382: INFO: coredns-5cbcf9db85-q2lfd from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container coredns ready: true, restart count 0
Nov 29 12:06:48.382: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:06:48.382: INFO: k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container etcd ready: true, restart count 0
Nov 29 12:06:48.382: INFO: k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (3 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container apiserver ready: true, restart count 0
Nov 29 12:06:48.382: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov 29 12:06:48.382: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov 29 12:06:48.382: INFO: kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container kube-addon-manager ready: true, restart count 0
Nov 29 12:06:48.382: INFO: kube-dns-autoscaler-bd7b594d-dwsh9 from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container autoscaler ready: true, restart count 0
Nov 29 12:06:48.382: INFO: kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:06:48.382: INFO: kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container node-label ready: true, restart count 0
Nov 29 12:06:48.382: INFO: kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container main ready: true, restart count 0
Nov 29 12:06:48.382: INFO: kublr-system-shell-d595b78f-7ngf9 from kube-system started at 2022-11-29 10:52:20 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container shell ready: true, restart count 0
Nov 29 12:06:48.382: INFO: metrics-server-v0.5.2-54b5b7598b-zq8q6 from kube-system started at 2022-11-29 10:51:11 +0000 UTC (2 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container metrics-server ready: true, restart count 1
Nov 29 12:06:48.382: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 29 12:06:48.382: INFO: node-local-dns-fp5nm from kube-system started at 2022-11-29 10:49:25 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:06:48.382: INFO: dashboard-metrics-scraper-6fffb6f45f-q7h8c from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 29 12:06:48.382: INFO: kubernetes-dashboard-c5db79646-sq2km from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 29 12:06:48.382: INFO: kublr-operator-576b5465f6-gdg4s from kublr started at 2022-11-29 10:51:53 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container kublr-operator ready: true, restart count 0
Nov 29 12:06:48.382: INFO: netserver-3 from pod-network-test-3195 started at 2022-11-29 12:06:19 +0000 UTC (1 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container webserver ready: true, restart count 0
Nov 29 12:06:48.382: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:06:48.382: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:06:48.382: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/29/22 12:06:48.382
Nov 29 12:06:48.386: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-4671" to be "running"
Nov 29 12:06:48.389: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.900849ms
Nov 29 12:06:50.392: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.005709436s
Nov 29 12:06:50.392: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/29/22 12:06:50.394
STEP: Trying to apply a random label on the found node. 11/29/22 12:06:50.406
STEP: verifying the node has the label kubernetes.io/e2e-e825dcfe-73da-4f98-8a3d-6733b063f0a3 95 11/29/22 12:06:50.42
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/29/22 12:06:50.432
Nov 29 12:06:50.435: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-4671" to be "not pending"
Nov 29 12:06:50.439: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.179503ms
Nov 29 12:06:52.443: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.007691785s
Nov 29 12:06:52.443: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.8.111 on the node which pod4 resides and expect not scheduled 11/29/22 12:06:52.443
Nov 29 12:06:52.447: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-4671" to be "not pending"
Nov 29 12:06:52.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.554161ms
Nov 29 12:06:54.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013458494s
Nov 29 12:06:56.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014882531s
Nov 29 12:06:58.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013249667s
Nov 29 12:07:00.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014469774s
Nov 29 12:07:02.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013610944s
Nov 29 12:07:04.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.013257487s
Nov 29 12:07:06.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.014283564s
Nov 29 12:07:08.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.013156446s
Nov 29 12:07:10.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.0144579s
Nov 29 12:07:12.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.0150505s
Nov 29 12:07:14.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.01361112s
Nov 29 12:07:16.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.01452502s
Nov 29 12:07:18.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.015271264s
Nov 29 12:07:20.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.013409681s
Nov 29 12:07:22.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.013680609s
Nov 29 12:07:24.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.01412809s
Nov 29 12:07:26.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.013432168s
Nov 29 12:07:28.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.013159981s
Nov 29 12:07:30.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015069254s
Nov 29 12:07:32.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.015991783s
Nov 29 12:07:34.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013939663s
Nov 29 12:07:36.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.01348546s
Nov 29 12:07:38.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014054913s
Nov 29 12:07:40.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.01764529s
Nov 29 12:07:42.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.015727951s
Nov 29 12:07:44.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.014922743s
Nov 29 12:07:46.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.013111891s
Nov 29 12:07:48.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.016104214s
Nov 29 12:07:50.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.013706175s
Nov 29 12:07:52.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.013617564s
Nov 29 12:07:54.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.015246139s
Nov 29 12:07:56.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.013964308s
Nov 29 12:07:58.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014367842s
Nov 29 12:08:00.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.015518409s
Nov 29 12:08:02.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.016358391s
Nov 29 12:08:04.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.014232644s
Nov 29 12:08:06.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.013920576s
Nov 29 12:08:08.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.014003468s
Nov 29 12:08:10.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.014608598s
Nov 29 12:08:12.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.019196304s
Nov 29 12:08:14.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.019177798s
Nov 29 12:08:16.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.016103519s
Nov 29 12:08:18.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.014497088s
Nov 29 12:08:20.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.014573897s
Nov 29 12:08:22.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013240007s
Nov 29 12:08:24.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013428073s
Nov 29 12:08:26.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013161873s
Nov 29 12:08:28.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.013789019s
Nov 29 12:08:30.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.015576348s
Nov 29 12:08:32.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.013240304s
Nov 29 12:08:34.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.013529407s
Nov 29 12:08:36.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.015130369s
Nov 29 12:08:38.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.013746835s
Nov 29 12:08:40.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.014153851s
Nov 29 12:08:42.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013970695s
Nov 29 12:08:44.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.014726969s
Nov 29 12:08:46.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.018705415s
Nov 29 12:08:48.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.013906548s
Nov 29 12:08:50.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014578556s
Nov 29 12:08:52.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.01546017s
Nov 29 12:08:54.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.013529841s
Nov 29 12:08:56.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.013985363s
Nov 29 12:08:58.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014577885s
Nov 29 12:09:00.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.015251023s
Nov 29 12:09:02.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.01420712s
Nov 29 12:09:04.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.014210853s
Nov 29 12:09:06.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.014257758s
Nov 29 12:09:08.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.014429389s
Nov 29 12:09:10.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.015292539s
Nov 29 12:09:12.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.0157409s
Nov 29 12:09:14.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.017685514s
Nov 29 12:09:16.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.014491745s
Nov 29 12:09:18.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.014561852s
Nov 29 12:09:20.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.014166268s
Nov 29 12:09:22.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.013906512s
Nov 29 12:09:24.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.015026642s
Nov 29 12:09:26.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.013595279s
Nov 29 12:09:28.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.013962771s
Nov 29 12:09:30.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.014063388s
Nov 29 12:09:32.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.014302756s
Nov 29 12:09:34.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.014539381s
Nov 29 12:09:36.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.017349774s
Nov 29 12:09:38.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.013193919s
Nov 29 12:09:40.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.017231629s
Nov 29 12:09:42.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.014784375s
Nov 29 12:09:44.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.015272006s
Nov 29 12:09:46.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.014837158s
Nov 29 12:09:48.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.013785692s
Nov 29 12:09:50.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.014119153s
Nov 29 12:09:52.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.014081197s
Nov 29 12:09:54.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.014921087s
Nov 29 12:09:56.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.015361787s
Nov 29 12:09:58.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.014118928s
Nov 29 12:10:00.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.016585673s
Nov 29 12:10:02.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.01456909s
Nov 29 12:10:04.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.014580755s
Nov 29 12:10:06.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.01399696s
Nov 29 12:10:08.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.013934143s
Nov 29 12:10:10.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.016047224s
Nov 29 12:10:12.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.014749543s
Nov 29 12:10:14.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.016169517s
Nov 29 12:10:16.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.014374846s
Nov 29 12:10:18.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.013609728s
Nov 29 12:10:20.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.013482654s
Nov 29 12:10:22.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.013732688s
Nov 29 12:10:24.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.015414426s
Nov 29 12:10:26.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.014907427s
Nov 29 12:10:28.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.013486871s
Nov 29 12:10:30.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.014512793s
Nov 29 12:10:32.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.014035378s
Nov 29 12:10:34.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.013992091s
Nov 29 12:10:36.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.016125632s
Nov 29 12:10:38.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.01351035s
Nov 29 12:10:40.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.015792935s
Nov 29 12:10:42.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.014850862s
Nov 29 12:10:44.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.014220409s
Nov 29 12:10:46.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.020737327s
Nov 29 12:10:48.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.013466904s
Nov 29 12:10:50.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.015761475s
Nov 29 12:10:52.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.014948353s
Nov 29 12:10:54.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.013767087s
Nov 29 12:10:56.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.015414285s
Nov 29 12:10:58.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.014030737s
Nov 29 12:11:00.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.015992151s
Nov 29 12:11:02.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.014387872s
Nov 29 12:11:04.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.014996223s
Nov 29 12:11:06.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.015290008s
Nov 29 12:11:08.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.014308566s
Nov 29 12:11:10.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.017140717s
Nov 29 12:11:12.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.015318709s
Nov 29 12:11:14.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.014277034s
Nov 29 12:11:16.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.014836317s
Nov 29 12:11:18.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.014101236s
Nov 29 12:11:20.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.0158025s
Nov 29 12:11:22.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.014355189s
Nov 29 12:11:24.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.015064751s
Nov 29 12:11:26.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.013558687s
Nov 29 12:11:28.517: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.07049987s
Nov 29 12:11:30.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.015943397s
Nov 29 12:11:32.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.013954381s
Nov 29 12:11:34.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.014761286s
Nov 29 12:11:36.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.015559526s
Nov 29 12:11:38.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.014063733s
Nov 29 12:11:40.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.01490903s
Nov 29 12:11:42.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.014933363s
Nov 29 12:11:44.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.014692113s
Nov 29 12:11:46.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.016998634s
Nov 29 12:11:48.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.01415313s
Nov 29 12:11:50.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.014563904s
Nov 29 12:11:52.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.017575709s
Nov 29 12:11:52.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.020633293s
STEP: removing the label kubernetes.io/e2e-e825dcfe-73da-4f98-8a3d-6733b063f0a3 off the node dvi-7336-1669718118-vsp1-group1-0 11/29/22 12:11:52.467
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e825dcfe-73da-4f98-8a3d-6733b063f0a3 11/29/22 12:11:52.481
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:11:52.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4671" for this suite. 11/29/22 12:11:52.494
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":161,"skipped":2972,"failed":0}
------------------------------
• [SLOW TEST] [304.170 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:06:48.327
    Nov 29 12:06:48.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-pred 11/29/22 12:06:48.328
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:06:48.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:06:48.344
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 29 12:06:48.346: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 29 12:06:48.352: INFO: Waiting for terminating namespaces to be deleted...
    Nov 29 12:06:48.354: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-0 before test
    Nov 29 12:06:48.359: INFO: canal-wsz7n from kube-system started at 2022-11-29 11:01:45 +0000 UTC (3 container statuses recorded)
    Nov 29 12:06:48.359: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:06:48.359: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:06:48.359: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:06:48.359: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.359: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:06:48.359: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.359: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:06:48.359: INFO: kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.359: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:06:48.359: INFO: node-local-dns-hqwqq from kube-system started at 2022-11-29 11:01:45 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.359: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:06:48.360: INFO: netserver-0 from pod-network-test-3195 started at 2022-11-29 12:06:20 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.360: INFO: 	Container webserver ready: true, restart count 0
    Nov 29 12:06:48.360: INFO: sonobuoy from sonobuoy started at 2022-11-29 11:25:29 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.360: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 29 12:06:48.360: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:06:48.360: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:06:48.360: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:06:48.360: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-1 before test
    Nov 29 12:06:48.366: INFO: canal-f2ndl from kube-system started at 2022-11-29 11:02:00 +0000 UTC (3 container statuses recorded)
    Nov 29 12:06:48.366: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:06:48.366: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:06:48.366: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:06:48.366: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.366: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:06:48.366: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.366: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:06:48.366: INFO: kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.366: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:06:48.367: INFO: node-local-dns-wwm5j from kube-system started at 2022-11-29 11:02:00 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.367: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:06:48.367: INFO: netserver-1 from pod-network-test-3195 started at 2022-11-29 12:06:19 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.367: INFO: 	Container webserver ready: true, restart count 0
    Nov 29 12:06:48.367: INFO: sonobuoy-e2e-job-2558967603d841e7 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:06:48.367: INFO: 	Container e2e ready: true, restart count 0
    Nov 29 12:06:48.367: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:06:48.367: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk from sonobuoy started at 2022-11-29 11:25:37 +0000 UTC (2 container statuses recorded)
    Nov 29 12:06:48.367: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:06:48.367: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:06:48.367: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-2 before test
    Nov 29 12:06:48.373: INFO: canal-xwmmp from kube-system started at 2022-11-29 11:01:59 +0000 UTC (3 container statuses recorded)
    Nov 29 12:06:48.373: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:06:48.373: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:06:48.373: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:06:48.373: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.373: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:06:48.373: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.373: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:06:48.373: INFO: kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.373: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:06:48.373: INFO: node-local-dns-rf4vc from kube-system started at 2022-11-29 11:01:59 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.373: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:06:48.373: INFO: netserver-2 from pod-network-test-3195 started at 2022-11-29 12:06:19 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.373: INFO: 	Container webserver ready: true, restart count 0
    Nov 29 12:06:48.373: INFO: test-container-pod from pod-network-test-3195 started at 2022-11-29 12:06:41 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.374: INFO: 	Container webserver ready: true, restart count 0
    Nov 29 12:06:48.374: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:06:48.374: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:06:48.374: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:06:48.374: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-master-0 before test
    Nov 29 12:06:48.382: INFO: calico-kube-controllers-5c9848945f-6wztn from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: canal-5j97l from kube-system started at 2022-11-29 10:49:25 +0000 UTC (3 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: coredns-5cbcf9db85-hbrbr from kube-system started at 2022-11-29 11:01:49 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container coredns ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: coredns-5cbcf9db85-q2lfd from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container coredns ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container etcd ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (3 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container apiserver ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: 	Container kube-scheduler ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: kube-dns-autoscaler-bd7b594d-dwsh9 from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container autoscaler ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container node-label ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: kublr-system-shell-d595b78f-7ngf9 from kube-system started at 2022-11-29 10:52:20 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container shell ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: metrics-server-v0.5.2-54b5b7598b-zq8q6 from kube-system started at 2022-11-29 10:51:11 +0000 UTC (2 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container metrics-server ready: true, restart count 1
    Nov 29 12:06:48.382: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: node-local-dns-fp5nm from kube-system started at 2022-11-29 10:49:25 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: dashboard-metrics-scraper-6fffb6f45f-q7h8c from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: kubernetes-dashboard-c5db79646-sq2km from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: kublr-operator-576b5465f6-gdg4s from kublr started at 2022-11-29 10:51:53 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container kublr-operator ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: netserver-3 from pod-network-test-3195 started at 2022-11-29 12:06:19 +0000 UTC (1 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container webserver ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:06:48.382: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:06:48.382: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/29/22 12:06:48.382
    Nov 29 12:06:48.386: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-4671" to be "running"
    Nov 29 12:06:48.389: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.900849ms
    Nov 29 12:06:50.392: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.005709436s
    Nov 29 12:06:50.392: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/29/22 12:06:50.394
    STEP: Trying to apply a random label on the found node. 11/29/22 12:06:50.406
    STEP: verifying the node has the label kubernetes.io/e2e-e825dcfe-73da-4f98-8a3d-6733b063f0a3 95 11/29/22 12:06:50.42
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/29/22 12:06:50.432
    Nov 29 12:06:50.435: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-4671" to be "not pending"
    Nov 29 12:06:50.439: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.179503ms
    Nov 29 12:06:52.443: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.007691785s
    Nov 29 12:06:52.443: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.8.111 on the node which pod4 resides and expect not scheduled 11/29/22 12:06:52.443
    Nov 29 12:06:52.447: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-4671" to be "not pending"
    Nov 29 12:06:52.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.554161ms
    Nov 29 12:06:54.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013458494s
    Nov 29 12:06:56.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014882531s
    Nov 29 12:06:58.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013249667s
    Nov 29 12:07:00.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014469774s
    Nov 29 12:07:02.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013610944s
    Nov 29 12:07:04.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.013257487s
    Nov 29 12:07:06.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.014283564s
    Nov 29 12:07:08.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.013156446s
    Nov 29 12:07:10.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.0144579s
    Nov 29 12:07:12.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.0150505s
    Nov 29 12:07:14.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.01361112s
    Nov 29 12:07:16.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.01452502s
    Nov 29 12:07:18.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.015271264s
    Nov 29 12:07:20.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.013409681s
    Nov 29 12:07:22.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.013680609s
    Nov 29 12:07:24.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.01412809s
    Nov 29 12:07:26.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.013432168s
    Nov 29 12:07:28.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.013159981s
    Nov 29 12:07:30.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015069254s
    Nov 29 12:07:32.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.015991783s
    Nov 29 12:07:34.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013939663s
    Nov 29 12:07:36.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.01348546s
    Nov 29 12:07:38.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014054913s
    Nov 29 12:07:40.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.01764529s
    Nov 29 12:07:42.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.015727951s
    Nov 29 12:07:44.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.014922743s
    Nov 29 12:07:46.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.013111891s
    Nov 29 12:07:48.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.016104214s
    Nov 29 12:07:50.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.013706175s
    Nov 29 12:07:52.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.013617564s
    Nov 29 12:07:54.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.015246139s
    Nov 29 12:07:56.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.013964308s
    Nov 29 12:07:58.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014367842s
    Nov 29 12:08:00.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.015518409s
    Nov 29 12:08:02.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.016358391s
    Nov 29 12:08:04.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.014232644s
    Nov 29 12:08:06.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.013920576s
    Nov 29 12:08:08.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.014003468s
    Nov 29 12:08:10.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.014608598s
    Nov 29 12:08:12.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.019196304s
    Nov 29 12:08:14.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.019177798s
    Nov 29 12:08:16.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.016103519s
    Nov 29 12:08:18.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.014497088s
    Nov 29 12:08:20.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.014573897s
    Nov 29 12:08:22.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013240007s
    Nov 29 12:08:24.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013428073s
    Nov 29 12:08:26.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013161873s
    Nov 29 12:08:28.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.013789019s
    Nov 29 12:08:30.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.015576348s
    Nov 29 12:08:32.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.013240304s
    Nov 29 12:08:34.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.013529407s
    Nov 29 12:08:36.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.015130369s
    Nov 29 12:08:38.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.013746835s
    Nov 29 12:08:40.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.014153851s
    Nov 29 12:08:42.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013970695s
    Nov 29 12:08:44.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.014726969s
    Nov 29 12:08:46.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.018705415s
    Nov 29 12:08:48.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.013906548s
    Nov 29 12:08:50.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014578556s
    Nov 29 12:08:52.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.01546017s
    Nov 29 12:08:54.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.013529841s
    Nov 29 12:08:56.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.013985363s
    Nov 29 12:08:58.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014577885s
    Nov 29 12:09:00.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.015251023s
    Nov 29 12:09:02.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.01420712s
    Nov 29 12:09:04.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.014210853s
    Nov 29 12:09:06.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.014257758s
    Nov 29 12:09:08.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.014429389s
    Nov 29 12:09:10.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.015292539s
    Nov 29 12:09:12.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.0157409s
    Nov 29 12:09:14.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.017685514s
    Nov 29 12:09:16.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.014491745s
    Nov 29 12:09:18.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.014561852s
    Nov 29 12:09:20.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.014166268s
    Nov 29 12:09:22.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.013906512s
    Nov 29 12:09:24.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.015026642s
    Nov 29 12:09:26.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.013595279s
    Nov 29 12:09:28.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.013962771s
    Nov 29 12:09:30.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.014063388s
    Nov 29 12:09:32.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.014302756s
    Nov 29 12:09:34.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.014539381s
    Nov 29 12:09:36.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.017349774s
    Nov 29 12:09:38.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.013193919s
    Nov 29 12:09:40.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.017231629s
    Nov 29 12:09:42.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.014784375s
    Nov 29 12:09:44.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.015272006s
    Nov 29 12:09:46.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.014837158s
    Nov 29 12:09:48.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.013785692s
    Nov 29 12:09:50.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.014119153s
    Nov 29 12:09:52.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.014081197s
    Nov 29 12:09:54.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.014921087s
    Nov 29 12:09:56.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.015361787s
    Nov 29 12:09:58.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.014118928s
    Nov 29 12:10:00.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.016585673s
    Nov 29 12:10:02.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.01456909s
    Nov 29 12:10:04.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.014580755s
    Nov 29 12:10:06.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.01399696s
    Nov 29 12:10:08.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.013934143s
    Nov 29 12:10:10.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.016047224s
    Nov 29 12:10:12.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.014749543s
    Nov 29 12:10:14.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.016169517s
    Nov 29 12:10:16.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.014374846s
    Nov 29 12:10:18.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.013609728s
    Nov 29 12:10:20.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.013482654s
    Nov 29 12:10:22.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.013732688s
    Nov 29 12:10:24.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.015414426s
    Nov 29 12:10:26.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.014907427s
    Nov 29 12:10:28.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.013486871s
    Nov 29 12:10:30.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.014512793s
    Nov 29 12:10:32.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.014035378s
    Nov 29 12:10:34.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.013992091s
    Nov 29 12:10:36.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.016125632s
    Nov 29 12:10:38.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.01351035s
    Nov 29 12:10:40.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.015792935s
    Nov 29 12:10:42.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.014850862s
    Nov 29 12:10:44.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.014220409s
    Nov 29 12:10:46.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.020737327s
    Nov 29 12:10:48.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.013466904s
    Nov 29 12:10:50.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.015761475s
    Nov 29 12:10:52.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.014948353s
    Nov 29 12:10:54.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.013767087s
    Nov 29 12:10:56.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.015414285s
    Nov 29 12:10:58.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.014030737s
    Nov 29 12:11:00.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.015992151s
    Nov 29 12:11:02.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.014387872s
    Nov 29 12:11:04.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.014996223s
    Nov 29 12:11:06.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.015290008s
    Nov 29 12:11:08.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.014308566s
    Nov 29 12:11:10.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.017140717s
    Nov 29 12:11:12.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.015318709s
    Nov 29 12:11:14.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.014277034s
    Nov 29 12:11:16.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.014836317s
    Nov 29 12:11:18.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.014101236s
    Nov 29 12:11:20.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.0158025s
    Nov 29 12:11:22.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.014355189s
    Nov 29 12:11:24.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.015064751s
    Nov 29 12:11:26.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.013558687s
    Nov 29 12:11:28.517: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.07049987s
    Nov 29 12:11:30.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.015943397s
    Nov 29 12:11:32.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.013954381s
    Nov 29 12:11:34.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.014761286s
    Nov 29 12:11:36.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.015559526s
    Nov 29 12:11:38.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.014063733s
    Nov 29 12:11:40.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.01490903s
    Nov 29 12:11:42.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.014933363s
    Nov 29 12:11:44.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.014692113s
    Nov 29 12:11:46.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.016998634s
    Nov 29 12:11:48.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.01415313s
    Nov 29 12:11:50.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.014563904s
    Nov 29 12:11:52.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.017575709s
    Nov 29 12:11:52.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.020633293s
    STEP: removing the label kubernetes.io/e2e-e825dcfe-73da-4f98-8a3d-6733b063f0a3 off the node dvi-7336-1669718118-vsp1-group1-0 11/29/22 12:11:52.467
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-e825dcfe-73da-4f98-8a3d-6733b063f0a3 11/29/22 12:11:52.481
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:11:52.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4671" for this suite. 11/29/22 12:11:52.494
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:11:52.498
Nov 29 12:11:52.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:11:52.499
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:11:52.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:11:52.516
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:11:52.525
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:11:53.132
STEP: Deploying the webhook pod 11/29/22 12:11:53.138
STEP: Wait for the deployment to be ready 11/29/22 12:11:53.145
Nov 29 12:11:53.152: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:11:55.16
STEP: Verifying the service has paired with the endpoint 11/29/22 12:11:55.167
Nov 29 12:11:56.167: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/29/22 12:11:56.171
STEP: create a pod that should be updated by the webhook 11/29/22 12:11:56.184
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:11:56.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6809" for this suite. 11/29/22 12:11:56.221
STEP: Destroying namespace "webhook-6809-markers" for this suite. 11/29/22 12:11:56.225
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":162,"skipped":2998,"failed":0}
------------------------------
• [3.753 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:11:52.498
    Nov 29 12:11:52.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:11:52.499
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:11:52.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:11:52.516
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:11:52.525
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:11:53.132
    STEP: Deploying the webhook pod 11/29/22 12:11:53.138
    STEP: Wait for the deployment to be ready 11/29/22 12:11:53.145
    Nov 29 12:11:53.152: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:11:55.16
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:11:55.167
    Nov 29 12:11:56.167: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/29/22 12:11:56.171
    STEP: create a pod that should be updated by the webhook 11/29/22 12:11:56.184
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:11:56.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6809" for this suite. 11/29/22 12:11:56.221
    STEP: Destroying namespace "webhook-6809-markers" for this suite. 11/29/22 12:11:56.225
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:11:56.252
Nov 29 12:11:56.252: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename cronjob 11/29/22 12:11:56.253
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:11:56.263
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:11:56.267
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 11/29/22 12:11:56.27
STEP: Ensuring more than one job is running at a time 11/29/22 12:11:56.279
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/29/22 12:13:00.282
STEP: Removing cronjob 11/29/22 12:13:00.285
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 29 12:13:00.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4470" for this suite. 11/29/22 12:13:00.294
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":163,"skipped":3013,"failed":0}
------------------------------
• [SLOW TEST] [64.046 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:11:56.252
    Nov 29 12:11:56.252: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename cronjob 11/29/22 12:11:56.253
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:11:56.263
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:11:56.267
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 11/29/22 12:11:56.27
    STEP: Ensuring more than one job is running at a time 11/29/22 12:11:56.279
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/29/22 12:13:00.282
    STEP: Removing cronjob 11/29/22 12:13:00.285
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 29 12:13:00.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-4470" for this suite. 11/29/22 12:13:00.294
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:13:00.298
Nov 29 12:13:00.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename svc-latency 11/29/22 12:13:00.299
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:00.311
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:00.314
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Nov 29 12:13:00.323: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: creating replication controller svc-latency-rc in namespace svc-latency-422 11/29/22 12:13:00.324
I1129 12:13:00.330428      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-422, replica count: 1
I1129 12:13:01.381709      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:13:02.382214      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 12:13:02.488: INFO: Created: latency-svc-wn8dk
Nov 29 12:13:02.492: INFO: Got endpoints: latency-svc-wn8dk [10.037959ms]
Nov 29 12:13:02.501: INFO: Created: latency-svc-97qt4
Nov 29 12:13:02.505: INFO: Got endpoints: latency-svc-97qt4 [12.719616ms]
Nov 29 12:13:02.511: INFO: Created: latency-svc-8gn2p
Nov 29 12:13:02.515: INFO: Got endpoints: latency-svc-8gn2p [22.615ms]
Nov 29 12:13:02.594: INFO: Created: latency-svc-v9jht
Nov 29 12:13:02.594: INFO: Created: latency-svc-qvtjs
Nov 29 12:13:02.595: INFO: Created: latency-svc-tjlfl
Nov 29 12:13:02.595: INFO: Created: latency-svc-t5wbw
Nov 29 12:13:02.605: INFO: Created: latency-svc-766vh
Nov 29 12:13:02.605: INFO: Created: latency-svc-njc59
Nov 29 12:13:02.605: INFO: Created: latency-svc-pz5hk
Nov 29 12:13:02.605: INFO: Created: latency-svc-6kt7t
Nov 29 12:13:02.607: INFO: Created: latency-svc-ntv5r
Nov 29 12:13:02.607: INFO: Created: latency-svc-vhdfs
Nov 29 12:13:02.608: INFO: Created: latency-svc-hvpp7
Nov 29 12:13:02.610: INFO: Got endpoints: latency-svc-t5wbw [117.101794ms]
Nov 29 12:13:02.610: INFO: Created: latency-svc-w9xhp
Nov 29 12:13:02.610: INFO: Created: latency-svc-z9bxl
Nov 29 12:13:02.613: INFO: Created: latency-svc-2nxzs
Nov 29 12:13:02.613: INFO: Got endpoints: latency-svc-tjlfl [120.451839ms]
Nov 29 12:13:02.614: INFO: Got endpoints: latency-svc-qvtjs [120.404329ms]
Nov 29 12:13:02.614: INFO: Got endpoints: latency-svc-v9jht [120.659847ms]
Nov 29 12:13:02.614: INFO: Created: latency-svc-g96k8
Nov 29 12:13:02.617: INFO: Got endpoints: latency-svc-njc59 [123.524667ms]
Nov 29 12:13:02.618: INFO: Got endpoints: latency-svc-ntv5r [125.190003ms]
Nov 29 12:13:02.621: INFO: Got endpoints: latency-svc-hvpp7 [127.959174ms]
Nov 29 12:13:02.625: INFO: Got endpoints: latency-svc-w9xhp [131.497776ms]
Nov 29 12:13:02.625: INFO: Got endpoints: latency-svc-z9bxl [132.129298ms]
Nov 29 12:13:02.626: INFO: Got endpoints: latency-svc-2nxzs [110.98223ms]
Nov 29 12:13:02.630: INFO: Got endpoints: latency-svc-g96k8 [137.209526ms]
Nov 29 12:13:02.636: INFO: Created: latency-svc-qsz72
Nov 29 12:13:02.636: INFO: Got endpoints: latency-svc-vhdfs [130.689051ms]
Nov 29 12:13:02.636: INFO: Got endpoints: latency-svc-766vh [143.113944ms]
Nov 29 12:13:02.636: INFO: Got endpoints: latency-svc-pz5hk [143.333479ms]
Nov 29 12:13:02.637: INFO: Got endpoints: latency-svc-6kt7t [143.714499ms]
Nov 29 12:13:02.648: INFO: Got endpoints: latency-svc-qsz72 [34.133686ms]
Nov 29 12:13:02.659: INFO: Created: latency-svc-lwg5d
Nov 29 12:13:02.668: INFO: Got endpoints: latency-svc-lwg5d [54.855865ms]
Nov 29 12:13:02.720: INFO: Created: latency-svc-rsr7k
Nov 29 12:13:02.723: INFO: Got endpoints: latency-svc-rsr7k [113.016926ms]
Nov 29 12:13:02.725: INFO: Created: latency-svc-kblxb
Nov 29 12:13:02.731: INFO: Got endpoints: latency-svc-kblxb [117.101454ms]
Nov 29 12:13:02.736: INFO: Created: latency-svc-xvx7l
Nov 29 12:13:02.742: INFO: Got endpoints: latency-svc-xvx7l [125.669777ms]
Nov 29 12:13:02.743: INFO: Created: latency-svc-gzqsp
Nov 29 12:13:02.747: INFO: Got endpoints: latency-svc-gzqsp [128.530283ms]
Nov 29 12:13:02.763: INFO: Created: latency-svc-g2msr
Nov 29 12:13:02.766: INFO: Got endpoints: latency-svc-g2msr [145.107834ms]
Nov 29 12:13:02.777: INFO: Created: latency-svc-6sdnf
Nov 29 12:13:02.779: INFO: Got endpoints: latency-svc-6sdnf [154.685651ms]
Nov 29 12:13:02.784: INFO: Created: latency-svc-47mbc
Nov 29 12:13:02.791: INFO: Got endpoints: latency-svc-47mbc [165.637829ms]
Nov 29 12:13:02.792: INFO: Created: latency-svc-hmgl2
Nov 29 12:13:02.794: INFO: Got endpoints: latency-svc-hmgl2 [167.890713ms]
Nov 29 12:13:02.798: INFO: Created: latency-svc-2mmtc
Nov 29 12:13:02.802: INFO: Got endpoints: latency-svc-2mmtc [171.679592ms]
Nov 29 12:13:02.804: INFO: Created: latency-svc-wgxvh
Nov 29 12:13:02.808: INFO: Got endpoints: latency-svc-wgxvh [171.94564ms]
Nov 29 12:13:02.810: INFO: Created: latency-svc-xwq8r
Nov 29 12:13:02.814: INFO: Created: latency-svc-fq2xp
Nov 29 12:13:02.815: INFO: Got endpoints: latency-svc-xwq8r [178.662587ms]
Nov 29 12:13:02.819: INFO: Created: latency-svc-2f4tk
Nov 29 12:13:02.820: INFO: Got endpoints: latency-svc-fq2xp [183.999293ms]
Nov 29 12:13:02.828: INFO: Got endpoints: latency-svc-2f4tk [191.689574ms]
Nov 29 12:13:02.829: INFO: Created: latency-svc-chccp
Nov 29 12:13:02.834: INFO: Got endpoints: latency-svc-chccp [185.492078ms]
Nov 29 12:13:02.834: INFO: Created: latency-svc-75874
Nov 29 12:13:02.843: INFO: Got endpoints: latency-svc-75874 [174.633429ms]
Nov 29 12:13:02.847: INFO: Created: latency-svc-kzbbs
Nov 29 12:13:02.872: INFO: Created: latency-svc-x2xzj
Nov 29 12:13:02.873: INFO: Got endpoints: latency-svc-kzbbs [149.950351ms]
Nov 29 12:13:02.877: INFO: Created: latency-svc-rjnf5
Nov 29 12:13:02.878: INFO: Got endpoints: latency-svc-x2xzj [147.260723ms]
Nov 29 12:13:02.886: INFO: Created: latency-svc-wxkz4
Nov 29 12:13:02.899: INFO: Got endpoints: latency-svc-rjnf5 [156.644253ms]
Nov 29 12:13:02.900: INFO: Created: latency-svc-74rb9
Nov 29 12:13:02.906: INFO: Created: latency-svc-pt8w4
Nov 29 12:13:02.909: INFO: Created: latency-svc-whtjj
Nov 29 12:13:02.913: INFO: Created: latency-svc-w9dgl
Nov 29 12:13:02.916: INFO: Created: latency-svc-h6fqs
Nov 29 12:13:02.921: INFO: Created: latency-svc-gdcxl
Nov 29 12:13:02.922: INFO: Created: latency-svc-m5nww
Nov 29 12:13:02.925: INFO: Created: latency-svc-8dcvk
Nov 29 12:13:02.928: INFO: Created: latency-svc-fxgn4
Nov 29 12:13:02.931: INFO: Created: latency-svc-lk2kc
Nov 29 12:13:02.937: INFO: Created: latency-svc-g95vz
Nov 29 12:13:02.938: INFO: Created: latency-svc-5fl5h
Nov 29 12:13:02.942: INFO: Got endpoints: latency-svc-wxkz4 [195.105732ms]
Nov 29 12:13:02.944: INFO: Created: latency-svc-zp44l
Nov 29 12:13:02.988: INFO: Created: latency-svc-htmt2
Nov 29 12:13:02.998: INFO: Got endpoints: latency-svc-74rb9 [232.392917ms]
Nov 29 12:13:03.001: INFO: Created: latency-svc-7bw6c
Nov 29 12:13:03.008: INFO: Created: latency-svc-xtxpw
Nov 29 12:13:03.042: INFO: Got endpoints: latency-svc-pt8w4 [262.6881ms]
Nov 29 12:13:03.049: INFO: Created: latency-svc-tc7dq
Nov 29 12:13:03.093: INFO: Got endpoints: latency-svc-whtjj [301.945169ms]
Nov 29 12:13:03.116: INFO: Created: latency-svc-m8dv9
Nov 29 12:13:03.142: INFO: Got endpoints: latency-svc-w9dgl [347.552334ms]
Nov 29 12:13:03.160: INFO: Created: latency-svc-hdjqz
Nov 29 12:13:03.194: INFO: Got endpoints: latency-svc-h6fqs [391.4086ms]
Nov 29 12:13:03.201: INFO: Created: latency-svc-dzwtw
Nov 29 12:13:03.241: INFO: Got endpoints: latency-svc-gdcxl [433.040241ms]
Nov 29 12:13:03.261: INFO: Created: latency-svc-bv65b
Nov 29 12:13:03.293: INFO: Got endpoints: latency-svc-m5nww [478.079856ms]
Nov 29 12:13:03.314: INFO: Created: latency-svc-987kk
Nov 29 12:13:03.342: INFO: Got endpoints: latency-svc-8dcvk [521.944643ms]
Nov 29 12:13:03.352: INFO: Created: latency-svc-v5867
Nov 29 12:13:03.394: INFO: Got endpoints: latency-svc-fxgn4 [565.274499ms]
Nov 29 12:13:03.409: INFO: Created: latency-svc-lt968
Nov 29 12:13:03.443: INFO: Got endpoints: latency-svc-lk2kc [609.032033ms]
Nov 29 12:13:03.450: INFO: Created: latency-svc-klfs8
Nov 29 12:13:03.492: INFO: Got endpoints: latency-svc-g95vz [648.687857ms]
Nov 29 12:13:03.498: INFO: Created: latency-svc-b6tgq
Nov 29 12:13:03.542: INFO: Got endpoints: latency-svc-5fl5h [669.019452ms]
Nov 29 12:13:03.598: INFO: Got endpoints: latency-svc-zp44l [720.01034ms]
Nov 29 12:13:03.684: INFO: Got endpoints: latency-svc-htmt2 [784.736556ms]
Nov 29 12:13:03.687: INFO: Created: latency-svc-zm57f
Nov 29 12:13:03.690: INFO: Created: latency-svc-xc8cr
Nov 29 12:13:03.692: INFO: Got endpoints: latency-svc-7bw6c [749.935131ms]
Nov 29 12:13:03.694: INFO: Created: latency-svc-dnvfb
Nov 29 12:13:03.715: INFO: Created: latency-svc-ltg9h
Nov 29 12:13:03.744: INFO: Got endpoints: latency-svc-xtxpw [745.225043ms]
Nov 29 12:13:03.750: INFO: Created: latency-svc-22wp9
Nov 29 12:13:03.792: INFO: Got endpoints: latency-svc-tc7dq [749.77879ms]
Nov 29 12:13:03.798: INFO: Created: latency-svc-nmr7h
Nov 29 12:13:03.841: INFO: Got endpoints: latency-svc-m8dv9 [748.547541ms]
Nov 29 12:13:03.847: INFO: Created: latency-svc-hc29n
Nov 29 12:13:03.892: INFO: Got endpoints: latency-svc-hdjqz [750.102392ms]
Nov 29 12:13:03.898: INFO: Created: latency-svc-czkg6
Nov 29 12:13:03.942: INFO: Got endpoints: latency-svc-dzwtw [748.019971ms]
Nov 29 12:13:03.959: INFO: Created: latency-svc-l9gqf
Nov 29 12:13:03.993: INFO: Got endpoints: latency-svc-bv65b [751.333169ms]
Nov 29 12:13:04.000: INFO: Created: latency-svc-d259r
Nov 29 12:13:04.042: INFO: Got endpoints: latency-svc-987kk [748.787809ms]
Nov 29 12:13:04.048: INFO: Created: latency-svc-sppzs
Nov 29 12:13:04.092: INFO: Got endpoints: latency-svc-v5867 [750.149539ms]
Nov 29 12:13:04.100: INFO: Created: latency-svc-r89lt
Nov 29 12:13:04.142: INFO: Got endpoints: latency-svc-lt968 [747.992764ms]
Nov 29 12:13:04.149: INFO: Created: latency-svc-7hjwb
Nov 29 12:13:04.192: INFO: Got endpoints: latency-svc-klfs8 [749.686496ms]
Nov 29 12:13:04.203: INFO: Created: latency-svc-vz57g
Nov 29 12:13:04.243: INFO: Got endpoints: latency-svc-b6tgq [750.865334ms]
Nov 29 12:13:04.249: INFO: Created: latency-svc-bjqfb
Nov 29 12:13:04.293: INFO: Got endpoints: latency-svc-zm57f [751.278089ms]
Nov 29 12:13:04.299: INFO: Created: latency-svc-ll9g8
Nov 29 12:13:04.342: INFO: Got endpoints: latency-svc-xc8cr [743.494386ms]
Nov 29 12:13:04.349: INFO: Created: latency-svc-qh4cm
Nov 29 12:13:04.393: INFO: Got endpoints: latency-svc-dnvfb [709.168441ms]
Nov 29 12:13:04.399: INFO: Created: latency-svc-fqqk9
Nov 29 12:13:04.441: INFO: Got endpoints: latency-svc-ltg9h [749.55077ms]
Nov 29 12:13:04.448: INFO: Created: latency-svc-j55b8
Nov 29 12:13:04.494: INFO: Got endpoints: latency-svc-22wp9 [749.918653ms]
Nov 29 12:13:04.528: INFO: Created: latency-svc-t2n84
Nov 29 12:13:04.542: INFO: Got endpoints: latency-svc-nmr7h [749.86859ms]
Nov 29 12:13:04.549: INFO: Created: latency-svc-pm6q2
Nov 29 12:13:04.592: INFO: Got endpoints: latency-svc-hc29n [751.083814ms]
Nov 29 12:13:04.600: INFO: Created: latency-svc-q8mbl
Nov 29 12:13:04.644: INFO: Got endpoints: latency-svc-czkg6 [751.874956ms]
Nov 29 12:13:04.649: INFO: Created: latency-svc-szk6q
Nov 29 12:13:04.692: INFO: Got endpoints: latency-svc-l9gqf [749.979215ms]
Nov 29 12:13:04.699: INFO: Created: latency-svc-nc8tg
Nov 29 12:13:04.741: INFO: Got endpoints: latency-svc-d259r [748.40499ms]
Nov 29 12:13:04.748: INFO: Created: latency-svc-g66hf
Nov 29 12:13:04.792: INFO: Got endpoints: latency-svc-sppzs [749.711684ms]
Nov 29 12:13:04.802: INFO: Created: latency-svc-cfnx8
Nov 29 12:13:04.842: INFO: Got endpoints: latency-svc-r89lt [749.827474ms]
Nov 29 12:13:04.849: INFO: Created: latency-svc-bgv6d
Nov 29 12:13:04.891: INFO: Got endpoints: latency-svc-7hjwb [749.627036ms]
Nov 29 12:13:04.900: INFO: Created: latency-svc-qqnjg
Nov 29 12:13:04.942: INFO: Got endpoints: latency-svc-vz57g [750.054494ms]
Nov 29 12:13:04.949: INFO: Created: latency-svc-pj56t
Nov 29 12:13:04.992: INFO: Got endpoints: latency-svc-bjqfb [749.072183ms]
Nov 29 12:13:05.001: INFO: Created: latency-svc-z4btx
Nov 29 12:13:05.043: INFO: Got endpoints: latency-svc-ll9g8 [749.014454ms]
Nov 29 12:13:05.067: INFO: Created: latency-svc-bzd5p
Nov 29 12:13:05.091: INFO: Got endpoints: latency-svc-qh4cm [749.549868ms]
Nov 29 12:13:05.105: INFO: Created: latency-svc-kv69p
Nov 29 12:13:05.142: INFO: Got endpoints: latency-svc-fqqk9 [749.13731ms]
Nov 29 12:13:05.151: INFO: Created: latency-svc-cgrqp
Nov 29 12:13:05.193: INFO: Got endpoints: latency-svc-j55b8 [752.04346ms]
Nov 29 12:13:05.200: INFO: Created: latency-svc-9sf7h
Nov 29 12:13:05.244: INFO: Got endpoints: latency-svc-t2n84 [750.480147ms]
Nov 29 12:13:05.288: INFO: Created: latency-svc-79hz7
Nov 29 12:13:05.292: INFO: Got endpoints: latency-svc-pm6q2 [750.228434ms]
Nov 29 12:13:05.298: INFO: Created: latency-svc-8crxn
Nov 29 12:13:05.342: INFO: Got endpoints: latency-svc-q8mbl [749.877224ms]
Nov 29 12:13:05.351: INFO: Created: latency-svc-8gz9h
Nov 29 12:13:05.393: INFO: Got endpoints: latency-svc-szk6q [748.891798ms]
Nov 29 12:13:05.405: INFO: Created: latency-svc-v5rtj
Nov 29 12:13:05.443: INFO: Got endpoints: latency-svc-nc8tg [750.662604ms]
Nov 29 12:13:05.457: INFO: Created: latency-svc-j4djc
Nov 29 12:13:05.493: INFO: Got endpoints: latency-svc-g66hf [751.97745ms]
Nov 29 12:13:05.499: INFO: Created: latency-svc-hfnjb
Nov 29 12:13:05.543: INFO: Got endpoints: latency-svc-cfnx8 [751.388147ms]
Nov 29 12:13:05.549: INFO: Created: latency-svc-5djvz
Nov 29 12:13:05.592: INFO: Got endpoints: latency-svc-bgv6d [749.348018ms]
Nov 29 12:13:05.600: INFO: Created: latency-svc-4d8fx
Nov 29 12:13:05.641: INFO: Got endpoints: latency-svc-qqnjg [749.961033ms]
Nov 29 12:13:05.650: INFO: Created: latency-svc-w8cmp
Nov 29 12:13:05.692: INFO: Got endpoints: latency-svc-pj56t [750.011274ms]
Nov 29 12:13:05.699: INFO: Created: latency-svc-9jdm4
Nov 29 12:13:05.743: INFO: Got endpoints: latency-svc-z4btx [750.793903ms]
Nov 29 12:13:05.751: INFO: Created: latency-svc-nnvlw
Nov 29 12:13:05.792: INFO: Got endpoints: latency-svc-bzd5p [749.234961ms]
Nov 29 12:13:05.798: INFO: Created: latency-svc-7zmwf
Nov 29 12:13:05.842: INFO: Got endpoints: latency-svc-kv69p [750.927654ms]
Nov 29 12:13:05.848: INFO: Created: latency-svc-gp982
Nov 29 12:13:05.892: INFO: Got endpoints: latency-svc-cgrqp [750.007998ms]
Nov 29 12:13:05.898: INFO: Created: latency-svc-njmd9
Nov 29 12:13:05.942: INFO: Got endpoints: latency-svc-9sf7h [748.031171ms]
Nov 29 12:13:05.966: INFO: Created: latency-svc-p2x9q
Nov 29 12:13:05.993: INFO: Got endpoints: latency-svc-79hz7 [749.333631ms]
Nov 29 12:13:06.001: INFO: Created: latency-svc-rws2h
Nov 29 12:13:06.042: INFO: Got endpoints: latency-svc-8crxn [749.321201ms]
Nov 29 12:13:06.060: INFO: Created: latency-svc-wrplm
Nov 29 12:13:06.092: INFO: Got endpoints: latency-svc-8gz9h [748.571683ms]
Nov 29 12:13:06.098: INFO: Created: latency-svc-9x667
Nov 29 12:13:06.155: INFO: Got endpoints: latency-svc-v5rtj [762.368206ms]
Nov 29 12:13:06.163: INFO: Created: latency-svc-g8srt
Nov 29 12:13:06.193: INFO: Got endpoints: latency-svc-j4djc [750.022739ms]
Nov 29 12:13:06.200: INFO: Created: latency-svc-lznn9
Nov 29 12:13:06.242: INFO: Got endpoints: latency-svc-hfnjb [748.500039ms]
Nov 29 12:13:06.249: INFO: Created: latency-svc-547nd
Nov 29 12:13:06.312: INFO: Got endpoints: latency-svc-5djvz [768.926997ms]
Nov 29 12:13:06.327: INFO: Created: latency-svc-r82w7
Nov 29 12:13:06.342: INFO: Got endpoints: latency-svc-4d8fx [750.44119ms]
Nov 29 12:13:06.352: INFO: Created: latency-svc-bg22c
Nov 29 12:13:06.392: INFO: Got endpoints: latency-svc-w8cmp [750.746311ms]
Nov 29 12:13:06.404: INFO: Created: latency-svc-44xx4
Nov 29 12:13:06.444: INFO: Got endpoints: latency-svc-9jdm4 [751.01816ms]
Nov 29 12:13:06.450: INFO: Created: latency-svc-8qdbf
Nov 29 12:13:06.493: INFO: Got endpoints: latency-svc-nnvlw [750.592636ms]
Nov 29 12:13:06.500: INFO: Created: latency-svc-6bbt4
Nov 29 12:13:06.544: INFO: Got endpoints: latency-svc-7zmwf [751.672076ms]
Nov 29 12:13:06.551: INFO: Created: latency-svc-5h8gb
Nov 29 12:13:06.593: INFO: Got endpoints: latency-svc-gp982 [750.548792ms]
Nov 29 12:13:06.599: INFO: Created: latency-svc-n28vl
Nov 29 12:13:06.654: INFO: Got endpoints: latency-svc-njmd9 [762.026382ms]
Nov 29 12:13:06.731: INFO: Created: latency-svc-twbg8
Nov 29 12:13:06.738: INFO: Got endpoints: latency-svc-p2x9q [795.904288ms]
Nov 29 12:13:06.755: INFO: Got endpoints: latency-svc-rws2h [761.696782ms]
Nov 29 12:13:06.831: INFO: Got endpoints: latency-svc-wrplm [789.721752ms]
Nov 29 12:13:06.832: INFO: Created: latency-svc-2gf2g
Nov 29 12:13:06.838: INFO: Created: latency-svc-d7hbd
Nov 29 12:13:06.842: INFO: Created: latency-svc-56jnd
Nov 29 12:13:06.843: INFO: Got endpoints: latency-svc-9x667 [750.804738ms]
Nov 29 12:13:06.871: INFO: Created: latency-svc-r82c2
Nov 29 12:13:06.893: INFO: Got endpoints: latency-svc-g8srt [738.059705ms]
Nov 29 12:13:06.899: INFO: Created: latency-svc-2mrx8
Nov 29 12:13:06.943: INFO: Got endpoints: latency-svc-lznn9 [750.155562ms]
Nov 29 12:13:06.948: INFO: Created: latency-svc-tfw2s
Nov 29 12:13:06.992: INFO: Got endpoints: latency-svc-547nd [750.16087ms]
Nov 29 12:13:07.000: INFO: Created: latency-svc-j9gm2
Nov 29 12:13:07.044: INFO: Got endpoints: latency-svc-r82w7 [731.434693ms]
Nov 29 12:13:07.050: INFO: Created: latency-svc-hz6zw
Nov 29 12:13:07.100: INFO: Got endpoints: latency-svc-bg22c [757.558408ms]
Nov 29 12:13:07.108: INFO: Created: latency-svc-sd79c
Nov 29 12:13:07.142: INFO: Got endpoints: latency-svc-44xx4 [750.168377ms]
Nov 29 12:13:07.164: INFO: Created: latency-svc-d9gr6
Nov 29 12:13:07.192: INFO: Got endpoints: latency-svc-8qdbf [748.735874ms]
Nov 29 12:13:07.199: INFO: Created: latency-svc-dzw5k
Nov 29 12:13:07.243: INFO: Got endpoints: latency-svc-6bbt4 [749.350769ms]
Nov 29 12:13:07.249: INFO: Created: latency-svc-4shcd
Nov 29 12:13:07.291: INFO: Got endpoints: latency-svc-5h8gb [747.808746ms]
Nov 29 12:13:07.300: INFO: Created: latency-svc-t44ml
Nov 29 12:13:07.342: INFO: Got endpoints: latency-svc-n28vl [748.912264ms]
Nov 29 12:13:07.349: INFO: Created: latency-svc-k5t6z
Nov 29 12:13:07.394: INFO: Got endpoints: latency-svc-twbg8 [739.63388ms]
Nov 29 12:13:07.401: INFO: Created: latency-svc-r756x
Nov 29 12:13:07.443: INFO: Got endpoints: latency-svc-2gf2g [705.401837ms]
Nov 29 12:13:07.449: INFO: Created: latency-svc-xmn66
Nov 29 12:13:07.492: INFO: Got endpoints: latency-svc-d7hbd [737.149464ms]
Nov 29 12:13:07.501: INFO: Created: latency-svc-9hkx9
Nov 29 12:13:07.553: INFO: Got endpoints: latency-svc-56jnd [721.209605ms]
Nov 29 12:13:07.559: INFO: Created: latency-svc-hwlwc
Nov 29 12:13:07.593: INFO: Got endpoints: latency-svc-r82c2 [749.823791ms]
Nov 29 12:13:07.602: INFO: Created: latency-svc-mlswx
Nov 29 12:13:07.642: INFO: Got endpoints: latency-svc-2mrx8 [748.338997ms]
Nov 29 12:13:07.649: INFO: Created: latency-svc-7w4bx
Nov 29 12:13:07.692: INFO: Got endpoints: latency-svc-tfw2s [749.342223ms]
Nov 29 12:13:07.707: INFO: Created: latency-svc-rhfhr
Nov 29 12:13:07.742: INFO: Got endpoints: latency-svc-j9gm2 [750.048303ms]
Nov 29 12:13:07.749: INFO: Created: latency-svc-glzlk
Nov 29 12:13:07.793: INFO: Got endpoints: latency-svc-hz6zw [748.860769ms]
Nov 29 12:13:07.799: INFO: Created: latency-svc-5hl5g
Nov 29 12:13:07.844: INFO: Got endpoints: latency-svc-sd79c [743.990991ms]
Nov 29 12:13:07.850: INFO: Created: latency-svc-mqwtm
Nov 29 12:13:07.893: INFO: Got endpoints: latency-svc-d9gr6 [750.30731ms]
Nov 29 12:13:07.899: INFO: Created: latency-svc-bzh89
Nov 29 12:13:07.942: INFO: Got endpoints: latency-svc-dzw5k [749.967105ms]
Nov 29 12:13:07.948: INFO: Created: latency-svc-q9hmz
Nov 29 12:13:07.994: INFO: Got endpoints: latency-svc-4shcd [750.713227ms]
Nov 29 12:13:08.002: INFO: Created: latency-svc-q9jfq
Nov 29 12:13:08.045: INFO: Got endpoints: latency-svc-t44ml [753.209939ms]
Nov 29 12:13:08.052: INFO: Created: latency-svc-78wtg
Nov 29 12:13:08.092: INFO: Got endpoints: latency-svc-k5t6z [749.959749ms]
Nov 29 12:13:08.104: INFO: Created: latency-svc-6sjjv
Nov 29 12:13:08.143: INFO: Got endpoints: latency-svc-r756x [749.511439ms]
Nov 29 12:13:08.157: INFO: Created: latency-svc-44jqz
Nov 29 12:13:08.193: INFO: Got endpoints: latency-svc-xmn66 [750.209132ms]
Nov 29 12:13:08.200: INFO: Created: latency-svc-bs92d
Nov 29 12:13:08.244: INFO: Got endpoints: latency-svc-9hkx9 [751.671117ms]
Nov 29 12:13:08.257: INFO: Created: latency-svc-c4rkt
Nov 29 12:13:08.291: INFO: Got endpoints: latency-svc-hwlwc [738.69602ms]
Nov 29 12:13:08.310: INFO: Created: latency-svc-fbgsb
Nov 29 12:13:08.341: INFO: Got endpoints: latency-svc-mlswx [748.802525ms]
Nov 29 12:13:08.357: INFO: Created: latency-svc-sxmmv
Nov 29 12:13:08.392: INFO: Got endpoints: latency-svc-7w4bx [749.795098ms]
Nov 29 12:13:08.458: INFO: Created: latency-svc-fk6vv
Nov 29 12:13:08.458: INFO: Got endpoints: latency-svc-rhfhr [766.007365ms]
Nov 29 12:13:08.465: INFO: Created: latency-svc-wkhcf
Nov 29 12:13:08.493: INFO: Got endpoints: latency-svc-glzlk [750.1385ms]
Nov 29 12:13:08.499: INFO: Created: latency-svc-f4cxh
Nov 29 12:13:08.543: INFO: Got endpoints: latency-svc-5hl5g [749.857363ms]
Nov 29 12:13:08.556: INFO: Created: latency-svc-pt95b
Nov 29 12:13:08.593: INFO: Got endpoints: latency-svc-mqwtm [748.864011ms]
Nov 29 12:13:08.602: INFO: Created: latency-svc-b8lms
Nov 29 12:13:08.641: INFO: Got endpoints: latency-svc-bzh89 [748.794227ms]
Nov 29 12:13:08.649: INFO: Created: latency-svc-zqd5j
Nov 29 12:13:08.694: INFO: Got endpoints: latency-svc-q9hmz [751.069106ms]
Nov 29 12:13:08.700: INFO: Created: latency-svc-g6pbn
Nov 29 12:13:08.750: INFO: Got endpoints: latency-svc-q9jfq [755.923404ms]
Nov 29 12:13:08.756: INFO: Created: latency-svc-7xkts
Nov 29 12:13:08.792: INFO: Got endpoints: latency-svc-78wtg [747.775842ms]
Nov 29 12:13:08.801: INFO: Created: latency-svc-w7p9s
Nov 29 12:13:08.841: INFO: Got endpoints: latency-svc-6sjjv [748.629609ms]
Nov 29 12:13:08.917: INFO: Got endpoints: latency-svc-44jqz [773.227273ms]
Nov 29 12:13:08.922: INFO: Created: latency-svc-qqbrz
Nov 29 12:13:08.925: INFO: Created: latency-svc-88f9f
Nov 29 12:13:08.953: INFO: Got endpoints: latency-svc-bs92d [759.531738ms]
Nov 29 12:13:08.960: INFO: Created: latency-svc-tq259
Nov 29 12:13:08.992: INFO: Got endpoints: latency-svc-c4rkt [747.693077ms]
Nov 29 12:13:09.010: INFO: Created: latency-svc-xgdzg
Nov 29 12:13:09.045: INFO: Got endpoints: latency-svc-fbgsb [753.758787ms]
Nov 29 12:13:09.060: INFO: Created: latency-svc-5l68d
Nov 29 12:13:09.092: INFO: Got endpoints: latency-svc-sxmmv [750.139979ms]
Nov 29 12:13:09.098: INFO: Created: latency-svc-r7bg5
Nov 29 12:13:09.153: INFO: Got endpoints: latency-svc-fk6vv [761.621148ms]
Nov 29 12:13:09.169: INFO: Created: latency-svc-76b5w
Nov 29 12:13:09.192: INFO: Got endpoints: latency-svc-wkhcf [733.901147ms]
Nov 29 12:13:09.199: INFO: Created: latency-svc-tk7kv
Nov 29 12:13:09.243: INFO: Got endpoints: latency-svc-f4cxh [750.510406ms]
Nov 29 12:13:09.249: INFO: Created: latency-svc-r4vxj
Nov 29 12:13:09.293: INFO: Got endpoints: latency-svc-pt95b [750.336974ms]
Nov 29 12:13:09.299: INFO: Created: latency-svc-7jlg8
Nov 29 12:13:09.343: INFO: Got endpoints: latency-svc-b8lms [749.731159ms]
Nov 29 12:13:09.349: INFO: Created: latency-svc-cnnj2
Nov 29 12:13:09.393: INFO: Got endpoints: latency-svc-zqd5j [751.100558ms]
Nov 29 12:13:09.400: INFO: Created: latency-svc-jfvj4
Nov 29 12:13:09.444: INFO: Got endpoints: latency-svc-g6pbn [749.973673ms]
Nov 29 12:13:09.449: INFO: Created: latency-svc-2kmfz
Nov 29 12:13:09.493: INFO: Got endpoints: latency-svc-7xkts [743.21444ms]
Nov 29 12:13:09.499: INFO: Created: latency-svc-q7cxj
Nov 29 12:13:09.542: INFO: Got endpoints: latency-svc-w7p9s [749.454353ms]
Nov 29 12:13:09.559: INFO: Created: latency-svc-nzc5g
Nov 29 12:13:09.593: INFO: Got endpoints: latency-svc-qqbrz [751.967518ms]
Nov 29 12:13:09.598: INFO: Created: latency-svc-82jrr
Nov 29 12:13:09.641: INFO: Got endpoints: latency-svc-88f9f [724.500971ms]
Nov 29 12:13:09.648: INFO: Created: latency-svc-5gsw7
Nov 29 12:13:09.692: INFO: Got endpoints: latency-svc-tq259 [738.800707ms]
Nov 29 12:13:09.698: INFO: Created: latency-svc-fgb4w
Nov 29 12:13:09.742: INFO: Got endpoints: latency-svc-xgdzg [749.767841ms]
Nov 29 12:13:09.749: INFO: Created: latency-svc-vrxqt
Nov 29 12:13:09.793: INFO: Got endpoints: latency-svc-5l68d [747.581692ms]
Nov 29 12:13:09.803: INFO: Created: latency-svc-ttj6s
Nov 29 12:13:09.843: INFO: Got endpoints: latency-svc-r7bg5 [751.776831ms]
Nov 29 12:13:09.849: INFO: Created: latency-svc-pfr6d
Nov 29 12:13:09.894: INFO: Got endpoints: latency-svc-76b5w [740.52817ms]
Nov 29 12:13:09.900: INFO: Created: latency-svc-fh5v4
Nov 29 12:13:09.942: INFO: Got endpoints: latency-svc-tk7kv [749.631801ms]
Nov 29 12:13:09.954: INFO: Created: latency-svc-svmpm
Nov 29 12:13:09.992: INFO: Got endpoints: latency-svc-r4vxj [748.163585ms]
Nov 29 12:13:10.003: INFO: Created: latency-svc-w9bp8
Nov 29 12:13:10.042: INFO: Got endpoints: latency-svc-7jlg8 [749.381095ms]
Nov 29 12:13:10.049: INFO: Created: latency-svc-99vtn
Nov 29 12:13:10.092: INFO: Got endpoints: latency-svc-cnnj2 [749.451383ms]
Nov 29 12:13:10.098: INFO: Created: latency-svc-p99kt
Nov 29 12:13:10.141: INFO: Got endpoints: latency-svc-jfvj4 [748.354027ms]
Nov 29 12:13:10.147: INFO: Created: latency-svc-q4sq9
Nov 29 12:13:10.194: INFO: Got endpoints: latency-svc-2kmfz [750.751163ms]
Nov 29 12:13:10.200: INFO: Created: latency-svc-n5c7x
Nov 29 12:13:10.241: INFO: Got endpoints: latency-svc-q7cxj [748.595043ms]
Nov 29 12:13:10.247: INFO: Created: latency-svc-cfj8s
Nov 29 12:13:10.292: INFO: Got endpoints: latency-svc-nzc5g [750.171088ms]
Nov 29 12:13:10.298: INFO: Created: latency-svc-bvv2m
Nov 29 12:13:10.343: INFO: Got endpoints: latency-svc-82jrr [750.458566ms]
Nov 29 12:13:10.392: INFO: Got endpoints: latency-svc-5gsw7 [750.597333ms]
Nov 29 12:13:10.442: INFO: Got endpoints: latency-svc-fgb4w [749.951249ms]
Nov 29 12:13:10.491: INFO: Got endpoints: latency-svc-vrxqt [749.821927ms]
Nov 29 12:13:10.542: INFO: Got endpoints: latency-svc-ttj6s [748.808587ms]
Nov 29 12:13:10.592: INFO: Got endpoints: latency-svc-pfr6d [748.947849ms]
Nov 29 12:13:10.644: INFO: Got endpoints: latency-svc-fh5v4 [750.131805ms]
Nov 29 12:13:10.692: INFO: Got endpoints: latency-svc-svmpm [749.639507ms]
Nov 29 12:13:10.742: INFO: Got endpoints: latency-svc-w9bp8 [749.807135ms]
Nov 29 12:13:10.793: INFO: Got endpoints: latency-svc-99vtn [750.198556ms]
Nov 29 12:13:10.844: INFO: Got endpoints: latency-svc-p99kt [752.274376ms]
Nov 29 12:13:10.893: INFO: Got endpoints: latency-svc-q4sq9 [751.723201ms]
Nov 29 12:13:10.942: INFO: Got endpoints: latency-svc-n5c7x [747.077812ms]
Nov 29 12:13:10.991: INFO: Got endpoints: latency-svc-cfj8s [749.985746ms]
Nov 29 12:13:11.042: INFO: Got endpoints: latency-svc-bvv2m [749.362158ms]
Nov 29 12:13:11.042: INFO: Latencies: [12.719616ms 22.615ms 34.133686ms 54.855865ms 110.98223ms 113.016926ms 117.101454ms 117.101794ms 120.404329ms 120.451839ms 120.659847ms 123.524667ms 125.190003ms 125.669777ms 127.959174ms 128.530283ms 130.689051ms 131.497776ms 132.129298ms 137.209526ms 143.113944ms 143.333479ms 143.714499ms 145.107834ms 147.260723ms 149.950351ms 154.685651ms 156.644253ms 165.637829ms 167.890713ms 171.679592ms 171.94564ms 174.633429ms 178.662587ms 183.999293ms 185.492078ms 191.689574ms 195.105732ms 232.392917ms 262.6881ms 301.945169ms 347.552334ms 391.4086ms 433.040241ms 478.079856ms 521.944643ms 565.274499ms 609.032033ms 648.687857ms 669.019452ms 705.401837ms 709.168441ms 720.01034ms 721.209605ms 724.500971ms 731.434693ms 733.901147ms 737.149464ms 738.059705ms 738.69602ms 738.800707ms 739.63388ms 740.52817ms 743.21444ms 743.494386ms 743.990991ms 745.225043ms 747.077812ms 747.581692ms 747.693077ms 747.775842ms 747.808746ms 747.992764ms 748.019971ms 748.031171ms 748.163585ms 748.338997ms 748.354027ms 748.40499ms 748.500039ms 748.547541ms 748.571683ms 748.595043ms 748.629609ms 748.735874ms 748.787809ms 748.794227ms 748.802525ms 748.808587ms 748.860769ms 748.864011ms 748.891798ms 748.912264ms 748.947849ms 749.014454ms 749.072183ms 749.13731ms 749.234961ms 749.321201ms 749.333631ms 749.342223ms 749.348018ms 749.350769ms 749.362158ms 749.381095ms 749.451383ms 749.454353ms 749.511439ms 749.549868ms 749.55077ms 749.627036ms 749.631801ms 749.639507ms 749.686496ms 749.711684ms 749.731159ms 749.767841ms 749.77879ms 749.795098ms 749.807135ms 749.821927ms 749.823791ms 749.827474ms 749.857363ms 749.86859ms 749.877224ms 749.918653ms 749.935131ms 749.951249ms 749.959749ms 749.961033ms 749.967105ms 749.973673ms 749.979215ms 749.985746ms 750.007998ms 750.011274ms 750.022739ms 750.048303ms 750.054494ms 750.102392ms 750.131805ms 750.1385ms 750.139979ms 750.149539ms 750.155562ms 750.16087ms 750.168377ms 750.171088ms 750.198556ms 750.209132ms 750.228434ms 750.30731ms 750.336974ms 750.44119ms 750.458566ms 750.480147ms 750.510406ms 750.548792ms 750.592636ms 750.597333ms 750.662604ms 750.713227ms 750.746311ms 750.751163ms 750.793903ms 750.804738ms 750.865334ms 750.927654ms 751.01816ms 751.069106ms 751.083814ms 751.100558ms 751.278089ms 751.333169ms 751.388147ms 751.671117ms 751.672076ms 751.723201ms 751.776831ms 751.874956ms 751.967518ms 751.97745ms 752.04346ms 752.274376ms 753.209939ms 753.758787ms 755.923404ms 757.558408ms 759.531738ms 761.621148ms 761.696782ms 762.026382ms 762.368206ms 766.007365ms 768.926997ms 773.227273ms 784.736556ms 789.721752ms 795.904288ms]
Nov 29 12:13:11.042: INFO: 50 %ile: 749.342223ms
Nov 29 12:13:11.042: INFO: 90 %ile: 751.874956ms
Nov 29 12:13:11.042: INFO: 99 %ile: 789.721752ms
Nov 29 12:13:11.042: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Nov 29 12:13:11.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-422" for this suite. 11/29/22 12:13:11.048
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":164,"skipped":3036,"failed":0}
------------------------------
• [SLOW TEST] [10.754 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:13:00.298
    Nov 29 12:13:00.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename svc-latency 11/29/22 12:13:00.299
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:00.311
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:00.314
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Nov 29 12:13:00.323: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-422 11/29/22 12:13:00.324
    I1129 12:13:00.330428      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-422, replica count: 1
    I1129 12:13:01.381709      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:13:02.382214      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 12:13:02.488: INFO: Created: latency-svc-wn8dk
    Nov 29 12:13:02.492: INFO: Got endpoints: latency-svc-wn8dk [10.037959ms]
    Nov 29 12:13:02.501: INFO: Created: latency-svc-97qt4
    Nov 29 12:13:02.505: INFO: Got endpoints: latency-svc-97qt4 [12.719616ms]
    Nov 29 12:13:02.511: INFO: Created: latency-svc-8gn2p
    Nov 29 12:13:02.515: INFO: Got endpoints: latency-svc-8gn2p [22.615ms]
    Nov 29 12:13:02.594: INFO: Created: latency-svc-v9jht
    Nov 29 12:13:02.594: INFO: Created: latency-svc-qvtjs
    Nov 29 12:13:02.595: INFO: Created: latency-svc-tjlfl
    Nov 29 12:13:02.595: INFO: Created: latency-svc-t5wbw
    Nov 29 12:13:02.605: INFO: Created: latency-svc-766vh
    Nov 29 12:13:02.605: INFO: Created: latency-svc-njc59
    Nov 29 12:13:02.605: INFO: Created: latency-svc-pz5hk
    Nov 29 12:13:02.605: INFO: Created: latency-svc-6kt7t
    Nov 29 12:13:02.607: INFO: Created: latency-svc-ntv5r
    Nov 29 12:13:02.607: INFO: Created: latency-svc-vhdfs
    Nov 29 12:13:02.608: INFO: Created: latency-svc-hvpp7
    Nov 29 12:13:02.610: INFO: Got endpoints: latency-svc-t5wbw [117.101794ms]
    Nov 29 12:13:02.610: INFO: Created: latency-svc-w9xhp
    Nov 29 12:13:02.610: INFO: Created: latency-svc-z9bxl
    Nov 29 12:13:02.613: INFO: Created: latency-svc-2nxzs
    Nov 29 12:13:02.613: INFO: Got endpoints: latency-svc-tjlfl [120.451839ms]
    Nov 29 12:13:02.614: INFO: Got endpoints: latency-svc-qvtjs [120.404329ms]
    Nov 29 12:13:02.614: INFO: Got endpoints: latency-svc-v9jht [120.659847ms]
    Nov 29 12:13:02.614: INFO: Created: latency-svc-g96k8
    Nov 29 12:13:02.617: INFO: Got endpoints: latency-svc-njc59 [123.524667ms]
    Nov 29 12:13:02.618: INFO: Got endpoints: latency-svc-ntv5r [125.190003ms]
    Nov 29 12:13:02.621: INFO: Got endpoints: latency-svc-hvpp7 [127.959174ms]
    Nov 29 12:13:02.625: INFO: Got endpoints: latency-svc-w9xhp [131.497776ms]
    Nov 29 12:13:02.625: INFO: Got endpoints: latency-svc-z9bxl [132.129298ms]
    Nov 29 12:13:02.626: INFO: Got endpoints: latency-svc-2nxzs [110.98223ms]
    Nov 29 12:13:02.630: INFO: Got endpoints: latency-svc-g96k8 [137.209526ms]
    Nov 29 12:13:02.636: INFO: Created: latency-svc-qsz72
    Nov 29 12:13:02.636: INFO: Got endpoints: latency-svc-vhdfs [130.689051ms]
    Nov 29 12:13:02.636: INFO: Got endpoints: latency-svc-766vh [143.113944ms]
    Nov 29 12:13:02.636: INFO: Got endpoints: latency-svc-pz5hk [143.333479ms]
    Nov 29 12:13:02.637: INFO: Got endpoints: latency-svc-6kt7t [143.714499ms]
    Nov 29 12:13:02.648: INFO: Got endpoints: latency-svc-qsz72 [34.133686ms]
    Nov 29 12:13:02.659: INFO: Created: latency-svc-lwg5d
    Nov 29 12:13:02.668: INFO: Got endpoints: latency-svc-lwg5d [54.855865ms]
    Nov 29 12:13:02.720: INFO: Created: latency-svc-rsr7k
    Nov 29 12:13:02.723: INFO: Got endpoints: latency-svc-rsr7k [113.016926ms]
    Nov 29 12:13:02.725: INFO: Created: latency-svc-kblxb
    Nov 29 12:13:02.731: INFO: Got endpoints: latency-svc-kblxb [117.101454ms]
    Nov 29 12:13:02.736: INFO: Created: latency-svc-xvx7l
    Nov 29 12:13:02.742: INFO: Got endpoints: latency-svc-xvx7l [125.669777ms]
    Nov 29 12:13:02.743: INFO: Created: latency-svc-gzqsp
    Nov 29 12:13:02.747: INFO: Got endpoints: latency-svc-gzqsp [128.530283ms]
    Nov 29 12:13:02.763: INFO: Created: latency-svc-g2msr
    Nov 29 12:13:02.766: INFO: Got endpoints: latency-svc-g2msr [145.107834ms]
    Nov 29 12:13:02.777: INFO: Created: latency-svc-6sdnf
    Nov 29 12:13:02.779: INFO: Got endpoints: latency-svc-6sdnf [154.685651ms]
    Nov 29 12:13:02.784: INFO: Created: latency-svc-47mbc
    Nov 29 12:13:02.791: INFO: Got endpoints: latency-svc-47mbc [165.637829ms]
    Nov 29 12:13:02.792: INFO: Created: latency-svc-hmgl2
    Nov 29 12:13:02.794: INFO: Got endpoints: latency-svc-hmgl2 [167.890713ms]
    Nov 29 12:13:02.798: INFO: Created: latency-svc-2mmtc
    Nov 29 12:13:02.802: INFO: Got endpoints: latency-svc-2mmtc [171.679592ms]
    Nov 29 12:13:02.804: INFO: Created: latency-svc-wgxvh
    Nov 29 12:13:02.808: INFO: Got endpoints: latency-svc-wgxvh [171.94564ms]
    Nov 29 12:13:02.810: INFO: Created: latency-svc-xwq8r
    Nov 29 12:13:02.814: INFO: Created: latency-svc-fq2xp
    Nov 29 12:13:02.815: INFO: Got endpoints: latency-svc-xwq8r [178.662587ms]
    Nov 29 12:13:02.819: INFO: Created: latency-svc-2f4tk
    Nov 29 12:13:02.820: INFO: Got endpoints: latency-svc-fq2xp [183.999293ms]
    Nov 29 12:13:02.828: INFO: Got endpoints: latency-svc-2f4tk [191.689574ms]
    Nov 29 12:13:02.829: INFO: Created: latency-svc-chccp
    Nov 29 12:13:02.834: INFO: Got endpoints: latency-svc-chccp [185.492078ms]
    Nov 29 12:13:02.834: INFO: Created: latency-svc-75874
    Nov 29 12:13:02.843: INFO: Got endpoints: latency-svc-75874 [174.633429ms]
    Nov 29 12:13:02.847: INFO: Created: latency-svc-kzbbs
    Nov 29 12:13:02.872: INFO: Created: latency-svc-x2xzj
    Nov 29 12:13:02.873: INFO: Got endpoints: latency-svc-kzbbs [149.950351ms]
    Nov 29 12:13:02.877: INFO: Created: latency-svc-rjnf5
    Nov 29 12:13:02.878: INFO: Got endpoints: latency-svc-x2xzj [147.260723ms]
    Nov 29 12:13:02.886: INFO: Created: latency-svc-wxkz4
    Nov 29 12:13:02.899: INFO: Got endpoints: latency-svc-rjnf5 [156.644253ms]
    Nov 29 12:13:02.900: INFO: Created: latency-svc-74rb9
    Nov 29 12:13:02.906: INFO: Created: latency-svc-pt8w4
    Nov 29 12:13:02.909: INFO: Created: latency-svc-whtjj
    Nov 29 12:13:02.913: INFO: Created: latency-svc-w9dgl
    Nov 29 12:13:02.916: INFO: Created: latency-svc-h6fqs
    Nov 29 12:13:02.921: INFO: Created: latency-svc-gdcxl
    Nov 29 12:13:02.922: INFO: Created: latency-svc-m5nww
    Nov 29 12:13:02.925: INFO: Created: latency-svc-8dcvk
    Nov 29 12:13:02.928: INFO: Created: latency-svc-fxgn4
    Nov 29 12:13:02.931: INFO: Created: latency-svc-lk2kc
    Nov 29 12:13:02.937: INFO: Created: latency-svc-g95vz
    Nov 29 12:13:02.938: INFO: Created: latency-svc-5fl5h
    Nov 29 12:13:02.942: INFO: Got endpoints: latency-svc-wxkz4 [195.105732ms]
    Nov 29 12:13:02.944: INFO: Created: latency-svc-zp44l
    Nov 29 12:13:02.988: INFO: Created: latency-svc-htmt2
    Nov 29 12:13:02.998: INFO: Got endpoints: latency-svc-74rb9 [232.392917ms]
    Nov 29 12:13:03.001: INFO: Created: latency-svc-7bw6c
    Nov 29 12:13:03.008: INFO: Created: latency-svc-xtxpw
    Nov 29 12:13:03.042: INFO: Got endpoints: latency-svc-pt8w4 [262.6881ms]
    Nov 29 12:13:03.049: INFO: Created: latency-svc-tc7dq
    Nov 29 12:13:03.093: INFO: Got endpoints: latency-svc-whtjj [301.945169ms]
    Nov 29 12:13:03.116: INFO: Created: latency-svc-m8dv9
    Nov 29 12:13:03.142: INFO: Got endpoints: latency-svc-w9dgl [347.552334ms]
    Nov 29 12:13:03.160: INFO: Created: latency-svc-hdjqz
    Nov 29 12:13:03.194: INFO: Got endpoints: latency-svc-h6fqs [391.4086ms]
    Nov 29 12:13:03.201: INFO: Created: latency-svc-dzwtw
    Nov 29 12:13:03.241: INFO: Got endpoints: latency-svc-gdcxl [433.040241ms]
    Nov 29 12:13:03.261: INFO: Created: latency-svc-bv65b
    Nov 29 12:13:03.293: INFO: Got endpoints: latency-svc-m5nww [478.079856ms]
    Nov 29 12:13:03.314: INFO: Created: latency-svc-987kk
    Nov 29 12:13:03.342: INFO: Got endpoints: latency-svc-8dcvk [521.944643ms]
    Nov 29 12:13:03.352: INFO: Created: latency-svc-v5867
    Nov 29 12:13:03.394: INFO: Got endpoints: latency-svc-fxgn4 [565.274499ms]
    Nov 29 12:13:03.409: INFO: Created: latency-svc-lt968
    Nov 29 12:13:03.443: INFO: Got endpoints: latency-svc-lk2kc [609.032033ms]
    Nov 29 12:13:03.450: INFO: Created: latency-svc-klfs8
    Nov 29 12:13:03.492: INFO: Got endpoints: latency-svc-g95vz [648.687857ms]
    Nov 29 12:13:03.498: INFO: Created: latency-svc-b6tgq
    Nov 29 12:13:03.542: INFO: Got endpoints: latency-svc-5fl5h [669.019452ms]
    Nov 29 12:13:03.598: INFO: Got endpoints: latency-svc-zp44l [720.01034ms]
    Nov 29 12:13:03.684: INFO: Got endpoints: latency-svc-htmt2 [784.736556ms]
    Nov 29 12:13:03.687: INFO: Created: latency-svc-zm57f
    Nov 29 12:13:03.690: INFO: Created: latency-svc-xc8cr
    Nov 29 12:13:03.692: INFO: Got endpoints: latency-svc-7bw6c [749.935131ms]
    Nov 29 12:13:03.694: INFO: Created: latency-svc-dnvfb
    Nov 29 12:13:03.715: INFO: Created: latency-svc-ltg9h
    Nov 29 12:13:03.744: INFO: Got endpoints: latency-svc-xtxpw [745.225043ms]
    Nov 29 12:13:03.750: INFO: Created: latency-svc-22wp9
    Nov 29 12:13:03.792: INFO: Got endpoints: latency-svc-tc7dq [749.77879ms]
    Nov 29 12:13:03.798: INFO: Created: latency-svc-nmr7h
    Nov 29 12:13:03.841: INFO: Got endpoints: latency-svc-m8dv9 [748.547541ms]
    Nov 29 12:13:03.847: INFO: Created: latency-svc-hc29n
    Nov 29 12:13:03.892: INFO: Got endpoints: latency-svc-hdjqz [750.102392ms]
    Nov 29 12:13:03.898: INFO: Created: latency-svc-czkg6
    Nov 29 12:13:03.942: INFO: Got endpoints: latency-svc-dzwtw [748.019971ms]
    Nov 29 12:13:03.959: INFO: Created: latency-svc-l9gqf
    Nov 29 12:13:03.993: INFO: Got endpoints: latency-svc-bv65b [751.333169ms]
    Nov 29 12:13:04.000: INFO: Created: latency-svc-d259r
    Nov 29 12:13:04.042: INFO: Got endpoints: latency-svc-987kk [748.787809ms]
    Nov 29 12:13:04.048: INFO: Created: latency-svc-sppzs
    Nov 29 12:13:04.092: INFO: Got endpoints: latency-svc-v5867 [750.149539ms]
    Nov 29 12:13:04.100: INFO: Created: latency-svc-r89lt
    Nov 29 12:13:04.142: INFO: Got endpoints: latency-svc-lt968 [747.992764ms]
    Nov 29 12:13:04.149: INFO: Created: latency-svc-7hjwb
    Nov 29 12:13:04.192: INFO: Got endpoints: latency-svc-klfs8 [749.686496ms]
    Nov 29 12:13:04.203: INFO: Created: latency-svc-vz57g
    Nov 29 12:13:04.243: INFO: Got endpoints: latency-svc-b6tgq [750.865334ms]
    Nov 29 12:13:04.249: INFO: Created: latency-svc-bjqfb
    Nov 29 12:13:04.293: INFO: Got endpoints: latency-svc-zm57f [751.278089ms]
    Nov 29 12:13:04.299: INFO: Created: latency-svc-ll9g8
    Nov 29 12:13:04.342: INFO: Got endpoints: latency-svc-xc8cr [743.494386ms]
    Nov 29 12:13:04.349: INFO: Created: latency-svc-qh4cm
    Nov 29 12:13:04.393: INFO: Got endpoints: latency-svc-dnvfb [709.168441ms]
    Nov 29 12:13:04.399: INFO: Created: latency-svc-fqqk9
    Nov 29 12:13:04.441: INFO: Got endpoints: latency-svc-ltg9h [749.55077ms]
    Nov 29 12:13:04.448: INFO: Created: latency-svc-j55b8
    Nov 29 12:13:04.494: INFO: Got endpoints: latency-svc-22wp9 [749.918653ms]
    Nov 29 12:13:04.528: INFO: Created: latency-svc-t2n84
    Nov 29 12:13:04.542: INFO: Got endpoints: latency-svc-nmr7h [749.86859ms]
    Nov 29 12:13:04.549: INFO: Created: latency-svc-pm6q2
    Nov 29 12:13:04.592: INFO: Got endpoints: latency-svc-hc29n [751.083814ms]
    Nov 29 12:13:04.600: INFO: Created: latency-svc-q8mbl
    Nov 29 12:13:04.644: INFO: Got endpoints: latency-svc-czkg6 [751.874956ms]
    Nov 29 12:13:04.649: INFO: Created: latency-svc-szk6q
    Nov 29 12:13:04.692: INFO: Got endpoints: latency-svc-l9gqf [749.979215ms]
    Nov 29 12:13:04.699: INFO: Created: latency-svc-nc8tg
    Nov 29 12:13:04.741: INFO: Got endpoints: latency-svc-d259r [748.40499ms]
    Nov 29 12:13:04.748: INFO: Created: latency-svc-g66hf
    Nov 29 12:13:04.792: INFO: Got endpoints: latency-svc-sppzs [749.711684ms]
    Nov 29 12:13:04.802: INFO: Created: latency-svc-cfnx8
    Nov 29 12:13:04.842: INFO: Got endpoints: latency-svc-r89lt [749.827474ms]
    Nov 29 12:13:04.849: INFO: Created: latency-svc-bgv6d
    Nov 29 12:13:04.891: INFO: Got endpoints: latency-svc-7hjwb [749.627036ms]
    Nov 29 12:13:04.900: INFO: Created: latency-svc-qqnjg
    Nov 29 12:13:04.942: INFO: Got endpoints: latency-svc-vz57g [750.054494ms]
    Nov 29 12:13:04.949: INFO: Created: latency-svc-pj56t
    Nov 29 12:13:04.992: INFO: Got endpoints: latency-svc-bjqfb [749.072183ms]
    Nov 29 12:13:05.001: INFO: Created: latency-svc-z4btx
    Nov 29 12:13:05.043: INFO: Got endpoints: latency-svc-ll9g8 [749.014454ms]
    Nov 29 12:13:05.067: INFO: Created: latency-svc-bzd5p
    Nov 29 12:13:05.091: INFO: Got endpoints: latency-svc-qh4cm [749.549868ms]
    Nov 29 12:13:05.105: INFO: Created: latency-svc-kv69p
    Nov 29 12:13:05.142: INFO: Got endpoints: latency-svc-fqqk9 [749.13731ms]
    Nov 29 12:13:05.151: INFO: Created: latency-svc-cgrqp
    Nov 29 12:13:05.193: INFO: Got endpoints: latency-svc-j55b8 [752.04346ms]
    Nov 29 12:13:05.200: INFO: Created: latency-svc-9sf7h
    Nov 29 12:13:05.244: INFO: Got endpoints: latency-svc-t2n84 [750.480147ms]
    Nov 29 12:13:05.288: INFO: Created: latency-svc-79hz7
    Nov 29 12:13:05.292: INFO: Got endpoints: latency-svc-pm6q2 [750.228434ms]
    Nov 29 12:13:05.298: INFO: Created: latency-svc-8crxn
    Nov 29 12:13:05.342: INFO: Got endpoints: latency-svc-q8mbl [749.877224ms]
    Nov 29 12:13:05.351: INFO: Created: latency-svc-8gz9h
    Nov 29 12:13:05.393: INFO: Got endpoints: latency-svc-szk6q [748.891798ms]
    Nov 29 12:13:05.405: INFO: Created: latency-svc-v5rtj
    Nov 29 12:13:05.443: INFO: Got endpoints: latency-svc-nc8tg [750.662604ms]
    Nov 29 12:13:05.457: INFO: Created: latency-svc-j4djc
    Nov 29 12:13:05.493: INFO: Got endpoints: latency-svc-g66hf [751.97745ms]
    Nov 29 12:13:05.499: INFO: Created: latency-svc-hfnjb
    Nov 29 12:13:05.543: INFO: Got endpoints: latency-svc-cfnx8 [751.388147ms]
    Nov 29 12:13:05.549: INFO: Created: latency-svc-5djvz
    Nov 29 12:13:05.592: INFO: Got endpoints: latency-svc-bgv6d [749.348018ms]
    Nov 29 12:13:05.600: INFO: Created: latency-svc-4d8fx
    Nov 29 12:13:05.641: INFO: Got endpoints: latency-svc-qqnjg [749.961033ms]
    Nov 29 12:13:05.650: INFO: Created: latency-svc-w8cmp
    Nov 29 12:13:05.692: INFO: Got endpoints: latency-svc-pj56t [750.011274ms]
    Nov 29 12:13:05.699: INFO: Created: latency-svc-9jdm4
    Nov 29 12:13:05.743: INFO: Got endpoints: latency-svc-z4btx [750.793903ms]
    Nov 29 12:13:05.751: INFO: Created: latency-svc-nnvlw
    Nov 29 12:13:05.792: INFO: Got endpoints: latency-svc-bzd5p [749.234961ms]
    Nov 29 12:13:05.798: INFO: Created: latency-svc-7zmwf
    Nov 29 12:13:05.842: INFO: Got endpoints: latency-svc-kv69p [750.927654ms]
    Nov 29 12:13:05.848: INFO: Created: latency-svc-gp982
    Nov 29 12:13:05.892: INFO: Got endpoints: latency-svc-cgrqp [750.007998ms]
    Nov 29 12:13:05.898: INFO: Created: latency-svc-njmd9
    Nov 29 12:13:05.942: INFO: Got endpoints: latency-svc-9sf7h [748.031171ms]
    Nov 29 12:13:05.966: INFO: Created: latency-svc-p2x9q
    Nov 29 12:13:05.993: INFO: Got endpoints: latency-svc-79hz7 [749.333631ms]
    Nov 29 12:13:06.001: INFO: Created: latency-svc-rws2h
    Nov 29 12:13:06.042: INFO: Got endpoints: latency-svc-8crxn [749.321201ms]
    Nov 29 12:13:06.060: INFO: Created: latency-svc-wrplm
    Nov 29 12:13:06.092: INFO: Got endpoints: latency-svc-8gz9h [748.571683ms]
    Nov 29 12:13:06.098: INFO: Created: latency-svc-9x667
    Nov 29 12:13:06.155: INFO: Got endpoints: latency-svc-v5rtj [762.368206ms]
    Nov 29 12:13:06.163: INFO: Created: latency-svc-g8srt
    Nov 29 12:13:06.193: INFO: Got endpoints: latency-svc-j4djc [750.022739ms]
    Nov 29 12:13:06.200: INFO: Created: latency-svc-lznn9
    Nov 29 12:13:06.242: INFO: Got endpoints: latency-svc-hfnjb [748.500039ms]
    Nov 29 12:13:06.249: INFO: Created: latency-svc-547nd
    Nov 29 12:13:06.312: INFO: Got endpoints: latency-svc-5djvz [768.926997ms]
    Nov 29 12:13:06.327: INFO: Created: latency-svc-r82w7
    Nov 29 12:13:06.342: INFO: Got endpoints: latency-svc-4d8fx [750.44119ms]
    Nov 29 12:13:06.352: INFO: Created: latency-svc-bg22c
    Nov 29 12:13:06.392: INFO: Got endpoints: latency-svc-w8cmp [750.746311ms]
    Nov 29 12:13:06.404: INFO: Created: latency-svc-44xx4
    Nov 29 12:13:06.444: INFO: Got endpoints: latency-svc-9jdm4 [751.01816ms]
    Nov 29 12:13:06.450: INFO: Created: latency-svc-8qdbf
    Nov 29 12:13:06.493: INFO: Got endpoints: latency-svc-nnvlw [750.592636ms]
    Nov 29 12:13:06.500: INFO: Created: latency-svc-6bbt4
    Nov 29 12:13:06.544: INFO: Got endpoints: latency-svc-7zmwf [751.672076ms]
    Nov 29 12:13:06.551: INFO: Created: latency-svc-5h8gb
    Nov 29 12:13:06.593: INFO: Got endpoints: latency-svc-gp982 [750.548792ms]
    Nov 29 12:13:06.599: INFO: Created: latency-svc-n28vl
    Nov 29 12:13:06.654: INFO: Got endpoints: latency-svc-njmd9 [762.026382ms]
    Nov 29 12:13:06.731: INFO: Created: latency-svc-twbg8
    Nov 29 12:13:06.738: INFO: Got endpoints: latency-svc-p2x9q [795.904288ms]
    Nov 29 12:13:06.755: INFO: Got endpoints: latency-svc-rws2h [761.696782ms]
    Nov 29 12:13:06.831: INFO: Got endpoints: latency-svc-wrplm [789.721752ms]
    Nov 29 12:13:06.832: INFO: Created: latency-svc-2gf2g
    Nov 29 12:13:06.838: INFO: Created: latency-svc-d7hbd
    Nov 29 12:13:06.842: INFO: Created: latency-svc-56jnd
    Nov 29 12:13:06.843: INFO: Got endpoints: latency-svc-9x667 [750.804738ms]
    Nov 29 12:13:06.871: INFO: Created: latency-svc-r82c2
    Nov 29 12:13:06.893: INFO: Got endpoints: latency-svc-g8srt [738.059705ms]
    Nov 29 12:13:06.899: INFO: Created: latency-svc-2mrx8
    Nov 29 12:13:06.943: INFO: Got endpoints: latency-svc-lznn9 [750.155562ms]
    Nov 29 12:13:06.948: INFO: Created: latency-svc-tfw2s
    Nov 29 12:13:06.992: INFO: Got endpoints: latency-svc-547nd [750.16087ms]
    Nov 29 12:13:07.000: INFO: Created: latency-svc-j9gm2
    Nov 29 12:13:07.044: INFO: Got endpoints: latency-svc-r82w7 [731.434693ms]
    Nov 29 12:13:07.050: INFO: Created: latency-svc-hz6zw
    Nov 29 12:13:07.100: INFO: Got endpoints: latency-svc-bg22c [757.558408ms]
    Nov 29 12:13:07.108: INFO: Created: latency-svc-sd79c
    Nov 29 12:13:07.142: INFO: Got endpoints: latency-svc-44xx4 [750.168377ms]
    Nov 29 12:13:07.164: INFO: Created: latency-svc-d9gr6
    Nov 29 12:13:07.192: INFO: Got endpoints: latency-svc-8qdbf [748.735874ms]
    Nov 29 12:13:07.199: INFO: Created: latency-svc-dzw5k
    Nov 29 12:13:07.243: INFO: Got endpoints: latency-svc-6bbt4 [749.350769ms]
    Nov 29 12:13:07.249: INFO: Created: latency-svc-4shcd
    Nov 29 12:13:07.291: INFO: Got endpoints: latency-svc-5h8gb [747.808746ms]
    Nov 29 12:13:07.300: INFO: Created: latency-svc-t44ml
    Nov 29 12:13:07.342: INFO: Got endpoints: latency-svc-n28vl [748.912264ms]
    Nov 29 12:13:07.349: INFO: Created: latency-svc-k5t6z
    Nov 29 12:13:07.394: INFO: Got endpoints: latency-svc-twbg8 [739.63388ms]
    Nov 29 12:13:07.401: INFO: Created: latency-svc-r756x
    Nov 29 12:13:07.443: INFO: Got endpoints: latency-svc-2gf2g [705.401837ms]
    Nov 29 12:13:07.449: INFO: Created: latency-svc-xmn66
    Nov 29 12:13:07.492: INFO: Got endpoints: latency-svc-d7hbd [737.149464ms]
    Nov 29 12:13:07.501: INFO: Created: latency-svc-9hkx9
    Nov 29 12:13:07.553: INFO: Got endpoints: latency-svc-56jnd [721.209605ms]
    Nov 29 12:13:07.559: INFO: Created: latency-svc-hwlwc
    Nov 29 12:13:07.593: INFO: Got endpoints: latency-svc-r82c2 [749.823791ms]
    Nov 29 12:13:07.602: INFO: Created: latency-svc-mlswx
    Nov 29 12:13:07.642: INFO: Got endpoints: latency-svc-2mrx8 [748.338997ms]
    Nov 29 12:13:07.649: INFO: Created: latency-svc-7w4bx
    Nov 29 12:13:07.692: INFO: Got endpoints: latency-svc-tfw2s [749.342223ms]
    Nov 29 12:13:07.707: INFO: Created: latency-svc-rhfhr
    Nov 29 12:13:07.742: INFO: Got endpoints: latency-svc-j9gm2 [750.048303ms]
    Nov 29 12:13:07.749: INFO: Created: latency-svc-glzlk
    Nov 29 12:13:07.793: INFO: Got endpoints: latency-svc-hz6zw [748.860769ms]
    Nov 29 12:13:07.799: INFO: Created: latency-svc-5hl5g
    Nov 29 12:13:07.844: INFO: Got endpoints: latency-svc-sd79c [743.990991ms]
    Nov 29 12:13:07.850: INFO: Created: latency-svc-mqwtm
    Nov 29 12:13:07.893: INFO: Got endpoints: latency-svc-d9gr6 [750.30731ms]
    Nov 29 12:13:07.899: INFO: Created: latency-svc-bzh89
    Nov 29 12:13:07.942: INFO: Got endpoints: latency-svc-dzw5k [749.967105ms]
    Nov 29 12:13:07.948: INFO: Created: latency-svc-q9hmz
    Nov 29 12:13:07.994: INFO: Got endpoints: latency-svc-4shcd [750.713227ms]
    Nov 29 12:13:08.002: INFO: Created: latency-svc-q9jfq
    Nov 29 12:13:08.045: INFO: Got endpoints: latency-svc-t44ml [753.209939ms]
    Nov 29 12:13:08.052: INFO: Created: latency-svc-78wtg
    Nov 29 12:13:08.092: INFO: Got endpoints: latency-svc-k5t6z [749.959749ms]
    Nov 29 12:13:08.104: INFO: Created: latency-svc-6sjjv
    Nov 29 12:13:08.143: INFO: Got endpoints: latency-svc-r756x [749.511439ms]
    Nov 29 12:13:08.157: INFO: Created: latency-svc-44jqz
    Nov 29 12:13:08.193: INFO: Got endpoints: latency-svc-xmn66 [750.209132ms]
    Nov 29 12:13:08.200: INFO: Created: latency-svc-bs92d
    Nov 29 12:13:08.244: INFO: Got endpoints: latency-svc-9hkx9 [751.671117ms]
    Nov 29 12:13:08.257: INFO: Created: latency-svc-c4rkt
    Nov 29 12:13:08.291: INFO: Got endpoints: latency-svc-hwlwc [738.69602ms]
    Nov 29 12:13:08.310: INFO: Created: latency-svc-fbgsb
    Nov 29 12:13:08.341: INFO: Got endpoints: latency-svc-mlswx [748.802525ms]
    Nov 29 12:13:08.357: INFO: Created: latency-svc-sxmmv
    Nov 29 12:13:08.392: INFO: Got endpoints: latency-svc-7w4bx [749.795098ms]
    Nov 29 12:13:08.458: INFO: Created: latency-svc-fk6vv
    Nov 29 12:13:08.458: INFO: Got endpoints: latency-svc-rhfhr [766.007365ms]
    Nov 29 12:13:08.465: INFO: Created: latency-svc-wkhcf
    Nov 29 12:13:08.493: INFO: Got endpoints: latency-svc-glzlk [750.1385ms]
    Nov 29 12:13:08.499: INFO: Created: latency-svc-f4cxh
    Nov 29 12:13:08.543: INFO: Got endpoints: latency-svc-5hl5g [749.857363ms]
    Nov 29 12:13:08.556: INFO: Created: latency-svc-pt95b
    Nov 29 12:13:08.593: INFO: Got endpoints: latency-svc-mqwtm [748.864011ms]
    Nov 29 12:13:08.602: INFO: Created: latency-svc-b8lms
    Nov 29 12:13:08.641: INFO: Got endpoints: latency-svc-bzh89 [748.794227ms]
    Nov 29 12:13:08.649: INFO: Created: latency-svc-zqd5j
    Nov 29 12:13:08.694: INFO: Got endpoints: latency-svc-q9hmz [751.069106ms]
    Nov 29 12:13:08.700: INFO: Created: latency-svc-g6pbn
    Nov 29 12:13:08.750: INFO: Got endpoints: latency-svc-q9jfq [755.923404ms]
    Nov 29 12:13:08.756: INFO: Created: latency-svc-7xkts
    Nov 29 12:13:08.792: INFO: Got endpoints: latency-svc-78wtg [747.775842ms]
    Nov 29 12:13:08.801: INFO: Created: latency-svc-w7p9s
    Nov 29 12:13:08.841: INFO: Got endpoints: latency-svc-6sjjv [748.629609ms]
    Nov 29 12:13:08.917: INFO: Got endpoints: latency-svc-44jqz [773.227273ms]
    Nov 29 12:13:08.922: INFO: Created: latency-svc-qqbrz
    Nov 29 12:13:08.925: INFO: Created: latency-svc-88f9f
    Nov 29 12:13:08.953: INFO: Got endpoints: latency-svc-bs92d [759.531738ms]
    Nov 29 12:13:08.960: INFO: Created: latency-svc-tq259
    Nov 29 12:13:08.992: INFO: Got endpoints: latency-svc-c4rkt [747.693077ms]
    Nov 29 12:13:09.010: INFO: Created: latency-svc-xgdzg
    Nov 29 12:13:09.045: INFO: Got endpoints: latency-svc-fbgsb [753.758787ms]
    Nov 29 12:13:09.060: INFO: Created: latency-svc-5l68d
    Nov 29 12:13:09.092: INFO: Got endpoints: latency-svc-sxmmv [750.139979ms]
    Nov 29 12:13:09.098: INFO: Created: latency-svc-r7bg5
    Nov 29 12:13:09.153: INFO: Got endpoints: latency-svc-fk6vv [761.621148ms]
    Nov 29 12:13:09.169: INFO: Created: latency-svc-76b5w
    Nov 29 12:13:09.192: INFO: Got endpoints: latency-svc-wkhcf [733.901147ms]
    Nov 29 12:13:09.199: INFO: Created: latency-svc-tk7kv
    Nov 29 12:13:09.243: INFO: Got endpoints: latency-svc-f4cxh [750.510406ms]
    Nov 29 12:13:09.249: INFO: Created: latency-svc-r4vxj
    Nov 29 12:13:09.293: INFO: Got endpoints: latency-svc-pt95b [750.336974ms]
    Nov 29 12:13:09.299: INFO: Created: latency-svc-7jlg8
    Nov 29 12:13:09.343: INFO: Got endpoints: latency-svc-b8lms [749.731159ms]
    Nov 29 12:13:09.349: INFO: Created: latency-svc-cnnj2
    Nov 29 12:13:09.393: INFO: Got endpoints: latency-svc-zqd5j [751.100558ms]
    Nov 29 12:13:09.400: INFO: Created: latency-svc-jfvj4
    Nov 29 12:13:09.444: INFO: Got endpoints: latency-svc-g6pbn [749.973673ms]
    Nov 29 12:13:09.449: INFO: Created: latency-svc-2kmfz
    Nov 29 12:13:09.493: INFO: Got endpoints: latency-svc-7xkts [743.21444ms]
    Nov 29 12:13:09.499: INFO: Created: latency-svc-q7cxj
    Nov 29 12:13:09.542: INFO: Got endpoints: latency-svc-w7p9s [749.454353ms]
    Nov 29 12:13:09.559: INFO: Created: latency-svc-nzc5g
    Nov 29 12:13:09.593: INFO: Got endpoints: latency-svc-qqbrz [751.967518ms]
    Nov 29 12:13:09.598: INFO: Created: latency-svc-82jrr
    Nov 29 12:13:09.641: INFO: Got endpoints: latency-svc-88f9f [724.500971ms]
    Nov 29 12:13:09.648: INFO: Created: latency-svc-5gsw7
    Nov 29 12:13:09.692: INFO: Got endpoints: latency-svc-tq259 [738.800707ms]
    Nov 29 12:13:09.698: INFO: Created: latency-svc-fgb4w
    Nov 29 12:13:09.742: INFO: Got endpoints: latency-svc-xgdzg [749.767841ms]
    Nov 29 12:13:09.749: INFO: Created: latency-svc-vrxqt
    Nov 29 12:13:09.793: INFO: Got endpoints: latency-svc-5l68d [747.581692ms]
    Nov 29 12:13:09.803: INFO: Created: latency-svc-ttj6s
    Nov 29 12:13:09.843: INFO: Got endpoints: latency-svc-r7bg5 [751.776831ms]
    Nov 29 12:13:09.849: INFO: Created: latency-svc-pfr6d
    Nov 29 12:13:09.894: INFO: Got endpoints: latency-svc-76b5w [740.52817ms]
    Nov 29 12:13:09.900: INFO: Created: latency-svc-fh5v4
    Nov 29 12:13:09.942: INFO: Got endpoints: latency-svc-tk7kv [749.631801ms]
    Nov 29 12:13:09.954: INFO: Created: latency-svc-svmpm
    Nov 29 12:13:09.992: INFO: Got endpoints: latency-svc-r4vxj [748.163585ms]
    Nov 29 12:13:10.003: INFO: Created: latency-svc-w9bp8
    Nov 29 12:13:10.042: INFO: Got endpoints: latency-svc-7jlg8 [749.381095ms]
    Nov 29 12:13:10.049: INFO: Created: latency-svc-99vtn
    Nov 29 12:13:10.092: INFO: Got endpoints: latency-svc-cnnj2 [749.451383ms]
    Nov 29 12:13:10.098: INFO: Created: latency-svc-p99kt
    Nov 29 12:13:10.141: INFO: Got endpoints: latency-svc-jfvj4 [748.354027ms]
    Nov 29 12:13:10.147: INFO: Created: latency-svc-q4sq9
    Nov 29 12:13:10.194: INFO: Got endpoints: latency-svc-2kmfz [750.751163ms]
    Nov 29 12:13:10.200: INFO: Created: latency-svc-n5c7x
    Nov 29 12:13:10.241: INFO: Got endpoints: latency-svc-q7cxj [748.595043ms]
    Nov 29 12:13:10.247: INFO: Created: latency-svc-cfj8s
    Nov 29 12:13:10.292: INFO: Got endpoints: latency-svc-nzc5g [750.171088ms]
    Nov 29 12:13:10.298: INFO: Created: latency-svc-bvv2m
    Nov 29 12:13:10.343: INFO: Got endpoints: latency-svc-82jrr [750.458566ms]
    Nov 29 12:13:10.392: INFO: Got endpoints: latency-svc-5gsw7 [750.597333ms]
    Nov 29 12:13:10.442: INFO: Got endpoints: latency-svc-fgb4w [749.951249ms]
    Nov 29 12:13:10.491: INFO: Got endpoints: latency-svc-vrxqt [749.821927ms]
    Nov 29 12:13:10.542: INFO: Got endpoints: latency-svc-ttj6s [748.808587ms]
    Nov 29 12:13:10.592: INFO: Got endpoints: latency-svc-pfr6d [748.947849ms]
    Nov 29 12:13:10.644: INFO: Got endpoints: latency-svc-fh5v4 [750.131805ms]
    Nov 29 12:13:10.692: INFO: Got endpoints: latency-svc-svmpm [749.639507ms]
    Nov 29 12:13:10.742: INFO: Got endpoints: latency-svc-w9bp8 [749.807135ms]
    Nov 29 12:13:10.793: INFO: Got endpoints: latency-svc-99vtn [750.198556ms]
    Nov 29 12:13:10.844: INFO: Got endpoints: latency-svc-p99kt [752.274376ms]
    Nov 29 12:13:10.893: INFO: Got endpoints: latency-svc-q4sq9 [751.723201ms]
    Nov 29 12:13:10.942: INFO: Got endpoints: latency-svc-n5c7x [747.077812ms]
    Nov 29 12:13:10.991: INFO: Got endpoints: latency-svc-cfj8s [749.985746ms]
    Nov 29 12:13:11.042: INFO: Got endpoints: latency-svc-bvv2m [749.362158ms]
    Nov 29 12:13:11.042: INFO: Latencies: [12.719616ms 22.615ms 34.133686ms 54.855865ms 110.98223ms 113.016926ms 117.101454ms 117.101794ms 120.404329ms 120.451839ms 120.659847ms 123.524667ms 125.190003ms 125.669777ms 127.959174ms 128.530283ms 130.689051ms 131.497776ms 132.129298ms 137.209526ms 143.113944ms 143.333479ms 143.714499ms 145.107834ms 147.260723ms 149.950351ms 154.685651ms 156.644253ms 165.637829ms 167.890713ms 171.679592ms 171.94564ms 174.633429ms 178.662587ms 183.999293ms 185.492078ms 191.689574ms 195.105732ms 232.392917ms 262.6881ms 301.945169ms 347.552334ms 391.4086ms 433.040241ms 478.079856ms 521.944643ms 565.274499ms 609.032033ms 648.687857ms 669.019452ms 705.401837ms 709.168441ms 720.01034ms 721.209605ms 724.500971ms 731.434693ms 733.901147ms 737.149464ms 738.059705ms 738.69602ms 738.800707ms 739.63388ms 740.52817ms 743.21444ms 743.494386ms 743.990991ms 745.225043ms 747.077812ms 747.581692ms 747.693077ms 747.775842ms 747.808746ms 747.992764ms 748.019971ms 748.031171ms 748.163585ms 748.338997ms 748.354027ms 748.40499ms 748.500039ms 748.547541ms 748.571683ms 748.595043ms 748.629609ms 748.735874ms 748.787809ms 748.794227ms 748.802525ms 748.808587ms 748.860769ms 748.864011ms 748.891798ms 748.912264ms 748.947849ms 749.014454ms 749.072183ms 749.13731ms 749.234961ms 749.321201ms 749.333631ms 749.342223ms 749.348018ms 749.350769ms 749.362158ms 749.381095ms 749.451383ms 749.454353ms 749.511439ms 749.549868ms 749.55077ms 749.627036ms 749.631801ms 749.639507ms 749.686496ms 749.711684ms 749.731159ms 749.767841ms 749.77879ms 749.795098ms 749.807135ms 749.821927ms 749.823791ms 749.827474ms 749.857363ms 749.86859ms 749.877224ms 749.918653ms 749.935131ms 749.951249ms 749.959749ms 749.961033ms 749.967105ms 749.973673ms 749.979215ms 749.985746ms 750.007998ms 750.011274ms 750.022739ms 750.048303ms 750.054494ms 750.102392ms 750.131805ms 750.1385ms 750.139979ms 750.149539ms 750.155562ms 750.16087ms 750.168377ms 750.171088ms 750.198556ms 750.209132ms 750.228434ms 750.30731ms 750.336974ms 750.44119ms 750.458566ms 750.480147ms 750.510406ms 750.548792ms 750.592636ms 750.597333ms 750.662604ms 750.713227ms 750.746311ms 750.751163ms 750.793903ms 750.804738ms 750.865334ms 750.927654ms 751.01816ms 751.069106ms 751.083814ms 751.100558ms 751.278089ms 751.333169ms 751.388147ms 751.671117ms 751.672076ms 751.723201ms 751.776831ms 751.874956ms 751.967518ms 751.97745ms 752.04346ms 752.274376ms 753.209939ms 753.758787ms 755.923404ms 757.558408ms 759.531738ms 761.621148ms 761.696782ms 762.026382ms 762.368206ms 766.007365ms 768.926997ms 773.227273ms 784.736556ms 789.721752ms 795.904288ms]
    Nov 29 12:13:11.042: INFO: 50 %ile: 749.342223ms
    Nov 29 12:13:11.042: INFO: 90 %ile: 751.874956ms
    Nov 29 12:13:11.042: INFO: 99 %ile: 789.721752ms
    Nov 29 12:13:11.042: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Nov 29 12:13:11.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-422" for this suite. 11/29/22 12:13:11.048
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:13:11.056
Nov 29 12:13:11.056: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:13:11.056
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:11.065
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:11.067
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-a5437d58-bc87-46e5-b6e0-77708892c013 11/29/22 12:13:11.079
STEP: Creating configMap with name cm-test-opt-upd-98f4ad61-6081-4d59-af9d-44157e40b95c 11/29/22 12:13:11.082
STEP: Creating the pod 11/29/22 12:13:11.084
Nov 29 12:13:11.089: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b" in namespace "projected-7444" to be "running and ready"
Nov 29 12:13:11.097: INFO: Pod "pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.242732ms
Nov 29 12:13:11.097: INFO: The phase of Pod pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:13:13.100: INFO: Pod "pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010592244s
Nov 29 12:13:13.100: INFO: The phase of Pod pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b is Running (Ready = true)
Nov 29 12:13:13.100: INFO: Pod "pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-a5437d58-bc87-46e5-b6e0-77708892c013 11/29/22 12:13:13.126
STEP: Updating configmap cm-test-opt-upd-98f4ad61-6081-4d59-af9d-44157e40b95c 11/29/22 12:13:13.132
STEP: Creating configMap with name cm-test-opt-create-079263d7-ccd9-4766-8bbf-11d36008ebc0 11/29/22 12:13:13.135
STEP: waiting to observe update in volume 11/29/22 12:13:13.138
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 12:13:17.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7444" for this suite. 11/29/22 12:13:17.173
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":165,"skipped":3056,"failed":0}
------------------------------
• [SLOW TEST] [6.121 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:13:11.056
    Nov 29 12:13:11.056: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:13:11.056
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:11.065
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:11.067
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-a5437d58-bc87-46e5-b6e0-77708892c013 11/29/22 12:13:11.079
    STEP: Creating configMap with name cm-test-opt-upd-98f4ad61-6081-4d59-af9d-44157e40b95c 11/29/22 12:13:11.082
    STEP: Creating the pod 11/29/22 12:13:11.084
    Nov 29 12:13:11.089: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b" in namespace "projected-7444" to be "running and ready"
    Nov 29 12:13:11.097: INFO: Pod "pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.242732ms
    Nov 29 12:13:11.097: INFO: The phase of Pod pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:13:13.100: INFO: Pod "pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010592244s
    Nov 29 12:13:13.100: INFO: The phase of Pod pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b is Running (Ready = true)
    Nov 29 12:13:13.100: INFO: Pod "pod-projected-configmaps-ef0a64f4-9990-44da-b1a2-036ab88e6d2b" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-a5437d58-bc87-46e5-b6e0-77708892c013 11/29/22 12:13:13.126
    STEP: Updating configmap cm-test-opt-upd-98f4ad61-6081-4d59-af9d-44157e40b95c 11/29/22 12:13:13.132
    STEP: Creating configMap with name cm-test-opt-create-079263d7-ccd9-4766-8bbf-11d36008ebc0 11/29/22 12:13:13.135
    STEP: waiting to observe update in volume 11/29/22 12:13:13.138
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 12:13:17.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7444" for this suite. 11/29/22 12:13:17.173
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:13:17.181
Nov 29 12:13:17.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename subpath 11/29/22 12:13:17.182
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:17.193
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:17.195
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/29/22 12:13:17.198
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-9brt 11/29/22 12:13:17.203
STEP: Creating a pod to test atomic-volume-subpath 11/29/22 12:13:17.204
Nov 29 12:13:17.209: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9brt" in namespace "subpath-9352" to be "Succeeded or Failed"
Nov 29 12:13:17.218: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.20294ms
Nov 29 12:13:19.224: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 2.015484179s
Nov 29 12:13:21.222: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 4.012892193s
Nov 29 12:13:23.222: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 6.012741227s
Nov 29 12:13:25.224: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 8.014659434s
Nov 29 12:13:27.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 10.012497464s
Nov 29 12:13:29.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 12.011911369s
Nov 29 12:13:31.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 14.012286664s
Nov 29 12:13:33.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 16.012157994s
Nov 29 12:13:35.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 18.012520814s
Nov 29 12:13:37.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 20.012114943s
Nov 29 12:13:39.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=false. Elapsed: 22.012132272s
Nov 29 12:13:41.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012554119s
STEP: Saw pod success 11/29/22 12:13:41.221
Nov 29 12:13:41.222: INFO: Pod "pod-subpath-test-configmap-9brt" satisfied condition "Succeeded or Failed"
Nov 29 12:13:41.224: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-subpath-test-configmap-9brt container test-container-subpath-configmap-9brt: <nil>
STEP: delete the pod 11/29/22 12:13:41.236
Nov 29 12:13:41.244: INFO: Waiting for pod pod-subpath-test-configmap-9brt to disappear
Nov 29 12:13:41.245: INFO: Pod pod-subpath-test-configmap-9brt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9brt 11/29/22 12:13:41.245
Nov 29 12:13:41.245: INFO: Deleting pod "pod-subpath-test-configmap-9brt" in namespace "subpath-9352"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 29 12:13:41.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9352" for this suite. 11/29/22 12:13:41.25
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":166,"skipped":3120,"failed":0}
------------------------------
• [SLOW TEST] [24.072 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:13:17.181
    Nov 29 12:13:17.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename subpath 11/29/22 12:13:17.182
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:17.193
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:17.195
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/29/22 12:13:17.198
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-9brt 11/29/22 12:13:17.203
    STEP: Creating a pod to test atomic-volume-subpath 11/29/22 12:13:17.204
    Nov 29 12:13:17.209: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9brt" in namespace "subpath-9352" to be "Succeeded or Failed"
    Nov 29 12:13:17.218: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.20294ms
    Nov 29 12:13:19.224: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 2.015484179s
    Nov 29 12:13:21.222: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 4.012892193s
    Nov 29 12:13:23.222: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 6.012741227s
    Nov 29 12:13:25.224: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 8.014659434s
    Nov 29 12:13:27.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 10.012497464s
    Nov 29 12:13:29.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 12.011911369s
    Nov 29 12:13:31.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 14.012286664s
    Nov 29 12:13:33.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 16.012157994s
    Nov 29 12:13:35.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 18.012520814s
    Nov 29 12:13:37.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=true. Elapsed: 20.012114943s
    Nov 29 12:13:39.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Running", Reason="", readiness=false. Elapsed: 22.012132272s
    Nov 29 12:13:41.221: INFO: Pod "pod-subpath-test-configmap-9brt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012554119s
    STEP: Saw pod success 11/29/22 12:13:41.221
    Nov 29 12:13:41.222: INFO: Pod "pod-subpath-test-configmap-9brt" satisfied condition "Succeeded or Failed"
    Nov 29 12:13:41.224: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-subpath-test-configmap-9brt container test-container-subpath-configmap-9brt: <nil>
    STEP: delete the pod 11/29/22 12:13:41.236
    Nov 29 12:13:41.244: INFO: Waiting for pod pod-subpath-test-configmap-9brt to disappear
    Nov 29 12:13:41.245: INFO: Pod pod-subpath-test-configmap-9brt no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-9brt 11/29/22 12:13:41.245
    Nov 29 12:13:41.245: INFO: Deleting pod "pod-subpath-test-configmap-9brt" in namespace "subpath-9352"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 29 12:13:41.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-9352" for this suite. 11/29/22 12:13:41.25
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:13:41.258
Nov 29 12:13:41.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 12:13:41.259
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:41.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:41.276
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 11/29/22 12:13:41.279
STEP: Counting existing ResourceQuota 11/29/22 12:13:46.282
STEP: Creating a ResourceQuota 11/29/22 12:13:51.286
STEP: Ensuring resource quota status is calculated 11/29/22 12:13:51.29
STEP: Creating a Secret 11/29/22 12:13:53.292
STEP: Ensuring resource quota status captures secret creation 11/29/22 12:13:53.298
STEP: Deleting a secret 11/29/22 12:13:55.301
STEP: Ensuring resource quota status released usage 11/29/22 12:13:55.304
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 12:13:57.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5604" for this suite. 11/29/22 12:13:57.313
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":167,"skipped":3145,"failed":0}
------------------------------
• [SLOW TEST] [16.060 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:13:41.258
    Nov 29 12:13:41.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 12:13:41.259
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:41.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:41.276
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 11/29/22 12:13:41.279
    STEP: Counting existing ResourceQuota 11/29/22 12:13:46.282
    STEP: Creating a ResourceQuota 11/29/22 12:13:51.286
    STEP: Ensuring resource quota status is calculated 11/29/22 12:13:51.29
    STEP: Creating a Secret 11/29/22 12:13:53.292
    STEP: Ensuring resource quota status captures secret creation 11/29/22 12:13:53.298
    STEP: Deleting a secret 11/29/22 12:13:55.301
    STEP: Ensuring resource quota status released usage 11/29/22 12:13:55.304
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 12:13:57.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5604" for this suite. 11/29/22 12:13:57.313
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:13:57.318
Nov 29 12:13:57.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:13:57.319
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:57.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:57.333
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:13:57.335
Nov 29 12:13:57.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48" in namespace "downward-api-7109" to be "Succeeded or Failed"
Nov 29 12:13:57.341: INFO: Pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48": Phase="Pending", Reason="", readiness=false. Elapsed: 1.912423ms
Nov 29 12:13:59.345: INFO: Pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005805704s
Nov 29 12:14:01.345: INFO: Pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006019879s
STEP: Saw pod success 11/29/22 12:14:01.345
Nov 29 12:14:01.345: INFO: Pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48" satisfied condition "Succeeded or Failed"
Nov 29 12:14:01.347: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48 container client-container: <nil>
STEP: delete the pod 11/29/22 12:14:01.352
Nov 29 12:14:01.358: INFO: Waiting for pod downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48 to disappear
Nov 29 12:14:01.360: INFO: Pod downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:14:01.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7109" for this suite. 11/29/22 12:14:01.364
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":168,"skipped":3153,"failed":0}
------------------------------
• [4.050 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:13:57.318
    Nov 29 12:13:57.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:13:57.319
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:13:57.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:13:57.333
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:13:57.335
    Nov 29 12:13:57.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48" in namespace "downward-api-7109" to be "Succeeded or Failed"
    Nov 29 12:13:57.341: INFO: Pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48": Phase="Pending", Reason="", readiness=false. Elapsed: 1.912423ms
    Nov 29 12:13:59.345: INFO: Pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005805704s
    Nov 29 12:14:01.345: INFO: Pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006019879s
    STEP: Saw pod success 11/29/22 12:14:01.345
    Nov 29 12:14:01.345: INFO: Pod "downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48" satisfied condition "Succeeded or Failed"
    Nov 29 12:14:01.347: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:14:01.352
    Nov 29 12:14:01.358: INFO: Waiting for pod downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48 to disappear
    Nov 29 12:14:01.360: INFO: Pod downwardapi-volume-b55c4b98-1365-4c95-8d8c-8b41acfd2e48 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:14:01.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7109" for this suite. 11/29/22 12:14:01.364
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:01.369
Nov 29 12:14:01.370: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:14:01.373
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:01.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:01.389
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-f924ffc7-a2da-4f26-935b-5bfaac57deb6 11/29/22 12:14:01.392
STEP: Creating a pod to test consume secrets 11/29/22 12:14:01.395
Nov 29 12:14:01.400: INFO: Waiting up to 5m0s for pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0" in namespace "secrets-5756" to be "Succeeded or Failed"
Nov 29 12:14:01.402: INFO: Pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.621655ms
Nov 29 12:14:03.405: INFO: Pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005400203s
Nov 29 12:14:05.406: INFO: Pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006897702s
STEP: Saw pod success 11/29/22 12:14:05.407
Nov 29 12:14:05.407: INFO: Pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0" satisfied condition "Succeeded or Failed"
Nov 29 12:14:05.409: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0 container secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:14:05.412
Nov 29 12:14:05.418: INFO: Waiting for pod pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0 to disappear
Nov 29 12:14:05.420: INFO: Pod pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:14:05.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5756" for this suite. 11/29/22 12:14:05.423
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":169,"skipped":3170,"failed":0}
------------------------------
• [4.056 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:01.369
    Nov 29 12:14:01.370: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:14:01.373
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:01.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:01.389
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-f924ffc7-a2da-4f26-935b-5bfaac57deb6 11/29/22 12:14:01.392
    STEP: Creating a pod to test consume secrets 11/29/22 12:14:01.395
    Nov 29 12:14:01.400: INFO: Waiting up to 5m0s for pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0" in namespace "secrets-5756" to be "Succeeded or Failed"
    Nov 29 12:14:01.402: INFO: Pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.621655ms
    Nov 29 12:14:03.405: INFO: Pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005400203s
    Nov 29 12:14:05.406: INFO: Pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006897702s
    STEP: Saw pod success 11/29/22 12:14:05.407
    Nov 29 12:14:05.407: INFO: Pod "pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0" satisfied condition "Succeeded or Failed"
    Nov 29 12:14:05.409: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0 container secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:14:05.412
    Nov 29 12:14:05.418: INFO: Waiting for pod pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0 to disappear
    Nov 29 12:14:05.420: INFO: Pod pod-secrets-56747028-ad3d-4ba2-a27b-c8b2e9c5c2e0 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:14:05.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5756" for this suite. 11/29/22 12:14:05.423
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:05.426
Nov 29 12:14:05.426: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename daemonsets 11/29/22 12:14:05.427
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:05.436
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:05.439
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 11/29/22 12:14:05.452
STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:14:05.455
Nov 29 12:14:05.460: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:14:05.460: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:14:06.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:14:06.468: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:14:07.467: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 12:14:07.467: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: listing all DeamonSets 11/29/22 12:14:07.469
STEP: DeleteCollection of the DaemonSets 11/29/22 12:14:07.472
STEP: Verify that ReplicaSets have been deleted 11/29/22 12:14:07.475
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Nov 29 12:14:07.488: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24151"},"items":null}

Nov 29 12:14:07.495: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24156"},"items":[{"metadata":{"name":"daemon-set-52b97","generateName":"daemon-set-","namespace":"daemonsets-6181","uid":"bbe05f8f-4487-4131-b3ad-34864a6d913e","resourceVersion":"24154","creationTimestamp":"2022-11-29T12:14:05Z","deletionTimestamp":"2022-11-29T12:14:37Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"2cf9fcdd348c5767a71bae64ca29f855787455e656996e695683c983d5aead26","cni.projectcalico.org/podIP":"100.96.1.107/32","cni.projectcalico.org/podIPs":"100.96.1.107/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3c86d81f-f792-465b-9b20-7ec97a488e16","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c86d81f-f792-465b-9b20-7ec97a488e16\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.107\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-czs4h","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-czs4h","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"dvi-7336-1669718118-vsp1-group1-0","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["dvi-7336-1669718118-vsp1-group1-0"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"}],"hostIP":"192.168.8.111","podIP":"100.96.1.107","podIPs":[{"ip":"100.96.1.107"}],"startTime":"2022-11-29T12:14:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-29T12:14:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://720945b383df0d11f93056c028385d0b61fea02ac1ae76ee6d2254eed28a6bea","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-b75sl","generateName":"daemon-set-","namespace":"daemonsets-6181","uid":"8e6b9608-9b00-490a-8dd7-6e5c0aca0f82","resourceVersion":"24153","creationTimestamp":"2022-11-29T12:14:05Z","deletionTimestamp":"2022-11-29T12:14:37Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"10f19d34350f27540695ef5975cce3d06cdf661dbae078bc1a01d9055ffe93c3","cni.projectcalico.org/podIP":"100.96.3.81/32","cni.projectcalico.org/podIPs":"100.96.3.81/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3c86d81f-f792-465b-9b20-7ec97a488e16","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c86d81f-f792-465b-9b20-7ec97a488e16\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.81\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-r4l58","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-r4l58","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"dvi-7336-1669718118-vsp1-group1-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["dvi-7336-1669718118-vsp1-group1-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"}],"hostIP":"192.168.8.35","podIP":"100.96.3.81","podIPs":[{"ip":"100.96.3.81"}],"startTime":"2022-11-29T12:14:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-29T12:14:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://8d2d03005183777e7a94275c4c7ac66d311f1ddb1297ace44bb4b1c0a419e217","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-qkst5","generateName":"daemon-set-","namespace":"daemonsets-6181","uid":"213dede9-d8f2-4471-9c92-e85c6d50d4ca","resourceVersion":"24155","creationTimestamp":"2022-11-29T12:14:05Z","deletionTimestamp":"2022-11-29T12:14:37Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"8678a42e063ab224a9bc9f599f5a51152b46be52622aa1969fee4818c0bcadc2","cni.projectcalico.org/podIP":"100.96.0.69/32","cni.projectcalico.org/podIPs":"100.96.0.69/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3c86d81f-f792-465b-9b20-7ec97a488e16","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c86d81f-f792-465b-9b20-7ec97a488e16\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-nlksx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-nlksx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"dvi-7336-1669718118-vsp1-master-0","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["dvi-7336-1669718118-vsp1-master-0"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:06Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:06Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"}],"hostIP":"192.168.8.155","podIP":"100.96.0.69","podIPs":[{"ip":"100.96.0.69"}],"startTime":"2022-11-29T12:14:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-29T12:14:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://f1465b930e01c11e05c23176f5bbae245ff1602d5f2dd70097f10501f0e5230d","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-z85m4","generateName":"daemon-set-","namespace":"daemonsets-6181","uid":"666b8e2f-3da3-4873-b691-dfd6b2acffd7","resourceVersion":"24156","creationTimestamp":"2022-11-29T12:14:05Z","deletionTimestamp":"2022-11-29T12:14:37Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"124d1357aa39046ee480aceda0825a4b7e01780060bfd41895721e0a00c1b1a6","cni.projectcalico.org/podIP":"100.96.2.183/32","cni.projectcalico.org/podIPs":"100.96.2.183/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3c86d81f-f792-465b-9b20-7ec97a488e16","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c86d81f-f792-465b-9b20-7ec97a488e16\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.183\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-j4hn5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-j4hn5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"dvi-7336-1669718118-vsp1-group1-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["dvi-7336-1669718118-vsp1-group1-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"}],"hostIP":"192.168.8.22","podIP":"100.96.2.183","podIPs":[{"ip":"100.96.2.183"}],"startTime":"2022-11-29T12:14:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-29T12:14:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://f93fac97475960bd70541aafb8a50f5f4001009e6f5163b78218d87ccbece709","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:14:07.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6181" for this suite. 11/29/22 12:14:07.522
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":170,"skipped":3174,"failed":0}
------------------------------
• [2.099 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:05.426
    Nov 29 12:14:05.426: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename daemonsets 11/29/22 12:14:05.427
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:05.436
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:05.439
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 11/29/22 12:14:05.452
    STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:14:05.455
    Nov 29 12:14:05.460: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:14:05.460: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:14:06.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:14:06.468: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:14:07.467: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 12:14:07.467: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: listing all DeamonSets 11/29/22 12:14:07.469
    STEP: DeleteCollection of the DaemonSets 11/29/22 12:14:07.472
    STEP: Verify that ReplicaSets have been deleted 11/29/22 12:14:07.475
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Nov 29 12:14:07.488: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24151"},"items":null}

    Nov 29 12:14:07.495: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24156"},"items":[{"metadata":{"name":"daemon-set-52b97","generateName":"daemon-set-","namespace":"daemonsets-6181","uid":"bbe05f8f-4487-4131-b3ad-34864a6d913e","resourceVersion":"24154","creationTimestamp":"2022-11-29T12:14:05Z","deletionTimestamp":"2022-11-29T12:14:37Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"2cf9fcdd348c5767a71bae64ca29f855787455e656996e695683c983d5aead26","cni.projectcalico.org/podIP":"100.96.1.107/32","cni.projectcalico.org/podIPs":"100.96.1.107/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3c86d81f-f792-465b-9b20-7ec97a488e16","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c86d81f-f792-465b-9b20-7ec97a488e16\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.107\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-czs4h","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-czs4h","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"dvi-7336-1669718118-vsp1-group1-0","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["dvi-7336-1669718118-vsp1-group1-0"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"}],"hostIP":"192.168.8.111","podIP":"100.96.1.107","podIPs":[{"ip":"100.96.1.107"}],"startTime":"2022-11-29T12:14:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-29T12:14:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://720945b383df0d11f93056c028385d0b61fea02ac1ae76ee6d2254eed28a6bea","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-b75sl","generateName":"daemon-set-","namespace":"daemonsets-6181","uid":"8e6b9608-9b00-490a-8dd7-6e5c0aca0f82","resourceVersion":"24153","creationTimestamp":"2022-11-29T12:14:05Z","deletionTimestamp":"2022-11-29T12:14:37Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"10f19d34350f27540695ef5975cce3d06cdf661dbae078bc1a01d9055ffe93c3","cni.projectcalico.org/podIP":"100.96.3.81/32","cni.projectcalico.org/podIPs":"100.96.3.81/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3c86d81f-f792-465b-9b20-7ec97a488e16","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c86d81f-f792-465b-9b20-7ec97a488e16\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.81\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-r4l58","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-r4l58","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"dvi-7336-1669718118-vsp1-group1-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["dvi-7336-1669718118-vsp1-group1-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"}],"hostIP":"192.168.8.35","podIP":"100.96.3.81","podIPs":[{"ip":"100.96.3.81"}],"startTime":"2022-11-29T12:14:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-29T12:14:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://8d2d03005183777e7a94275c4c7ac66d311f1ddb1297ace44bb4b1c0a419e217","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-qkst5","generateName":"daemon-set-","namespace":"daemonsets-6181","uid":"213dede9-d8f2-4471-9c92-e85c6d50d4ca","resourceVersion":"24155","creationTimestamp":"2022-11-29T12:14:05Z","deletionTimestamp":"2022-11-29T12:14:37Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"8678a42e063ab224a9bc9f599f5a51152b46be52622aa1969fee4818c0bcadc2","cni.projectcalico.org/podIP":"100.96.0.69/32","cni.projectcalico.org/podIPs":"100.96.0.69/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3c86d81f-f792-465b-9b20-7ec97a488e16","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c86d81f-f792-465b-9b20-7ec97a488e16\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-nlksx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-nlksx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"dvi-7336-1669718118-vsp1-master-0","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["dvi-7336-1669718118-vsp1-master-0"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:06Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:06Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"}],"hostIP":"192.168.8.155","podIP":"100.96.0.69","podIPs":[{"ip":"100.96.0.69"}],"startTime":"2022-11-29T12:14:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-29T12:14:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://f1465b930e01c11e05c23176f5bbae245ff1602d5f2dd70097f10501f0e5230d","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-z85m4","generateName":"daemon-set-","namespace":"daemonsets-6181","uid":"666b8e2f-3da3-4873-b691-dfd6b2acffd7","resourceVersion":"24156","creationTimestamp":"2022-11-29T12:14:05Z","deletionTimestamp":"2022-11-29T12:14:37Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"124d1357aa39046ee480aceda0825a4b7e01780060bfd41895721e0a00c1b1a6","cni.projectcalico.org/podIP":"100.96.2.183/32","cni.projectcalico.org/podIPs":"100.96.2.183/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3c86d81f-f792-465b-9b20-7ec97a488e16","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c86d81f-f792-465b-9b20-7ec97a488e16\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-29T12:14:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.183\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-j4hn5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-j4hn5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"dvi-7336-1669718118-vsp1-group1-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["dvi-7336-1669718118-vsp1-group1-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-29T12:14:05Z"}],"hostIP":"192.168.8.22","podIP":"100.96.2.183","podIPs":[{"ip":"100.96.2.183"}],"startTime":"2022-11-29T12:14:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-29T12:14:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://f93fac97475960bd70541aafb8a50f5f4001009e6f5163b78218d87ccbece709","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:14:07.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6181" for this suite. 11/29/22 12:14:07.522
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:07.526
Nov 29 12:14:07.526: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 12:14:07.527
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:07.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:07.539
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-1272/configmap-test-0d578e97-3fbd-4c02-be38-219744754ca4 11/29/22 12:14:07.542
STEP: Creating a pod to test consume configMaps 11/29/22 12:14:07.544
Nov 29 12:14:07.548: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3" in namespace "configmap-1272" to be "Succeeded or Failed"
Nov 29 12:14:07.551: INFO: Pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.739665ms
Nov 29 12:14:09.555: INFO: Pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00662529s
Nov 29 12:14:11.554: INFO: Pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005783069s
STEP: Saw pod success 11/29/22 12:14:11.554
Nov 29 12:14:11.555: INFO: Pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3" satisfied condition "Succeeded or Failed"
Nov 29 12:14:11.556: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3 container env-test: <nil>
STEP: delete the pod 11/29/22 12:14:11.56
Nov 29 12:14:11.565: INFO: Waiting for pod pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3 to disappear
Nov 29 12:14:11.567: INFO: Pod pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 12:14:11.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1272" for this suite. 11/29/22 12:14:11.57
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":171,"skipped":3181,"failed":0}
------------------------------
• [4.046 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:07.526
    Nov 29 12:14:07.526: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 12:14:07.527
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:07.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:07.539
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-1272/configmap-test-0d578e97-3fbd-4c02-be38-219744754ca4 11/29/22 12:14:07.542
    STEP: Creating a pod to test consume configMaps 11/29/22 12:14:07.544
    Nov 29 12:14:07.548: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3" in namespace "configmap-1272" to be "Succeeded or Failed"
    Nov 29 12:14:07.551: INFO: Pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.739665ms
    Nov 29 12:14:09.555: INFO: Pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00662529s
    Nov 29 12:14:11.554: INFO: Pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005783069s
    STEP: Saw pod success 11/29/22 12:14:11.554
    Nov 29 12:14:11.555: INFO: Pod "pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3" satisfied condition "Succeeded or Failed"
    Nov 29 12:14:11.556: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3 container env-test: <nil>
    STEP: delete the pod 11/29/22 12:14:11.56
    Nov 29 12:14:11.565: INFO: Waiting for pod pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3 to disappear
    Nov 29 12:14:11.567: INFO: Pod pod-configmaps-8f613b90-fcf5-4a2b-862d-c3d2255c01c3 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 12:14:11.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1272" for this suite. 11/29/22 12:14:11.57
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:11.573
Nov 29 12:14:11.573: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:14:11.574
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:11.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:11.585
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-d187cf0b-60ea-4ca5-a05f-f6f264599e5d 11/29/22 12:14:11.594
STEP: Creating a pod to test consume secrets 11/29/22 12:14:11.596
Nov 29 12:14:11.602: INFO: Waiting up to 5m0s for pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389" in namespace "secrets-4547" to be "Succeeded or Failed"
Nov 29 12:14:11.604: INFO: Pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.477194ms
Nov 29 12:14:13.607: INFO: Pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005671091s
Nov 29 12:14:15.608: INFO: Pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005941422s
STEP: Saw pod success 11/29/22 12:14:15.608
Nov 29 12:14:15.608: INFO: Pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389" satisfied condition "Succeeded or Failed"
Nov 29 12:14:15.610: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389 container secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:14:15.615
Nov 29 12:14:15.620: INFO: Waiting for pod pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389 to disappear
Nov 29 12:14:15.622: INFO: Pod pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:14:15.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4547" for this suite. 11/29/22 12:14:15.625
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":172,"skipped":3184,"failed":0}
------------------------------
• [4.055 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:11.573
    Nov 29 12:14:11.573: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:14:11.574
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:11.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:11.585
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-d187cf0b-60ea-4ca5-a05f-f6f264599e5d 11/29/22 12:14:11.594
    STEP: Creating a pod to test consume secrets 11/29/22 12:14:11.596
    Nov 29 12:14:11.602: INFO: Waiting up to 5m0s for pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389" in namespace "secrets-4547" to be "Succeeded or Failed"
    Nov 29 12:14:11.604: INFO: Pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.477194ms
    Nov 29 12:14:13.607: INFO: Pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005671091s
    Nov 29 12:14:15.608: INFO: Pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005941422s
    STEP: Saw pod success 11/29/22 12:14:15.608
    Nov 29 12:14:15.608: INFO: Pod "pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389" satisfied condition "Succeeded or Failed"
    Nov 29 12:14:15.610: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389 container secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:14:15.615
    Nov 29 12:14:15.620: INFO: Waiting for pod pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389 to disappear
    Nov 29 12:14:15.622: INFO: Pod pod-secrets-f18ba842-509b-4d27-b54a-1dc7dcc35389 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:14:15.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4547" for this suite. 11/29/22 12:14:15.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:15.629
Nov 29 12:14:15.630: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename tables 11/29/22 12:14:15.631
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:15.639
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:15.642
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Nov 29 12:14:15.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5072" for this suite. 11/29/22 12:14:15.658
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":173,"skipped":3213,"failed":0}
------------------------------
• [0.033 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:15.629
    Nov 29 12:14:15.630: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename tables 11/29/22 12:14:15.631
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:15.639
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:15.642
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Nov 29 12:14:15.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-5072" for this suite. 11/29/22 12:14:15.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:15.666
Nov 29 12:14:15.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:14:15.668
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:15.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:15.681
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-a3149002-d923-4106-b059-2f8da06dee9a 11/29/22 12:14:15.684
STEP: Creating a pod to test consume secrets 11/29/22 12:14:15.69
Nov 29 12:14:15.695: INFO: Waiting up to 5m0s for pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85" in namespace "secrets-8912" to be "Succeeded or Failed"
Nov 29 12:14:15.698: INFO: Pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85": Phase="Pending", Reason="", readiness=false. Elapsed: 3.078069ms
Nov 29 12:14:17.701: INFO: Pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006332847s
Nov 29 12:14:19.702: INFO: Pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007478296s
STEP: Saw pod success 11/29/22 12:14:19.702
Nov 29 12:14:19.702: INFO: Pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85" satisfied condition "Succeeded or Failed"
Nov 29 12:14:19.704: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85 container secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:14:19.708
Nov 29 12:14:19.714: INFO: Waiting for pod pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85 to disappear
Nov 29 12:14:19.716: INFO: Pod pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:14:19.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8912" for this suite. 11/29/22 12:14:19.719
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":174,"skipped":3223,"failed":0}
------------------------------
• [4.056 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:15.666
    Nov 29 12:14:15.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:14:15.668
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:15.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:15.681
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-a3149002-d923-4106-b059-2f8da06dee9a 11/29/22 12:14:15.684
    STEP: Creating a pod to test consume secrets 11/29/22 12:14:15.69
    Nov 29 12:14:15.695: INFO: Waiting up to 5m0s for pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85" in namespace "secrets-8912" to be "Succeeded or Failed"
    Nov 29 12:14:15.698: INFO: Pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85": Phase="Pending", Reason="", readiness=false. Elapsed: 3.078069ms
    Nov 29 12:14:17.701: INFO: Pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006332847s
    Nov 29 12:14:19.702: INFO: Pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007478296s
    STEP: Saw pod success 11/29/22 12:14:19.702
    Nov 29 12:14:19.702: INFO: Pod "pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85" satisfied condition "Succeeded or Failed"
    Nov 29 12:14:19.704: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85 container secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:14:19.708
    Nov 29 12:14:19.714: INFO: Waiting for pod pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85 to disappear
    Nov 29 12:14:19.716: INFO: Pod pod-secrets-29821fcf-3e77-4e80-8943-f3f959402d85 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:14:19.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8912" for this suite. 11/29/22 12:14:19.719
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:19.723
Nov 29 12:14:19.723: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:14:19.724
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:19.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:19.739
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:14:19.741
Nov 29 12:14:19.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f" in namespace "downward-api-6551" to be "Succeeded or Failed"
Nov 29 12:14:19.763: INFO: Pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.597069ms
Nov 29 12:14:21.766: INFO: Pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018452976s
Nov 29 12:14:23.766: INFO: Pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019316019s
STEP: Saw pod success 11/29/22 12:14:23.767
Nov 29 12:14:23.767: INFO: Pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f" satisfied condition "Succeeded or Failed"
Nov 29 12:14:23.769: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f container client-container: <nil>
STEP: delete the pod 11/29/22 12:14:23.773
Nov 29 12:14:23.778: INFO: Waiting for pod downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f to disappear
Nov 29 12:14:23.780: INFO: Pod downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:14:23.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6551" for this suite. 11/29/22 12:14:23.784
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":175,"skipped":3223,"failed":0}
------------------------------
• [4.064 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:19.723
    Nov 29 12:14:19.723: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:14:19.724
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:19.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:19.739
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:14:19.741
    Nov 29 12:14:19.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f" in namespace "downward-api-6551" to be "Succeeded or Failed"
    Nov 29 12:14:19.763: INFO: Pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.597069ms
    Nov 29 12:14:21.766: INFO: Pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018452976s
    Nov 29 12:14:23.766: INFO: Pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019316019s
    STEP: Saw pod success 11/29/22 12:14:23.767
    Nov 29 12:14:23.767: INFO: Pod "downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f" satisfied condition "Succeeded or Failed"
    Nov 29 12:14:23.769: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f container client-container: <nil>
    STEP: delete the pod 11/29/22 12:14:23.773
    Nov 29 12:14:23.778: INFO: Waiting for pod downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f to disappear
    Nov 29 12:14:23.780: INFO: Pod downwardapi-volume-84e38093-0831-4a93-87f7-b22e62af5d0f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:14:23.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6551" for this suite. 11/29/22 12:14:23.784
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:23.788
Nov 29 12:14:23.789: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-lifecycle-hook 11/29/22 12:14:23.789
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:23.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:23.804
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/29/22 12:14:23.809
Nov 29 12:14:23.814: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8123" to be "running and ready"
Nov 29 12:14:23.819: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.78921ms
Nov 29 12:14:23.819: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:14:25.822: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.007476762s
Nov 29 12:14:25.822: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 29 12:14:25.822: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 11/29/22 12:14:25.824
Nov 29 12:14:25.827: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-8123" to be "running and ready"
Nov 29 12:14:25.831: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.000688ms
Nov 29 12:14:25.831: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:14:27.835: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.007614722s
Nov 29 12:14:27.835: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Nov 29 12:14:27.835: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/29/22 12:14:27.837
Nov 29 12:14:27.840: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 29 12:14:27.842: INFO: Pod pod-with-prestop-http-hook still exists
Nov 29 12:14:29.843: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 29 12:14:29.846: INFO: Pod pod-with-prestop-http-hook still exists
Nov 29 12:14:31.843: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 29 12:14:31.845: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 11/29/22 12:14:31.846
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 29 12:14:31.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8123" for this suite. 11/29/22 12:14:31.862
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":176,"skipped":3230,"failed":0}
------------------------------
• [SLOW TEST] [8.076 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:23.788
    Nov 29 12:14:23.789: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/29/22 12:14:23.789
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:23.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:23.804
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/29/22 12:14:23.809
    Nov 29 12:14:23.814: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8123" to be "running and ready"
    Nov 29 12:14:23.819: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.78921ms
    Nov 29 12:14:23.819: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:14:25.822: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.007476762s
    Nov 29 12:14:25.822: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 29 12:14:25.822: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 11/29/22 12:14:25.824
    Nov 29 12:14:25.827: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-8123" to be "running and ready"
    Nov 29 12:14:25.831: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.000688ms
    Nov 29 12:14:25.831: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:14:27.835: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.007614722s
    Nov 29 12:14:27.835: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Nov 29 12:14:27.835: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/29/22 12:14:27.837
    Nov 29 12:14:27.840: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 29 12:14:27.842: INFO: Pod pod-with-prestop-http-hook still exists
    Nov 29 12:14:29.843: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 29 12:14:29.846: INFO: Pod pod-with-prestop-http-hook still exists
    Nov 29 12:14:31.843: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 29 12:14:31.845: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 11/29/22 12:14:31.846
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 29 12:14:31.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8123" for this suite. 11/29/22 12:14:31.862
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:31.865
Nov 29 12:14:31.865: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename watch 11/29/22 12:14:31.866
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:31.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:31.875
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 11/29/22 12:14:31.877
STEP: creating a watch on configmaps with label B 11/29/22 12:14:31.878
STEP: creating a watch on configmaps with label A or B 11/29/22 12:14:31.879
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/29/22 12:14:31.88
Nov 29 12:14:31.882: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24400 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 12:14:31.883: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24400 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/29/22 12:14:31.883
Nov 29 12:14:31.887: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24401 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 12:14:31.887: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24401 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/29/22 12:14:31.887
Nov 29 12:14:31.890: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24402 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 12:14:31.890: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24402 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/29/22 12:14:31.89
Nov 29 12:14:31.896: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24403 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 12:14:31.896: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24403 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/29/22 12:14:31.896
Nov 29 12:14:31.898: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3359  0e329d91-9855-40c2-92c9-46b832765790 24404 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 12:14:31.899: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3359  0e329d91-9855-40c2-92c9-46b832765790 24404 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/29/22 12:14:41.9
Nov 29 12:14:41.904: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3359  0e329d91-9855-40c2-92c9-46b832765790 24441 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 12:14:41.904: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3359  0e329d91-9855-40c2-92c9-46b832765790 24441 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 29 12:14:51.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3359" for this suite. 11/29/22 12:14:51.914
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":177,"skipped":3236,"failed":0}
------------------------------
• [SLOW TEST] [20.054 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:31.865
    Nov 29 12:14:31.865: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename watch 11/29/22 12:14:31.866
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:31.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:31.875
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 11/29/22 12:14:31.877
    STEP: creating a watch on configmaps with label B 11/29/22 12:14:31.878
    STEP: creating a watch on configmaps with label A or B 11/29/22 12:14:31.879
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/29/22 12:14:31.88
    Nov 29 12:14:31.882: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24400 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 12:14:31.883: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24400 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/29/22 12:14:31.883
    Nov 29 12:14:31.887: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24401 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 12:14:31.887: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24401 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/29/22 12:14:31.887
    Nov 29 12:14:31.890: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24402 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 12:14:31.890: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24402 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/29/22 12:14:31.89
    Nov 29 12:14:31.896: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24403 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 12:14:31.896: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3359  4a9e82e1-abfa-4b67-9e36-49d531745354 24403 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/29/22 12:14:31.896
    Nov 29 12:14:31.898: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3359  0e329d91-9855-40c2-92c9-46b832765790 24404 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 12:14:31.899: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3359  0e329d91-9855-40c2-92c9-46b832765790 24404 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/29/22 12:14:41.9
    Nov 29 12:14:41.904: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3359  0e329d91-9855-40c2-92c9-46b832765790 24441 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 12:14:41.904: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3359  0e329d91-9855-40c2-92c9-46b832765790 24441 0 2022-11-29 12:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-29 12:14:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 29 12:14:51.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3359" for this suite. 11/29/22 12:14:51.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:14:51.922
Nov 29 12:14:51.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename deployment 11/29/22 12:14:51.924
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:51.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:51.943
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Nov 29 12:14:51.953: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 29 12:14:56.958: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/29/22 12:14:56.958
Nov 29 12:14:56.958: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 29 12:14:58.961: INFO: Creating deployment "test-rollover-deployment"
Nov 29 12:14:58.966: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 29 12:15:00.973: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 29 12:15:00.979: INFO: Ensure that both replica sets have 1 created replica
Nov 29 12:15:00.984: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 29 12:15:00.990: INFO: Updating deployment test-rollover-deployment
Nov 29 12:15:00.990: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 29 12:15:02.998: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 29 12:15:03.002: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 29 12:15:03.006: INFO: all replica sets need to contain the pod-template-hash label
Nov 29 12:15:03.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 12:15:05.011: INFO: all replica sets need to contain the pod-template-hash label
Nov 29 12:15:05.011: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 12:15:07.014: INFO: all replica sets need to contain the pod-template-hash label
Nov 29 12:15:07.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 12:15:09.011: INFO: all replica sets need to contain the pod-template-hash label
Nov 29 12:15:09.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 12:15:11.013: INFO: all replica sets need to contain the pod-template-hash label
Nov 29 12:15:11.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 12:15:13.013: INFO: 
Nov 29 12:15:13.013: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 29 12:15:13.019: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7417  3d370ab5-3912-4a64-9e90-5ba8bd5b3f17 24589 2 2022-11-29 12:14:58 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002410148 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-29 12:14:58 +0000 UTC,LastTransitionTime:2022-11-29 12:14:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-29 12:15:12 +0000 UTC,LastTransitionTime:2022-11-29 12:14:58 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 29 12:15:13.022: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7417  8555e0a1-b9fe-45ce-9484-0bb82291abc1 24579 2 2022-11-29 12:15:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 3d370ab5-3912-4a64-9e90-5ba8bd5b3f17 0xc002410a57 0xc002410a58}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d370ab5-3912-4a64-9e90-5ba8bd5b3f17\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:12 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002410b08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 29 12:15:13.022: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 29 12:15:13.022: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7417  bf2557fb-2617-4a05-afe2-a146a8ba65bf 24588 2 2022-11-29 12:14:51 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 3d370ab5-3912-4a64-9e90-5ba8bd5b3f17 0xc0024107f7 0xc0024107f8}] [] [{e2e.test Update apps/v1 2022-11-29 12:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d370ab5-3912-4a64-9e90-5ba8bd5b3f17\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:12 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0024108b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 29 12:15:13.022: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7417  ed364737-b7fd-4d91-ba4b-5102c3847c48 24532 2 2022-11-29 12:14:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 3d370ab5-3912-4a64-9e90-5ba8bd5b3f17 0xc002410927 0xc002410928}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d370ab5-3912-4a64-9e90-5ba8bd5b3f17\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0024109d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 29 12:15:13.026: INFO: Pod "test-rollover-deployment-6d45fd857b-d7m7s" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-d7m7s test-rollover-deployment-6d45fd857b- deployment-7417  d93c687a-be7b-4762-8054-0486b303a295 24552 0 2022-11-29 12:15:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:ed9fe5702c2870f059c0f5f554a00f194ff9571633d864a25c1c1fb5aa95a576 cni.projectcalico.org/podIP:100.96.2.187/32 cni.projectcalico.org/podIPs:100.96.2.187/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 8555e0a1-b9fe-45ce-9484-0bb82291abc1 0xc003d905d7 0xc003d905d8}] [] [{kube-controller-manager Update v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8555e0a1-b9fe-45ce-9484-0bb82291abc1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:15:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:15:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.187\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kj5p2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kj5p2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:15:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:15:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:15:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:15:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.187,StartTime:2022-11-29 12:15:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:15:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://f77fdc25af44e917b8e1cd6478bb9ffa4ee63b7f80374daee96b68d66d535f2e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.187,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 29 12:15:13.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7417" for this suite. 11/29/22 12:15:13.029
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":178,"skipped":3247,"failed":0}
------------------------------
• [SLOW TEST] [21.111 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:14:51.922
    Nov 29 12:14:51.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename deployment 11/29/22 12:14:51.924
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:14:51.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:14:51.943
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Nov 29 12:14:51.953: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Nov 29 12:14:56.958: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/29/22 12:14:56.958
    Nov 29 12:14:56.958: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Nov 29 12:14:58.961: INFO: Creating deployment "test-rollover-deployment"
    Nov 29 12:14:58.966: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Nov 29 12:15:00.973: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Nov 29 12:15:00.979: INFO: Ensure that both replica sets have 1 created replica
    Nov 29 12:15:00.984: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Nov 29 12:15:00.990: INFO: Updating deployment test-rollover-deployment
    Nov 29 12:15:00.990: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Nov 29 12:15:02.998: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Nov 29 12:15:03.002: INFO: Make sure deployment "test-rollover-deployment" is complete
    Nov 29 12:15:03.006: INFO: all replica sets need to contain the pod-template-hash label
    Nov 29 12:15:03.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 12:15:05.011: INFO: all replica sets need to contain the pod-template-hash label
    Nov 29 12:15:05.011: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 12:15:07.014: INFO: all replica sets need to contain the pod-template-hash label
    Nov 29 12:15:07.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 12:15:09.011: INFO: all replica sets need to contain the pod-template-hash label
    Nov 29 12:15:09.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 12:15:11.013: INFO: all replica sets need to contain the pod-template-hash label
    Nov 29 12:15:11.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 15, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 14, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 12:15:13.013: INFO: 
    Nov 29 12:15:13.013: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 29 12:15:13.019: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-7417  3d370ab5-3912-4a64-9e90-5ba8bd5b3f17 24589 2 2022-11-29 12:14:58 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002410148 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-29 12:14:58 +0000 UTC,LastTransitionTime:2022-11-29 12:14:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-29 12:15:12 +0000 UTC,LastTransitionTime:2022-11-29 12:14:58 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 29 12:15:13.022: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7417  8555e0a1-b9fe-45ce-9484-0bb82291abc1 24579 2 2022-11-29 12:15:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 3d370ab5-3912-4a64-9e90-5ba8bd5b3f17 0xc002410a57 0xc002410a58}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d370ab5-3912-4a64-9e90-5ba8bd5b3f17\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:12 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002410b08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 12:15:13.022: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Nov 29 12:15:13.022: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7417  bf2557fb-2617-4a05-afe2-a146a8ba65bf 24588 2 2022-11-29 12:14:51 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 3d370ab5-3912-4a64-9e90-5ba8bd5b3f17 0xc0024107f7 0xc0024107f8}] [] [{e2e.test Update apps/v1 2022-11-29 12:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d370ab5-3912-4a64-9e90-5ba8bd5b3f17\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:12 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0024108b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 12:15:13.022: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7417  ed364737-b7fd-4d91-ba4b-5102c3847c48 24532 2 2022-11-29 12:14:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 3d370ab5-3912-4a64-9e90-5ba8bd5b3f17 0xc002410927 0xc002410928}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d370ab5-3912-4a64-9e90-5ba8bd5b3f17\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0024109d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 12:15:13.026: INFO: Pod "test-rollover-deployment-6d45fd857b-d7m7s" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-d7m7s test-rollover-deployment-6d45fd857b- deployment-7417  d93c687a-be7b-4762-8054-0486b303a295 24552 0 2022-11-29 12:15:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:ed9fe5702c2870f059c0f5f554a00f194ff9571633d864a25c1c1fb5aa95a576 cni.projectcalico.org/podIP:100.96.2.187/32 cni.projectcalico.org/podIPs:100.96.2.187/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 8555e0a1-b9fe-45ce-9484-0bb82291abc1 0xc003d905d7 0xc003d905d8}] [] [{kube-controller-manager Update v1 2022-11-29 12:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8555e0a1-b9fe-45ce-9484-0bb82291abc1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:15:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:15:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.187\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kj5p2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kj5p2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:15:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:15:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:15:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:15:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.187,StartTime:2022-11-29 12:15:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:15:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://f77fdc25af44e917b8e1cd6478bb9ffa4ee63b7f80374daee96b68d66d535f2e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.187,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 29 12:15:13.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7417" for this suite. 11/29/22 12:15:13.029
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:15:13.035
Nov 29 12:15:13.035: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replicaset 11/29/22 12:15:13.035
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:15:13.043
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:15:13.045
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/29/22 12:15:13.046
Nov 29 12:15:13.051: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 29 12:15:18.058: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/29/22 12:15:18.058
STEP: getting scale subresource 11/29/22 12:15:18.058
STEP: updating a scale subresource 11/29/22 12:15:18.062
STEP: verifying the replicaset Spec.Replicas was modified 11/29/22 12:15:18.065
STEP: Patch a scale subresource 11/29/22 12:15:18.068
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 29 12:15:18.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5999" for this suite. 11/29/22 12:15:18.083
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":179,"skipped":3274,"failed":0}
------------------------------
• [SLOW TEST] [5.055 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:15:13.035
    Nov 29 12:15:13.035: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replicaset 11/29/22 12:15:13.035
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:15:13.043
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:15:13.045
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/29/22 12:15:13.046
    Nov 29 12:15:13.051: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 29 12:15:18.058: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/29/22 12:15:18.058
    STEP: getting scale subresource 11/29/22 12:15:18.058
    STEP: updating a scale subresource 11/29/22 12:15:18.062
    STEP: verifying the replicaset Spec.Replicas was modified 11/29/22 12:15:18.065
    STEP: Patch a scale subresource 11/29/22 12:15:18.068
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 29 12:15:18.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5999" for this suite. 11/29/22 12:15:18.083
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:15:18.09
Nov 29 12:15:18.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replicaset 11/29/22 12:15:18.091
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:15:18.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:15:18.131
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 11/29/22 12:15:18.14
STEP: Verify that the required pods have come up. 11/29/22 12:15:18.147
Nov 29 12:15:18.160: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 29 12:15:23.165: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/29/22 12:15:23.166
STEP: Getting /status 11/29/22 12:15:23.166
Nov 29 12:15:23.173: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 11/29/22 12:15:23.173
Nov 29 12:15:23.184: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 11/29/22 12:15:23.184
Nov 29 12:15:23.186: INFO: Observed &ReplicaSet event: ADDED
Nov 29 12:15:23.186: INFO: Observed &ReplicaSet event: MODIFIED
Nov 29 12:15:23.186: INFO: Observed &ReplicaSet event: MODIFIED
Nov 29 12:15:23.187: INFO: Observed &ReplicaSet event: MODIFIED
Nov 29 12:15:23.187: INFO: Found replicaset test-rs in namespace replicaset-3066 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 29 12:15:23.187: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 11/29/22 12:15:23.187
Nov 29 12:15:23.187: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 29 12:15:23.191: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 11/29/22 12:15:23.192
Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: ADDED
Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: MODIFIED
Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: MODIFIED
Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: MODIFIED
Nov 29 12:15:23.194: INFO: Observed replicaset test-rs in namespace replicaset-3066 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: MODIFIED
Nov 29 12:15:23.194: INFO: Found replicaset test-rs in namespace replicaset-3066 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Nov 29 12:15:23.194: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 29 12:15:23.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3066" for this suite. 11/29/22 12:15:23.197
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":180,"skipped":3279,"failed":0}
------------------------------
• [SLOW TEST] [5.111 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:15:18.09
    Nov 29 12:15:18.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replicaset 11/29/22 12:15:18.091
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:15:18.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:15:18.131
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 11/29/22 12:15:18.14
    STEP: Verify that the required pods have come up. 11/29/22 12:15:18.147
    Nov 29 12:15:18.160: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 29 12:15:23.165: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/29/22 12:15:23.166
    STEP: Getting /status 11/29/22 12:15:23.166
    Nov 29 12:15:23.173: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 11/29/22 12:15:23.173
    Nov 29 12:15:23.184: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 11/29/22 12:15:23.184
    Nov 29 12:15:23.186: INFO: Observed &ReplicaSet event: ADDED
    Nov 29 12:15:23.186: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 29 12:15:23.186: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 29 12:15:23.187: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 29 12:15:23.187: INFO: Found replicaset test-rs in namespace replicaset-3066 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 29 12:15:23.187: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 11/29/22 12:15:23.187
    Nov 29 12:15:23.187: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 29 12:15:23.191: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 11/29/22 12:15:23.192
    Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: ADDED
    Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 29 12:15:23.194: INFO: Observed replicaset test-rs in namespace replicaset-3066 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 29 12:15:23.194: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 29 12:15:23.194: INFO: Found replicaset test-rs in namespace replicaset-3066 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Nov 29 12:15:23.194: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 29 12:15:23.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3066" for this suite. 11/29/22 12:15:23.197
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:15:23.203
Nov 29 12:15:23.203: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename dns 11/29/22 12:15:23.204
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:15:23.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:15:23.214
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 11/29/22 12:15:23.217
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8106.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8106.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 37.27.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.27.37_udp@PTR;check="$$(dig +tcp +noall +answer +search 37.27.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.27.37_tcp@PTR;sleep 1; done
 11/29/22 12:15:23.237
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8106.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8106.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 37.27.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.27.37_udp@PTR;check="$$(dig +tcp +noall +answer +search 37.27.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.27.37_tcp@PTR;sleep 1; done
 11/29/22 12:15:23.237
STEP: creating a pod to probe DNS 11/29/22 12:15:23.237
STEP: submitting the pod to kubernetes 11/29/22 12:15:23.237
Nov 29 12:15:23.247: INFO: Waiting up to 15m0s for pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541" in namespace "dns-8106" to be "running"
Nov 29 12:15:23.259: INFO: Pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541": Phase="Pending", Reason="", readiness=false. Elapsed: 12.153138ms
Nov 29 12:15:25.263: INFO: Pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016505052s
Nov 29 12:15:27.263: INFO: Pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541": Phase="Running", Reason="", readiness=true. Elapsed: 4.015908055s
Nov 29 12:15:27.263: INFO: Pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541" satisfied condition "running"
STEP: retrieving the pod 11/29/22 12:15:27.263
STEP: looking for the results for each expected name from probers 11/29/22 12:15:27.265
Nov 29 12:15:27.269: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:27.272: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:27.275: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:27.279: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:27.295: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:27.297: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:27.299: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:27.301: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:27.311: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

Nov 29 12:15:32.315: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:32.319: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:32.322: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:32.324: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:32.334: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:32.337: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:32.339: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:32.340: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:32.347: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

Nov 29 12:15:37.321: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:37.326: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:37.334: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:37.336: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:37.359: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:37.362: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:37.365: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:37.368: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:37.381: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

Nov 29 12:15:42.320: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:42.324: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:42.327: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:42.329: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:42.343: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:42.345: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:42.347: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:42.349: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:42.358: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

Nov 29 12:15:47.322: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:47.325: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:47.328: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:47.330: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:47.342: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:47.343: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:47.345: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:47.347: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:47.355: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

Nov 29 12:15:52.316: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:52.319: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:52.321: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:52.323: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:52.335: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:52.337: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:52.340: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:52.342: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
Nov 29 12:15:52.352: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

Nov 29 12:15:57.357: INFO: DNS probes using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 succeeded

STEP: deleting the pod 11/29/22 12:15:57.357
STEP: deleting the test service 11/29/22 12:15:57.366
STEP: deleting the test headless service 11/29/22 12:15:57.391
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 29 12:15:57.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8106" for this suite. 11/29/22 12:15:57.403
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":181,"skipped":3280,"failed":0}
------------------------------
• [SLOW TEST] [34.214 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:15:23.203
    Nov 29 12:15:23.203: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename dns 11/29/22 12:15:23.204
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:15:23.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:15:23.214
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 11/29/22 12:15:23.217
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8106.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8106.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 37.27.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.27.37_udp@PTR;check="$$(dig +tcp +noall +answer +search 37.27.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.27.37_tcp@PTR;sleep 1; done
     11/29/22 12:15:23.237
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8106.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8106.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8106.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8106.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8106.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 37.27.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.27.37_udp@PTR;check="$$(dig +tcp +noall +answer +search 37.27.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.27.37_tcp@PTR;sleep 1; done
     11/29/22 12:15:23.237
    STEP: creating a pod to probe DNS 11/29/22 12:15:23.237
    STEP: submitting the pod to kubernetes 11/29/22 12:15:23.237
    Nov 29 12:15:23.247: INFO: Waiting up to 15m0s for pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541" in namespace "dns-8106" to be "running"
    Nov 29 12:15:23.259: INFO: Pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541": Phase="Pending", Reason="", readiness=false. Elapsed: 12.153138ms
    Nov 29 12:15:25.263: INFO: Pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016505052s
    Nov 29 12:15:27.263: INFO: Pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541": Phase="Running", Reason="", readiness=true. Elapsed: 4.015908055s
    Nov 29 12:15:27.263: INFO: Pod "dns-test-30cf909b-8159-444c-a154-0e3c36b21541" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 12:15:27.263
    STEP: looking for the results for each expected name from probers 11/29/22 12:15:27.265
    Nov 29 12:15:27.269: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:27.272: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:27.275: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:27.279: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:27.295: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:27.297: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:27.299: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:27.301: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:27.311: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

    Nov 29 12:15:32.315: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:32.319: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:32.322: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:32.324: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:32.334: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:32.337: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:32.339: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:32.340: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:32.347: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

    Nov 29 12:15:37.321: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:37.326: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:37.334: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:37.336: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:37.359: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:37.362: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:37.365: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:37.368: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:37.381: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

    Nov 29 12:15:42.320: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:42.324: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:42.327: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:42.329: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:42.343: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:42.345: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:42.347: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:42.349: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:42.358: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

    Nov 29 12:15:47.322: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:47.325: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:47.328: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:47.330: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:47.342: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:47.343: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:47.345: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:47.347: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:47.355: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

    Nov 29 12:15:52.316: INFO: Unable to read wheezy_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:52.319: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:52.321: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:52.323: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:52.335: INFO: Unable to read jessie_udp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:52.337: INFO: Unable to read jessie_tcp@dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:52.340: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:52.342: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local from pod dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541: the server could not find the requested resource (get pods dns-test-30cf909b-8159-444c-a154-0e3c36b21541)
    Nov 29 12:15:52.352: INFO: Lookups using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 failed for: [wheezy_udp@dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@dns-test-service.dns-8106.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_udp@dns-test-service.dns-8106.svc.cluster.local jessie_tcp@dns-test-service.dns-8106.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8106.svc.cluster.local]

    Nov 29 12:15:57.357: INFO: DNS probes using dns-8106/dns-test-30cf909b-8159-444c-a154-0e3c36b21541 succeeded

    STEP: deleting the pod 11/29/22 12:15:57.357
    STEP: deleting the test service 11/29/22 12:15:57.366
    STEP: deleting the test headless service 11/29/22 12:15:57.391
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 29 12:15:57.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8106" for this suite. 11/29/22 12:15:57.403
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:15:57.419
Nov 29 12:15:57.420: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename init-container 11/29/22 12:15:57.42
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:15:57.433
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:15:57.436
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 11/29/22 12:15:57.439
Nov 29 12:15:57.439: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 29 12:16:02.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5058" for this suite. 11/29/22 12:16:02.385
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":182,"skipped":3304,"failed":0}
------------------------------
• [4.969 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:15:57.419
    Nov 29 12:15:57.420: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename init-container 11/29/22 12:15:57.42
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:15:57.433
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:15:57.436
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 11/29/22 12:15:57.439
    Nov 29 12:15:57.439: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 29 12:16:02.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5058" for this suite. 11/29/22 12:16:02.385
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:16:02.393
Nov 29 12:16:02.393: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:16:02.394
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:02.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:02.404
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:16:02.413
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:16:03.252
STEP: Deploying the webhook pod 11/29/22 12:16:03.26
STEP: Wait for the deployment to be ready 11/29/22 12:16:03.267
Nov 29 12:16:03.274: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:16:05.282
STEP: Verifying the service has paired with the endpoint 11/29/22 12:16:05.287
Nov 29 12:16:06.287: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 11/29/22 12:16:06.292
Nov 29 12:16:16.316: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource definition that should be denied by the webhook 11/29/22 12:16:16.427
Nov 29 12:16:16.427: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:16:16.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4172" for this suite. 11/29/22 12:16:16.444
STEP: Destroying namespace "webhook-4172-markers" for this suite. 11/29/22 12:16:16.446
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":183,"skipped":3364,"failed":0}
------------------------------
• [SLOW TEST] [14.080 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:16:02.393
    Nov 29 12:16:02.393: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:16:02.394
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:02.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:02.404
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:16:02.413
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:16:03.252
    STEP: Deploying the webhook pod 11/29/22 12:16:03.26
    STEP: Wait for the deployment to be ready 11/29/22 12:16:03.267
    Nov 29 12:16:03.274: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:16:05.282
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:16:05.287
    Nov 29 12:16:06.287: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 11/29/22 12:16:06.292
    Nov 29 12:16:16.316: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource definition that should be denied by the webhook 11/29/22 12:16:16.427
    Nov 29 12:16:16.427: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:16:16.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4172" for this suite. 11/29/22 12:16:16.444
    STEP: Destroying namespace "webhook-4172-markers" for this suite. 11/29/22 12:16:16.446
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:16:16.474
Nov 29 12:16:16.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:16:16.476
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:16.488
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:16.491
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-42077ae9-4342-43d1-b357-0399c1baf0c3 11/29/22 12:16:16.494
STEP: Creating a pod to test consume secrets 11/29/22 12:16:16.497
Nov 29 12:16:16.503: INFO: Waiting up to 5m0s for pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746" in namespace "secrets-3185" to be "Succeeded or Failed"
Nov 29 12:16:16.507: INFO: Pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746": Phase="Pending", Reason="", readiness=false. Elapsed: 3.318429ms
Nov 29 12:16:18.511: INFO: Pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007471676s
Nov 29 12:16:20.511: INFO: Pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008032586s
STEP: Saw pod success 11/29/22 12:16:20.511
Nov 29 12:16:20.512: INFO: Pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746" satisfied condition "Succeeded or Failed"
Nov 29 12:16:20.514: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746 container secret-env-test: <nil>
STEP: delete the pod 11/29/22 12:16:20.525
Nov 29 12:16:20.532: INFO: Waiting for pod pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746 to disappear
Nov 29 12:16:20.535: INFO: Pod pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:16:20.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3185" for this suite. 11/29/22 12:16:20.538
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":184,"skipped":3376,"failed":0}
------------------------------
• [4.067 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:16:16.474
    Nov 29 12:16:16.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:16:16.476
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:16.488
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:16.491
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-42077ae9-4342-43d1-b357-0399c1baf0c3 11/29/22 12:16:16.494
    STEP: Creating a pod to test consume secrets 11/29/22 12:16:16.497
    Nov 29 12:16:16.503: INFO: Waiting up to 5m0s for pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746" in namespace "secrets-3185" to be "Succeeded or Failed"
    Nov 29 12:16:16.507: INFO: Pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746": Phase="Pending", Reason="", readiness=false. Elapsed: 3.318429ms
    Nov 29 12:16:18.511: INFO: Pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007471676s
    Nov 29 12:16:20.511: INFO: Pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008032586s
    STEP: Saw pod success 11/29/22 12:16:20.511
    Nov 29 12:16:20.512: INFO: Pod "pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746" satisfied condition "Succeeded or Failed"
    Nov 29 12:16:20.514: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746 container secret-env-test: <nil>
    STEP: delete the pod 11/29/22 12:16:20.525
    Nov 29 12:16:20.532: INFO: Waiting for pod pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746 to disappear
    Nov 29 12:16:20.535: INFO: Pod pod-secrets-a8dd2ff5-01e6-46de-8f03-785ef8e62746 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:16:20.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3185" for this suite. 11/29/22 12:16:20.538
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:16:20.542
Nov 29 12:16:20.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:16:20.543
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:20.559
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:20.562
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:16:20.572
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:16:21.071
STEP: Deploying the webhook pod 11/29/22 12:16:21.075
STEP: Wait for the deployment to be ready 11/29/22 12:16:21.08
Nov 29 12:16:21.084: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/29/22 12:16:23.093
STEP: Verifying the service has paired with the endpoint 11/29/22 12:16:23.127
Nov 29 12:16:24.127: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Nov 29 12:16:24.130: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3847-crds.webhook.example.com via the AdmissionRegistration API 11/29/22 12:16:24.641
Nov 29 12:16:27.461: INFO: Waiting for webhook configuration to be ready...
Nov 29 12:16:30.463: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook 11/29/22 12:16:30.576
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:16:31.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5212" for this suite. 11/29/22 12:16:31.316
STEP: Destroying namespace "webhook-5212-markers" for this suite. 11/29/22 12:16:31.321
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":185,"skipped":3399,"failed":0}
------------------------------
• [SLOW TEST] [10.810 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:16:20.542
    Nov 29 12:16:20.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:16:20.543
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:20.559
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:20.562
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:16:20.572
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:16:21.071
    STEP: Deploying the webhook pod 11/29/22 12:16:21.075
    STEP: Wait for the deployment to be ready 11/29/22 12:16:21.08
    Nov 29 12:16:21.084: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/29/22 12:16:23.093
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:16:23.127
    Nov 29 12:16:24.127: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Nov 29 12:16:24.130: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3847-crds.webhook.example.com via the AdmissionRegistration API 11/29/22 12:16:24.641
    Nov 29 12:16:27.461: INFO: Waiting for webhook configuration to be ready...
    Nov 29 12:16:30.463: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource that should be mutated by the webhook 11/29/22 12:16:30.576
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:16:31.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5212" for this suite. 11/29/22 12:16:31.316
    STEP: Destroying namespace "webhook-5212-markers" for this suite. 11/29/22 12:16:31.321
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:16:31.353
Nov 29 12:16:31.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replication-controller 11/29/22 12:16:31.354
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:31.365
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:31.367
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020 11/29/22 12:16:31.37
Nov 29 12:16:31.376: INFO: Pod name my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020: Found 0 pods out of 1
Nov 29 12:16:36.386: INFO: Pod name my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020: Found 1 pods out of 1
Nov 29 12:16:36.386: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020" are running
Nov 29 12:16:36.386: INFO: Waiting up to 5m0s for pod "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk" in namespace "replication-controller-306" to be "running"
Nov 29 12:16:36.389: INFO: Pod "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk": Phase="Running", Reason="", readiness=true. Elapsed: 2.905857ms
Nov 29 12:16:36.389: INFO: Pod "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk" satisfied condition "running"
Nov 29 12:16:36.389: INFO: Pod "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 12:16:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 12:16:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 12:16:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 12:16:31 +0000 UTC Reason: Message:}])
Nov 29 12:16:36.389: INFO: Trying to dial the pod
Nov 29 12:16:41.398: INFO: Controller my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020: Got expected result from replica 1 [my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk]: "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 29 12:16:41.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-306" for this suite. 11/29/22 12:16:41.401
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":186,"skipped":3418,"failed":0}
------------------------------
• [SLOW TEST] [10.051 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:16:31.353
    Nov 29 12:16:31.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replication-controller 11/29/22 12:16:31.354
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:31.365
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:31.367
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020 11/29/22 12:16:31.37
    Nov 29 12:16:31.376: INFO: Pod name my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020: Found 0 pods out of 1
    Nov 29 12:16:36.386: INFO: Pod name my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020: Found 1 pods out of 1
    Nov 29 12:16:36.386: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020" are running
    Nov 29 12:16:36.386: INFO: Waiting up to 5m0s for pod "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk" in namespace "replication-controller-306" to be "running"
    Nov 29 12:16:36.389: INFO: Pod "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk": Phase="Running", Reason="", readiness=true. Elapsed: 2.905857ms
    Nov 29 12:16:36.389: INFO: Pod "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk" satisfied condition "running"
    Nov 29 12:16:36.389: INFO: Pod "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 12:16:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 12:16:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 12:16:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-29 12:16:31 +0000 UTC Reason: Message:}])
    Nov 29 12:16:36.389: INFO: Trying to dial the pod
    Nov 29 12:16:41.398: INFO: Controller my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020: Got expected result from replica 1 [my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk]: "my-hostname-basic-ac8f6789-ec2c-48c3-a2b9-ce7556f13020-kwhxk", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 29 12:16:41.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-306" for this suite. 11/29/22 12:16:41.401
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:16:41.404
Nov 29 12:16:41.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 12:16:41.405
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:41.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:41.415
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 11/29/22 12:16:41.417
STEP: fetching the ConfigMap 11/29/22 12:16:41.42
STEP: patching the ConfigMap 11/29/22 12:16:41.422
STEP: listing all ConfigMaps in all namespaces with a label selector 11/29/22 12:16:41.425
STEP: deleting the ConfigMap by collection with a label selector 11/29/22 12:16:41.428
STEP: listing all ConfigMaps in test namespace 11/29/22 12:16:41.431
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 12:16:41.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1702" for this suite. 11/29/22 12:16:41.437
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":187,"skipped":3421,"failed":0}
------------------------------
• [0.036 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:16:41.404
    Nov 29 12:16:41.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 12:16:41.405
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:41.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:41.415
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 11/29/22 12:16:41.417
    STEP: fetching the ConfigMap 11/29/22 12:16:41.42
    STEP: patching the ConfigMap 11/29/22 12:16:41.422
    STEP: listing all ConfigMaps in all namespaces with a label selector 11/29/22 12:16:41.425
    STEP: deleting the ConfigMap by collection with a label selector 11/29/22 12:16:41.428
    STEP: listing all ConfigMaps in test namespace 11/29/22 12:16:41.431
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 12:16:41.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1702" for this suite. 11/29/22 12:16:41.437
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:16:41.441
Nov 29 12:16:41.441: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 12:16:41.442
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:41.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:41.453
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 11/29/22 12:16:41.456
STEP: submitting the pod to kubernetes 11/29/22 12:16:41.456
Nov 29 12:16:41.462: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55" in namespace "pods-6149" to be "running and ready"
Nov 29 12:16:41.465: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.096666ms
Nov 29 12:16:41.465: INFO: The phase of Pod pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:16:43.469: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.006599056s
Nov 29 12:16:43.469: INFO: The phase of Pod pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55 is Running (Ready = true)
Nov 29 12:16:43.469: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/29/22 12:16:43.471
STEP: updating the pod 11/29/22 12:16:43.474
Nov 29 12:16:43.988: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55"
Nov 29 12:16:43.988: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55" in namespace "pods-6149" to be "terminated with reason DeadlineExceeded"
Nov 29 12:16:43.999: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Running", Reason="", readiness=true. Elapsed: 11.358403ms
Nov 29 12:16:46.003: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.014942068s
Nov 29 12:16:48.003: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015718456s
Nov 29 12:16:48.003: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 12:16:48.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6149" for this suite. 11/29/22 12:16:48.006
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":188,"skipped":3455,"failed":0}
------------------------------
• [SLOW TEST] [6.569 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:16:41.441
    Nov 29 12:16:41.441: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 12:16:41.442
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:41.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:41.453
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 11/29/22 12:16:41.456
    STEP: submitting the pod to kubernetes 11/29/22 12:16:41.456
    Nov 29 12:16:41.462: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55" in namespace "pods-6149" to be "running and ready"
    Nov 29 12:16:41.465: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.096666ms
    Nov 29 12:16:41.465: INFO: The phase of Pod pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:16:43.469: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.006599056s
    Nov 29 12:16:43.469: INFO: The phase of Pod pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55 is Running (Ready = true)
    Nov 29 12:16:43.469: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/29/22 12:16:43.471
    STEP: updating the pod 11/29/22 12:16:43.474
    Nov 29 12:16:43.988: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55"
    Nov 29 12:16:43.988: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55" in namespace "pods-6149" to be "terminated with reason DeadlineExceeded"
    Nov 29 12:16:43.999: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Running", Reason="", readiness=true. Elapsed: 11.358403ms
    Nov 29 12:16:46.003: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.014942068s
    Nov 29 12:16:48.003: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015718456s
    Nov 29 12:16:48.003: INFO: Pod "pod-update-activedeadlineseconds-1154816b-89b4-4592-9d3c-148999ab3d55" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 12:16:48.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6149" for this suite. 11/29/22 12:16:48.006
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:16:48.011
Nov 29 12:16:48.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 12:16:48.012
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:48.02
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:48.022
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 11/29/22 12:16:48.024
Nov 29 12:16:48.029: INFO: Waiting up to 5m0s for pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188" in namespace "emptydir-2919" to be "Succeeded or Failed"
Nov 29 12:16:48.033: INFO: Pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188": Phase="Pending", Reason="", readiness=false. Elapsed: 4.514886ms
Nov 29 12:16:50.037: INFO: Pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007813932s
Nov 29 12:16:52.041: INFO: Pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012313003s
STEP: Saw pod success 11/29/22 12:16:52.041
Nov 29 12:16:52.041: INFO: Pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188" satisfied condition "Succeeded or Failed"
Nov 29 12:16:52.046: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188 container test-container: <nil>
STEP: delete the pod 11/29/22 12:16:52.051
Nov 29 12:16:52.064: INFO: Waiting for pod pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188 to disappear
Nov 29 12:16:52.066: INFO: Pod pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 12:16:52.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2919" for this suite. 11/29/22 12:16:52.069
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":189,"skipped":3499,"failed":0}
------------------------------
• [4.061 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:16:48.011
    Nov 29 12:16:48.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 12:16:48.012
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:48.02
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:48.022
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/29/22 12:16:48.024
    Nov 29 12:16:48.029: INFO: Waiting up to 5m0s for pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188" in namespace "emptydir-2919" to be "Succeeded or Failed"
    Nov 29 12:16:48.033: INFO: Pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188": Phase="Pending", Reason="", readiness=false. Elapsed: 4.514886ms
    Nov 29 12:16:50.037: INFO: Pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007813932s
    Nov 29 12:16:52.041: INFO: Pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012313003s
    STEP: Saw pod success 11/29/22 12:16:52.041
    Nov 29 12:16:52.041: INFO: Pod "pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188" satisfied condition "Succeeded or Failed"
    Nov 29 12:16:52.046: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188 container test-container: <nil>
    STEP: delete the pod 11/29/22 12:16:52.051
    Nov 29 12:16:52.064: INFO: Waiting for pod pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188 to disappear
    Nov 29 12:16:52.066: INFO: Pod pod-5fc4db7f-b728-4d9c-a9aa-a25eb70d7188 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 12:16:52.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2919" for this suite. 11/29/22 12:16:52.069
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:16:52.073
Nov 29 12:16:52.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename cronjob 11/29/22 12:16:52.074
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:52.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:52.085
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 11/29/22 12:16:52.088
STEP: Ensuring a job is scheduled 11/29/22 12:16:52.092
STEP: Ensuring exactly one is scheduled 11/29/22 12:17:02.095
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/29/22 12:17:02.097
STEP: Ensuring the job is replaced with a new one 11/29/22 12:17:02.099
STEP: Removing cronjob 11/29/22 12:18:02.103
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 29 12:18:02.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1279" for this suite. 11/29/22 12:18:02.109
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":190,"skipped":3506,"failed":0}
------------------------------
• [SLOW TEST] [70.040 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:16:52.073
    Nov 29 12:16:52.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename cronjob 11/29/22 12:16:52.074
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:16:52.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:16:52.085
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 11/29/22 12:16:52.088
    STEP: Ensuring a job is scheduled 11/29/22 12:16:52.092
    STEP: Ensuring exactly one is scheduled 11/29/22 12:17:02.095
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/29/22 12:17:02.097
    STEP: Ensuring the job is replaced with a new one 11/29/22 12:17:02.099
    STEP: Removing cronjob 11/29/22 12:18:02.103
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 29 12:18:02.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-1279" for this suite. 11/29/22 12:18:02.109
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:18:02.114
Nov 29 12:18:02.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:18:02.114
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:02.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:02.13
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 11/29/22 12:18:02.132
Nov 29 12:18:02.132: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-7909 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 11/29/22 12:18:02.176
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:18:02.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7909" for this suite. 11/29/22 12:18:02.187
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":191,"skipped":3512,"failed":0}
------------------------------
• [0.077 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:18:02.114
    Nov 29 12:18:02.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:18:02.114
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:02.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:02.13
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 11/29/22 12:18:02.132
    Nov 29 12:18:02.132: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-7909 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 11/29/22 12:18:02.176
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:18:02.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7909" for this suite. 11/29/22 12:18:02.187
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:18:02.192
Nov 29 12:18:02.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:18:02.193
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:02.201
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:02.204
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-2b84c305-f949-4ec5-834e-749fd8ee1592 11/29/22 12:18:02.206
STEP: Creating a pod to test consume secrets 11/29/22 12:18:02.209
Nov 29 12:18:02.214: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80" in namespace "projected-7698" to be "Succeeded or Failed"
Nov 29 12:18:02.216: INFO: Pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.533394ms
Nov 29 12:18:04.222: INFO: Pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008568779s
Nov 29 12:18:06.219: INFO: Pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004990819s
STEP: Saw pod success 11/29/22 12:18:06.219
Nov 29 12:18:06.219: INFO: Pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80" satisfied condition "Succeeded or Failed"
Nov 29 12:18:06.221: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:18:06.246
Nov 29 12:18:06.260: INFO: Waiting for pod pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80 to disappear
Nov 29 12:18:06.263: INFO: Pod pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 29 12:18:06.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7698" for this suite. 11/29/22 12:18:06.267
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":192,"skipped":3553,"failed":0}
------------------------------
• [4.077 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:18:02.192
    Nov 29 12:18:02.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:18:02.193
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:02.201
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:02.204
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-2b84c305-f949-4ec5-834e-749fd8ee1592 11/29/22 12:18:02.206
    STEP: Creating a pod to test consume secrets 11/29/22 12:18:02.209
    Nov 29 12:18:02.214: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80" in namespace "projected-7698" to be "Succeeded or Failed"
    Nov 29 12:18:02.216: INFO: Pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.533394ms
    Nov 29 12:18:04.222: INFO: Pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008568779s
    Nov 29 12:18:06.219: INFO: Pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004990819s
    STEP: Saw pod success 11/29/22 12:18:06.219
    Nov 29 12:18:06.219: INFO: Pod "pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80" satisfied condition "Succeeded or Failed"
    Nov 29 12:18:06.221: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:18:06.246
    Nov 29 12:18:06.260: INFO: Waiting for pod pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80 to disappear
    Nov 29 12:18:06.263: INFO: Pod pod-projected-secrets-a4da7864-6ab0-4dfa-85e6-c7e0875f1f80 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 29 12:18:06.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7698" for this suite. 11/29/22 12:18:06.267
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:18:06.271
Nov 29 12:18:06.271: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename dns 11/29/22 12:18:06.272
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:06.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:06.287
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 11/29/22 12:18:06.289
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1339.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1339.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 11/29/22 12:18:06.294
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1339.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1339.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 11/29/22 12:18:06.294
STEP: creating a pod to probe DNS 11/29/22 12:18:06.294
STEP: submitting the pod to kubernetes 11/29/22 12:18:06.294
Nov 29 12:18:06.303: INFO: Waiting up to 15m0s for pod "dns-test-358290d6-685e-476e-9218-046a2d092974" in namespace "dns-1339" to be "running"
Nov 29 12:18:06.306: INFO: Pod "dns-test-358290d6-685e-476e-9218-046a2d092974": Phase="Pending", Reason="", readiness=false. Elapsed: 2.692741ms
Nov 29 12:18:08.310: INFO: Pod "dns-test-358290d6-685e-476e-9218-046a2d092974": Phase="Running", Reason="", readiness=true. Elapsed: 2.006563111s
Nov 29 12:18:08.310: INFO: Pod "dns-test-358290d6-685e-476e-9218-046a2d092974" satisfied condition "running"
STEP: retrieving the pod 11/29/22 12:18:08.31
STEP: looking for the results for each expected name from probers 11/29/22 12:18:08.312
Nov 29 12:18:08.322: INFO: DNS probes using dns-1339/dns-test-358290d6-685e-476e-9218-046a2d092974 succeeded

STEP: deleting the pod 11/29/22 12:18:08.322
STEP: deleting the test headless service 11/29/22 12:18:08.328
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 29 12:18:08.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1339" for this suite. 11/29/22 12:18:08.342
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":193,"skipped":3558,"failed":0}
------------------------------
• [2.075 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:18:06.271
    Nov 29 12:18:06.271: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename dns 11/29/22 12:18:06.272
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:06.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:06.287
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 11/29/22 12:18:06.289
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1339.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1339.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     11/29/22 12:18:06.294
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1339.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1339.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     11/29/22 12:18:06.294
    STEP: creating a pod to probe DNS 11/29/22 12:18:06.294
    STEP: submitting the pod to kubernetes 11/29/22 12:18:06.294
    Nov 29 12:18:06.303: INFO: Waiting up to 15m0s for pod "dns-test-358290d6-685e-476e-9218-046a2d092974" in namespace "dns-1339" to be "running"
    Nov 29 12:18:06.306: INFO: Pod "dns-test-358290d6-685e-476e-9218-046a2d092974": Phase="Pending", Reason="", readiness=false. Elapsed: 2.692741ms
    Nov 29 12:18:08.310: INFO: Pod "dns-test-358290d6-685e-476e-9218-046a2d092974": Phase="Running", Reason="", readiness=true. Elapsed: 2.006563111s
    Nov 29 12:18:08.310: INFO: Pod "dns-test-358290d6-685e-476e-9218-046a2d092974" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 12:18:08.31
    STEP: looking for the results for each expected name from probers 11/29/22 12:18:08.312
    Nov 29 12:18:08.322: INFO: DNS probes using dns-1339/dns-test-358290d6-685e-476e-9218-046a2d092974 succeeded

    STEP: deleting the pod 11/29/22 12:18:08.322
    STEP: deleting the test headless service 11/29/22 12:18:08.328
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 29 12:18:08.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1339" for this suite. 11/29/22 12:18:08.342
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:18:08.351
Nov 29 12:18:08.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replication-controller 11/29/22 12:18:08.352
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:08.41
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:08.413
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 11/29/22 12:18:08.415
Nov 29 12:18:08.420: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-8922" to be "running and ready"
Nov 29 12:18:08.423: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.758897ms
Nov 29 12:18:08.423: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:18:10.428: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.007977254s
Nov 29 12:18:10.428: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Nov 29 12:18:10.428: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 11/29/22 12:18:10.433
STEP: Then the orphan pod is adopted 11/29/22 12:18:10.436
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 29 12:18:11.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8922" for this suite. 11/29/22 12:18:11.45
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":194,"skipped":3613,"failed":0}
------------------------------
• [3.102 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:18:08.351
    Nov 29 12:18:08.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replication-controller 11/29/22 12:18:08.352
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:08.41
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:08.413
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 11/29/22 12:18:08.415
    Nov 29 12:18:08.420: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-8922" to be "running and ready"
    Nov 29 12:18:08.423: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.758897ms
    Nov 29 12:18:08.423: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:18:10.428: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.007977254s
    Nov 29 12:18:10.428: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Nov 29 12:18:10.428: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 11/29/22 12:18:10.433
    STEP: Then the orphan pod is adopted 11/29/22 12:18:10.436
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 29 12:18:11.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8922" for this suite. 11/29/22 12:18:11.45
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:18:11.455
Nov 29 12:18:11.455: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:18:11.456
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:11.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:11.469
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 11/29/22 12:18:11.472
Nov 29 12:18:11.481: INFO: Waiting up to 5m0s for pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9" in namespace "downward-api-6763" to be "Succeeded or Failed"
Nov 29 12:18:11.490: INFO: Pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.577082ms
Nov 29 12:18:13.493: INFO: Pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01192254s
Nov 29 12:18:15.494: INFO: Pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012411644s
STEP: Saw pod success 11/29/22 12:18:15.494
Nov 29 12:18:15.494: INFO: Pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9" satisfied condition "Succeeded or Failed"
Nov 29 12:18:15.496: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9 container dapi-container: <nil>
STEP: delete the pod 11/29/22 12:18:15.501
Nov 29 12:18:15.510: INFO: Waiting for pod downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9 to disappear
Nov 29 12:18:15.513: INFO: Pod downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 29 12:18:15.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6763" for this suite. 11/29/22 12:18:15.516
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":195,"skipped":3617,"failed":0}
------------------------------
• [4.065 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:18:11.455
    Nov 29 12:18:11.455: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:18:11.456
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:11.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:11.469
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 11/29/22 12:18:11.472
    Nov 29 12:18:11.481: INFO: Waiting up to 5m0s for pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9" in namespace "downward-api-6763" to be "Succeeded or Failed"
    Nov 29 12:18:11.490: INFO: Pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.577082ms
    Nov 29 12:18:13.493: INFO: Pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01192254s
    Nov 29 12:18:15.494: INFO: Pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012411644s
    STEP: Saw pod success 11/29/22 12:18:15.494
    Nov 29 12:18:15.494: INFO: Pod "downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9" satisfied condition "Succeeded or Failed"
    Nov 29 12:18:15.496: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9 container dapi-container: <nil>
    STEP: delete the pod 11/29/22 12:18:15.501
    Nov 29 12:18:15.510: INFO: Waiting for pod downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9 to disappear
    Nov 29 12:18:15.513: INFO: Pod downward-api-6ec667bf-45d9-4f65-a49e-cb7f5205caa9 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 29 12:18:15.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6763" for this suite. 11/29/22 12:18:15.516
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:18:15.521
Nov 29 12:18:15.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:18:15.522
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:15.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:15.531
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 11/29/22 12:18:15.533
Nov 29 12:18:15.533: INFO: Creating e2e-svc-a-gfpnc
Nov 29 12:18:15.538: INFO: Creating e2e-svc-b-7bcd7
Nov 29 12:18:15.551: INFO: Creating e2e-svc-c-s2k6s
STEP: deleting service collection 11/29/22 12:18:15.567
Nov 29 12:18:15.597: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:18:15.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3412" for this suite. 11/29/22 12:18:15.602
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":196,"skipped":3658,"failed":0}
------------------------------
• [0.085 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:18:15.521
    Nov 29 12:18:15.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:18:15.522
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:15.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:15.531
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 11/29/22 12:18:15.533
    Nov 29 12:18:15.533: INFO: Creating e2e-svc-a-gfpnc
    Nov 29 12:18:15.538: INFO: Creating e2e-svc-b-7bcd7
    Nov 29 12:18:15.551: INFO: Creating e2e-svc-c-s2k6s
    STEP: deleting service collection 11/29/22 12:18:15.567
    Nov 29 12:18:15.597: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:18:15.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3412" for this suite. 11/29/22 12:18:15.602
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:18:15.609
Nov 29 12:18:15.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename cronjob 11/29/22 12:18:15.609
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:15.617
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:15.62
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 11/29/22 12:18:15.623
STEP: Ensuring a job is scheduled 11/29/22 12:18:15.627
STEP: Ensuring exactly one is scheduled 11/29/22 12:19:01.631
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/29/22 12:19:01.634
STEP: Ensuring no more jobs are scheduled 11/29/22 12:19:01.635
STEP: Removing cronjob 11/29/22 12:24:01.641
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 29 12:24:01.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8085" for this suite. 11/29/22 12:24:01.648
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":197,"skipped":3663,"failed":0}
------------------------------
• [SLOW TEST] [346.047 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:18:15.609
    Nov 29 12:18:15.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename cronjob 11/29/22 12:18:15.609
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:18:15.617
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:18:15.62
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 11/29/22 12:18:15.623
    STEP: Ensuring a job is scheduled 11/29/22 12:18:15.627
    STEP: Ensuring exactly one is scheduled 11/29/22 12:19:01.631
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/29/22 12:19:01.634
    STEP: Ensuring no more jobs are scheduled 11/29/22 12:19:01.635
    STEP: Removing cronjob 11/29/22 12:24:01.641
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 29 12:24:01.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-8085" for this suite. 11/29/22 12:24:01.648
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:24:01.656
Nov 29 12:24:01.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename taint-multiple-pods 11/29/22 12:24:01.657
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:24:01.667
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:24:01.669
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Nov 29 12:24:01.671: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 29 12:25:01.707: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Nov 29 12:25:01.711: INFO: Starting informer...
STEP: Starting pods... 11/29/22 12:25:01.711
Nov 29 12:25:01.926: INFO: Pod1 is running on dvi-7336-1669718118-vsp1-group1-2. Tainting Node
Nov 29 12:25:02.135: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-5319" to be "running"
Nov 29 12:25:02.138: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.656589ms
Nov 29 12:25:04.141: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005360179s
Nov 29 12:25:04.141: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Nov 29 12:25:04.141: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-5319" to be "running"
Nov 29 12:25:04.143: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.047949ms
Nov 29 12:25:04.143: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Nov 29 12:25:04.143: INFO: Pod2 is running on dvi-7336-1669718118-vsp1-group1-2. Tainting Node
STEP: Trying to apply a taint on the Node 11/29/22 12:25:04.143
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/29/22 12:25:04.154
STEP: Waiting for Pod1 and Pod2 to be deleted 11/29/22 12:25:04.161
Nov 29 12:25:09.782: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov 29 12:25:29.511: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/29/22 12:25:29.523
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:25:29.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-5319" for this suite. 11/29/22 12:25:29.534
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":198,"skipped":3674,"failed":0}
------------------------------
• [SLOW TEST] [87.881 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:24:01.656
    Nov 29 12:24:01.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename taint-multiple-pods 11/29/22 12:24:01.657
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:24:01.667
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:24:01.669
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Nov 29 12:24:01.671: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 29 12:25:01.707: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Nov 29 12:25:01.711: INFO: Starting informer...
    STEP: Starting pods... 11/29/22 12:25:01.711
    Nov 29 12:25:01.926: INFO: Pod1 is running on dvi-7336-1669718118-vsp1-group1-2. Tainting Node
    Nov 29 12:25:02.135: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-5319" to be "running"
    Nov 29 12:25:02.138: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.656589ms
    Nov 29 12:25:04.141: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005360179s
    Nov 29 12:25:04.141: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Nov 29 12:25:04.141: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-5319" to be "running"
    Nov 29 12:25:04.143: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.047949ms
    Nov 29 12:25:04.143: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Nov 29 12:25:04.143: INFO: Pod2 is running on dvi-7336-1669718118-vsp1-group1-2. Tainting Node
    STEP: Trying to apply a taint on the Node 11/29/22 12:25:04.143
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/29/22 12:25:04.154
    STEP: Waiting for Pod1 and Pod2 to be deleted 11/29/22 12:25:04.161
    Nov 29 12:25:09.782: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Nov 29 12:25:29.511: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/29/22 12:25:29.523
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:25:29.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-5319" for this suite. 11/29/22 12:25:29.534
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:25:29.538
Nov 29 12:25:29.538: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-runtime 11/29/22 12:25:29.539
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:25:29.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:25:29.56
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/29/22 12:25:29.568
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/29/22 12:25:45.636
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/29/22 12:25:45.639
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/29/22 12:25:45.645
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/29/22 12:25:45.645
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/29/22 12:25:45.657
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/29/22 12:25:47.67
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/29/22 12:25:49.678
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/29/22 12:25:49.682
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/29/22 12:25:49.682
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/29/22 12:25:49.691
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/29/22 12:25:50.696
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/29/22 12:25:52.705
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/29/22 12:25:52.709
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/29/22 12:25:52.709
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 29 12:25:52.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8685" for this suite. 11/29/22 12:25:52.724
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":199,"skipped":3683,"failed":0}
------------------------------
• [SLOW TEST] [23.189 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:25:29.538
    Nov 29 12:25:29.538: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-runtime 11/29/22 12:25:29.539
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:25:29.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:25:29.56
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/29/22 12:25:29.568
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/29/22 12:25:45.636
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/29/22 12:25:45.639
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/29/22 12:25:45.645
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/29/22 12:25:45.645
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/29/22 12:25:45.657
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/29/22 12:25:47.67
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/29/22 12:25:49.678
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/29/22 12:25:49.682
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/29/22 12:25:49.682
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/29/22 12:25:49.691
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/29/22 12:25:50.696
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/29/22 12:25:52.705
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/29/22 12:25:52.709
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/29/22 12:25:52.709
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 29 12:25:52.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8685" for this suite. 11/29/22 12:25:52.724
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:25:52.729
Nov 29 12:25:52.729: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:25:52.73
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:25:52.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:25:52.74
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:25:52.75
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:25:53.498
STEP: Deploying the webhook pod 11/29/22 12:25:53.502
STEP: Wait for the deployment to be ready 11/29/22 12:25:53.508
Nov 29 12:25:53.514: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:25:55.521
STEP: Verifying the service has paired with the endpoint 11/29/22 12:25:55.527
Nov 29 12:25:56.527: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 11/29/22 12:25:56.53
STEP: create a pod 11/29/22 12:25:56.54
Nov 29 12:25:56.543: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-9191" to be "running"
Nov 29 12:25:56.545: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 1.713674ms
Nov 29 12:25:58.548: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.004534412s
Nov 29 12:25:58.548: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 11/29/22 12:25:58.548
Nov 29 12:25:58.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=webhook-9191 attach --namespace=webhook-9191 to-be-attached-pod -i -c=container1'
Nov 29 12:25:58.629: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:25:58.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9191" for this suite. 11/29/22 12:25:58.635
STEP: Destroying namespace "webhook-9191-markers" for this suite. 11/29/22 12:25:58.638
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":200,"skipped":3713,"failed":0}
------------------------------
• [SLOW TEST] [5.947 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:25:52.729
    Nov 29 12:25:52.729: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:25:52.73
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:25:52.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:25:52.74
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:25:52.75
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:25:53.498
    STEP: Deploying the webhook pod 11/29/22 12:25:53.502
    STEP: Wait for the deployment to be ready 11/29/22 12:25:53.508
    Nov 29 12:25:53.514: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:25:55.521
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:25:55.527
    Nov 29 12:25:56.527: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 11/29/22 12:25:56.53
    STEP: create a pod 11/29/22 12:25:56.54
    Nov 29 12:25:56.543: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-9191" to be "running"
    Nov 29 12:25:56.545: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 1.713674ms
    Nov 29 12:25:58.548: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.004534412s
    Nov 29 12:25:58.548: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 11/29/22 12:25:58.548
    Nov 29 12:25:58.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=webhook-9191 attach --namespace=webhook-9191 to-be-attached-pod -i -c=container1'
    Nov 29 12:25:58.629: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:25:58.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9191" for this suite. 11/29/22 12:25:58.635
    STEP: Destroying namespace "webhook-9191-markers" for this suite. 11/29/22 12:25:58.638
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:25:58.676
Nov 29 12:25:58.676: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:25:58.677
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:25:58.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:25:58.698
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 11/29/22 12:25:58.706
Nov 29 12:25:58.706: INFO: namespace kubectl-1380
Nov 29 12:25:58.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1380 create -f -'
Nov 29 12:25:58.980: INFO: stderr: ""
Nov 29 12:25:58.980: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/29/22 12:25:58.98
Nov 29 12:25:59.984: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 12:25:59.984: INFO: Found 0 / 1
Nov 29 12:26:00.984: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 12:26:00.984: INFO: Found 1 / 1
Nov 29 12:26:00.984: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 29 12:26:00.986: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 12:26:00.986: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 29 12:26:00.986: INFO: wait on agnhost-primary startup in kubectl-1380 
Nov 29 12:26:00.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1380 logs agnhost-primary-s7dtg agnhost-primary'
Nov 29 12:26:01.063: INFO: stderr: ""
Nov 29 12:26:01.064: INFO: stdout: "Paused\n"
STEP: exposing RC 11/29/22 12:26:01.064
Nov 29 12:26:01.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1380 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Nov 29 12:26:01.133: INFO: stderr: ""
Nov 29 12:26:01.133: INFO: stdout: "service/rm2 exposed\n"
Nov 29 12:26:01.135: INFO: Service rm2 in namespace kubectl-1380 found.
STEP: exposing service 11/29/22 12:26:03.142
Nov 29 12:26:03.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1380 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Nov 29 12:26:03.206: INFO: stderr: ""
Nov 29 12:26:03.206: INFO: stdout: "service/rm3 exposed\n"
Nov 29 12:26:03.209: INFO: Service rm3 in namespace kubectl-1380 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:26:05.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1380" for this suite. 11/29/22 12:26:05.217
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":201,"skipped":3713,"failed":0}
------------------------------
• [SLOW TEST] [6.543 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:25:58.676
    Nov 29 12:25:58.676: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:25:58.677
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:25:58.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:25:58.698
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 11/29/22 12:25:58.706
    Nov 29 12:25:58.706: INFO: namespace kubectl-1380
    Nov 29 12:25:58.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1380 create -f -'
    Nov 29 12:25:58.980: INFO: stderr: ""
    Nov 29 12:25:58.980: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/29/22 12:25:58.98
    Nov 29 12:25:59.984: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 12:25:59.984: INFO: Found 0 / 1
    Nov 29 12:26:00.984: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 12:26:00.984: INFO: Found 1 / 1
    Nov 29 12:26:00.984: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov 29 12:26:00.986: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 12:26:00.986: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 29 12:26:00.986: INFO: wait on agnhost-primary startup in kubectl-1380 
    Nov 29 12:26:00.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1380 logs agnhost-primary-s7dtg agnhost-primary'
    Nov 29 12:26:01.063: INFO: stderr: ""
    Nov 29 12:26:01.064: INFO: stdout: "Paused\n"
    STEP: exposing RC 11/29/22 12:26:01.064
    Nov 29 12:26:01.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1380 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Nov 29 12:26:01.133: INFO: stderr: ""
    Nov 29 12:26:01.133: INFO: stdout: "service/rm2 exposed\n"
    Nov 29 12:26:01.135: INFO: Service rm2 in namespace kubectl-1380 found.
    STEP: exposing service 11/29/22 12:26:03.142
    Nov 29 12:26:03.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1380 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Nov 29 12:26:03.206: INFO: stderr: ""
    Nov 29 12:26:03.206: INFO: stdout: "service/rm3 exposed\n"
    Nov 29 12:26:03.209: INFO: Service rm3 in namespace kubectl-1380 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:26:05.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1380" for this suite. 11/29/22 12:26:05.217
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:26:05.222
Nov 29 12:26:05.222: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:26:05.223
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:26:05.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:26:05.232
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:26:05.234
Nov 29 12:26:05.238: INFO: Waiting up to 5m0s for pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6" in namespace "downward-api-4175" to be "Succeeded or Failed"
Nov 29 12:26:05.241: INFO: Pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.434042ms
Nov 29 12:26:07.245: INFO: Pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006557164s
Nov 29 12:26:09.245: INFO: Pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006565213s
STEP: Saw pod success 11/29/22 12:26:09.245
Nov 29 12:26:09.245: INFO: Pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6" satisfied condition "Succeeded or Failed"
Nov 29 12:26:09.247: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6 container client-container: <nil>
STEP: delete the pod 11/29/22 12:26:09.259
Nov 29 12:26:09.265: INFO: Waiting for pod downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6 to disappear
Nov 29 12:26:09.267: INFO: Pod downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:26:09.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4175" for this suite. 11/29/22 12:26:09.271
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":202,"skipped":3758,"failed":0}
------------------------------
• [4.053 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:26:05.222
    Nov 29 12:26:05.222: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:26:05.223
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:26:05.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:26:05.232
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:26:05.234
    Nov 29 12:26:05.238: INFO: Waiting up to 5m0s for pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6" in namespace "downward-api-4175" to be "Succeeded or Failed"
    Nov 29 12:26:05.241: INFO: Pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.434042ms
    Nov 29 12:26:07.245: INFO: Pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006557164s
    Nov 29 12:26:09.245: INFO: Pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006565213s
    STEP: Saw pod success 11/29/22 12:26:09.245
    Nov 29 12:26:09.245: INFO: Pod "downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6" satisfied condition "Succeeded or Failed"
    Nov 29 12:26:09.247: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:26:09.259
    Nov 29 12:26:09.265: INFO: Waiting for pod downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6 to disappear
    Nov 29 12:26:09.267: INFO: Pod downwardapi-volume-890de4a4-4924-4a33-b52b-5023ac9c50d6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:26:09.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4175" for this suite. 11/29/22 12:26:09.271
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:26:09.275
Nov 29 12:26:09.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-pred 11/29/22 12:26:09.276
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:26:09.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:26:09.287
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 29 12:26:09.289: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 29 12:26:09.295: INFO: Waiting for terminating namespaces to be deleted...
Nov 29 12:26:09.296: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-0 before test
Nov 29 12:26:09.302: INFO: canal-wsz7n from kube-system started at 2022-11-29 11:01:45 +0000 UTC (3 container statuses recorded)
Nov 29 12:26:09.302: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:26:09.302: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:26:09.302: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:26:09.302: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.302: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:26:09.302: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.302: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:26:09.302: INFO: kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.302: INFO: 	Container main ready: true, restart count 0
Nov 29 12:26:09.302: INFO: node-local-dns-hqwqq from kube-system started at 2022-11-29 11:01:45 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.302: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:26:09.302: INFO: sonobuoy from sonobuoy started at 2022-11-29 11:25:29 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.302: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 29 12:26:09.302: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:26:09.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:26:09.302: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:26:09.302: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-1 before test
Nov 29 12:26:09.308: INFO: canal-f2ndl from kube-system started at 2022-11-29 11:02:00 +0000 UTC (3 container statuses recorded)
Nov 29 12:26:09.308: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:26:09.308: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:26:09.308: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:26:09.308: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.308: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:26:09.308: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.308: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:26:09.308: INFO: kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.308: INFO: 	Container main ready: true, restart count 0
Nov 29 12:26:09.308: INFO: node-local-dns-wwm5j from kube-system started at 2022-11-29 11:02:00 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.308: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:26:09.308: INFO: sonobuoy-e2e-job-2558967603d841e7 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:26:09.308: INFO: 	Container e2e ready: true, restart count 0
Nov 29 12:26:09.308: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:26:09.308: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk from sonobuoy started at 2022-11-29 11:25:37 +0000 UTC (2 container statuses recorded)
Nov 29 12:26:09.308: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:26:09.308: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:26:09.308: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-2 before test
Nov 29 12:26:09.314: INFO: canal-xwmmp from kube-system started at 2022-11-29 11:01:59 +0000 UTC (3 container statuses recorded)
Nov 29 12:26:09.314: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:26:09.314: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:26:09.314: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:26:09.314: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.314: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:26:09.314: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.314: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:26:09.314: INFO: kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.314: INFO: 	Container main ready: true, restart count 0
Nov 29 12:26:09.314: INFO: node-local-dns-rf4vc from kube-system started at 2022-11-29 11:01:59 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.314: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:26:09.314: INFO: agnhost-primary-s7dtg from kubectl-1380 started at 2022-11-29 12:25:58 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.314: INFO: 	Container agnhost-primary ready: true, restart count 0
Nov 29 12:26:09.314: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:26:09.314: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:26:09.314: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:26:09.314: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-master-0 before test
Nov 29 12:26:09.326: INFO: calico-kube-controllers-5c9848945f-6wztn from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.326: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 29 12:26:09.326: INFO: canal-5j97l from kube-system started at 2022-11-29 10:49:25 +0000 UTC (3 container statuses recorded)
Nov 29 12:26:09.326: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:26:09.326: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:26:09.326: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:26:09.326: INFO: coredns-5cbcf9db85-hbrbr from kube-system started at 2022-11-29 11:01:49 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.326: INFO: 	Container coredns ready: true, restart count 0
Nov 29 12:26:09.326: INFO: coredns-5cbcf9db85-q2lfd from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.326: INFO: 	Container coredns ready: true, restart count 0
Nov 29 12:26:09.326: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.326: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:26:09.326: INFO: k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.326: INFO: 	Container etcd ready: true, restart count 0
Nov 29 12:26:09.326: INFO: k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (3 container statuses recorded)
Nov 29 12:26:09.326: INFO: 	Container apiserver ready: true, restart count 0
Nov 29 12:26:09.326: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov 29 12:26:09.326: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov 29 12:26:09.326: INFO: kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.326: INFO: 	Container kube-addon-manager ready: true, restart count 0
Nov 29 12:26:09.327: INFO: kube-dns-autoscaler-bd7b594d-dwsh9 from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container autoscaler ready: true, restart count 0
Nov 29 12:26:09.327: INFO: kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:26:09.327: INFO: kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container node-label ready: true, restart count 0
Nov 29 12:26:09.327: INFO: kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container main ready: true, restart count 0
Nov 29 12:26:09.327: INFO: kublr-system-shell-d595b78f-7ngf9 from kube-system started at 2022-11-29 10:52:20 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container shell ready: true, restart count 0
Nov 29 12:26:09.327: INFO: metrics-server-v0.5.2-54b5b7598b-zq8q6 from kube-system started at 2022-11-29 10:51:11 +0000 UTC (2 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container metrics-server ready: true, restart count 1
Nov 29 12:26:09.327: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 29 12:26:09.327: INFO: node-local-dns-fp5nm from kube-system started at 2022-11-29 10:49:25 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:26:09.327: INFO: dashboard-metrics-scraper-6fffb6f45f-q7h8c from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 29 12:26:09.327: INFO: kubernetes-dashboard-c5db79646-sq2km from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.327: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 29 12:26:09.327: INFO: kublr-operator-576b5465f6-gdg4s from kublr started at 2022-11-29 10:51:53 +0000 UTC (1 container statuses recorded)
Nov 29 12:26:09.328: INFO: 	Container kublr-operator ready: true, restart count 0
Nov 29 12:26:09.328: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:26:09.328: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:26:09.328: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node dvi-7336-1669718118-vsp1-group1-0 11/29/22 12:26:09.427
STEP: verifying the node has the label node dvi-7336-1669718118-vsp1-group1-1 11/29/22 12:26:09.454
STEP: verifying the node has the label node dvi-7336-1669718118-vsp1-group1-2 11/29/22 12:26:09.539
STEP: verifying the node has the label node dvi-7336-1669718118-vsp1-master-0 11/29/22 12:26:09.558
Nov 29 12:26:09.579: INFO: Pod calico-kube-controllers-5c9848945f-6wztn requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod canal-5j97l requesting resource cpu=40m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod canal-f2ndl requesting resource cpu=40m on Node dvi-7336-1669718118-vsp1-group1-1
Nov 29 12:26:09.579: INFO: Pod canal-wsz7n requesting resource cpu=40m on Node dvi-7336-1669718118-vsp1-group1-0
Nov 29 12:26:09.579: INFO: Pod canal-xwmmp requesting resource cpu=40m on Node dvi-7336-1669718118-vsp1-group1-2
Nov 29 12:26:09.579: INFO: Pod coredns-5cbcf9db85-hbrbr requesting resource cpu=100m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod coredns-5cbcf9db85-q2lfd requesting resource cpu=100m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-group1-0
Nov 29 12:26:09.579: INFO: Pod k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-group1-1
Nov 29 12:26:09.579: INFO: Pod k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-group1-2
Nov 29 12:26:09.579: INFO: Pod k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=100m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=160m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=50m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod kube-dns-autoscaler-bd7b594d-dwsh9 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-group1-0
Nov 29 12:26:09.579: INFO: Pod kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-group1-1
Nov 29 12:26:09.579: INFO: Pod kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-group1-2
Nov 29 12:26:09.579: INFO: Pod kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-2
Nov 29 12:26:09.579: INFO: Pod kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-0
Nov 29 12:26:09.579: INFO: Pod kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-1
Nov 29 12:26:09.579: INFO: Pod kublr-system-shell-d595b78f-7ngf9 requesting resource cpu=10m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod metrics-server-v0.5.2-54b5b7598b-zq8q6 requesting resource cpu=98m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod node-local-dns-fp5nm requesting resource cpu=25m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod node-local-dns-hqwqq requesting resource cpu=25m on Node dvi-7336-1669718118-vsp1-group1-0
Nov 29 12:26:09.579: INFO: Pod node-local-dns-rf4vc requesting resource cpu=25m on Node dvi-7336-1669718118-vsp1-group1-2
Nov 29 12:26:09.579: INFO: Pod node-local-dns-wwm5j requesting resource cpu=25m on Node dvi-7336-1669718118-vsp1-group1-1
Nov 29 12:26:09.579: INFO: Pod agnhost-primary-s7dtg requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-2
Nov 29 12:26:09.579: INFO: Pod dashboard-metrics-scraper-6fffb6f45f-q7h8c requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod kubernetes-dashboard-c5db79646-sq2km requesting resource cpu=10m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod kublr-operator-576b5465f6-gdg4s requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod sonobuoy requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-0
Nov 29 12:26:09.579: INFO: Pod sonobuoy-e2e-job-2558967603d841e7 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-1
Nov 29 12:26:09.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-0
Nov 29 12:26:09.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-2
Nov 29 12:26:09.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-1
STEP: Starting Pods to consume most of the cluster CPU. 11/29/22 12:26:09.579
Nov 29 12:26:09.579: INFO: Creating a pod which consumes cpu=2680m on Node dvi-7336-1669718118-vsp1-group1-2
Nov 29 12:26:09.584: INFO: Creating a pod which consumes cpu=2236m on Node dvi-7336-1669718118-vsp1-master-0
Nov 29 12:26:09.589: INFO: Creating a pod which consumes cpu=2680m on Node dvi-7336-1669718118-vsp1-group1-0
Nov 29 12:26:09.640: INFO: Creating a pod which consumes cpu=2680m on Node dvi-7336-1669718118-vsp1-group1-1
Nov 29 12:26:09.647: INFO: Waiting up to 5m0s for pod "filler-pod-2909791a-e85a-4574-bb2a-59206fb59744" in namespace "sched-pred-7697" to be "running"
Nov 29 12:26:09.650: INFO: Pod "filler-pod-2909791a-e85a-4574-bb2a-59206fb59744": Phase="Pending", Reason="", readiness=false. Elapsed: 3.190739ms
Nov 29 12:26:11.653: INFO: Pod "filler-pod-2909791a-e85a-4574-bb2a-59206fb59744": Phase="Running", Reason="", readiness=true. Elapsed: 2.006320454s
Nov 29 12:26:11.653: INFO: Pod "filler-pod-2909791a-e85a-4574-bb2a-59206fb59744" satisfied condition "running"
Nov 29 12:26:11.653: INFO: Waiting up to 5m0s for pod "filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c" in namespace "sched-pred-7697" to be "running"
Nov 29 12:26:11.655: INFO: Pod "filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.311915ms
Nov 29 12:26:11.655: INFO: Pod "filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c" satisfied condition "running"
Nov 29 12:26:11.655: INFO: Waiting up to 5m0s for pod "filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd" in namespace "sched-pred-7697" to be "running"
Nov 29 12:26:11.657: INFO: Pod "filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd": Phase="Running", Reason="", readiness=true. Elapsed: 2.014506ms
Nov 29 12:26:11.657: INFO: Pod "filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd" satisfied condition "running"
Nov 29 12:26:11.657: INFO: Waiting up to 5m0s for pod "filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a" in namespace "sched-pred-7697" to be "running"
Nov 29 12:26:11.660: INFO: Pod "filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a": Phase="Running", Reason="", readiness=true. Elapsed: 2.107083ms
Nov 29 12:26:11.660: INFO: Pod "filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 11/29/22 12:26:11.66
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2909791a-e85a-4574-bb2a-59206fb59744.172c0dd4d2883529], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7697/filler-pod-2909791a-e85a-4574-bb2a-59206fb59744 to dvi-7336-1669718118-vsp1-group1-2] 11/29/22 12:26:11.662
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2909791a-e85a-4574-bb2a-59206fb59744.172c0dd4f6dc7865], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/29/22 12:26:11.663
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2909791a-e85a-4574-bb2a-59206fb59744.172c0dd5051ea97d], Reason = [Created], Message = [Created container filler-pod-2909791a-e85a-4574-bb2a-59206fb59744] 11/29/22 12:26:11.663
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2909791a-e85a-4574-bb2a-59206fb59744.172c0dd50a64a7d6], Reason = [Started], Message = [Started container filler-pod-2909791a-e85a-4574-bb2a-59206fb59744] 11/29/22 12:26:11.663
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd.172c0dd4d5e3b727], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7697/filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd to dvi-7336-1669718118-vsp1-group1-0] 11/29/22 12:26:11.663
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd.172c0dd50a1adb04], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/29/22 12:26:11.663
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd.172c0dd512e60aef], Reason = [Created], Message = [Created container filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd] 11/29/22 12:26:11.663
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd.172c0dd517a3aaad], Reason = [Started], Message = [Started container filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd] 11/29/22 12:26:11.664
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c.172c0dd4d516f0d8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7697/filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c to dvi-7336-1669718118-vsp1-master-0] 11/29/22 12:26:11.664
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c.172c0dd5083589f9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/29/22 12:26:11.664
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c.172c0dd511a626ea], Reason = [Created], Message = [Created container filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c] 11/29/22 12:26:11.664
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c.172c0dd516fe8d42], Reason = [Started], Message = [Started container filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c] 11/29/22 12:26:11.664
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a.172c0dd4d6936bbf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7697/filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a to dvi-7336-1669718118-vsp1-group1-1] 11/29/22 12:26:11.664
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a.172c0dd509810c71], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/29/22 12:26:11.664
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a.172c0dd512d71aa7], Reason = [Created], Message = [Created container filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a] 11/29/22 12:26:11.665
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a.172c0dd518f09575], Reason = [Started], Message = [Started container filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a] 11/29/22 12:26:11.665
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.172c0dd54e698f5c], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu. preemption: 0/4 nodes are available: 4 No preemption victims found for incoming pod.] 11/29/22 12:26:11.669
STEP: removing the label node off the node dvi-7336-1669718118-vsp1-group1-0 11/29/22 12:26:12.67
STEP: verifying the node doesn't have the label node 11/29/22 12:26:12.681
STEP: removing the label node off the node dvi-7336-1669718118-vsp1-group1-1 11/29/22 12:26:12.69
STEP: verifying the node doesn't have the label node 11/29/22 12:26:12.7
STEP: removing the label node off the node dvi-7336-1669718118-vsp1-group1-2 11/29/22 12:26:12.704
STEP: verifying the node doesn't have the label node 11/29/22 12:26:12.717
STEP: removing the label node off the node dvi-7336-1669718118-vsp1-master-0 11/29/22 12:26:12.722
STEP: verifying the node doesn't have the label node 11/29/22 12:26:12.733
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:26:12.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7697" for this suite. 11/29/22 12:26:12.747
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":203,"skipped":3769,"failed":0}
------------------------------
• [3.477 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:26:09.275
    Nov 29 12:26:09.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-pred 11/29/22 12:26:09.276
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:26:09.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:26:09.287
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 29 12:26:09.289: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 29 12:26:09.295: INFO: Waiting for terminating namespaces to be deleted...
    Nov 29 12:26:09.296: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-0 before test
    Nov 29 12:26:09.302: INFO: canal-wsz7n from kube-system started at 2022-11-29 11:01:45 +0000 UTC (3 container statuses recorded)
    Nov 29 12:26:09.302: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.302: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.302: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.302: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: node-local-dns-hqwqq from kube-system started at 2022-11-29 11:01:45 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.302: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: sonobuoy from sonobuoy started at 2022-11-29 11:25:29 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.302: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:26:09.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:26:09.302: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-1 before test
    Nov 29 12:26:09.308: INFO: canal-f2ndl from kube-system started at 2022-11-29 11:02:00 +0000 UTC (3 container statuses recorded)
    Nov 29 12:26:09.308: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.308: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.308: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.308: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: node-local-dns-wwm5j from kube-system started at 2022-11-29 11:02:00 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.308: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: sonobuoy-e2e-job-2558967603d841e7 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:26:09.308: INFO: 	Container e2e ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk from sonobuoy started at 2022-11-29 11:25:37 +0000 UTC (2 container statuses recorded)
    Nov 29 12:26:09.308: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:26:09.308: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-2 before test
    Nov 29 12:26:09.314: INFO: canal-xwmmp from kube-system started at 2022-11-29 11:01:59 +0000 UTC (3 container statuses recorded)
    Nov 29 12:26:09.314: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.314: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.314: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.314: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: node-local-dns-rf4vc from kube-system started at 2022-11-29 11:01:59 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.314: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: agnhost-primary-s7dtg from kubectl-1380 started at 2022-11-29 12:25:58 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.314: INFO: 	Container agnhost-primary ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:26:09.314: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:26:09.314: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-master-0 before test
    Nov 29 12:26:09.326: INFO: calico-kube-controllers-5c9848945f-6wztn from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.326: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: canal-5j97l from kube-system started at 2022-11-29 10:49:25 +0000 UTC (3 container statuses recorded)
    Nov 29 12:26:09.326: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: coredns-5cbcf9db85-hbrbr from kube-system started at 2022-11-29 11:01:49 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.326: INFO: 	Container coredns ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: coredns-5cbcf9db85-q2lfd from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.326: INFO: 	Container coredns ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.326: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.326: INFO: 	Container etcd ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (3 container statuses recorded)
    Nov 29 12:26:09.326: INFO: 	Container apiserver ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: 	Container kube-scheduler ready: true, restart count 0
    Nov 29 12:26:09.326: INFO: kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.326: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: kube-dns-autoscaler-bd7b594d-dwsh9 from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container autoscaler ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container node-label ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: kublr-system-shell-d595b78f-7ngf9 from kube-system started at 2022-11-29 10:52:20 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container shell ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: metrics-server-v0.5.2-54b5b7598b-zq8q6 from kube-system started at 2022-11-29 10:51:11 +0000 UTC (2 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container metrics-server ready: true, restart count 1
    Nov 29 12:26:09.327: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: node-local-dns-fp5nm from kube-system started at 2022-11-29 10:49:25 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: dashboard-metrics-scraper-6fffb6f45f-q7h8c from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: kubernetes-dashboard-c5db79646-sq2km from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.327: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 29 12:26:09.327: INFO: kublr-operator-576b5465f6-gdg4s from kublr started at 2022-11-29 10:51:53 +0000 UTC (1 container statuses recorded)
    Nov 29 12:26:09.328: INFO: 	Container kublr-operator ready: true, restart count 0
    Nov 29 12:26:09.328: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:26:09.328: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:26:09.328: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node dvi-7336-1669718118-vsp1-group1-0 11/29/22 12:26:09.427
    STEP: verifying the node has the label node dvi-7336-1669718118-vsp1-group1-1 11/29/22 12:26:09.454
    STEP: verifying the node has the label node dvi-7336-1669718118-vsp1-group1-2 11/29/22 12:26:09.539
    STEP: verifying the node has the label node dvi-7336-1669718118-vsp1-master-0 11/29/22 12:26:09.558
    Nov 29 12:26:09.579: INFO: Pod calico-kube-controllers-5c9848945f-6wztn requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod canal-5j97l requesting resource cpu=40m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod canal-f2ndl requesting resource cpu=40m on Node dvi-7336-1669718118-vsp1-group1-1
    Nov 29 12:26:09.579: INFO: Pod canal-wsz7n requesting resource cpu=40m on Node dvi-7336-1669718118-vsp1-group1-0
    Nov 29 12:26:09.579: INFO: Pod canal-xwmmp requesting resource cpu=40m on Node dvi-7336-1669718118-vsp1-group1-2
    Nov 29 12:26:09.579: INFO: Pod coredns-5cbcf9db85-hbrbr requesting resource cpu=100m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod coredns-5cbcf9db85-q2lfd requesting resource cpu=100m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-group1-0
    Nov 29 12:26:09.579: INFO: Pod k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-group1-1
    Nov 29 12:26:09.579: INFO: Pod k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-group1-2
    Nov 29 12:26:09.579: INFO: Pod k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=100m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=160m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=50m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod kube-dns-autoscaler-bd7b594d-dwsh9 requesting resource cpu=1m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-group1-0
    Nov 29 12:26:09.579: INFO: Pod kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-group1-1
    Nov 29 12:26:09.579: INFO: Pod kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-group1-2
    Nov 29 12:26:09.579: INFO: Pod kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-2
    Nov 29 12:26:09.579: INFO: Pod kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-0
    Nov 29 12:26:09.579: INFO: Pod kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-1
    Nov 29 12:26:09.579: INFO: Pod kublr-system-shell-d595b78f-7ngf9 requesting resource cpu=10m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod metrics-server-v0.5.2-54b5b7598b-zq8q6 requesting resource cpu=98m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod node-local-dns-fp5nm requesting resource cpu=25m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod node-local-dns-hqwqq requesting resource cpu=25m on Node dvi-7336-1669718118-vsp1-group1-0
    Nov 29 12:26:09.579: INFO: Pod node-local-dns-rf4vc requesting resource cpu=25m on Node dvi-7336-1669718118-vsp1-group1-2
    Nov 29 12:26:09.579: INFO: Pod node-local-dns-wwm5j requesting resource cpu=25m on Node dvi-7336-1669718118-vsp1-group1-1
    Nov 29 12:26:09.579: INFO: Pod agnhost-primary-s7dtg requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-2
    Nov 29 12:26:09.579: INFO: Pod dashboard-metrics-scraper-6fffb6f45f-q7h8c requesting resource cpu=5m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod kubernetes-dashboard-c5db79646-sq2km requesting resource cpu=10m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod kublr-operator-576b5465f6-gdg4s requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod sonobuoy requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-0
    Nov 29 12:26:09.579: INFO: Pod sonobuoy-e2e-job-2558967603d841e7 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-1
    Nov 29 12:26:09.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-0
    Nov 29 12:26:09.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-2
    Nov 29 12:26:09.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk requesting resource cpu=0m on Node dvi-7336-1669718118-vsp1-group1-1
    STEP: Starting Pods to consume most of the cluster CPU. 11/29/22 12:26:09.579
    Nov 29 12:26:09.579: INFO: Creating a pod which consumes cpu=2680m on Node dvi-7336-1669718118-vsp1-group1-2
    Nov 29 12:26:09.584: INFO: Creating a pod which consumes cpu=2236m on Node dvi-7336-1669718118-vsp1-master-0
    Nov 29 12:26:09.589: INFO: Creating a pod which consumes cpu=2680m on Node dvi-7336-1669718118-vsp1-group1-0
    Nov 29 12:26:09.640: INFO: Creating a pod which consumes cpu=2680m on Node dvi-7336-1669718118-vsp1-group1-1
    Nov 29 12:26:09.647: INFO: Waiting up to 5m0s for pod "filler-pod-2909791a-e85a-4574-bb2a-59206fb59744" in namespace "sched-pred-7697" to be "running"
    Nov 29 12:26:09.650: INFO: Pod "filler-pod-2909791a-e85a-4574-bb2a-59206fb59744": Phase="Pending", Reason="", readiness=false. Elapsed: 3.190739ms
    Nov 29 12:26:11.653: INFO: Pod "filler-pod-2909791a-e85a-4574-bb2a-59206fb59744": Phase="Running", Reason="", readiness=true. Elapsed: 2.006320454s
    Nov 29 12:26:11.653: INFO: Pod "filler-pod-2909791a-e85a-4574-bb2a-59206fb59744" satisfied condition "running"
    Nov 29 12:26:11.653: INFO: Waiting up to 5m0s for pod "filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c" in namespace "sched-pred-7697" to be "running"
    Nov 29 12:26:11.655: INFO: Pod "filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.311915ms
    Nov 29 12:26:11.655: INFO: Pod "filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c" satisfied condition "running"
    Nov 29 12:26:11.655: INFO: Waiting up to 5m0s for pod "filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd" in namespace "sched-pred-7697" to be "running"
    Nov 29 12:26:11.657: INFO: Pod "filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd": Phase="Running", Reason="", readiness=true. Elapsed: 2.014506ms
    Nov 29 12:26:11.657: INFO: Pod "filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd" satisfied condition "running"
    Nov 29 12:26:11.657: INFO: Waiting up to 5m0s for pod "filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a" in namespace "sched-pred-7697" to be "running"
    Nov 29 12:26:11.660: INFO: Pod "filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a": Phase="Running", Reason="", readiness=true. Elapsed: 2.107083ms
    Nov 29 12:26:11.660: INFO: Pod "filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 11/29/22 12:26:11.66
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-2909791a-e85a-4574-bb2a-59206fb59744.172c0dd4d2883529], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7697/filler-pod-2909791a-e85a-4574-bb2a-59206fb59744 to dvi-7336-1669718118-vsp1-group1-2] 11/29/22 12:26:11.662
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-2909791a-e85a-4574-bb2a-59206fb59744.172c0dd4f6dc7865], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/29/22 12:26:11.663
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-2909791a-e85a-4574-bb2a-59206fb59744.172c0dd5051ea97d], Reason = [Created], Message = [Created container filler-pod-2909791a-e85a-4574-bb2a-59206fb59744] 11/29/22 12:26:11.663
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-2909791a-e85a-4574-bb2a-59206fb59744.172c0dd50a64a7d6], Reason = [Started], Message = [Started container filler-pod-2909791a-e85a-4574-bb2a-59206fb59744] 11/29/22 12:26:11.663
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd.172c0dd4d5e3b727], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7697/filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd to dvi-7336-1669718118-vsp1-group1-0] 11/29/22 12:26:11.663
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd.172c0dd50a1adb04], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/29/22 12:26:11.663
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd.172c0dd512e60aef], Reason = [Created], Message = [Created container filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd] 11/29/22 12:26:11.663
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd.172c0dd517a3aaad], Reason = [Started], Message = [Started container filler-pod-4484b504-4ef6-4faa-b30b-f27b0e275ddd] 11/29/22 12:26:11.664
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c.172c0dd4d516f0d8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7697/filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c to dvi-7336-1669718118-vsp1-master-0] 11/29/22 12:26:11.664
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c.172c0dd5083589f9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/29/22 12:26:11.664
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c.172c0dd511a626ea], Reason = [Created], Message = [Created container filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c] 11/29/22 12:26:11.664
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c.172c0dd516fe8d42], Reason = [Started], Message = [Started container filler-pod-55f7f988-fdb2-4dac-b049-124e4a95cf4c] 11/29/22 12:26:11.664
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a.172c0dd4d6936bbf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7697/filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a to dvi-7336-1669718118-vsp1-group1-1] 11/29/22 12:26:11.664
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a.172c0dd509810c71], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/29/22 12:26:11.664
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a.172c0dd512d71aa7], Reason = [Created], Message = [Created container filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a] 11/29/22 12:26:11.665
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a.172c0dd518f09575], Reason = [Started], Message = [Started container filler-pod-985c5916-6e77-4eeb-a36f-278a0560293a] 11/29/22 12:26:11.665
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.172c0dd54e698f5c], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu. preemption: 0/4 nodes are available: 4 No preemption victims found for incoming pod.] 11/29/22 12:26:11.669
    STEP: removing the label node off the node dvi-7336-1669718118-vsp1-group1-0 11/29/22 12:26:12.67
    STEP: verifying the node doesn't have the label node 11/29/22 12:26:12.681
    STEP: removing the label node off the node dvi-7336-1669718118-vsp1-group1-1 11/29/22 12:26:12.69
    STEP: verifying the node doesn't have the label node 11/29/22 12:26:12.7
    STEP: removing the label node off the node dvi-7336-1669718118-vsp1-group1-2 11/29/22 12:26:12.704
    STEP: verifying the node doesn't have the label node 11/29/22 12:26:12.717
    STEP: removing the label node off the node dvi-7336-1669718118-vsp1-master-0 11/29/22 12:26:12.722
    STEP: verifying the node doesn't have the label node 11/29/22 12:26:12.733
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:26:12.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-7697" for this suite. 11/29/22 12:26:12.747
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:26:12.752
Nov 29 12:26:12.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename taint-single-pod 11/29/22 12:26:12.753
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:26:12.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:26:12.765
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Nov 29 12:26:12.768: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 29 12:27:12.802: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Nov 29 12:27:12.805: INFO: Starting informer...
STEP: Starting pod... 11/29/22 12:27:12.805
Nov 29 12:27:13.018: INFO: Pod is running on dvi-7336-1669718118-vsp1-group1-2. Tainting Node
STEP: Trying to apply a taint on the Node 11/29/22 12:27:13.018
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/29/22 12:27:13.034
STEP: Waiting short time to make sure Pod is queued for deletion 11/29/22 12:27:13.045
Nov 29 12:27:13.045: INFO: Pod wasn't evicted. Proceeding
Nov 29 12:27:13.045: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/29/22 12:27:13.059
STEP: Waiting some time to make sure that toleration time passed. 11/29/22 12:27:13.119
Nov 29 12:28:28.120: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:28:28.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8658" for this suite. 11/29/22 12:28:28.124
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":204,"skipped":3774,"failed":0}
------------------------------
• [SLOW TEST] [135.378 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:26:12.752
    Nov 29 12:26:12.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename taint-single-pod 11/29/22 12:26:12.753
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:26:12.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:26:12.765
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Nov 29 12:26:12.768: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 29 12:27:12.802: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Nov 29 12:27:12.805: INFO: Starting informer...
    STEP: Starting pod... 11/29/22 12:27:12.805
    Nov 29 12:27:13.018: INFO: Pod is running on dvi-7336-1669718118-vsp1-group1-2. Tainting Node
    STEP: Trying to apply a taint on the Node 11/29/22 12:27:13.018
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/29/22 12:27:13.034
    STEP: Waiting short time to make sure Pod is queued for deletion 11/29/22 12:27:13.045
    Nov 29 12:27:13.045: INFO: Pod wasn't evicted. Proceeding
    Nov 29 12:27:13.045: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/29/22 12:27:13.059
    STEP: Waiting some time to make sure that toleration time passed. 11/29/22 12:27:13.119
    Nov 29 12:28:28.120: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:28:28.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-8658" for this suite. 11/29/22 12:28:28.124
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:28:28.131
Nov 29 12:28:28.131: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 12:28:28.131
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:28:28.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:28:28.144
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-40fd6ceb-79e7-41f3-b1c0-6900aa0821a3 11/29/22 12:28:28.15
STEP: Creating configMap with name cm-test-opt-upd-1f31fb95-451b-4de6-847c-806d929ac12a 11/29/22 12:28:28.152
STEP: Creating the pod 11/29/22 12:28:28.155
Nov 29 12:28:28.159: INFO: Waiting up to 5m0s for pod "pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee" in namespace "configmap-907" to be "running and ready"
Nov 29 12:28:28.163: INFO: Pod "pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.390351ms
Nov 29 12:28:28.163: INFO: The phase of Pod pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:28:30.166: INFO: Pod "pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee": Phase="Running", Reason="", readiness=true. Elapsed: 2.006578902s
Nov 29 12:28:30.166: INFO: The phase of Pod pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee is Running (Ready = true)
Nov 29 12:28:30.166: INFO: Pod "pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-40fd6ceb-79e7-41f3-b1c0-6900aa0821a3 11/29/22 12:28:30.187
STEP: Updating configmap cm-test-opt-upd-1f31fb95-451b-4de6-847c-806d929ac12a 11/29/22 12:28:30.191
STEP: Creating configMap with name cm-test-opt-create-d1d75bfc-1374-43bd-bf97-a806521ae2ef 11/29/22 12:28:30.194
STEP: waiting to observe update in volume 11/29/22 12:28:30.197
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 12:28:34.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-907" for this suite. 11/29/22 12:28:34.221
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":205,"skipped":3780,"failed":0}
------------------------------
• [SLOW TEST] [6.093 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:28:28.131
    Nov 29 12:28:28.131: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 12:28:28.131
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:28:28.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:28:28.144
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-40fd6ceb-79e7-41f3-b1c0-6900aa0821a3 11/29/22 12:28:28.15
    STEP: Creating configMap with name cm-test-opt-upd-1f31fb95-451b-4de6-847c-806d929ac12a 11/29/22 12:28:28.152
    STEP: Creating the pod 11/29/22 12:28:28.155
    Nov 29 12:28:28.159: INFO: Waiting up to 5m0s for pod "pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee" in namespace "configmap-907" to be "running and ready"
    Nov 29 12:28:28.163: INFO: Pod "pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.390351ms
    Nov 29 12:28:28.163: INFO: The phase of Pod pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:28:30.166: INFO: Pod "pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee": Phase="Running", Reason="", readiness=true. Elapsed: 2.006578902s
    Nov 29 12:28:30.166: INFO: The phase of Pod pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee is Running (Ready = true)
    Nov 29 12:28:30.166: INFO: Pod "pod-configmaps-2bb1f352-5207-4026-bf7c-6c4c131aebee" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-40fd6ceb-79e7-41f3-b1c0-6900aa0821a3 11/29/22 12:28:30.187
    STEP: Updating configmap cm-test-opt-upd-1f31fb95-451b-4de6-847c-806d929ac12a 11/29/22 12:28:30.191
    STEP: Creating configMap with name cm-test-opt-create-d1d75bfc-1374-43bd-bf97-a806521ae2ef 11/29/22 12:28:30.194
    STEP: waiting to observe update in volume 11/29/22 12:28:30.197
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 12:28:34.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-907" for this suite. 11/29/22 12:28:34.221
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:28:34.224
Nov 29 12:28:34.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename var-expansion 11/29/22 12:28:34.225
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:28:34.235
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:28:34.238
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 11/29/22 12:28:34.24
STEP: waiting for pod running 11/29/22 12:28:34.245
Nov 29 12:28:34.245: INFO: Waiting up to 2m0s for pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" in namespace "var-expansion-6093" to be "running"
Nov 29 12:28:34.250: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079": Phase="Pending", Reason="", readiness=false. Elapsed: 4.613979ms
Nov 29 12:28:36.254: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079": Phase="Running", Reason="", readiness=true. Elapsed: 2.009069342s
Nov 29 12:28:36.254: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" satisfied condition "running"
STEP: creating a file in subpath 11/29/22 12:28:36.254
Nov 29 12:28:36.258: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-6093 PodName:var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:28:36.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:28:36.259: INFO: ExecWithOptions: Clientset creation
Nov 29 12:28:36.259: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/var-expansion-6093/pods/var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 11/29/22 12:28:36.352
Nov 29 12:28:36.356: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-6093 PodName:var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:28:36.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:28:36.356: INFO: ExecWithOptions: Clientset creation
Nov 29 12:28:36.356: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/var-expansion-6093/pods/var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 11/29/22 12:28:36.425
Nov 29 12:28:36.934: INFO: Successfully updated pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079"
STEP: waiting for annotated pod running 11/29/22 12:28:36.935
Nov 29 12:28:36.935: INFO: Waiting up to 2m0s for pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" in namespace "var-expansion-6093" to be "running"
Nov 29 12:28:36.937: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079": Phase="Running", Reason="", readiness=true. Elapsed: 2.189585ms
Nov 29 12:28:36.937: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" satisfied condition "running"
STEP: deleting the pod gracefully 11/29/22 12:28:36.937
Nov 29 12:28:36.937: INFO: Deleting pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" in namespace "var-expansion-6093"
Nov 29 12:28:36.941: INFO: Wait up to 5m0s for pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 29 12:29:10.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6093" for this suite. 11/29/22 12:29:10.95
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":206,"skipped":3787,"failed":0}
------------------------------
• [SLOW TEST] [36.730 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:28:34.224
    Nov 29 12:28:34.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename var-expansion 11/29/22 12:28:34.225
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:28:34.235
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:28:34.238
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 11/29/22 12:28:34.24
    STEP: waiting for pod running 11/29/22 12:28:34.245
    Nov 29 12:28:34.245: INFO: Waiting up to 2m0s for pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" in namespace "var-expansion-6093" to be "running"
    Nov 29 12:28:34.250: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079": Phase="Pending", Reason="", readiness=false. Elapsed: 4.613979ms
    Nov 29 12:28:36.254: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079": Phase="Running", Reason="", readiness=true. Elapsed: 2.009069342s
    Nov 29 12:28:36.254: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" satisfied condition "running"
    STEP: creating a file in subpath 11/29/22 12:28:36.254
    Nov 29 12:28:36.258: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-6093 PodName:var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:28:36.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:28:36.259: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:28:36.259: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/var-expansion-6093/pods/var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 11/29/22 12:28:36.352
    Nov 29 12:28:36.356: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-6093 PodName:var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:28:36.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:28:36.356: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:28:36.356: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/var-expansion-6093/pods/var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 11/29/22 12:28:36.425
    Nov 29 12:28:36.934: INFO: Successfully updated pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079"
    STEP: waiting for annotated pod running 11/29/22 12:28:36.935
    Nov 29 12:28:36.935: INFO: Waiting up to 2m0s for pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" in namespace "var-expansion-6093" to be "running"
    Nov 29 12:28:36.937: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079": Phase="Running", Reason="", readiness=true. Elapsed: 2.189585ms
    Nov 29 12:28:36.937: INFO: Pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" satisfied condition "running"
    STEP: deleting the pod gracefully 11/29/22 12:28:36.937
    Nov 29 12:28:36.937: INFO: Deleting pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" in namespace "var-expansion-6093"
    Nov 29 12:28:36.941: INFO: Wait up to 5m0s for pod "var-expansion-8335b0c0-7175-4746-bbf2-c7f576829079" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 29 12:29:10.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6093" for this suite. 11/29/22 12:29:10.95
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:29:10.956
Nov 29 12:29:10.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename dns 11/29/22 12:29:10.957
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:29:10.965
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:29:10.967
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 11/29/22 12:29:10.969
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
 11/29/22 12:29:10.973
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
 11/29/22 12:29:10.973
STEP: creating a pod to probe DNS 11/29/22 12:29:10.973
STEP: submitting the pod to kubernetes 11/29/22 12:29:10.973
Nov 29 12:29:10.978: INFO: Waiting up to 15m0s for pod "dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2" in namespace "dns-3147" to be "running"
Nov 29 12:29:10.980: INFO: Pod "dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.981021ms
Nov 29 12:29:12.983: INFO: Pod "dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005580054s
Nov 29 12:29:12.983: INFO: Pod "dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2" satisfied condition "running"
STEP: retrieving the pod 11/29/22 12:29:12.983
STEP: looking for the results for each expected name from probers 11/29/22 12:29:12.985
Nov 29 12:29:12.992: INFO: DNS probes using dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2 succeeded

STEP: deleting the pod 11/29/22 12:29:12.992
STEP: changing the externalName to bar.example.com 11/29/22 12:29:13
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
 11/29/22 12:29:13.007
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
 11/29/22 12:29:13.008
STEP: creating a second pod to probe DNS 11/29/22 12:29:13.008
STEP: submitting the pod to kubernetes 11/29/22 12:29:13.008
Nov 29 12:29:13.013: INFO: Waiting up to 15m0s for pod "dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518" in namespace "dns-3147" to be "running"
Nov 29 12:29:13.016: INFO: Pod "dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518": Phase="Pending", Reason="", readiness=false. Elapsed: 3.026571ms
Nov 29 12:29:15.030: INFO: Pod "dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518": Phase="Running", Reason="", readiness=true. Elapsed: 2.017038163s
Nov 29 12:29:15.030: INFO: Pod "dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518" satisfied condition "running"
STEP: retrieving the pod 11/29/22 12:29:15.03
STEP: looking for the results for each expected name from probers 11/29/22 12:29:15.032
Nov 29 12:29:15.039: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:15.041: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains '' instead of 'bar.example.com.'
Nov 29 12:29:15.041: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

Nov 29 12:29:20.045: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:20.048: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:20.048: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

Nov 29 12:29:25.046: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:25.048: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:25.048: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

Nov 29 12:29:30.045: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:30.048: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:30.048: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

Nov 29 12:29:35.046: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:35.049: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:35.049: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

Nov 29 12:29:40.049: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:40.054: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 29 12:29:40.054: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

Nov 29 12:29:45.073: INFO: DNS probes using dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 succeeded

STEP: deleting the pod 11/29/22 12:29:45.073
STEP: changing the service to type=ClusterIP 11/29/22 12:29:45.114
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
 11/29/22 12:29:45.143
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
 11/29/22 12:29:45.143
STEP: creating a third pod to probe DNS 11/29/22 12:29:45.143
STEP: submitting the pod to kubernetes 11/29/22 12:29:45.149
Nov 29 12:29:45.156: INFO: Waiting up to 15m0s for pod "dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de" in namespace "dns-3147" to be "running"
Nov 29 12:29:45.170: INFO: Pod "dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de": Phase="Pending", Reason="", readiness=false. Elapsed: 13.51098ms
Nov 29 12:29:47.173: INFO: Pod "dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de": Phase="Running", Reason="", readiness=true. Elapsed: 2.017195815s
Nov 29 12:29:47.173: INFO: Pod "dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de" satisfied condition "running"
STEP: retrieving the pod 11/29/22 12:29:47.173
STEP: looking for the results for each expected name from probers 11/29/22 12:29:47.176
Nov 29 12:29:47.208: INFO: DNS probes using dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de succeeded

STEP: deleting the pod 11/29/22 12:29:47.208
STEP: deleting the test externalName service 11/29/22 12:29:47.219
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 29 12:29:47.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3147" for this suite. 11/29/22 12:29:47.238
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":207,"skipped":3799,"failed":0}
------------------------------
• [SLOW TEST] [36.286 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:29:10.956
    Nov 29 12:29:10.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename dns 11/29/22 12:29:10.957
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:29:10.965
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:29:10.967
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 11/29/22 12:29:10.969
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
     11/29/22 12:29:10.973
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
     11/29/22 12:29:10.973
    STEP: creating a pod to probe DNS 11/29/22 12:29:10.973
    STEP: submitting the pod to kubernetes 11/29/22 12:29:10.973
    Nov 29 12:29:10.978: INFO: Waiting up to 15m0s for pod "dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2" in namespace "dns-3147" to be "running"
    Nov 29 12:29:10.980: INFO: Pod "dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.981021ms
    Nov 29 12:29:12.983: INFO: Pod "dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005580054s
    Nov 29 12:29:12.983: INFO: Pod "dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 12:29:12.983
    STEP: looking for the results for each expected name from probers 11/29/22 12:29:12.985
    Nov 29 12:29:12.992: INFO: DNS probes using dns-test-7dba2c1c-c5fa-4462-a1d6-ec6437e416d2 succeeded

    STEP: deleting the pod 11/29/22 12:29:12.992
    STEP: changing the externalName to bar.example.com 11/29/22 12:29:13
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
     11/29/22 12:29:13.007
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
     11/29/22 12:29:13.008
    STEP: creating a second pod to probe DNS 11/29/22 12:29:13.008
    STEP: submitting the pod to kubernetes 11/29/22 12:29:13.008
    Nov 29 12:29:13.013: INFO: Waiting up to 15m0s for pod "dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518" in namespace "dns-3147" to be "running"
    Nov 29 12:29:13.016: INFO: Pod "dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518": Phase="Pending", Reason="", readiness=false. Elapsed: 3.026571ms
    Nov 29 12:29:15.030: INFO: Pod "dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518": Phase="Running", Reason="", readiness=true. Elapsed: 2.017038163s
    Nov 29 12:29:15.030: INFO: Pod "dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 12:29:15.03
    STEP: looking for the results for each expected name from probers 11/29/22 12:29:15.032
    Nov 29 12:29:15.039: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:15.041: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains '' instead of 'bar.example.com.'
    Nov 29 12:29:15.041: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

    Nov 29 12:29:20.045: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:20.048: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:20.048: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

    Nov 29 12:29:25.046: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:25.048: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:25.048: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

    Nov 29 12:29:30.045: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:30.048: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:30.048: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

    Nov 29 12:29:35.046: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:35.049: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:35.049: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

    Nov 29 12:29:40.049: INFO: File wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:40.054: INFO: File jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local from pod  dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 29 12:29:40.054: INFO: Lookups using dns-3147/dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 failed for: [wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local]

    Nov 29 12:29:45.073: INFO: DNS probes using dns-test-e6d9e45b-1907-4b02-9d9c-ea8c3d940518 succeeded

    STEP: deleting the pod 11/29/22 12:29:45.073
    STEP: changing the service to type=ClusterIP 11/29/22 12:29:45.114
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
     11/29/22 12:29:45.143
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3147.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3147.svc.cluster.local; sleep 1; done
     11/29/22 12:29:45.143
    STEP: creating a third pod to probe DNS 11/29/22 12:29:45.143
    STEP: submitting the pod to kubernetes 11/29/22 12:29:45.149
    Nov 29 12:29:45.156: INFO: Waiting up to 15m0s for pod "dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de" in namespace "dns-3147" to be "running"
    Nov 29 12:29:45.170: INFO: Pod "dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de": Phase="Pending", Reason="", readiness=false. Elapsed: 13.51098ms
    Nov 29 12:29:47.173: INFO: Pod "dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de": Phase="Running", Reason="", readiness=true. Elapsed: 2.017195815s
    Nov 29 12:29:47.173: INFO: Pod "dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 12:29:47.173
    STEP: looking for the results for each expected name from probers 11/29/22 12:29:47.176
    Nov 29 12:29:47.208: INFO: DNS probes using dns-test-e6e4998d-9f3d-45a8-9a4b-95dc5d2ec1de succeeded

    STEP: deleting the pod 11/29/22 12:29:47.208
    STEP: deleting the test externalName service 11/29/22 12:29:47.219
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 29 12:29:47.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3147" for this suite. 11/29/22 12:29:47.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:29:47.244
Nov 29 12:29:47.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename svcaccounts 11/29/22 12:29:47.245
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:29:47.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:29:47.264
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  11/29/22 12:29:47.266
Nov 29 12:29:47.273: INFO: Waiting up to 5m0s for pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e" in namespace "svcaccounts-176" to be "Succeeded or Failed"
Nov 29 12:29:47.276: INFO: Pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.539908ms
Nov 29 12:29:49.292: INFO: Pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019761528s
Nov 29 12:29:51.280: INFO: Pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006818446s
STEP: Saw pod success 11/29/22 12:29:51.28
Nov 29 12:29:51.280: INFO: Pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e" satisfied condition "Succeeded or Failed"
Nov 29 12:29:51.282: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod test-pod-4a068a79-a08a-4591-bca9-ead3db50143e container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:29:51.287
Nov 29 12:29:51.293: INFO: Waiting for pod test-pod-4a068a79-a08a-4591-bca9-ead3db50143e to disappear
Nov 29 12:29:51.297: INFO: Pod test-pod-4a068a79-a08a-4591-bca9-ead3db50143e no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 29 12:29:51.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-176" for this suite. 11/29/22 12:29:51.301
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":208,"skipped":3826,"failed":0}
------------------------------
• [4.062 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:29:47.244
    Nov 29 12:29:47.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename svcaccounts 11/29/22 12:29:47.245
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:29:47.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:29:47.264
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  11/29/22 12:29:47.266
    Nov 29 12:29:47.273: INFO: Waiting up to 5m0s for pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e" in namespace "svcaccounts-176" to be "Succeeded or Failed"
    Nov 29 12:29:47.276: INFO: Pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.539908ms
    Nov 29 12:29:49.292: INFO: Pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019761528s
    Nov 29 12:29:51.280: INFO: Pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006818446s
    STEP: Saw pod success 11/29/22 12:29:51.28
    Nov 29 12:29:51.280: INFO: Pod "test-pod-4a068a79-a08a-4591-bca9-ead3db50143e" satisfied condition "Succeeded or Failed"
    Nov 29 12:29:51.282: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod test-pod-4a068a79-a08a-4591-bca9-ead3db50143e container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:29:51.287
    Nov 29 12:29:51.293: INFO: Waiting for pod test-pod-4a068a79-a08a-4591-bca9-ead3db50143e to disappear
    Nov 29 12:29:51.297: INFO: Pod test-pod-4a068a79-a08a-4591-bca9-ead3db50143e no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 29 12:29:51.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-176" for this suite. 11/29/22 12:29:51.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:29:51.307
Nov 29 12:29:51.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:29:51.308
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:29:51.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:29:51.329
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-613d5787-ab71-4142-806f-81be2ff7b1f7 11/29/22 12:29:51.338
STEP: Creating the pod 11/29/22 12:29:51.341
Nov 29 12:29:51.345: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4" in namespace "projected-4086" to be "running and ready"
Nov 29 12:29:51.348: INFO: Pod "pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.063941ms
Nov 29 12:29:51.348: INFO: The phase of Pod pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:29:53.351: INFO: Pod "pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006656855s
Nov 29 12:29:53.351: INFO: The phase of Pod pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4 is Running (Ready = true)
Nov 29 12:29:53.351: INFO: Pod "pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-613d5787-ab71-4142-806f-81be2ff7b1f7 11/29/22 12:29:53.357
STEP: waiting to observe update in volume 11/29/22 12:29:53.36
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 12:31:03.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4086" for this suite. 11/29/22 12:31:03.591
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":209,"skipped":3834,"failed":0}
------------------------------
• [SLOW TEST] [72.288 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:29:51.307
    Nov 29 12:29:51.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:29:51.308
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:29:51.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:29:51.329
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-613d5787-ab71-4142-806f-81be2ff7b1f7 11/29/22 12:29:51.338
    STEP: Creating the pod 11/29/22 12:29:51.341
    Nov 29 12:29:51.345: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4" in namespace "projected-4086" to be "running and ready"
    Nov 29 12:29:51.348: INFO: Pod "pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.063941ms
    Nov 29 12:29:51.348: INFO: The phase of Pod pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:29:53.351: INFO: Pod "pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006656855s
    Nov 29 12:29:53.351: INFO: The phase of Pod pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4 is Running (Ready = true)
    Nov 29 12:29:53.351: INFO: Pod "pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-613d5787-ab71-4142-806f-81be2ff7b1f7 11/29/22 12:29:53.357
    STEP: waiting to observe update in volume 11/29/22 12:29:53.36
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 12:31:03.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4086" for this suite. 11/29/22 12:31:03.591
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:31:03.596
Nov 29 12:31:03.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-pred 11/29/22 12:31:03.597
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:31:03.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:31:03.608
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 29 12:31:03.610: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 29 12:31:03.617: INFO: Waiting for terminating namespaces to be deleted...
Nov 29 12:31:03.619: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-0 before test
Nov 29 12:31:03.625: INFO: canal-wsz7n from kube-system started at 2022-11-29 11:01:45 +0000 UTC (3 container statuses recorded)
Nov 29 12:31:03.625: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:31:03.625: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:31:03.626: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:31:03.626: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.626: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:31:03.626: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.626: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:31:03.626: INFO: kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.626: INFO: 	Container main ready: true, restart count 0
Nov 29 12:31:03.626: INFO: node-local-dns-hqwqq from kube-system started at 2022-11-29 11:01:45 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.626: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:31:03.626: INFO: sonobuoy from sonobuoy started at 2022-11-29 11:25:29 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.626: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 29 12:31:03.626: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:31:03.626: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:31:03.626: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:31:03.626: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-1 before test
Nov 29 12:31:03.632: INFO: canal-f2ndl from kube-system started at 2022-11-29 11:02:00 +0000 UTC (3 container statuses recorded)
Nov 29 12:31:03.632: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:31:03.632: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:31:03.632: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:31:03.632: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.632: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:31:03.632: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.632: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:31:03.632: INFO: kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.632: INFO: 	Container main ready: true, restart count 0
Nov 29 12:31:03.632: INFO: node-local-dns-wwm5j from kube-system started at 2022-11-29 11:02:00 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.632: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:31:03.632: INFO: sonobuoy-e2e-job-2558967603d841e7 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:31:03.632: INFO: 	Container e2e ready: true, restart count 0
Nov 29 12:31:03.632: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:31:03.632: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk from sonobuoy started at 2022-11-29 11:25:37 +0000 UTC (2 container statuses recorded)
Nov 29 12:31:03.632: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:31:03.632: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:31:03.632: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-2 before test
Nov 29 12:31:03.637: INFO: canal-xwmmp from kube-system started at 2022-11-29 11:01:59 +0000 UTC (3 container statuses recorded)
Nov 29 12:31:03.637: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:31:03.637: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:31:03.637: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:31:03.637: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.637: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:31:03.637: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.637: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:31:03.637: INFO: kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.637: INFO: 	Container main ready: true, restart count 0
Nov 29 12:31:03.637: INFO: node-local-dns-rf4vc from kube-system started at 2022-11-29 11:01:59 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.637: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:31:03.637: INFO: pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4 from projected-4086 started at 2022-11-29 12:29:51 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.637: INFO: 	Container agnhost-container ready: true, restart count 0
Nov 29 12:31:03.637: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:31:03.637: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:31:03.637: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:31:03.637: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-master-0 before test
Nov 29 12:31:03.644: INFO: calico-kube-controllers-5c9848945f-6wztn from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 29 12:31:03.645: INFO: canal-5j97l from kube-system started at 2022-11-29 10:49:25 +0000 UTC (3 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:31:03.645: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:31:03.645: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:31:03.645: INFO: coredns-5cbcf9db85-hbrbr from kube-system started at 2022-11-29 11:01:49 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container coredns ready: true, restart count 0
Nov 29 12:31:03.645: INFO: coredns-5cbcf9db85-q2lfd from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container coredns ready: true, restart count 0
Nov 29 12:31:03.645: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:31:03.645: INFO: k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container etcd ready: true, restart count 0
Nov 29 12:31:03.645: INFO: k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (3 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container apiserver ready: true, restart count 0
Nov 29 12:31:03.645: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov 29 12:31:03.645: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov 29 12:31:03.645: INFO: kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container kube-addon-manager ready: true, restart count 0
Nov 29 12:31:03.645: INFO: kube-dns-autoscaler-bd7b594d-dwsh9 from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container autoscaler ready: true, restart count 0
Nov 29 12:31:03.645: INFO: kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:31:03.645: INFO: kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container node-label ready: true, restart count 0
Nov 29 12:31:03.645: INFO: kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container main ready: true, restart count 0
Nov 29 12:31:03.645: INFO: kublr-system-shell-d595b78f-7ngf9 from kube-system started at 2022-11-29 10:52:20 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container shell ready: true, restart count 0
Nov 29 12:31:03.645: INFO: metrics-server-v0.5.2-54b5b7598b-zq8q6 from kube-system started at 2022-11-29 10:51:11 +0000 UTC (2 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container metrics-server ready: true, restart count 1
Nov 29 12:31:03.645: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 29 12:31:03.645: INFO: node-local-dns-fp5nm from kube-system started at 2022-11-29 10:49:25 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:31:03.645: INFO: dashboard-metrics-scraper-6fffb6f45f-q7h8c from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 29 12:31:03.645: INFO: kubernetes-dashboard-c5db79646-sq2km from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 29 12:31:03.645: INFO: kublr-operator-576b5465f6-gdg4s from kublr started at 2022-11-29 10:51:53 +0000 UTC (1 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container kublr-operator ready: true, restart count 0
Nov 29 12:31:03.645: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:31:03.645: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:31:03.645: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 11/29/22 12:31:03.645
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.172c0e194b5461b6], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match Pod's node affinity/selector. preemption: 0/4 nodes are available: 4 Preemption is not helpful for scheduling.] 11/29/22 12:31:03.684
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:31:04.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1251" for this suite. 11/29/22 12:31:04.677
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":210,"skipped":3835,"failed":0}
------------------------------
• [1.086 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:31:03.596
    Nov 29 12:31:03.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-pred 11/29/22 12:31:03.597
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:31:03.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:31:03.608
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 29 12:31:03.610: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 29 12:31:03.617: INFO: Waiting for terminating namespaces to be deleted...
    Nov 29 12:31:03.619: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-0 before test
    Nov 29 12:31:03.625: INFO: canal-wsz7n from kube-system started at 2022-11-29 11:01:45 +0000 UTC (3 container statuses recorded)
    Nov 29 12:31:03.625: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:31:03.625: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.626: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.626: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.626: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: node-local-dns-hqwqq from kube-system started at 2022-11-29 11:01:45 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.626: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: sonobuoy from sonobuoy started at 2022-11-29 11:25:29 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.626: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:31:03.626: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:31:03.626: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-1 before test
    Nov 29 12:31:03.632: INFO: canal-f2ndl from kube-system started at 2022-11-29 11:02:00 +0000 UTC (3 container statuses recorded)
    Nov 29 12:31:03.632: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.632: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.632: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.632: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: node-local-dns-wwm5j from kube-system started at 2022-11-29 11:02:00 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.632: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: sonobuoy-e2e-job-2558967603d841e7 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:31:03.632: INFO: 	Container e2e ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk from sonobuoy started at 2022-11-29 11:25:37 +0000 UTC (2 container statuses recorded)
    Nov 29 12:31:03.632: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:31:03.632: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-2 before test
    Nov 29 12:31:03.637: INFO: canal-xwmmp from kube-system started at 2022-11-29 11:01:59 +0000 UTC (3 container statuses recorded)
    Nov 29 12:31:03.637: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.637: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.637: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.637: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: node-local-dns-rf4vc from kube-system started at 2022-11-29 11:01:59 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.637: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: pod-projected-configmaps-1c6872f8-677d-4dc5-8e14-cd97a8483fa4 from projected-4086 started at 2022-11-29 12:29:51 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.637: INFO: 	Container agnhost-container ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:31:03.637: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:31:03.637: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-master-0 before test
    Nov 29 12:31:03.644: INFO: calico-kube-controllers-5c9848945f-6wztn from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: canal-5j97l from kube-system started at 2022-11-29 10:49:25 +0000 UTC (3 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: coredns-5cbcf9db85-hbrbr from kube-system started at 2022-11-29 11:01:49 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container coredns ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: coredns-5cbcf9db85-q2lfd from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container coredns ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container etcd ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (3 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container apiserver ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: 	Container kube-scheduler ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: kube-dns-autoscaler-bd7b594d-dwsh9 from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container autoscaler ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container node-label ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: kublr-system-shell-d595b78f-7ngf9 from kube-system started at 2022-11-29 10:52:20 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container shell ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: metrics-server-v0.5.2-54b5b7598b-zq8q6 from kube-system started at 2022-11-29 10:51:11 +0000 UTC (2 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container metrics-server ready: true, restart count 1
    Nov 29 12:31:03.645: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: node-local-dns-fp5nm from kube-system started at 2022-11-29 10:49:25 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: dashboard-metrics-scraper-6fffb6f45f-q7h8c from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: kubernetes-dashboard-c5db79646-sq2km from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: kublr-operator-576b5465f6-gdg4s from kublr started at 2022-11-29 10:51:53 +0000 UTC (1 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container kublr-operator ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:31:03.645: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:31:03.645: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 11/29/22 12:31:03.645
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.172c0e194b5461b6], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match Pod's node affinity/selector. preemption: 0/4 nodes are available: 4 Preemption is not helpful for scheduling.] 11/29/22 12:31:03.684
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:31:04.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-1251" for this suite. 11/29/22 12:31:04.677
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:31:04.684
Nov 29 12:31:04.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:31:04.685
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:31:04.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:31:04.696
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-befe8bc9-2447-4934-afc7-2741298d7818 11/29/22 12:31:04.702
STEP: Creating secret with name s-test-opt-upd-e8d33719-e91c-4841-83bd-69498e6aedd9 11/29/22 12:31:04.705
STEP: Creating the pod 11/29/22 12:31:04.707
Nov 29 12:31:04.712: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271" in namespace "projected-3551" to be "running and ready"
Nov 29 12:31:04.716: INFO: Pod "pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271": Phase="Pending", Reason="", readiness=false. Elapsed: 4.418061ms
Nov 29 12:31:04.717: INFO: The phase of Pod pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:31:06.721: INFO: Pod "pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271": Phase="Running", Reason="", readiness=true. Elapsed: 2.008971689s
Nov 29 12:31:06.721: INFO: The phase of Pod pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271 is Running (Ready = true)
Nov 29 12:31:06.721: INFO: Pod "pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-befe8bc9-2447-4934-afc7-2741298d7818 11/29/22 12:31:06.744
STEP: Updating secret s-test-opt-upd-e8d33719-e91c-4841-83bd-69498e6aedd9 11/29/22 12:31:06.748
STEP: Creating secret with name s-test-opt-create-7fd1c988-0a16-4318-9466-0086598c45f1 11/29/22 12:31:06.751
STEP: waiting to observe update in volume 11/29/22 12:31:06.754
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 29 12:31:10.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3551" for this suite. 11/29/22 12:31:10.784
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":211,"skipped":3841,"failed":0}
------------------------------
• [SLOW TEST] [6.104 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:31:04.684
    Nov 29 12:31:04.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:31:04.685
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:31:04.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:31:04.696
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-befe8bc9-2447-4934-afc7-2741298d7818 11/29/22 12:31:04.702
    STEP: Creating secret with name s-test-opt-upd-e8d33719-e91c-4841-83bd-69498e6aedd9 11/29/22 12:31:04.705
    STEP: Creating the pod 11/29/22 12:31:04.707
    Nov 29 12:31:04.712: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271" in namespace "projected-3551" to be "running and ready"
    Nov 29 12:31:04.716: INFO: Pod "pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271": Phase="Pending", Reason="", readiness=false. Elapsed: 4.418061ms
    Nov 29 12:31:04.717: INFO: The phase of Pod pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:31:06.721: INFO: Pod "pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271": Phase="Running", Reason="", readiness=true. Elapsed: 2.008971689s
    Nov 29 12:31:06.721: INFO: The phase of Pod pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271 is Running (Ready = true)
    Nov 29 12:31:06.721: INFO: Pod "pod-projected-secrets-2b3bbaf5-5ca1-49c2-a5d0-6432cbe24271" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-befe8bc9-2447-4934-afc7-2741298d7818 11/29/22 12:31:06.744
    STEP: Updating secret s-test-opt-upd-e8d33719-e91c-4841-83bd-69498e6aedd9 11/29/22 12:31:06.748
    STEP: Creating secret with name s-test-opt-create-7fd1c988-0a16-4318-9466-0086598c45f1 11/29/22 12:31:06.751
    STEP: waiting to observe update in volume 11/29/22 12:31:06.754
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 29 12:31:10.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3551" for this suite. 11/29/22 12:31:10.784
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:31:10.789
Nov 29 12:31:10.789: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-probe 11/29/22 12:31:10.79
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:31:10.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:31:10.803
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 in namespace container-probe-1339 11/29/22 12:31:10.806
Nov 29 12:31:10.810: INFO: Waiting up to 5m0s for pod "liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162" in namespace "container-probe-1339" to be "not pending"
Nov 29 12:31:10.823: INFO: Pod "liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162": Phase="Pending", Reason="", readiness=false. Elapsed: 12.845968ms
Nov 29 12:31:12.831: INFO: Pod "liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162": Phase="Running", Reason="", readiness=true. Elapsed: 2.021060749s
Nov 29 12:31:12.831: INFO: Pod "liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162" satisfied condition "not pending"
Nov 29 12:31:12.831: INFO: Started pod liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 in namespace container-probe-1339
STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 12:31:12.831
Nov 29 12:31:12.836: INFO: Initial restart count of pod liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is 0
Nov 29 12:31:32.877: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 1 (20.040429209s elapsed)
Nov 29 12:31:52.913: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 2 (40.076882932s elapsed)
Nov 29 12:32:12.951: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 3 (1m0.114785186s elapsed)
Nov 29 12:32:32.985: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 4 (1m20.14861329s elapsed)
Nov 29 12:33:37.134: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 5 (2m24.297479935s elapsed)
STEP: deleting the pod 11/29/22 12:33:37.134
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 29 12:33:37.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1339" for this suite. 11/29/22 12:33:37.157
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":212,"skipped":3843,"failed":0}
------------------------------
• [SLOW TEST] [146.372 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:31:10.789
    Nov 29 12:31:10.789: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-probe 11/29/22 12:31:10.79
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:31:10.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:31:10.803
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 in namespace container-probe-1339 11/29/22 12:31:10.806
    Nov 29 12:31:10.810: INFO: Waiting up to 5m0s for pod "liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162" in namespace "container-probe-1339" to be "not pending"
    Nov 29 12:31:10.823: INFO: Pod "liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162": Phase="Pending", Reason="", readiness=false. Elapsed: 12.845968ms
    Nov 29 12:31:12.831: INFO: Pod "liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162": Phase="Running", Reason="", readiness=true. Elapsed: 2.021060749s
    Nov 29 12:31:12.831: INFO: Pod "liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162" satisfied condition "not pending"
    Nov 29 12:31:12.831: INFO: Started pod liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 in namespace container-probe-1339
    STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 12:31:12.831
    Nov 29 12:31:12.836: INFO: Initial restart count of pod liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is 0
    Nov 29 12:31:32.877: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 1 (20.040429209s elapsed)
    Nov 29 12:31:52.913: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 2 (40.076882932s elapsed)
    Nov 29 12:32:12.951: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 3 (1m0.114785186s elapsed)
    Nov 29 12:32:32.985: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 4 (1m20.14861329s elapsed)
    Nov 29 12:33:37.134: INFO: Restart count of pod container-probe-1339/liveness-ecf85a02-d9d7-45de-ae5c-0ac0fb1bd162 is now 5 (2m24.297479935s elapsed)
    STEP: deleting the pod 11/29/22 12:33:37.134
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 29 12:33:37.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1339" for this suite. 11/29/22 12:33:37.157
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:33:37.161
Nov 29 12:33:37.161: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename statefulset 11/29/22 12:33:37.162
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:33:37.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:33:37.178
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5077 11/29/22 12:33:37.181
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-5077 11/29/22 12:33:37.185
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5077 11/29/22 12:33:37.193
Nov 29 12:33:37.203: INFO: Found 0 stateful pods, waiting for 1
Nov 29 12:33:47.206: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/29/22 12:33:47.206
Nov 29 12:33:47.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 12:33:47.333: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 12:33:47.333: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 12:33:47.333: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 12:33:47.335: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 29 12:33:57.341: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 29 12:33:57.341: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 12:33:57.352: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Nov 29 12:33:57.352: INFO: ss-0  dvi-7336-1669718118-vsp1-group1-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:37 +0000 UTC  }]
Nov 29 12:33:57.352: INFO: 
Nov 29 12:33:57.352: INFO: StatefulSet ss has not reached scale 3, at 1
Nov 29 12:33:58.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996812208s
Nov 29 12:33:59.364: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987673957s
Nov 29 12:34:00.369: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984455835s
Nov 29 12:34:01.373: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979330708s
Nov 29 12:34:02.376: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975767212s
Nov 29 12:34:03.379: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972517988s
Nov 29 12:34:04.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969362315s
Nov 29 12:34:05.387: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965360017s
Nov 29 12:34:06.390: INFO: Verifying statefulset ss doesn't scale past 3 for another 962.045911ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5077 11/29/22 12:34:07.39
Nov 29 12:34:07.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 12:34:07.526: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 29 12:34:07.526: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 12:34:07.526: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 29 12:34:07.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 12:34:07.667: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 29 12:34:07.667: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 12:34:07.667: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 29 12:34:07.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 29 12:34:07.794: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 29 12:34:07.794: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 29 12:34:07.794: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 29 12:34:07.796: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 12:34:07.796: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 29 12:34:07.796: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 11/29/22 12:34:07.796
Nov 29 12:34:07.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 12:34:07.936: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 12:34:07.936: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 12:34:07.936: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 12:34:07.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 12:34:08.063: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 12:34:08.063: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 12:34:08.063: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 12:34:08.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 29 12:34:08.178: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 29 12:34:08.178: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 29 12:34:08.178: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 29 12:34:08.178: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 12:34:08.181: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov 29 12:34:18.187: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 29 12:34:18.187: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 29 12:34:18.187: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 29 12:34:18.196: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Nov 29 12:34:18.196: INFO: ss-0  dvi-7336-1669718118-vsp1-group1-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:37 +0000 UTC  }]
Nov 29 12:34:18.196: INFO: ss-1  dvi-7336-1669718118-vsp1-group1-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  }]
Nov 29 12:34:18.196: INFO: ss-2  dvi-7336-1669718118-vsp1-group1-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  }]
Nov 29 12:34:18.196: INFO: 
Nov 29 12:34:18.196: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 29 12:34:19.200: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Nov 29 12:34:19.200: INFO: ss-2  dvi-7336-1669718118-vsp1-group1-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  }]
Nov 29 12:34:19.200: INFO: 
Nov 29 12:34:19.200: INFO: StatefulSet ss has not reached scale 0, at 1
Nov 29 12:34:20.203: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.992742574s
Nov 29 12:34:21.206: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.990082207s
Nov 29 12:34:22.209: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.986199549s
Nov 29 12:34:23.212: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.983389055s
Nov 29 12:34:24.215: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.980663745s
Nov 29 12:34:25.219: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.977251649s
Nov 29 12:34:26.222: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.973295508s
Nov 29 12:34:27.226: INFO: Verifying statefulset ss doesn't scale past 0 for another 970.587045ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5077 11/29/22 12:34:28.227
Nov 29 12:34:28.229: INFO: Scaling statefulset ss to 0
Nov 29 12:34:28.237: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 29 12:34:28.238: INFO: Deleting all statefulset in ns statefulset-5077
Nov 29 12:34:28.240: INFO: Scaling statefulset ss to 0
Nov 29 12:34:28.246: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 12:34:28.247: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 29 12:34:28.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5077" for this suite. 11/29/22 12:34:28.263
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":213,"skipped":3862,"failed":0}
------------------------------
• [SLOW TEST] [51.106 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:33:37.161
    Nov 29 12:33:37.161: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename statefulset 11/29/22 12:33:37.162
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:33:37.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:33:37.178
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5077 11/29/22 12:33:37.181
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-5077 11/29/22 12:33:37.185
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5077 11/29/22 12:33:37.193
    Nov 29 12:33:37.203: INFO: Found 0 stateful pods, waiting for 1
    Nov 29 12:33:47.206: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/29/22 12:33:47.206
    Nov 29 12:33:47.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 12:33:47.333: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 12:33:47.333: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 12:33:47.333: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 12:33:47.335: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov 29 12:33:57.341: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 29 12:33:57.341: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 12:33:57.352: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
    Nov 29 12:33:57.352: INFO: ss-0  dvi-7336-1669718118-vsp1-group1-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:37 +0000 UTC  }]
    Nov 29 12:33:57.352: INFO: 
    Nov 29 12:33:57.352: INFO: StatefulSet ss has not reached scale 3, at 1
    Nov 29 12:33:58.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996812208s
    Nov 29 12:33:59.364: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987673957s
    Nov 29 12:34:00.369: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984455835s
    Nov 29 12:34:01.373: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979330708s
    Nov 29 12:34:02.376: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975767212s
    Nov 29 12:34:03.379: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972517988s
    Nov 29 12:34:04.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969362315s
    Nov 29 12:34:05.387: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965360017s
    Nov 29 12:34:06.390: INFO: Verifying statefulset ss doesn't scale past 3 for another 962.045911ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5077 11/29/22 12:34:07.39
    Nov 29 12:34:07.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 12:34:07.526: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 29 12:34:07.526: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 12:34:07.526: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 29 12:34:07.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 12:34:07.667: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov 29 12:34:07.667: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 12:34:07.667: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 29 12:34:07.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 29 12:34:07.794: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov 29 12:34:07.794: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 29 12:34:07.794: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 29 12:34:07.796: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 12:34:07.796: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 29 12:34:07.796: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 11/29/22 12:34:07.796
    Nov 29 12:34:07.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 12:34:07.936: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 12:34:07.936: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 12:34:07.936: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 12:34:07.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 12:34:08.063: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 12:34:08.063: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 12:34:08.063: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 12:34:08.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=statefulset-5077 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 29 12:34:08.178: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 29 12:34:08.178: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 29 12:34:08.178: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 29 12:34:08.178: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 12:34:08.181: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Nov 29 12:34:18.187: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 29 12:34:18.187: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov 29 12:34:18.187: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov 29 12:34:18.196: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
    Nov 29 12:34:18.196: INFO: ss-0  dvi-7336-1669718118-vsp1-group1-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:37 +0000 UTC  }]
    Nov 29 12:34:18.196: INFO: ss-1  dvi-7336-1669718118-vsp1-group1-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  }]
    Nov 29 12:34:18.196: INFO: ss-2  dvi-7336-1669718118-vsp1-group1-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  }]
    Nov 29 12:34:18.196: INFO: 
    Nov 29 12:34:18.196: INFO: StatefulSet ss has not reached scale 0, at 3
    Nov 29 12:34:19.200: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
    Nov 29 12:34:19.200: INFO: ss-2  dvi-7336-1669718118-vsp1-group1-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:34:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 12:33:57 +0000 UTC  }]
    Nov 29 12:34:19.200: INFO: 
    Nov 29 12:34:19.200: INFO: StatefulSet ss has not reached scale 0, at 1
    Nov 29 12:34:20.203: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.992742574s
    Nov 29 12:34:21.206: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.990082207s
    Nov 29 12:34:22.209: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.986199549s
    Nov 29 12:34:23.212: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.983389055s
    Nov 29 12:34:24.215: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.980663745s
    Nov 29 12:34:25.219: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.977251649s
    Nov 29 12:34:26.222: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.973295508s
    Nov 29 12:34:27.226: INFO: Verifying statefulset ss doesn't scale past 0 for another 970.587045ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5077 11/29/22 12:34:28.227
    Nov 29 12:34:28.229: INFO: Scaling statefulset ss to 0
    Nov 29 12:34:28.237: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 29 12:34:28.238: INFO: Deleting all statefulset in ns statefulset-5077
    Nov 29 12:34:28.240: INFO: Scaling statefulset ss to 0
    Nov 29 12:34:28.246: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 12:34:28.247: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 29 12:34:28.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5077" for this suite. 11/29/22 12:34:28.263
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:34:28.269
Nov 29 12:34:28.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 12:34:28.27
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:34:28.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:34:28.283
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/29/22 12:34:28.285
Nov 29 12:34:28.285: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:34:32.314: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:34:44.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2879" for this suite. 11/29/22 12:34:44.293
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":214,"skipped":3888,"failed":0}
------------------------------
• [SLOW TEST] [16.027 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:34:28.269
    Nov 29 12:34:28.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 12:34:28.27
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:34:28.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:34:28.283
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/29/22 12:34:28.285
    Nov 29 12:34:28.285: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:34:32.314: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:34:44.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2879" for this suite. 11/29/22 12:34:44.293
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:34:44.297
Nov 29 12:34:44.297: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-probe 11/29/22 12:34:44.299
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:34:44.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:34:44.311
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d in namespace container-probe-7837 11/29/22 12:34:44.313
Nov 29 12:34:44.318: INFO: Waiting up to 5m0s for pod "busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d" in namespace "container-probe-7837" to be "not pending"
Nov 29 12:34:44.320: INFO: Pod "busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049578ms
Nov 29 12:34:46.324: INFO: Pod "busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d": Phase="Running", Reason="", readiness=true. Elapsed: 2.006329312s
Nov 29 12:34:46.324: INFO: Pod "busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d" satisfied condition "not pending"
Nov 29 12:34:46.324: INFO: Started pod busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d in namespace container-probe-7837
STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 12:34:46.324
Nov 29 12:34:46.327: INFO: Initial restart count of pod busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d is 0
Nov 29 12:35:36.468: INFO: Restart count of pod container-probe-7837/busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d is now 1 (50.141490108s elapsed)
STEP: deleting the pod 11/29/22 12:35:36.468
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 29 12:35:36.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7837" for this suite. 11/29/22 12:35:36.612
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":215,"skipped":3893,"failed":0}
------------------------------
• [SLOW TEST] [52.319 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:34:44.297
    Nov 29 12:34:44.297: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-probe 11/29/22 12:34:44.299
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:34:44.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:34:44.311
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d in namespace container-probe-7837 11/29/22 12:34:44.313
    Nov 29 12:34:44.318: INFO: Waiting up to 5m0s for pod "busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d" in namespace "container-probe-7837" to be "not pending"
    Nov 29 12:34:44.320: INFO: Pod "busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049578ms
    Nov 29 12:34:46.324: INFO: Pod "busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d": Phase="Running", Reason="", readiness=true. Elapsed: 2.006329312s
    Nov 29 12:34:46.324: INFO: Pod "busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d" satisfied condition "not pending"
    Nov 29 12:34:46.324: INFO: Started pod busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d in namespace container-probe-7837
    STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 12:34:46.324
    Nov 29 12:34:46.327: INFO: Initial restart count of pod busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d is 0
    Nov 29 12:35:36.468: INFO: Restart count of pod container-probe-7837/busybox-4ee405b4-5a5a-4afd-bb3e-209ca6de3e4d is now 1 (50.141490108s elapsed)
    STEP: deleting the pod 11/29/22 12:35:36.468
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 29 12:35:36.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7837" for this suite. 11/29/22 12:35:36.612
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:35:36.617
Nov 29 12:35:36.617: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:35:36.618
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:36.637
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:36.64
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:35:36.715
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:35:37.346
STEP: Deploying the webhook pod 11/29/22 12:35:37.35
STEP: Wait for the deployment to be ready 11/29/22 12:35:37.361
Nov 29 12:35:37.367: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/29/22 12:35:39.377
STEP: Verifying the service has paired with the endpoint 11/29/22 12:35:39.393
Nov 29 12:35:40.393: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/29/22 12:35:40.396
STEP: create a configmap that should be updated by the webhook 11/29/22 12:35:40.408
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:35:40.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9423" for this suite. 11/29/22 12:35:40.635
STEP: Destroying namespace "webhook-9423-markers" for this suite. 11/29/22 12:35:40.639
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":216,"skipped":3895,"failed":0}
------------------------------
• [4.048 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:35:36.617
    Nov 29 12:35:36.617: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:35:36.618
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:36.637
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:36.64
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:35:36.715
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:35:37.346
    STEP: Deploying the webhook pod 11/29/22 12:35:37.35
    STEP: Wait for the deployment to be ready 11/29/22 12:35:37.361
    Nov 29 12:35:37.367: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/29/22 12:35:39.377
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:35:39.393
    Nov 29 12:35:40.393: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/29/22 12:35:40.396
    STEP: create a configmap that should be updated by the webhook 11/29/22 12:35:40.408
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:35:40.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9423" for this suite. 11/29/22 12:35:40.635
    STEP: Destroying namespace "webhook-9423-markers" for this suite. 11/29/22 12:35:40.639
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:35:40.669
Nov 29 12:35:40.669: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:35:40.67
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:40.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:40.68
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1154 11/29/22 12:35:40.682
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/29/22 12:35:40.747
STEP: creating service externalsvc in namespace services-1154 11/29/22 12:35:40.747
STEP: creating replication controller externalsvc in namespace services-1154 11/29/22 12:35:40.756
I1129 12:35:40.777791      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1154, replica count: 2
I1129 12:35:43.828860      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 11/29/22 12:35:43.831
Nov 29 12:35:43.840: INFO: Creating new exec pod
Nov 29 12:35:43.843: INFO: Waiting up to 5m0s for pod "execpod9rh8g" in namespace "services-1154" to be "running"
Nov 29 12:35:43.846: INFO: Pod "execpod9rh8g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.897883ms
Nov 29 12:35:45.850: INFO: Pod "execpod9rh8g": Phase="Running", Reason="", readiness=true. Elapsed: 2.006479402s
Nov 29 12:35:45.850: INFO: Pod "execpod9rh8g" satisfied condition "running"
Nov 29 12:35:45.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-1154 exec execpod9rh8g -- /bin/sh -x -c nslookup nodeport-service.services-1154.svc.cluster.local'
Nov 29 12:35:46.003: INFO: stderr: "+ nslookup nodeport-service.services-1154.svc.cluster.local\n"
Nov 29 12:35:46.003: INFO: stdout: ";; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\nServer:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nnodeport-service.services-1154.svc.cluster.local\tcanonical name = externalsvc.services-1154.svc.cluster.local.\nName:\texternalsvc.services-1154.svc.cluster.local\nAddress: 100.70.248.195\n;; Got recursion not available from 169.254.20.10, trying next server\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1154, will wait for the garbage collector to delete the pods 11/29/22 12:35:46.003
Nov 29 12:35:46.060: INFO: Deleting ReplicationController externalsvc took: 3.47821ms
Nov 29 12:35:46.161: INFO: Terminating ReplicationController externalsvc pods took: 100.711925ms
Nov 29 12:35:47.974: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:35:47.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1154" for this suite. 11/29/22 12:35:47.993
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":217,"skipped":3931,"failed":0}
------------------------------
• [SLOW TEST] [7.333 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:35:40.669
    Nov 29 12:35:40.669: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:35:40.67
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:40.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:40.68
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-1154 11/29/22 12:35:40.682
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/29/22 12:35:40.747
    STEP: creating service externalsvc in namespace services-1154 11/29/22 12:35:40.747
    STEP: creating replication controller externalsvc in namespace services-1154 11/29/22 12:35:40.756
    I1129 12:35:40.777791      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1154, replica count: 2
    I1129 12:35:43.828860      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 11/29/22 12:35:43.831
    Nov 29 12:35:43.840: INFO: Creating new exec pod
    Nov 29 12:35:43.843: INFO: Waiting up to 5m0s for pod "execpod9rh8g" in namespace "services-1154" to be "running"
    Nov 29 12:35:43.846: INFO: Pod "execpod9rh8g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.897883ms
    Nov 29 12:35:45.850: INFO: Pod "execpod9rh8g": Phase="Running", Reason="", readiness=true. Elapsed: 2.006479402s
    Nov 29 12:35:45.850: INFO: Pod "execpod9rh8g" satisfied condition "running"
    Nov 29 12:35:45.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-1154 exec execpod9rh8g -- /bin/sh -x -c nslookup nodeport-service.services-1154.svc.cluster.local'
    Nov 29 12:35:46.003: INFO: stderr: "+ nslookup nodeport-service.services-1154.svc.cluster.local\n"
    Nov 29 12:35:46.003: INFO: stdout: ";; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\n;; Got recursion not available from 169.254.20.10, trying next server\nServer:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nnodeport-service.services-1154.svc.cluster.local\tcanonical name = externalsvc.services-1154.svc.cluster.local.\nName:\texternalsvc.services-1154.svc.cluster.local\nAddress: 100.70.248.195\n;; Got recursion not available from 169.254.20.10, trying next server\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-1154, will wait for the garbage collector to delete the pods 11/29/22 12:35:46.003
    Nov 29 12:35:46.060: INFO: Deleting ReplicationController externalsvc took: 3.47821ms
    Nov 29 12:35:46.161: INFO: Terminating ReplicationController externalsvc pods took: 100.711925ms
    Nov 29 12:35:47.974: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:35:47.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1154" for this suite. 11/29/22 12:35:47.993
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:35:48.003
Nov 29 12:35:48.003: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:35:48.004
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:48.012
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:48.015
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 11/29/22 12:35:48.017
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:35:48.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4962" for this suite. 11/29/22 12:35:48.022
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":218,"skipped":3957,"failed":0}
------------------------------
• [0.027 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:35:48.003
    Nov 29 12:35:48.003: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:35:48.004
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:48.012
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:48.015
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 11/29/22 12:35:48.017
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:35:48.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4962" for this suite. 11/29/22 12:35:48.022
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:35:48.031
Nov 29 12:35:48.031: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename containers 11/29/22 12:35:48.032
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:48.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:48.041
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 11/29/22 12:35:48.043
Nov 29 12:35:48.046: INFO: Waiting up to 5m0s for pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68" in namespace "containers-2943" to be "Succeeded or Failed"
Nov 29 12:35:48.048: INFO: Pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68": Phase="Pending", Reason="", readiness=false. Elapsed: 1.791561ms
Nov 29 12:35:50.052: INFO: Pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005370298s
Nov 29 12:35:52.053: INFO: Pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006817911s
STEP: Saw pod success 11/29/22 12:35:52.053
Nov 29 12:35:52.053: INFO: Pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68" satisfied condition "Succeeded or Failed"
Nov 29 12:35:52.056: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:35:52.075
Nov 29 12:35:52.084: INFO: Waiting for pod client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68 to disappear
Nov 29 12:35:52.086: INFO: Pod client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 29 12:35:52.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2943" for this suite. 11/29/22 12:35:52.09
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":219,"skipped":3959,"failed":0}
------------------------------
• [4.062 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:35:48.031
    Nov 29 12:35:48.031: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename containers 11/29/22 12:35:48.032
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:48.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:48.041
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 11/29/22 12:35:48.043
    Nov 29 12:35:48.046: INFO: Waiting up to 5m0s for pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68" in namespace "containers-2943" to be "Succeeded or Failed"
    Nov 29 12:35:48.048: INFO: Pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68": Phase="Pending", Reason="", readiness=false. Elapsed: 1.791561ms
    Nov 29 12:35:50.052: INFO: Pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005370298s
    Nov 29 12:35:52.053: INFO: Pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006817911s
    STEP: Saw pod success 11/29/22 12:35:52.053
    Nov 29 12:35:52.053: INFO: Pod "client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68" satisfied condition "Succeeded or Failed"
    Nov 29 12:35:52.056: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:35:52.075
    Nov 29 12:35:52.084: INFO: Waiting for pod client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68 to disappear
    Nov 29 12:35:52.086: INFO: Pod client-containers-80776363-2ee3-473a-86b2-3d8ebf060f68 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 29 12:35:52.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-2943" for this suite. 11/29/22 12:35:52.09
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:35:52.094
Nov 29 12:35:52.094: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename init-container 11/29/22 12:35:52.095
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:52.107
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:52.11
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 11/29/22 12:35:52.112
Nov 29 12:35:52.112: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 29 12:35:56.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7139" for this suite. 11/29/22 12:35:56.855
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":220,"skipped":3975,"failed":0}
------------------------------
• [4.765 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:35:52.094
    Nov 29 12:35:52.094: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename init-container 11/29/22 12:35:52.095
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:52.107
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:52.11
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 11/29/22 12:35:52.112
    Nov 29 12:35:52.112: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 29 12:35:56.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-7139" for this suite. 11/29/22 12:35:56.855
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:35:56.86
Nov 29 12:35:56.860: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename conformance-tests 11/29/22 12:35:56.861
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:56.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:56.872
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 11/29/22 12:35:56.874
Nov 29 12:35:56.874: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Nov 29 12:35:56.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-2043" for this suite. 11/29/22 12:35:56.881
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":221,"skipped":3984,"failed":0}
------------------------------
• [0.025 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:35:56.86
    Nov 29 12:35:56.860: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename conformance-tests 11/29/22 12:35:56.861
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:56.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:56.872
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 11/29/22 12:35:56.874
    Nov 29 12:35:56.874: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Nov 29 12:35:56.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-2043" for this suite. 11/29/22 12:35:56.881
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:35:56.887
Nov 29 12:35:56.887: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename statefulset 11/29/22 12:35:56.888
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:56.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:56.901
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9890 11/29/22 12:35:56.903
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 11/29/22 12:35:56.906
STEP: Creating pod with conflicting port in namespace statefulset-9890 11/29/22 12:35:56.912
STEP: Waiting until pod test-pod will start running in namespace statefulset-9890 11/29/22 12:35:56.917
Nov 29 12:35:56.917: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-9890" to be "running"
Nov 29 12:35:56.919: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068947ms
Nov 29 12:35:58.923: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005320775s
Nov 29 12:35:58.923: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-9890 11/29/22 12:35:58.923
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9890 11/29/22 12:35:58.926
Nov 29 12:35:58.932: INFO: Observed stateful pod in namespace: statefulset-9890, name: ss-0, uid: 7a1c34e6-6b45-4fc0-a114-34000c5dfd06, status phase: Pending. Waiting for statefulset controller to delete.
Nov 29 12:35:58.940: INFO: Observed stateful pod in namespace: statefulset-9890, name: ss-0, uid: 7a1c34e6-6b45-4fc0-a114-34000c5dfd06, status phase: Failed. Waiting for statefulset controller to delete.
Nov 29 12:35:58.945: INFO: Observed stateful pod in namespace: statefulset-9890, name: ss-0, uid: 7a1c34e6-6b45-4fc0-a114-34000c5dfd06, status phase: Failed. Waiting for statefulset controller to delete.
Nov 29 12:35:58.949: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9890
STEP: Removing pod with conflicting port in namespace statefulset-9890 11/29/22 12:35:58.949
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9890 and will be in running state 11/29/22 12:35:58.959
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 29 12:36:00.971: INFO: Deleting all statefulset in ns statefulset-9890
Nov 29 12:36:00.973: INFO: Scaling statefulset ss to 0
Nov 29 12:36:11.001: INFO: Waiting for statefulset status.replicas updated to 0
Nov 29 12:36:11.004: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 29 12:36:11.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9890" for this suite. 11/29/22 12:36:11.018
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":222,"skipped":4002,"failed":0}
------------------------------
• [SLOW TEST] [14.135 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:35:56.887
    Nov 29 12:35:56.887: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename statefulset 11/29/22 12:35:56.888
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:35:56.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:35:56.901
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9890 11/29/22 12:35:56.903
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 11/29/22 12:35:56.906
    STEP: Creating pod with conflicting port in namespace statefulset-9890 11/29/22 12:35:56.912
    STEP: Waiting until pod test-pod will start running in namespace statefulset-9890 11/29/22 12:35:56.917
    Nov 29 12:35:56.917: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-9890" to be "running"
    Nov 29 12:35:56.919: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068947ms
    Nov 29 12:35:58.923: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005320775s
    Nov 29 12:35:58.923: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-9890 11/29/22 12:35:58.923
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9890 11/29/22 12:35:58.926
    Nov 29 12:35:58.932: INFO: Observed stateful pod in namespace: statefulset-9890, name: ss-0, uid: 7a1c34e6-6b45-4fc0-a114-34000c5dfd06, status phase: Pending. Waiting for statefulset controller to delete.
    Nov 29 12:35:58.940: INFO: Observed stateful pod in namespace: statefulset-9890, name: ss-0, uid: 7a1c34e6-6b45-4fc0-a114-34000c5dfd06, status phase: Failed. Waiting for statefulset controller to delete.
    Nov 29 12:35:58.945: INFO: Observed stateful pod in namespace: statefulset-9890, name: ss-0, uid: 7a1c34e6-6b45-4fc0-a114-34000c5dfd06, status phase: Failed. Waiting for statefulset controller to delete.
    Nov 29 12:35:58.949: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9890
    STEP: Removing pod with conflicting port in namespace statefulset-9890 11/29/22 12:35:58.949
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9890 and will be in running state 11/29/22 12:35:58.959
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 29 12:36:00.971: INFO: Deleting all statefulset in ns statefulset-9890
    Nov 29 12:36:00.973: INFO: Scaling statefulset ss to 0
    Nov 29 12:36:11.001: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 29 12:36:11.004: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 29 12:36:11.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9890" for this suite. 11/29/22 12:36:11.018
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:36:11.024
Nov 29 12:36:11.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 12:36:11.025
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:11.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:11.036
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 11/29/22 12:36:11.038
STEP: Ensuring ResourceQuota status is calculated 11/29/22 12:36:11.041
STEP: Creating a ResourceQuota with not best effort scope 11/29/22 12:36:13.044
STEP: Ensuring ResourceQuota status is calculated 11/29/22 12:36:13.049
STEP: Creating a best-effort pod 11/29/22 12:36:15.054
STEP: Ensuring resource quota with best effort scope captures the pod usage 11/29/22 12:36:15.061
STEP: Ensuring resource quota with not best effort ignored the pod usage 11/29/22 12:36:17.064
STEP: Deleting the pod 11/29/22 12:36:19.067
STEP: Ensuring resource quota status released the pod usage 11/29/22 12:36:19.073
STEP: Creating a not best-effort pod 11/29/22 12:36:21.077
STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/29/22 12:36:21.083
STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/29/22 12:36:23.087
STEP: Deleting the pod 11/29/22 12:36:25.089
STEP: Ensuring resource quota status released the pod usage 11/29/22 12:36:25.098
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 12:36:27.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2073" for this suite. 11/29/22 12:36:27.105
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":223,"skipped":4014,"failed":0}
------------------------------
• [SLOW TEST] [16.084 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:36:11.024
    Nov 29 12:36:11.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 12:36:11.025
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:11.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:11.036
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 11/29/22 12:36:11.038
    STEP: Ensuring ResourceQuota status is calculated 11/29/22 12:36:11.041
    STEP: Creating a ResourceQuota with not best effort scope 11/29/22 12:36:13.044
    STEP: Ensuring ResourceQuota status is calculated 11/29/22 12:36:13.049
    STEP: Creating a best-effort pod 11/29/22 12:36:15.054
    STEP: Ensuring resource quota with best effort scope captures the pod usage 11/29/22 12:36:15.061
    STEP: Ensuring resource quota with not best effort ignored the pod usage 11/29/22 12:36:17.064
    STEP: Deleting the pod 11/29/22 12:36:19.067
    STEP: Ensuring resource quota status released the pod usage 11/29/22 12:36:19.073
    STEP: Creating a not best-effort pod 11/29/22 12:36:21.077
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/29/22 12:36:21.083
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/29/22 12:36:23.087
    STEP: Deleting the pod 11/29/22 12:36:25.089
    STEP: Ensuring resource quota status released the pod usage 11/29/22 12:36:25.098
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 12:36:27.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2073" for this suite. 11/29/22 12:36:27.105
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:36:27.11
Nov 29 12:36:27.110: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename prestop 11/29/22 12:36:27.11
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:27.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:27.121
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-8201 11/29/22 12:36:27.123
STEP: Waiting for pods to come up. 11/29/22 12:36:27.131
Nov 29 12:36:27.131: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-8201" to be "running"
Nov 29 12:36:27.134: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612644ms
Nov 29 12:36:29.137: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.005217208s
Nov 29 12:36:29.137: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-8201 11/29/22 12:36:29.139
Nov 29 12:36:29.141: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-8201" to be "running"
Nov 29 12:36:29.144: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765302ms
Nov 29 12:36:31.148: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.007009521s
Nov 29 12:36:31.149: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 11/29/22 12:36:31.149
Nov 29 12:36:36.159: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 11/29/22 12:36:36.159
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Nov 29 12:36:36.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8201" for this suite. 11/29/22 12:36:36.173
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":224,"skipped":4018,"failed":0}
------------------------------
• [SLOW TEST] [9.070 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:36:27.11
    Nov 29 12:36:27.110: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename prestop 11/29/22 12:36:27.11
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:27.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:27.121
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-8201 11/29/22 12:36:27.123
    STEP: Waiting for pods to come up. 11/29/22 12:36:27.131
    Nov 29 12:36:27.131: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-8201" to be "running"
    Nov 29 12:36:27.134: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612644ms
    Nov 29 12:36:29.137: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.005217208s
    Nov 29 12:36:29.137: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-8201 11/29/22 12:36:29.139
    Nov 29 12:36:29.141: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-8201" to be "running"
    Nov 29 12:36:29.144: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765302ms
    Nov 29 12:36:31.148: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.007009521s
    Nov 29 12:36:31.149: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 11/29/22 12:36:31.149
    Nov 29 12:36:36.159: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 11/29/22 12:36:36.159
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Nov 29 12:36:36.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-8201" for this suite. 11/29/22 12:36:36.173
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:36:36.18
Nov 29 12:36:36.180: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 12:36:36.181
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:36.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:36.203
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-66b5962e-8cef-48f2-99ae-fda51f3081fe 11/29/22 12:36:36.206
STEP: Creating a pod to test consume configMaps 11/29/22 12:36:36.209
Nov 29 12:36:36.225: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0" in namespace "configmap-964" to be "Succeeded or Failed"
Nov 29 12:36:36.235: INFO: Pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.073063ms
Nov 29 12:36:38.238: INFO: Pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013636835s
Nov 29 12:36:40.239: INFO: Pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014178093s
STEP: Saw pod success 11/29/22 12:36:40.239
Nov 29 12:36:40.239: INFO: Pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0" satisfied condition "Succeeded or Failed"
Nov 29 12:36:40.241: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:36:40.256
Nov 29 12:36:40.262: INFO: Waiting for pod pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0 to disappear
Nov 29 12:36:40.267: INFO: Pod pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 12:36:40.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-964" for this suite. 11/29/22 12:36:40.27
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":225,"skipped":4031,"failed":0}
------------------------------
• [4.094 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:36:36.18
    Nov 29 12:36:36.180: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 12:36:36.181
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:36.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:36.203
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-66b5962e-8cef-48f2-99ae-fda51f3081fe 11/29/22 12:36:36.206
    STEP: Creating a pod to test consume configMaps 11/29/22 12:36:36.209
    Nov 29 12:36:36.225: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0" in namespace "configmap-964" to be "Succeeded or Failed"
    Nov 29 12:36:36.235: INFO: Pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.073063ms
    Nov 29 12:36:38.238: INFO: Pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013636835s
    Nov 29 12:36:40.239: INFO: Pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014178093s
    STEP: Saw pod success 11/29/22 12:36:40.239
    Nov 29 12:36:40.239: INFO: Pod "pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0" satisfied condition "Succeeded or Failed"
    Nov 29 12:36:40.241: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:36:40.256
    Nov 29 12:36:40.262: INFO: Waiting for pod pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0 to disappear
    Nov 29 12:36:40.267: INFO: Pod pod-configmaps-5f80fcf6-6729-4b93-a060-98b828d3e0b0 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 12:36:40.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-964" for this suite. 11/29/22 12:36:40.27
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:36:40.274
Nov 29 12:36:40.274: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 12:36:40.275
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:40.286
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:40.288
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 11/29/22 12:36:40.291
STEP: submitting the pod to kubernetes 11/29/22 12:36:40.291
Nov 29 12:36:40.295: INFO: Waiting up to 5m0s for pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8" in namespace "pods-9336" to be "running and ready"
Nov 29 12:36:40.299: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.526732ms
Nov 29 12:36:40.299: INFO: The phase of Pod pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:36:42.303: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.008397107s
Nov 29 12:36:42.303: INFO: The phase of Pod pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8 is Running (Ready = true)
Nov 29 12:36:42.303: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/29/22 12:36:42.306
STEP: updating the pod 11/29/22 12:36:42.31
Nov 29 12:36:42.821: INFO: Successfully updated pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8"
Nov 29 12:36:42.821: INFO: Waiting up to 5m0s for pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8" in namespace "pods-9336" to be "running"
Nov 29 12:36:42.830: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8": Phase="Running", Reason="", readiness=true. Elapsed: 9.085216ms
Nov 29 12:36:42.830: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 11/29/22 12:36:42.83
Nov 29 12:36:42.833: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 12:36:42.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9336" for this suite. 11/29/22 12:36:42.836
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":226,"skipped":4036,"failed":0}
------------------------------
• [2.566 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:36:40.274
    Nov 29 12:36:40.274: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 12:36:40.275
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:40.286
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:40.288
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 11/29/22 12:36:40.291
    STEP: submitting the pod to kubernetes 11/29/22 12:36:40.291
    Nov 29 12:36:40.295: INFO: Waiting up to 5m0s for pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8" in namespace "pods-9336" to be "running and ready"
    Nov 29 12:36:40.299: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.526732ms
    Nov 29 12:36:40.299: INFO: The phase of Pod pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:36:42.303: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.008397107s
    Nov 29 12:36:42.303: INFO: The phase of Pod pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8 is Running (Ready = true)
    Nov 29 12:36:42.303: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/29/22 12:36:42.306
    STEP: updating the pod 11/29/22 12:36:42.31
    Nov 29 12:36:42.821: INFO: Successfully updated pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8"
    Nov 29 12:36:42.821: INFO: Waiting up to 5m0s for pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8" in namespace "pods-9336" to be "running"
    Nov 29 12:36:42.830: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8": Phase="Running", Reason="", readiness=true. Elapsed: 9.085216ms
    Nov 29 12:36:42.830: INFO: Pod "pod-update-cab1b9f2-53a2-435c-8167-fd89516635e8" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 11/29/22 12:36:42.83
    Nov 29 12:36:42.833: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 12:36:42.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9336" for this suite. 11/29/22 12:36:42.836
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:36:42.841
Nov 29 12:36:42.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 12:36:42.842
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:42.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:42.854
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/29/22 12:36:42.857
Nov 29 12:36:42.862: INFO: Waiting up to 5m0s for pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f" in namespace "emptydir-8141" to be "Succeeded or Failed"
Nov 29 12:36:42.866: INFO: Pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.369166ms
Nov 29 12:36:44.871: INFO: Pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008805202s
Nov 29 12:36:46.869: INFO: Pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007438907s
STEP: Saw pod success 11/29/22 12:36:46.87
Nov 29 12:36:46.870: INFO: Pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f" satisfied condition "Succeeded or Failed"
Nov 29 12:36:46.871: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-67faad2a-e950-421f-abd3-7e35882bd90f container test-container: <nil>
STEP: delete the pod 11/29/22 12:36:46.875
Nov 29 12:36:46.881: INFO: Waiting for pod pod-67faad2a-e950-421f-abd3-7e35882bd90f to disappear
Nov 29 12:36:46.883: INFO: Pod pod-67faad2a-e950-421f-abd3-7e35882bd90f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 12:36:46.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8141" for this suite. 11/29/22 12:36:46.886
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":227,"skipped":4050,"failed":0}
------------------------------
• [4.047 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:36:42.841
    Nov 29 12:36:42.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 12:36:42.842
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:42.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:42.854
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/29/22 12:36:42.857
    Nov 29 12:36:42.862: INFO: Waiting up to 5m0s for pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f" in namespace "emptydir-8141" to be "Succeeded or Failed"
    Nov 29 12:36:42.866: INFO: Pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.369166ms
    Nov 29 12:36:44.871: INFO: Pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008805202s
    Nov 29 12:36:46.869: INFO: Pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007438907s
    STEP: Saw pod success 11/29/22 12:36:46.87
    Nov 29 12:36:46.870: INFO: Pod "pod-67faad2a-e950-421f-abd3-7e35882bd90f" satisfied condition "Succeeded or Failed"
    Nov 29 12:36:46.871: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-67faad2a-e950-421f-abd3-7e35882bd90f container test-container: <nil>
    STEP: delete the pod 11/29/22 12:36:46.875
    Nov 29 12:36:46.881: INFO: Waiting for pod pod-67faad2a-e950-421f-abd3-7e35882bd90f to disappear
    Nov 29 12:36:46.883: INFO: Pod pod-67faad2a-e950-421f-abd3-7e35882bd90f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 12:36:46.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8141" for this suite. 11/29/22 12:36:46.886
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:36:46.89
Nov 29 12:36:46.890: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename security-context-test 11/29/22 12:36:46.891
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:46.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:46.899
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Nov 29 12:36:46.905: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b" in namespace "security-context-test-6171" to be "Succeeded or Failed"
Nov 29 12:36:46.907: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.211913ms
Nov 29 12:36:48.910: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005015206s
Nov 29 12:36:50.911: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005701442s
Nov 29 12:36:52.910: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.005298563s
Nov 29 12:36:54.910: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.004934481s
Nov 29 12:36:54.910: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 29 12:36:54.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6171" for this suite. 11/29/22 12:36:54.917
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":228,"skipped":4051,"failed":0}
------------------------------
• [SLOW TEST] [8.030 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:36:46.89
    Nov 29 12:36:46.890: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename security-context-test 11/29/22 12:36:46.891
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:46.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:46.899
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Nov 29 12:36:46.905: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b" in namespace "security-context-test-6171" to be "Succeeded or Failed"
    Nov 29 12:36:46.907: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.211913ms
    Nov 29 12:36:48.910: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005015206s
    Nov 29 12:36:50.911: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005701442s
    Nov 29 12:36:52.910: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.005298563s
    Nov 29 12:36:54.910: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.004934481s
    Nov 29 12:36:54.910: INFO: Pod "alpine-nnp-false-3aedaea9-874d-4e3a-8d1a-e78b9628b43b" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 29 12:36:54.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6171" for this suite. 11/29/22 12:36:54.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:36:54.921
Nov 29 12:36:54.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:36:54.921
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:54.933
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:54.936
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-6463 11/29/22 12:36:54.938
STEP: creating service affinity-clusterip in namespace services-6463 11/29/22 12:36:54.938
STEP: creating replication controller affinity-clusterip in namespace services-6463 11/29/22 12:36:54.945
I1129 12:36:54.951577      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-6463, replica count: 3
I1129 12:36:58.002141      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 12:36:58.006: INFO: Creating new exec pod
Nov 29 12:36:58.010: INFO: Waiting up to 5m0s for pod "execpod-affinityf6kpn" in namespace "services-6463" to be "running"
Nov 29 12:36:58.012: INFO: Pod "execpod-affinityf6kpn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.416439ms
Nov 29 12:37:00.016: INFO: Pod "execpod-affinityf6kpn": Phase="Running", Reason="", readiness=true. Elapsed: 2.005903194s
Nov 29 12:37:00.016: INFO: Pod "execpod-affinityf6kpn" satisfied condition "running"
Nov 29 12:37:01.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 29 12:37:01.151: INFO: rc: 1
Nov 29 12:37:01.151: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-clusterip 80
nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:37:02.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 29 12:37:02.272: INFO: rc: 1
Nov 29 12:37:02.272: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-clusterip 80
nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:37:03.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 29 12:37:03.286: INFO: rc: 1
Nov 29 12:37:03.286: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
Command stdout:

stderr:
+ nc -v -t -w 2 affinity-clusterip 80
+ echo hostName
nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:37:04.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 29 12:37:04.270: INFO: rc: 1
Nov 29 12:37:04.270: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-clusterip 80
nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:37:05.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 29 12:37:05.272: INFO: rc: 1
Nov 29 12:37:05.272: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-clusterip 80
nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:37:06.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 29 12:37:06.291: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Nov 29 12:37:06.291: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:37:06.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.44.155 80'
Nov 29 12:37:06.431: INFO: stderr: "+ nc -v -t -w 2 100.69.44.155 80\n+ echo hostName\nConnection to 100.69.44.155 80 port [tcp/http] succeeded!\n"
Nov 29 12:37:06.431: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:37:06.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.69.44.155:80/ ; done'
Nov 29 12:37:06.635: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n"
Nov 29 12:37:06.635: INFO: stdout: "\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp"
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
Nov 29 12:37:06.635: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-6463, will wait for the garbage collector to delete the pods 11/29/22 12:37:06.65
Nov 29 12:37:06.706: INFO: Deleting ReplicationController affinity-clusterip took: 3.27075ms
Nov 29 12:37:06.807: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.894155ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:37:09.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6463" for this suite. 11/29/22 12:37:09.221
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":229,"skipped":4063,"failed":0}
------------------------------
• [SLOW TEST] [14.304 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:36:54.921
    Nov 29 12:36:54.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:36:54.921
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:36:54.933
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:36:54.936
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-6463 11/29/22 12:36:54.938
    STEP: creating service affinity-clusterip in namespace services-6463 11/29/22 12:36:54.938
    STEP: creating replication controller affinity-clusterip in namespace services-6463 11/29/22 12:36:54.945
    I1129 12:36:54.951577      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-6463, replica count: 3
    I1129 12:36:58.002141      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 12:36:58.006: INFO: Creating new exec pod
    Nov 29 12:36:58.010: INFO: Waiting up to 5m0s for pod "execpod-affinityf6kpn" in namespace "services-6463" to be "running"
    Nov 29 12:36:58.012: INFO: Pod "execpod-affinityf6kpn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.416439ms
    Nov 29 12:37:00.016: INFO: Pod "execpod-affinityf6kpn": Phase="Running", Reason="", readiness=true. Elapsed: 2.005903194s
    Nov 29 12:37:00.016: INFO: Pod "execpod-affinityf6kpn" satisfied condition "running"
    Nov 29 12:37:01.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 29 12:37:01.151: INFO: rc: 1
    Nov 29 12:37:01.151: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-clusterip 80
    nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:37:02.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 29 12:37:02.272: INFO: rc: 1
    Nov 29 12:37:02.272: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-clusterip 80
    nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:37:03.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 29 12:37:03.286: INFO: rc: 1
    Nov 29 12:37:03.286: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
    Command stdout:

    stderr:
    + nc -v -t -w 2 affinity-clusterip 80
    + echo hostName
    nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:37:04.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 29 12:37:04.270: INFO: rc: 1
    Nov 29 12:37:04.270: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-clusterip 80
    nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:37:05.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 29 12:37:05.272: INFO: rc: 1
    Nov 29 12:37:05.272: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-clusterip 80
    nc: connect to affinity-clusterip port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:37:06.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 29 12:37:06.291: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Nov 29 12:37:06.291: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:37:06.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.44.155 80'
    Nov 29 12:37:06.431: INFO: stderr: "+ nc -v -t -w 2 100.69.44.155 80\n+ echo hostName\nConnection to 100.69.44.155 80 port [tcp/http] succeeded!\n"
    Nov 29 12:37:06.431: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:37:06.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-6463 exec execpod-affinityf6kpn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.69.44.155:80/ ; done'
    Nov 29 12:37:06.635: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.44.155:80/\n"
    Nov 29 12:37:06.635: INFO: stdout: "\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp\naffinity-clusterip-h24pp"
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Received response from host: affinity-clusterip-h24pp
    Nov 29 12:37:06.635: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-6463, will wait for the garbage collector to delete the pods 11/29/22 12:37:06.65
    Nov 29 12:37:06.706: INFO: Deleting ReplicationController affinity-clusterip took: 3.27075ms
    Nov 29 12:37:06.807: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.894155ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:37:09.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6463" for this suite. 11/29/22 12:37:09.221
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:37:09.225
Nov 29 12:37:09.225: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename controllerrevisions 11/29/22 12:37:09.226
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:09.234
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:37:09.235
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-65knm-daemon-set" 11/29/22 12:37:09.252
STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:37:09.256
Nov 29 12:37:09.260: INFO: Number of nodes with available pods controlled by daemonset e2e-65knm-daemon-set: 0
Nov 29 12:37:09.260: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:37:10.268: INFO: Number of nodes with available pods controlled by daemonset e2e-65knm-daemon-set: 0
Nov 29 12:37:10.268: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:37:11.269: INFO: Number of nodes with available pods controlled by daemonset e2e-65knm-daemon-set: 4
Nov 29 12:37:11.269: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset e2e-65knm-daemon-set
STEP: Confirm DaemonSet "e2e-65knm-daemon-set" successfully created with "daemonset-name=e2e-65knm-daemon-set" label 11/29/22 12:37:11.271
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-65knm-daemon-set" 11/29/22 12:37:11.275
Nov 29 12:37:11.278: INFO: Located ControllerRevision: "e2e-65knm-daemon-set-7cb588f848"
STEP: Patching ControllerRevision "e2e-65knm-daemon-set-7cb588f848" 11/29/22 12:37:11.281
Nov 29 12:37:11.286: INFO: e2e-65knm-daemon-set-7cb588f848 has been patched
STEP: Create a new ControllerRevision 11/29/22 12:37:11.286
Nov 29 12:37:11.291: INFO: Created ControllerRevision: e2e-65knm-daemon-set-66b8849b94
STEP: Confirm that there are two ControllerRevisions 11/29/22 12:37:11.291
Nov 29 12:37:11.291: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 29 12:37:11.294: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-65knm-daemon-set-7cb588f848" 11/29/22 12:37:11.294
STEP: Confirm that there is only one ControllerRevision 11/29/22 12:37:11.297
Nov 29 12:37:11.297: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 29 12:37:11.303: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-65knm-daemon-set-66b8849b94" 11/29/22 12:37:11.305
Nov 29 12:37:11.310: INFO: e2e-65knm-daemon-set-66b8849b94 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 11/29/22 12:37:11.31
W1129 12:37:11.324601      22 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 11/29/22 12:37:11.324
Nov 29 12:37:11.324: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 29 12:37:12.327: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 29 12:37:12.330: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-65knm-daemon-set-66b8849b94=updated" 11/29/22 12:37:12.33
STEP: Confirm that there is only one ControllerRevision 11/29/22 12:37:12.335
Nov 29 12:37:12.335: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 29 12:37:12.339: INFO: Found 1 ControllerRevisions
Nov 29 12:37:12.341: INFO: ControllerRevision "e2e-65knm-daemon-set-5cfb54fd55" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-65knm-daemon-set" 11/29/22 12:37:12.342
STEP: deleting DaemonSet.extensions e2e-65knm-daemon-set in namespace controllerrevisions-5733, will wait for the garbage collector to delete the pods 11/29/22 12:37:12.342
Nov 29 12:37:12.398: INFO: Deleting DaemonSet.extensions e2e-65knm-daemon-set took: 3.781252ms
Nov 29 12:37:12.499: INFO: Terminating DaemonSet.extensions e2e-65knm-daemon-set pods took: 101.099492ms
Nov 29 12:37:14.202: INFO: Number of nodes with available pods controlled by daemonset e2e-65knm-daemon-set: 0
Nov 29 12:37:14.202: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-65knm-daemon-set
Nov 29 12:37:14.204: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29560"},"items":null}

Nov 29 12:37:14.205: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29560"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:37:14.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-5733" for this suite. 11/29/22 12:37:14.218
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":230,"skipped":4084,"failed":0}
------------------------------
• [4.995 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:37:09.225
    Nov 29 12:37:09.225: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename controllerrevisions 11/29/22 12:37:09.226
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:09.234
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:37:09.235
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-65knm-daemon-set" 11/29/22 12:37:09.252
    STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:37:09.256
    Nov 29 12:37:09.260: INFO: Number of nodes with available pods controlled by daemonset e2e-65knm-daemon-set: 0
    Nov 29 12:37:09.260: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:37:10.268: INFO: Number of nodes with available pods controlled by daemonset e2e-65knm-daemon-set: 0
    Nov 29 12:37:10.268: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:37:11.269: INFO: Number of nodes with available pods controlled by daemonset e2e-65knm-daemon-set: 4
    Nov 29 12:37:11.269: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset e2e-65knm-daemon-set
    STEP: Confirm DaemonSet "e2e-65knm-daemon-set" successfully created with "daemonset-name=e2e-65knm-daemon-set" label 11/29/22 12:37:11.271
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-65knm-daemon-set" 11/29/22 12:37:11.275
    Nov 29 12:37:11.278: INFO: Located ControllerRevision: "e2e-65knm-daemon-set-7cb588f848"
    STEP: Patching ControllerRevision "e2e-65knm-daemon-set-7cb588f848" 11/29/22 12:37:11.281
    Nov 29 12:37:11.286: INFO: e2e-65knm-daemon-set-7cb588f848 has been patched
    STEP: Create a new ControllerRevision 11/29/22 12:37:11.286
    Nov 29 12:37:11.291: INFO: Created ControllerRevision: e2e-65knm-daemon-set-66b8849b94
    STEP: Confirm that there are two ControllerRevisions 11/29/22 12:37:11.291
    Nov 29 12:37:11.291: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 29 12:37:11.294: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-65knm-daemon-set-7cb588f848" 11/29/22 12:37:11.294
    STEP: Confirm that there is only one ControllerRevision 11/29/22 12:37:11.297
    Nov 29 12:37:11.297: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 29 12:37:11.303: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-65knm-daemon-set-66b8849b94" 11/29/22 12:37:11.305
    Nov 29 12:37:11.310: INFO: e2e-65knm-daemon-set-66b8849b94 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 11/29/22 12:37:11.31
    W1129 12:37:11.324601      22 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 11/29/22 12:37:11.324
    Nov 29 12:37:11.324: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 29 12:37:12.327: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 29 12:37:12.330: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-65knm-daemon-set-66b8849b94=updated" 11/29/22 12:37:12.33
    STEP: Confirm that there is only one ControllerRevision 11/29/22 12:37:12.335
    Nov 29 12:37:12.335: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 29 12:37:12.339: INFO: Found 1 ControllerRevisions
    Nov 29 12:37:12.341: INFO: ControllerRevision "e2e-65knm-daemon-set-5cfb54fd55" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-65knm-daemon-set" 11/29/22 12:37:12.342
    STEP: deleting DaemonSet.extensions e2e-65knm-daemon-set in namespace controllerrevisions-5733, will wait for the garbage collector to delete the pods 11/29/22 12:37:12.342
    Nov 29 12:37:12.398: INFO: Deleting DaemonSet.extensions e2e-65knm-daemon-set took: 3.781252ms
    Nov 29 12:37:12.499: INFO: Terminating DaemonSet.extensions e2e-65knm-daemon-set pods took: 101.099492ms
    Nov 29 12:37:14.202: INFO: Number of nodes with available pods controlled by daemonset e2e-65knm-daemon-set: 0
    Nov 29 12:37:14.202: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-65knm-daemon-set
    Nov 29 12:37:14.204: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29560"},"items":null}

    Nov 29 12:37:14.205: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29560"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:37:14.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-5733" for this suite. 11/29/22 12:37:14.218
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:37:14.224
Nov 29 12:37:14.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 12:37:14.225
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:14.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:37:14.24
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 11/29/22 12:37:14.242
STEP: Ensuring ResourceQuota status is calculated 11/29/22 12:37:14.306
STEP: Creating a ResourceQuota with not terminating scope 11/29/22 12:37:16.31
STEP: Ensuring ResourceQuota status is calculated 11/29/22 12:37:16.313
STEP: Creating a long running pod 11/29/22 12:37:18.316
STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/29/22 12:37:18.324
STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/29/22 12:37:20.328
STEP: Deleting the pod 11/29/22 12:37:22.332
STEP: Ensuring resource quota status released the pod usage 11/29/22 12:37:22.338
STEP: Creating a terminating pod 11/29/22 12:37:24.342
STEP: Ensuring resource quota with terminating scope captures the pod usage 11/29/22 12:37:24.349
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/29/22 12:37:26.352
STEP: Deleting the pod 11/29/22 12:37:28.356
STEP: Ensuring resource quota status released the pod usage 11/29/22 12:37:28.362
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 12:37:30.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-995" for this suite. 11/29/22 12:37:30.373
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":231,"skipped":4096,"failed":0}
------------------------------
• [SLOW TEST] [16.154 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:37:14.224
    Nov 29 12:37:14.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 12:37:14.225
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:14.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:37:14.24
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 11/29/22 12:37:14.242
    STEP: Ensuring ResourceQuota status is calculated 11/29/22 12:37:14.306
    STEP: Creating a ResourceQuota with not terminating scope 11/29/22 12:37:16.31
    STEP: Ensuring ResourceQuota status is calculated 11/29/22 12:37:16.313
    STEP: Creating a long running pod 11/29/22 12:37:18.316
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/29/22 12:37:18.324
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/29/22 12:37:20.328
    STEP: Deleting the pod 11/29/22 12:37:22.332
    STEP: Ensuring resource quota status released the pod usage 11/29/22 12:37:22.338
    STEP: Creating a terminating pod 11/29/22 12:37:24.342
    STEP: Ensuring resource quota with terminating scope captures the pod usage 11/29/22 12:37:24.349
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/29/22 12:37:26.352
    STEP: Deleting the pod 11/29/22 12:37:28.356
    STEP: Ensuring resource quota status released the pod usage 11/29/22 12:37:28.362
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 12:37:30.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-995" for this suite. 11/29/22 12:37:30.373
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:37:30.378
Nov 29 12:37:30.379: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename namespaces 11/29/22 12:37:30.38
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:30.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:37:30.392
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 11/29/22 12:37:30.395
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:30.404
STEP: Creating a pod in the namespace 11/29/22 12:37:30.406
STEP: Waiting for the pod to have running status 11/29/22 12:37:30.414
Nov 29 12:37:30.414: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7991" to be "running"
Nov 29 12:37:30.416: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.34921ms
Nov 29 12:37:32.419: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005071387s
Nov 29 12:37:32.419: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 11/29/22 12:37:32.419
STEP: Waiting for the namespace to be removed. 11/29/22 12:37:32.422
STEP: Recreating the namespace 11/29/22 12:37:43.426
STEP: Verifying there are no pods in the namespace 11/29/22 12:37:43.434
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:37:43.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4466" for this suite. 11/29/22 12:37:43.44
STEP: Destroying namespace "nsdeletetest-7991" for this suite. 11/29/22 12:37:43.443
Nov 29 12:37:43.444: INFO: Namespace nsdeletetest-7991 was already deleted
STEP: Destroying namespace "nsdeletetest-1874" for this suite. 11/29/22 12:37:43.445
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":232,"skipped":4098,"failed":0}
------------------------------
• [SLOW TEST] [13.069 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:37:30.378
    Nov 29 12:37:30.379: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename namespaces 11/29/22 12:37:30.38
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:30.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:37:30.392
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 11/29/22 12:37:30.395
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:30.404
    STEP: Creating a pod in the namespace 11/29/22 12:37:30.406
    STEP: Waiting for the pod to have running status 11/29/22 12:37:30.414
    Nov 29 12:37:30.414: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7991" to be "running"
    Nov 29 12:37:30.416: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.34921ms
    Nov 29 12:37:32.419: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005071387s
    Nov 29 12:37:32.419: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 11/29/22 12:37:32.419
    STEP: Waiting for the namespace to be removed. 11/29/22 12:37:32.422
    STEP: Recreating the namespace 11/29/22 12:37:43.426
    STEP: Verifying there are no pods in the namespace 11/29/22 12:37:43.434
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:37:43.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4466" for this suite. 11/29/22 12:37:43.44
    STEP: Destroying namespace "nsdeletetest-7991" for this suite. 11/29/22 12:37:43.443
    Nov 29 12:37:43.444: INFO: Namespace nsdeletetest-7991 was already deleted
    STEP: Destroying namespace "nsdeletetest-1874" for this suite. 11/29/22 12:37:43.445
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:37:43.448
Nov 29 12:37:43.448: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 12:37:43.449
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:43.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:37:43.468
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 11/29/22 12:38:00.474
STEP: Creating a ResourceQuota 11/29/22 12:38:05.477
STEP: Ensuring resource quota status is calculated 11/29/22 12:38:05.48
STEP: Creating a ConfigMap 11/29/22 12:38:07.483
STEP: Ensuring resource quota status captures configMap creation 11/29/22 12:38:07.489
STEP: Deleting a ConfigMap 11/29/22 12:38:09.493
STEP: Ensuring resource quota status released usage 11/29/22 12:38:09.496
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 12:38:11.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1077" for this suite. 11/29/22 12:38:11.504
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":233,"skipped":4100,"failed":0}
------------------------------
• [SLOW TEST] [28.060 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:37:43.448
    Nov 29 12:37:43.448: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 12:37:43.449
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:37:43.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:37:43.468
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 11/29/22 12:38:00.474
    STEP: Creating a ResourceQuota 11/29/22 12:38:05.477
    STEP: Ensuring resource quota status is calculated 11/29/22 12:38:05.48
    STEP: Creating a ConfigMap 11/29/22 12:38:07.483
    STEP: Ensuring resource quota status captures configMap creation 11/29/22 12:38:07.489
    STEP: Deleting a ConfigMap 11/29/22 12:38:09.493
    STEP: Ensuring resource quota status released usage 11/29/22 12:38:09.496
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 12:38:11.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1077" for this suite. 11/29/22 12:38:11.504
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:38:11.508
Nov 29 12:38:11.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:38:11.509
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:11.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:11.52
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 11/29/22 12:38:11.522
Nov 29 12:38:11.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov 29 12:38:11.589: INFO: stderr: ""
Nov 29 12:38:11.589: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 11/29/22 12:38:11.589
Nov 29 12:38:11.589: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov 29 12:38:11.589: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6509" to be "running and ready, or succeeded"
Nov 29 12:38:11.591: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.999456ms
Nov 29 12:38:11.591: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'dvi-7336-1669718118-vsp1-group1-2' to be 'Running' but was 'Pending'
Nov 29 12:38:13.595: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.005206461s
Nov 29 12:38:13.595: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov 29 12:38:13.595: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 11/29/22 12:38:13.595
Nov 29 12:38:13.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator'
Nov 29 12:38:13.665: INFO: stderr: ""
Nov 29 12:38:13.665: INFO: stdout: "I1129 12:38:12.300929       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/r2n 357\nI1129 12:38:12.501108       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/gvkz 403\nI1129 12:38:12.701828       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/4kl 536\nI1129 12:38:12.901136       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/22k 303\nI1129 12:38:13.101423       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/6tmc 451\nI1129 12:38:13.301655       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/6jpr 367\nI1129 12:38:13.501980       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/qxt 410\n"
STEP: limiting log lines 11/29/22 12:38:13.665
Nov 29 12:38:13.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --tail=1'
Nov 29 12:38:13.740: INFO: stderr: ""
Nov 29 12:38:13.740: INFO: stdout: "I1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\n"
Nov 29 12:38:13.740: INFO: got output "I1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\n"
STEP: limiting log bytes 11/29/22 12:38:13.74
Nov 29 12:38:13.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --limit-bytes=1'
Nov 29 12:38:13.806: INFO: stderr: ""
Nov 29 12:38:13.807: INFO: stdout: "I"
Nov 29 12:38:13.807: INFO: got output "I"
STEP: exposing timestamps 11/29/22 12:38:13.807
Nov 29 12:38:13.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --tail=1 --timestamps'
Nov 29 12:38:13.883: INFO: stderr: ""
Nov 29 12:38:13.883: INFO: stdout: "2022-11-29T12:38:13.701559172Z I1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\n"
Nov 29 12:38:13.883: INFO: got output "2022-11-29T12:38:13.701559172Z I1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\n"
STEP: restricting to a time range 11/29/22 12:38:13.883
Nov 29 12:38:16.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --since=1s'
Nov 29 12:38:16.457: INFO: stderr: ""
Nov 29 12:38:16.457: INFO: stdout: "I1129 12:38:15.501484       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/xcj 467\nI1129 12:38:15.701841       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/w8g 596\nI1129 12:38:15.901131       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/mvlv 516\nI1129 12:38:16.101551       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/n77 226\nI1129 12:38:16.301985       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/vhj 365\n"
Nov 29 12:38:16.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --since=24h'
Nov 29 12:38:16.527: INFO: stderr: ""
Nov 29 12:38:16.528: INFO: stdout: "I1129 12:38:12.300929       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/r2n 357\nI1129 12:38:12.501108       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/gvkz 403\nI1129 12:38:12.701828       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/4kl 536\nI1129 12:38:12.901136       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/22k 303\nI1129 12:38:13.101423       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/6tmc 451\nI1129 12:38:13.301655       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/6jpr 367\nI1129 12:38:13.501980       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/qxt 410\nI1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\nI1129 12:38:13.901626       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/sn29 426\nI1129 12:38:14.102044       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/t6qp 423\nI1129 12:38:14.301529       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/h4bb 478\nI1129 12:38:14.501916       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/xhb 276\nI1129 12:38:14.701224       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/cxn 358\nI1129 12:38:14.901570       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/9hvf 511\nI1129 12:38:15.101801       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/xmq 203\nI1129 12:38:15.301042       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/7mgk 502\nI1129 12:38:15.501484       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/xcj 467\nI1129 12:38:15.701841       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/w8g 596\nI1129 12:38:15.901131       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/mvlv 516\nI1129 12:38:16.101551       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/n77 226\nI1129 12:38:16.301985       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/vhj 365\nI1129 12:38:16.501356       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/zcsg 461\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Nov 29 12:38:16.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 delete pod logs-generator'
Nov 29 12:38:17.184: INFO: stderr: ""
Nov 29 12:38:17.184: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:38:17.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6509" for this suite. 11/29/22 12:38:17.187
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":234,"skipped":4107,"failed":0}
------------------------------
• [SLOW TEST] [5.682 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:38:11.508
    Nov 29 12:38:11.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:38:11.509
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:11.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:11.52
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 11/29/22 12:38:11.522
    Nov 29 12:38:11.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Nov 29 12:38:11.589: INFO: stderr: ""
    Nov 29 12:38:11.589: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 11/29/22 12:38:11.589
    Nov 29 12:38:11.589: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Nov 29 12:38:11.589: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6509" to be "running and ready, or succeeded"
    Nov 29 12:38:11.591: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.999456ms
    Nov 29 12:38:11.591: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'dvi-7336-1669718118-vsp1-group1-2' to be 'Running' but was 'Pending'
    Nov 29 12:38:13.595: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.005206461s
    Nov 29 12:38:13.595: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Nov 29 12:38:13.595: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 11/29/22 12:38:13.595
    Nov 29 12:38:13.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator'
    Nov 29 12:38:13.665: INFO: stderr: ""
    Nov 29 12:38:13.665: INFO: stdout: "I1129 12:38:12.300929       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/r2n 357\nI1129 12:38:12.501108       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/gvkz 403\nI1129 12:38:12.701828       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/4kl 536\nI1129 12:38:12.901136       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/22k 303\nI1129 12:38:13.101423       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/6tmc 451\nI1129 12:38:13.301655       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/6jpr 367\nI1129 12:38:13.501980       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/qxt 410\n"
    STEP: limiting log lines 11/29/22 12:38:13.665
    Nov 29 12:38:13.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --tail=1'
    Nov 29 12:38:13.740: INFO: stderr: ""
    Nov 29 12:38:13.740: INFO: stdout: "I1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\n"
    Nov 29 12:38:13.740: INFO: got output "I1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\n"
    STEP: limiting log bytes 11/29/22 12:38:13.74
    Nov 29 12:38:13.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --limit-bytes=1'
    Nov 29 12:38:13.806: INFO: stderr: ""
    Nov 29 12:38:13.807: INFO: stdout: "I"
    Nov 29 12:38:13.807: INFO: got output "I"
    STEP: exposing timestamps 11/29/22 12:38:13.807
    Nov 29 12:38:13.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --tail=1 --timestamps'
    Nov 29 12:38:13.883: INFO: stderr: ""
    Nov 29 12:38:13.883: INFO: stdout: "2022-11-29T12:38:13.701559172Z I1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\n"
    Nov 29 12:38:13.883: INFO: got output "2022-11-29T12:38:13.701559172Z I1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\n"
    STEP: restricting to a time range 11/29/22 12:38:13.883
    Nov 29 12:38:16.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --since=1s'
    Nov 29 12:38:16.457: INFO: stderr: ""
    Nov 29 12:38:16.457: INFO: stdout: "I1129 12:38:15.501484       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/xcj 467\nI1129 12:38:15.701841       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/w8g 596\nI1129 12:38:15.901131       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/mvlv 516\nI1129 12:38:16.101551       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/n77 226\nI1129 12:38:16.301985       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/vhj 365\n"
    Nov 29 12:38:16.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 logs logs-generator logs-generator --since=24h'
    Nov 29 12:38:16.527: INFO: stderr: ""
    Nov 29 12:38:16.528: INFO: stdout: "I1129 12:38:12.300929       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/r2n 357\nI1129 12:38:12.501108       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/gvkz 403\nI1129 12:38:12.701828       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/4kl 536\nI1129 12:38:12.901136       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/22k 303\nI1129 12:38:13.101423       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/6tmc 451\nI1129 12:38:13.301655       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/6jpr 367\nI1129 12:38:13.501980       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/qxt 410\nI1129 12:38:13.701339       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/sg7 507\nI1129 12:38:13.901626       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/sn29 426\nI1129 12:38:14.102044       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/t6qp 423\nI1129 12:38:14.301529       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/h4bb 478\nI1129 12:38:14.501916       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/xhb 276\nI1129 12:38:14.701224       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/cxn 358\nI1129 12:38:14.901570       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/9hvf 511\nI1129 12:38:15.101801       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/xmq 203\nI1129 12:38:15.301042       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/7mgk 502\nI1129 12:38:15.501484       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/xcj 467\nI1129 12:38:15.701841       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/w8g 596\nI1129 12:38:15.901131       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/mvlv 516\nI1129 12:38:16.101551       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/n77 226\nI1129 12:38:16.301985       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/vhj 365\nI1129 12:38:16.501356       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/zcsg 461\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Nov 29 12:38:16.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-6509 delete pod logs-generator'
    Nov 29 12:38:17.184: INFO: stderr: ""
    Nov 29 12:38:17.184: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:38:17.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6509" for this suite. 11/29/22 12:38:17.187
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:38:17.191
Nov 29 12:38:17.191: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename ingressclass 11/29/22 12:38:17.191
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:17.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:17.209
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 11/29/22 12:38:17.212
STEP: getting /apis/networking.k8s.io 11/29/22 12:38:17.213
STEP: getting /apis/networking.k8s.iov1 11/29/22 12:38:17.214
STEP: creating 11/29/22 12:38:17.215
STEP: getting 11/29/22 12:38:17.224
STEP: listing 11/29/22 12:38:17.225
STEP: watching 11/29/22 12:38:17.227
Nov 29 12:38:17.228: INFO: starting watch
STEP: patching 11/29/22 12:38:17.229
STEP: updating 11/29/22 12:38:17.232
Nov 29 12:38:17.236: INFO: waiting for watch events with expected annotations
Nov 29 12:38:17.236: INFO: saw patched and updated annotations
STEP: deleting 11/29/22 12:38:17.236
STEP: deleting a collection 11/29/22 12:38:17.242
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Nov 29 12:38:17.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-1372" for this suite. 11/29/22 12:38:17.251
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":235,"skipped":4113,"failed":0}
------------------------------
• [0.062 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:38:17.191
    Nov 29 12:38:17.191: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename ingressclass 11/29/22 12:38:17.191
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:17.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:17.209
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 11/29/22 12:38:17.212
    STEP: getting /apis/networking.k8s.io 11/29/22 12:38:17.213
    STEP: getting /apis/networking.k8s.iov1 11/29/22 12:38:17.214
    STEP: creating 11/29/22 12:38:17.215
    STEP: getting 11/29/22 12:38:17.224
    STEP: listing 11/29/22 12:38:17.225
    STEP: watching 11/29/22 12:38:17.227
    Nov 29 12:38:17.228: INFO: starting watch
    STEP: patching 11/29/22 12:38:17.229
    STEP: updating 11/29/22 12:38:17.232
    Nov 29 12:38:17.236: INFO: waiting for watch events with expected annotations
    Nov 29 12:38:17.236: INFO: saw patched and updated annotations
    STEP: deleting 11/29/22 12:38:17.236
    STEP: deleting a collection 11/29/22 12:38:17.242
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Nov 29 12:38:17.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-1372" for this suite. 11/29/22 12:38:17.251
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:38:17.253
Nov 29 12:38:17.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename var-expansion 11/29/22 12:38:17.254
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:17.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:17.271
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 11/29/22 12:38:17.273
Nov 29 12:38:17.277: INFO: Waiting up to 5m0s for pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663" in namespace "var-expansion-7961" to be "Succeeded or Failed"
Nov 29 12:38:17.280: INFO: Pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663": Phase="Pending", Reason="", readiness=false. Elapsed: 2.327416ms
Nov 29 12:38:19.283: INFO: Pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005262854s
Nov 29 12:38:21.285: INFO: Pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007403582s
STEP: Saw pod success 11/29/22 12:38:21.285
Nov 29 12:38:21.285: INFO: Pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663" satisfied condition "Succeeded or Failed"
Nov 29 12:38:21.288: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663 container dapi-container: <nil>
STEP: delete the pod 11/29/22 12:38:21.292
Nov 29 12:38:21.298: INFO: Waiting for pod var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663 to disappear
Nov 29 12:38:21.300: INFO: Pod var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 29 12:38:21.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7961" for this suite. 11/29/22 12:38:21.303
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":236,"skipped":4122,"failed":0}
------------------------------
• [4.052 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:38:17.253
    Nov 29 12:38:17.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename var-expansion 11/29/22 12:38:17.254
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:17.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:17.271
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 11/29/22 12:38:17.273
    Nov 29 12:38:17.277: INFO: Waiting up to 5m0s for pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663" in namespace "var-expansion-7961" to be "Succeeded or Failed"
    Nov 29 12:38:17.280: INFO: Pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663": Phase="Pending", Reason="", readiness=false. Elapsed: 2.327416ms
    Nov 29 12:38:19.283: INFO: Pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005262854s
    Nov 29 12:38:21.285: INFO: Pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007403582s
    STEP: Saw pod success 11/29/22 12:38:21.285
    Nov 29 12:38:21.285: INFO: Pod "var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663" satisfied condition "Succeeded or Failed"
    Nov 29 12:38:21.288: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663 container dapi-container: <nil>
    STEP: delete the pod 11/29/22 12:38:21.292
    Nov 29 12:38:21.298: INFO: Waiting for pod var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663 to disappear
    Nov 29 12:38:21.300: INFO: Pod var-expansion-4df51181-c8a0-4ac2-959e-847a5e73e663 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 29 12:38:21.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7961" for this suite. 11/29/22 12:38:21.303
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:38:21.307
Nov 29 12:38:21.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename watch 11/29/22 12:38:21.308
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:21.316
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:21.319
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 11/29/22 12:38:21.321
STEP: starting a background goroutine to produce watch events 11/29/22 12:38:21.323
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/29/22 12:38:21.323
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 29 12:38:24.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7602" for this suite. 11/29/22 12:38:24.162
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":237,"skipped":4177,"failed":0}
------------------------------
• [2.905 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:38:21.307
    Nov 29 12:38:21.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename watch 11/29/22 12:38:21.308
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:21.316
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:21.319
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 11/29/22 12:38:21.321
    STEP: starting a background goroutine to produce watch events 11/29/22 12:38:21.323
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/29/22 12:38:21.323
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 29 12:38:24.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7602" for this suite. 11/29/22 12:38:24.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:38:24.213
Nov 29 12:38:24.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:38:24.214
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:24.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:24.233
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:38:24.242
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:38:24.941
STEP: Deploying the webhook pod 11/29/22 12:38:24.944
STEP: Wait for the deployment to be ready 11/29/22 12:38:24.954
Nov 29 12:38:24.980: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:38:26.986
STEP: Verifying the service has paired with the endpoint 11/29/22 12:38:26.993
Nov 29 12:38:27.993: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 11/29/22 12:38:28.021
STEP: Creating a configMap that should be mutated 11/29/22 12:38:28.034
STEP: Deleting the collection of validation webhooks 11/29/22 12:38:28.264
STEP: Creating a configMap that should not be mutated 11/29/22 12:38:28.301
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:38:28.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6208" for this suite. 11/29/22 12:38:28.309
STEP: Destroying namespace "webhook-6208-markers" for this suite. 11/29/22 12:38:28.312
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":238,"skipped":4185,"failed":0}
------------------------------
• [4.127 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:38:24.213
    Nov 29 12:38:24.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:38:24.214
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:24.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:24.233
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:38:24.242
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:38:24.941
    STEP: Deploying the webhook pod 11/29/22 12:38:24.944
    STEP: Wait for the deployment to be ready 11/29/22 12:38:24.954
    Nov 29 12:38:24.980: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:38:26.986
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:38:26.993
    Nov 29 12:38:27.993: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 11/29/22 12:38:28.021
    STEP: Creating a configMap that should be mutated 11/29/22 12:38:28.034
    STEP: Deleting the collection of validation webhooks 11/29/22 12:38:28.264
    STEP: Creating a configMap that should not be mutated 11/29/22 12:38:28.301
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:38:28.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6208" for this suite. 11/29/22 12:38:28.309
    STEP: Destroying namespace "webhook-6208-markers" for this suite. 11/29/22 12:38:28.312
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:38:28.343
Nov 29 12:38:28.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:38:28.344
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:28.352
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:28.354
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:38:28.364
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:38:28.816
STEP: Deploying the webhook pod 11/29/22 12:38:28.82
STEP: Wait for the deployment to be ready 11/29/22 12:38:28.825
Nov 29 12:38:28.831: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:38:30.838
STEP: Verifying the service has paired with the endpoint 11/29/22 12:38:30.845
Nov 29 12:38:31.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 11/29/22 12:38:31.849
Nov 29 12:38:41.859: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:38:41.977
STEP: Updating a validating webhook configuration's rules to not include the create operation 11/29/22 12:38:41.985
STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:38:41.991
STEP: Patching a validating webhook configuration's rules to include the create operation 11/29/22 12:38:41.996
STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:38:42
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:38:42.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2770" for this suite. 11/29/22 12:38:42.217
STEP: Destroying namespace "webhook-2770-markers" for this suite. 11/29/22 12:38:42.221
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":239,"skipped":4211,"failed":0}
------------------------------
• [SLOW TEST] [13.910 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:38:28.343
    Nov 29 12:38:28.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:38:28.344
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:28.352
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:28.354
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:38:28.364
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:38:28.816
    STEP: Deploying the webhook pod 11/29/22 12:38:28.82
    STEP: Wait for the deployment to be ready 11/29/22 12:38:28.825
    Nov 29 12:38:28.831: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:38:30.838
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:38:30.845
    Nov 29 12:38:31.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 11/29/22 12:38:31.849
    Nov 29 12:38:41.859: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:38:41.977
    STEP: Updating a validating webhook configuration's rules to not include the create operation 11/29/22 12:38:41.985
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:38:41.991
    STEP: Patching a validating webhook configuration's rules to include the create operation 11/29/22 12:38:41.996
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/29/22 12:38:42
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:38:42.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2770" for this suite. 11/29/22 12:38:42.217
    STEP: Destroying namespace "webhook-2770-markers" for this suite. 11/29/22 12:38:42.221
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:38:42.258
Nov 29 12:38:42.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename security-context-test 11/29/22 12:38:42.258
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:42.266
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:42.268
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Nov 29 12:38:42.275: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9" in namespace "security-context-test-2981" to be "Succeeded or Failed"
Nov 29 12:38:42.279: INFO: Pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.866976ms
Nov 29 12:38:44.282: INFO: Pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007511297s
Nov 29 12:38:46.283: INFO: Pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007618092s
Nov 29 12:38:46.283: INFO: Pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9" satisfied condition "Succeeded or Failed"
Nov 29 12:38:46.287: INFO: Got logs for pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 29 12:38:46.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2981" for this suite. 11/29/22 12:38:46.292
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":240,"skipped":4278,"failed":0}
------------------------------
• [4.039 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:38:42.258
    Nov 29 12:38:42.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename security-context-test 11/29/22 12:38:42.258
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:42.266
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:42.268
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Nov 29 12:38:42.275: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9" in namespace "security-context-test-2981" to be "Succeeded or Failed"
    Nov 29 12:38:42.279: INFO: Pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.866976ms
    Nov 29 12:38:44.282: INFO: Pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007511297s
    Nov 29 12:38:46.283: INFO: Pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007618092s
    Nov 29 12:38:46.283: INFO: Pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9" satisfied condition "Succeeded or Failed"
    Nov 29 12:38:46.287: INFO: Got logs for pod "busybox-privileged-false-6a233d52-365b-4e1a-a216-74279a384fc9": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 29 12:38:46.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2981" for this suite. 11/29/22 12:38:46.292
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:38:46.299
Nov 29 12:38:46.300: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:38:46.302
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:46.314
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:46.316
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-314 11/29/22 12:38:46.318
Nov 29 12:38:46.322: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-314" to be "running and ready"
Nov 29 12:38:46.339: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 17.509799ms
Nov 29 12:38:46.340: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:38:48.343: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.020974365s
Nov 29 12:38:48.343: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov 29 12:38:48.343: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov 29 12:38:48.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov 29 12:38:48.484: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov 29 12:38:48.484: INFO: stdout: "iptables"
Nov 29 12:38:48.484: INFO: proxyMode: iptables
Nov 29 12:38:48.490: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov 29 12:38:48.492: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-314 11/29/22 12:38:48.492
STEP: creating replication controller affinity-clusterip-timeout in namespace services-314 11/29/22 12:38:48.513
I1129 12:38:48.517230      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-314, replica count: 3
I1129 12:38:51.568194      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 12:38:51.572: INFO: Creating new exec pod
Nov 29 12:38:51.576: INFO: Waiting up to 5m0s for pod "execpod-affinityfkspw" in namespace "services-314" to be "running"
Nov 29 12:38:51.579: INFO: Pod "execpod-affinityfkspw": Phase="Pending", Reason="", readiness=false. Elapsed: 3.355315ms
Nov 29 12:38:53.583: INFO: Pod "execpod-affinityfkspw": Phase="Running", Reason="", readiness=true. Elapsed: 2.006866254s
Nov 29 12:38:53.583: INFO: Pod "execpod-affinityfkspw" satisfied condition "running"
Nov 29 12:38:54.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Nov 29 12:38:56.716: INFO: rc: 1
Nov 29 12:38:56.716: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-clusterip-timeout 80
nc: connect to affinity-clusterip-timeout port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:38:57.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Nov 29 12:38:57.897: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Nov 29 12:38:57.897: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:38:57.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.90.201 80'
Nov 29 12:38:58.039: INFO: stderr: "+ + nc -v -t -w 2 100.69.90.201echo 80\n hostName\nConnection to 100.69.90.201 80 port [tcp/http] succeeded!\n"
Nov 29 12:38:58.039: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:38:58.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.69.90.201:80/ ; done'
Nov 29 12:38:58.219: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n"
Nov 29 12:38:58.219: INFO: stdout: "\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd"
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
Nov 29 12:38:58.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.69.90.201:80/'
Nov 29 12:38:58.368: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n"
Nov 29 12:38:58.368: INFO: stdout: "affinity-clusterip-timeout-rddrd"
Nov 29 12:39:18.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.69.90.201:80/'
Nov 29 12:39:18.526: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n"
Nov 29 12:39:18.526: INFO: stdout: "affinity-clusterip-timeout-knttj"
Nov 29 12:39:18.526: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-314, will wait for the garbage collector to delete the pods 11/29/22 12:39:18.532
Nov 29 12:39:18.597: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 4.028071ms
Nov 29 12:39:18.697: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.103829ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:39:20.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-314" for this suite. 11/29/22 12:39:20.415
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":241,"skipped":4287,"failed":0}
------------------------------
• [SLOW TEST] [34.119 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:38:46.299
    Nov 29 12:38:46.300: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:38:46.302
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:38:46.314
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:38:46.316
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-314 11/29/22 12:38:46.318
    Nov 29 12:38:46.322: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-314" to be "running and ready"
    Nov 29 12:38:46.339: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 17.509799ms
    Nov 29 12:38:46.340: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:38:48.343: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.020974365s
    Nov 29 12:38:48.343: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov 29 12:38:48.343: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov 29 12:38:48.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov 29 12:38:48.484: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov 29 12:38:48.484: INFO: stdout: "iptables"
    Nov 29 12:38:48.484: INFO: proxyMode: iptables
    Nov 29 12:38:48.490: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov 29 12:38:48.492: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-314 11/29/22 12:38:48.492
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-314 11/29/22 12:38:48.513
    I1129 12:38:48.517230      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-314, replica count: 3
    I1129 12:38:51.568194      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 12:38:51.572: INFO: Creating new exec pod
    Nov 29 12:38:51.576: INFO: Waiting up to 5m0s for pod "execpod-affinityfkspw" in namespace "services-314" to be "running"
    Nov 29 12:38:51.579: INFO: Pod "execpod-affinityfkspw": Phase="Pending", Reason="", readiness=false. Elapsed: 3.355315ms
    Nov 29 12:38:53.583: INFO: Pod "execpod-affinityfkspw": Phase="Running", Reason="", readiness=true. Elapsed: 2.006866254s
    Nov 29 12:38:53.583: INFO: Pod "execpod-affinityfkspw" satisfied condition "running"
    Nov 29 12:38:54.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Nov 29 12:38:56.716: INFO: rc: 1
    Nov 29 12:38:56.716: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-clusterip-timeout 80
    nc: connect to affinity-clusterip-timeout port 80 (tcp) timed out: Operation in progress
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:38:57.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Nov 29 12:38:57.897: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Nov 29 12:38:57.897: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:38:57.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.90.201 80'
    Nov 29 12:38:58.039: INFO: stderr: "+ + nc -v -t -w 2 100.69.90.201echo 80\n hostName\nConnection to 100.69.90.201 80 port [tcp/http] succeeded!\n"
    Nov 29 12:38:58.039: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:38:58.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.69.90.201:80/ ; done'
    Nov 29 12:38:58.219: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n"
    Nov 29 12:38:58.219: INFO: stdout: "\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd\naffinity-clusterip-timeout-rddrd"
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Received response from host: affinity-clusterip-timeout-rddrd
    Nov 29 12:38:58.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.69.90.201:80/'
    Nov 29 12:38:58.368: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n"
    Nov 29 12:38:58.368: INFO: stdout: "affinity-clusterip-timeout-rddrd"
    Nov 29 12:39:18.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-314 exec execpod-affinityfkspw -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://100.69.90.201:80/'
    Nov 29 12:39:18.526: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://100.69.90.201:80/\n"
    Nov 29 12:39:18.526: INFO: stdout: "affinity-clusterip-timeout-knttj"
    Nov 29 12:39:18.526: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-314, will wait for the garbage collector to delete the pods 11/29/22 12:39:18.532
    Nov 29 12:39:18.597: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 4.028071ms
    Nov 29 12:39:18.697: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.103829ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:39:20.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-314" for this suite. 11/29/22 12:39:20.415
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:39:20.42
Nov 29 12:39:20.420: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:39:20.421
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:39:20.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:39:20.432
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-d264c1e5-6ec8-4825-bc86-d90af390b00f 11/29/22 12:39:20.439
STEP: Creating a pod to test consume secrets 11/29/22 12:39:20.442
Nov 29 12:39:20.446: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11" in namespace "projected-7349" to be "Succeeded or Failed"
Nov 29 12:39:20.448: INFO: Pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11": Phase="Pending", Reason="", readiness=false. Elapsed: 1.780751ms
Nov 29 12:39:22.451: INFO: Pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11": Phase="Running", Reason="", readiness=false. Elapsed: 2.004686002s
Nov 29 12:39:24.452: INFO: Pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005242865s
STEP: Saw pod success 11/29/22 12:39:24.452
Nov 29 12:39:24.452: INFO: Pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11" satisfied condition "Succeeded or Failed"
Nov 29 12:39:24.454: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:39:24.458
Nov 29 12:39:24.468: INFO: Waiting for pod pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11 to disappear
Nov 29 12:39:24.472: INFO: Pod pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 29 12:39:24.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7349" for this suite. 11/29/22 12:39:24.476
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":242,"skipped":4288,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:39:20.42
    Nov 29 12:39:20.420: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:39:20.421
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:39:20.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:39:20.432
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-d264c1e5-6ec8-4825-bc86-d90af390b00f 11/29/22 12:39:20.439
    STEP: Creating a pod to test consume secrets 11/29/22 12:39:20.442
    Nov 29 12:39:20.446: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11" in namespace "projected-7349" to be "Succeeded or Failed"
    Nov 29 12:39:20.448: INFO: Pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11": Phase="Pending", Reason="", readiness=false. Elapsed: 1.780751ms
    Nov 29 12:39:22.451: INFO: Pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11": Phase="Running", Reason="", readiness=false. Elapsed: 2.004686002s
    Nov 29 12:39:24.452: INFO: Pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005242865s
    STEP: Saw pod success 11/29/22 12:39:24.452
    Nov 29 12:39:24.452: INFO: Pod "pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11" satisfied condition "Succeeded or Failed"
    Nov 29 12:39:24.454: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:39:24.458
    Nov 29 12:39:24.468: INFO: Waiting for pod pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11 to disappear
    Nov 29 12:39:24.472: INFO: Pod pod-projected-secrets-c53cfb27-eb34-4fb0-929c-df45a067bb11 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 29 12:39:24.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7349" for this suite. 11/29/22 12:39:24.476
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:39:24.48
Nov 29 12:39:24.480: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:39:24.481
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:39:24.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:39:24.492
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 11/29/22 12:39:24.494
Nov 29 12:39:24.499: INFO: Waiting up to 5m0s for pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616" in namespace "projected-8758" to be "running and ready"
Nov 29 12:39:24.502: INFO: Pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616": Phase="Pending", Reason="", readiness=false. Elapsed: 2.850247ms
Nov 29 12:39:24.502: INFO: The phase of Pod annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:39:26.505: INFO: Pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616": Phase="Running", Reason="", readiness=true. Elapsed: 2.00574236s
Nov 29 12:39:26.505: INFO: The phase of Pod annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616 is Running (Ready = true)
Nov 29 12:39:26.505: INFO: Pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616" satisfied condition "running and ready"
Nov 29 12:39:27.050: INFO: Successfully updated pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 12:39:31.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8758" for this suite. 11/29/22 12:39:31.138
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":243,"skipped":4296,"failed":0}
------------------------------
• [SLOW TEST] [6.662 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:39:24.48
    Nov 29 12:39:24.480: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:39:24.481
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:39:24.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:39:24.492
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 11/29/22 12:39:24.494
    Nov 29 12:39:24.499: INFO: Waiting up to 5m0s for pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616" in namespace "projected-8758" to be "running and ready"
    Nov 29 12:39:24.502: INFO: Pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616": Phase="Pending", Reason="", readiness=false. Elapsed: 2.850247ms
    Nov 29 12:39:24.502: INFO: The phase of Pod annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:39:26.505: INFO: Pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616": Phase="Running", Reason="", readiness=true. Elapsed: 2.00574236s
    Nov 29 12:39:26.505: INFO: The phase of Pod annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616 is Running (Ready = true)
    Nov 29 12:39:26.505: INFO: Pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616" satisfied condition "running and ready"
    Nov 29 12:39:27.050: INFO: Successfully updated pod "annotationupdateb15cea93-b7a5-47aa-a852-e96ff8c46616"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 12:39:31.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8758" for this suite. 11/29/22 12:39:31.138
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:39:31.143
Nov 29 12:39:31.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-runtime 11/29/22 12:39:31.144
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:39:31.152
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:39:31.154
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 11/29/22 12:39:31.157
STEP: wait for the container to reach Succeeded 11/29/22 12:39:31.161
STEP: get the container status 11/29/22 12:39:35.178
STEP: the container should be terminated 11/29/22 12:39:35.18
STEP: the termination message should be set 11/29/22 12:39:35.18
Nov 29 12:39:35.180: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/29/22 12:39:35.18
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 29 12:39:35.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9876" for this suite. 11/29/22 12:39:35.19
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":244,"skipped":4350,"failed":0}
------------------------------
• [4.050 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:39:31.143
    Nov 29 12:39:31.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-runtime 11/29/22 12:39:31.144
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:39:31.152
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:39:31.154
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 11/29/22 12:39:31.157
    STEP: wait for the container to reach Succeeded 11/29/22 12:39:31.161
    STEP: get the container status 11/29/22 12:39:35.178
    STEP: the container should be terminated 11/29/22 12:39:35.18
    STEP: the termination message should be set 11/29/22 12:39:35.18
    Nov 29 12:39:35.180: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/29/22 12:39:35.18
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 29 12:39:35.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-9876" for this suite. 11/29/22 12:39:35.19
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:39:35.193
Nov 29 12:39:35.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pod-network-test 11/29/22 12:39:35.194
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:39:35.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:39:35.207
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-6846 11/29/22 12:39:35.21
STEP: creating a selector 11/29/22 12:39:35.21
STEP: Creating the service pods in kubernetes 11/29/22 12:39:35.21
Nov 29 12:39:35.210: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 29 12:39:35.234: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6846" to be "running and ready"
Nov 29 12:39:35.240: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.536216ms
Nov 29 12:39:35.240: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:39:37.244: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00997033s
Nov 29 12:39:37.244: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:39:39.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.00859359s
Nov 29 12:39:39.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:41.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.008736525s
Nov 29 12:39:41.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:43.242: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.00818491s
Nov 29 12:39:43.242: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:45.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.008864471s
Nov 29 12:39:45.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:47.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.009048104s
Nov 29 12:39:47.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:49.245: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.01119714s
Nov 29 12:39:49.245: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:51.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.009496586s
Nov 29 12:39:51.244: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:53.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.009136866s
Nov 29 12:39:53.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:55.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.009795121s
Nov 29 12:39:55.244: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:39:57.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.009341805s
Nov 29 12:39:57.244: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 29 12:39:57.244: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 29 12:39:57.247: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6846" to be "running and ready"
Nov 29 12:39:57.250: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.201203ms
Nov 29 12:39:57.250: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 29 12:39:57.250: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 29 12:39:57.253: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6846" to be "running and ready"
Nov 29 12:39:57.255: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.475327ms
Nov 29 12:39:57.255: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 29 12:39:57.255: INFO: Pod "netserver-2" satisfied condition "running and ready"
Nov 29 12:39:57.257: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-6846" to be "running and ready"
Nov 29 12:39:57.258: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 1.51289ms
Nov 29 12:39:57.258: INFO: The phase of Pod netserver-3 is Running (Ready = true)
Nov 29 12:39:57.258: INFO: Pod "netserver-3" satisfied condition "running and ready"
STEP: Creating test pods 11/29/22 12:39:57.26
Nov 29 12:39:57.262: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6846" to be "running"
Nov 29 12:39:57.286: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 23.762277ms
Nov 29 12:39:59.290: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027976894s
Nov 29 12:40:01.543: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.2805412s
Nov 29 12:40:01.543: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 29 12:40:01.545: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
Nov 29 12:40:01.545: INFO: Breadth first check of 100.96.1.128 on host 192.168.8.111...
Nov 29 12:40:01.550: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.244:9080/dial?request=hostname&protocol=http&host=100.96.1.128&port=8083&tries=1'] Namespace:pod-network-test-6846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:40:01.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:40:01.551: INFO: ExecWithOptions: Clientset creation
Nov 29 12:40:01.551: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-6846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.244%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.1.128%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 29 12:40:01.652: INFO: Waiting for responses: map[]
Nov 29 12:40:01.652: INFO: reached 100.96.1.128 after 0/1 tries
Nov 29 12:40:01.652: INFO: Breadth first check of 100.96.3.89 on host 192.168.8.35...
Nov 29 12:40:02.201: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.244:9080/dial?request=hostname&protocol=http&host=100.96.3.89&port=8083&tries=1'] Namespace:pod-network-test-6846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:40:02.201: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:40:02.202: INFO: ExecWithOptions: Clientset creation
Nov 29 12:40:02.202: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-6846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.244%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.3.89%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 29 12:40:02.266: INFO: Waiting for responses: map[]
Nov 29 12:40:02.266: INFO: reached 100.96.3.89 after 0/1 tries
Nov 29 12:40:02.266: INFO: Breadth first check of 100.96.2.243 on host 192.168.8.22...
Nov 29 12:40:02.269: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.244:9080/dial?request=hostname&protocol=http&host=100.96.2.243&port=8083&tries=1'] Namespace:pod-network-test-6846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:40:02.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:40:02.270: INFO: ExecWithOptions: Clientset creation
Nov 29 12:40:02.270: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-6846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.244%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.2.243%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 29 12:40:02.333: INFO: Waiting for responses: map[]
Nov 29 12:40:02.333: INFO: reached 100.96.2.243 after 0/1 tries
Nov 29 12:40:02.333: INFO: Breadth first check of 100.96.0.72 on host 192.168.8.155...
Nov 29 12:40:02.335: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.244:9080/dial?request=hostname&protocol=http&host=100.96.0.72&port=8083&tries=1'] Namespace:pod-network-test-6846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:40:02.335: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:40:02.336: INFO: ExecWithOptions: Clientset creation
Nov 29 12:40:02.336: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-6846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.244%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.0.72%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 29 12:40:02.400: INFO: Waiting for responses: map[]
Nov 29 12:40:02.400: INFO: reached 100.96.0.72 after 0/1 tries
Nov 29 12:40:02.400: INFO: Going to retry 0 out of 4 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 29 12:40:02.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6846" for this suite. 11/29/22 12:40:02.403
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":245,"skipped":4354,"failed":0}
------------------------------
• [SLOW TEST] [27.213 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:39:35.193
    Nov 29 12:39:35.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pod-network-test 11/29/22 12:39:35.194
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:39:35.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:39:35.207
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-6846 11/29/22 12:39:35.21
    STEP: creating a selector 11/29/22 12:39:35.21
    STEP: Creating the service pods in kubernetes 11/29/22 12:39:35.21
    Nov 29 12:39:35.210: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 29 12:39:35.234: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6846" to be "running and ready"
    Nov 29 12:39:35.240: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.536216ms
    Nov 29 12:39:35.240: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:39:37.244: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00997033s
    Nov 29 12:39:37.244: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:39:39.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.00859359s
    Nov 29 12:39:39.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:41.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.008736525s
    Nov 29 12:39:41.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:43.242: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.00818491s
    Nov 29 12:39:43.242: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:45.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.008864471s
    Nov 29 12:39:45.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:47.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.009048104s
    Nov 29 12:39:47.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:49.245: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.01119714s
    Nov 29 12:39:49.245: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:51.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.009496586s
    Nov 29 12:39:51.244: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:53.243: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.009136866s
    Nov 29 12:39:53.243: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:55.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.009795121s
    Nov 29 12:39:55.244: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:39:57.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.009341805s
    Nov 29 12:39:57.244: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 29 12:39:57.244: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 29 12:39:57.247: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6846" to be "running and ready"
    Nov 29 12:39:57.250: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.201203ms
    Nov 29 12:39:57.250: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 29 12:39:57.250: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 29 12:39:57.253: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6846" to be "running and ready"
    Nov 29 12:39:57.255: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.475327ms
    Nov 29 12:39:57.255: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 29 12:39:57.255: INFO: Pod "netserver-2" satisfied condition "running and ready"
    Nov 29 12:39:57.257: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-6846" to be "running and ready"
    Nov 29 12:39:57.258: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 1.51289ms
    Nov 29 12:39:57.258: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    Nov 29 12:39:57.258: INFO: Pod "netserver-3" satisfied condition "running and ready"
    STEP: Creating test pods 11/29/22 12:39:57.26
    Nov 29 12:39:57.262: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6846" to be "running"
    Nov 29 12:39:57.286: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 23.762277ms
    Nov 29 12:39:59.290: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027976894s
    Nov 29 12:40:01.543: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.2805412s
    Nov 29 12:40:01.543: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 29 12:40:01.545: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
    Nov 29 12:40:01.545: INFO: Breadth first check of 100.96.1.128 on host 192.168.8.111...
    Nov 29 12:40:01.550: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.244:9080/dial?request=hostname&protocol=http&host=100.96.1.128&port=8083&tries=1'] Namespace:pod-network-test-6846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:40:01.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:40:01.551: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:40:01.551: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-6846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.244%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.1.128%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 29 12:40:01.652: INFO: Waiting for responses: map[]
    Nov 29 12:40:01.652: INFO: reached 100.96.1.128 after 0/1 tries
    Nov 29 12:40:01.652: INFO: Breadth first check of 100.96.3.89 on host 192.168.8.35...
    Nov 29 12:40:02.201: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.244:9080/dial?request=hostname&protocol=http&host=100.96.3.89&port=8083&tries=1'] Namespace:pod-network-test-6846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:40:02.201: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:40:02.202: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:40:02.202: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-6846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.244%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.3.89%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 29 12:40:02.266: INFO: Waiting for responses: map[]
    Nov 29 12:40:02.266: INFO: reached 100.96.3.89 after 0/1 tries
    Nov 29 12:40:02.266: INFO: Breadth first check of 100.96.2.243 on host 192.168.8.22...
    Nov 29 12:40:02.269: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.244:9080/dial?request=hostname&protocol=http&host=100.96.2.243&port=8083&tries=1'] Namespace:pod-network-test-6846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:40:02.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:40:02.270: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:40:02.270: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-6846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.244%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.2.243%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 29 12:40:02.333: INFO: Waiting for responses: map[]
    Nov 29 12:40:02.333: INFO: reached 100.96.2.243 after 0/1 tries
    Nov 29 12:40:02.333: INFO: Breadth first check of 100.96.0.72 on host 192.168.8.155...
    Nov 29 12:40:02.335: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.244:9080/dial?request=hostname&protocol=http&host=100.96.0.72&port=8083&tries=1'] Namespace:pod-network-test-6846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:40:02.335: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:40:02.336: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:40:02.336: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-6846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.2.244%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.0.72%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 29 12:40:02.400: INFO: Waiting for responses: map[]
    Nov 29 12:40:02.400: INFO: reached 100.96.0.72 after 0/1 tries
    Nov 29 12:40:02.400: INFO: Going to retry 0 out of 4 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 29 12:40:02.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6846" for this suite. 11/29/22 12:40:02.403
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:40:02.408
Nov 29 12:40:02.408: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:40:02.409
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:40:02.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:40:02.463
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-7390 11/29/22 12:40:02.466
STEP: creating replication controller nodeport-test in namespace services-7390 11/29/22 12:40:02.625
I1129 12:40:02.666447      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-7390, replica count: 2
I1129 12:40:05.717845      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:40:08.718972      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:40:11.720686      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 12:40:11.720: INFO: Creating new exec pod
Nov 29 12:40:11.723: INFO: Waiting up to 5m0s for pod "execpodhd6c9" in namespace "services-7390" to be "running"
Nov 29 12:40:11.728: INFO: Pod "execpodhd6c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.809066ms
Nov 29 12:40:13.732: INFO: Pod "execpodhd6c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.00829266s
Nov 29 12:40:13.732: INFO: Pod "execpodhd6c9" satisfied condition "running"
Nov 29 12:40:14.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov 29 12:40:19.488: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 29 12:40:19.488: INFO: stdout: "nodeport-test-dvsp6"
Nov 29 12:40:19.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.66.81.200 80'
Nov 29 12:40:19.631: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.66.81.200 80\nConnection to 100.66.81.200 80 port [tcp/http] succeeded!\n"
Nov 29 12:40:19.631: INFO: stdout: ""
Nov 29 12:40:20.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.66.81.200 80'
Nov 29 12:40:20.747: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.66.81.200 80\nConnection to 100.66.81.200 80 port [tcp/http] succeeded!\n"
Nov 29 12:40:20.747: INFO: stdout: "nodeport-test-dvsp6"
Nov 29 12:40:20.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.111 30053'
Nov 29 12:40:20.879: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.111 30053\nConnection to 192.168.8.111 30053 port [tcp/*] succeeded!\n"
Nov 29 12:40:20.879: INFO: stdout: "nodeport-test-tr4l9"
Nov 29 12:40:20.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.35 30053'
Nov 29 12:40:21.092: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.35 30053\nConnection to 192.168.8.35 30053 port [tcp/*] succeeded!\n"
Nov 29 12:40:21.092: INFO: stdout: "nodeport-test-dvsp6"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:40:21.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7390" for this suite. 11/29/22 12:40:21.095
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":246,"skipped":4368,"failed":0}
------------------------------
• [SLOW TEST] [18.691 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:40:02.408
    Nov 29 12:40:02.408: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:40:02.409
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:40:02.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:40:02.463
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-7390 11/29/22 12:40:02.466
    STEP: creating replication controller nodeport-test in namespace services-7390 11/29/22 12:40:02.625
    I1129 12:40:02.666447      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-7390, replica count: 2
    I1129 12:40:05.717845      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:40:08.718972      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:40:11.720686      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 12:40:11.720: INFO: Creating new exec pod
    Nov 29 12:40:11.723: INFO: Waiting up to 5m0s for pod "execpodhd6c9" in namespace "services-7390" to be "running"
    Nov 29 12:40:11.728: INFO: Pod "execpodhd6c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.809066ms
    Nov 29 12:40:13.732: INFO: Pod "execpodhd6c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.00829266s
    Nov 29 12:40:13.732: INFO: Pod "execpodhd6c9" satisfied condition "running"
    Nov 29 12:40:14.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov 29 12:40:19.488: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov 29 12:40:19.488: INFO: stdout: "nodeport-test-dvsp6"
    Nov 29 12:40:19.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.66.81.200 80'
    Nov 29 12:40:19.631: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.66.81.200 80\nConnection to 100.66.81.200 80 port [tcp/http] succeeded!\n"
    Nov 29 12:40:19.631: INFO: stdout: ""
    Nov 29 12:40:20.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.66.81.200 80'
    Nov 29 12:40:20.747: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.66.81.200 80\nConnection to 100.66.81.200 80 port [tcp/http] succeeded!\n"
    Nov 29 12:40:20.747: INFO: stdout: "nodeport-test-dvsp6"
    Nov 29 12:40:20.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.111 30053'
    Nov 29 12:40:20.879: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.111 30053\nConnection to 192.168.8.111 30053 port [tcp/*] succeeded!\n"
    Nov 29 12:40:20.879: INFO: stdout: "nodeport-test-tr4l9"
    Nov 29 12:40:20.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-7390 exec execpodhd6c9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.35 30053'
    Nov 29 12:40:21.092: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.35 30053\nConnection to 192.168.8.35 30053 port [tcp/*] succeeded!\n"
    Nov 29 12:40:21.092: INFO: stdout: "nodeport-test-dvsp6"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:40:21.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7390" for this suite. 11/29/22 12:40:21.095
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:40:21.1
Nov 29 12:40:21.100: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:40:21.101
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:40:21.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:40:21.125
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:40:21.186
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:40:21.867
STEP: Deploying the webhook pod 11/29/22 12:40:21.87
STEP: Wait for the deployment to be ready 11/29/22 12:40:21.951
Nov 29 12:40:22.011: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 29 12:40:24.315: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 40, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 12:40:26.395: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 40, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/29/22 12:40:28.478
STEP: Verifying the service has paired with the endpoint 11/29/22 12:40:29.532
Nov 29 12:40:30.533: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 11/29/22 12:40:30.573
Nov 29 12:40:40.671: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be denied by the webhook 11/29/22 12:40:40.78
STEP: create a pod that causes the webhook to hang 11/29/22 12:40:41.025
STEP: create a configmap that should be denied by the webhook 11/29/22 12:40:51.031
STEP: create a configmap that should be admitted by the webhook 11/29/22 12:40:51.043
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/29/22 12:40:51.051
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/29/22 12:40:51.059
STEP: create a namespace that bypass the webhook 11/29/22 12:40:51.063
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/29/22 12:40:51.067
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:40:51.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5221" for this suite. 11/29/22 12:40:51.129
STEP: Destroying namespace "webhook-5221-markers" for this suite. 11/29/22 12:40:51.135
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":247,"skipped":4384,"failed":0}
------------------------------
• [SLOW TEST] [30.221 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:40:21.1
    Nov 29 12:40:21.100: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:40:21.101
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:40:21.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:40:21.125
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:40:21.186
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:40:21.867
    STEP: Deploying the webhook pod 11/29/22 12:40:21.87
    STEP: Wait for the deployment to be ready 11/29/22 12:40:21.951
    Nov 29 12:40:22.011: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 29 12:40:24.315: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 40, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 12:40:26.395: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 40, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 40, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/29/22 12:40:28.478
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:40:29.532
    Nov 29 12:40:30.533: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 11/29/22 12:40:30.573
    Nov 29 12:40:40.671: INFO: Waiting for webhook configuration to be ready...
    STEP: create a pod that should be denied by the webhook 11/29/22 12:40:40.78
    STEP: create a pod that causes the webhook to hang 11/29/22 12:40:41.025
    STEP: create a configmap that should be denied by the webhook 11/29/22 12:40:51.031
    STEP: create a configmap that should be admitted by the webhook 11/29/22 12:40:51.043
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/29/22 12:40:51.051
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/29/22 12:40:51.059
    STEP: create a namespace that bypass the webhook 11/29/22 12:40:51.063
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/29/22 12:40:51.067
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:40:51.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5221" for this suite. 11/29/22 12:40:51.129
    STEP: Destroying namespace "webhook-5221-markers" for this suite. 11/29/22 12:40:51.135
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:40:51.325
Nov 29 12:40:51.325: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 12:40:51.327
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:40:51.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:40:51.365
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Nov 29 12:40:51.370: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:40:52.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2126" for this suite. 11/29/22 12:40:52.428
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":248,"skipped":4397,"failed":0}
------------------------------
• [1.107 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:40:51.325
    Nov 29 12:40:51.325: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 12:40:51.327
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:40:51.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:40:51.365
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Nov 29 12:40:51.370: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:40:52.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2126" for this suite. 11/29/22 12:40:52.428
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:40:52.433
Nov 29 12:40:52.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 12:40:52.434
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:40:52.448
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:40:52.451
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Nov 29 12:40:52.457: INFO: Waiting up to 5m0s for pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290" in namespace "pods-6695" to be "running and ready"
Nov 29 12:40:52.461: INFO: Pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290": Phase="Pending", Reason="", readiness=false. Elapsed: 3.335928ms
Nov 29 12:40:52.461: INFO: The phase of Pod server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:40:54.467: INFO: Pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009726617s
Nov 29 12:40:54.467: INFO: The phase of Pod server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:40:56.487: INFO: Pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290": Phase="Running", Reason="", readiness=true. Elapsed: 4.029272244s
Nov 29 12:40:56.487: INFO: The phase of Pod server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290 is Running (Ready = true)
Nov 29 12:40:56.487: INFO: Pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290" satisfied condition "running and ready"
Nov 29 12:40:56.562: INFO: Waiting up to 5m0s for pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35" in namespace "pods-6695" to be "Succeeded or Failed"
Nov 29 12:40:56.624: INFO: Pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35": Phase="Pending", Reason="", readiness=false. Elapsed: 62.873887ms
Nov 29 12:40:58.653: INFO: Pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091748236s
Nov 29 12:41:00.629: INFO: Pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067003089s
STEP: Saw pod success 11/29/22 12:41:00.629
Nov 29 12:41:00.629: INFO: Pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35" satisfied condition "Succeeded or Failed"
Nov 29 12:41:00.633: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35 container env3cont: <nil>
STEP: delete the pod 11/29/22 12:41:00.637
Nov 29 12:41:00.734: INFO: Waiting for pod client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35 to disappear
Nov 29 12:41:00.781: INFO: Pod client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 12:41:00.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6695" for this suite. 11/29/22 12:41:00.786
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":249,"skipped":4428,"failed":0}
------------------------------
• [SLOW TEST] [8.357 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:40:52.433
    Nov 29 12:40:52.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 12:40:52.434
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:40:52.448
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:40:52.451
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Nov 29 12:40:52.457: INFO: Waiting up to 5m0s for pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290" in namespace "pods-6695" to be "running and ready"
    Nov 29 12:40:52.461: INFO: Pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290": Phase="Pending", Reason="", readiness=false. Elapsed: 3.335928ms
    Nov 29 12:40:52.461: INFO: The phase of Pod server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:40:54.467: INFO: Pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009726617s
    Nov 29 12:40:54.467: INFO: The phase of Pod server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:40:56.487: INFO: Pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290": Phase="Running", Reason="", readiness=true. Elapsed: 4.029272244s
    Nov 29 12:40:56.487: INFO: The phase of Pod server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290 is Running (Ready = true)
    Nov 29 12:40:56.487: INFO: Pod "server-envvars-d778edfc-55c6-4841-8d15-f69f554e3290" satisfied condition "running and ready"
    Nov 29 12:40:56.562: INFO: Waiting up to 5m0s for pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35" in namespace "pods-6695" to be "Succeeded or Failed"
    Nov 29 12:40:56.624: INFO: Pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35": Phase="Pending", Reason="", readiness=false. Elapsed: 62.873887ms
    Nov 29 12:40:58.653: INFO: Pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091748236s
    Nov 29 12:41:00.629: INFO: Pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067003089s
    STEP: Saw pod success 11/29/22 12:41:00.629
    Nov 29 12:41:00.629: INFO: Pod "client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35" satisfied condition "Succeeded or Failed"
    Nov 29 12:41:00.633: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35 container env3cont: <nil>
    STEP: delete the pod 11/29/22 12:41:00.637
    Nov 29 12:41:00.734: INFO: Waiting for pod client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35 to disappear
    Nov 29 12:41:00.781: INFO: Pod client-envvars-1fa4be37-f8cd-4499-b69d-8f5f5cf6fa35 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 12:41:00.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6695" for this suite. 11/29/22 12:41:00.786
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:41:00.791
Nov 29 12:41:00.791: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-probe 11/29/22 12:41:00.792
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:41:00.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:41:00.842
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-71692954-22f2-4c03-b488-de0b5339a31e in namespace container-probe-5736 11/29/22 12:41:00.856
Nov 29 12:41:00.866: INFO: Waiting up to 5m0s for pod "busybox-71692954-22f2-4c03-b488-de0b5339a31e" in namespace "container-probe-5736" to be "not pending"
Nov 29 12:41:00.896: INFO: Pod "busybox-71692954-22f2-4c03-b488-de0b5339a31e": Phase="Pending", Reason="", readiness=false. Elapsed: 30.155062ms
Nov 29 12:41:02.900: INFO: Pod "busybox-71692954-22f2-4c03-b488-de0b5339a31e": Phase="Running", Reason="", readiness=true. Elapsed: 2.033191988s
Nov 29 12:41:02.900: INFO: Pod "busybox-71692954-22f2-4c03-b488-de0b5339a31e" satisfied condition "not pending"
Nov 29 12:41:02.900: INFO: Started pod busybox-71692954-22f2-4c03-b488-de0b5339a31e in namespace container-probe-5736
STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 12:41:02.9
Nov 29 12:41:02.902: INFO: Initial restart count of pod busybox-71692954-22f2-4c03-b488-de0b5339a31e is 0
STEP: deleting the pod 11/29/22 12:45:03.281
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 29 12:45:03.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5736" for this suite. 11/29/22 12:45:03.297
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":250,"skipped":4432,"failed":0}
------------------------------
• [SLOW TEST] [242.509 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:41:00.791
    Nov 29 12:41:00.791: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-probe 11/29/22 12:41:00.792
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:41:00.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:41:00.842
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-71692954-22f2-4c03-b488-de0b5339a31e in namespace container-probe-5736 11/29/22 12:41:00.856
    Nov 29 12:41:00.866: INFO: Waiting up to 5m0s for pod "busybox-71692954-22f2-4c03-b488-de0b5339a31e" in namespace "container-probe-5736" to be "not pending"
    Nov 29 12:41:00.896: INFO: Pod "busybox-71692954-22f2-4c03-b488-de0b5339a31e": Phase="Pending", Reason="", readiness=false. Elapsed: 30.155062ms
    Nov 29 12:41:02.900: INFO: Pod "busybox-71692954-22f2-4c03-b488-de0b5339a31e": Phase="Running", Reason="", readiness=true. Elapsed: 2.033191988s
    Nov 29 12:41:02.900: INFO: Pod "busybox-71692954-22f2-4c03-b488-de0b5339a31e" satisfied condition "not pending"
    Nov 29 12:41:02.900: INFO: Started pod busybox-71692954-22f2-4c03-b488-de0b5339a31e in namespace container-probe-5736
    STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 12:41:02.9
    Nov 29 12:41:02.902: INFO: Initial restart count of pod busybox-71692954-22f2-4c03-b488-de0b5339a31e is 0
    STEP: deleting the pod 11/29/22 12:45:03.281
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 29 12:45:03.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5736" for this suite. 11/29/22 12:45:03.297
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:45:03.302
Nov 29 12:45:03.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename dns 11/29/22 12:45:03.303
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:03.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:03.315
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/29/22 12:45:03.317
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/29/22 12:45:03.317
STEP: creating a pod to probe DNS 11/29/22 12:45:03.317
STEP: submitting the pod to kubernetes 11/29/22 12:45:03.317
Nov 29 12:45:03.326: INFO: Waiting up to 15m0s for pod "dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be" in namespace "dns-1982" to be "running"
Nov 29 12:45:03.330: INFO: Pod "dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.169199ms
Nov 29 12:45:05.333: INFO: Pod "dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be": Phase="Running", Reason="", readiness=true. Elapsed: 2.007373221s
Nov 29 12:45:05.333: INFO: Pod "dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be" satisfied condition "running"
STEP: retrieving the pod 11/29/22 12:45:05.333
STEP: looking for the results for each expected name from probers 11/29/22 12:45:05.336
Nov 29 12:45:05.345: INFO: DNS probes using dns-1982/dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be succeeded

STEP: deleting the pod 11/29/22 12:45:05.345
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 29 12:45:05.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1982" for this suite. 11/29/22 12:45:05.354
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":251,"skipped":4462,"failed":0}
------------------------------
• [2.056 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:45:03.302
    Nov 29 12:45:03.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename dns 11/29/22 12:45:03.303
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:03.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:03.315
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/29/22 12:45:03.317
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/29/22 12:45:03.317
    STEP: creating a pod to probe DNS 11/29/22 12:45:03.317
    STEP: submitting the pod to kubernetes 11/29/22 12:45:03.317
    Nov 29 12:45:03.326: INFO: Waiting up to 15m0s for pod "dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be" in namespace "dns-1982" to be "running"
    Nov 29 12:45:03.330: INFO: Pod "dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.169199ms
    Nov 29 12:45:05.333: INFO: Pod "dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be": Phase="Running", Reason="", readiness=true. Elapsed: 2.007373221s
    Nov 29 12:45:05.333: INFO: Pod "dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 12:45:05.333
    STEP: looking for the results for each expected name from probers 11/29/22 12:45:05.336
    Nov 29 12:45:05.345: INFO: DNS probes using dns-1982/dns-test-bf8dc6a8-90c5-4f8a-82b1-87480ce117be succeeded

    STEP: deleting the pod 11/29/22 12:45:05.345
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 29 12:45:05.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1982" for this suite. 11/29/22 12:45:05.354
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:45:05.359
Nov 29 12:45:05.359: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename ephemeral-containers-test 11/29/22 12:45:05.36
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:05.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:05.37
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 11/29/22 12:45:05.372
Nov 29 12:45:05.377: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-9697" to be "running and ready"
Nov 29 12:45:05.379: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.588872ms
Nov 29 12:45:05.379: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:45:07.382: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005165297s
Nov 29 12:45:07.382: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Nov 29 12:45:07.382: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 11/29/22 12:45:07.384
Nov 29 12:45:07.393: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-9697" to be "container debugger running"
Nov 29 12:45:07.407: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 13.228451ms
Nov 29 12:45:09.411: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017582584s
Nov 29 12:45:11.410: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.01708021s
Nov 29 12:45:11.411: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 11/29/22 12:45:11.411
Nov 29 12:45:11.411: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-9697 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:45:11.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:45:11.411: INFO: ExecWithOptions: Clientset creation
Nov 29 12:45:11.411: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/ephemeral-containers-test-9697/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Nov 29 12:45:11.476: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 29 12:45:11.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-9697" for this suite. 11/29/22 12:45:11.485
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":252,"skipped":4478,"failed":0}
------------------------------
• [SLOW TEST] [6.130 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:45:05.359
    Nov 29 12:45:05.359: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename ephemeral-containers-test 11/29/22 12:45:05.36
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:05.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:05.37
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 11/29/22 12:45:05.372
    Nov 29 12:45:05.377: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-9697" to be "running and ready"
    Nov 29 12:45:05.379: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.588872ms
    Nov 29 12:45:05.379: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:45:07.382: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005165297s
    Nov 29 12:45:07.382: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Nov 29 12:45:07.382: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 11/29/22 12:45:07.384
    Nov 29 12:45:07.393: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-9697" to be "container debugger running"
    Nov 29 12:45:07.407: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 13.228451ms
    Nov 29 12:45:09.411: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017582584s
    Nov 29 12:45:11.410: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.01708021s
    Nov 29 12:45:11.411: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 11/29/22 12:45:11.411
    Nov 29 12:45:11.411: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-9697 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:45:11.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:45:11.411: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:45:11.411: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/ephemeral-containers-test-9697/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Nov 29 12:45:11.476: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 29 12:45:11.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-9697" for this suite. 11/29/22 12:45:11.485
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:45:11.492
Nov 29 12:45:11.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:45:11.493
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:11.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:11.525
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/29/22 12:45:11.528
Nov 29 12:45:11.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-8999 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov 29 12:45:11.600: INFO: stderr: ""
Nov 29 12:45:11.600: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 11/29/22 12:45:11.6
Nov 29 12:45:11.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-8999 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Nov 29 12:45:11.821: INFO: stderr: ""
Nov 29 12:45:11.821: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/29/22 12:45:11.821
Nov 29 12:45:11.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-8999 delete pods e2e-test-httpd-pod'
Nov 29 12:45:14.043: INFO: stderr: ""
Nov 29 12:45:14.043: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:45:14.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8999" for this suite. 11/29/22 12:45:14.049
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":253,"skipped":4515,"failed":0}
------------------------------
• [2.561 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:45:11.492
    Nov 29 12:45:11.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:45:11.493
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:11.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:11.525
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/29/22 12:45:11.528
    Nov 29 12:45:11.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-8999 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov 29 12:45:11.600: INFO: stderr: ""
    Nov 29 12:45:11.600: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 11/29/22 12:45:11.6
    Nov 29 12:45:11.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-8999 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Nov 29 12:45:11.821: INFO: stderr: ""
    Nov 29 12:45:11.821: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/29/22 12:45:11.821
    Nov 29 12:45:11.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-8999 delete pods e2e-test-httpd-pod'
    Nov 29 12:45:14.043: INFO: stderr: ""
    Nov 29 12:45:14.043: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:45:14.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8999" for this suite. 11/29/22 12:45:14.049
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:45:14.053
Nov 29 12:45:14.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename init-container 11/29/22 12:45:14.053
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:14.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:14.066
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 11/29/22 12:45:14.071
Nov 29 12:45:14.071: INFO: PodSpec: initContainers in spec.initContainers
Nov 29 12:45:56.124: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e6a4f94d-1102-4e6c-bef8-f4c613b14d91", GenerateName:"", Namespace:"init-container-5764", SelfLink:"", UID:"eb5fcbd8-8692-4a51-91dd-0083253f5a2d", ResourceVersion:"31759", Generation:0, CreationTimestamp:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"71129285"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"416b33e8660ec638f18df3c200d2a159c8fbdcb41189dabf2df93ba64ea895a7", "cni.projectcalico.org/podIP":"100.96.2.253/32", "cni.projectcalico.org/podIPs":"100.96.2.253/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004dd4fa8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004dd4ff0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 29, 12, 45, 56, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004dd5020), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-2cdtp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0036c0400), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2cdtp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2cdtp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2cdtp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00482d4e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"dvi-7336-1669718118-vsp1-group1-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0057a7490), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00482d560)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00482d580)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00482d588), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00482d58c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003e3df60), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.8.22", PodIP:"100.96.2.253", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.96.2.253"}}, StartTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0057a7570)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0057a75e0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://5bd326ff07924b5b0f94d3feb3f23d4f18bac93cafec4ff42bfd60825eff9bc9", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0036c0480), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0036c0460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc00482d60f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 29 12:45:56.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5764" for this suite. 11/29/22 12:45:56.128
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":254,"skipped":4518,"failed":0}
------------------------------
• [SLOW TEST] [42.078 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:45:14.053
    Nov 29 12:45:14.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename init-container 11/29/22 12:45:14.053
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:14.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:14.066
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 11/29/22 12:45:14.071
    Nov 29 12:45:14.071: INFO: PodSpec: initContainers in spec.initContainers
    Nov 29 12:45:56.124: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e6a4f94d-1102-4e6c-bef8-f4c613b14d91", GenerateName:"", Namespace:"init-container-5764", SelfLink:"", UID:"eb5fcbd8-8692-4a51-91dd-0083253f5a2d", ResourceVersion:"31759", Generation:0, CreationTimestamp:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"71129285"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"416b33e8660ec638f18df3c200d2a159c8fbdcb41189dabf2df93ba64ea895a7", "cni.projectcalico.org/podIP":"100.96.2.253/32", "cni.projectcalico.org/podIPs":"100.96.2.253/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004dd4fa8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004dd4ff0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 29, 12, 45, 56, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004dd5020), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-2cdtp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0036c0400), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2cdtp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2cdtp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-2cdtp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00482d4e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"dvi-7336-1669718118-vsp1-group1-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0057a7490), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00482d560)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00482d580)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00482d588), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00482d58c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003e3df60), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.8.22", PodIP:"100.96.2.253", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.96.2.253"}}, StartTime:time.Date(2022, time.November, 29, 12, 45, 14, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0057a7570)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0057a75e0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://5bd326ff07924b5b0f94d3feb3f23d4f18bac93cafec4ff42bfd60825eff9bc9", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0036c0480), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0036c0460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc00482d60f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 29 12:45:56.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5764" for this suite. 11/29/22 12:45:56.128
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:45:56.131
Nov 29 12:45:56.131: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename job 11/29/22 12:45:56.132
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:56.139
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:56.142
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 11/29/22 12:45:56.144
STEP: Ensuring job reaches completions 11/29/22 12:45:56.15
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 29 12:46:06.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1846" for this suite. 11/29/22 12:46:06.158
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":255,"skipped":4519,"failed":0}
------------------------------
• [SLOW TEST] [10.030 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:45:56.131
    Nov 29 12:45:56.131: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename job 11/29/22 12:45:56.132
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:45:56.139
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:45:56.142
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 11/29/22 12:45:56.144
    STEP: Ensuring job reaches completions 11/29/22 12:45:56.15
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 29 12:46:06.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1846" for this suite. 11/29/22 12:46:06.158
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:06.162
Nov 29 12:46:06.162: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename var-expansion 11/29/22 12:46:06.163
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:06.17
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:06.173
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Nov 29 12:46:06.179: INFO: Waiting up to 2m0s for pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8" in namespace "var-expansion-6784" to be "container 0 failed with reason CreateContainerConfigError"
Nov 29 12:46:06.183: INFO: Pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.684231ms
Nov 29 12:46:08.187: INFO: Pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007149661s
Nov 29 12:46:08.187: INFO: Pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov 29 12:46:08.187: INFO: Deleting pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8" in namespace "var-expansion-6784"
Nov 29 12:46:08.190: INFO: Wait up to 5m0s for pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 29 12:46:10.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6784" for this suite. 11/29/22 12:46:10.199
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":256,"skipped":4538,"failed":0}
------------------------------
• [4.040 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:06.162
    Nov 29 12:46:06.162: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename var-expansion 11/29/22 12:46:06.163
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:06.17
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:06.173
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Nov 29 12:46:06.179: INFO: Waiting up to 2m0s for pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8" in namespace "var-expansion-6784" to be "container 0 failed with reason CreateContainerConfigError"
    Nov 29 12:46:06.183: INFO: Pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.684231ms
    Nov 29 12:46:08.187: INFO: Pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007149661s
    Nov 29 12:46:08.187: INFO: Pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov 29 12:46:08.187: INFO: Deleting pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8" in namespace "var-expansion-6784"
    Nov 29 12:46:08.190: INFO: Wait up to 5m0s for pod "var-expansion-3cf286dc-2881-4946-8780-711c412ce3f8" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 29 12:46:10.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6784" for this suite. 11/29/22 12:46:10.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:10.203
Nov 29 12:46:10.203: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:46:10.204
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:10.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:10.219
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:46:10.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5057" for this suite. 11/29/22 12:46:10.242
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":257,"skipped":4563,"failed":0}
------------------------------
• [0.042 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:10.203
    Nov 29 12:46:10.203: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:46:10.204
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:10.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:10.219
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:46:10.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5057" for this suite. 11/29/22 12:46:10.242
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:10.246
Nov 29 12:46:10.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename gc 11/29/22 12:46:10.247
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:10.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:10.258
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 11/29/22 12:46:10.26
STEP: delete the rc 11/29/22 12:46:15.271
STEP: wait for all pods to be garbage collected 11/29/22 12:46:15.277
STEP: Gathering metrics 11/29/22 12:46:20.281
W1129 12:46:20.296331      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 29 12:46:20.296: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 29 12:46:20.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2461" for this suite. 11/29/22 12:46:20.299
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":258,"skipped":4568,"failed":0}
------------------------------
• [SLOW TEST] [10.056 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:10.246
    Nov 29 12:46:10.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename gc 11/29/22 12:46:10.247
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:10.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:10.258
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 11/29/22 12:46:10.26
    STEP: delete the rc 11/29/22 12:46:15.271
    STEP: wait for all pods to be garbage collected 11/29/22 12:46:15.277
    STEP: Gathering metrics 11/29/22 12:46:20.281
    W1129 12:46:20.296331      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 29 12:46:20.296: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 29 12:46:20.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2461" for this suite. 11/29/22 12:46:20.299
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:20.302
Nov 29 12:46:20.303: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:46:20.303
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:20.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:20.315
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:46:20.323
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:46:20.556
STEP: Deploying the webhook pod 11/29/22 12:46:20.559
STEP: Wait for the deployment to be ready 11/29/22 12:46:20.564
Nov 29 12:46:20.572: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:46:22.581
STEP: Verifying the service has paired with the endpoint 11/29/22 12:46:22.588
Nov 29 12:46:23.589: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 11/29/22 12:46:23.591
STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/29/22 12:46:23.604
STEP: Creating a configMap that should not be mutated 11/29/22 12:46:23.608
STEP: Patching a mutating webhook configuration's rules to include the create operation 11/29/22 12:46:23.613
STEP: Creating a configMap that should be mutated 11/29/22 12:46:23.617
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:46:23.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1" for this suite. 11/29/22 12:46:23.714
STEP: Destroying namespace "webhook-1-markers" for this suite. 11/29/22 12:46:23.717
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":259,"skipped":4575,"failed":0}
------------------------------
• [3.472 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:20.302
    Nov 29 12:46:20.303: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:46:20.303
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:20.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:20.315
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:46:20.323
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:46:20.556
    STEP: Deploying the webhook pod 11/29/22 12:46:20.559
    STEP: Wait for the deployment to be ready 11/29/22 12:46:20.564
    Nov 29 12:46:20.572: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:46:22.581
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:46:22.588
    Nov 29 12:46:23.589: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 11/29/22 12:46:23.591
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/29/22 12:46:23.604
    STEP: Creating a configMap that should not be mutated 11/29/22 12:46:23.608
    STEP: Patching a mutating webhook configuration's rules to include the create operation 11/29/22 12:46:23.613
    STEP: Creating a configMap that should be mutated 11/29/22 12:46:23.617
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:46:23.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1" for this suite. 11/29/22 12:46:23.714
    STEP: Destroying namespace "webhook-1-markers" for this suite. 11/29/22 12:46:23.717
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:23.775
Nov 29 12:46:23.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename deployment 11/29/22 12:46:23.776
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:23.788
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:23.792
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 11/29/22 12:46:23.803
STEP: waiting for Deployment to be created 11/29/22 12:46:23.806
STEP: waiting for all Replicas to be Ready 11/29/22 12:46:23.808
Nov 29 12:46:23.812: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 29 12:46:23.812: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 29 12:46:23.813: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 29 12:46:23.813: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 29 12:46:23.837: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 29 12:46:23.837: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 29 12:46:23.852: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 29 12:46:23.852: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 29 12:46:25.210: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov 29 12:46:25.210: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov 29 12:46:25.261: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 11/29/22 12:46:25.261
W1129 12:46:25.271209      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 29 12:46:25.273: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 11/29/22 12:46:25.273
Nov 29 12:46:25.275: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
Nov 29 12:46:25.275: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
Nov 29 12:46:25.275: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
Nov 29 12:46:25.275: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:25.280: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:25.280: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:25.306: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:25.306: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:25.314: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:25.314: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:25.345: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:25.345: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:26.227: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:26.227: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:26.240: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
STEP: listing Deployments 11/29/22 12:46:26.24
Nov 29 12:46:26.247: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 11/29/22 12:46:26.247
Nov 29 12:46:26.256: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 11/29/22 12:46:26.256
Nov 29 12:46:26.266: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 29 12:46:26.267: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 29 12:46:26.279: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 29 12:46:26.309: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 29 12:46:27.328: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 29 12:46:27.351: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 29 12:46:27.358: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 29 12:46:27.373: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 29 12:46:28.234: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 11/29/22 12:46:28.249
STEP: fetching the DeploymentStatus 11/29/22 12:46:28.254
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 3
STEP: deleting the Deployment 11/29/22 12:46:28.258
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.264: INFO: observed event type MODIFIED
Nov 29 12:46:28.265: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 29 12:46:28.269: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 29 12:46:28.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5969" for this suite. 11/29/22 12:46:28.289
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":260,"skipped":4576,"failed":0}
------------------------------
• [4.530 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:23.775
    Nov 29 12:46:23.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename deployment 11/29/22 12:46:23.776
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:23.788
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:23.792
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 11/29/22 12:46:23.803
    STEP: waiting for Deployment to be created 11/29/22 12:46:23.806
    STEP: waiting for all Replicas to be Ready 11/29/22 12:46:23.808
    Nov 29 12:46:23.812: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 29 12:46:23.812: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 29 12:46:23.813: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 29 12:46:23.813: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 29 12:46:23.837: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 29 12:46:23.837: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 29 12:46:23.852: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 29 12:46:23.852: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 29 12:46:25.210: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov 29 12:46:25.210: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov 29 12:46:25.261: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 11/29/22 12:46:25.261
    W1129 12:46:25.271209      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 29 12:46:25.273: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 11/29/22 12:46:25.273
    Nov 29 12:46:25.275: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
    Nov 29 12:46:25.275: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
    Nov 29 12:46:25.275: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
    Nov 29 12:46:25.275: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 0
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:25.276: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:25.280: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:25.280: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:25.306: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:25.306: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:25.314: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:25.314: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:25.345: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:25.345: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:26.227: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:26.227: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:26.240: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    STEP: listing Deployments 11/29/22 12:46:26.24
    Nov 29 12:46:26.247: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 11/29/22 12:46:26.247
    Nov 29 12:46:26.256: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 11/29/22 12:46:26.256
    Nov 29 12:46:26.266: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 29 12:46:26.267: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 29 12:46:26.279: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 29 12:46:26.309: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 29 12:46:27.328: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 29 12:46:27.351: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 29 12:46:27.358: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 29 12:46:27.373: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 29 12:46:28.234: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 11/29/22 12:46:28.249
    STEP: fetching the DeploymentStatus 11/29/22 12:46:28.254
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 1
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 2
    Nov 29 12:46:28.258: INFO: observed Deployment test-deployment in namespace deployment-5969 with ReadyReplicas 3
    STEP: deleting the Deployment 11/29/22 12:46:28.258
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.264: INFO: observed event type MODIFIED
    Nov 29 12:46:28.265: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 29 12:46:28.269: INFO: Log out all the ReplicaSets if there is no deployment created
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 29 12:46:28.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5969" for this suite. 11/29/22 12:46:28.289
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:28.307
Nov 29 12:46:28.308: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubelet-test 11/29/22 12:46:28.308
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:28.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:28.327
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 29 12:46:32.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3785" for this suite. 11/29/22 12:46:32.344
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":261,"skipped":4605,"failed":0}
------------------------------
• [4.043 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:28.307
    Nov 29 12:46:28.308: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubelet-test 11/29/22 12:46:28.308
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:28.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:28.327
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 29 12:46:32.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3785" for this suite. 11/29/22 12:46:32.344
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:32.352
Nov 29 12:46:32.352: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:46:32.353
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.364
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.367
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Nov 29 12:46:32.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-2696 version'
Nov 29 12:46:32.423: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Nov 29 12:46:32.423: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:29:58Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:46:32.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2696" for this suite. 11/29/22 12:46:32.426
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":262,"skipped":4619,"failed":0}
------------------------------
• [0.078 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:32.352
    Nov 29 12:46:32.352: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:46:32.353
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.364
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.367
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Nov 29 12:46:32.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-2696 version'
    Nov 29 12:46:32.423: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Nov 29 12:46:32.423: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:29:58Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:46:32.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2696" for this suite. 11/29/22 12:46:32.426
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:32.43
Nov 29 12:46:32.430: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename ingress 11/29/22 12:46:32.431
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.445
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 11/29/22 12:46:32.447
STEP: getting /apis/networking.k8s.io 11/29/22 12:46:32.449
STEP: getting /apis/networking.k8s.iov1 11/29/22 12:46:32.45
STEP: creating 11/29/22 12:46:32.45
STEP: getting 11/29/22 12:46:32.458
STEP: listing 11/29/22 12:46:32.46
STEP: watching 11/29/22 12:46:32.462
Nov 29 12:46:32.462: INFO: starting watch
STEP: cluster-wide listing 11/29/22 12:46:32.463
STEP: cluster-wide watching 11/29/22 12:46:32.465
Nov 29 12:46:32.465: INFO: starting watch
STEP: patching 11/29/22 12:46:32.466
STEP: updating 11/29/22 12:46:32.47
Nov 29 12:46:32.475: INFO: waiting for watch events with expected annotations
Nov 29 12:46:32.475: INFO: saw patched and updated annotations
STEP: patching /status 11/29/22 12:46:32.475
STEP: updating /status 11/29/22 12:46:32.478
STEP: get /status 11/29/22 12:46:32.482
STEP: deleting 11/29/22 12:46:32.484
STEP: deleting a collection 11/29/22 12:46:32.491
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Nov 29 12:46:32.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-4543" for this suite. 11/29/22 12:46:32.5
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":263,"skipped":4621,"failed":0}
------------------------------
• [0.074 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:32.43
    Nov 29 12:46:32.430: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename ingress 11/29/22 12:46:32.431
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.445
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 11/29/22 12:46:32.447
    STEP: getting /apis/networking.k8s.io 11/29/22 12:46:32.449
    STEP: getting /apis/networking.k8s.iov1 11/29/22 12:46:32.45
    STEP: creating 11/29/22 12:46:32.45
    STEP: getting 11/29/22 12:46:32.458
    STEP: listing 11/29/22 12:46:32.46
    STEP: watching 11/29/22 12:46:32.462
    Nov 29 12:46:32.462: INFO: starting watch
    STEP: cluster-wide listing 11/29/22 12:46:32.463
    STEP: cluster-wide watching 11/29/22 12:46:32.465
    Nov 29 12:46:32.465: INFO: starting watch
    STEP: patching 11/29/22 12:46:32.466
    STEP: updating 11/29/22 12:46:32.47
    Nov 29 12:46:32.475: INFO: waiting for watch events with expected annotations
    Nov 29 12:46:32.475: INFO: saw patched and updated annotations
    STEP: patching /status 11/29/22 12:46:32.475
    STEP: updating /status 11/29/22 12:46:32.478
    STEP: get /status 11/29/22 12:46:32.482
    STEP: deleting 11/29/22 12:46:32.484
    STEP: deleting a collection 11/29/22 12:46:32.491
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Nov 29 12:46:32.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-4543" for this suite. 11/29/22 12:46:32.5
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:32.505
Nov 29 12:46:32.505: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:46:32.506
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.515
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 11/29/22 12:46:32.517
Nov 29 12:46:32.517: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4545 proxy --unix-socket=/tmp/kubectl-proxy-unix2725163510/test'
STEP: retrieving proxy /api/ output 11/29/22 12:46:32.56
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:46:32.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4545" for this suite. 11/29/22 12:46:32.565
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":264,"skipped":4641,"failed":0}
------------------------------
• [0.063 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:32.505
    Nov 29 12:46:32.505: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:46:32.506
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.515
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 11/29/22 12:46:32.517
    Nov 29 12:46:32.517: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-4545 proxy --unix-socket=/tmp/kubectl-proxy-unix2725163510/test'
    STEP: retrieving proxy /api/ output 11/29/22 12:46:32.56
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:46:32.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4545" for this suite. 11/29/22 12:46:32.565
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:32.57
Nov 29 12:46:32.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:46:32.572
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.582
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:46:32.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4065" for this suite. 11/29/22 12:46:32.59
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":265,"skipped":4659,"failed":0}
------------------------------
• [0.024 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:32.57
    Nov 29 12:46:32.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:46:32.572
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.582
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:46:32.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4065" for this suite. 11/29/22 12:46:32.59
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:32.596
Nov 29 12:46:32.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 12:46:32.597
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.607
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Nov 29 12:46:32.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:46:33.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9449" for this suite. 11/29/22 12:46:33.139
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":266,"skipped":4691,"failed":0}
------------------------------
• [0.546 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:32.596
    Nov 29 12:46:32.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 12:46:32.597
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:32.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:32.607
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Nov 29 12:46:32.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:46:33.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-9449" for this suite. 11/29/22 12:46:33.139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:33.145
Nov 29 12:46:33.146: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:46:33.146
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:33.156
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:33.158
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 11/29/22 12:46:33.16
Nov 29 12:46:33.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-2693 create -f -'
Nov 29 12:46:33.408: INFO: stderr: ""
Nov 29 12:46:33.408: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 11/29/22 12:46:33.408
Nov 29 12:46:33.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-2693 diff -f -'
Nov 29 12:46:33.645: INFO: rc: 1
Nov 29 12:46:33.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-2693 delete -f -'
Nov 29 12:46:33.707: INFO: stderr: ""
Nov 29 12:46:33.707: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:46:33.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2693" for this suite. 11/29/22 12:46:33.713
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":267,"skipped":4743,"failed":0}
------------------------------
• [0.571 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:33.145
    Nov 29 12:46:33.146: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:46:33.146
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:33.156
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:33.158
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 11/29/22 12:46:33.16
    Nov 29 12:46:33.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-2693 create -f -'
    Nov 29 12:46:33.408: INFO: stderr: ""
    Nov 29 12:46:33.408: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 11/29/22 12:46:33.408
    Nov 29 12:46:33.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-2693 diff -f -'
    Nov 29 12:46:33.645: INFO: rc: 1
    Nov 29 12:46:33.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-2693 delete -f -'
    Nov 29 12:46:33.707: INFO: stderr: ""
    Nov 29 12:46:33.707: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:46:33.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2693" for this suite. 11/29/22 12:46:33.713
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:33.718
Nov 29 12:46:33.718: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replication-controller 11/29/22 12:46:33.719
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:33.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:33.735
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Nov 29 12:46:33.738: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/29/22 12:46:33.751
STEP: Checking rc "condition-test" has the desired failure condition set 11/29/22 12:46:33.754
STEP: Scaling down rc "condition-test" to satisfy pod quota 11/29/22 12:46:34.76
Nov 29 12:46:34.767: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 11/29/22 12:46:34.767
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 29 12:46:35.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-818" for this suite. 11/29/22 12:46:35.778
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":268,"skipped":4783,"failed":0}
------------------------------
• [2.063 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:33.718
    Nov 29 12:46:33.718: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replication-controller 11/29/22 12:46:33.719
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:33.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:33.735
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Nov 29 12:46:33.738: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/29/22 12:46:33.751
    STEP: Checking rc "condition-test" has the desired failure condition set 11/29/22 12:46:33.754
    STEP: Scaling down rc "condition-test" to satisfy pod quota 11/29/22 12:46:34.76
    Nov 29 12:46:34.767: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 11/29/22 12:46:34.767
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 29 12:46:35.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-818" for this suite. 11/29/22 12:46:35.778
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:46:35.782
Nov 29 12:46:35.782: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-preemption 11/29/22 12:46:35.783
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:35.795
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:35.797
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 29 12:46:35.806: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 29 12:47:35.843: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:47:35.846
Nov 29 12:47:35.846: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-preemption-path 11/29/22 12:47:35.847
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:47:35.857
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:47:35.861
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Nov 29 12:47:35.871: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Nov 29 12:47:35.873: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Nov 29 12:47:35.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-9125" for this suite. 11/29/22 12:47:35.887
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:47:35.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4926" for this suite. 11/29/22 12:47:35.898
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":269,"skipped":4795,"failed":0}
------------------------------
• [SLOW TEST] [60.170 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:46:35.782
    Nov 29 12:46:35.782: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-preemption 11/29/22 12:46:35.783
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:46:35.795
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:46:35.797
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 29 12:46:35.806: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 29 12:47:35.843: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:47:35.846
    Nov 29 12:47:35.846: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-preemption-path 11/29/22 12:47:35.847
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:47:35.857
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:47:35.861
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Nov 29 12:47:35.871: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Nov 29 12:47:35.873: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Nov 29 12:47:35.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-9125" for this suite. 11/29/22 12:47:35.887
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:47:35.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4926" for this suite. 11/29/22 12:47:35.898
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:47:35.953
Nov 29 12:47:35.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:47:35.954
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:47:35.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:47:35.964
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-4408 11/29/22 12:47:35.966
Nov 29 12:47:35.970: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-4408" to be "running and ready"
Nov 29 12:47:35.972: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 2.443472ms
Nov 29 12:47:35.972: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:47:37.976: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.006096583s
Nov 29 12:47:37.976: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov 29 12:47:37.976: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov 29 12:47:37.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov 29 12:47:38.103: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov 29 12:47:38.104: INFO: stdout: "iptables"
Nov 29 12:47:38.104: INFO: proxyMode: iptables
Nov 29 12:47:38.111: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov 29 12:47:38.121: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-4408 11/29/22 12:47:38.121
STEP: creating replication controller affinity-nodeport-timeout in namespace services-4408 11/29/22 12:47:38.135
I1129 12:47:38.139839      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-4408, replica count: 3
I1129 12:47:41.190091      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 12:47:41.198: INFO: Creating new exec pod
Nov 29 12:47:41.201: INFO: Waiting up to 5m0s for pod "execpod-affinityw4drj" in namespace "services-4408" to be "running"
Nov 29 12:47:41.203: INFO: Pod "execpod-affinityw4drj": Phase="Pending", Reason="", readiness=false. Elapsed: 1.893454ms
Nov 29 12:47:43.207: INFO: Pod "execpod-affinityw4drj": Phase="Running", Reason="", readiness=true. Elapsed: 2.005641928s
Nov 29 12:47:43.207: INFO: Pod "execpod-affinityw4drj" satisfied condition "running"
Nov 29 12:47:44.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 29 12:47:44.347: INFO: rc: 1
Nov 29 12:47:44.347: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport-timeout 80
nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:47:45.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 29 12:47:45.486: INFO: rc: 1
Nov 29 12:47:45.486: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport-timeout 80
nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:47:46.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 29 12:47:46.488: INFO: rc: 1
Nov 29 12:47:46.488: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport-timeout 80
nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:47:47.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 29 12:47:47.477: INFO: rc: 1
Nov 29 12:47:47.477: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport-timeout 80
nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:47:48.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 29 12:47:48.486: INFO: rc: 1
Nov 29 12:47:48.486: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 affinity-nodeport-timeout 80
nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Nov 29 12:47:49.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 29 12:47:49.486: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Nov 29 12:47:49.486: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:47:49.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.71.228.16 80'
Nov 29 12:47:49.623: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.71.228.16 80\nConnection to 100.71.228.16 80 port [tcp/http] succeeded!\n"
Nov 29 12:47:49.623: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:47:49.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.111 30217'
Nov 29 12:47:49.755: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.111 30217\nConnection to 192.168.8.111 30217 port [tcp/*] succeeded!\n"
Nov 29 12:47:49.755: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:47:49.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.35 30217'
Nov 29 12:47:49.883: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.35 30217\nConnection to 192.168.8.35 30217 port [tcp/*] succeeded!\n"
Nov 29 12:47:49.883: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:47:49.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:30217/ ; done'
Nov 29 12:47:50.076: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n"
Nov 29 12:47:50.076: INFO: stdout: "\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r"
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
Nov 29 12:47:50.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.8.111:30217/'
Nov 29 12:47:50.195: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n"
Nov 29 12:47:50.195: INFO: stdout: "affinity-nodeport-timeout-gwz5r"
Nov 29 12:48:10.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.8.111:30217/'
Nov 29 12:48:10.360: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n"
Nov 29 12:48:10.360: INFO: stdout: "affinity-nodeport-timeout-zzmft"
Nov 29 12:48:10.360: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-4408, will wait for the garbage collector to delete the pods 11/29/22 12:48:10.367
Nov 29 12:48:10.429: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 7.198391ms
Nov 29 12:48:10.529: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.825914ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:48:12.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4408" for this suite. 11/29/22 12:48:12.548
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":270,"skipped":4814,"failed":0}
------------------------------
• [SLOW TEST] [36.599 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:47:35.953
    Nov 29 12:47:35.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:47:35.954
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:47:35.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:47:35.964
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-4408 11/29/22 12:47:35.966
    Nov 29 12:47:35.970: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-4408" to be "running and ready"
    Nov 29 12:47:35.972: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 2.443472ms
    Nov 29 12:47:35.972: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:47:37.976: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.006096583s
    Nov 29 12:47:37.976: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov 29 12:47:37.976: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov 29 12:47:37.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov 29 12:47:38.103: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov 29 12:47:38.104: INFO: stdout: "iptables"
    Nov 29 12:47:38.104: INFO: proxyMode: iptables
    Nov 29 12:47:38.111: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov 29 12:47:38.121: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-4408 11/29/22 12:47:38.121
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-4408 11/29/22 12:47:38.135
    I1129 12:47:38.139839      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-4408, replica count: 3
    I1129 12:47:41.190091      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 12:47:41.198: INFO: Creating new exec pod
    Nov 29 12:47:41.201: INFO: Waiting up to 5m0s for pod "execpod-affinityw4drj" in namespace "services-4408" to be "running"
    Nov 29 12:47:41.203: INFO: Pod "execpod-affinityw4drj": Phase="Pending", Reason="", readiness=false. Elapsed: 1.893454ms
    Nov 29 12:47:43.207: INFO: Pod "execpod-affinityw4drj": Phase="Running", Reason="", readiness=true. Elapsed: 2.005641928s
    Nov 29 12:47:43.207: INFO: Pod "execpod-affinityw4drj" satisfied condition "running"
    Nov 29 12:47:44.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 29 12:47:44.347: INFO: rc: 1
    Nov 29 12:47:44.347: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport-timeout 80
    nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:47:45.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 29 12:47:45.486: INFO: rc: 1
    Nov 29 12:47:45.486: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport-timeout 80
    nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:47:46.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 29 12:47:46.488: INFO: rc: 1
    Nov 29 12:47:46.488: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport-timeout 80
    nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:47:47.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 29 12:47:47.477: INFO: rc: 1
    Nov 29 12:47:47.477: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport-timeout 80
    nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:47:48.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 29 12:47:48.486: INFO: rc: 1
    Nov 29 12:47:48.486: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 affinity-nodeport-timeout 80
    nc: connect to affinity-nodeport-timeout port 80 (tcp) failed: Connection refused
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Nov 29 12:47:49.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 29 12:47:49.486: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Nov 29 12:47:49.486: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:47:49.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.71.228.16 80'
    Nov 29 12:47:49.623: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.71.228.16 80\nConnection to 100.71.228.16 80 port [tcp/http] succeeded!\n"
    Nov 29 12:47:49.623: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:47:49.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.111 30217'
    Nov 29 12:47:49.755: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.111 30217\nConnection to 192.168.8.111 30217 port [tcp/*] succeeded!\n"
    Nov 29 12:47:49.755: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:47:49.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.35 30217'
    Nov 29 12:47:49.883: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.35 30217\nConnection to 192.168.8.35 30217 port [tcp/*] succeeded!\n"
    Nov 29 12:47:49.883: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:47:49.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:30217/ ; done'
    Nov 29 12:47:50.076: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n"
    Nov 29 12:47:50.076: INFO: stdout: "\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r\naffinity-nodeport-timeout-gwz5r"
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Received response from host: affinity-nodeport-timeout-gwz5r
    Nov 29 12:47:50.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.8.111:30217/'
    Nov 29 12:47:50.195: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n"
    Nov 29 12:47:50.195: INFO: stdout: "affinity-nodeport-timeout-gwz5r"
    Nov 29 12:48:10.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-4408 exec execpod-affinityw4drj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.8.111:30217/'
    Nov 29 12:48:10.360: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.8.111:30217/\n"
    Nov 29 12:48:10.360: INFO: stdout: "affinity-nodeport-timeout-zzmft"
    Nov 29 12:48:10.360: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-4408, will wait for the garbage collector to delete the pods 11/29/22 12:48:10.367
    Nov 29 12:48:10.429: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 7.198391ms
    Nov 29 12:48:10.529: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.825914ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:48:12.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4408" for this suite. 11/29/22 12:48:12.548
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:12.553
Nov 29 12:48:12.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename deployment 11/29/22 12:48:12.554
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:12.563
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:12.565
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 11/29/22 12:48:12.569
Nov 29 12:48:12.569: INFO: Creating simple deployment test-deployment-slz9t
Nov 29 12:48:12.589: INFO: deployment "test-deployment-slz9t" doesn't have the required revision set
STEP: Getting /status 11/29/22 12:48:14.598
Nov 29 12:48:14.600: INFO: Deployment test-deployment-slz9t has Conditions: [{Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 11/29/22 12:48:14.6
Nov 29 12:48:14.606: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 48, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 48, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 48, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 48, 12, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-slz9t-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 11/29/22 12:48:14.606
Nov 29 12:48:14.607: INFO: Observed &Deployment event: ADDED
Nov 29 12:48:14.607: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-slz9t-777898ffcc"}
Nov 29 12:48:14.607: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.607: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-slz9t-777898ffcc"}
Nov 29 12:48:14.607: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 29 12:48:14.608: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-slz9t-777898ffcc" is progressing.}
Nov 29 12:48:14.608: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}
Nov 29 12:48:14.608: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}
Nov 29 12:48:14.608: INFO: Found Deployment test-deployment-slz9t in namespace deployment-4054 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 29 12:48:14.608: INFO: Deployment test-deployment-slz9t has an updated status
STEP: patching the Statefulset Status 11/29/22 12:48:14.608
Nov 29 12:48:14.608: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 29 12:48:14.612: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 11/29/22 12:48:14.612
Nov 29 12:48:14.613: INFO: Observed &Deployment event: ADDED
Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-slz9t-777898ffcc"}
Nov 29 12:48:14.614: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-slz9t-777898ffcc"}
Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 29 12:48:14.614: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-slz9t-777898ffcc" is progressing.}
Nov 29 12:48:14.614: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}
Nov 29 12:48:14.615: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.615: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 29 12:48:14.615: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}
Nov 29 12:48:14.615: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 29 12:48:14.615: INFO: Observed &Deployment event: MODIFIED
Nov 29 12:48:14.615: INFO: Found deployment test-deployment-slz9t in namespace deployment-4054 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Nov 29 12:48:14.615: INFO: Deployment test-deployment-slz9t has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 29 12:48:14.617: INFO: Deployment "test-deployment-slz9t":
&Deployment{ObjectMeta:{test-deployment-slz9t  deployment-4054  934e7d6e-382e-4ac9-a642-9a06bd32e924 32897 1 2022-11-29 12:48:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-29 12:48:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-29 12:48:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-29 12:48:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039bc918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-slz9t-777898ffcc",LastUpdateTime:2022-11-29 12:48:14 +0000 UTC,LastTransitionTime:2022-11-29 12:48:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 29 12:48:14.619: INFO: New ReplicaSet "test-deployment-slz9t-777898ffcc" of Deployment "test-deployment-slz9t":
&ReplicaSet{ObjectMeta:{test-deployment-slz9t-777898ffcc  deployment-4054  d9260c55-d4ee-4d3e-9377-41d3fb956a7b 32888 1 2022-11-29 12:48:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-slz9t 934e7d6e-382e-4ac9-a642-9a06bd32e924 0xc0039bcfe0 0xc0039bcfe1}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:48:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"934e7d6e-382e-4ac9-a642-9a06bd32e924\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:48:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039bd108 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 29 12:48:14.621: INFO: Pod "test-deployment-slz9t-777898ffcc-tf2kk" is available:
&Pod{ObjectMeta:{test-deployment-slz9t-777898ffcc-tf2kk test-deployment-slz9t-777898ffcc- deployment-4054  a63d519f-70a9-4ea0-80f0-7302b6975e83 32887 0 2022-11-29 12:48:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:5f1cc4ae84e7b23538dfe4ac36f985f8346eb3ac6c53b7176d608621813c5621 cni.projectcalico.org/podIP:100.96.2.13/32 cni.projectcalico.org/podIPs:100.96.2.13/32] [{apps/v1 ReplicaSet test-deployment-slz9t-777898ffcc d9260c55-d4ee-4d3e-9377-41d3fb956a7b 0xc003d73130 0xc003d73131}] [] [{calico Update v1 2022-11-29 12:48:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:48:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d9260c55-d4ee-4d3e-9377-41d3fb956a7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:48:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.13\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-snhvh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-snhvh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:48:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:48:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:48:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:48:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.13,StartTime:2022-11-29 12:48:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:48:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://46f2977ebbcae2fbd799f13cead8d52b097c4608159b46e5f4b40cdc7f17cd6f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.13,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 29 12:48:14.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4054" for this suite. 11/29/22 12:48:14.625
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":271,"skipped":4822,"failed":0}
------------------------------
• [2.074 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:12.553
    Nov 29 12:48:12.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename deployment 11/29/22 12:48:12.554
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:12.563
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:12.565
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 11/29/22 12:48:12.569
    Nov 29 12:48:12.569: INFO: Creating simple deployment test-deployment-slz9t
    Nov 29 12:48:12.589: INFO: deployment "test-deployment-slz9t" doesn't have the required revision set
    STEP: Getting /status 11/29/22 12:48:14.598
    Nov 29 12:48:14.600: INFO: Deployment test-deployment-slz9t has Conditions: [{Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 11/29/22 12:48:14.6
    Nov 29 12:48:14.606: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 48, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 48, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 48, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 48, 12, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-slz9t-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 11/29/22 12:48:14.606
    Nov 29 12:48:14.607: INFO: Observed &Deployment event: ADDED
    Nov 29 12:48:14.607: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-slz9t-777898ffcc"}
    Nov 29 12:48:14.607: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.607: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-slz9t-777898ffcc"}
    Nov 29 12:48:14.607: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 29 12:48:14.608: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-slz9t-777898ffcc" is progressing.}
    Nov 29 12:48:14.608: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}
    Nov 29 12:48:14.608: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 29 12:48:14.608: INFO: Observed Deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}
    Nov 29 12:48:14.608: INFO: Found Deployment test-deployment-slz9t in namespace deployment-4054 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 29 12:48:14.608: INFO: Deployment test-deployment-slz9t has an updated status
    STEP: patching the Statefulset Status 11/29/22 12:48:14.608
    Nov 29 12:48:14.608: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 29 12:48:14.612: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 11/29/22 12:48:14.612
    Nov 29 12:48:14.613: INFO: Observed &Deployment event: ADDED
    Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-slz9t-777898ffcc"}
    Nov 29 12:48:14.614: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-slz9t-777898ffcc"}
    Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 29 12:48:14.614: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:12 +0000 UTC 2022-11-29 12:48:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-slz9t-777898ffcc" is progressing.}
    Nov 29 12:48:14.614: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 29 12:48:14.614: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}
    Nov 29 12:48:14.615: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.615: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 29 12:48:14.615: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-29 12:48:13 +0000 UTC 2022-11-29 12:48:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-slz9t-777898ffcc" has successfully progressed.}
    Nov 29 12:48:14.615: INFO: Observed deployment test-deployment-slz9t in namespace deployment-4054 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 29 12:48:14.615: INFO: Observed &Deployment event: MODIFIED
    Nov 29 12:48:14.615: INFO: Found deployment test-deployment-slz9t in namespace deployment-4054 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Nov 29 12:48:14.615: INFO: Deployment test-deployment-slz9t has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 29 12:48:14.617: INFO: Deployment "test-deployment-slz9t":
    &Deployment{ObjectMeta:{test-deployment-slz9t  deployment-4054  934e7d6e-382e-4ac9-a642-9a06bd32e924 32897 1 2022-11-29 12:48:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-29 12:48:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-29 12:48:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-29 12:48:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039bc918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-slz9t-777898ffcc",LastUpdateTime:2022-11-29 12:48:14 +0000 UTC,LastTransitionTime:2022-11-29 12:48:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 29 12:48:14.619: INFO: New ReplicaSet "test-deployment-slz9t-777898ffcc" of Deployment "test-deployment-slz9t":
    &ReplicaSet{ObjectMeta:{test-deployment-slz9t-777898ffcc  deployment-4054  d9260c55-d4ee-4d3e-9377-41d3fb956a7b 32888 1 2022-11-29 12:48:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-slz9t 934e7d6e-382e-4ac9-a642-9a06bd32e924 0xc0039bcfe0 0xc0039bcfe1}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:48:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"934e7d6e-382e-4ac9-a642-9a06bd32e924\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:48:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039bd108 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 12:48:14.621: INFO: Pod "test-deployment-slz9t-777898ffcc-tf2kk" is available:
    &Pod{ObjectMeta:{test-deployment-slz9t-777898ffcc-tf2kk test-deployment-slz9t-777898ffcc- deployment-4054  a63d519f-70a9-4ea0-80f0-7302b6975e83 32887 0 2022-11-29 12:48:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:5f1cc4ae84e7b23538dfe4ac36f985f8346eb3ac6c53b7176d608621813c5621 cni.projectcalico.org/podIP:100.96.2.13/32 cni.projectcalico.org/podIPs:100.96.2.13/32] [{apps/v1 ReplicaSet test-deployment-slz9t-777898ffcc d9260c55-d4ee-4d3e-9377-41d3fb956a7b 0xc003d73130 0xc003d73131}] [] [{calico Update v1 2022-11-29 12:48:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:48:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d9260c55-d4ee-4d3e-9377-41d3fb956a7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:48:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.13\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-snhvh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-snhvh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:48:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:48:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:48:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:48:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.13,StartTime:2022-11-29 12:48:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:48:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://46f2977ebbcae2fbd799f13cead8d52b097c4608159b46e5f4b40cdc7f17cd6f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.13,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 29 12:48:14.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4054" for this suite. 11/29/22 12:48:14.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:14.628
Nov 29 12:48:14.629: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-runtime 11/29/22 12:48:14.629
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:14.638
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:14.64
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 11/29/22 12:48:14.642
STEP: wait for the container to reach Succeeded 11/29/22 12:48:14.646
STEP: get the container status 11/29/22 12:48:17.661
STEP: the container should be terminated 11/29/22 12:48:17.663
STEP: the termination message should be set 11/29/22 12:48:17.663
Nov 29 12:48:17.663: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 11/29/22 12:48:17.663
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 29 12:48:17.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5440" for this suite. 11/29/22 12:48:17.675
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":272,"skipped":4827,"failed":0}
------------------------------
• [3.050 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:14.628
    Nov 29 12:48:14.629: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-runtime 11/29/22 12:48:14.629
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:14.638
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:14.64
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 11/29/22 12:48:14.642
    STEP: wait for the container to reach Succeeded 11/29/22 12:48:14.646
    STEP: get the container status 11/29/22 12:48:17.661
    STEP: the container should be terminated 11/29/22 12:48:17.663
    STEP: the termination message should be set 11/29/22 12:48:17.663
    Nov 29 12:48:17.663: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 11/29/22 12:48:17.663
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 29 12:48:17.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5440" for this suite. 11/29/22 12:48:17.675
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:17.679
Nov 29 12:48:17.679: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:48:17.68
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:17.691
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:17.694
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:48:17.695
Nov 29 12:48:17.700: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be" in namespace "projected-2451" to be "Succeeded or Failed"
Nov 29 12:48:17.702: INFO: Pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be": Phase="Pending", Reason="", readiness=false. Elapsed: 1.780232ms
Nov 29 12:48:19.707: INFO: Pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be": Phase="Running", Reason="", readiness=false. Elapsed: 2.006801311s
Nov 29 12:48:21.705: INFO: Pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005563859s
STEP: Saw pod success 11/29/22 12:48:21.706
Nov 29 12:48:21.706: INFO: Pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be" satisfied condition "Succeeded or Failed"
Nov 29 12:48:21.708: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be container client-container: <nil>
STEP: delete the pod 11/29/22 12:48:21.711
Nov 29 12:48:21.749: INFO: Waiting for pod downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be to disappear
Nov 29 12:48:21.752: INFO: Pod downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 29 12:48:21.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2451" for this suite. 11/29/22 12:48:21.756
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":273,"skipped":4844,"failed":0}
------------------------------
• [4.080 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:17.679
    Nov 29 12:48:17.679: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:48:17.68
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:17.691
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:17.694
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:48:17.695
    Nov 29 12:48:17.700: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be" in namespace "projected-2451" to be "Succeeded or Failed"
    Nov 29 12:48:17.702: INFO: Pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be": Phase="Pending", Reason="", readiness=false. Elapsed: 1.780232ms
    Nov 29 12:48:19.707: INFO: Pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be": Phase="Running", Reason="", readiness=false. Elapsed: 2.006801311s
    Nov 29 12:48:21.705: INFO: Pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005563859s
    STEP: Saw pod success 11/29/22 12:48:21.706
    Nov 29 12:48:21.706: INFO: Pod "downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be" satisfied condition "Succeeded or Failed"
    Nov 29 12:48:21.708: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be container client-container: <nil>
    STEP: delete the pod 11/29/22 12:48:21.711
    Nov 29 12:48:21.749: INFO: Waiting for pod downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be to disappear
    Nov 29 12:48:21.752: INFO: Pod downwardapi-volume-b4c47126-0b70-423b-8709-bff4877245be no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 29 12:48:21.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2451" for this suite. 11/29/22 12:48:21.756
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:21.763
Nov 29 12:48:21.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:48:21.764
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:21.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:21.773
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-fdbcea24-97d2-4884-b37b-7f7c162c9ed6 11/29/22 12:48:21.778
STEP: Creating secret with name s-test-opt-upd-44ac50b6-16d5-4d93-a5b8-3689d43c999c 11/29/22 12:48:21.781
STEP: Creating the pod 11/29/22 12:48:21.783
Nov 29 12:48:21.788: INFO: Waiting up to 5m0s for pod "pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799" in namespace "secrets-2742" to be "running and ready"
Nov 29 12:48:21.792: INFO: Pod "pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116362ms
Nov 29 12:48:21.792: INFO: The phase of Pod pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:48:23.795: INFO: Pod "pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799": Phase="Running", Reason="", readiness=true. Elapsed: 2.007547549s
Nov 29 12:48:23.795: INFO: The phase of Pod pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799 is Running (Ready = true)
Nov 29 12:48:23.795: INFO: Pod "pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-fdbcea24-97d2-4884-b37b-7f7c162c9ed6 11/29/22 12:48:23.808
STEP: Updating secret s-test-opt-upd-44ac50b6-16d5-4d93-a5b8-3689d43c999c 11/29/22 12:48:23.811
STEP: Creating secret with name s-test-opt-create-294aae1a-ecdd-4220-bd62-b5a3e8e47a1b 11/29/22 12:48:23.856
STEP: waiting to observe update in volume 11/29/22 12:48:23.966
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:48:25.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2742" for this suite. 11/29/22 12:48:25.993
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":274,"skipped":4898,"failed":0}
------------------------------
• [4.234 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:21.763
    Nov 29 12:48:21.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:48:21.764
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:21.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:21.773
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-fdbcea24-97d2-4884-b37b-7f7c162c9ed6 11/29/22 12:48:21.778
    STEP: Creating secret with name s-test-opt-upd-44ac50b6-16d5-4d93-a5b8-3689d43c999c 11/29/22 12:48:21.781
    STEP: Creating the pod 11/29/22 12:48:21.783
    Nov 29 12:48:21.788: INFO: Waiting up to 5m0s for pod "pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799" in namespace "secrets-2742" to be "running and ready"
    Nov 29 12:48:21.792: INFO: Pod "pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116362ms
    Nov 29 12:48:21.792: INFO: The phase of Pod pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:48:23.795: INFO: Pod "pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799": Phase="Running", Reason="", readiness=true. Elapsed: 2.007547549s
    Nov 29 12:48:23.795: INFO: The phase of Pod pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799 is Running (Ready = true)
    Nov 29 12:48:23.795: INFO: Pod "pod-secrets-b52033bd-e791-4b47-b6e7-263c61e83799" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-fdbcea24-97d2-4884-b37b-7f7c162c9ed6 11/29/22 12:48:23.808
    STEP: Updating secret s-test-opt-upd-44ac50b6-16d5-4d93-a5b8-3689d43c999c 11/29/22 12:48:23.811
    STEP: Creating secret with name s-test-opt-create-294aae1a-ecdd-4220-bd62-b5a3e8e47a1b 11/29/22 12:48:23.856
    STEP: waiting to observe update in volume 11/29/22 12:48:23.966
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:48:25.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2742" for this suite. 11/29/22 12:48:25.993
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:25.999
Nov 29 12:48:25.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 12:48:25.999
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:26.007
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:26.01
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-e25bd178-8856-43fc-a494-41542f5b440f 11/29/22 12:48:26.012
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 12:48:26.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7294" for this suite. 11/29/22 12:48:26.016
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":275,"skipped":4928,"failed":0}
------------------------------
• [0.021 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:25.999
    Nov 29 12:48:25.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 12:48:25.999
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:26.007
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:26.01
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-e25bd178-8856-43fc-a494-41542f5b440f 11/29/22 12:48:26.012
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 12:48:26.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7294" for this suite. 11/29/22 12:48:26.016
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:26.023
Nov 29 12:48:26.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:48:26.024
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:26.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:26.034
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-68c5d661-4aaf-4c10-aa03-c376e329bc00 11/29/22 12:48:26.036
STEP: Creating a pod to test consume configMaps 11/29/22 12:48:26.038
Nov 29 12:48:26.042: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950" in namespace "projected-2257" to be "Succeeded or Failed"
Nov 29 12:48:26.044: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186539ms
Nov 29 12:48:28.048: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950": Phase="Running", Reason="", readiness=true. Elapsed: 2.005670058s
Nov 29 12:48:30.048: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950": Phase="Running", Reason="", readiness=false. Elapsed: 4.006140443s
Nov 29 12:48:32.048: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.005987139s
STEP: Saw pod success 11/29/22 12:48:32.048
Nov 29 12:48:32.048: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950" satisfied condition "Succeeded or Failed"
Nov 29 12:48:32.050: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:48:32.055
Nov 29 12:48:32.065: INFO: Waiting for pod pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950 to disappear
Nov 29 12:48:32.067: INFO: Pod pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 12:48:32.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2257" for this suite. 11/29/22 12:48:32.072
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":276,"skipped":4982,"failed":0}
------------------------------
• [SLOW TEST] [6.059 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:26.023
    Nov 29 12:48:26.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:48:26.024
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:26.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:26.034
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-68c5d661-4aaf-4c10-aa03-c376e329bc00 11/29/22 12:48:26.036
    STEP: Creating a pod to test consume configMaps 11/29/22 12:48:26.038
    Nov 29 12:48:26.042: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950" in namespace "projected-2257" to be "Succeeded or Failed"
    Nov 29 12:48:26.044: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186539ms
    Nov 29 12:48:28.048: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950": Phase="Running", Reason="", readiness=true. Elapsed: 2.005670058s
    Nov 29 12:48:30.048: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950": Phase="Running", Reason="", readiness=false. Elapsed: 4.006140443s
    Nov 29 12:48:32.048: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.005987139s
    STEP: Saw pod success 11/29/22 12:48:32.048
    Nov 29 12:48:32.048: INFO: Pod "pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950" satisfied condition "Succeeded or Failed"
    Nov 29 12:48:32.050: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:48:32.055
    Nov 29 12:48:32.065: INFO: Waiting for pod pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950 to disappear
    Nov 29 12:48:32.067: INFO: Pod pod-projected-configmaps-5245ac3b-37dd-4cb4-963c-74cf89bfa950 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 12:48:32.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2257" for this suite. 11/29/22 12:48:32.072
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:32.083
Nov 29 12:48:32.083: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir-wrapper 11/29/22 12:48:32.084
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:32.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:32.096
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Nov 29 12:48:32.109: INFO: Waiting up to 5m0s for pod "pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8" in namespace "emptydir-wrapper-5787" to be "running and ready"
Nov 29 12:48:32.111: INFO: Pod "pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.419586ms
Nov 29 12:48:32.111: INFO: The phase of Pod pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:48:34.115: INFO: Pod "pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006142269s
Nov 29 12:48:34.115: INFO: The phase of Pod pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8 is Running (Ready = true)
Nov 29 12:48:34.115: INFO: Pod "pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8" satisfied condition "running and ready"
STEP: Cleaning up the secret 11/29/22 12:48:34.117
STEP: Cleaning up the configmap 11/29/22 12:48:34.12
STEP: Cleaning up the pod 11/29/22 12:48:34.123
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov 29 12:48:34.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5787" for this suite. 11/29/22 12:48:34.133
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":277,"skipped":5023,"failed":0}
------------------------------
• [2.054 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:32.083
    Nov 29 12:48:32.083: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir-wrapper 11/29/22 12:48:32.084
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:32.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:32.096
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Nov 29 12:48:32.109: INFO: Waiting up to 5m0s for pod "pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8" in namespace "emptydir-wrapper-5787" to be "running and ready"
    Nov 29 12:48:32.111: INFO: Pod "pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.419586ms
    Nov 29 12:48:32.111: INFO: The phase of Pod pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:48:34.115: INFO: Pod "pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006142269s
    Nov 29 12:48:34.115: INFO: The phase of Pod pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8 is Running (Ready = true)
    Nov 29 12:48:34.115: INFO: Pod "pod-secrets-f94dd1cd-dfcf-4c27-bd61-4329191312b8" satisfied condition "running and ready"
    STEP: Cleaning up the secret 11/29/22 12:48:34.117
    STEP: Cleaning up the configmap 11/29/22 12:48:34.12
    STEP: Cleaning up the pod 11/29/22 12:48:34.123
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov 29 12:48:34.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-5787" for this suite. 11/29/22 12:48:34.133
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:34.138
Nov 29 12:48:34.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 12:48:34.139
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:34.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:34.149
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-25b26cc1-f295-4de2-a00e-10936191e7dd 11/29/22 12:48:34.151
STEP: Creating a pod to test consume configMaps 11/29/22 12:48:34.155
Nov 29 12:48:34.160: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170" in namespace "configmap-4744" to be "Succeeded or Failed"
Nov 29 12:48:34.168: INFO: Pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170": Phase="Pending", Reason="", readiness=false. Elapsed: 7.563022ms
Nov 29 12:48:36.171: INFO: Pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01078444s
Nov 29 12:48:38.172: INFO: Pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011182965s
STEP: Saw pod success 11/29/22 12:48:38.172
Nov 29 12:48:38.172: INFO: Pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170" satisfied condition "Succeeded or Failed"
Nov 29 12:48:38.174: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170 container configmap-volume-test: <nil>
STEP: delete the pod 11/29/22 12:48:38.178
Nov 29 12:48:38.184: INFO: Waiting for pod pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170 to disappear
Nov 29 12:48:38.186: INFO: Pod pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 12:48:38.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4744" for this suite. 11/29/22 12:48:38.189
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":278,"skipped":5033,"failed":0}
------------------------------
• [4.055 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:34.138
    Nov 29 12:48:34.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 12:48:34.139
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:34.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:34.149
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-25b26cc1-f295-4de2-a00e-10936191e7dd 11/29/22 12:48:34.151
    STEP: Creating a pod to test consume configMaps 11/29/22 12:48:34.155
    Nov 29 12:48:34.160: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170" in namespace "configmap-4744" to be "Succeeded or Failed"
    Nov 29 12:48:34.168: INFO: Pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170": Phase="Pending", Reason="", readiness=false. Elapsed: 7.563022ms
    Nov 29 12:48:36.171: INFO: Pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01078444s
    Nov 29 12:48:38.172: INFO: Pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011182965s
    STEP: Saw pod success 11/29/22 12:48:38.172
    Nov 29 12:48:38.172: INFO: Pod "pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170" satisfied condition "Succeeded or Failed"
    Nov 29 12:48:38.174: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170 container configmap-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:48:38.178
    Nov 29 12:48:38.184: INFO: Waiting for pod pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170 to disappear
    Nov 29 12:48:38.186: INFO: Pod pod-configmaps-c2a359da-b490-4f4e-8027-ed1099083170 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 12:48:38.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4744" for this suite. 11/29/22 12:48:38.189
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:38.195
Nov 29 12:48:38.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename disruption 11/29/22 12:48:38.196
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:38.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:38.208
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 11/29/22 12:48:38.21
STEP: Waiting for the pdb to be processed 11/29/22 12:48:38.212
STEP: First trying to evict a pod which shouldn't be evictable 11/29/22 12:48:40.22
STEP: Waiting for all pods to be running 11/29/22 12:48:40.22
Nov 29 12:48:40.222: INFO: pods: 0 < 3
STEP: locating a running pod 11/29/22 12:48:42.226
STEP: Updating the pdb to allow a pod to be evicted 11/29/22 12:48:42.242
STEP: Waiting for the pdb to be processed 11/29/22 12:48:42.251
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/29/22 12:48:44.264
STEP: Waiting for all pods to be running 11/29/22 12:48:44.264
STEP: Waiting for the pdb to observed all healthy pods 11/29/22 12:48:44.267
STEP: Patching the pdb to disallow a pod to be evicted 11/29/22 12:48:44.303
STEP: Waiting for the pdb to be processed 11/29/22 12:48:44.321
STEP: Waiting for all pods to be running 11/29/22 12:48:46.326
STEP: locating a running pod 11/29/22 12:48:46.328
STEP: Deleting the pdb to allow a pod to be evicted 11/29/22 12:48:46.333
STEP: Waiting for the pdb to be deleted 11/29/22 12:48:46.336
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/29/22 12:48:46.337
STEP: Waiting for all pods to be running 11/29/22 12:48:46.338
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 29 12:48:46.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6063" for this suite. 11/29/22 12:48:46.351
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":279,"skipped":5071,"failed":0}
------------------------------
• [SLOW TEST] [8.163 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:38.195
    Nov 29 12:48:38.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename disruption 11/29/22 12:48:38.196
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:38.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:38.208
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 11/29/22 12:48:38.21
    STEP: Waiting for the pdb to be processed 11/29/22 12:48:38.212
    STEP: First trying to evict a pod which shouldn't be evictable 11/29/22 12:48:40.22
    STEP: Waiting for all pods to be running 11/29/22 12:48:40.22
    Nov 29 12:48:40.222: INFO: pods: 0 < 3
    STEP: locating a running pod 11/29/22 12:48:42.226
    STEP: Updating the pdb to allow a pod to be evicted 11/29/22 12:48:42.242
    STEP: Waiting for the pdb to be processed 11/29/22 12:48:42.251
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/29/22 12:48:44.264
    STEP: Waiting for all pods to be running 11/29/22 12:48:44.264
    STEP: Waiting for the pdb to observed all healthy pods 11/29/22 12:48:44.267
    STEP: Patching the pdb to disallow a pod to be evicted 11/29/22 12:48:44.303
    STEP: Waiting for the pdb to be processed 11/29/22 12:48:44.321
    STEP: Waiting for all pods to be running 11/29/22 12:48:46.326
    STEP: locating a running pod 11/29/22 12:48:46.328
    STEP: Deleting the pdb to allow a pod to be evicted 11/29/22 12:48:46.333
    STEP: Waiting for the pdb to be deleted 11/29/22 12:48:46.336
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/29/22 12:48:46.337
    STEP: Waiting for all pods to be running 11/29/22 12:48:46.338
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 29 12:48:46.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6063" for this suite. 11/29/22 12:48:46.351
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:46.364
Nov 29 12:48:46.364: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:48:46.364
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:46.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:46.393
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 11/29/22 12:48:46.395
Nov 29 12:48:46.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-675 api-versions'
Nov 29 12:48:46.464: INFO: stderr: ""
Nov 29 12:48:46.464: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncore.kublr.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nfeature.crd.kublr.com/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:48:46.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-675" for this suite. 11/29/22 12:48:46.467
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":280,"skipped":5157,"failed":0}
------------------------------
• [0.107 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:46.364
    Nov 29 12:48:46.364: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:48:46.364
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:46.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:46.393
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 11/29/22 12:48:46.395
    Nov 29 12:48:46.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-675 api-versions'
    Nov 29 12:48:46.464: INFO: stderr: ""
    Nov 29 12:48:46.464: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncore.kublr.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nfeature.crd.kublr.com/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:48:46.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-675" for this suite. 11/29/22 12:48:46.467
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:48:46.471
Nov 29 12:48:46.471: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:48:46.473
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:46.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:46.485
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 11/29/22 12:48:46.487
Nov 29 12:48:46.487: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Nov 29 12:48:46.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
Nov 29 12:48:46.750: INFO: stderr: ""
Nov 29 12:48:46.750: INFO: stdout: "service/agnhost-replica created\n"
Nov 29 12:48:46.750: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Nov 29 12:48:46.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
Nov 29 12:48:46.991: INFO: stderr: ""
Nov 29 12:48:46.991: INFO: stdout: "service/agnhost-primary created\n"
Nov 29 12:48:46.991: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 29 12:48:46.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
Nov 29 12:48:47.237: INFO: stderr: ""
Nov 29 12:48:47.237: INFO: stdout: "service/frontend created\n"
Nov 29 12:48:47.237: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Nov 29 12:48:47.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
Nov 29 12:48:47.452: INFO: stderr: ""
Nov 29 12:48:47.452: INFO: stdout: "deployment.apps/frontend created\n"
Nov 29 12:48:47.452: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 29 12:48:47.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
Nov 29 12:48:47.814: INFO: stderr: ""
Nov 29 12:48:47.814: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Nov 29 12:48:47.814: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 29 12:48:47.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
Nov 29 12:48:48.220: INFO: stderr: ""
Nov 29 12:48:48.220: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 11/29/22 12:48:48.22
Nov 29 12:48:48.220: INFO: Waiting for all frontend pods to be Running.
Nov 29 12:48:53.272: INFO: Waiting for frontend to serve content.
Nov 29 12:48:53.279: INFO: Failed to get response from guestbook. err: the server responded with the status code 417 but did not return more information (get services frontend), response: 
Nov 29 12:48:58.287: INFO: Trying to add a new entry to the guestbook.
Nov 29 12:48:58.293: INFO: Verifying that added entry can be retrieved.
Nov 29 12:48:58.300: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources 11/29/22 12:49:03.313
Nov 29 12:49:03.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
Nov 29 12:49:03.391: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 12:49:03.391: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 11/29/22 12:49:03.391
Nov 29 12:49:03.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
Nov 29 12:49:03.464: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 12:49:03.464: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/29/22 12:49:03.464
Nov 29 12:49:03.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
Nov 29 12:49:03.530: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 12:49:03.530: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/29/22 12:49:03.531
Nov 29 12:49:03.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
Nov 29 12:49:03.595: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 12:49:03.595: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/29/22 12:49:03.596
Nov 29 12:49:03.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
Nov 29 12:49:03.691: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 12:49:03.691: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/29/22 12:49:03.691
Nov 29 12:49:03.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
Nov 29 12:49:03.770: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 12:49:03.770: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:49:03.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-538" for this suite. 11/29/22 12:49:03.774
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":281,"skipped":5163,"failed":0}
------------------------------
• [SLOW TEST] [17.309 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:48:46.471
    Nov 29 12:48:46.471: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:48:46.473
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:48:46.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:48:46.485
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 11/29/22 12:48:46.487
    Nov 29 12:48:46.487: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Nov 29 12:48:46.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
    Nov 29 12:48:46.750: INFO: stderr: ""
    Nov 29 12:48:46.750: INFO: stdout: "service/agnhost-replica created\n"
    Nov 29 12:48:46.750: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Nov 29 12:48:46.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
    Nov 29 12:48:46.991: INFO: stderr: ""
    Nov 29 12:48:46.991: INFO: stdout: "service/agnhost-primary created\n"
    Nov 29 12:48:46.991: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Nov 29 12:48:46.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
    Nov 29 12:48:47.237: INFO: stderr: ""
    Nov 29 12:48:47.237: INFO: stdout: "service/frontend created\n"
    Nov 29 12:48:47.237: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Nov 29 12:48:47.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
    Nov 29 12:48:47.452: INFO: stderr: ""
    Nov 29 12:48:47.452: INFO: stdout: "deployment.apps/frontend created\n"
    Nov 29 12:48:47.452: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov 29 12:48:47.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
    Nov 29 12:48:47.814: INFO: stderr: ""
    Nov 29 12:48:47.814: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Nov 29 12:48:47.814: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov 29 12:48:47.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 create -f -'
    Nov 29 12:48:48.220: INFO: stderr: ""
    Nov 29 12:48:48.220: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 11/29/22 12:48:48.22
    Nov 29 12:48:48.220: INFO: Waiting for all frontend pods to be Running.
    Nov 29 12:48:53.272: INFO: Waiting for frontend to serve content.
    Nov 29 12:48:53.279: INFO: Failed to get response from guestbook. err: the server responded with the status code 417 but did not return more information (get services frontend), response: 
    Nov 29 12:48:58.287: INFO: Trying to add a new entry to the guestbook.
    Nov 29 12:48:58.293: INFO: Verifying that added entry can be retrieved.
    Nov 29 12:48:58.300: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
    STEP: using delete to clean up resources 11/29/22 12:49:03.313
    Nov 29 12:49:03.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
    Nov 29 12:49:03.391: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 12:49:03.391: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 11/29/22 12:49:03.391
    Nov 29 12:49:03.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
    Nov 29 12:49:03.464: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 12:49:03.464: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/29/22 12:49:03.464
    Nov 29 12:49:03.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
    Nov 29 12:49:03.530: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 12:49:03.530: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/29/22 12:49:03.531
    Nov 29 12:49:03.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
    Nov 29 12:49:03.595: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 12:49:03.595: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/29/22 12:49:03.596
    Nov 29 12:49:03.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
    Nov 29 12:49:03.691: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 12:49:03.691: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/29/22 12:49:03.691
    Nov 29 12:49:03.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-538 delete --grace-period=0 --force -f -'
    Nov 29 12:49:03.770: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 12:49:03.770: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:49:03.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-538" for this suite. 11/29/22 12:49:03.774
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:49:03.785
Nov 29 12:49:03.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename daemonsets 11/29/22 12:49:03.787
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:03.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:03.805
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Nov 29 12:49:03.828: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:49:03.831
Nov 29 12:49:03.881: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:49:03.881: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:49:05.064: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:49:05.064: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:49:05.888: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 12:49:05.888: INFO: Node dvi-7336-1669718118-vsp1-group1-1 is running 0 daemon pod, expected 1
Nov 29 12:49:06.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 12:49:06.890: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Update daemon pods image. 11/29/22 12:49:06.898
STEP: Check that daemon pods images are updated. 11/29/22 12:49:06.915
Nov 29 12:49:06.919: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:06.919: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:06.919: INFO: Wrong image for pod: daemon-set-qh6lt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:07.929: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:07.929: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:07.929: INFO: Wrong image for pod: daemon-set-qh6lt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:08.932: INFO: Pod daemon-set-9wwqn is not available
Nov 29 12:49:08.932: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:08.932: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:08.932: INFO: Wrong image for pod: daemon-set-qh6lt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:09.929: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:09.929: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:10.930: INFO: Pod daemon-set-8mhs4 is not available
Nov 29 12:49:10.930: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:10.930: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:11.935: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:12.929: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 29 12:49:12.929: INFO: Pod daemon-set-rv7hx is not available
Nov 29 12:49:14.930: INFO: Pod daemon-set-zklqw is not available
STEP: Check that daemon pods are still running on every node of the cluster. 11/29/22 12:49:14.933
Nov 29 12:49:14.940: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 12:49:14.940: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 12:49:15.947: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 12:49:15.948: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:49:15.956
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4382, will wait for the garbage collector to delete the pods 11/29/22 12:49:15.956
Nov 29 12:49:16.013: INFO: Deleting DaemonSet.extensions daemon-set took: 3.736369ms
Nov 29 12:49:16.113: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.379061ms
Nov 29 12:49:18.516: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:49:18.516: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 29 12:49:18.518: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33780"},"items":null}

Nov 29 12:49:18.520: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33780"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:49:18.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4382" for this suite. 11/29/22 12:49:18.537
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":282,"skipped":5217,"failed":0}
------------------------------
• [SLOW TEST] [14.760 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:49:03.785
    Nov 29 12:49:03.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename daemonsets 11/29/22 12:49:03.787
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:03.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:03.805
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Nov 29 12:49:03.828: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:49:03.831
    Nov 29 12:49:03.881: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:49:03.881: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:49:05.064: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:49:05.064: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:49:05.888: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 12:49:05.888: INFO: Node dvi-7336-1669718118-vsp1-group1-1 is running 0 daemon pod, expected 1
    Nov 29 12:49:06.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 12:49:06.890: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Update daemon pods image. 11/29/22 12:49:06.898
    STEP: Check that daemon pods images are updated. 11/29/22 12:49:06.915
    Nov 29 12:49:06.919: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:06.919: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:06.919: INFO: Wrong image for pod: daemon-set-qh6lt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:07.929: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:07.929: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:07.929: INFO: Wrong image for pod: daemon-set-qh6lt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:08.932: INFO: Pod daemon-set-9wwqn is not available
    Nov 29 12:49:08.932: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:08.932: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:08.932: INFO: Wrong image for pod: daemon-set-qh6lt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:09.929: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:09.929: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:10.930: INFO: Pod daemon-set-8mhs4 is not available
    Nov 29 12:49:10.930: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:10.930: INFO: Wrong image for pod: daemon-set-p6m95. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:11.935: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:12.929: INFO: Wrong image for pod: daemon-set-kktss. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 29 12:49:12.929: INFO: Pod daemon-set-rv7hx is not available
    Nov 29 12:49:14.930: INFO: Pod daemon-set-zklqw is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 11/29/22 12:49:14.933
    Nov 29 12:49:14.940: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 12:49:14.940: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 12:49:15.947: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 12:49:15.948: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:49:15.956
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4382, will wait for the garbage collector to delete the pods 11/29/22 12:49:15.956
    Nov 29 12:49:16.013: INFO: Deleting DaemonSet.extensions daemon-set took: 3.736369ms
    Nov 29 12:49:16.113: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.379061ms
    Nov 29 12:49:18.516: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:49:18.516: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 29 12:49:18.518: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33780"},"items":null}

    Nov 29 12:49:18.520: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33780"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:49:18.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4382" for this suite. 11/29/22 12:49:18.537
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:49:18.547
Nov 29 12:49:18.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename subpath 11/29/22 12:49:18.548
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:18.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:18.576
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/29/22 12:49:18.578
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-sqnc 11/29/22 12:49:18.589
STEP: Creating a pod to test atomic-volume-subpath 11/29/22 12:49:18.589
Nov 29 12:49:18.594: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sqnc" in namespace "subpath-108" to be "Succeeded or Failed"
Nov 29 12:49:18.607: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.60695ms
Nov 29 12:49:20.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 2.017112238s
Nov 29 12:49:22.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 4.01737181s
Nov 29 12:49:24.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 6.016961772s
Nov 29 12:49:26.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 8.017479413s
Nov 29 12:49:28.610: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 10.016440469s
Nov 29 12:49:30.612: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 12.017982739s
Nov 29 12:49:32.613: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 14.019452606s
Nov 29 12:49:34.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 16.017032949s
Nov 29 12:49:36.626: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 18.032538872s
Nov 29 12:49:38.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 20.017316202s
Nov 29 12:49:40.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=false. Elapsed: 22.017745139s
Nov 29 12:49:42.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.017288552s
STEP: Saw pod success 11/29/22 12:49:42.611
Nov 29 12:49:42.611: INFO: Pod "pod-subpath-test-configmap-sqnc" satisfied condition "Succeeded or Failed"
Nov 29 12:49:42.614: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-subpath-test-configmap-sqnc container test-container-subpath-configmap-sqnc: <nil>
STEP: delete the pod 11/29/22 12:49:42.619
Nov 29 12:49:42.626: INFO: Waiting for pod pod-subpath-test-configmap-sqnc to disappear
Nov 29 12:49:42.628: INFO: Pod pod-subpath-test-configmap-sqnc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-sqnc 11/29/22 12:49:42.628
Nov 29 12:49:42.628: INFO: Deleting pod "pod-subpath-test-configmap-sqnc" in namespace "subpath-108"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 29 12:49:42.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-108" for this suite. 11/29/22 12:49:42.632
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":283,"skipped":5234,"failed":0}
------------------------------
• [SLOW TEST] [24.089 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:49:18.547
    Nov 29 12:49:18.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename subpath 11/29/22 12:49:18.548
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:18.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:18.576
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/29/22 12:49:18.578
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-sqnc 11/29/22 12:49:18.589
    STEP: Creating a pod to test atomic-volume-subpath 11/29/22 12:49:18.589
    Nov 29 12:49:18.594: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sqnc" in namespace "subpath-108" to be "Succeeded or Failed"
    Nov 29 12:49:18.607: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.60695ms
    Nov 29 12:49:20.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 2.017112238s
    Nov 29 12:49:22.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 4.01737181s
    Nov 29 12:49:24.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 6.016961772s
    Nov 29 12:49:26.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 8.017479413s
    Nov 29 12:49:28.610: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 10.016440469s
    Nov 29 12:49:30.612: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 12.017982739s
    Nov 29 12:49:32.613: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 14.019452606s
    Nov 29 12:49:34.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 16.017032949s
    Nov 29 12:49:36.626: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 18.032538872s
    Nov 29 12:49:38.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=true. Elapsed: 20.017316202s
    Nov 29 12:49:40.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Running", Reason="", readiness=false. Elapsed: 22.017745139s
    Nov 29 12:49:42.611: INFO: Pod "pod-subpath-test-configmap-sqnc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.017288552s
    STEP: Saw pod success 11/29/22 12:49:42.611
    Nov 29 12:49:42.611: INFO: Pod "pod-subpath-test-configmap-sqnc" satisfied condition "Succeeded or Failed"
    Nov 29 12:49:42.614: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-subpath-test-configmap-sqnc container test-container-subpath-configmap-sqnc: <nil>
    STEP: delete the pod 11/29/22 12:49:42.619
    Nov 29 12:49:42.626: INFO: Waiting for pod pod-subpath-test-configmap-sqnc to disappear
    Nov 29 12:49:42.628: INFO: Pod pod-subpath-test-configmap-sqnc no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-sqnc 11/29/22 12:49:42.628
    Nov 29 12:49:42.628: INFO: Deleting pod "pod-subpath-test-configmap-sqnc" in namespace "subpath-108"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 29 12:49:42.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-108" for this suite. 11/29/22 12:49:42.632
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:49:42.637
Nov 29 12:49:42.637: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename podtemplate 11/29/22 12:49:42.638
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:42.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:42.647
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 11/29/22 12:49:42.649
STEP: Replace a pod template 11/29/22 12:49:42.652
Nov 29 12:49:42.656: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 29 12:49:42.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2057" for this suite. 11/29/22 12:49:42.662
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":284,"skipped":5254,"failed":0}
------------------------------
• [0.028 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:49:42.637
    Nov 29 12:49:42.637: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename podtemplate 11/29/22 12:49:42.638
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:42.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:42.647
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 11/29/22 12:49:42.649
    STEP: Replace a pod template 11/29/22 12:49:42.652
    Nov 29 12:49:42.656: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 29 12:49:42.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-2057" for this suite. 11/29/22 12:49:42.662
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:49:42.665
Nov 29 12:49:42.665: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 12:49:42.666
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:42.676
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:42.679
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 11/29/22 12:49:42.681
STEP: Creating a ResourceQuota 11/29/22 12:49:47.685
STEP: Ensuring resource quota status is calculated 11/29/22 12:49:47.687
STEP: Creating a Service 11/29/22 12:49:49.691
STEP: Creating a NodePort Service 11/29/22 12:49:49.7
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/29/22 12:49:49.726
STEP: Ensuring resource quota status captures service creation 11/29/22 12:49:49.741
STEP: Deleting Services 11/29/22 12:49:51.746
STEP: Ensuring resource quota status released usage 11/29/22 12:49:51.767
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 12:49:53.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2989" for this suite. 11/29/22 12:49:53.774
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":285,"skipped":5260,"failed":0}
------------------------------
• [SLOW TEST] [11.113 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:49:42.665
    Nov 29 12:49:42.665: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 12:49:42.666
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:42.676
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:42.679
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 11/29/22 12:49:42.681
    STEP: Creating a ResourceQuota 11/29/22 12:49:47.685
    STEP: Ensuring resource quota status is calculated 11/29/22 12:49:47.687
    STEP: Creating a Service 11/29/22 12:49:49.691
    STEP: Creating a NodePort Service 11/29/22 12:49:49.7
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/29/22 12:49:49.726
    STEP: Ensuring resource quota status captures service creation 11/29/22 12:49:49.741
    STEP: Deleting Services 11/29/22 12:49:51.746
    STEP: Ensuring resource quota status released usage 11/29/22 12:49:51.767
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 12:49:53.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2989" for this suite. 11/29/22 12:49:53.774
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:49:53.778
Nov 29 12:49:53.778: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename daemonsets 11/29/22 12:49:53.779
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:53.787
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:53.789
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Nov 29 12:49:53.809: INFO: Create a RollingUpdate DaemonSet
Nov 29 12:49:53.812: INFO: Check that daemon pods launch on every node of the cluster
Nov 29 12:49:53.817: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:49:53.817: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:49:54.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:49:54.829: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:49:55.823: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 12:49:55.823: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
Nov 29 12:49:55.823: INFO: Update the DaemonSet to trigger a rollout
Nov 29 12:49:55.828: INFO: Updating DaemonSet daemon-set
Nov 29 12:49:58.849: INFO: Roll back the DaemonSet before rollout is complete
Nov 29 12:49:58.854: INFO: Updating DaemonSet daemon-set
Nov 29 12:49:58.854: INFO: Make sure DaemonSet rollback is complete
Nov 29 12:49:58.859: INFO: Wrong image for pod: daemon-set-s97qv. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Nov 29 12:49:58.859: INFO: Pod daemon-set-s97qv is not available
Nov 29 12:50:01.867: INFO: Pod daemon-set-72zxh is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:50:01.875
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7985, will wait for the garbage collector to delete the pods 11/29/22 12:50:01.875
Nov 29 12:50:01.931: INFO: Deleting DaemonSet.extensions daemon-set took: 3.426862ms
Nov 29 12:50:02.032: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.9234ms
Nov 29 12:50:03.734: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:50:03.734: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 29 12:50:03.736: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34118"},"items":null}

Nov 29 12:50:03.738: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34118"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:50:03.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7985" for this suite. 11/29/22 12:50:03.75
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":286,"skipped":5273,"failed":0}
------------------------------
• [SLOW TEST] [9.974 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:49:53.778
    Nov 29 12:49:53.778: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename daemonsets 11/29/22 12:49:53.779
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:49:53.787
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:49:53.789
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Nov 29 12:49:53.809: INFO: Create a RollingUpdate DaemonSet
    Nov 29 12:49:53.812: INFO: Check that daemon pods launch on every node of the cluster
    Nov 29 12:49:53.817: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:49:53.817: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:49:54.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:49:54.829: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:49:55.823: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 12:49:55.823: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    Nov 29 12:49:55.823: INFO: Update the DaemonSet to trigger a rollout
    Nov 29 12:49:55.828: INFO: Updating DaemonSet daemon-set
    Nov 29 12:49:58.849: INFO: Roll back the DaemonSet before rollout is complete
    Nov 29 12:49:58.854: INFO: Updating DaemonSet daemon-set
    Nov 29 12:49:58.854: INFO: Make sure DaemonSet rollback is complete
    Nov 29 12:49:58.859: INFO: Wrong image for pod: daemon-set-s97qv. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Nov 29 12:49:58.859: INFO: Pod daemon-set-s97qv is not available
    Nov 29 12:50:01.867: INFO: Pod daemon-set-72zxh is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:50:01.875
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7985, will wait for the garbage collector to delete the pods 11/29/22 12:50:01.875
    Nov 29 12:50:01.931: INFO: Deleting DaemonSet.extensions daemon-set took: 3.426862ms
    Nov 29 12:50:02.032: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.9234ms
    Nov 29 12:50:03.734: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:50:03.734: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 29 12:50:03.736: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34118"},"items":null}

    Nov 29 12:50:03.738: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34118"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:50:03.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7985" for this suite. 11/29/22 12:50:03.75
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:03.756
Nov 29 12:50:03.756: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename lease-test 11/29/22 12:50:03.756
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:03.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:03.769
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Nov 29 12:50:03.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-3358" for this suite. 11/29/22 12:50:03.813
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":287,"skipped":5293,"failed":0}
------------------------------
• [0.061 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:03.756
    Nov 29 12:50:03.756: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename lease-test 11/29/22 12:50:03.756
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:03.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:03.769
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Nov 29 12:50:03.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-3358" for this suite. 11/29/22 12:50:03.813
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:03.818
Nov 29 12:50:03.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 12:50:03.819
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:03.827
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:03.828
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Nov 29 12:50:03.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: creating the pod 11/29/22 12:50:03.831
STEP: submitting the pod to kubernetes 11/29/22 12:50:03.831
Nov 29 12:50:03.835: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5" in namespace "pods-7013" to be "running and ready"
Nov 29 12:50:03.841: INFO: Pod "pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.210325ms
Nov 29 12:50:03.842: INFO: The phase of Pod pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:50:05.844: INFO: Pod "pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008989329s
Nov 29 12:50:05.844: INFO: The phase of Pod pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5 is Running (Ready = true)
Nov 29 12:50:05.844: INFO: Pod "pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 12:50:05.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7013" for this suite. 11/29/22 12:50:05.857
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":288,"skipped":5300,"failed":0}
------------------------------
• [2.042 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:03.818
    Nov 29 12:50:03.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 12:50:03.819
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:03.827
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:03.828
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Nov 29 12:50:03.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: creating the pod 11/29/22 12:50:03.831
    STEP: submitting the pod to kubernetes 11/29/22 12:50:03.831
    Nov 29 12:50:03.835: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5" in namespace "pods-7013" to be "running and ready"
    Nov 29 12:50:03.841: INFO: Pod "pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.210325ms
    Nov 29 12:50:03.842: INFO: The phase of Pod pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:50:05.844: INFO: Pod "pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008989329s
    Nov 29 12:50:05.844: INFO: The phase of Pod pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5 is Running (Ready = true)
    Nov 29 12:50:05.844: INFO: Pod "pod-logs-websocket-e5b9ff87-b3aa-4083-adbf-a55e418cb9d5" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 12:50:05.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7013" for this suite. 11/29/22 12:50:05.857
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:05.864
Nov 29 12:50:05.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:50:05.865
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:05.874
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:05.876
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:50:05.878
Nov 29 12:50:05.882: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026" in namespace "downward-api-908" to be "Succeeded or Failed"
Nov 29 12:50:05.886: INFO: Pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026": Phase="Pending", Reason="", readiness=false. Elapsed: 4.254234ms
Nov 29 12:50:07.890: INFO: Pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026": Phase="Running", Reason="", readiness=false. Elapsed: 2.00799383s
Nov 29 12:50:09.890: INFO: Pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008371685s
STEP: Saw pod success 11/29/22 12:50:09.89
Nov 29 12:50:09.891: INFO: Pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026" satisfied condition "Succeeded or Failed"
Nov 29 12:50:09.893: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026 container client-container: <nil>
STEP: delete the pod 11/29/22 12:50:09.896
Nov 29 12:50:09.901: INFO: Waiting for pod downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026 to disappear
Nov 29 12:50:09.904: INFO: Pod downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:50:09.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-908" for this suite. 11/29/22 12:50:09.907
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":289,"skipped":5316,"failed":0}
------------------------------
• [4.046 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:05.864
    Nov 29 12:50:05.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:50:05.865
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:05.874
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:05.876
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:50:05.878
    Nov 29 12:50:05.882: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026" in namespace "downward-api-908" to be "Succeeded or Failed"
    Nov 29 12:50:05.886: INFO: Pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026": Phase="Pending", Reason="", readiness=false. Elapsed: 4.254234ms
    Nov 29 12:50:07.890: INFO: Pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026": Phase="Running", Reason="", readiness=false. Elapsed: 2.00799383s
    Nov 29 12:50:09.890: INFO: Pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008371685s
    STEP: Saw pod success 11/29/22 12:50:09.89
    Nov 29 12:50:09.891: INFO: Pod "downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026" satisfied condition "Succeeded or Failed"
    Nov 29 12:50:09.893: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:50:09.896
    Nov 29 12:50:09.901: INFO: Waiting for pod downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026 to disappear
    Nov 29 12:50:09.904: INFO: Pod downwardapi-volume-8239d319-f327-49ab-a37b-70fb9dd81026 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:50:09.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-908" for this suite. 11/29/22 12:50:09.907
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:09.912
Nov 29 12:50:09.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename csistoragecapacity 11/29/22 12:50:09.913
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:09.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:09.923
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 11/29/22 12:50:09.925
STEP: getting /apis/storage.k8s.io 11/29/22 12:50:09.926
STEP: getting /apis/storage.k8s.io/v1 11/29/22 12:50:09.927
STEP: creating 11/29/22 12:50:09.928
STEP: watching 11/29/22 12:50:09.934
Nov 29 12:50:09.934: INFO: starting watch
STEP: getting 11/29/22 12:50:09.938
STEP: listing in namespace 11/29/22 12:50:09.94
STEP: listing across namespaces 11/29/22 12:50:09.941
STEP: patching 11/29/22 12:50:09.943
STEP: updating 11/29/22 12:50:09.946
Nov 29 12:50:09.948: INFO: waiting for watch events with expected annotations in namespace
Nov 29 12:50:09.948: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 11/29/22 12:50:09.948
STEP: deleting a collection 11/29/22 12:50:09.961
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Nov 29 12:50:09.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-4595" for this suite. 11/29/22 12:50:09.969
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":290,"skipped":5340,"failed":0}
------------------------------
• [0.060 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:09.912
    Nov 29 12:50:09.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename csistoragecapacity 11/29/22 12:50:09.913
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:09.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:09.923
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 11/29/22 12:50:09.925
    STEP: getting /apis/storage.k8s.io 11/29/22 12:50:09.926
    STEP: getting /apis/storage.k8s.io/v1 11/29/22 12:50:09.927
    STEP: creating 11/29/22 12:50:09.928
    STEP: watching 11/29/22 12:50:09.934
    Nov 29 12:50:09.934: INFO: starting watch
    STEP: getting 11/29/22 12:50:09.938
    STEP: listing in namespace 11/29/22 12:50:09.94
    STEP: listing across namespaces 11/29/22 12:50:09.941
    STEP: patching 11/29/22 12:50:09.943
    STEP: updating 11/29/22 12:50:09.946
    Nov 29 12:50:09.948: INFO: waiting for watch events with expected annotations in namespace
    Nov 29 12:50:09.948: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 11/29/22 12:50:09.948
    STEP: deleting a collection 11/29/22 12:50:09.961
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Nov 29 12:50:09.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-4595" for this suite. 11/29/22 12:50:09.969
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:09.973
Nov 29 12:50:09.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:50:09.974
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:09.992
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:09.994
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 11/29/22 12:50:09.996
Nov 29 12:50:09.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 create -f -'
Nov 29 12:50:10.230: INFO: stderr: ""
Nov 29 12:50:10.230: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/29/22 12:50:10.23
Nov 29 12:50:10.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 12:50:10.295: INFO: stderr: ""
Nov 29 12:50:10.295: INFO: stdout: "update-demo-nautilus-jm2jw update-demo-nautilus-v47bg "
Nov 29 12:50:10.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-jm2jw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 12:50:10.363: INFO: stderr: ""
Nov 29 12:50:10.363: INFO: stdout: ""
Nov 29 12:50:10.363: INFO: update-demo-nautilus-jm2jw is created but not running
Nov 29 12:50:15.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 29 12:50:15.432: INFO: stderr: ""
Nov 29 12:50:15.432: INFO: stdout: "update-demo-nautilus-jm2jw update-demo-nautilus-v47bg "
Nov 29 12:50:15.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-jm2jw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 12:50:15.502: INFO: stderr: ""
Nov 29 12:50:15.502: INFO: stdout: "true"
Nov 29 12:50:15.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-jm2jw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 12:50:15.573: INFO: stderr: ""
Nov 29 12:50:15.573: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 12:50:15.573: INFO: validating pod update-demo-nautilus-jm2jw
Nov 29 12:50:15.577: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 12:50:15.577: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 12:50:15.577: INFO: update-demo-nautilus-jm2jw is verified up and running
Nov 29 12:50:15.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-v47bg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 29 12:50:15.642: INFO: stderr: ""
Nov 29 12:50:15.642: INFO: stdout: "true"
Nov 29 12:50:15.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-v47bg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 29 12:50:15.712: INFO: stderr: ""
Nov 29 12:50:15.712: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 29 12:50:15.712: INFO: validating pod update-demo-nautilus-v47bg
Nov 29 12:50:15.716: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 29 12:50:15.716: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 29 12:50:15.716: INFO: update-demo-nautilus-v47bg is verified up and running
STEP: using delete to clean up resources 11/29/22 12:50:15.716
Nov 29 12:50:15.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 delete --grace-period=0 --force -f -'
Nov 29 12:50:15.776: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 29 12:50:15.776: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 29 12:50:15.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get rc,svc -l name=update-demo --no-headers'
Nov 29 12:50:15.858: INFO: stderr: "No resources found in kubectl-9252 namespace.\n"
Nov 29 12:50:15.858: INFO: stdout: ""
Nov 29 12:50:15.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 29 12:50:15.928: INFO: stderr: ""
Nov 29 12:50:15.928: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:50:15.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9252" for this suite. 11/29/22 12:50:15.933
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":291,"skipped":5341,"failed":0}
------------------------------
• [SLOW TEST] [5.963 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:09.973
    Nov 29 12:50:09.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:50:09.974
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:09.992
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:09.994
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 11/29/22 12:50:09.996
    Nov 29 12:50:09.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 create -f -'
    Nov 29 12:50:10.230: INFO: stderr: ""
    Nov 29 12:50:10.230: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/29/22 12:50:10.23
    Nov 29 12:50:10.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 12:50:10.295: INFO: stderr: ""
    Nov 29 12:50:10.295: INFO: stdout: "update-demo-nautilus-jm2jw update-demo-nautilus-v47bg "
    Nov 29 12:50:10.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-jm2jw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 12:50:10.363: INFO: stderr: ""
    Nov 29 12:50:10.363: INFO: stdout: ""
    Nov 29 12:50:10.363: INFO: update-demo-nautilus-jm2jw is created but not running
    Nov 29 12:50:15.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 29 12:50:15.432: INFO: stderr: ""
    Nov 29 12:50:15.432: INFO: stdout: "update-demo-nautilus-jm2jw update-demo-nautilus-v47bg "
    Nov 29 12:50:15.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-jm2jw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 12:50:15.502: INFO: stderr: ""
    Nov 29 12:50:15.502: INFO: stdout: "true"
    Nov 29 12:50:15.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-jm2jw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 12:50:15.573: INFO: stderr: ""
    Nov 29 12:50:15.573: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 12:50:15.573: INFO: validating pod update-demo-nautilus-jm2jw
    Nov 29 12:50:15.577: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 12:50:15.577: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 12:50:15.577: INFO: update-demo-nautilus-jm2jw is verified up and running
    Nov 29 12:50:15.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-v47bg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 29 12:50:15.642: INFO: stderr: ""
    Nov 29 12:50:15.642: INFO: stdout: "true"
    Nov 29 12:50:15.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods update-demo-nautilus-v47bg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 29 12:50:15.712: INFO: stderr: ""
    Nov 29 12:50:15.712: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 29 12:50:15.712: INFO: validating pod update-demo-nautilus-v47bg
    Nov 29 12:50:15.716: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 29 12:50:15.716: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 29 12:50:15.716: INFO: update-demo-nautilus-v47bg is verified up and running
    STEP: using delete to clean up resources 11/29/22 12:50:15.716
    Nov 29 12:50:15.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 delete --grace-period=0 --force -f -'
    Nov 29 12:50:15.776: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 29 12:50:15.776: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov 29 12:50:15.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get rc,svc -l name=update-demo --no-headers'
    Nov 29 12:50:15.858: INFO: stderr: "No resources found in kubectl-9252 namespace.\n"
    Nov 29 12:50:15.858: INFO: stdout: ""
    Nov 29 12:50:15.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-9252 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 29 12:50:15.928: INFO: stderr: ""
    Nov 29 12:50:15.928: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:50:15.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9252" for this suite. 11/29/22 12:50:15.933
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:15.936
Nov 29 12:50:15.937: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:50:15.938
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:15.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:15.999
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:50:16.001
Nov 29 12:50:16.009: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126" in namespace "downward-api-1417" to be "Succeeded or Failed"
Nov 29 12:50:16.015: INFO: Pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126": Phase="Pending", Reason="", readiness=false. Elapsed: 5.158484ms
Nov 29 12:50:18.019: INFO: Pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009568639s
Nov 29 12:50:20.021: INFO: Pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011343357s
STEP: Saw pod success 11/29/22 12:50:20.021
Nov 29 12:50:20.021: INFO: Pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126" satisfied condition "Succeeded or Failed"
Nov 29 12:50:20.025: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126 container client-container: <nil>
STEP: delete the pod 11/29/22 12:50:20.03
Nov 29 12:50:20.036: INFO: Waiting for pod downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126 to disappear
Nov 29 12:50:20.039: INFO: Pod downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:50:20.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1417" for this suite. 11/29/22 12:50:20.042
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":292,"skipped":5343,"failed":0}
------------------------------
• [4.108 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:15.936
    Nov 29 12:50:15.937: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:50:15.938
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:15.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:15.999
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:50:16.001
    Nov 29 12:50:16.009: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126" in namespace "downward-api-1417" to be "Succeeded or Failed"
    Nov 29 12:50:16.015: INFO: Pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126": Phase="Pending", Reason="", readiness=false. Elapsed: 5.158484ms
    Nov 29 12:50:18.019: INFO: Pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009568639s
    Nov 29 12:50:20.021: INFO: Pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011343357s
    STEP: Saw pod success 11/29/22 12:50:20.021
    Nov 29 12:50:20.021: INFO: Pod "downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126" satisfied condition "Succeeded or Failed"
    Nov 29 12:50:20.025: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-0 pod downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:50:20.03
    Nov 29 12:50:20.036: INFO: Waiting for pod downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126 to disappear
    Nov 29 12:50:20.039: INFO: Pod downwardapi-volume-d2332f3d-dfc3-4470-a853-2aeb94d31126 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:50:20.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1417" for this suite. 11/29/22 12:50:20.042
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:20.046
Nov 29 12:50:20.046: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename daemonsets 11/29/22 12:50:20.047
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:20.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:20.056
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 11/29/22 12:50:20.074
STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:50:20.077
Nov 29 12:50:20.092: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:50:20.092: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:50:21.144: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:50:21.144: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:50:22.100: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 12:50:22.101: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/29/22 12:50:22.106
Nov 29 12:50:22.147: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 12:50:22.147: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 12:50:23.155: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 29 12:50:23.155: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
Nov 29 12:50:24.154: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 12:50:24.154: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 11/29/22 12:50:24.154
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:50:24.157
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6863, will wait for the garbage collector to delete the pods 11/29/22 12:50:24.157
Nov 29 12:50:24.213: INFO: Deleting DaemonSet.extensions daemon-set took: 3.681271ms
Nov 29 12:50:24.313: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.118242ms
Nov 29 12:50:26.616: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:50:26.616: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 29 12:50:26.618: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34457"},"items":null}

Nov 29 12:50:26.622: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34457"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:50:26.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6863" for this suite. 11/29/22 12:50:26.636
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":293,"skipped":5367,"failed":0}
------------------------------
• [SLOW TEST] [6.593 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:20.046
    Nov 29 12:50:20.046: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename daemonsets 11/29/22 12:50:20.047
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:20.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:20.056
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 11/29/22 12:50:20.074
    STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:50:20.077
    Nov 29 12:50:20.092: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:50:20.092: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:50:21.144: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:50:21.144: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:50:22.100: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 12:50:22.101: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/29/22 12:50:22.106
    Nov 29 12:50:22.147: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 12:50:22.147: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 12:50:23.155: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 29 12:50:23.155: INFO: Node dvi-7336-1669718118-vsp1-master-0 is running 0 daemon pod, expected 1
    Nov 29 12:50:24.154: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 12:50:24.154: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 11/29/22 12:50:24.154
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:50:24.157
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6863, will wait for the garbage collector to delete the pods 11/29/22 12:50:24.157
    Nov 29 12:50:24.213: INFO: Deleting DaemonSet.extensions daemon-set took: 3.681271ms
    Nov 29 12:50:24.313: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.118242ms
    Nov 29 12:50:26.616: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:50:26.616: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 29 12:50:26.618: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34457"},"items":null}

    Nov 29 12:50:26.622: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34457"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:50:26.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6863" for this suite. 11/29/22 12:50:26.636
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:26.64
Nov 29 12:50:26.640: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename events 11/29/22 12:50:26.641
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:26.649
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:26.651
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 11/29/22 12:50:26.653
STEP: listing all events in all namespaces 11/29/22 12:50:26.655
STEP: patching the test event 11/29/22 12:50:26.659
STEP: fetching the test event 11/29/22 12:50:26.662
STEP: updating the test event 11/29/22 12:50:26.669
STEP: getting the test event 11/29/22 12:50:26.674
STEP: deleting the test event 11/29/22 12:50:26.676
STEP: listing all events in all namespaces 11/29/22 12:50:26.68
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov 29 12:50:26.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1450" for this suite. 11/29/22 12:50:26.685
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":294,"skipped":5370,"failed":0}
------------------------------
• [0.048 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:26.64
    Nov 29 12:50:26.640: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename events 11/29/22 12:50:26.641
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:26.649
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:26.651
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 11/29/22 12:50:26.653
    STEP: listing all events in all namespaces 11/29/22 12:50:26.655
    STEP: patching the test event 11/29/22 12:50:26.659
    STEP: fetching the test event 11/29/22 12:50:26.662
    STEP: updating the test event 11/29/22 12:50:26.669
    STEP: getting the test event 11/29/22 12:50:26.674
    STEP: deleting the test event 11/29/22 12:50:26.676
    STEP: listing all events in all namespaces 11/29/22 12:50:26.68
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov 29 12:50:26.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1450" for this suite. 11/29/22 12:50:26.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:26.689
Nov 29 12:50:26.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-webhook 11/29/22 12:50:26.69
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:26.708
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:26.71
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/29/22 12:50:26.712
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/29/22 12:50:27.109
STEP: Deploying the custom resource conversion webhook pod 11/29/22 12:50:27.113
STEP: Wait for the deployment to be ready 11/29/22 12:50:27.121
Nov 29 12:50:27.144: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:50:29.151
STEP: Verifying the service has paired with the endpoint 11/29/22 12:50:29.173
Nov 29 12:50:30.174: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Nov 29 12:50:30.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Creating a v1 custom resource 11/29/22 12:50:32.777
STEP: v2 custom resource should be converted 11/29/22 12:50:32.78
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:50:33.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8065" for this suite. 11/29/22 12:50:33.301
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":295,"skipped":5377,"failed":0}
------------------------------
• [SLOW TEST] [6.654 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:26.689
    Nov 29 12:50:26.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-webhook 11/29/22 12:50:26.69
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:26.708
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:26.71
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/29/22 12:50:26.712
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/29/22 12:50:27.109
    STEP: Deploying the custom resource conversion webhook pod 11/29/22 12:50:27.113
    STEP: Wait for the deployment to be ready 11/29/22 12:50:27.121
    Nov 29 12:50:27.144: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:50:29.151
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:50:29.173
    Nov 29 12:50:30.174: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Nov 29 12:50:30.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Creating a v1 custom resource 11/29/22 12:50:32.777
    STEP: v2 custom resource should be converted 11/29/22 12:50:32.78
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:50:33.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-8065" for this suite. 11/29/22 12:50:33.301
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:33.344
Nov 29 12:50:33.344: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pod-network-test 11/29/22 12:50:33.345
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:33.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:33.359
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-8500 11/29/22 12:50:33.361
STEP: creating a selector 11/29/22 12:50:33.362
STEP: Creating the service pods in kubernetes 11/29/22 12:50:33.362
Nov 29 12:50:33.362: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 29 12:50:33.447: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8500" to be "running and ready"
Nov 29 12:50:33.458: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.909766ms
Nov 29 12:50:33.458: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:50:35.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.014577964s
Nov 29 12:50:35.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:37.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.015248116s
Nov 29 12:50:37.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:39.464: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.01717935s
Nov 29 12:50:39.464: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:41.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014800076s
Nov 29 12:50:41.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:43.461: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.014060731s
Nov 29 12:50:43.461: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:45.463: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.016322683s
Nov 29 12:50:45.464: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:47.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014833957s
Nov 29 12:50:47.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:49.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.01451918s
Nov 29 12:50:49.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:51.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014552607s
Nov 29 12:50:51.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:53.461: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013771004s
Nov 29 12:50:53.461: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 12:50:55.461: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.014116756s
Nov 29 12:50:55.461: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 29 12:50:55.461: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 29 12:50:55.463: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8500" to be "running and ready"
Nov 29 12:50:55.465: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 1.79248ms
Nov 29 12:50:55.465: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 29 12:50:55.465: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 29 12:50:55.467: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8500" to be "running and ready"
Nov 29 12:50:55.469: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 1.903477ms
Nov 29 12:50:55.469: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 29 12:50:55.469: INFO: Pod "netserver-2" satisfied condition "running and ready"
Nov 29 12:50:55.471: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-8500" to be "running and ready"
Nov 29 12:50:55.472: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 1.658465ms
Nov 29 12:50:55.472: INFO: The phase of Pod netserver-3 is Running (Ready = true)
Nov 29 12:50:55.472: INFO: Pod "netserver-3" satisfied condition "running and ready"
STEP: Creating test pods 11/29/22 12:50:55.474
Nov 29 12:50:55.481: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8500" to be "running"
Nov 29 12:50:55.484: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.596149ms
Nov 29 12:50:57.489: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007772148s
Nov 29 12:50:57.489: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 29 12:50:57.491: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-8500" to be "running"
Nov 29 12:50:57.492: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 1.75146ms
Nov 29 12:50:57.492: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov 29 12:50:57.494: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
Nov 29 12:50:57.494: INFO: Going to poll 100.96.1.153 on port 8083 at least 0 times, with a maximum of 46 tries before failing
Nov 29 12:50:57.496: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.153:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:50:57.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:50:57.497: INFO: ExecWithOptions: Clientset creation
Nov 29 12:50:57.497: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-8500/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.1.153%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 12:50:57.576: INFO: Found all 1 expected endpoints: [netserver-0]
Nov 29 12:50:57.576: INFO: Going to poll 100.96.3.98 on port 8083 at least 0 times, with a maximum of 46 tries before failing
Nov 29 12:50:57.578: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.3.98:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:50:57.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:50:57.579: INFO: ExecWithOptions: Clientset creation
Nov 29 12:50:57.579: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-8500/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.3.98%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 12:50:57.665: INFO: Found all 1 expected endpoints: [netserver-1]
Nov 29 12:50:57.665: INFO: Going to poll 100.96.2.31 on port 8083 at least 0 times, with a maximum of 46 tries before failing
Nov 29 12:50:57.670: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.2.31:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:50:57.671: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:50:57.671: INFO: ExecWithOptions: Clientset creation
Nov 29 12:50:57.671: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-8500/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.2.31%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 12:50:57.749: INFO: Found all 1 expected endpoints: [netserver-2]
Nov 29 12:50:57.749: INFO: Going to poll 100.96.0.78 on port 8083 at least 0 times, with a maximum of 46 tries before failing
Nov 29 12:50:57.753: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.78:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:50:57.753: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:50:57.754: INFO: ExecWithOptions: Clientset creation
Nov 29 12:50:57.754: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-8500/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.0.78%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 12:50:57.816: INFO: Found all 1 expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 29 12:50:57.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8500" for this suite. 11/29/22 12:50:57.82
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":296,"skipped":5385,"failed":0}
------------------------------
• [SLOW TEST] [24.480 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:33.344
    Nov 29 12:50:33.344: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pod-network-test 11/29/22 12:50:33.345
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:33.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:33.359
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-8500 11/29/22 12:50:33.361
    STEP: creating a selector 11/29/22 12:50:33.362
    STEP: Creating the service pods in kubernetes 11/29/22 12:50:33.362
    Nov 29 12:50:33.362: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 29 12:50:33.447: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8500" to be "running and ready"
    Nov 29 12:50:33.458: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.909766ms
    Nov 29 12:50:33.458: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:50:35.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.014577964s
    Nov 29 12:50:35.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:37.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.015248116s
    Nov 29 12:50:37.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:39.464: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.01717935s
    Nov 29 12:50:39.464: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:41.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014800076s
    Nov 29 12:50:41.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:43.461: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.014060731s
    Nov 29 12:50:43.461: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:45.463: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.016322683s
    Nov 29 12:50:45.464: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:47.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014833957s
    Nov 29 12:50:47.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:49.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.01451918s
    Nov 29 12:50:49.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:51.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014552607s
    Nov 29 12:50:51.462: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:53.461: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013771004s
    Nov 29 12:50:53.461: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 12:50:55.461: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.014116756s
    Nov 29 12:50:55.461: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 29 12:50:55.461: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 29 12:50:55.463: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8500" to be "running and ready"
    Nov 29 12:50:55.465: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 1.79248ms
    Nov 29 12:50:55.465: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 29 12:50:55.465: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 29 12:50:55.467: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8500" to be "running and ready"
    Nov 29 12:50:55.469: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 1.903477ms
    Nov 29 12:50:55.469: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 29 12:50:55.469: INFO: Pod "netserver-2" satisfied condition "running and ready"
    Nov 29 12:50:55.471: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-8500" to be "running and ready"
    Nov 29 12:50:55.472: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 1.658465ms
    Nov 29 12:50:55.472: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    Nov 29 12:50:55.472: INFO: Pod "netserver-3" satisfied condition "running and ready"
    STEP: Creating test pods 11/29/22 12:50:55.474
    Nov 29 12:50:55.481: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8500" to be "running"
    Nov 29 12:50:55.484: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.596149ms
    Nov 29 12:50:57.489: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007772148s
    Nov 29 12:50:57.489: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 29 12:50:57.491: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-8500" to be "running"
    Nov 29 12:50:57.492: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 1.75146ms
    Nov 29 12:50:57.492: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov 29 12:50:57.494: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
    Nov 29 12:50:57.494: INFO: Going to poll 100.96.1.153 on port 8083 at least 0 times, with a maximum of 46 tries before failing
    Nov 29 12:50:57.496: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.153:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:50:57.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:50:57.497: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:50:57.497: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-8500/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.1.153%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 12:50:57.576: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov 29 12:50:57.576: INFO: Going to poll 100.96.3.98 on port 8083 at least 0 times, with a maximum of 46 tries before failing
    Nov 29 12:50:57.578: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.3.98:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:50:57.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:50:57.579: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:50:57.579: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-8500/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.3.98%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 12:50:57.665: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov 29 12:50:57.665: INFO: Going to poll 100.96.2.31 on port 8083 at least 0 times, with a maximum of 46 tries before failing
    Nov 29 12:50:57.670: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.2.31:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:50:57.671: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:50:57.671: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:50:57.671: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-8500/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.2.31%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 12:50:57.749: INFO: Found all 1 expected endpoints: [netserver-2]
    Nov 29 12:50:57.749: INFO: Going to poll 100.96.0.78 on port 8083 at least 0 times, with a maximum of 46 tries before failing
    Nov 29 12:50:57.753: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.78:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:50:57.753: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:50:57.754: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:50:57.754: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-8500/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.0.78%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 12:50:57.816: INFO: Found all 1 expected endpoints: [netserver-3]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 29 12:50:57.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-8500" for this suite. 11/29/22 12:50:57.82
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:50:57.824
Nov 29 12:50:57.824: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename webhook 11/29/22 12:50:57.825
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:57.833
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:57.835
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/29/22 12:50:57.858
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:50:58.358
STEP: Deploying the webhook pod 11/29/22 12:50:58.363
STEP: Wait for the deployment to be ready 11/29/22 12:50:58.37
Nov 29 12:50:58.388: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/29/22 12:51:00.399
STEP: Verifying the service has paired with the endpoint 11/29/22 12:51:00.413
Nov 29 12:51:01.413: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Nov 29 12:51:01.416: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/29/22 12:51:01.924
STEP: Creating a custom resource that should be denied by the webhook 11/29/22 12:51:01.935
STEP: Creating a custom resource whose deletion would be denied by the webhook 11/29/22 12:51:03.977
STEP: Updating the custom resource with disallowed data should be denied 11/29/22 12:51:04.188
STEP: Deleting the custom resource should be denied 11/29/22 12:51:04.194
STEP: Remove the offending key and value from the custom resource data 11/29/22 12:51:04.199
STEP: Deleting the updated custom resource should be successful 11/29/22 12:51:04.205
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:51:04.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7693" for this suite. 11/29/22 12:51:04.732
STEP: Destroying namespace "webhook-7693-markers" for this suite. 11/29/22 12:51:04.735
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":297,"skipped":5385,"failed":0}
------------------------------
• [SLOW TEST] [6.943 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:50:57.824
    Nov 29 12:50:57.824: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename webhook 11/29/22 12:50:57.825
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:50:57.833
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:50:57.835
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/29/22 12:50:57.858
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/29/22 12:50:58.358
    STEP: Deploying the webhook pod 11/29/22 12:50:58.363
    STEP: Wait for the deployment to be ready 11/29/22 12:50:58.37
    Nov 29 12:50:58.388: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/29/22 12:51:00.399
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:51:00.413
    Nov 29 12:51:01.413: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Nov 29 12:51:01.416: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/29/22 12:51:01.924
    STEP: Creating a custom resource that should be denied by the webhook 11/29/22 12:51:01.935
    STEP: Creating a custom resource whose deletion would be denied by the webhook 11/29/22 12:51:03.977
    STEP: Updating the custom resource with disallowed data should be denied 11/29/22 12:51:04.188
    STEP: Deleting the custom resource should be denied 11/29/22 12:51:04.194
    STEP: Remove the offending key and value from the custom resource data 11/29/22 12:51:04.199
    STEP: Deleting the updated custom resource should be successful 11/29/22 12:51:04.205
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:51:04.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7693" for this suite. 11/29/22 12:51:04.732
    STEP: Destroying namespace "webhook-7693-markers" for this suite. 11/29/22 12:51:04.735
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:04.772
Nov 29 12:51:04.772: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:51:04.774
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:04.857
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:04.86
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:51:04.872
Nov 29 12:51:04.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768" in namespace "downward-api-5806" to be "Succeeded or Failed"
Nov 29 12:51:04.890: INFO: Pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768": Phase="Pending", Reason="", readiness=false. Elapsed: 10.999405ms
Nov 29 12:51:06.892: INFO: Pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013866702s
Nov 29 12:51:08.894: INFO: Pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015180406s
STEP: Saw pod success 11/29/22 12:51:08.894
Nov 29 12:51:08.894: INFO: Pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768" satisfied condition "Succeeded or Failed"
Nov 29 12:51:08.896: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768 container client-container: <nil>
STEP: delete the pod 11/29/22 12:51:08.901
Nov 29 12:51:08.906: INFO: Waiting for pod downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768 to disappear
Nov 29 12:51:08.909: INFO: Pod downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:51:08.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5806" for this suite. 11/29/22 12:51:08.911
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":298,"skipped":5399,"failed":0}
------------------------------
• [4.143 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:04.772
    Nov 29 12:51:04.772: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:51:04.774
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:04.857
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:04.86
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:51:04.872
    Nov 29 12:51:04.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768" in namespace "downward-api-5806" to be "Succeeded or Failed"
    Nov 29 12:51:04.890: INFO: Pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768": Phase="Pending", Reason="", readiness=false. Elapsed: 10.999405ms
    Nov 29 12:51:06.892: INFO: Pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013866702s
    Nov 29 12:51:08.894: INFO: Pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015180406s
    STEP: Saw pod success 11/29/22 12:51:08.894
    Nov 29 12:51:08.894: INFO: Pod "downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768" satisfied condition "Succeeded or Failed"
    Nov 29 12:51:08.896: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:51:08.901
    Nov 29 12:51:08.906: INFO: Waiting for pod downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768 to disappear
    Nov 29 12:51:08.909: INFO: Pod downwardapi-volume-98e91842-7cb0-4bf1-a8a1-dfefbcf93768 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:51:08.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5806" for this suite. 11/29/22 12:51:08.911
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:08.917
Nov 29 12:51:08.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename podtemplate 11/29/22 12:51:08.918
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:08.927
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:08.929
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 11/29/22 12:51:08.931
Nov 29 12:51:08.933: INFO: created test-podtemplate-1
Nov 29 12:51:08.936: INFO: created test-podtemplate-2
Nov 29 12:51:08.938: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 11/29/22 12:51:08.938
STEP: delete collection of pod templates 11/29/22 12:51:08.939
Nov 29 12:51:08.939: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 11/29/22 12:51:08.958
Nov 29 12:51:08.958: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 29 12:51:08.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6631" for this suite. 11/29/22 12:51:08.966
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":299,"skipped":5422,"failed":0}
------------------------------
• [0.052 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:08.917
    Nov 29 12:51:08.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename podtemplate 11/29/22 12:51:08.918
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:08.927
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:08.929
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 11/29/22 12:51:08.931
    Nov 29 12:51:08.933: INFO: created test-podtemplate-1
    Nov 29 12:51:08.936: INFO: created test-podtemplate-2
    Nov 29 12:51:08.938: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 11/29/22 12:51:08.938
    STEP: delete collection of pod templates 11/29/22 12:51:08.939
    Nov 29 12:51:08.939: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 11/29/22 12:51:08.958
    Nov 29 12:51:08.958: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 29 12:51:08.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-6631" for this suite. 11/29/22 12:51:08.966
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:08.97
Nov 29 12:51:08.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename job 11/29/22 12:51:08.971
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:08.979
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:08.985
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 11/29/22 12:51:08.989
STEP: Patching the Job 11/29/22 12:51:08.992
STEP: Watching for Job to be patched 11/29/22 12:51:09.005
Nov 29 12:51:09.007: INFO: Event ADDED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67] and annotations: map[batch.kubernetes.io/job-tracking:]
Nov 29 12:51:09.007: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67] and annotations: map[batch.kubernetes.io/job-tracking:]
Nov 29 12:51:09.007: INFO: Event MODIFIED found for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 11/29/22 12:51:09.007
STEP: Watching for Job to be updated 11/29/22 12:51:09.014
Nov 29 12:51:09.016: INFO: Event MODIFIED found for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:09.016: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 11/29/22 12:51:09.016
Nov 29 12:51:09.018: INFO: Job: e2e-srt67 as labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched]
STEP: Waiting for job to complete 11/29/22 12:51:09.018
STEP: Delete a job collection with a labelselector 11/29/22 12:51:17.022
STEP: Watching for Job to be deleted 11/29/22 12:51:17.033
Nov 29 12:51:17.035: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.035: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.035: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 29 12:51:17.036: INFO: Event DELETED found for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 11/29/22 12:51:17.036
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 29 12:51:17.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3418" for this suite. 11/29/22 12:51:17.051
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":300,"skipped":5436,"failed":0}
------------------------------
• [SLOW TEST] [8.092 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:08.97
    Nov 29 12:51:08.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename job 11/29/22 12:51:08.971
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:08.979
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:08.985
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 11/29/22 12:51:08.989
    STEP: Patching the Job 11/29/22 12:51:08.992
    STEP: Watching for Job to be patched 11/29/22 12:51:09.005
    Nov 29 12:51:09.007: INFO: Event ADDED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67] and annotations: map[batch.kubernetes.io/job-tracking:]
    Nov 29 12:51:09.007: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67] and annotations: map[batch.kubernetes.io/job-tracking:]
    Nov 29 12:51:09.007: INFO: Event MODIFIED found for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 11/29/22 12:51:09.007
    STEP: Watching for Job to be updated 11/29/22 12:51:09.014
    Nov 29 12:51:09.016: INFO: Event MODIFIED found for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:09.016: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 11/29/22 12:51:09.016
    Nov 29 12:51:09.018: INFO: Job: e2e-srt67 as labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched]
    STEP: Waiting for job to complete 11/29/22 12:51:09.018
    STEP: Delete a job collection with a labelselector 11/29/22 12:51:17.022
    STEP: Watching for Job to be deleted 11/29/22 12:51:17.033
    Nov 29 12:51:17.035: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.035: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.035: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.036: INFO: Event MODIFIED observed for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 29 12:51:17.036: INFO: Event DELETED found for Job e2e-srt67 in namespace job-3418 with labels: map[e2e-job-label:e2e-srt67 e2e-srt67:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 11/29/22 12:51:17.036
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 29 12:51:17.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3418" for this suite. 11/29/22 12:51:17.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:17.062
Nov 29 12:51:17.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 12:51:17.063
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:17.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:17.074
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Nov 29 12:51:17.076: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:51:20.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1292" for this suite. 11/29/22 12:51:20.219
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":301,"skipped":5444,"failed":0}
------------------------------
• [3.161 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:17.062
    Nov 29 12:51:17.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename custom-resource-definition 11/29/22 12:51:17.063
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:17.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:17.074
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Nov 29 12:51:17.076: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:51:20.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1292" for this suite. 11/29/22 12:51:20.219
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:20.224
Nov 29 12:51:20.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 12:51:20.225
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:20.237
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:20.24
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-ae480789-7146-4b2f-899a-a11863473473 11/29/22 12:51:20.27
STEP: Creating a pod to test consume secrets 11/29/22 12:51:20.275
Nov 29 12:51:20.280: INFO: Waiting up to 5m0s for pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd" in namespace "secrets-6506" to be "Succeeded or Failed"
Nov 29 12:51:20.286: INFO: Pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.36899ms
Nov 29 12:51:22.291: INFO: Pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011267278s
Nov 29 12:51:24.291: INFO: Pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011232257s
STEP: Saw pod success 11/29/22 12:51:24.291
Nov 29 12:51:24.291: INFO: Pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd" satisfied condition "Succeeded or Failed"
Nov 29 12:51:24.294: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd container secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:51:24.3
Nov 29 12:51:24.307: INFO: Waiting for pod pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd to disappear
Nov 29 12:51:24.310: INFO: Pod pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 12:51:24.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6506" for this suite. 11/29/22 12:51:24.315
STEP: Destroying namespace "secret-namespace-899" for this suite. 11/29/22 12:51:24.321
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":302,"skipped":5462,"failed":0}
------------------------------
• [4.101 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:20.224
    Nov 29 12:51:20.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 12:51:20.225
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:20.237
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:20.24
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-ae480789-7146-4b2f-899a-a11863473473 11/29/22 12:51:20.27
    STEP: Creating a pod to test consume secrets 11/29/22 12:51:20.275
    Nov 29 12:51:20.280: INFO: Waiting up to 5m0s for pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd" in namespace "secrets-6506" to be "Succeeded or Failed"
    Nov 29 12:51:20.286: INFO: Pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.36899ms
    Nov 29 12:51:22.291: INFO: Pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011267278s
    Nov 29 12:51:24.291: INFO: Pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011232257s
    STEP: Saw pod success 11/29/22 12:51:24.291
    Nov 29 12:51:24.291: INFO: Pod "pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd" satisfied condition "Succeeded or Failed"
    Nov 29 12:51:24.294: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd container secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:51:24.3
    Nov 29 12:51:24.307: INFO: Waiting for pod pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd to disappear
    Nov 29 12:51:24.310: INFO: Pod pod-secrets-b18a5400-d3ff-464c-8581-3dc5ff39cacd no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 12:51:24.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6506" for this suite. 11/29/22 12:51:24.315
    STEP: Destroying namespace "secret-namespace-899" for this suite. 11/29/22 12:51:24.321
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:24.327
Nov 29 12:51:24.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:51:24.328
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:24.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:24.339
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/29/22 12:51:24.342
Nov 29 12:51:24.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-3780 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Nov 29 12:51:24.415: INFO: stderr: ""
Nov 29 12:51:24.415: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 11/29/22 12:51:24.415
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Nov 29 12:51:24.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-3780 delete pods e2e-test-httpd-pod'
Nov 29 12:51:26.905: INFO: stderr: ""
Nov 29 12:51:26.905: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:51:26.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3780" for this suite. 11/29/22 12:51:26.913
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":303,"skipped":5466,"failed":0}
------------------------------
• [2.590 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:24.327
    Nov 29 12:51:24.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:51:24.328
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:24.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:24.339
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/29/22 12:51:24.342
    Nov 29 12:51:24.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-3780 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Nov 29 12:51:24.415: INFO: stderr: ""
    Nov 29 12:51:24.415: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 11/29/22 12:51:24.415
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Nov 29 12:51:24.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-3780 delete pods e2e-test-httpd-pod'
    Nov 29 12:51:26.905: INFO: stderr: ""
    Nov 29 12:51:26.905: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:51:26.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3780" for this suite. 11/29/22 12:51:26.913
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:26.917
Nov 29 12:51:26.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename discovery 11/29/22 12:51:26.918
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:26.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:26.928
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 11/29/22 12:51:26.941
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Nov 29 12:51:27.352: INFO: Checking APIGroup: apiregistration.k8s.io
Nov 29 12:51:27.353: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Nov 29 12:51:27.353: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Nov 29 12:51:27.353: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Nov 29 12:51:27.353: INFO: Checking APIGroup: apps
Nov 29 12:51:27.354: INFO: PreferredVersion.GroupVersion: apps/v1
Nov 29 12:51:27.354: INFO: Versions found [{apps/v1 v1}]
Nov 29 12:51:27.354: INFO: apps/v1 matches apps/v1
Nov 29 12:51:27.354: INFO: Checking APIGroup: events.k8s.io
Nov 29 12:51:27.355: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Nov 29 12:51:27.355: INFO: Versions found [{events.k8s.io/v1 v1}]
Nov 29 12:51:27.355: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Nov 29 12:51:27.355: INFO: Checking APIGroup: authentication.k8s.io
Nov 29 12:51:27.356: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Nov 29 12:51:27.356: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Nov 29 12:51:27.356: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Nov 29 12:51:27.356: INFO: Checking APIGroup: authorization.k8s.io
Nov 29 12:51:27.357: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Nov 29 12:51:27.357: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Nov 29 12:51:27.357: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Nov 29 12:51:27.357: INFO: Checking APIGroup: autoscaling
Nov 29 12:51:27.357: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Nov 29 12:51:27.357: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Nov 29 12:51:27.357: INFO: autoscaling/v2 matches autoscaling/v2
Nov 29 12:51:27.357: INFO: Checking APIGroup: batch
Nov 29 12:51:27.358: INFO: PreferredVersion.GroupVersion: batch/v1
Nov 29 12:51:27.358: INFO: Versions found [{batch/v1 v1}]
Nov 29 12:51:27.358: INFO: batch/v1 matches batch/v1
Nov 29 12:51:27.358: INFO: Checking APIGroup: certificates.k8s.io
Nov 29 12:51:27.358: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Nov 29 12:51:27.359: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Nov 29 12:51:27.359: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Nov 29 12:51:27.359: INFO: Checking APIGroup: networking.k8s.io
Nov 29 12:51:27.359: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Nov 29 12:51:27.359: INFO: Versions found [{networking.k8s.io/v1 v1}]
Nov 29 12:51:27.359: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Nov 29 12:51:27.359: INFO: Checking APIGroup: policy
Nov 29 12:51:27.360: INFO: PreferredVersion.GroupVersion: policy/v1
Nov 29 12:51:27.360: INFO: Versions found [{policy/v1 v1}]
Nov 29 12:51:27.360: INFO: policy/v1 matches policy/v1
Nov 29 12:51:27.360: INFO: Checking APIGroup: rbac.authorization.k8s.io
Nov 29 12:51:27.360: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Nov 29 12:51:27.360: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Nov 29 12:51:27.360: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Nov 29 12:51:27.360: INFO: Checking APIGroup: storage.k8s.io
Nov 29 12:51:27.361: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Nov 29 12:51:27.361: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Nov 29 12:51:27.361: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Nov 29 12:51:27.361: INFO: Checking APIGroup: admissionregistration.k8s.io
Nov 29 12:51:27.362: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Nov 29 12:51:27.362: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Nov 29 12:51:27.362: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Nov 29 12:51:27.362: INFO: Checking APIGroup: apiextensions.k8s.io
Nov 29 12:51:27.362: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Nov 29 12:51:27.362: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Nov 29 12:51:27.362: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Nov 29 12:51:27.362: INFO: Checking APIGroup: scheduling.k8s.io
Nov 29 12:51:27.363: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Nov 29 12:51:27.363: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Nov 29 12:51:27.363: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Nov 29 12:51:27.363: INFO: Checking APIGroup: coordination.k8s.io
Nov 29 12:51:27.364: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Nov 29 12:51:27.364: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Nov 29 12:51:27.364: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Nov 29 12:51:27.364: INFO: Checking APIGroup: node.k8s.io
Nov 29 12:51:27.364: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Nov 29 12:51:27.364: INFO: Versions found [{node.k8s.io/v1 v1}]
Nov 29 12:51:27.364: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Nov 29 12:51:27.364: INFO: Checking APIGroup: discovery.k8s.io
Nov 29 12:51:27.365: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Nov 29 12:51:27.365: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Nov 29 12:51:27.365: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Nov 29 12:51:27.365: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Nov 29 12:51:27.365: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Nov 29 12:51:27.365: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Nov 29 12:51:27.365: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Nov 29 12:51:27.365: INFO: Checking APIGroup: core.kublr.io
Nov 29 12:51:27.366: INFO: PreferredVersion.GroupVersion: core.kublr.io/v1
Nov 29 12:51:27.366: INFO: Versions found [{core.kublr.io/v1 v1}]
Nov 29 12:51:27.366: INFO: core.kublr.io/v1 matches core.kublr.io/v1
Nov 29 12:51:27.366: INFO: Checking APIGroup: crd.projectcalico.org
Nov 29 12:51:27.367: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Nov 29 12:51:27.367: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Nov 29 12:51:27.367: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Nov 29 12:51:27.367: INFO: Checking APIGroup: feature.crd.kublr.com
Nov 29 12:51:27.367: INFO: PreferredVersion.GroupVersion: feature.crd.kublr.com/v1
Nov 29 12:51:27.367: INFO: Versions found [{feature.crd.kublr.com/v1 v1}]
Nov 29 12:51:27.367: INFO: feature.crd.kublr.com/v1 matches feature.crd.kublr.com/v1
Nov 29 12:51:27.367: INFO: Checking APIGroup: metrics.k8s.io
Nov 29 12:51:27.368: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Nov 29 12:51:27.368: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Nov 29 12:51:27.368: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Nov 29 12:51:27.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-9322" for this suite. 11/29/22 12:51:27.371
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":304,"skipped":5486,"failed":0}
------------------------------
• [0.458 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:26.917
    Nov 29 12:51:26.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename discovery 11/29/22 12:51:26.918
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:26.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:26.928
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 11/29/22 12:51:26.941
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Nov 29 12:51:27.352: INFO: Checking APIGroup: apiregistration.k8s.io
    Nov 29 12:51:27.353: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Nov 29 12:51:27.353: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Nov 29 12:51:27.353: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Nov 29 12:51:27.353: INFO: Checking APIGroup: apps
    Nov 29 12:51:27.354: INFO: PreferredVersion.GroupVersion: apps/v1
    Nov 29 12:51:27.354: INFO: Versions found [{apps/v1 v1}]
    Nov 29 12:51:27.354: INFO: apps/v1 matches apps/v1
    Nov 29 12:51:27.354: INFO: Checking APIGroup: events.k8s.io
    Nov 29 12:51:27.355: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Nov 29 12:51:27.355: INFO: Versions found [{events.k8s.io/v1 v1}]
    Nov 29 12:51:27.355: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Nov 29 12:51:27.355: INFO: Checking APIGroup: authentication.k8s.io
    Nov 29 12:51:27.356: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Nov 29 12:51:27.356: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Nov 29 12:51:27.356: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Nov 29 12:51:27.356: INFO: Checking APIGroup: authorization.k8s.io
    Nov 29 12:51:27.357: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Nov 29 12:51:27.357: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Nov 29 12:51:27.357: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Nov 29 12:51:27.357: INFO: Checking APIGroup: autoscaling
    Nov 29 12:51:27.357: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Nov 29 12:51:27.357: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Nov 29 12:51:27.357: INFO: autoscaling/v2 matches autoscaling/v2
    Nov 29 12:51:27.357: INFO: Checking APIGroup: batch
    Nov 29 12:51:27.358: INFO: PreferredVersion.GroupVersion: batch/v1
    Nov 29 12:51:27.358: INFO: Versions found [{batch/v1 v1}]
    Nov 29 12:51:27.358: INFO: batch/v1 matches batch/v1
    Nov 29 12:51:27.358: INFO: Checking APIGroup: certificates.k8s.io
    Nov 29 12:51:27.358: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Nov 29 12:51:27.359: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Nov 29 12:51:27.359: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Nov 29 12:51:27.359: INFO: Checking APIGroup: networking.k8s.io
    Nov 29 12:51:27.359: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Nov 29 12:51:27.359: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Nov 29 12:51:27.359: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Nov 29 12:51:27.359: INFO: Checking APIGroup: policy
    Nov 29 12:51:27.360: INFO: PreferredVersion.GroupVersion: policy/v1
    Nov 29 12:51:27.360: INFO: Versions found [{policy/v1 v1}]
    Nov 29 12:51:27.360: INFO: policy/v1 matches policy/v1
    Nov 29 12:51:27.360: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Nov 29 12:51:27.360: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Nov 29 12:51:27.360: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Nov 29 12:51:27.360: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Nov 29 12:51:27.360: INFO: Checking APIGroup: storage.k8s.io
    Nov 29 12:51:27.361: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Nov 29 12:51:27.361: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Nov 29 12:51:27.361: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Nov 29 12:51:27.361: INFO: Checking APIGroup: admissionregistration.k8s.io
    Nov 29 12:51:27.362: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Nov 29 12:51:27.362: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Nov 29 12:51:27.362: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Nov 29 12:51:27.362: INFO: Checking APIGroup: apiextensions.k8s.io
    Nov 29 12:51:27.362: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Nov 29 12:51:27.362: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Nov 29 12:51:27.362: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Nov 29 12:51:27.362: INFO: Checking APIGroup: scheduling.k8s.io
    Nov 29 12:51:27.363: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Nov 29 12:51:27.363: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Nov 29 12:51:27.363: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Nov 29 12:51:27.363: INFO: Checking APIGroup: coordination.k8s.io
    Nov 29 12:51:27.364: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Nov 29 12:51:27.364: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Nov 29 12:51:27.364: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Nov 29 12:51:27.364: INFO: Checking APIGroup: node.k8s.io
    Nov 29 12:51:27.364: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Nov 29 12:51:27.364: INFO: Versions found [{node.k8s.io/v1 v1}]
    Nov 29 12:51:27.364: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Nov 29 12:51:27.364: INFO: Checking APIGroup: discovery.k8s.io
    Nov 29 12:51:27.365: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Nov 29 12:51:27.365: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Nov 29 12:51:27.365: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Nov 29 12:51:27.365: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Nov 29 12:51:27.365: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Nov 29 12:51:27.365: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Nov 29 12:51:27.365: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Nov 29 12:51:27.365: INFO: Checking APIGroup: core.kublr.io
    Nov 29 12:51:27.366: INFO: PreferredVersion.GroupVersion: core.kublr.io/v1
    Nov 29 12:51:27.366: INFO: Versions found [{core.kublr.io/v1 v1}]
    Nov 29 12:51:27.366: INFO: core.kublr.io/v1 matches core.kublr.io/v1
    Nov 29 12:51:27.366: INFO: Checking APIGroup: crd.projectcalico.org
    Nov 29 12:51:27.367: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Nov 29 12:51:27.367: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Nov 29 12:51:27.367: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Nov 29 12:51:27.367: INFO: Checking APIGroup: feature.crd.kublr.com
    Nov 29 12:51:27.367: INFO: PreferredVersion.GroupVersion: feature.crd.kublr.com/v1
    Nov 29 12:51:27.367: INFO: Versions found [{feature.crd.kublr.com/v1 v1}]
    Nov 29 12:51:27.367: INFO: feature.crd.kublr.com/v1 matches feature.crd.kublr.com/v1
    Nov 29 12:51:27.367: INFO: Checking APIGroup: metrics.k8s.io
    Nov 29 12:51:27.368: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Nov 29 12:51:27.368: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Nov 29 12:51:27.368: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Nov 29 12:51:27.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-9322" for this suite. 11/29/22 12:51:27.371
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:27.377
Nov 29 12:51:27.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename deployment 11/29/22 12:51:27.378
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:27.392
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:27.395
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Nov 29 12:51:27.398: INFO: Creating deployment "webserver-deployment"
Nov 29 12:51:27.407: INFO: Waiting for observed generation 1
Nov 29 12:51:29.421: INFO: Waiting for all required pods to come up
Nov 29 12:51:29.425: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 11/29/22 12:51:29.425
Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-x6t6f" in namespace "deployment-3062" to be "running"
Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-9f2qr" in namespace "deployment-3062" to be "running"
Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-gds57" in namespace "deployment-3062" to be "running"
Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ddp8g" in namespace "deployment-3062" to be "running"
Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hkfqg" in namespace "deployment-3062" to be "running"
Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-kdskk" in namespace "deployment-3062" to be "running"
Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-x5g86" in namespace "deployment-3062" to be "running"
Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7blwn" in namespace "deployment-3062" to be "running"
Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-x5g86": Phase="Pending", Reason="", readiness=false. Elapsed: 3.619901ms
Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-9f2qr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05987ms
Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-7blwn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.74632ms
Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-gds57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.20829ms
Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-kdskk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.99865ms
Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-ddp8g": Phase="Pending", Reason="", readiness=false. Elapsed: 4.153257ms
Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-hkfqg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.442785ms
Nov 29 12:51:29.430: INFO: Pod "webserver-deployment-845c8977d9-x6t6f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.937938ms
Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-kdskk": Phase="Running", Reason="", readiness=true. Elapsed: 2.008013502s
Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-kdskk" satisfied condition "running"
Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-x6t6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.008317073s
Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-x6t6f" satisfied condition "running"
Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-9f2qr": Phase="Running", Reason="", readiness=true. Elapsed: 2.008348703s
Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-9f2qr" satisfied condition "running"
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-x5g86": Phase="Running", Reason="", readiness=true. Elapsed: 2.00864936s
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-x5g86" satisfied condition "running"
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-hkfqg": Phase="Running", Reason="", readiness=true. Elapsed: 2.008950258s
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-hkfqg" satisfied condition "running"
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-gds57": Phase="Running", Reason="", readiness=true. Elapsed: 2.009282427s
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-gds57" satisfied condition "running"
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-ddp8g": Phase="Running", Reason="", readiness=true. Elapsed: 2.009218499s
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-ddp8g" satisfied condition "running"
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-7blwn": Phase="Running", Reason="", readiness=true. Elapsed: 2.008984742s
Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-7blwn" satisfied condition "running"
Nov 29 12:51:31.434: INFO: Waiting for deployment "webserver-deployment" to complete
Nov 29 12:51:31.438: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov 29 12:51:31.444: INFO: Updating deployment webserver-deployment
Nov 29 12:51:31.444: INFO: Waiting for observed generation 2
Nov 29 12:51:33.465: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 29 12:51:33.469: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 29 12:51:33.473: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 29 12:51:33.480: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 29 12:51:33.480: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 29 12:51:33.482: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 29 12:51:33.484: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov 29 12:51:33.485: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov 29 12:51:33.491: INFO: Updating deployment webserver-deployment
Nov 29 12:51:33.491: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov 29 12:51:33.510: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 29 12:51:35.745: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 29 12:51:36.802: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-3062  f92ec754-9e28-4f62-a18d-a3f7862954f2 35436 3 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003311338 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-29 12:51:33 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-29 12:51:33 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov 29 12:51:36.810: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-3062  5a0da8fc-870d-426f-a5d4-a83b38d139c5 35435 3 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment f92ec754-9e28-4f62-a18d-a3f7862954f2 0xc003311747 0xc003311748}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f92ec754-9e28-4f62-a18d-a3f7862954f2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0033117e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 29 12:51:36.810: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov 29 12:51:36.810: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-3062  330c377c-48aa-4a72-8149-a91e116d9e88 35415 3 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment f92ec754-9e28-4f62-a18d-a3f7862954f2 0xc003311847 0xc003311848}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f92ec754-9e28-4f62-a18d-a3f7862954f2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0033118d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov 29 12:51:37.083: INFO: Pod "webserver-deployment-69b7448995-2r678" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-2r678 webserver-deployment-69b7448995- deployment-3062  19623ce2-3448-4ff8-bc02-7e4efd58e2fa 35344 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:1fa576a1f6d7eb2ac249f86730ab2b79f0969672061ac4b60b5cd78276e4c97a cni.projectcalico.org/podIP:100.96.3.101/32 cni.projectcalico.org/podIPs:100.96.3.101/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc00389ff37 0xc00389ff38}] [] [{calico Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.101\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dcfcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dcfcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:100.96.3.101,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.083: INFO: Pod "webserver-deployment-69b7448995-5lbz2" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-5lbz2 webserver-deployment-69b7448995- deployment-3062  61f96d64-f4d7-416b-a989-5aef9cf78b8d 35481 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:3719dc99da0bdc6cc666d6171246d69f567be0fd3b5992d60ddf1dd9ab27e911 cni.projectcalico.org/podIP:100.96.1.162/32 cni.projectcalico.org/podIPs:100.96.1.162/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90177 0xc003d90178}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-252vb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-252vb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.084: INFO: Pod "webserver-deployment-69b7448995-74qrc" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-74qrc webserver-deployment-69b7448995- deployment-3062  7bcf0e1b-b038-494f-bd76-6401cfd1e166 35444 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90377 0xc003d90378}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-47c67,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-47c67,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.084: INFO: Pod "webserver-deployment-69b7448995-7wb2b" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7wb2b webserver-deployment-69b7448995- deployment-3062  d5c61e96-c4e5-47ac-8485-3fc7154d9304 35437 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90557 0xc003d90558}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kv4bk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kv4bk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.084: INFO: Pod "webserver-deployment-69b7448995-8kxt6" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-8kxt6 webserver-deployment-69b7448995- deployment-3062  fdc187e2-7ef2-40fa-8363-a83e6edfbcba 35312 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:a193c006374c9633f9139c83a66520a8f05c74a12cb5f9aabec8eccdd8536af4 cni.projectcalico.org/podIP:100.96.2.43/32 cni.projectcalico.org/podIPs:100.96.2.43/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90757 0xc003d90758}] [] [{calico Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dhl6c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dhl6c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-bp4bp" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-bp4bp webserver-deployment-69b7448995- deployment-3062  bf83136f-b05c-4fa1-9660-30911c7f9986 35494 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:c945f53a7b75c4cb1dd147bc45abe4d5b67b9cd27515676331ea6a96f6214317 cni.projectcalico.org/podIP:100.96.0.81/32 cni.projectcalico.org/podIPs:100.96.0.81/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90967 0xc003d90968}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.81\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dqg5n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dqg5n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:100.96.0.81,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-f6854" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-f6854 webserver-deployment-69b7448995- deployment-3062  e9aee89e-52e5-488e-ba30-9274d42910e6 35505 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:c15e206bc4ebe4586f26cf1524b31601ddb6308536b8ba37ebec712984996fe7 cni.projectcalico.org/podIP:100.96.0.82/32 cni.projectcalico.org/podIPs:100.96.0.82/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90bb0 0xc003d90bb1}] [] [{calico Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sfcvm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sfcvm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:100.96.0.82,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-fpqd9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fpqd9 webserver-deployment-69b7448995- deployment-3062  3c3d19ff-0300-41a9-bb98-dd413f9ef22a 35476 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0fd2d8a143369db61f0650f06a8ea3231afc78e116f83ad0f56e7e9a9f4d331f cni.projectcalico.org/podIP:100.96.1.158/32 cni.projectcalico.org/podIPs:100.96.1.158/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90df0 0xc003d90df1}] [] [{calico Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2cq9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2cq9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:100.96.1.158,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-kmfsl" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-kmfsl webserver-deployment-69b7448995- deployment-3062  a9c695ef-e149-4acd-981a-e3d456d03c90 35463 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ff29c8f47809c8dbca0d54e9eaed60d1a00120bf08fcea5e59cbd6768868c692 cni.projectcalico.org/podIP:100.96.1.160/32 cni.projectcalico.org/podIPs:100.96.1.160/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91037 0xc003d91038}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fppgf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fppgf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-l9sfq" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-l9sfq webserver-deployment-69b7448995- deployment-3062  2e88ee37-6f8f-42d8-98aa-b419ac018aa9 35441 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91237 0xc003d91238}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cshzp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cshzp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-69b7448995-n8rnt" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-n8rnt webserver-deployment-69b7448995- deployment-3062  41a96612-b1ce-41a9-9424-fa79c16540d7 35496 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91417 0xc003d91418}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4c46,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4c46,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-69b7448995-sg9rp" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sg9rp webserver-deployment-69b7448995- deployment-3062  28510009-facd-425b-b465-dab2aafb672b 35506 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:24431ca3efd31998cdaadd8d03109df46706db5ea088d554882a85d36e7c045d cni.projectcalico.org/podIP:100.96.2.44/32 cni.projectcalico.org/podIPs:100.96.2.44/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91617 0xc003d91618}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.44\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29dnd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29dnd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.44,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-69b7448995-vd9tq" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-vd9tq webserver-deployment-69b7448995- deployment-3062  0402eafd-482d-47af-973d-4d582786772c 35450 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91840 0xc003d91841}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-skb2z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-skb2z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-845c8977d9-4j4p4" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4j4p4 webserver-deployment-845c8977d9- deployment-3062  f92feae0-22e8-48ce-ac7a-df1a9a6f2c3f 35472 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ba2e00707a3d86c3799a45b55d6f9a3ee11dd005a10489a0de9aeffb9aa3974d cni.projectcalico.org/podIP:100.96.3.102/32 cni.projectcalico.org/podIPs:100.96.3.102/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc003d91a37 0xc003d91a38}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6nqzd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6nqzd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-845c8977d9-65s8n" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-65s8n webserver-deployment-845c8977d9- deployment-3062  319a638c-e9c9-44ff-b0d5-353bfa3b008b 35477 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4dfe3b400deb06add93c871aa861eb755d800b6603fbb144f66d18b07710bd1f cni.projectcalico.org/podIP:100.96.0.84/32 cni.projectcalico.org/podIPs:100.96.0.84/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc003d91c37 0xc003d91c38}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jjg8w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jjg8w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-6nh7z" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-6nh7z webserver-deployment-845c8977d9- deployment-3062  68b9765d-9d48-4580-81f6-2e87d2a79855 35459 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:18bb74b7d383b92298a7cfca57b59cac775147c154a590d246c574453a0d3388 cni.projectcalico.org/podIP:100.96.2.45/32 cni.projectcalico.org/podIPs:100.96.2.45/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc003d91e47 0xc003d91e48}] [] [{calico Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pw82j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pw82j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-7j52p" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-7j52p webserver-deployment-845c8977d9- deployment-3062  5d131cb8-1559-4fac-8c21-86664e26d797 35196 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d6fa70c72fb629c1307aace98da025b4805b02e2aa2fbde5889b2e5db7a81dfe cni.projectcalico.org/podIP:100.96.1.155/32 cni.projectcalico.org/podIPs:100.96.1.155/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c047 0xc00415c048}] [] [{calico Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2z785,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2z785,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:100.96.1.155,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://222e75d09fa92011f7ebd377c9fe8ca6454237a81069e93e6dcb19aed1984fcb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-9f2qr" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9f2qr webserver-deployment-845c8977d9- deployment-3062  bfc31af0-e62a-4807-8c44-ec0929cebb8f 35246 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a4c7e12db4ef7d3b099874ffcc020f1f7a073b94c308dd4ff2cde3a914b0229a cni.projectcalico.org/podIP:100.96.1.157/32 cni.projectcalico.org/podIPs:100.96.1.157/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c267 0xc00415c268}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.157\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vnknj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vnknj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:100.96.1.157,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://753e34565f975d578ac04a55edcd2947e61880f200ae3d873161764adbaa8bcf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.157,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-9xjps" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9xjps webserver-deployment-845c8977d9- deployment-3062  db3bbc1d-5a5b-420a-816d-839a52184df8 35507 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:04a6b5a810a63f7087d38996d7d975f0029aefde0cf526ebca42e44d5ef6bcca cni.projectcalico.org/podIP:100.96.0.85/32 cni.projectcalico.org/podIPs:100.96.0.85/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c487 0xc00415c488}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fk5xw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fk5xw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-b92cc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-b92cc webserver-deployment-845c8977d9- deployment-3062  cc74196d-a0e7-4638-9089-e488880df073 35501 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:870704384686eb5282c24d01db3a76ccb8950f72d256a2990b40f7ab47daad37 cni.projectcalico.org/podIP:100.96.3.103/32 cni.projectcalico.org/podIPs:100.96.3.103/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c687 0xc00415c688}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k5nhl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k5nhl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-ddp8g" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ddp8g webserver-deployment-845c8977d9- deployment-3062  d12f4631-575c-44b6-9de8-a8b1e82c1676 35243 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6852cf42eff6ed3843b1284aa88a6f5a6035a875655655a7687b912dfbc7b1c2 cni.projectcalico.org/podIP:100.96.0.80/32 cni.projectcalico.org/podIPs:100.96.0.80/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c887 0xc00415c888}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.80\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wmkf9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wmkf9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:100.96.0.80,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cd96f590c16aa306a233cde6c3360de00cdad9961dc659e5632eae6cc77e0bce,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.80,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-dxzgq" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-dxzgq webserver-deployment-845c8977d9- deployment-3062  f17b29df-d1dd-4e25-a832-a2a1a47f6954 35440 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415ca80 0xc00415ca81}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7ft4q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7ft4q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-fbwv9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fbwv9 webserver-deployment-845c8977d9- deployment-3062  890c9046-b070-4075-99f9-f1ecb95c6748 35508 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:0513017bb71fc6b766b5dd3cea607a62aa59b9bd9c59f2ed13b87d5c7990f6ed cni.projectcalico.org/podIP:100.96.2.47/32 cni.projectcalico.org/podIPs:100.96.2.47/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415cc57 0xc00415cc58}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-49pp9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-49pp9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-gds57" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gds57 webserver-deployment-845c8977d9- deployment-3062  be200992-4501-4a06-a927-e0d465ecb8cf 35240 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:db425596a4349fce0040b2cdf985ed477cbdbb72888d9061649d9b87f523d2ad cni.projectcalico.org/podIP:100.96.0.79/32 cni.projectcalico.org/podIPs:100.96.0.79/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415ce57 0xc00415ce58}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.79\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hw9hx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hw9hx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:100.96.0.79,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://385f70d2c22a93f12768597d3123837d82416044c8c8f159b61a9802a743fd6a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-gtjfv" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gtjfv webserver-deployment-845c8977d9- deployment-3062  ac423bd2-3cf2-4867-bbb6-120b7669569c 35378 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d050 0xc00415d051}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xtwk4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xtwk4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-hkfqg" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hkfqg webserver-deployment-845c8977d9- deployment-3062  d4146263-0671-4af4-b46a-0eaf8ab8ca21 35251 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:554b896123f200588cb6af40b4cb9fc434acec6db9852c3a9453837a83785953 cni.projectcalico.org/podIP:100.96.2.42/32 cni.projectcalico.org/podIPs:100.96.2.42/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d227 0xc00415d228}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jbg9g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jbg9g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.42,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://66c8effc660105d94f2a60b379da875d4cfd2797e8fec4a804666d60b339fbbd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-kdskk" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kdskk webserver-deployment-845c8977d9- deployment-3062  14ebf027-6301-4e60-bf0f-402af100f999 35224 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e2bd49048da4ef411b8438b3d2dcb62da1a54a008cf44899bfb8af49fcd516e8 cni.projectcalico.org/podIP:100.96.3.99/32 cni.projectcalico.org/podIPs:100.96.3.99/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d440 0xc00415d441}] [] [{calico Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.99\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p49hz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p49hz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:100.96.3.99,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2fb3f1031bac3626b5b9a52bda1cbb7df9cbee0396f37c5cb1100ebf9ff237c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.99,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-klmx7" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-klmx7 webserver-deployment-845c8977d9- deployment-3062  b818e823-ec5a-4e72-af72-fd4aa4768b13 35464 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e93e9899d6a0a26f9a2e664088e58c12d448fc98805a9d0519ec50d08845cec7 cni.projectcalico.org/podIP:100.96.1.161/32 cni.projectcalico.org/podIPs:100.96.1.161/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d650 0xc00415d651}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nrg9x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nrg9x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-ljp5j" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ljp5j webserver-deployment-845c8977d9- deployment-3062  e392b82c-d5bf-4727-8b29-e9b13c5ec751 35474 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:50603b1a8f72ffa57f64ab0d45825204921e3e66cd6656b8f72dcd3fdcea6a5e cni.projectcalico.org/podIP:100.96.0.83/32 cni.projectcalico.org/podIPs:100.96.0.83/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d847 0xc00415d848}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8fvll,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8fvll,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-tdf97" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tdf97 webserver-deployment-845c8977d9- deployment-3062  6d93567d-64ab-49c4-9af7-e2fb0e2f4a57 35473 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8eeb5cfa65b64f2d2993ba891bf699b33b56efc9339d36cfc8774b555ddd7a97 cni.projectcalico.org/podIP:100.96.2.46/32 cni.projectcalico.org/podIPs:100.96.2.46/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415da77 0xc00415da78}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bhvlt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bhvlt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-x5g86" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-x5g86 webserver-deployment-845c8977d9- deployment-3062  8387f637-9c0f-44c4-8165-a95b3846a277 35248 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:217e96c169469b04f6aaff174cd2eaabd9769be08b9dbb8319abc4fb1cb7d1db cni.projectcalico.org/podIP:100.96.1.156/32 cni.projectcalico.org/podIPs:100.96.1.156/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415dc97 0xc00415dc98}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.156\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5pxcg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5pxcg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:100.96.1.156,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://113dcfed43ec3a320476f3ec844aed299527215ccd5ab1b566b0e89ea3505a6f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.156,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-x6t6f" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-x6t6f webserver-deployment-845c8977d9- deployment-3062  a6a621ff-5f5d-4924-80f7-b5a47e47cd16 35227 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:366bbc85fd364e294060566e835f546ad6ae0b3dad83fe226ac1b1f286dfb7da cni.projectcalico.org/podIP:100.96.3.100/32 cni.projectcalico.org/podIPs:100.96.3.100/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415dec7 0xc00415dec8}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.100\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lb9ww,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lb9ww,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:100.96.3.100,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://934685877aa2a6f93b91f82fc4a69701f0f074b4c08561ce28b3463976e356d3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-zsz8h" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zsz8h webserver-deployment-845c8977d9- deployment-3062  53d75f97-2365-444d-bbe7-eec07adb02d1 35462 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4286ae1fb8e3e7f39d5a3659134c663248321c7a7977ea58fdf06946f6597ae8 cni.projectcalico.org/podIP:100.96.1.159/32 cni.projectcalico.org/podIPs:100.96.1.159/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc0039120f7 0xc0039120f8}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t8cqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t8cqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 29 12:51:37.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3062" for this suite. 11/29/22 12:51:37.862
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":305,"skipped":5514,"failed":0}
------------------------------
• [SLOW TEST] [10.678 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:27.377
    Nov 29 12:51:27.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename deployment 11/29/22 12:51:27.378
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:27.392
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:27.395
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Nov 29 12:51:27.398: INFO: Creating deployment "webserver-deployment"
    Nov 29 12:51:27.407: INFO: Waiting for observed generation 1
    Nov 29 12:51:29.421: INFO: Waiting for all required pods to come up
    Nov 29 12:51:29.425: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 11/29/22 12:51:29.425
    Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-x6t6f" in namespace "deployment-3062" to be "running"
    Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-9f2qr" in namespace "deployment-3062" to be "running"
    Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-gds57" in namespace "deployment-3062" to be "running"
    Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ddp8g" in namespace "deployment-3062" to be "running"
    Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hkfqg" in namespace "deployment-3062" to be "running"
    Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-kdskk" in namespace "deployment-3062" to be "running"
    Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-x5g86" in namespace "deployment-3062" to be "running"
    Nov 29 12:51:29.425: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7blwn" in namespace "deployment-3062" to be "running"
    Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-x5g86": Phase="Pending", Reason="", readiness=false. Elapsed: 3.619901ms
    Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-9f2qr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05987ms
    Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-7blwn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.74632ms
    Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-gds57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.20829ms
    Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-kdskk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.99865ms
    Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-ddp8g": Phase="Pending", Reason="", readiness=false. Elapsed: 4.153257ms
    Nov 29 12:51:29.429: INFO: Pod "webserver-deployment-845c8977d9-hkfqg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.442785ms
    Nov 29 12:51:29.430: INFO: Pod "webserver-deployment-845c8977d9-x6t6f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.937938ms
    Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-kdskk": Phase="Running", Reason="", readiness=true. Elapsed: 2.008013502s
    Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-kdskk" satisfied condition "running"
    Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-x6t6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.008317073s
    Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-x6t6f" satisfied condition "running"
    Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-9f2qr": Phase="Running", Reason="", readiness=true. Elapsed: 2.008348703s
    Nov 29 12:51:31.433: INFO: Pod "webserver-deployment-845c8977d9-9f2qr" satisfied condition "running"
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-x5g86": Phase="Running", Reason="", readiness=true. Elapsed: 2.00864936s
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-x5g86" satisfied condition "running"
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-hkfqg": Phase="Running", Reason="", readiness=true. Elapsed: 2.008950258s
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-hkfqg" satisfied condition "running"
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-gds57": Phase="Running", Reason="", readiness=true. Elapsed: 2.009282427s
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-gds57" satisfied condition "running"
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-ddp8g": Phase="Running", Reason="", readiness=true. Elapsed: 2.009218499s
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-ddp8g" satisfied condition "running"
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-7blwn": Phase="Running", Reason="", readiness=true. Elapsed: 2.008984742s
    Nov 29 12:51:31.434: INFO: Pod "webserver-deployment-845c8977d9-7blwn" satisfied condition "running"
    Nov 29 12:51:31.434: INFO: Waiting for deployment "webserver-deployment" to complete
    Nov 29 12:51:31.438: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Nov 29 12:51:31.444: INFO: Updating deployment webserver-deployment
    Nov 29 12:51:31.444: INFO: Waiting for observed generation 2
    Nov 29 12:51:33.465: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Nov 29 12:51:33.469: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Nov 29 12:51:33.473: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov 29 12:51:33.480: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Nov 29 12:51:33.480: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Nov 29 12:51:33.482: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov 29 12:51:33.484: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Nov 29 12:51:33.485: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Nov 29 12:51:33.491: INFO: Updating deployment webserver-deployment
    Nov 29 12:51:33.491: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Nov 29 12:51:33.510: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Nov 29 12:51:35.745: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 29 12:51:36.802: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-3062  f92ec754-9e28-4f62-a18d-a3f7862954f2 35436 3 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003311338 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-29 12:51:33 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-29 12:51:33 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Nov 29 12:51:36.810: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-3062  5a0da8fc-870d-426f-a5d4-a83b38d139c5 35435 3 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment f92ec754-9e28-4f62-a18d-a3f7862954f2 0xc003311747 0xc003311748}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f92ec754-9e28-4f62-a18d-a3f7862954f2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0033117e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 12:51:36.810: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Nov 29 12:51:36.810: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-3062  330c377c-48aa-4a72-8149-a91e116d9e88 35415 3 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment f92ec754-9e28-4f62-a18d-a3f7862954f2 0xc003311847 0xc003311848}] [] [{kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f92ec754-9e28-4f62-a18d-a3f7862954f2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0033118d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Nov 29 12:51:37.083: INFO: Pod "webserver-deployment-69b7448995-2r678" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-2r678 webserver-deployment-69b7448995- deployment-3062  19623ce2-3448-4ff8-bc02-7e4efd58e2fa 35344 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:1fa576a1f6d7eb2ac249f86730ab2b79f0969672061ac4b60b5cd78276e4c97a cni.projectcalico.org/podIP:100.96.3.101/32 cni.projectcalico.org/podIPs:100.96.3.101/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc00389ff37 0xc00389ff38}] [] [{calico Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.101\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dcfcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dcfcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:100.96.3.101,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.083: INFO: Pod "webserver-deployment-69b7448995-5lbz2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-5lbz2 webserver-deployment-69b7448995- deployment-3062  61f96d64-f4d7-416b-a989-5aef9cf78b8d 35481 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:3719dc99da0bdc6cc666d6171246d69f567be0fd3b5992d60ddf1dd9ab27e911 cni.projectcalico.org/podIP:100.96.1.162/32 cni.projectcalico.org/podIPs:100.96.1.162/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90177 0xc003d90178}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-252vb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-252vb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.084: INFO: Pod "webserver-deployment-69b7448995-74qrc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-74qrc webserver-deployment-69b7448995- deployment-3062  7bcf0e1b-b038-494f-bd76-6401cfd1e166 35444 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90377 0xc003d90378}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-47c67,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-47c67,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.084: INFO: Pod "webserver-deployment-69b7448995-7wb2b" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7wb2b webserver-deployment-69b7448995- deployment-3062  d5c61e96-c4e5-47ac-8485-3fc7154d9304 35437 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90557 0xc003d90558}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kv4bk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kv4bk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.084: INFO: Pod "webserver-deployment-69b7448995-8kxt6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-8kxt6 webserver-deployment-69b7448995- deployment-3062  fdc187e2-7ef2-40fa-8363-a83e6edfbcba 35312 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:a193c006374c9633f9139c83a66520a8f05c74a12cb5f9aabec8eccdd8536af4 cni.projectcalico.org/podIP:100.96.2.43/32 cni.projectcalico.org/podIPs:100.96.2.43/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90757 0xc003d90758}] [] [{calico Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dhl6c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dhl6c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-bp4bp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-bp4bp webserver-deployment-69b7448995- deployment-3062  bf83136f-b05c-4fa1-9660-30911c7f9986 35494 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:c945f53a7b75c4cb1dd147bc45abe4d5b67b9cd27515676331ea6a96f6214317 cni.projectcalico.org/podIP:100.96.0.81/32 cni.projectcalico.org/podIPs:100.96.0.81/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90967 0xc003d90968}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.81\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dqg5n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dqg5n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:100.96.0.81,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-f6854" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-f6854 webserver-deployment-69b7448995- deployment-3062  e9aee89e-52e5-488e-ba30-9274d42910e6 35505 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:c15e206bc4ebe4586f26cf1524b31601ddb6308536b8ba37ebec712984996fe7 cni.projectcalico.org/podIP:100.96.0.82/32 cni.projectcalico.org/podIPs:100.96.0.82/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90bb0 0xc003d90bb1}] [] [{calico Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sfcvm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sfcvm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:100.96.0.82,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-fpqd9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fpqd9 webserver-deployment-69b7448995- deployment-3062  3c3d19ff-0300-41a9-bb98-dd413f9ef22a 35476 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0fd2d8a143369db61f0650f06a8ea3231afc78e116f83ad0f56e7e9a9f4d331f cni.projectcalico.org/podIP:100.96.1.158/32 cni.projectcalico.org/podIPs:100.96.1.158/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d90df0 0xc003d90df1}] [] [{calico Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2cq9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2cq9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:100.96.1.158,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-kmfsl" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-kmfsl webserver-deployment-69b7448995- deployment-3062  a9c695ef-e149-4acd-981a-e3d456d03c90 35463 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ff29c8f47809c8dbca0d54e9eaed60d1a00120bf08fcea5e59cbd6768868c692 cni.projectcalico.org/podIP:100.96.1.160/32 cni.projectcalico.org/podIPs:100.96.1.160/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91037 0xc003d91038}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fppgf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fppgf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.085: INFO: Pod "webserver-deployment-69b7448995-l9sfq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-l9sfq webserver-deployment-69b7448995- deployment-3062  2e88ee37-6f8f-42d8-98aa-b419ac018aa9 35441 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91237 0xc003d91238}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cshzp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cshzp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-69b7448995-n8rnt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-n8rnt webserver-deployment-69b7448995- deployment-3062  41a96612-b1ce-41a9-9424-fa79c16540d7 35496 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91417 0xc003d91418}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4c46,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4c46,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-69b7448995-sg9rp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sg9rp webserver-deployment-69b7448995- deployment-3062  28510009-facd-425b-b465-dab2aafb672b 35506 0 2022-11-29 12:51:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:24431ca3efd31998cdaadd8d03109df46706db5ea088d554882a85d36e7c045d cni.projectcalico.org/podIP:100.96.2.44/32 cni.projectcalico.org/podIPs:100.96.2.44/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91617 0xc003d91618}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.44\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29dnd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29dnd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.44,StartTime:2022-11-29 12:51:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-69b7448995-vd9tq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-vd9tq webserver-deployment-69b7448995- deployment-3062  0402eafd-482d-47af-973d-4d582786772c 35450 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 5a0da8fc-870d-426f-a5d4-a83b38d139c5 0xc003d91840 0xc003d91841}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a0da8fc-870d-426f-a5d4-a83b38d139c5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-skb2z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-skb2z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-845c8977d9-4j4p4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4j4p4 webserver-deployment-845c8977d9- deployment-3062  f92feae0-22e8-48ce-ac7a-df1a9a6f2c3f 35472 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ba2e00707a3d86c3799a45b55d6f9a3ee11dd005a10489a0de9aeffb9aa3974d cni.projectcalico.org/podIP:100.96.3.102/32 cni.projectcalico.org/podIPs:100.96.3.102/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc003d91a37 0xc003d91a38}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6nqzd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6nqzd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.086: INFO: Pod "webserver-deployment-845c8977d9-65s8n" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-65s8n webserver-deployment-845c8977d9- deployment-3062  319a638c-e9c9-44ff-b0d5-353bfa3b008b 35477 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4dfe3b400deb06add93c871aa861eb755d800b6603fbb144f66d18b07710bd1f cni.projectcalico.org/podIP:100.96.0.84/32 cni.projectcalico.org/podIPs:100.96.0.84/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc003d91c37 0xc003d91c38}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jjg8w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jjg8w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-6nh7z" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-6nh7z webserver-deployment-845c8977d9- deployment-3062  68b9765d-9d48-4580-81f6-2e87d2a79855 35459 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:18bb74b7d383b92298a7cfca57b59cac775147c154a590d246c574453a0d3388 cni.projectcalico.org/podIP:100.96.2.45/32 cni.projectcalico.org/podIPs:100.96.2.45/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc003d91e47 0xc003d91e48}] [] [{calico Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pw82j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pw82j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-7j52p" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-7j52p webserver-deployment-845c8977d9- deployment-3062  5d131cb8-1559-4fac-8c21-86664e26d797 35196 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d6fa70c72fb629c1307aace98da025b4805b02e2aa2fbde5889b2e5db7a81dfe cni.projectcalico.org/podIP:100.96.1.155/32 cni.projectcalico.org/podIPs:100.96.1.155/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c047 0xc00415c048}] [] [{calico Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2z785,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2z785,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:100.96.1.155,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://222e75d09fa92011f7ebd377c9fe8ca6454237a81069e93e6dcb19aed1984fcb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-9f2qr" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9f2qr webserver-deployment-845c8977d9- deployment-3062  bfc31af0-e62a-4807-8c44-ec0929cebb8f 35246 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a4c7e12db4ef7d3b099874ffcc020f1f7a073b94c308dd4ff2cde3a914b0229a cni.projectcalico.org/podIP:100.96.1.157/32 cni.projectcalico.org/podIPs:100.96.1.157/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c267 0xc00415c268}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.157\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vnknj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vnknj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:100.96.1.157,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://753e34565f975d578ac04a55edcd2947e61880f200ae3d873161764adbaa8bcf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.157,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-9xjps" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9xjps webserver-deployment-845c8977d9- deployment-3062  db3bbc1d-5a5b-420a-816d-839a52184df8 35507 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:04a6b5a810a63f7087d38996d7d975f0029aefde0cf526ebca42e44d5ef6bcca cni.projectcalico.org/podIP:100.96.0.85/32 cni.projectcalico.org/podIPs:100.96.0.85/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c487 0xc00415c488}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fk5xw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fk5xw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-b92cc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-b92cc webserver-deployment-845c8977d9- deployment-3062  cc74196d-a0e7-4638-9089-e488880df073 35501 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:870704384686eb5282c24d01db3a76ccb8950f72d256a2990b40f7ab47daad37 cni.projectcalico.org/podIP:100.96.3.103/32 cni.projectcalico.org/podIPs:100.96.3.103/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c687 0xc00415c688}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k5nhl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k5nhl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.087: INFO: Pod "webserver-deployment-845c8977d9-ddp8g" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ddp8g webserver-deployment-845c8977d9- deployment-3062  d12f4631-575c-44b6-9de8-a8b1e82c1676 35243 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6852cf42eff6ed3843b1284aa88a6f5a6035a875655655a7687b912dfbc7b1c2 cni.projectcalico.org/podIP:100.96.0.80/32 cni.projectcalico.org/podIPs:100.96.0.80/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415c887 0xc00415c888}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.80\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wmkf9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wmkf9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:100.96.0.80,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cd96f590c16aa306a233cde6c3360de00cdad9961dc659e5632eae6cc77e0bce,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.80,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-dxzgq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-dxzgq webserver-deployment-845c8977d9- deployment-3062  f17b29df-d1dd-4e25-a832-a2a1a47f6954 35440 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415ca80 0xc00415ca81}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7ft4q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7ft4q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-fbwv9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fbwv9 webserver-deployment-845c8977d9- deployment-3062  890c9046-b070-4075-99f9-f1ecb95c6748 35508 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:0513017bb71fc6b766b5dd3cea607a62aa59b9bd9c59f2ed13b87d5c7990f6ed cni.projectcalico.org/podIP:100.96.2.47/32 cni.projectcalico.org/podIPs:100.96.2.47/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415cc57 0xc00415cc58}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-49pp9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-49pp9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-gds57" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gds57 webserver-deployment-845c8977d9- deployment-3062  be200992-4501-4a06-a927-e0d465ecb8cf 35240 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:db425596a4349fce0040b2cdf985ed477cbdbb72888d9061649d9b87f523d2ad cni.projectcalico.org/podIP:100.96.0.79/32 cni.projectcalico.org/podIPs:100.96.0.79/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415ce57 0xc00415ce58}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.79\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hw9hx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hw9hx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:100.96.0.79,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://385f70d2c22a93f12768597d3123837d82416044c8c8f159b61a9802a743fd6a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-gtjfv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gtjfv webserver-deployment-845c8977d9- deployment-3062  ac423bd2-3cf2-4867-bbb6-120b7669569c 35378 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d050 0xc00415d051}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xtwk4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xtwk4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-hkfqg" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hkfqg webserver-deployment-845c8977d9- deployment-3062  d4146263-0671-4af4-b46a-0eaf8ab8ca21 35251 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:554b896123f200588cb6af40b4cb9fc434acec6db9852c3a9453837a83785953 cni.projectcalico.org/podIP:100.96.2.42/32 cni.projectcalico.org/podIPs:100.96.2.42/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d227 0xc00415d228}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jbg9g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jbg9g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:100.96.2.42,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://66c8effc660105d94f2a60b379da875d4cfd2797e8fec4a804666d60b339fbbd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-kdskk" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kdskk webserver-deployment-845c8977d9- deployment-3062  14ebf027-6301-4e60-bf0f-402af100f999 35224 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e2bd49048da4ef411b8438b3d2dcb62da1a54a008cf44899bfb8af49fcd516e8 cni.projectcalico.org/podIP:100.96.3.99/32 cni.projectcalico.org/podIPs:100.96.3.99/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d440 0xc00415d441}] [] [{calico Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.99\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p49hz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p49hz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:100.96.3.99,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2fb3f1031bac3626b5b9a52bda1cbb7df9cbee0396f37c5cb1100ebf9ff237c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.99,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.088: INFO: Pod "webserver-deployment-845c8977d9-klmx7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-klmx7 webserver-deployment-845c8977d9- deployment-3062  b818e823-ec5a-4e72-af72-fd4aa4768b13 35464 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e93e9899d6a0a26f9a2e664088e58c12d448fc98805a9d0519ec50d08845cec7 cni.projectcalico.org/podIP:100.96.1.161/32 cni.projectcalico.org/podIPs:100.96.1.161/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d650 0xc00415d651}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nrg9x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nrg9x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-ljp5j" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ljp5j webserver-deployment-845c8977d9- deployment-3062  e392b82c-d5bf-4727-8b29-e9b13c5ec751 35474 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:50603b1a8f72ffa57f64ab0d45825204921e3e66cd6656b8f72dcd3fdcea6a5e cni.projectcalico.org/podIP:100.96.0.83/32 cni.projectcalico.org/podIPs:100.96.0.83/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415d847 0xc00415d848}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8fvll,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8fvll,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-master-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.155,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-tdf97" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tdf97 webserver-deployment-845c8977d9- deployment-3062  6d93567d-64ab-49c4-9af7-e2fb0e2f4a57 35473 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8eeb5cfa65b64f2d2993ba891bf699b33b56efc9339d36cfc8774b555ddd7a97 cni.projectcalico.org/podIP:100.96.2.46/32 cni.projectcalico.org/podIPs:100.96.2.46/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415da77 0xc00415da78}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bhvlt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bhvlt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.22,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-x5g86" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-x5g86 webserver-deployment-845c8977d9- deployment-3062  8387f637-9c0f-44c4-8165-a95b3846a277 35248 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:217e96c169469b04f6aaff174cd2eaabd9769be08b9dbb8319abc4fb1cb7d1db cni.projectcalico.org/podIP:100.96.1.156/32 cni.projectcalico.org/podIPs:100.96.1.156/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415dc97 0xc00415dc98}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.156\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5pxcg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5pxcg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:100.96.1.156,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://113dcfed43ec3a320476f3ec844aed299527215ccd5ab1b566b0e89ea3505a6f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.156,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-x6t6f" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-x6t6f webserver-deployment-845c8977d9- deployment-3062  a6a621ff-5f5d-4924-80f7-b5a47e47cd16 35227 0 2022-11-29 12:51:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:366bbc85fd364e294060566e835f546ad6ae0b3dad83fe226ac1b1f286dfb7da cni.projectcalico.org/podIP:100.96.3.100/32 cni.projectcalico.org/podIPs:100.96.3.100/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc00415dec7 0xc00415dec8}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-29 12:51:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-29 12:51:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.100\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lb9ww,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lb9ww,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.35,PodIP:100.96.3.100,StartTime:2022-11-29 12:51:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-29 12:51:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://934685877aa2a6f93b91f82fc4a69701f0f074b4c08561ce28b3463976e356d3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:51:37.089: INFO: Pod "webserver-deployment-845c8977d9-zsz8h" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zsz8h webserver-deployment-845c8977d9- deployment-3062  53d75f97-2365-444d-bbe7-eec07adb02d1 35462 0 2022-11-29 12:51:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4286ae1fb8e3e7f39d5a3659134c663248321c7a7977ea58fdf06946f6597ae8 cni.projectcalico.org/podIP:100.96.1.159/32 cni.projectcalico.org/podIPs:100.96.1.159/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 330c377c-48aa-4a72-8149-a91e116d9e88 0xc0039120f7 0xc0039120f8}] [] [{kube-controller-manager Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"330c377c-48aa-4a72-8149-a91e116d9e88\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-29 12:51:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-29 12:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t8cqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t8cqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:dvi-7336-1669718118-vsp1-group1-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-29 12:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.8.111,PodIP:,StartTime:2022-11-29 12:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 29 12:51:37.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3062" for this suite. 11/29/22 12:51:37.862
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:38.059
Nov 29 12:51:38.059: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename gc 11/29/22 12:51:38.06
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:38.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:38.273
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Nov 29 12:51:39.290: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"240e3845-fafd-4174-837c-fe45c6d04586", Controller:(*bool)(0xc003aff5f6), BlockOwnerDeletion:(*bool)(0xc003aff5f7)}}
Nov 29 12:51:39.363: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6dede8fd-d8a5-4441-bf4c-141eb993fa94", Controller:(*bool)(0xc003aff8d6), BlockOwnerDeletion:(*bool)(0xc003aff8d7)}}
Nov 29 12:51:39.516: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ce96233e-1ab3-48cc-b299-386bfa5221dc", Controller:(*bool)(0xc003c6ae26), BlockOwnerDeletion:(*bool)(0xc003c6ae27)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 29 12:51:45.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5892" for this suite. 11/29/22 12:51:45.371
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":306,"skipped":5550,"failed":0}
------------------------------
• [SLOW TEST] [7.361 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:38.059
    Nov 29 12:51:38.059: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename gc 11/29/22 12:51:38.06
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:38.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:38.273
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Nov 29 12:51:39.290: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"240e3845-fafd-4174-837c-fe45c6d04586", Controller:(*bool)(0xc003aff5f6), BlockOwnerDeletion:(*bool)(0xc003aff5f7)}}
    Nov 29 12:51:39.363: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6dede8fd-d8a5-4441-bf4c-141eb993fa94", Controller:(*bool)(0xc003aff8d6), BlockOwnerDeletion:(*bool)(0xc003aff8d7)}}
    Nov 29 12:51:39.516: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ce96233e-1ab3-48cc-b299-386bfa5221dc", Controller:(*bool)(0xc003c6ae26), BlockOwnerDeletion:(*bool)(0xc003c6ae27)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 29 12:51:45.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5892" for this suite. 11/29/22 12:51:45.371
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:45.422
Nov 29 12:51:45.422: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-webhook 11/29/22 12:51:45.423
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:45.493
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:45.498
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/29/22 12:51:45.503
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/29/22 12:51:46.321
STEP: Deploying the custom resource conversion webhook pod 11/29/22 12:51:46.509
STEP: Wait for the deployment to be ready 11/29/22 12:51:46.911
Nov 29 12:51:47.724: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 46, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-crd-conversion-webhook-deployment-59dfc5db8d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Nov 29 12:51:49.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 29 12:51:51.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/29/22 12:51:53.727
STEP: Verifying the service has paired with the endpoint 11/29/22 12:51:53.736
Nov 29 12:51:54.736: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Nov 29 12:51:54.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Creating a v1 custom resource 11/29/22 12:51:57.31
STEP: Create a v2 custom resource 11/29/22 12:51:57.321
STEP: List CRs in v1 11/29/22 12:51:57.377
STEP: List CRs in v2 11/29/22 12:51:57.382
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:51:57.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8052" for this suite. 11/29/22 12:51:57.902
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":307,"skipped":5598,"failed":0}
------------------------------
• [SLOW TEST] [12.524 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:45.422
    Nov 29 12:51:45.422: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-webhook 11/29/22 12:51:45.423
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:45.493
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:45.498
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/29/22 12:51:45.503
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/29/22 12:51:46.321
    STEP: Deploying the custom resource conversion webhook pod 11/29/22 12:51:46.509
    STEP: Wait for the deployment to be ready 11/29/22 12:51:46.911
    Nov 29 12:51:47.724: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 46, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-crd-conversion-webhook-deployment-59dfc5db8d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
    Nov 29 12:51:49.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 29 12:51:51.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 29, 12, 51, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 29, 12, 51, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/29/22 12:51:53.727
    STEP: Verifying the service has paired with the endpoint 11/29/22 12:51:53.736
    Nov 29 12:51:54.736: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Nov 29 12:51:54.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Creating a v1 custom resource 11/29/22 12:51:57.31
    STEP: Create a v2 custom resource 11/29/22 12:51:57.321
    STEP: List CRs in v1 11/29/22 12:51:57.377
    STEP: List CRs in v2 11/29/22 12:51:57.382
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:51:57.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-8052" for this suite. 11/29/22 12:51:57.902
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:51:57.948
Nov 29 12:51:57.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 12:51:57.949
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:57.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:57.969
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 11/29/22 12:51:57.973
Nov 29 12:51:57.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: rename a version 11/29/22 12:52:06.329
STEP: check the new version name is served 11/29/22 12:52:06.344
STEP: check the old version name is removed 11/29/22 12:52:09.124
STEP: check the other version is not changed 11/29/22 12:52:10.619
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:52:17.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5907" for this suite. 11/29/22 12:52:17.25
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":308,"skipped":5618,"failed":0}
------------------------------
• [SLOW TEST] [19.305 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:51:57.948
    Nov 29 12:51:57.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 12:51:57.949
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:51:57.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:51:57.969
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 11/29/22 12:51:57.973
    Nov 29 12:51:57.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: rename a version 11/29/22 12:52:06.329
    STEP: check the new version name is served 11/29/22 12:52:06.344
    STEP: check the old version name is removed 11/29/22 12:52:09.124
    STEP: check the other version is not changed 11/29/22 12:52:10.619
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:52:17.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5907" for this suite. 11/29/22 12:52:17.25
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:17.254
Nov 29 12:52:17.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:52:17.255
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:17.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:17.264
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-3a3ce5c6-c85d-441d-8954-00b12a0422cb 11/29/22 12:52:17.276
STEP: Creating a pod to test consume secrets 11/29/22 12:52:17.278
Nov 29 12:52:17.282: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69" in namespace "projected-5837" to be "Succeeded or Failed"
Nov 29 12:52:17.287: INFO: Pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.689783ms
Nov 29 12:52:19.290: INFO: Pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69": Phase="Running", Reason="", readiness=false. Elapsed: 2.008086294s
Nov 29 12:52:21.291: INFO: Pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008480979s
STEP: Saw pod success 11/29/22 12:52:21.291
Nov 29 12:52:21.291: INFO: Pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69" satisfied condition "Succeeded or Failed"
Nov 29 12:52:21.293: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/29/22 12:52:21.296
Nov 29 12:52:21.302: INFO: Waiting for pod pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69 to disappear
Nov 29 12:52:21.305: INFO: Pod pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 29 12:52:21.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5837" for this suite. 11/29/22 12:52:21.312
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":309,"skipped":5621,"failed":0}
------------------------------
• [4.062 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:17.254
    Nov 29 12:52:17.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:52:17.255
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:17.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:17.264
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-3a3ce5c6-c85d-441d-8954-00b12a0422cb 11/29/22 12:52:17.276
    STEP: Creating a pod to test consume secrets 11/29/22 12:52:17.278
    Nov 29 12:52:17.282: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69" in namespace "projected-5837" to be "Succeeded or Failed"
    Nov 29 12:52:17.287: INFO: Pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.689783ms
    Nov 29 12:52:19.290: INFO: Pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69": Phase="Running", Reason="", readiness=false. Elapsed: 2.008086294s
    Nov 29 12:52:21.291: INFO: Pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008480979s
    STEP: Saw pod success 11/29/22 12:52:21.291
    Nov 29 12:52:21.291: INFO: Pod "pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69" satisfied condition "Succeeded or Failed"
    Nov 29 12:52:21.293: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:52:21.296
    Nov 29 12:52:21.302: INFO: Waiting for pod pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69 to disappear
    Nov 29 12:52:21.305: INFO: Pod pod-projected-secrets-40f78a31-fc0f-4cb2-a381-6ff2d7420a69 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 29 12:52:21.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5837" for this suite. 11/29/22 12:52:21.312
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:21.317
Nov 29 12:52:21.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename dns 11/29/22 12:52:21.318
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:21.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:21.335
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/29/22 12:52:21.337
Nov 29 12:52:21.342: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6720  7259cdc2-bbd6-4f6e-9d9c-bd3d16816ec7 36073 0 2022-11-29 12:52:21 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-29 12:52:21 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l82dp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l82dp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 29 12:52:21.342: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-6720" to be "running and ready"
Nov 29 12:52:21.347: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036591ms
Nov 29 12:52:21.347: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:52:23.349: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.006588929s
Nov 29 12:52:23.349: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Nov 29 12:52:23.349: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 11/29/22 12:52:23.349
Nov 29 12:52:23.349: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6720 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:52:23.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:52:23.350: INFO: ExecWithOptions: Clientset creation
Nov 29 12:52:23.350: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/dns-6720/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 11/29/22 12:52:23.419
Nov 29 12:52:23.419: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6720 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:52:23.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:52:23.420: INFO: ExecWithOptions: Clientset creation
Nov 29 12:52:23.420: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/dns-6720/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 12:52:23.487: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 29 12:52:23.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6720" for this suite. 11/29/22 12:52:23.508
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":310,"skipped":5636,"failed":0}
------------------------------
• [2.194 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:21.317
    Nov 29 12:52:21.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename dns 11/29/22 12:52:21.318
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:21.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:21.335
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/29/22 12:52:21.337
    Nov 29 12:52:21.342: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6720  7259cdc2-bbd6-4f6e-9d9c-bd3d16816ec7 36073 0 2022-11-29 12:52:21 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-29 12:52:21 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l82dp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l82dp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 29 12:52:21.342: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-6720" to be "running and ready"
    Nov 29 12:52:21.347: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036591ms
    Nov 29 12:52:21.347: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:52:23.349: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.006588929s
    Nov 29 12:52:23.349: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Nov 29 12:52:23.349: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 11/29/22 12:52:23.349
    Nov 29 12:52:23.349: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6720 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:52:23.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:52:23.350: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:52:23.350: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/dns-6720/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 11/29/22 12:52:23.419
    Nov 29 12:52:23.419: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6720 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:52:23.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:52:23.420: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:52:23.420: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/dns-6720/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 12:52:23.487: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 29 12:52:23.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6720" for this suite. 11/29/22 12:52:23.508
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:23.512
Nov 29 12:52:23.512: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 12:52:23.513
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:23.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:23.523
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 12:52:23.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1470" for this suite. 11/29/22 12:52:23.559
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":311,"skipped":5652,"failed":0}
------------------------------
• [0.050 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:23.512
    Nov 29 12:52:23.512: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 12:52:23.513
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:23.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:23.523
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 12:52:23.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1470" for this suite. 11/29/22 12:52:23.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:23.564
Nov 29 12:52:23.564: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename server-version 11/29/22 12:52:23.565
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:23.573
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:23.575
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 11/29/22 12:52:23.577
STEP: Confirm major version 11/29/22 12:52:23.578
Nov 29 12:52:23.578: INFO: Major version: 1
STEP: Confirm minor version 11/29/22 12:52:23.578
Nov 29 12:52:23.578: INFO: cleanMinorVersion: 25
Nov 29 12:52:23.578: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Nov 29 12:52:23.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-5488" for this suite. 11/29/22 12:52:23.581
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":312,"skipped":5689,"failed":0}
------------------------------
• [0.020 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:23.564
    Nov 29 12:52:23.564: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename server-version 11/29/22 12:52:23.565
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:23.573
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:23.575
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 11/29/22 12:52:23.577
    STEP: Confirm major version 11/29/22 12:52:23.578
    Nov 29 12:52:23.578: INFO: Major version: 1
    STEP: Confirm minor version 11/29/22 12:52:23.578
    Nov 29 12:52:23.578: INFO: cleanMinorVersion: 25
    Nov 29 12:52:23.578: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Nov 29 12:52:23.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-5488" for this suite. 11/29/22 12:52:23.581
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:23.586
Nov 29 12:52:23.586: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename hostport 11/29/22 12:52:23.587
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:23.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:23.596
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/29/22 12:52:23.601
Nov 29 12:52:23.605: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-4614" to be "running and ready"
Nov 29 12:52:23.607: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061777ms
Nov 29 12:52:23.607: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:52:25.611: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005821159s
Nov 29 12:52:25.611: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 29 12:52:25.611: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.8.35 on the node which pod1 resides and expect scheduled 11/29/22 12:52:25.611
Nov 29 12:52:25.616: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-4614" to be "running and ready"
Nov 29 12:52:25.618: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154418ms
Nov 29 12:52:25.618: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:52:27.622: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005936279s
Nov 29 12:52:27.622: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 29 12:52:27.622: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.8.35 but use UDP protocol on the node which pod2 resides 11/29/22 12:52:27.622
Nov 29 12:52:27.625: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-4614" to be "running and ready"
Nov 29 12:52:27.628: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.73704ms
Nov 29 12:52:27.628: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:52:29.632: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.006728808s
Nov 29 12:52:29.632: INFO: The phase of Pod pod3 is Running (Ready = false)
Nov 29 12:52:31.631: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.005573732s
Nov 29 12:52:31.631: INFO: The phase of Pod pod3 is Running (Ready = true)
Nov 29 12:52:31.631: INFO: Pod "pod3" satisfied condition "running and ready"
Nov 29 12:52:31.634: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-4614" to be "running and ready"
Nov 29 12:52:31.643: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.451829ms
Nov 29 12:52:31.643: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Nov 29 12:52:33.648: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013234767s
Nov 29 12:52:33.648: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Nov 29 12:52:33.648: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/29/22 12:52:33.65
Nov 29 12:52:33.650: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.8.35 http://127.0.0.1:54323/hostname] Namespace:hostport-4614 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:52:33.650: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:52:33.651: INFO: ExecWithOptions: Clientset creation
Nov 29 12:52:33.651: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/hostport-4614/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.8.35+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.8.35, port: 54323 11/29/22 12:52:33.736
Nov 29 12:52:33.736: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.8.35:54323/hostname] Namespace:hostport-4614 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:52:33.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:52:33.737: INFO: ExecWithOptions: Clientset creation
Nov 29 12:52:33.737: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/hostport-4614/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.8.35%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.8.35, port: 54323 UDP 11/29/22 12:52:33.807
Nov 29 12:52:33.808: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.8.35 54323] Namespace:hostport-4614 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:52:33.808: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:52:33.808: INFO: ExecWithOptions: Clientset creation
Nov 29 12:52:33.808: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/hostport-4614/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.8.35+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Nov 29 12:52:38.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-4614" for this suite. 11/29/22 12:52:38.874
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":313,"skipped":5708,"failed":0}
------------------------------
• [SLOW TEST] [15.291 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:23.586
    Nov 29 12:52:23.586: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename hostport 11/29/22 12:52:23.587
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:23.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:23.596
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/29/22 12:52:23.601
    Nov 29 12:52:23.605: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-4614" to be "running and ready"
    Nov 29 12:52:23.607: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061777ms
    Nov 29 12:52:23.607: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:52:25.611: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005821159s
    Nov 29 12:52:25.611: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 29 12:52:25.611: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.8.35 on the node which pod1 resides and expect scheduled 11/29/22 12:52:25.611
    Nov 29 12:52:25.616: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-4614" to be "running and ready"
    Nov 29 12:52:25.618: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154418ms
    Nov 29 12:52:25.618: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:52:27.622: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005936279s
    Nov 29 12:52:27.622: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 29 12:52:27.622: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.8.35 but use UDP protocol on the node which pod2 resides 11/29/22 12:52:27.622
    Nov 29 12:52:27.625: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-4614" to be "running and ready"
    Nov 29 12:52:27.628: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.73704ms
    Nov 29 12:52:27.628: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:52:29.632: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.006728808s
    Nov 29 12:52:29.632: INFO: The phase of Pod pod3 is Running (Ready = false)
    Nov 29 12:52:31.631: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.005573732s
    Nov 29 12:52:31.631: INFO: The phase of Pod pod3 is Running (Ready = true)
    Nov 29 12:52:31.631: INFO: Pod "pod3" satisfied condition "running and ready"
    Nov 29 12:52:31.634: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-4614" to be "running and ready"
    Nov 29 12:52:31.643: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.451829ms
    Nov 29 12:52:31.643: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 12:52:33.648: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013234767s
    Nov 29 12:52:33.648: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Nov 29 12:52:33.648: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/29/22 12:52:33.65
    Nov 29 12:52:33.650: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.8.35 http://127.0.0.1:54323/hostname] Namespace:hostport-4614 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:52:33.650: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:52:33.651: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:52:33.651: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/hostport-4614/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.8.35+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.8.35, port: 54323 11/29/22 12:52:33.736
    Nov 29 12:52:33.736: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.8.35:54323/hostname] Namespace:hostport-4614 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:52:33.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:52:33.737: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:52:33.737: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/hostport-4614/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.8.35%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.8.35, port: 54323 UDP 11/29/22 12:52:33.807
    Nov 29 12:52:33.808: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.8.35 54323] Namespace:hostport-4614 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:52:33.808: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:52:33.808: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:52:33.808: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/hostport-4614/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.8.35+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Nov 29 12:52:38.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-4614" for this suite. 11/29/22 12:52:38.874
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:38.878
Nov 29 12:52:38.878: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:52:38.879
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:38.887
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:38.893
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 11/29/22 12:52:38.896
STEP: watching for the Service to be added 11/29/22 12:52:38.902
Nov 29 12:52:38.904: INFO: Found Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Nov 29 12:52:38.904: INFO: Service test-service-zhrs6 created
STEP: Getting /status 11/29/22 12:52:38.904
Nov 29 12:52:38.908: INFO: Service test-service-zhrs6 has LoadBalancer: {[]}
STEP: patching the ServiceStatus 11/29/22 12:52:38.908
STEP: watching for the Service to be patched 11/29/22 12:52:38.914
Nov 29 12:52:38.916: INFO: observed Service test-service-zhrs6 in namespace services-5723 with annotations: map[] & LoadBalancer: {[]}
Nov 29 12:52:38.916: INFO: Found Service test-service-zhrs6 in namespace services-5723 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Nov 29 12:52:38.916: INFO: Service test-service-zhrs6 has service status patched
STEP: updating the ServiceStatus 11/29/22 12:52:38.916
Nov 29 12:52:38.926: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 11/29/22 12:52:38.926
Nov 29 12:52:38.928: INFO: Observed Service test-service-zhrs6 in namespace services-5723 with annotations: map[] & Conditions: {[]}
Nov 29 12:52:38.928: INFO: Observed event: &Service{ObjectMeta:{test-service-zhrs6  services-5723  e71af9d1-7390-4740-a061-a11ee1e12048 36203 0 2022-11-29 12:52:38 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-29 12:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-29 12:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.68.242.1,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.68.242.1],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Nov 29 12:52:38.928: INFO: Found Service test-service-zhrs6 in namespace services-5723 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 29 12:52:38.928: INFO: Service test-service-zhrs6 has service status updated
STEP: patching the service 11/29/22 12:52:38.928
STEP: watching for the Service to be patched 11/29/22 12:52:38.938
Nov 29 12:52:38.940: INFO: observed Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service-static:true]
Nov 29 12:52:38.940: INFO: observed Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service-static:true]
Nov 29 12:52:38.940: INFO: observed Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service-static:true]
Nov 29 12:52:38.940: INFO: Found Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service:patched test-service-static:true]
Nov 29 12:52:38.940: INFO: Service test-service-zhrs6 patched
STEP: deleting the service 11/29/22 12:52:38.94
STEP: watching for the Service to be deleted 11/29/22 12:52:38.949
Nov 29 12:52:38.951: INFO: Observed event: ADDED
Nov 29 12:52:38.951: INFO: Observed event: MODIFIED
Nov 29 12:52:38.951: INFO: Observed event: MODIFIED
Nov 29 12:52:38.951: INFO: Observed event: MODIFIED
Nov 29 12:52:38.951: INFO: Found Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Nov 29 12:52:38.951: INFO: Service test-service-zhrs6 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:52:38.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5723" for this suite. 11/29/22 12:52:38.955
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":314,"skipped":5711,"failed":0}
------------------------------
• [0.080 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:38.878
    Nov 29 12:52:38.878: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:52:38.879
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:38.887
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:38.893
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 11/29/22 12:52:38.896
    STEP: watching for the Service to be added 11/29/22 12:52:38.902
    Nov 29 12:52:38.904: INFO: Found Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Nov 29 12:52:38.904: INFO: Service test-service-zhrs6 created
    STEP: Getting /status 11/29/22 12:52:38.904
    Nov 29 12:52:38.908: INFO: Service test-service-zhrs6 has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 11/29/22 12:52:38.908
    STEP: watching for the Service to be patched 11/29/22 12:52:38.914
    Nov 29 12:52:38.916: INFO: observed Service test-service-zhrs6 in namespace services-5723 with annotations: map[] & LoadBalancer: {[]}
    Nov 29 12:52:38.916: INFO: Found Service test-service-zhrs6 in namespace services-5723 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Nov 29 12:52:38.916: INFO: Service test-service-zhrs6 has service status patched
    STEP: updating the ServiceStatus 11/29/22 12:52:38.916
    Nov 29 12:52:38.926: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 11/29/22 12:52:38.926
    Nov 29 12:52:38.928: INFO: Observed Service test-service-zhrs6 in namespace services-5723 with annotations: map[] & Conditions: {[]}
    Nov 29 12:52:38.928: INFO: Observed event: &Service{ObjectMeta:{test-service-zhrs6  services-5723  e71af9d1-7390-4740-a061-a11ee1e12048 36203 0 2022-11-29 12:52:38 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-29 12:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-29 12:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.68.242.1,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.68.242.1],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Nov 29 12:52:38.928: INFO: Found Service test-service-zhrs6 in namespace services-5723 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 29 12:52:38.928: INFO: Service test-service-zhrs6 has service status updated
    STEP: patching the service 11/29/22 12:52:38.928
    STEP: watching for the Service to be patched 11/29/22 12:52:38.938
    Nov 29 12:52:38.940: INFO: observed Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service-static:true]
    Nov 29 12:52:38.940: INFO: observed Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service-static:true]
    Nov 29 12:52:38.940: INFO: observed Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service-static:true]
    Nov 29 12:52:38.940: INFO: Found Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service:patched test-service-static:true]
    Nov 29 12:52:38.940: INFO: Service test-service-zhrs6 patched
    STEP: deleting the service 11/29/22 12:52:38.94
    STEP: watching for the Service to be deleted 11/29/22 12:52:38.949
    Nov 29 12:52:38.951: INFO: Observed event: ADDED
    Nov 29 12:52:38.951: INFO: Observed event: MODIFIED
    Nov 29 12:52:38.951: INFO: Observed event: MODIFIED
    Nov 29 12:52:38.951: INFO: Observed event: MODIFIED
    Nov 29 12:52:38.951: INFO: Found Service test-service-zhrs6 in namespace services-5723 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Nov 29 12:52:38.951: INFO: Service test-service-zhrs6 deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:52:38.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5723" for this suite. 11/29/22 12:52:38.955
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:38.959
Nov 29 12:52:38.959: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename endpointslice 11/29/22 12:52:38.959
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:38.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:38.971
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Nov 29 12:52:38.982: INFO: Endpoints addresses: [192.168.8.155] , ports: [6443]
Nov 29 12:52:38.983: INFO: EndpointSlices addresses: [192.168.8.155] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 29 12:52:38.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5038" for this suite. 11/29/22 12:52:38.987
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":315,"skipped":5729,"failed":0}
------------------------------
• [0.032 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:38.959
    Nov 29 12:52:38.959: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename endpointslice 11/29/22 12:52:38.959
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:38.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:38.971
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Nov 29 12:52:38.982: INFO: Endpoints addresses: [192.168.8.155] , ports: [6443]
    Nov 29 12:52:38.983: INFO: EndpointSlices addresses: [192.168.8.155] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 29 12:52:38.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5038" for this suite. 11/29/22 12:52:38.987
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:38.999
Nov 29 12:52:38.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename daemonsets 11/29/22 12:52:39
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:39.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:39.01
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 11/29/22 12:52:39.028
STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:52:39.03
Nov 29 12:52:39.036: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:52:39.036: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:52:40.135: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:52:40.135: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
Nov 29 12:52:41.042: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Nov 29 12:52:41.042: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Getting /status 11/29/22 12:52:41.044
Nov 29 12:52:41.046: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 11/29/22 12:52:41.046
Nov 29 12:52:41.052: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 11/29/22 12:52:41.052
Nov 29 12:52:41.053: INFO: Observed &DaemonSet event: ADDED
Nov 29 12:52:41.053: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.055: INFO: Found daemon set daemon-set in namespace daemonsets-3 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 29 12:52:41.055: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 11/29/22 12:52:41.055
STEP: watching for the daemon set status to be patched 11/29/22 12:52:41.063
Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: ADDED
Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.066: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.066: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.066: INFO: Observed daemon set daemon-set in namespace daemonsets-3 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 29 12:52:41.066: INFO: Observed &DaemonSet event: MODIFIED
Nov 29 12:52:41.066: INFO: Found daemon set daemon-set in namespace daemonsets-3 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Nov 29 12:52:41.066: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:52:41.075
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3, will wait for the garbage collector to delete the pods 11/29/22 12:52:41.075
Nov 29 12:52:41.132: INFO: Deleting DaemonSet.extensions daemon-set took: 4.352982ms
Nov 29 12:52:41.232: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.427984ms
Nov 29 12:52:43.936: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 29 12:52:43.936: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 29 12:52:43.945: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36306"},"items":null}

Nov 29 12:52:43.951: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36308"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:52:43.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3" for this suite. 11/29/22 12:52:43.978
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":316,"skipped":5777,"failed":0}
------------------------------
• [4.982 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:38.999
    Nov 29 12:52:38.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename daemonsets 11/29/22 12:52:39
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:39.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:39.01
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 11/29/22 12:52:39.028
    STEP: Check that daemon pods launch on every node of the cluster. 11/29/22 12:52:39.03
    Nov 29 12:52:39.036: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:52:39.036: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:52:40.135: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:52:40.135: INFO: Node dvi-7336-1669718118-vsp1-group1-0 is running 0 daemon pod, expected 1
    Nov 29 12:52:41.042: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Nov 29 12:52:41.042: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Getting /status 11/29/22 12:52:41.044
    Nov 29 12:52:41.046: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 11/29/22 12:52:41.046
    Nov 29 12:52:41.052: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 11/29/22 12:52:41.052
    Nov 29 12:52:41.053: INFO: Observed &DaemonSet event: ADDED
    Nov 29 12:52:41.053: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.054: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.055: INFO: Found daemon set daemon-set in namespace daemonsets-3 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 29 12:52:41.055: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 11/29/22 12:52:41.055
    STEP: watching for the daemon set status to be patched 11/29/22 12:52:41.063
    Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: ADDED
    Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.065: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.066: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.066: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.066: INFO: Observed daemon set daemon-set in namespace daemonsets-3 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 29 12:52:41.066: INFO: Observed &DaemonSet event: MODIFIED
    Nov 29 12:52:41.066: INFO: Found daemon set daemon-set in namespace daemonsets-3 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Nov 29 12:52:41.066: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/29/22 12:52:41.075
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3, will wait for the garbage collector to delete the pods 11/29/22 12:52:41.075
    Nov 29 12:52:41.132: INFO: Deleting DaemonSet.extensions daemon-set took: 4.352982ms
    Nov 29 12:52:41.232: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.427984ms
    Nov 29 12:52:43.936: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 29 12:52:43.936: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 29 12:52:43.945: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36306"},"items":null}

    Nov 29 12:52:43.951: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36308"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:52:43.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3" for this suite. 11/29/22 12:52:43.978
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:43.983
Nov 29 12:52:43.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename events 11/29/22 12:52:43.984
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:43.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:43.999
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 11/29/22 12:52:44.002
Nov 29 12:52:44.028: INFO: created test-event-1
Nov 29 12:52:44.051: INFO: created test-event-2
Nov 29 12:52:44.059: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 11/29/22 12:52:44.059
STEP: delete collection of events 11/29/22 12:52:44.081
Nov 29 12:52:44.081: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/29/22 12:52:44.098
Nov 29 12:52:44.098: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov 29 12:52:44.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8620" for this suite. 11/29/22 12:52:44.104
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":317,"skipped":5816,"failed":0}
------------------------------
• [0.125 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:43.983
    Nov 29 12:52:43.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename events 11/29/22 12:52:43.984
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:43.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:43.999
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 11/29/22 12:52:44.002
    Nov 29 12:52:44.028: INFO: created test-event-1
    Nov 29 12:52:44.051: INFO: created test-event-2
    Nov 29 12:52:44.059: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 11/29/22 12:52:44.059
    STEP: delete collection of events 11/29/22 12:52:44.081
    Nov 29 12:52:44.081: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/29/22 12:52:44.098
    Nov 29 12:52:44.098: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov 29 12:52:44.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8620" for this suite. 11/29/22 12:52:44.104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:44.109
Nov 29 12:52:44.109: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename gc 11/29/22 12:52:44.11
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:44.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:44.222
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 11/29/22 12:52:44.237
STEP: delete the rc 11/29/22 12:52:49.328
STEP: wait for the rc to be deleted 11/29/22 12:52:50.031
Nov 29 12:52:51.434: INFO: 80 pods remaining
Nov 29 12:52:51.434: INFO: 80 pods has nil DeletionTimestamp
Nov 29 12:52:51.434: INFO: 
Nov 29 12:52:52.573: INFO: 61 pods remaining
Nov 29 12:52:52.573: INFO: 60 pods has nil DeletionTimestamp
Nov 29 12:52:52.573: INFO: 
Nov 29 12:52:53.641: INFO: 59 pods remaining
Nov 29 12:52:53.641: INFO: 59 pods has nil DeletionTimestamp
Nov 29 12:52:53.641: INFO: 
Nov 29 12:52:54.512: INFO: 40 pods remaining
Nov 29 12:52:54.512: INFO: 39 pods has nil DeletionTimestamp
Nov 29 12:52:54.512: INFO: 
Nov 29 12:52:55.631: INFO: 20 pods remaining
Nov 29 12:52:55.631: INFO: 20 pods has nil DeletionTimestamp
Nov 29 12:52:55.631: INFO: 
Nov 29 12:52:56.376: INFO: 19 pods remaining
Nov 29 12:52:56.376: INFO: 12 pods has nil DeletionTimestamp
Nov 29 12:52:56.376: INFO: 
STEP: Gathering metrics 11/29/22 12:52:57.623
W1129 12:52:57.635087      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 29 12:52:57.635: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 29 12:52:57.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5784" for this suite. 11/29/22 12:52:57.678
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":318,"skipped":5832,"failed":0}
------------------------------
• [SLOW TEST] [14.013 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:44.109
    Nov 29 12:52:44.109: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename gc 11/29/22 12:52:44.11
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:44.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:44.222
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 11/29/22 12:52:44.237
    STEP: delete the rc 11/29/22 12:52:49.328
    STEP: wait for the rc to be deleted 11/29/22 12:52:50.031
    Nov 29 12:52:51.434: INFO: 80 pods remaining
    Nov 29 12:52:51.434: INFO: 80 pods has nil DeletionTimestamp
    Nov 29 12:52:51.434: INFO: 
    Nov 29 12:52:52.573: INFO: 61 pods remaining
    Nov 29 12:52:52.573: INFO: 60 pods has nil DeletionTimestamp
    Nov 29 12:52:52.573: INFO: 
    Nov 29 12:52:53.641: INFO: 59 pods remaining
    Nov 29 12:52:53.641: INFO: 59 pods has nil DeletionTimestamp
    Nov 29 12:52:53.641: INFO: 
    Nov 29 12:52:54.512: INFO: 40 pods remaining
    Nov 29 12:52:54.512: INFO: 39 pods has nil DeletionTimestamp
    Nov 29 12:52:54.512: INFO: 
    Nov 29 12:52:55.631: INFO: 20 pods remaining
    Nov 29 12:52:55.631: INFO: 20 pods has nil DeletionTimestamp
    Nov 29 12:52:55.631: INFO: 
    Nov 29 12:52:56.376: INFO: 19 pods remaining
    Nov 29 12:52:56.376: INFO: 12 pods has nil DeletionTimestamp
    Nov 29 12:52:56.376: INFO: 
    STEP: Gathering metrics 11/29/22 12:52:57.623
    W1129 12:52:57.635087      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 29 12:52:57.635: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 29 12:52:57.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5784" for this suite. 11/29/22 12:52:57.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:52:58.124
Nov 29 12:52:58.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename services 11/29/22 12:52:58.125
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:58.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:58.37
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-5849 11/29/22 12:52:58.372
STEP: creating service affinity-nodeport-transition in namespace services-5849 11/29/22 12:52:58.372
STEP: creating replication controller affinity-nodeport-transition in namespace services-5849 11/29/22 12:52:58.613
I1129 12:52:58.643878      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-5849, replica count: 3
I1129 12:53:01.694458      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:53:04.695572      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:53:07.696215      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:53:10.696800      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:53:13.697937      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:53:16.699977      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:53:19.700567      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:53:22.700975      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1129 12:53:25.701695      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 29 12:53:26.125: INFO: Creating new exec pod
Nov 29 12:53:26.128: INFO: Waiting up to 5m0s for pod "execpod-affinitydwshm" in namespace "services-5849" to be "running"
Nov 29 12:53:26.175: INFO: Pod "execpod-affinitydwshm": Phase="Pending", Reason="", readiness=false. Elapsed: 46.523906ms
Nov 29 12:53:28.177: INFO: Pod "execpod-affinitydwshm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049104974s
Nov 29 12:53:30.179: INFO: Pod "execpod-affinitydwshm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050742134s
Nov 29 12:53:32.179: INFO: Pod "execpod-affinitydwshm": Phase="Running", Reason="", readiness=true. Elapsed: 6.050603371s
Nov 29 12:53:32.179: INFO: Pod "execpod-affinitydwshm" satisfied condition "running"
Nov 29 12:53:33.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Nov 29 12:53:33.317: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Nov 29 12:53:33.317: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:53:33.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.64.174.194 80'
Nov 29 12:53:33.449: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.64.174.194 80\nConnection to 100.64.174.194 80 port [tcp/http] succeeded!\n"
Nov 29 12:53:33.449: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:53:33.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.155 30887'
Nov 29 12:53:33.578: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.155 30887\nConnection to 192.168.8.155 30887 port [tcp/*] succeeded!\n"
Nov 29 12:53:33.578: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:53:33.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.22 30887'
Nov 29 12:53:33.711: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.22 30887\nConnection to 192.168.8.22 30887 port [tcp/*] succeeded!\n"
Nov 29 12:53:33.711: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 29 12:53:33.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:30887/ ; done'
Nov 29 12:53:33.898: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n"
Nov 29 12:53:33.898: INFO: stdout: "\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t"
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:03.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:30887/ ; done'
Nov 29 12:54:04.083: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n"
Nov 29 12:54:04.083: INFO: stdout: "\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-8cx4x\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-8cx4x\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt"
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-8cx4x
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-8cx4x
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
Nov 29 12:54:04.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:30887/ ; done'
Nov 29 12:54:04.301: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n"
Nov 29 12:54:04.301: INFO: stdout: "\naffinity-nodeport-transition-8cx4x\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t"
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-8cx4x
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
Nov 29 12:54:04.301: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-5849, will wait for the garbage collector to delete the pods 11/29/22 12:54:04.309
Nov 29 12:54:04.366: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.090152ms
Nov 29 12:54:04.466: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.097496ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 29 12:54:06.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5849" for this suite. 11/29/22 12:54:06.392
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":319,"skipped":5866,"failed":0}
------------------------------
• [SLOW TEST] [68.271 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:52:58.124
    Nov 29 12:52:58.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename services 11/29/22 12:52:58.125
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:52:58.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:52:58.37
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-5849 11/29/22 12:52:58.372
    STEP: creating service affinity-nodeport-transition in namespace services-5849 11/29/22 12:52:58.372
    STEP: creating replication controller affinity-nodeport-transition in namespace services-5849 11/29/22 12:52:58.613
    I1129 12:52:58.643878      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-5849, replica count: 3
    I1129 12:53:01.694458      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:53:04.695572      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:53:07.696215      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:53:10.696800      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:53:13.697937      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:53:16.699977      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:53:19.700567      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:53:22.700975      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1129 12:53:25.701695      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 29 12:53:26.125: INFO: Creating new exec pod
    Nov 29 12:53:26.128: INFO: Waiting up to 5m0s for pod "execpod-affinitydwshm" in namespace "services-5849" to be "running"
    Nov 29 12:53:26.175: INFO: Pod "execpod-affinitydwshm": Phase="Pending", Reason="", readiness=false. Elapsed: 46.523906ms
    Nov 29 12:53:28.177: INFO: Pod "execpod-affinitydwshm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049104974s
    Nov 29 12:53:30.179: INFO: Pod "execpod-affinitydwshm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050742134s
    Nov 29 12:53:32.179: INFO: Pod "execpod-affinitydwshm": Phase="Running", Reason="", readiness=true. Elapsed: 6.050603371s
    Nov 29 12:53:32.179: INFO: Pod "execpod-affinitydwshm" satisfied condition "running"
    Nov 29 12:53:33.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Nov 29 12:53:33.317: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Nov 29 12:53:33.317: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:53:33.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.64.174.194 80'
    Nov 29 12:53:33.449: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.64.174.194 80\nConnection to 100.64.174.194 80 port [tcp/http] succeeded!\n"
    Nov 29 12:53:33.449: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:53:33.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.155 30887'
    Nov 29 12:53:33.578: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.155 30887\nConnection to 192.168.8.155 30887 port [tcp/*] succeeded!\n"
    Nov 29 12:53:33.578: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:53:33.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.8.22 30887'
    Nov 29 12:53:33.711: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.8.22 30887\nConnection to 192.168.8.22 30887 port [tcp/*] succeeded!\n"
    Nov 29 12:53:33.711: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 29 12:53:33.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:30887/ ; done'
    Nov 29 12:53:33.898: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n"
    Nov 29 12:53:33.898: INFO: stdout: "\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t"
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:53:33.898: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:03.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:30887/ ; done'
    Nov 29 12:54:04.083: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n"
    Nov 29 12:54:04.083: INFO: stdout: "\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-8cx4x\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-8cx4x\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-5hvnt\naffinity-nodeport-transition-5hvnt"
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-8cx4x
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-8cx4x
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.083: INFO: Received response from host: affinity-nodeport-transition-5hvnt
    Nov 29 12:54:04.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=services-5849 exec execpod-affinitydwshm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.8.111:30887/ ; done'
    Nov 29 12:54:04.301: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.8.111:30887/\n"
    Nov 29 12:54:04.301: INFO: stdout: "\naffinity-nodeport-transition-8cx4x\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t\naffinity-nodeport-transition-t6z7t"
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-8cx4x
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Received response from host: affinity-nodeport-transition-t6z7t
    Nov 29 12:54:04.301: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-5849, will wait for the garbage collector to delete the pods 11/29/22 12:54:04.309
    Nov 29 12:54:04.366: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.090152ms
    Nov 29 12:54:04.466: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.097496ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 29 12:54:06.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5849" for this suite. 11/29/22 12:54:06.392
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:06.397
Nov 29 12:54:06.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename events 11/29/22 12:54:06.398
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:06.406
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:06.411
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 11/29/22 12:54:06.413
STEP: get a list of Events with a label in the current namespace 11/29/22 12:54:06.426
STEP: delete a list of events 11/29/22 12:54:06.428
Nov 29 12:54:06.428: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/29/22 12:54:06.438
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov 29 12:54:06.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5504" for this suite. 11/29/22 12:54:06.445
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":320,"skipped":5896,"failed":0}
------------------------------
• [0.051 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:06.397
    Nov 29 12:54:06.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename events 11/29/22 12:54:06.398
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:06.406
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:06.411
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 11/29/22 12:54:06.413
    STEP: get a list of Events with a label in the current namespace 11/29/22 12:54:06.426
    STEP: delete a list of events 11/29/22 12:54:06.428
    Nov 29 12:54:06.428: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/29/22 12:54:06.438
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov 29 12:54:06.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5504" for this suite. 11/29/22 12:54:06.445
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:06.449
Nov 29 12:54:06.449: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 12:54:06.449
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:06.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:06.458
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 11/29/22 12:54:06.461
STEP: Getting a ResourceQuota 11/29/22 12:54:06.463
STEP: Listing all ResourceQuotas with LabelSelector 11/29/22 12:54:06.465
STEP: Patching the ResourceQuota 11/29/22 12:54:06.467
STEP: Deleting a Collection of ResourceQuotas 11/29/22 12:54:06.473
STEP: Verifying the deleted ResourceQuota 11/29/22 12:54:06.486
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 12:54:06.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4849" for this suite. 11/29/22 12:54:06.491
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":321,"skipped":5909,"failed":0}
------------------------------
• [0.046 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:06.449
    Nov 29 12:54:06.449: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 12:54:06.449
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:06.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:06.458
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 11/29/22 12:54:06.461
    STEP: Getting a ResourceQuota 11/29/22 12:54:06.463
    STEP: Listing all ResourceQuotas with LabelSelector 11/29/22 12:54:06.465
    STEP: Patching the ResourceQuota 11/29/22 12:54:06.467
    STEP: Deleting a Collection of ResourceQuotas 11/29/22 12:54:06.473
    STEP: Verifying the deleted ResourceQuota 11/29/22 12:54:06.486
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 12:54:06.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4849" for this suite. 11/29/22 12:54:06.491
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:06.497
Nov 29 12:54:06.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 12:54:06.498
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:06.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:06.508
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/29/22 12:54:06.51
Nov 29 12:54:06.514: INFO: Waiting up to 5m0s for pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb" in namespace "emptydir-8445" to be "Succeeded or Failed"
Nov 29 12:54:06.520: INFO: Pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.798265ms
Nov 29 12:54:08.523: INFO: Pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008623143s
Nov 29 12:54:10.524: INFO: Pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009989352s
STEP: Saw pod success 11/29/22 12:54:10.524
Nov 29 12:54:10.524: INFO: Pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb" satisfied condition "Succeeded or Failed"
Nov 29 12:54:10.527: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-efe1456f-ff32-411c-b01c-eefe5f5295cb container test-container: <nil>
STEP: delete the pod 11/29/22 12:54:10.531
Nov 29 12:54:10.537: INFO: Waiting for pod pod-efe1456f-ff32-411c-b01c-eefe5f5295cb to disappear
Nov 29 12:54:10.539: INFO: Pod pod-efe1456f-ff32-411c-b01c-eefe5f5295cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 12:54:10.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8445" for this suite. 11/29/22 12:54:10.542
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":322,"skipped":5939,"failed":0}
------------------------------
• [4.048 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:06.497
    Nov 29 12:54:06.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 12:54:06.498
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:06.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:06.508
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/29/22 12:54:06.51
    Nov 29 12:54:06.514: INFO: Waiting up to 5m0s for pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb" in namespace "emptydir-8445" to be "Succeeded or Failed"
    Nov 29 12:54:06.520: INFO: Pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.798265ms
    Nov 29 12:54:08.523: INFO: Pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008623143s
    Nov 29 12:54:10.524: INFO: Pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009989352s
    STEP: Saw pod success 11/29/22 12:54:10.524
    Nov 29 12:54:10.524: INFO: Pod "pod-efe1456f-ff32-411c-b01c-eefe5f5295cb" satisfied condition "Succeeded or Failed"
    Nov 29 12:54:10.527: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-efe1456f-ff32-411c-b01c-eefe5f5295cb container test-container: <nil>
    STEP: delete the pod 11/29/22 12:54:10.531
    Nov 29 12:54:10.537: INFO: Waiting for pod pod-efe1456f-ff32-411c-b01c-eefe5f5295cb to disappear
    Nov 29 12:54:10.539: INFO: Pod pod-efe1456f-ff32-411c-b01c-eefe5f5295cb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 12:54:10.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8445" for this suite. 11/29/22 12:54:10.542
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:10.547
Nov 29 12:54:10.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 12:54:10.548
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:10.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:10.56
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/29/22 12:54:10.562
Nov 29 12:54:10.563: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:54:14.332: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:54:26.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8726" for this suite. 11/29/22 12:54:26.021
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":323,"skipped":5969,"failed":0}
------------------------------
• [SLOW TEST] [15.478 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:10.547
    Nov 29 12:54:10.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 12:54:10.548
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:10.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:10.56
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/29/22 12:54:10.562
    Nov 29 12:54:10.563: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:54:14.332: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:54:26.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8726" for this suite. 11/29/22 12:54:26.021
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:26.028
Nov 29 12:54:26.029: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 12:54:26.029
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:26.037
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:26.039
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 11/29/22 12:54:26.042
Nov 29 12:54:26.046: INFO: Waiting up to 5m0s for pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e" in namespace "emptydir-6972" to be "Succeeded or Failed"
Nov 29 12:54:26.050: INFO: Pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450826ms
Nov 29 12:54:28.052: INFO: Pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006196033s
Nov 29 12:54:30.054: INFO: Pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007703152s
STEP: Saw pod success 11/29/22 12:54:30.054
Nov 29 12:54:30.054: INFO: Pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e" satisfied condition "Succeeded or Failed"
Nov 29 12:54:30.056: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e container test-container: <nil>
STEP: delete the pod 11/29/22 12:54:30.059
Nov 29 12:54:30.066: INFO: Waiting for pod pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e to disappear
Nov 29 12:54:30.069: INFO: Pod pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 12:54:30.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6972" for this suite. 11/29/22 12:54:30.072
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":324,"skipped":5984,"failed":0}
------------------------------
• [4.047 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:26.028
    Nov 29 12:54:26.029: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 12:54:26.029
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:26.037
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:26.039
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 11/29/22 12:54:26.042
    Nov 29 12:54:26.046: INFO: Waiting up to 5m0s for pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e" in namespace "emptydir-6972" to be "Succeeded or Failed"
    Nov 29 12:54:26.050: INFO: Pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450826ms
    Nov 29 12:54:28.052: INFO: Pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006196033s
    Nov 29 12:54:30.054: INFO: Pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007703152s
    STEP: Saw pod success 11/29/22 12:54:30.054
    Nov 29 12:54:30.054: INFO: Pod "pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e" satisfied condition "Succeeded or Failed"
    Nov 29 12:54:30.056: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e container test-container: <nil>
    STEP: delete the pod 11/29/22 12:54:30.059
    Nov 29 12:54:30.066: INFO: Waiting for pod pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e to disappear
    Nov 29 12:54:30.069: INFO: Pod pod-41c6fea2-8737-4c8d-9f4f-41d0734aff9e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 12:54:30.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6972" for this suite. 11/29/22 12:54:30.072
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:30.078
Nov 29 12:54:30.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:54:30.079
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:30.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:30.091
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-3f00cea9-4c9a-4a8d-9be1-77f16823a15f 11/29/22 12:54:30.093
STEP: Creating a pod to test consume configMaps 11/29/22 12:54:30.096
Nov 29 12:54:30.101: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5" in namespace "projected-5833" to be "Succeeded or Failed"
Nov 29 12:54:30.105: INFO: Pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.465432ms
Nov 29 12:54:32.109: INFO: Pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008137111s
Nov 29 12:54:34.109: INFO: Pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008107519s
STEP: Saw pod success 11/29/22 12:54:34.109
Nov 29 12:54:34.109: INFO: Pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5" satisfied condition "Succeeded or Failed"
Nov 29 12:54:34.111: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5 container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:54:34.115
Nov 29 12:54:34.123: INFO: Waiting for pod pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5 to disappear
Nov 29 12:54:34.126: INFO: Pod pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 12:54:34.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5833" for this suite. 11/29/22 12:54:34.129
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":325,"skipped":6017,"failed":0}
------------------------------
• [4.056 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:30.078
    Nov 29 12:54:30.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:54:30.079
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:30.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:30.091
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-3f00cea9-4c9a-4a8d-9be1-77f16823a15f 11/29/22 12:54:30.093
    STEP: Creating a pod to test consume configMaps 11/29/22 12:54:30.096
    Nov 29 12:54:30.101: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5" in namespace "projected-5833" to be "Succeeded or Failed"
    Nov 29 12:54:30.105: INFO: Pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.465432ms
    Nov 29 12:54:32.109: INFO: Pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008137111s
    Nov 29 12:54:34.109: INFO: Pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008107519s
    STEP: Saw pod success 11/29/22 12:54:34.109
    Nov 29 12:54:34.109: INFO: Pod "pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5" satisfied condition "Succeeded or Failed"
    Nov 29 12:54:34.111: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5 container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:54:34.115
    Nov 29 12:54:34.123: INFO: Waiting for pod pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5 to disappear
    Nov 29 12:54:34.126: INFO: Pod pod-projected-configmaps-09315c04-42ff-4301-a26b-4a886fccbbe5 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 12:54:34.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5833" for this suite. 11/29/22 12:54:34.129
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:34.134
Nov 29 12:54:34.135: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename watch 11/29/22 12:54:34.136
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:34.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:34.149
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 11/29/22 12:54:34.151
STEP: modifying the configmap once 11/29/22 12:54:34.155
STEP: modifying the configmap a second time 11/29/22 12:54:34.159
STEP: deleting the configmap 11/29/22 12:54:34.185
STEP: creating a watch on configmaps from the resource version returned by the first update 11/29/22 12:54:34.188
STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/29/22 12:54:34.19
Nov 29 12:54:34.190: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-581  edecb818-8bdb-4daa-a1f0-0a92e992912b 37755 0 2022-11-29 12:54:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-29 12:54:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 29 12:54:34.191: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-581  edecb818-8bdb-4daa-a1f0-0a92e992912b 37756 0 2022-11-29 12:54:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-29 12:54:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 29 12:54:34.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-581" for this suite. 11/29/22 12:54:34.194
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":326,"skipped":6017,"failed":0}
------------------------------
• [0.064 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:34.134
    Nov 29 12:54:34.135: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename watch 11/29/22 12:54:34.136
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:34.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:34.149
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 11/29/22 12:54:34.151
    STEP: modifying the configmap once 11/29/22 12:54:34.155
    STEP: modifying the configmap a second time 11/29/22 12:54:34.159
    STEP: deleting the configmap 11/29/22 12:54:34.185
    STEP: creating a watch on configmaps from the resource version returned by the first update 11/29/22 12:54:34.188
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/29/22 12:54:34.19
    Nov 29 12:54:34.190: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-581  edecb818-8bdb-4daa-a1f0-0a92e992912b 37755 0 2022-11-29 12:54:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-29 12:54:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 29 12:54:34.191: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-581  edecb818-8bdb-4daa-a1f0-0a92e992912b 37756 0 2022-11-29 12:54:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-29 12:54:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 29 12:54:34.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-581" for this suite. 11/29/22 12:54:34.194
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:34.199
Nov 29 12:54:34.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 12:54:34.2
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:34.211
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:34.213
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 11/29/22 12:54:34.215
Nov 29 12:54:34.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-495 cluster-info'
Nov 29 12:54:34.297: INFO: stderr: ""
Nov 29 12:54:34.297: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 12:54:34.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-495" for this suite. 11/29/22 12:54:34.301
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":327,"skipped":6020,"failed":0}
------------------------------
• [0.106 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:34.199
    Nov 29 12:54:34.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 12:54:34.2
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:34.211
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:34.213
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 11/29/22 12:54:34.215
    Nov 29 12:54:34.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-495 cluster-info'
    Nov 29 12:54:34.297: INFO: stderr: ""
    Nov 29 12:54:34.297: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 12:54:34.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-495" for this suite. 11/29/22 12:54:34.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:34.306
Nov 29 12:54:34.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename resourcequota 11/29/22 12:54:34.306
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:34.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:34.322
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 11/29/22 12:54:34.325
STEP: Creating a ResourceQuota 11/29/22 12:54:39.329
STEP: Ensuring resource quota status is calculated 11/29/22 12:54:39.332
STEP: Creating a ReplicaSet 11/29/22 12:54:41.335
STEP: Ensuring resource quota status captures replicaset creation 11/29/22 12:54:41.342
STEP: Deleting a ReplicaSet 11/29/22 12:54:43.345
STEP: Ensuring resource quota status released usage 11/29/22 12:54:43.348
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 29 12:54:45.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3937" for this suite. 11/29/22 12:54:45.356
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":328,"skipped":6030,"failed":0}
------------------------------
• [SLOW TEST] [11.054 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:34.306
    Nov 29 12:54:34.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename resourcequota 11/29/22 12:54:34.306
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:34.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:34.322
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 11/29/22 12:54:34.325
    STEP: Creating a ResourceQuota 11/29/22 12:54:39.329
    STEP: Ensuring resource quota status is calculated 11/29/22 12:54:39.332
    STEP: Creating a ReplicaSet 11/29/22 12:54:41.335
    STEP: Ensuring resource quota status captures replicaset creation 11/29/22 12:54:41.342
    STEP: Deleting a ReplicaSet 11/29/22 12:54:43.345
    STEP: Ensuring resource quota status released usage 11/29/22 12:54:43.348
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 29 12:54:45.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3937" for this suite. 11/29/22 12:54:45.356
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:45.36
Nov 29 12:54:45.360: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename downward-api 11/29/22 12:54:45.361
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:45.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:45.407
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 11/29/22 12:54:45.41
Nov 29 12:54:45.420: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412" in namespace "downward-api-6550" to be "Succeeded or Failed"
Nov 29 12:54:45.440: INFO: Pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412": Phase="Pending", Reason="", readiness=false. Elapsed: 19.657457ms
Nov 29 12:54:47.444: INFO: Pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023842789s
Nov 29 12:54:49.443: INFO: Pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023299913s
STEP: Saw pod success 11/29/22 12:54:49.443
Nov 29 12:54:49.444: INFO: Pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412" satisfied condition "Succeeded or Failed"
Nov 29 12:54:49.449: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412 container client-container: <nil>
STEP: delete the pod 11/29/22 12:54:49.453
Nov 29 12:54:49.459: INFO: Waiting for pod downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412 to disappear
Nov 29 12:54:49.461: INFO: Pod downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 29 12:54:49.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6550" for this suite. 11/29/22 12:54:49.465
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":329,"skipped":6044,"failed":0}
------------------------------
• [4.108 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:45.36
    Nov 29 12:54:45.360: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename downward-api 11/29/22 12:54:45.361
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:45.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:45.407
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 11/29/22 12:54:45.41
    Nov 29 12:54:45.420: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412" in namespace "downward-api-6550" to be "Succeeded or Failed"
    Nov 29 12:54:45.440: INFO: Pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412": Phase="Pending", Reason="", readiness=false. Elapsed: 19.657457ms
    Nov 29 12:54:47.444: INFO: Pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023842789s
    Nov 29 12:54:49.443: INFO: Pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023299913s
    STEP: Saw pod success 11/29/22 12:54:49.443
    Nov 29 12:54:49.444: INFO: Pod "downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412" satisfied condition "Succeeded or Failed"
    Nov 29 12:54:49.449: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412 container client-container: <nil>
    STEP: delete the pod 11/29/22 12:54:49.453
    Nov 29 12:54:49.459: INFO: Waiting for pod downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412 to disappear
    Nov 29 12:54:49.461: INFO: Pod downwardapi-volume-e427732f-59cf-4ada-8e76-f9ae41f1b412 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 29 12:54:49.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6550" for this suite. 11/29/22 12:54:49.465
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:49.468
Nov 29 12:54:49.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 12:54:49.469
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:49.479
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:49.481
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 11/29/22 12:54:49.483
Nov 29 12:54:49.487: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d" in namespace "emptydir-4938" to be "running"
Nov 29 12:54:49.491: INFO: Pod "pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.96936ms
Nov 29 12:54:51.494: INFO: Pod "pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d": Phase="Running", Reason="", readiness=false. Elapsed: 2.007080819s
Nov 29 12:54:51.494: INFO: Pod "pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d" satisfied condition "running"
STEP: Reading file content from the nginx-container 11/29/22 12:54:51.495
Nov 29 12:54:51.495: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-4938 PodName:pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 12:54:51.495: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 12:54:51.495: INFO: ExecWithOptions: Clientset creation
Nov 29 12:54:51.496: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/emptydir-4938/pods/pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Nov 29 12:54:51.555: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 12:54:51.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4938" for this suite. 11/29/22 12:54:51.558
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":330,"skipped":6045,"failed":0}
------------------------------
• [2.094 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:49.468
    Nov 29 12:54:49.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 12:54:49.469
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:49.479
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:49.481
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 11/29/22 12:54:49.483
    Nov 29 12:54:49.487: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d" in namespace "emptydir-4938" to be "running"
    Nov 29 12:54:49.491: INFO: Pod "pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.96936ms
    Nov 29 12:54:51.494: INFO: Pod "pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d": Phase="Running", Reason="", readiness=false. Elapsed: 2.007080819s
    Nov 29 12:54:51.494: INFO: Pod "pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d" satisfied condition "running"
    STEP: Reading file content from the nginx-container 11/29/22 12:54:51.495
    Nov 29 12:54:51.495: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-4938 PodName:pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 12:54:51.495: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 12:54:51.495: INFO: ExecWithOptions: Clientset creation
    Nov 29 12:54:51.496: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/emptydir-4938/pods/pod-sharedvolume-488ec4d1-b8f3-40c4-acda-183a52ce7b5d/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Nov 29 12:54:51.555: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 12:54:51.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4938" for this suite. 11/29/22 12:54:51.558
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:54:51.564
Nov 29 12:54:51.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename dns 11/29/22 12:54:51.565
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:51.578
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:51.58
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 11/29/22 12:54:51.583
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3120 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3120;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3120 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3120;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3120.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3120.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3120.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3120.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3120.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3120.svc;check="$$(dig +notcp +noall +answer +search 242.230.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.230.242_udp@PTR;check="$$(dig +tcp +noall +answer +search 242.230.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.230.242_tcp@PTR;sleep 1; done
 11/29/22 12:54:51.595
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3120 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3120;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3120 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3120;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3120.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3120.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3120.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3120.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3120.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3120.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3120.svc;check="$$(dig +notcp +noall +answer +search 242.230.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.230.242_udp@PTR;check="$$(dig +tcp +noall +answer +search 242.230.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.230.242_tcp@PTR;sleep 1; done
 11/29/22 12:54:51.595
STEP: creating a pod to probe DNS 11/29/22 12:54:51.595
STEP: submitting the pod to kubernetes 11/29/22 12:54:51.595
Nov 29 12:54:51.603: INFO: Waiting up to 15m0s for pod "dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f" in namespace "dns-3120" to be "running"
Nov 29 12:54:51.609: INFO: Pod "dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.317484ms
Nov 29 12:54:53.613: INFO: Pod "dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.009872907s
Nov 29 12:54:53.613: INFO: Pod "dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f" satisfied condition "running"
STEP: retrieving the pod 11/29/22 12:54:53.613
STEP: looking for the results for each expected name from probers 11/29/22 12:54:53.615
Nov 29 12:54:53.618: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.620: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.622: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.624: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.626: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.628: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.630: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.632: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.642: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.644: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.646: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.648: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.649: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.651: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.653: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.655: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:53.662: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

Nov 29 12:54:58.665: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.668: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.670: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.673: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.675: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.678: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.680: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.682: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.693: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.694: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.696: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.698: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.700: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.703: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.705: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.707: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:54:58.715: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

Nov 29 12:55:03.666: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.670: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.673: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.675: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.678: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.681: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.683: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.695: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.698: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.701: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.703: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.706: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.708: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.711: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.713: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:03.722: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

Nov 29 12:55:08.666: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.669: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.671: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.674: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.677: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.679: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.681: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.683: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.693: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.695: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.696: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.698: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.700: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.702: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.704: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.706: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:08.714: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

Nov 29 12:55:13.665: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.668: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.670: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.675: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.677: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.679: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.681: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.682: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.691: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.695: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.697: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.719: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.722: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.725: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.727: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.729: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:13.741: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

Nov 29 12:55:18.670: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.673: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.675: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.678: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.681: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.684: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.686: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.689: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.706: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.709: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.711: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.713: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.715: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.718: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.720: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.723: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:18.735: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

Nov 29 12:55:23.665: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.669: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.672: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.674: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.677: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.679: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.681: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.683: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.694: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.696: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.699: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.701: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.702: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.704: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.706: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.708: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
Nov 29 12:55:23.715: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

Nov 29 12:55:28.713: INFO: DNS probes using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f succeeded

STEP: deleting the pod 11/29/22 12:55:28.713
STEP: deleting the test service 11/29/22 12:55:28.728
STEP: deleting the test headless service 11/29/22 12:55:28.777
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 29 12:55:28.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3120" for this suite. 11/29/22 12:55:28.8
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":331,"skipped":6055,"failed":0}
------------------------------
• [SLOW TEST] [37.250 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:54:51.564
    Nov 29 12:54:51.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename dns 11/29/22 12:54:51.565
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:54:51.578
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:54:51.58
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 11/29/22 12:54:51.583
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3120 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3120;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3120 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3120;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3120.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3120.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3120.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3120.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3120.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3120.svc;check="$$(dig +notcp +noall +answer +search 242.230.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.230.242_udp@PTR;check="$$(dig +tcp +noall +answer +search 242.230.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.230.242_tcp@PTR;sleep 1; done
     11/29/22 12:54:51.595
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3120 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3120;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3120 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3120;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3120.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3120.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3120.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3120.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3120.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3120.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3120.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3120.svc;check="$$(dig +notcp +noall +answer +search 242.230.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.230.242_udp@PTR;check="$$(dig +tcp +noall +answer +search 242.230.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.230.242_tcp@PTR;sleep 1; done
     11/29/22 12:54:51.595
    STEP: creating a pod to probe DNS 11/29/22 12:54:51.595
    STEP: submitting the pod to kubernetes 11/29/22 12:54:51.595
    Nov 29 12:54:51.603: INFO: Waiting up to 15m0s for pod "dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f" in namespace "dns-3120" to be "running"
    Nov 29 12:54:51.609: INFO: Pod "dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.317484ms
    Nov 29 12:54:53.613: INFO: Pod "dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.009872907s
    Nov 29 12:54:53.613: INFO: Pod "dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f" satisfied condition "running"
    STEP: retrieving the pod 11/29/22 12:54:53.613
    STEP: looking for the results for each expected name from probers 11/29/22 12:54:53.615
    Nov 29 12:54:53.618: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.620: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.622: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.624: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.626: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.628: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.630: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.632: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.642: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.644: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.646: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.648: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.649: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.651: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.653: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.655: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:53.662: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

    Nov 29 12:54:58.665: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.668: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.670: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.673: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.675: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.678: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.680: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.682: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.693: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.694: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.696: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.698: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.700: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.703: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.705: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.707: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:54:58.715: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

    Nov 29 12:55:03.666: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.670: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.673: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.675: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.678: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.681: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.683: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.695: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.698: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.701: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.703: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.706: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.708: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.711: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.713: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:03.722: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

    Nov 29 12:55:08.666: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.669: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.671: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.674: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.677: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.679: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.681: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.683: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.693: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.695: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.696: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.698: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.700: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.702: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.704: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.706: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:08.714: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

    Nov 29 12:55:13.665: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.668: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.670: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.675: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.677: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.679: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.681: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.682: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.691: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.695: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.697: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.719: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.722: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.725: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.727: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.729: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:13.741: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

    Nov 29 12:55:18.670: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.673: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.675: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.678: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.681: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.684: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.686: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.689: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.706: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.709: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.711: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.713: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.715: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.718: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.720: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.723: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:18.735: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

    Nov 29 12:55:23.665: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.669: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.672: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.674: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.677: INFO: Unable to read wheezy_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.679: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.681: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.683: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.694: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.696: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.699: INFO: Unable to read jessie_udp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.701: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120 from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.702: INFO: Unable to read jessie_udp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.704: INFO: Unable to read jessie_tcp@dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.706: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.708: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc from pod dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f: the server could not find the requested resource (get pods dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f)
    Nov 29 12:55:23.715: INFO: Lookups using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3120 wheezy_tcp@dns-test-service.dns-3120 wheezy_udp@dns-test-service.dns-3120.svc wheezy_tcp@dns-test-service.dns-3120.svc wheezy_udp@_http._tcp.dns-test-service.dns-3120.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3120.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3120 jessie_tcp@dns-test-service.dns-3120 jessie_udp@dns-test-service.dns-3120.svc jessie_tcp@dns-test-service.dns-3120.svc jessie_udp@_http._tcp.dns-test-service.dns-3120.svc jessie_tcp@_http._tcp.dns-test-service.dns-3120.svc]

    Nov 29 12:55:28.713: INFO: DNS probes using dns-3120/dns-test-4d809ec9-8c5e-4732-b246-fd95840f8b6f succeeded

    STEP: deleting the pod 11/29/22 12:55:28.713
    STEP: deleting the test service 11/29/22 12:55:28.728
    STEP: deleting the test headless service 11/29/22 12:55:28.777
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 29 12:55:28.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3120" for this suite. 11/29/22 12:55:28.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:55:28.817
Nov 29 12:55:28.817: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename configmap 11/29/22 12:55:28.818
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:55:28.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:55:28.842
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-12200139-cbc8-4677-8a86-7024d5d64603 11/29/22 12:55:28.844
STEP: Creating a pod to test consume configMaps 11/29/22 12:55:28.847
Nov 29 12:55:28.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de" in namespace "configmap-4504" to be "Succeeded or Failed"
Nov 29 12:55:28.855: INFO: Pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de": Phase="Pending", Reason="", readiness=false. Elapsed: 3.062722ms
Nov 29 12:55:30.859: INFO: Pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00687851s
Nov 29 12:55:32.858: INFO: Pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006159117s
STEP: Saw pod success 11/29/22 12:55:32.858
Nov 29 12:55:32.859: INFO: Pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de" satisfied condition "Succeeded or Failed"
Nov 29 12:55:32.861: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:55:32.864
Nov 29 12:55:32.870: INFO: Waiting for pod pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de to disappear
Nov 29 12:55:32.872: INFO: Pod pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 29 12:55:32.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4504" for this suite. 11/29/22 12:55:32.875
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":332,"skipped":6068,"failed":0}
------------------------------
• [4.062 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:55:28.817
    Nov 29 12:55:28.817: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename configmap 11/29/22 12:55:28.818
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:55:28.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:55:28.842
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-12200139-cbc8-4677-8a86-7024d5d64603 11/29/22 12:55:28.844
    STEP: Creating a pod to test consume configMaps 11/29/22 12:55:28.847
    Nov 29 12:55:28.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de" in namespace "configmap-4504" to be "Succeeded or Failed"
    Nov 29 12:55:28.855: INFO: Pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de": Phase="Pending", Reason="", readiness=false. Elapsed: 3.062722ms
    Nov 29 12:55:30.859: INFO: Pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00687851s
    Nov 29 12:55:32.858: INFO: Pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006159117s
    STEP: Saw pod success 11/29/22 12:55:32.858
    Nov 29 12:55:32.859: INFO: Pod "pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de" satisfied condition "Succeeded or Failed"
    Nov 29 12:55:32.861: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:55:32.864
    Nov 29 12:55:32.870: INFO: Waiting for pod pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de to disappear
    Nov 29 12:55:32.872: INFO: Pod pod-configmaps-21b39dec-5c61-418c-9205-358ff92b65de no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 29 12:55:32.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4504" for this suite. 11/29/22 12:55:32.875
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:55:32.88
Nov 29 12:55:32.880: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:55:32.881
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:55:32.888
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:55:32.89
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-9bab5afe-7195-4f20-a1fe-faa2051e6f36 11/29/22 12:55:32.892
STEP: Creating a pod to test consume configMaps 11/29/22 12:55:32.898
Nov 29 12:55:32.903: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322" in namespace "projected-8443" to be "Succeeded or Failed"
Nov 29 12:55:32.906: INFO: Pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322": Phase="Pending", Reason="", readiness=false. Elapsed: 2.559303ms
Nov 29 12:55:34.909: INFO: Pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006185709s
Nov 29 12:55:36.910: INFO: Pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00675067s
STEP: Saw pod success 11/29/22 12:55:36.91
Nov 29 12:55:36.910: INFO: Pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322" satisfied condition "Succeeded or Failed"
Nov 29 12:55:36.912: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322 container projected-configmap-volume-test: <nil>
STEP: delete the pod 11/29/22 12:55:36.915
Nov 29 12:55:36.922: INFO: Waiting for pod pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322 to disappear
Nov 29 12:55:36.924: INFO: Pod pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 12:55:36.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8443" for this suite. 11/29/22 12:55:36.927
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":333,"skipped":6087,"failed":0}
------------------------------
• [4.050 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:55:32.88
    Nov 29 12:55:32.880: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:55:32.881
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:55:32.888
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:55:32.89
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-9bab5afe-7195-4f20-a1fe-faa2051e6f36 11/29/22 12:55:32.892
    STEP: Creating a pod to test consume configMaps 11/29/22 12:55:32.898
    Nov 29 12:55:32.903: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322" in namespace "projected-8443" to be "Succeeded or Failed"
    Nov 29 12:55:32.906: INFO: Pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322": Phase="Pending", Reason="", readiness=false. Elapsed: 2.559303ms
    Nov 29 12:55:34.909: INFO: Pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006185709s
    Nov 29 12:55:36.910: INFO: Pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00675067s
    STEP: Saw pod success 11/29/22 12:55:36.91
    Nov 29 12:55:36.910: INFO: Pod "pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322" satisfied condition "Succeeded or Failed"
    Nov 29 12:55:36.912: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 11/29/22 12:55:36.915
    Nov 29 12:55:36.922: INFO: Waiting for pod pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322 to disappear
    Nov 29 12:55:36.924: INFO: Pod pod-projected-configmaps-2503c3ae-d1c3-49b1-a875-883cb43da322 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 12:55:36.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8443" for this suite. 11/29/22 12:55:36.927
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:55:36.93
Nov 29 12:55:36.930: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-watch 11/29/22 12:55:36.931
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:55:36.941
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:55:36.944
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Nov 29 12:55:36.945: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Creating first CR  11/29/22 12:55:39.495
Nov 29 12:55:39.499: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:39Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:55:39Z]] name:name1 resourceVersion:38102 uid:fa8baefd-cd8a-4aba-bdf5-4edc50360b62] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 11/29/22 12:55:49.499
Nov 29 12:55:49.505: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:49Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:55:49Z]] name:name2 resourceVersion:38132 uid:68b8ebda-5bd3-4d83-95f2-c0162f2d7f71] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 11/29/22 12:55:59.506
Nov 29 12:55:59.510: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:39Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:55:59Z]] name:name1 resourceVersion:38152 uid:fa8baefd-cd8a-4aba-bdf5-4edc50360b62] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 11/29/22 12:56:09.512
Nov 29 12:56:09.517: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:49Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:56:09Z]] name:name2 resourceVersion:38171 uid:68b8ebda-5bd3-4d83-95f2-c0162f2d7f71] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 11/29/22 12:56:19.518
Nov 29 12:56:19.716: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:39Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:55:59Z]] name:name1 resourceVersion:38191 uid:fa8baefd-cd8a-4aba-bdf5-4edc50360b62] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 11/29/22 12:56:29.719
Nov 29 12:56:29.723: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:49Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:56:09Z]] name:name2 resourceVersion:38210 uid:68b8ebda-5bd3-4d83-95f2-c0162f2d7f71] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 12:56:40.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-1940" for this suite. 11/29/22 12:56:40.241
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":334,"skipped":6095,"failed":0}
------------------------------
• [SLOW TEST] [63.315 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:55:36.93
    Nov 29 12:55:36.930: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-watch 11/29/22 12:55:36.931
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:55:36.941
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:55:36.944
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Nov 29 12:55:36.945: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Creating first CR  11/29/22 12:55:39.495
    Nov 29 12:55:39.499: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:39Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:55:39Z]] name:name1 resourceVersion:38102 uid:fa8baefd-cd8a-4aba-bdf5-4edc50360b62] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 11/29/22 12:55:49.499
    Nov 29 12:55:49.505: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:49Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:55:49Z]] name:name2 resourceVersion:38132 uid:68b8ebda-5bd3-4d83-95f2-c0162f2d7f71] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 11/29/22 12:55:59.506
    Nov 29 12:55:59.510: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:39Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:55:59Z]] name:name1 resourceVersion:38152 uid:fa8baefd-cd8a-4aba-bdf5-4edc50360b62] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 11/29/22 12:56:09.512
    Nov 29 12:56:09.517: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:49Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:56:09Z]] name:name2 resourceVersion:38171 uid:68b8ebda-5bd3-4d83-95f2-c0162f2d7f71] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 11/29/22 12:56:19.518
    Nov 29 12:56:19.716: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:39Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:55:59Z]] name:name1 resourceVersion:38191 uid:fa8baefd-cd8a-4aba-bdf5-4edc50360b62] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 11/29/22 12:56:29.719
    Nov 29 12:56:29.723: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-29T12:55:49Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-29T12:56:09Z]] name:name2 resourceVersion:38210 uid:68b8ebda-5bd3-4d83-95f2-c0162f2d7f71] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 12:56:40.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-1940" for this suite. 11/29/22 12:56:40.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:56:40.247
Nov 29 12:56:40.247: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-probe 11/29/22 12:56:40.248
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:56:40.256
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:56:40.259
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 29 12:57:40.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7117" for this suite. 11/29/22 12:57:40.275
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":335,"skipped":6125,"failed":0}
------------------------------
• [SLOW TEST] [60.033 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:56:40.247
    Nov 29 12:56:40.247: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-probe 11/29/22 12:56:40.248
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:56:40.256
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:56:40.259
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 29 12:57:40.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7117" for this suite. 11/29/22 12:57:40.275
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:57:40.281
Nov 29 12:57:40.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 12:57:40.282
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:57:40.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:57:40.292
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-55252446-6579-4925-ba23-17c036064616 11/29/22 12:57:40.295
STEP: Creating a pod to test consume configMaps 11/29/22 12:57:40.301
Nov 29 12:57:40.311: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e" in namespace "projected-7072" to be "Succeeded or Failed"
Nov 29 12:57:40.316: INFO: Pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.074794ms
Nov 29 12:57:42.319: INFO: Pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008625715s
Nov 29 12:57:44.319: INFO: Pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008111751s
STEP: Saw pod success 11/29/22 12:57:44.319
Nov 29 12:57:44.319: INFO: Pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e" satisfied condition "Succeeded or Failed"
Nov 29 12:57:44.321: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e container agnhost-container: <nil>
STEP: delete the pod 11/29/22 12:57:44.327
Nov 29 12:57:44.333: INFO: Waiting for pod pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e to disappear
Nov 29 12:57:44.335: INFO: Pod pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 29 12:57:44.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7072" for this suite. 11/29/22 12:57:44.338
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":336,"skipped":6156,"failed":0}
------------------------------
• [4.065 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:57:40.281
    Nov 29 12:57:40.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 12:57:40.282
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:57:40.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:57:40.292
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-55252446-6579-4925-ba23-17c036064616 11/29/22 12:57:40.295
    STEP: Creating a pod to test consume configMaps 11/29/22 12:57:40.301
    Nov 29 12:57:40.311: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e" in namespace "projected-7072" to be "Succeeded or Failed"
    Nov 29 12:57:40.316: INFO: Pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.074794ms
    Nov 29 12:57:42.319: INFO: Pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008625715s
    Nov 29 12:57:44.319: INFO: Pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008111751s
    STEP: Saw pod success 11/29/22 12:57:44.319
    Nov 29 12:57:44.319: INFO: Pod "pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e" satisfied condition "Succeeded or Failed"
    Nov 29 12:57:44.321: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e container agnhost-container: <nil>
    STEP: delete the pod 11/29/22 12:57:44.327
    Nov 29 12:57:44.333: INFO: Waiting for pod pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e to disappear
    Nov 29 12:57:44.335: INFO: Pod pod-projected-configmaps-0e8963c0-afdb-46ed-ab70-7ae6dfa8256e no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 29 12:57:44.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7072" for this suite. 11/29/22 12:57:44.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:57:44.346
Nov 29 12:57:44.346: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-preemption 11/29/22 12:57:44.347
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:57:44.36
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:57:44.363
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 29 12:57:44.377: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 29 12:58:44.416: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 11/29/22 12:58:44.418
Nov 29 12:58:44.435: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov 29 12:58:44.439: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov 29 12:58:44.457: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov 29 12:58:44.461: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov 29 12:58:44.477: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov 29 12:58:44.481: INFO: Created pod: pod2-1-sched-preemption-medium-priority
Nov 29 12:58:44.497: INFO: Created pod: pod3-0-sched-preemption-medium-priority
Nov 29 12:58:44.519: INFO: Created pod: pod3-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/29/22 12:58:44.519
Nov 29 12:58:44.519: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:44.523: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.78531ms
Nov 29 12:58:46.527: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007955728s
Nov 29 12:58:48.527: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007686132s
Nov 29 12:58:50.526: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006833024s
Nov 29 12:58:52.526: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00705839s
Nov 29 12:58:54.531: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.01174357s
Nov 29 12:58:54.531: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov 29 12:58:54.531: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:54.535: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.715935ms
Nov 29 12:58:54.535: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 12:58:54.535: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:54.538: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.867172ms
Nov 29 12:58:54.538: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 12:58:54.538: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:54.540: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.591546ms
Nov 29 12:58:54.541: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 12:58:54.541: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:54.543: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.705835ms
Nov 29 12:58:54.543: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 12:58:54.543: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:54.547: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.230201ms
Nov 29 12:58:54.547: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 12:58:54.547: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:54.551: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.833438ms
Nov 29 12:58:56.555: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.007756087s
Nov 29 12:58:56.555: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 12:58:56.555: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:56.559: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.029197ms
Nov 29 12:58:56.559: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/29/22 12:58:56.559
Nov 29 12:58:56.562: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-3124" to be "running"
Nov 29 12:58:56.566: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380419ms
Nov 29 12:58:58.571: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008275928s
Nov 29 12:59:00.570: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.00776931s
Nov 29 12:59:00.570: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:59:00.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3124" for this suite. 11/29/22 12:59:00.599
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":337,"skipped":6167,"failed":0}
------------------------------
• [SLOW TEST] [76.304 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:57:44.346
    Nov 29 12:57:44.346: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-preemption 11/29/22 12:57:44.347
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:57:44.36
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:57:44.363
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 29 12:57:44.377: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 29 12:58:44.416: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 11/29/22 12:58:44.418
    Nov 29 12:58:44.435: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov 29 12:58:44.439: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov 29 12:58:44.457: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov 29 12:58:44.461: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov 29 12:58:44.477: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov 29 12:58:44.481: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    Nov 29 12:58:44.497: INFO: Created pod: pod3-0-sched-preemption-medium-priority
    Nov 29 12:58:44.519: INFO: Created pod: pod3-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/29/22 12:58:44.519
    Nov 29 12:58:44.519: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:44.523: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.78531ms
    Nov 29 12:58:46.527: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007955728s
    Nov 29 12:58:48.527: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007686132s
    Nov 29 12:58:50.526: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006833024s
    Nov 29 12:58:52.526: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00705839s
    Nov 29 12:58:54.531: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.01174357s
    Nov 29 12:58:54.531: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov 29 12:58:54.531: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:54.535: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.715935ms
    Nov 29 12:58:54.535: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 12:58:54.535: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:54.538: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.867172ms
    Nov 29 12:58:54.538: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 12:58:54.538: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:54.540: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.591546ms
    Nov 29 12:58:54.541: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 12:58:54.541: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:54.543: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.705835ms
    Nov 29 12:58:54.543: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 12:58:54.543: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:54.547: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.230201ms
    Nov 29 12:58:54.547: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 12:58:54.547: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:54.551: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.833438ms
    Nov 29 12:58:56.555: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.007756087s
    Nov 29 12:58:56.555: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 12:58:56.555: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:56.559: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.029197ms
    Nov 29 12:58:56.559: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/29/22 12:58:56.559
    Nov 29 12:58:56.562: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-3124" to be "running"
    Nov 29 12:58:56.566: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380419ms
    Nov 29 12:58:58.571: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008275928s
    Nov 29 12:59:00.570: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.00776931s
    Nov 29 12:59:00.570: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:59:00.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3124" for this suite. 11/29/22 12:59:00.599
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:59:00.651
Nov 29 12:59:00.651: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename var-expansion 11/29/22 12:59:00.652
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:00.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:00.665
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 11/29/22 12:59:00.668
Nov 29 12:59:00.674: INFO: Waiting up to 5m0s for pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784" in namespace "var-expansion-2615" to be "Succeeded or Failed"
Nov 29 12:59:00.676: INFO: Pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784": Phase="Pending", Reason="", readiness=false. Elapsed: 2.746065ms
Nov 29 12:59:02.680: INFO: Pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00622073s
Nov 29 12:59:04.680: INFO: Pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006188218s
STEP: Saw pod success 11/29/22 12:59:04.68
Nov 29 12:59:04.680: INFO: Pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784" satisfied condition "Succeeded or Failed"
Nov 29 12:59:04.682: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784 container dapi-container: <nil>
STEP: delete the pod 11/29/22 12:59:04.686
Nov 29 12:59:04.695: INFO: Waiting for pod var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784 to disappear
Nov 29 12:59:04.697: INFO: Pod var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 29 12:59:04.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2615" for this suite. 11/29/22 12:59:04.7
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":338,"skipped":6176,"failed":0}
------------------------------
• [4.052 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:59:00.651
    Nov 29 12:59:00.651: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename var-expansion 11/29/22 12:59:00.652
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:00.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:00.665
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 11/29/22 12:59:00.668
    Nov 29 12:59:00.674: INFO: Waiting up to 5m0s for pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784" in namespace "var-expansion-2615" to be "Succeeded or Failed"
    Nov 29 12:59:00.676: INFO: Pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784": Phase="Pending", Reason="", readiness=false. Elapsed: 2.746065ms
    Nov 29 12:59:02.680: INFO: Pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00622073s
    Nov 29 12:59:04.680: INFO: Pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006188218s
    STEP: Saw pod success 11/29/22 12:59:04.68
    Nov 29 12:59:04.680: INFO: Pod "var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784" satisfied condition "Succeeded or Failed"
    Nov 29 12:59:04.682: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784 container dapi-container: <nil>
    STEP: delete the pod 11/29/22 12:59:04.686
    Nov 29 12:59:04.695: INFO: Waiting for pod var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784 to disappear
    Nov 29 12:59:04.697: INFO: Pod var-expansion-6fd934b7-530e-457f-a787-fbfc37b12784 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 29 12:59:04.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2615" for this suite. 11/29/22 12:59:04.7
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:59:04.704
Nov 29 12:59:04.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename runtimeclass 11/29/22 12:59:04.705
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:04.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:04.715
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 11/29/22 12:59:04.717
STEP: getting /apis/node.k8s.io 11/29/22 12:59:04.718
STEP: getting /apis/node.k8s.io/v1 11/29/22 12:59:04.719
STEP: creating 11/29/22 12:59:04.719
STEP: watching 11/29/22 12:59:04.73
Nov 29 12:59:04.730: INFO: starting watch
STEP: getting 11/29/22 12:59:04.733
STEP: listing 11/29/22 12:59:04.735
STEP: patching 11/29/22 12:59:04.736
STEP: updating 11/29/22 12:59:04.739
Nov 29 12:59:04.741: INFO: waiting for watch events with expected annotations
STEP: deleting 11/29/22 12:59:04.742
STEP: deleting a collection 11/29/22 12:59:04.75
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 29 12:59:04.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4421" for this suite. 11/29/22 12:59:04.762
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":339,"skipped":6190,"failed":0}
------------------------------
• [0.061 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:59:04.704
    Nov 29 12:59:04.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename runtimeclass 11/29/22 12:59:04.705
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:04.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:04.715
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 11/29/22 12:59:04.717
    STEP: getting /apis/node.k8s.io 11/29/22 12:59:04.718
    STEP: getting /apis/node.k8s.io/v1 11/29/22 12:59:04.719
    STEP: creating 11/29/22 12:59:04.719
    STEP: watching 11/29/22 12:59:04.73
    Nov 29 12:59:04.730: INFO: starting watch
    STEP: getting 11/29/22 12:59:04.733
    STEP: listing 11/29/22 12:59:04.735
    STEP: patching 11/29/22 12:59:04.736
    STEP: updating 11/29/22 12:59:04.739
    Nov 29 12:59:04.741: INFO: waiting for watch events with expected annotations
    STEP: deleting 11/29/22 12:59:04.742
    STEP: deleting a collection 11/29/22 12:59:04.75
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 29 12:59:04.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4421" for this suite. 11/29/22 12:59:04.762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:59:04.767
Nov 29 12:59:04.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename job 11/29/22 12:59:04.768
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:04.774
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:04.776
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 11/29/22 12:59:04.779
STEP: Ensuring active pods == parallelism 11/29/22 12:59:04.781
STEP: Orphaning one of the Job's Pods 11/29/22 12:59:06.784
Nov 29 12:59:07.294: INFO: Successfully updated pod "adopt-release-r6slt"
STEP: Checking that the Job readopts the Pod 11/29/22 12:59:07.294
Nov 29 12:59:07.295: INFO: Waiting up to 15m0s for pod "adopt-release-r6slt" in namespace "job-4165" to be "adopted"
Nov 29 12:59:07.297: INFO: Pod "adopt-release-r6slt": Phase="Running", Reason="", readiness=true. Elapsed: 2.846465ms
Nov 29 12:59:09.300: INFO: Pod "adopt-release-r6slt": Phase="Running", Reason="", readiness=true. Elapsed: 2.005515548s
Nov 29 12:59:09.300: INFO: Pod "adopt-release-r6slt" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 11/29/22 12:59:09.3
Nov 29 12:59:09.809: INFO: Successfully updated pod "adopt-release-r6slt"
STEP: Checking that the Job releases the Pod 11/29/22 12:59:09.809
Nov 29 12:59:09.809: INFO: Waiting up to 15m0s for pod "adopt-release-r6slt" in namespace "job-4165" to be "released"
Nov 29 12:59:09.812: INFO: Pod "adopt-release-r6slt": Phase="Running", Reason="", readiness=true. Elapsed: 2.702119ms
Nov 29 12:59:11.816: INFO: Pod "adopt-release-r6slt": Phase="Running", Reason="", readiness=true. Elapsed: 2.006811705s
Nov 29 12:59:11.816: INFO: Pod "adopt-release-r6slt" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 29 12:59:11.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4165" for this suite. 11/29/22 12:59:11.819
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":340,"skipped":6211,"failed":0}
------------------------------
• [SLOW TEST] [7.056 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:59:04.767
    Nov 29 12:59:04.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename job 11/29/22 12:59:04.768
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:04.774
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:04.776
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 11/29/22 12:59:04.779
    STEP: Ensuring active pods == parallelism 11/29/22 12:59:04.781
    STEP: Orphaning one of the Job's Pods 11/29/22 12:59:06.784
    Nov 29 12:59:07.294: INFO: Successfully updated pod "adopt-release-r6slt"
    STEP: Checking that the Job readopts the Pod 11/29/22 12:59:07.294
    Nov 29 12:59:07.295: INFO: Waiting up to 15m0s for pod "adopt-release-r6slt" in namespace "job-4165" to be "adopted"
    Nov 29 12:59:07.297: INFO: Pod "adopt-release-r6slt": Phase="Running", Reason="", readiness=true. Elapsed: 2.846465ms
    Nov 29 12:59:09.300: INFO: Pod "adopt-release-r6slt": Phase="Running", Reason="", readiness=true. Elapsed: 2.005515548s
    Nov 29 12:59:09.300: INFO: Pod "adopt-release-r6slt" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 11/29/22 12:59:09.3
    Nov 29 12:59:09.809: INFO: Successfully updated pod "adopt-release-r6slt"
    STEP: Checking that the Job releases the Pod 11/29/22 12:59:09.809
    Nov 29 12:59:09.809: INFO: Waiting up to 15m0s for pod "adopt-release-r6slt" in namespace "job-4165" to be "released"
    Nov 29 12:59:09.812: INFO: Pod "adopt-release-r6slt": Phase="Running", Reason="", readiness=true. Elapsed: 2.702119ms
    Nov 29 12:59:11.816: INFO: Pod "adopt-release-r6slt": Phase="Running", Reason="", readiness=true. Elapsed: 2.006811705s
    Nov 29 12:59:11.816: INFO: Pod "adopt-release-r6slt" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 29 12:59:11.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4165" for this suite. 11/29/22 12:59:11.819
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:59:11.823
Nov 29 12:59:11.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-pred 11/29/22 12:59:11.824
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:11.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:11.834
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 29 12:59:11.836: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 29 12:59:11.842: INFO: Waiting for terminating namespaces to be deleted...
Nov 29 12:59:11.845: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-0 before test
Nov 29 12:59:11.852: INFO: adopt-release-r6slt from job-4165 started at 2022-11-29 12:59:04 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.852: INFO: 	Container c ready: true, restart count 0
Nov 29 12:59:11.852: INFO: canal-wsz7n from kube-system started at 2022-11-29 11:01:45 +0000 UTC (3 container statuses recorded)
Nov 29 12:59:11.852: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:59:11.852: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:59:11.852: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:59:11.852: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.852: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:59:11.852: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.852: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:59:11.852: INFO: kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.852: INFO: 	Container main ready: true, restart count 0
Nov 29 12:59:11.852: INFO: node-local-dns-hqwqq from kube-system started at 2022-11-29 11:01:45 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.852: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:59:11.852: INFO: sonobuoy from sonobuoy started at 2022-11-29 11:25:29 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.852: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 29 12:59:11.852: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:59:11.852: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:59:11.852: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:59:11.852: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-1 before test
Nov 29 12:59:11.859: INFO: canal-f2ndl from kube-system started at 2022-11-29 11:02:00 +0000 UTC (3 container statuses recorded)
Nov 29 12:59:11.859: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:59:11.859: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:59:11.859: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:59:11.859: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.859: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:59:11.859: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.859: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:59:11.859: INFO: kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.859: INFO: 	Container main ready: true, restart count 0
Nov 29 12:59:11.859: INFO: node-local-dns-wwm5j from kube-system started at 2022-11-29 11:02:00 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.859: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:59:11.859: INFO: sonobuoy-e2e-job-2558967603d841e7 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:59:11.859: INFO: 	Container e2e ready: true, restart count 0
Nov 29 12:59:11.859: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:59:11.859: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk from sonobuoy started at 2022-11-29 11:25:37 +0000 UTC (2 container statuses recorded)
Nov 29 12:59:11.859: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:59:11.859: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:59:11.859: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-2 before test
Nov 29 12:59:11.865: INFO: adopt-release-2qcrr from job-4165 started at 2022-11-29 12:59:10 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.865: INFO: 	Container c ready: false, restart count 0
Nov 29 12:59:11.865: INFO: adopt-release-w5hkb from job-4165 started at 2022-11-29 12:59:04 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.865: INFO: 	Container c ready: true, restart count 0
Nov 29 12:59:11.865: INFO: canal-xwmmp from kube-system started at 2022-11-29 11:01:59 +0000 UTC (3 container statuses recorded)
Nov 29 12:59:11.865: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:59:11.865: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:59:11.865: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:59:11.865: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.865: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:59:11.865: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.865: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:59:11.865: INFO: kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.865: INFO: 	Container main ready: true, restart count 0
Nov 29 12:59:11.865: INFO: node-local-dns-rf4vc from kube-system started at 2022-11-29 11:01:59 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.865: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:59:11.865: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:59:11.865: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:59:11.865: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 29 12:59:11.865: INFO: 
Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-master-0 before test
Nov 29 12:59:11.877: INFO: calico-kube-controllers-5c9848945f-6wztn from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 29 12:59:11.877: INFO: canal-5j97l from kube-system started at 2022-11-29 10:49:25 +0000 UTC (3 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container calico-node ready: true, restart count 0
Nov 29 12:59:11.877: INFO: 	Container kube-flannel ready: true, restart count 0
Nov 29 12:59:11.877: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Nov 29 12:59:11.877: INFO: coredns-5cbcf9db85-hbrbr from kube-system started at 2022-11-29 11:01:49 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container coredns ready: true, restart count 0
Nov 29 12:59:11.877: INFO: coredns-5cbcf9db85-q2lfd from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container coredns ready: true, restart count 0
Nov 29 12:59:11.877: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Nov 29 12:59:11.877: INFO: k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container etcd ready: true, restart count 0
Nov 29 12:59:11.877: INFO: k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (3 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container apiserver ready: true, restart count 0
Nov 29 12:59:11.877: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov 29 12:59:11.877: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov 29 12:59:11.877: INFO: kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container kube-addon-manager ready: true, restart count 0
Nov 29 12:59:11.877: INFO: kube-dns-autoscaler-bd7b594d-dwsh9 from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container autoscaler ready: true, restart count 0
Nov 29 12:59:11.877: INFO: kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 29 12:59:11.877: INFO: kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container node-label ready: true, restart count 0
Nov 29 12:59:11.877: INFO: kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container main ready: true, restart count 0
Nov 29 12:59:11.877: INFO: kublr-system-shell-d595b78f-7ngf9 from kube-system started at 2022-11-29 10:52:20 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container shell ready: true, restart count 0
Nov 29 12:59:11.877: INFO: metrics-server-v0.5.2-54b5b7598b-zq8q6 from kube-system started at 2022-11-29 10:51:11 +0000 UTC (2 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container metrics-server ready: true, restart count 1
Nov 29 12:59:11.877: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 29 12:59:11.877: INFO: node-local-dns-fp5nm from kube-system started at 2022-11-29 10:49:25 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container node-cache ready: true, restart count 0
Nov 29 12:59:11.877: INFO: dashboard-metrics-scraper-6fffb6f45f-q7h8c from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 29 12:59:11.877: INFO: kubernetes-dashboard-c5db79646-sq2km from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 29 12:59:11.877: INFO: kublr-operator-576b5465f6-gdg4s from kublr started at 2022-11-29 10:51:53 +0000 UTC (1 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container kublr-operator ready: true, restart count 0
Nov 29 12:59:11.877: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
Nov 29 12:59:11.877: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 29 12:59:11.877: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/29/22 12:59:11.878
Nov 29 12:59:11.883: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-4477" to be "running"
Nov 29 12:59:11.945: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 61.499127ms
Nov 29 12:59:13.950: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.066328172s
Nov 29 12:59:13.950: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/29/22 12:59:13.953
STEP: Trying to apply a random label on the found node. 11/29/22 12:59:13.96
STEP: verifying the node has the label kubernetes.io/e2e-0c024f30-f3df-4a50-908e-d8a7f27f7f18 42 11/29/22 12:59:13.97
STEP: Trying to relaunch the pod, now with labels. 11/29/22 12:59:13.974
Nov 29 12:59:13.978: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-4477" to be "not pending"
Nov 29 12:59:13.981: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.626781ms
Nov 29 12:59:15.984: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.005813467s
Nov 29 12:59:15.984: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-0c024f30-f3df-4a50-908e-d8a7f27f7f18 off the node dvi-7336-1669718118-vsp1-group1-2 11/29/22 12:59:15.986
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0c024f30-f3df-4a50-908e-d8a7f27f7f18 11/29/22 12:59:15.999
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 29 12:59:16.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4477" for this suite. 11/29/22 12:59:16.006
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":341,"skipped":6212,"failed":0}
------------------------------
• [4.187 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:59:11.823
    Nov 29 12:59:11.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-pred 11/29/22 12:59:11.824
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:11.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:11.834
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 29 12:59:11.836: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 29 12:59:11.842: INFO: Waiting for terminating namespaces to be deleted...
    Nov 29 12:59:11.845: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-0 before test
    Nov 29 12:59:11.852: INFO: adopt-release-r6slt from job-4165 started at 2022-11-29 12:59:04 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.852: INFO: 	Container c ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: canal-wsz7n from kube-system started at 2022-11-29 11:01:45 +0000 UTC (3 container statuses recorded)
    Nov 29 12:59:11.852: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.852: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.852: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0 from kube-system started at 2022-11-29 11:01:17 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.852: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: node-local-dns-hqwqq from kube-system started at 2022-11-29 11:01:45 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.852: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: sonobuoy from sonobuoy started at 2022-11-29 11:25:29 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.852: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:59:11.852: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:59:11.852: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-1 before test
    Nov 29 12:59:11.859: INFO: canal-f2ndl from kube-system started at 2022-11-29 11:02:00 +0000 UTC (3 container statuses recorded)
    Nov 29 12:59:11.859: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.859: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.859: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: kublr-node-name-reporter-e963aba390d485a548cd93dffac1c0c0c7d1330fb59a65c5b89afc01c647a082-dvi-7336-1669718118-vsp1-group1-1 from kube-system started at 2022-11-29 11:01:40 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.859: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: node-local-dns-wwm5j from kube-system started at 2022-11-29 11:02:00 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.859: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: sonobuoy-e2e-job-2558967603d841e7 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:59:11.859: INFO: 	Container e2e ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-tlvrk from sonobuoy started at 2022-11-29 11:25:37 +0000 UTC (2 container statuses recorded)
    Nov 29 12:59:11.859: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:59:11.859: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-group1-2 before test
    Nov 29 12:59:11.865: INFO: adopt-release-2qcrr from job-4165 started at 2022-11-29 12:59:10 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.865: INFO: 	Container c ready: false, restart count 0
    Nov 29 12:59:11.865: INFO: adopt-release-w5hkb from job-4165 started at 2022-11-29 12:59:04 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.865: INFO: 	Container c ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: canal-xwmmp from kube-system started at 2022-11-29 11:01:59 +0000 UTC (3 container statuses recorded)
    Nov 29 12:59:11.865: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.865: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.865: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: kublr-node-name-reporter-bc194c6da2ec3cc6a7fbecd870df25958e1a30419c74f5d340873ba77b91398f-dvi-7336-1669718118-vsp1-group1-2 from kube-system started at 2022-11-29 11:01:31 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.865: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: node-local-dns-rf4vc from kube-system started at 2022-11-29 11:01:59 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.865: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-gxdvl from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:59:11.865: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 29 12:59:11.865: INFO: 
    Logging pods the apiserver thinks is on node dvi-7336-1669718118-vsp1-master-0 before test
    Nov 29 12:59:11.877: INFO: calico-kube-controllers-5c9848945f-6wztn from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: canal-5j97l from kube-system started at 2022-11-29 10:49:25 +0000 UTC (3 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container calico-node ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: 	Container kube-flannel ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: coredns-5cbcf9db85-hbrbr from kube-system started at 2022-11-29 11:01:49 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container coredns ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: coredns-5cbcf9db85-q2lfd from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container coredns ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: k8s-etcd-adc52f31fd97b375186d9b95944ba7df2d4c4bf7575569cd8ae378566c2928c6-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container etcd ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: k8s-master-2a913b64a537294cf7c0ea7f1f169415e41552ae5c9d7a7f72082ecee92dd24c-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (3 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container apiserver ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: 	Container kube-scheduler ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: kube-addon-manager-8ada715feb53c3503ed6bfe1e72cf19cebf2ae763a8fdbe1fbce19dbacbbe8d2-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: kube-dns-autoscaler-bd7b594d-dwsh9 from kube-system started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container autoscaler ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: kube-proxy-42882b5a27964c3df632f18284feed1c3130a4dd0fd999e576721d29300671fd-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container kube-proxy ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: kublr-label-master-node-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container node-label ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: kublr-node-name-reporter-1d980546bb03c9812f588a42bb1a52155891e68c52eb766ed65d2c7d21183aac-dvi-7336-1669718118-vsp1-master-0 from kube-system started at 2022-11-29 10:47:56 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container main ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: kublr-system-shell-d595b78f-7ngf9 from kube-system started at 2022-11-29 10:52:20 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container shell ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: metrics-server-v0.5.2-54b5b7598b-zq8q6 from kube-system started at 2022-11-29 10:51:11 +0000 UTC (2 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container metrics-server ready: true, restart count 1
    Nov 29 12:59:11.877: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: node-local-dns-fp5nm from kube-system started at 2022-11-29 10:49:25 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container node-cache ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: dashboard-metrics-scraper-6fffb6f45f-q7h8c from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: kubernetes-dashboard-c5db79646-sq2km from kubernetes-dashboard started at 2022-11-29 10:50:16 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: kublr-operator-576b5465f6-gdg4s from kublr started at 2022-11-29 10:51:53 +0000 UTC (1 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container kublr-operator ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-qnxf9 from sonobuoy started at 2022-11-29 11:25:36 +0000 UTC (2 container statuses recorded)
    Nov 29 12:59:11.877: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 29 12:59:11.877: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/29/22 12:59:11.878
    Nov 29 12:59:11.883: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-4477" to be "running"
    Nov 29 12:59:11.945: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 61.499127ms
    Nov 29 12:59:13.950: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.066328172s
    Nov 29 12:59:13.950: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/29/22 12:59:13.953
    STEP: Trying to apply a random label on the found node. 11/29/22 12:59:13.96
    STEP: verifying the node has the label kubernetes.io/e2e-0c024f30-f3df-4a50-908e-d8a7f27f7f18 42 11/29/22 12:59:13.97
    STEP: Trying to relaunch the pod, now with labels. 11/29/22 12:59:13.974
    Nov 29 12:59:13.978: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-4477" to be "not pending"
    Nov 29 12:59:13.981: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.626781ms
    Nov 29 12:59:15.984: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.005813467s
    Nov 29 12:59:15.984: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-0c024f30-f3df-4a50-908e-d8a7f27f7f18 off the node dvi-7336-1669718118-vsp1-group1-2 11/29/22 12:59:15.986
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-0c024f30-f3df-4a50-908e-d8a7f27f7f18 11/29/22 12:59:15.999
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 12:59:16.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4477" for this suite. 11/29/22 12:59:16.006
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:59:16.012
Nov 29 12:59:16.012: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename var-expansion 11/29/22 12:59:16.013
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:16.023
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:16.026
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 11/29/22 12:59:16.028
Nov 29 12:59:16.034: INFO: Waiting up to 5m0s for pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188" in namespace "var-expansion-4811" to be "Succeeded or Failed"
Nov 29 12:59:16.038: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188": Phase="Pending", Reason="", readiness=false. Elapsed: 3.65829ms
Nov 29 12:59:18.041: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006711569s
Nov 29 12:59:20.043: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008215915s
Nov 29 12:59:22.040: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.005772357s
STEP: Saw pod success 11/29/22 12:59:22.04
Nov 29 12:59:22.040: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188" satisfied condition "Succeeded or Failed"
Nov 29 12:59:22.044: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-1 pod var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188 container dapi-container: <nil>
STEP: delete the pod 11/29/22 12:59:22.051
Nov 29 12:59:22.058: INFO: Waiting for pod var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188 to disappear
Nov 29 12:59:22.060: INFO: Pod var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 29 12:59:22.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4811" for this suite. 11/29/22 12:59:22.065
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":342,"skipped":6226,"failed":0}
------------------------------
• [SLOW TEST] [6.059 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:59:16.012
    Nov 29 12:59:16.012: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename var-expansion 11/29/22 12:59:16.013
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:16.023
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:16.026
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 11/29/22 12:59:16.028
    Nov 29 12:59:16.034: INFO: Waiting up to 5m0s for pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188" in namespace "var-expansion-4811" to be "Succeeded or Failed"
    Nov 29 12:59:16.038: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188": Phase="Pending", Reason="", readiness=false. Elapsed: 3.65829ms
    Nov 29 12:59:18.041: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006711569s
    Nov 29 12:59:20.043: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008215915s
    Nov 29 12:59:22.040: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.005772357s
    STEP: Saw pod success 11/29/22 12:59:22.04
    Nov 29 12:59:22.040: INFO: Pod "var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188" satisfied condition "Succeeded or Failed"
    Nov 29 12:59:22.044: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-1 pod var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188 container dapi-container: <nil>
    STEP: delete the pod 11/29/22 12:59:22.051
    Nov 29 12:59:22.058: INFO: Waiting for pod var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188 to disappear
    Nov 29 12:59:22.060: INFO: Pod var-expansion-e2fe3cd9-5f91-4dcd-8119-9d880daa9188 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 29 12:59:22.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4811" for this suite. 11/29/22 12:59:22.065
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 12:59:22.071
Nov 29 12:59:22.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sched-preemption 11/29/22 12:59:22.072
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:22.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:22.083
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 29 12:59:22.098: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 29 13:00:22.146: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 11/29/22 13:00:22.149
Nov 29 13:00:22.168: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov 29 13:00:22.179: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov 29 13:00:22.193: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov 29 13:00:22.201: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov 29 13:00:22.219: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov 29 13:00:22.223: INFO: Created pod: pod2-1-sched-preemption-medium-priority
Nov 29 13:00:22.241: INFO: Created pod: pod3-0-sched-preemption-medium-priority
Nov 29 13:00:22.246: INFO: Created pod: pod3-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/29/22 13:00:22.246
Nov 29 13:00:22.246: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-3898" to be "running"
Nov 29 13:00:22.252: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.290538ms
Nov 29 13:00:24.255: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.009322905s
Nov 29 13:00:24.255: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov 29 13:00:24.255: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
Nov 29 13:00:24.258: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.246373ms
Nov 29 13:00:24.258: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 13:00:24.258: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
Nov 29 13:00:24.259: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 1.840341ms
Nov 29 13:00:24.259: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 13:00:24.260: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
Nov 29 13:00:24.261: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 1.727544ms
Nov 29 13:00:24.261: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 13:00:24.261: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
Nov 29 13:00:24.263: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.107111ms
Nov 29 13:00:24.263: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 13:00:24.263: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
Nov 29 13:00:24.266: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.746869ms
Nov 29 13:00:24.266: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 13:00:24.266: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
Nov 29 13:00:24.268: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 1.660918ms
Nov 29 13:00:26.271: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.004997337s
Nov 29 13:00:26.271: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 29 13:00:26.271: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
Nov 29 13:00:26.273: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 1.973287ms
Nov 29 13:00:26.273: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 11/29/22 13:00:26.273
Nov 29 13:00:26.278: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Nov 29 13:00:26.281: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.824089ms
Nov 29 13:00:28.285: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007008498s
Nov 29 13:00:30.285: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007073957s
Nov 29 13:00:30.285: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 29 13:00:30.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3898" for this suite. 11/29/22 13:00:30.36
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":343,"skipped":6229,"failed":0}
------------------------------
• [SLOW TEST] [68.348 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 12:59:22.071
    Nov 29 12:59:22.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sched-preemption 11/29/22 12:59:22.072
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 12:59:22.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 12:59:22.083
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 29 12:59:22.098: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 29 13:00:22.146: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 11/29/22 13:00:22.149
    Nov 29 13:00:22.168: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov 29 13:00:22.179: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov 29 13:00:22.193: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov 29 13:00:22.201: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov 29 13:00:22.219: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov 29 13:00:22.223: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    Nov 29 13:00:22.241: INFO: Created pod: pod3-0-sched-preemption-medium-priority
    Nov 29 13:00:22.246: INFO: Created pod: pod3-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/29/22 13:00:22.246
    Nov 29 13:00:22.246: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-3898" to be "running"
    Nov 29 13:00:22.252: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.290538ms
    Nov 29 13:00:24.255: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.009322905s
    Nov 29 13:00:24.255: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov 29 13:00:24.255: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
    Nov 29 13:00:24.258: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.246373ms
    Nov 29 13:00:24.258: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 13:00:24.258: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
    Nov 29 13:00:24.259: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 1.840341ms
    Nov 29 13:00:24.259: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 13:00:24.260: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
    Nov 29 13:00:24.261: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 1.727544ms
    Nov 29 13:00:24.261: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 13:00:24.261: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
    Nov 29 13:00:24.263: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.107111ms
    Nov 29 13:00:24.263: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 13:00:24.263: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
    Nov 29 13:00:24.266: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.746869ms
    Nov 29 13:00:24.266: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 13:00:24.266: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
    Nov 29 13:00:24.268: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 1.660918ms
    Nov 29 13:00:26.271: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.004997337s
    Nov 29 13:00:26.271: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 29 13:00:26.271: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-3898" to be "running"
    Nov 29 13:00:26.273: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 1.973287ms
    Nov 29 13:00:26.273: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 11/29/22 13:00:26.273
    Nov 29 13:00:26.278: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Nov 29 13:00:26.281: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.824089ms
    Nov 29 13:00:28.285: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007008498s
    Nov 29 13:00:30.285: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007073957s
    Nov 29 13:00:30.285: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 29 13:00:30.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3898" for this suite. 11/29/22 13:00:30.36
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:00:30.425
Nov 29 13:00:30.425: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename endpointslicemirroring 11/29/22 13:00:30.427
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:30.437
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:30.44
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 11/29/22 13:00:30.459
Nov 29 13:00:30.468: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 11/29/22 13:00:32.471
Nov 29 13:00:32.476: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 11/29/22 13:00:34.479
Nov 29 13:00:34.484: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Nov 29 13:00:36.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-7781" for this suite. 11/29/22 13:00:36.49
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":344,"skipped":6268,"failed":0}
------------------------------
• [SLOW TEST] [6.068 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:00:30.425
    Nov 29 13:00:30.425: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename endpointslicemirroring 11/29/22 13:00:30.427
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:30.437
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:30.44
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 11/29/22 13:00:30.459
    Nov 29 13:00:30.468: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 11/29/22 13:00:32.471
    Nov 29 13:00:32.476: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 11/29/22 13:00:34.479
    Nov 29 13:00:34.484: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Nov 29 13:00:36.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-7781" for this suite. 11/29/22 13:00:36.49
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:00:36.496
Nov 29 13:00:36.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/29/22 13:00:36.497
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:36.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:36.512
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 11/29/22 13:00:36.514
STEP: Creating hostNetwork=false pod 11/29/22 13:00:36.514
Nov 29 13:00:36.518: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-9298" to be "running and ready"
Nov 29 13:00:36.530: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.699453ms
Nov 29 13:00:36.530: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 29 13:00:38.533: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014858105s
Nov 29 13:00:38.533: INFO: The phase of Pod test-pod is Running (Ready = true)
Nov 29 13:00:38.533: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 11/29/22 13:00:38.535
Nov 29 13:00:38.538: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-9298" to be "running and ready"
Nov 29 13:00:38.540: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064967ms
Nov 29 13:00:38.540: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 29 13:00:40.543: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005253944s
Nov 29 13:00:40.543: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Nov 29 13:00:40.543: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 11/29/22 13:00:40.545
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/29/22 13:00:40.545
Nov 29 13:00:40.546: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:40.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:40.546: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:40.546: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 29 13:00:40.613: INFO: Exec stderr: ""
Nov 29 13:00:40.613: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:40.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:40.614: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:40.614: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 29 13:00:40.669: INFO: Exec stderr: ""
Nov 29 13:00:40.669: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:40.669: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:40.670: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:40.670: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 29 13:00:40.713: INFO: Exec stderr: ""
Nov 29 13:00:40.713: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:40.713: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:40.714: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:40.714: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 29 13:00:40.766: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/29/22 13:00:40.766
Nov 29 13:00:40.766: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:40.766: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:40.767: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:40.767: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov 29 13:00:40.831: INFO: Exec stderr: ""
Nov 29 13:00:40.832: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:40.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:40.832: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:40.833: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov 29 13:00:40.896: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/29/22 13:00:40.896
Nov 29 13:00:40.896: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:40.896: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:40.896: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:40.896: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 29 13:00:40.966: INFO: Exec stderr: ""
Nov 29 13:00:40.966: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:40.967: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:40.967: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:40.967: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 29 13:00:41.022: INFO: Exec stderr: ""
Nov 29 13:00:41.022: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:41.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:41.023: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:41.023: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 29 13:00:41.077: INFO: Exec stderr: ""
Nov 29 13:00:41.077: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:00:41.077: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:00:41.077: INFO: ExecWithOptions: Clientset creation
Nov 29 13:00:41.077: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 29 13:00:41.138: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Nov 29 13:00:41.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9298" for this suite. 11/29/22 13:00:41.142
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":345,"skipped":6289,"failed":0}
------------------------------
• [4.650 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:00:36.496
    Nov 29 13:00:36.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/29/22 13:00:36.497
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:36.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:36.512
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 11/29/22 13:00:36.514
    STEP: Creating hostNetwork=false pod 11/29/22 13:00:36.514
    Nov 29 13:00:36.518: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-9298" to be "running and ready"
    Nov 29 13:00:36.530: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.699453ms
    Nov 29 13:00:36.530: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 13:00:38.533: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014858105s
    Nov 29 13:00:38.533: INFO: The phase of Pod test-pod is Running (Ready = true)
    Nov 29 13:00:38.533: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 11/29/22 13:00:38.535
    Nov 29 13:00:38.538: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-9298" to be "running and ready"
    Nov 29 13:00:38.540: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064967ms
    Nov 29 13:00:38.540: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 13:00:40.543: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005253944s
    Nov 29 13:00:40.543: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Nov 29 13:00:40.543: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 11/29/22 13:00:40.545
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/29/22 13:00:40.545
    Nov 29 13:00:40.546: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:40.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:40.546: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:40.546: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 29 13:00:40.613: INFO: Exec stderr: ""
    Nov 29 13:00:40.613: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:40.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:40.614: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:40.614: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 29 13:00:40.669: INFO: Exec stderr: ""
    Nov 29 13:00:40.669: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:40.669: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:40.670: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:40.670: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 29 13:00:40.713: INFO: Exec stderr: ""
    Nov 29 13:00:40.713: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:40.713: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:40.714: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:40.714: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 29 13:00:40.766: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/29/22 13:00:40.766
    Nov 29 13:00:40.766: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:40.766: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:40.767: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:40.767: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov 29 13:00:40.831: INFO: Exec stderr: ""
    Nov 29 13:00:40.832: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:40.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:40.832: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:40.833: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov 29 13:00:40.896: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/29/22 13:00:40.896
    Nov 29 13:00:40.896: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:40.896: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:40.896: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:40.896: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 29 13:00:40.966: INFO: Exec stderr: ""
    Nov 29 13:00:40.966: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:40.967: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:40.967: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:40.967: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 29 13:00:41.022: INFO: Exec stderr: ""
    Nov 29 13:00:41.022: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:41.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:41.023: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:41.023: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 29 13:00:41.077: INFO: Exec stderr: ""
    Nov 29 13:00:41.077: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9298 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:00:41.077: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:00:41.077: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:00:41.077: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9298/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 29 13:00:41.138: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Nov 29 13:00:41.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-9298" for this suite. 11/29/22 13:00:41.142
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:00:41.147
Nov 29 13:00:41.148: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-lifecycle-hook 11/29/22 13:00:41.148
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:41.156
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:41.158
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/29/22 13:00:41.164
Nov 29 13:00:41.169: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3969" to be "running and ready"
Nov 29 13:00:41.171: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.562052ms
Nov 29 13:00:41.171: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 29 13:00:43.174: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.00574662s
Nov 29 13:00:43.174: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 29 13:00:43.174: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 11/29/22 13:00:43.176
Nov 29 13:00:43.180: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-3969" to be "running and ready"
Nov 29 13:00:43.182: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 1.972608ms
Nov 29 13:00:43.182: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 29 13:00:45.185: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.005545762s
Nov 29 13:00:45.185: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Nov 29 13:00:45.186: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/29/22 13:00:45.188
Nov 29 13:00:45.191: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 29 13:00:45.193: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 29 13:00:47.194: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 29 13:00:47.197: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 29 13:00:49.194: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 29 13:00:49.197: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 11/29/22 13:00:49.197
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 29 13:00:49.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3969" for this suite. 11/29/22 13:00:49.206
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":346,"skipped":6306,"failed":0}
------------------------------
• [SLOW TEST] [8.062 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:00:41.147
    Nov 29 13:00:41.148: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/29/22 13:00:41.148
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:41.156
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:41.158
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/29/22 13:00:41.164
    Nov 29 13:00:41.169: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3969" to be "running and ready"
    Nov 29 13:00:41.171: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.562052ms
    Nov 29 13:00:41.171: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 13:00:43.174: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.00574662s
    Nov 29 13:00:43.174: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 29 13:00:43.174: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 11/29/22 13:00:43.176
    Nov 29 13:00:43.180: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-3969" to be "running and ready"
    Nov 29 13:00:43.182: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 1.972608ms
    Nov 29 13:00:43.182: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 13:00:45.185: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.005545762s
    Nov 29 13:00:45.185: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Nov 29 13:00:45.186: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/29/22 13:00:45.188
    Nov 29 13:00:45.191: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 29 13:00:45.193: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov 29 13:00:47.194: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 29 13:00:47.197: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov 29 13:00:49.194: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 29 13:00:49.197: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 11/29/22 13:00:49.197
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 29 13:00:49.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3969" for this suite. 11/29/22 13:00:49.206
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:00:49.212
Nov 29 13:00:49.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename proxy 11/29/22 13:00:49.213
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:49.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:49.225
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Nov 29 13:00:49.227: INFO: Creating pod...
Nov 29 13:00:49.231: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-5657" to be "running"
Nov 29 13:00:49.243: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 11.492315ms
Nov 29 13:00:51.247: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.015796436s
Nov 29 13:00:51.247: INFO: Pod "agnhost" satisfied condition "running"
Nov 29 13:00:51.247: INFO: Creating service...
Nov 29 13:00:51.257: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=DELETE
Nov 29 13:00:51.262: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 29 13:00:51.262: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=OPTIONS
Nov 29 13:00:51.268: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 29 13:00:51.268: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=PATCH
Nov 29 13:00:51.270: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 29 13:00:51.270: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=POST
Nov 29 13:00:51.272: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 29 13:00:51.272: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=PUT
Nov 29 13:00:51.273: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 29 13:00:51.273: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=DELETE
Nov 29 13:00:51.276: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 29 13:00:51.276: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=OPTIONS
Nov 29 13:00:51.278: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 29 13:00:51.278: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=PATCH
Nov 29 13:00:51.281: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 29 13:00:51.281: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=POST
Nov 29 13:00:51.284: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 29 13:00:51.284: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=PUT
Nov 29 13:00:51.297: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 29 13:00:51.297: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=GET
Nov 29 13:00:51.298: INFO: http.Client request:GET StatusCode:301
Nov 29 13:00:51.298: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=GET
Nov 29 13:00:51.302: INFO: http.Client request:GET StatusCode:301
Nov 29 13:00:51.303: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=HEAD
Nov 29 13:00:51.304: INFO: http.Client request:HEAD StatusCode:301
Nov 29 13:00:51.304: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=HEAD
Nov 29 13:00:51.306: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 29 13:00:51.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5657" for this suite. 11/29/22 13:00:51.311
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":347,"skipped":6339,"failed":0}
------------------------------
• [2.103 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:00:49.212
    Nov 29 13:00:49.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename proxy 11/29/22 13:00:49.213
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:49.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:49.225
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Nov 29 13:00:49.227: INFO: Creating pod...
    Nov 29 13:00:49.231: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-5657" to be "running"
    Nov 29 13:00:49.243: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 11.492315ms
    Nov 29 13:00:51.247: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.015796436s
    Nov 29 13:00:51.247: INFO: Pod "agnhost" satisfied condition "running"
    Nov 29 13:00:51.247: INFO: Creating service...
    Nov 29 13:00:51.257: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=DELETE
    Nov 29 13:00:51.262: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 29 13:00:51.262: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=OPTIONS
    Nov 29 13:00:51.268: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 29 13:00:51.268: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=PATCH
    Nov 29 13:00:51.270: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 29 13:00:51.270: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=POST
    Nov 29 13:00:51.272: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 29 13:00:51.272: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=PUT
    Nov 29 13:00:51.273: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 29 13:00:51.273: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=DELETE
    Nov 29 13:00:51.276: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 29 13:00:51.276: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Nov 29 13:00:51.278: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 29 13:00:51.278: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=PATCH
    Nov 29 13:00:51.281: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 29 13:00:51.281: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=POST
    Nov 29 13:00:51.284: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 29 13:00:51.284: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=PUT
    Nov 29 13:00:51.297: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 29 13:00:51.297: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=GET
    Nov 29 13:00:51.298: INFO: http.Client request:GET StatusCode:301
    Nov 29 13:00:51.298: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=GET
    Nov 29 13:00:51.302: INFO: http.Client request:GET StatusCode:301
    Nov 29 13:00:51.303: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/pods/agnhost/proxy?method=HEAD
    Nov 29 13:00:51.304: INFO: http.Client request:HEAD StatusCode:301
    Nov 29 13:00:51.304: INFO: Starting http.Client for https://100.64.0.1:443/api/v1/namespaces/proxy-5657/services/e2e-proxy-test-service/proxy?method=HEAD
    Nov 29 13:00:51.306: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 29 13:00:51.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-5657" for this suite. 11/29/22 13:00:51.311
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:00:51.316
Nov 29 13:00:51.316: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pods 11/29/22 13:00:51.317
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:51.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:51.331
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 11/29/22 13:00:51.343
STEP: watching for Pod to be ready 11/29/22 13:00:51.349
Nov 29 13:00:51.350: INFO: observed Pod pod-test in namespace pods-4391 in phase Pending with labels: map[test-pod-static:true] & conditions []
Nov 29 13:00:51.351: INFO: observed Pod pod-test in namespace pods-4391 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  }]
Nov 29 13:00:51.368: INFO: observed Pod pod-test in namespace pods-4391 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  }]
Nov 29 13:00:51.768: INFO: observed Pod pod-test in namespace pods-4391 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  }]
Nov 29 13:00:52.159: INFO: Found Pod pod-test in namespace pods-4391 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 11/29/22 13:00:52.164
STEP: getting the Pod and ensuring that it's patched 11/29/22 13:00:52.176
STEP: replacing the Pod's status Ready condition to False 11/29/22 13:00:52.178
STEP: check the Pod again to ensure its Ready conditions are False 11/29/22 13:00:52.186
STEP: deleting the Pod via a Collection with a LabelSelector 11/29/22 13:00:52.186
STEP: watching for the Pod to be deleted 11/29/22 13:00:52.192
Nov 29 13:00:52.194: INFO: observed event type MODIFIED
Nov 29 13:00:54.166: INFO: observed event type MODIFIED
Nov 29 13:00:54.376: INFO: observed event type MODIFIED
Nov 29 13:00:55.170: INFO: observed event type MODIFIED
Nov 29 13:00:55.175: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 29 13:00:55.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4391" for this suite. 11/29/22 13:00:55.186
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":348,"skipped":6358,"failed":0}
------------------------------
• [3.875 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:00:51.316
    Nov 29 13:00:51.316: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pods 11/29/22 13:00:51.317
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:51.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:51.331
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 11/29/22 13:00:51.343
    STEP: watching for Pod to be ready 11/29/22 13:00:51.349
    Nov 29 13:00:51.350: INFO: observed Pod pod-test in namespace pods-4391 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Nov 29 13:00:51.351: INFO: observed Pod pod-test in namespace pods-4391 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  }]
    Nov 29 13:00:51.368: INFO: observed Pod pod-test in namespace pods-4391 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  }]
    Nov 29 13:00:51.768: INFO: observed Pod pod-test in namespace pods-4391 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  }]
    Nov 29 13:00:52.159: INFO: Found Pod pod-test in namespace pods-4391 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-29 13:00:51 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 11/29/22 13:00:52.164
    STEP: getting the Pod and ensuring that it's patched 11/29/22 13:00:52.176
    STEP: replacing the Pod's status Ready condition to False 11/29/22 13:00:52.178
    STEP: check the Pod again to ensure its Ready conditions are False 11/29/22 13:00:52.186
    STEP: deleting the Pod via a Collection with a LabelSelector 11/29/22 13:00:52.186
    STEP: watching for the Pod to be deleted 11/29/22 13:00:52.192
    Nov 29 13:00:52.194: INFO: observed event type MODIFIED
    Nov 29 13:00:54.166: INFO: observed event type MODIFIED
    Nov 29 13:00:54.376: INFO: observed event type MODIFIED
    Nov 29 13:00:55.170: INFO: observed event type MODIFIED
    Nov 29 13:00:55.175: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 29 13:00:55.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4391" for this suite. 11/29/22 13:00:55.186
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:00:55.192
Nov 29 13:00:55.192: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename events 11/29/22 13:00:55.193
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:55.201
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:55.203
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 11/29/22 13:00:55.206
STEP: listing events in all namespaces 11/29/22 13:00:55.208
STEP: listing events in test namespace 11/29/22 13:00:55.212
STEP: listing events with field selection filtering on source 11/29/22 13:00:55.214
STEP: listing events with field selection filtering on reportingController 11/29/22 13:00:55.216
STEP: getting the test event 11/29/22 13:00:55.217
STEP: patching the test event 11/29/22 13:00:55.219
STEP: getting the test event 11/29/22 13:00:55.222
STEP: updating the test event 11/29/22 13:00:55.224
STEP: getting the test event 11/29/22 13:00:55.227
STEP: deleting the test event 11/29/22 13:00:55.228
STEP: listing events in all namespaces 11/29/22 13:00:55.231
STEP: listing events in test namespace 11/29/22 13:00:55.234
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov 29 13:00:55.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6110" for this suite. 11/29/22 13:00:55.238
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":349,"skipped":6369,"failed":0}
------------------------------
• [0.049 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:00:55.192
    Nov 29 13:00:55.192: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename events 11/29/22 13:00:55.193
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:55.201
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:55.203
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 11/29/22 13:00:55.206
    STEP: listing events in all namespaces 11/29/22 13:00:55.208
    STEP: listing events in test namespace 11/29/22 13:00:55.212
    STEP: listing events with field selection filtering on source 11/29/22 13:00:55.214
    STEP: listing events with field selection filtering on reportingController 11/29/22 13:00:55.216
    STEP: getting the test event 11/29/22 13:00:55.217
    STEP: patching the test event 11/29/22 13:00:55.219
    STEP: getting the test event 11/29/22 13:00:55.222
    STEP: updating the test event 11/29/22 13:00:55.224
    STEP: getting the test event 11/29/22 13:00:55.227
    STEP: deleting the test event 11/29/22 13:00:55.228
    STEP: listing events in all namespaces 11/29/22 13:00:55.231
    STEP: listing events in test namespace 11/29/22 13:00:55.234
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov 29 13:00:55.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6110" for this suite. 11/29/22 13:00:55.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:00:55.244
Nov 29 13:00:55.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename kubectl 11/29/22 13:00:55.244
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:55.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:55.254
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Nov 29 13:00:55.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 create -f -'
Nov 29 13:00:55.498: INFO: stderr: ""
Nov 29 13:00:55.498: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Nov 29 13:00:55.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 create -f -'
Nov 29 13:00:55.745: INFO: stderr: ""
Nov 29 13:00:55.745: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/29/22 13:00:55.745
Nov 29 13:00:56.748: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 13:00:56.748: INFO: Found 0 / 1
Nov 29 13:00:57.749: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 13:00:57.749: INFO: Found 1 / 1
Nov 29 13:00:57.749: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 29 13:00:57.751: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 29 13:00:57.751: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 29 13:00:57.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe pod agnhost-primary-26cf9'
Nov 29 13:00:57.821: INFO: stderr: ""
Nov 29 13:00:57.821: INFO: stdout: "Name:             agnhost-primary-26cf9\nNamespace:        kubectl-1139\nPriority:         0\nService Account:  default\nNode:             dvi-7336-1669718118-vsp1-group1-2/192.168.8.22\nStart Time:       Tue, 29 Nov 2022 13:00:55 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 2eff9deb9aee59101d9e966b4cceb308ff67c987577e38a091490c5eec862bf3\n                  cni.projectcalico.org/podIP: 100.96.2.103/32\n                  cni.projectcalico.org/podIPs: 100.96.2.103/32\nStatus:           Running\nIP:               100.96.2.103\nIPs:\n  IP:           100.96.2.103\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://32a032dbaa6f378a53aba8ec0c5e12e3dd0ff209c0e6aacf48c41365cc82553f\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 29 Nov 2022 13:00:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nd6gr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-nd6gr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-1139/agnhost-primary-26cf9 to dvi-7336-1669718118-vsp1-group1-2\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Nov 29 13:00:57.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe rc agnhost-primary'
Nov 29 13:00:57.896: INFO: stderr: ""
Nov 29 13:00:57.897: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-1139\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-26cf9\n"
Nov 29 13:00:57.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe service agnhost-primary'
Nov 29 13:00:57.975: INFO: stderr: ""
Nov 29 13:00:57.976: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-1139\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                100.67.43.245\nIPs:               100.67.43.245\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.96.2.103:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 29 13:00:57.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe node dvi-7336-1669718118-vsp1-group1-0'
Nov 29 13:00:58.066: INFO: stderr: ""
Nov 29 13:00:58.066: INFO: stdout: "Name:               dvi-7336-1669718118-vsp1-group1-0\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=dvi-7336-1669718118-vsp1-group1-0\n                    kubernetes.io/os=linux\n                    kublr.io/location=vsp1\n                    kublr.io/node-group=group1\n                    kublr.io/node-identifier=3ee8b740-36dc-438f-9754-8e5f2a6a08dd\n                    kublr.io/node-ordinal=0\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 192.168.8.111\n                    flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"3e:dd:fa:c9:56:42\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.8.111\n                    kublr.io/agent-status:\n                      {\"clusterName\":\"dvi-7336-1669718118\",\"location\":\"vsp1\",\"nodeGroup\":\"group1\",\"nodeOrdinal\":0,\"nodeIdentifier\":\"3ee8b740-36dc-438f-9754-8e5f...\n                    kublr.io/location: vsp1\n                    kublr.io/node-group: group1\n                    kublr.io/node-identifier: 3ee8b740-36dc-438f-9754-8e5f2a6a08dd\n                    kublr.io/node-ordinal: 0\n                    kublr.io/seeder-status:\n                      {\"clusterName\":\"dvi-7336-1669718118\",\"location\":\"vsp1\",\"nodeGroup\":\"group1\",\"nodeOrdinal\":0,\"nodeIdentifier\":\"3ee8b740-36dc-438f-9754-8e5f...\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.8.111/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.96.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 29 Nov 2022 11:01:44 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  dvi-7336-1669718118-vsp1-group1-0\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 29 Nov 2022 13:00:54 +0000\nConditions:\n  Type                                  Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                                  ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable                    False   Tue, 29 Nov 2022 11:02:56 +0000   Tue, 29 Nov 2022 11:02:56 +0000   FlannelIsUp                  Flannel is running on this node\n  KublrAgentContainerEngineReady        True    Tue, 29 Nov 2022 13:00:30 +0000   Tue, 29 Nov 2022 11:01:27 +0000   DockerRunning                Docker is running\n  KublrAgentInstanceReady               True    Tue, 29 Nov 2022 13:00:29 +0000   Tue, 29 Nov 2022 11:00:56 +0000   AgentRunning                 Agent is running\n  KublrAgentKubeletReady                True    Tue, 29 Nov 2022 13:00:29 +0000   Tue, 29 Nov 2022 11:01:27 +0000   KubeletRunning               Kubelet is running\n  KublrAgentKubernetesReady             True    Tue, 29 Nov 2022 13:00:29 +0000   Tue, 29 Nov 2022 11:02:00 +0000   KubernetesRunning            Kubernetes is running\n  KublrAgentOptionalPackagesInstalled   True    Tue, 29 Nov 2022 11:00:56 +0000   Tue, 29 Nov 2022 11:00:56 +0000   AllInstalled                 All optional packages installed\n  KublrSeederAgentReady                 True    Tue, 29 Nov 2022 13:00:45 +0000   Tue, 29 Nov 2022 11:01:27 +0000   KublrAgentRunning            Kublr agent is running\n  KublrSeederInstanceReady              True    Tue, 29 Nov 2022 13:00:45 +0000   Tue, 29 Nov 2022 10:58:56 +0000   SeederRunning                Seeder is running\n  KublrSeederSecretStoreReady           True    Tue, 29 Nov 2022 13:00:45 +0000   Tue, 29 Nov 2022 10:58:56 +0000   SecretStoreOk                Secret store is running and accessible\n  MemoryPressure                        False   Tue, 29 Nov 2022 13:00:34 +0000   Tue, 29 Nov 2022 11:01:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure                          False   Tue, 29 Nov 2022 13:00:34 +0000   Tue, 29 Nov 2022 11:01:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure                           False   Tue, 29 Nov 2022 13:00:34 +0000   Tue, 29 Nov 2022 11:01:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                                 True    Tue, 29 Nov 2022 13:00:34 +0000   Tue, 29 Nov 2022 11:02:25 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  192.168.8.111\n  InternalIP:  192.168.8.111\n  Hostname:    dvi-7336-1669718118-vsp1-group1-0\nCapacity:\n  cpu:                4\n  ephemeral-storage:  40458684Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8140300Ki\n  pods:               110\nAllocatable:\n  cpu:                3900m\n  ephemeral-storage:  35139239465\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             6989324Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 a6dea97e79e344148c0d2a685dbe002d\n  System UUID:                420c5102-798a-83ae-025e-7dcbad5e315d\n  Boot ID:                    ee0a7364-cb6a-48c7-8d41-32a4f5f8b8e8\n  Kernel Version:             5.15.0-46-generic\n  OS Image:                   Ubuntu 22.04.1 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.5.9-0ubuntu3\n  Kubelet Version:            v1.25.4\n  Kube-Proxy Version:         v1.25.4\nPodCIDR:                      100.96.1.0/24\nPodCIDRs:                     100.96.1.0/24\nProviderID:                   vsphere://420c5102-798a-83ae-025e-7dcbad5e315d\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                                                                                           CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                                                                                           ------------  ----------  ---------------  -------------  ---\n  kube-system                 canal-wsz7n                                                                                                                    40m (1%)      0 (0%)      82Mi (1%)        793Mi (11%)    119m\n  kube-system                 k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0             1m (0%)       0 (0%)      20Mi (0%)        20Mi (0%)      118m\n  kube-system                 kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0                  5m (0%)       250m (6%)   24Mi (0%)        512Mi (7%)     118m\n  kube-system                 kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0    0 (0%)        0 (0%)      32Mi (0%)        32Mi (0%)      118m\n  kube-system                 node-local-dns-hqwqq                                                                                                           25m (0%)      0 (0%)      5Mi (0%)         30Mi (0%)      119m\n  sonobuoy                    sonobuoy                                                                                                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz                                                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                71m (1%)    250m (6%)\n  memory             163Mi (2%)  1387Mi (20%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
Nov 29 13:00:58.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe namespace kubectl-1139'
Nov 29 13:00:58.149: INFO: stderr: ""
Nov 29 13:00:58.149: INFO: stdout: "Name:         kubectl-1139\nLabels:       e2e-framework=kubectl\n              e2e-run=282b770b-3805-4cbc-9692-d81e0f561fad\n              kubernetes.io/metadata.name=kubectl-1139\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 29 13:00:58.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1139" for this suite. 11/29/22 13:00:58.152
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":350,"skipped":6420,"failed":0}
------------------------------
• [2.912 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:00:55.244
    Nov 29 13:00:55.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename kubectl 11/29/22 13:00:55.244
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:55.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:55.254
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Nov 29 13:00:55.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 create -f -'
    Nov 29 13:00:55.498: INFO: stderr: ""
    Nov 29 13:00:55.498: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Nov 29 13:00:55.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 create -f -'
    Nov 29 13:00:55.745: INFO: stderr: ""
    Nov 29 13:00:55.745: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/29/22 13:00:55.745
    Nov 29 13:00:56.748: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 13:00:56.748: INFO: Found 0 / 1
    Nov 29 13:00:57.749: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 13:00:57.749: INFO: Found 1 / 1
    Nov 29 13:00:57.749: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov 29 13:00:57.751: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 29 13:00:57.751: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 29 13:00:57.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe pod agnhost-primary-26cf9'
    Nov 29 13:00:57.821: INFO: stderr: ""
    Nov 29 13:00:57.821: INFO: stdout: "Name:             agnhost-primary-26cf9\nNamespace:        kubectl-1139\nPriority:         0\nService Account:  default\nNode:             dvi-7336-1669718118-vsp1-group1-2/192.168.8.22\nStart Time:       Tue, 29 Nov 2022 13:00:55 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 2eff9deb9aee59101d9e966b4cceb308ff67c987577e38a091490c5eec862bf3\n                  cni.projectcalico.org/podIP: 100.96.2.103/32\n                  cni.projectcalico.org/podIPs: 100.96.2.103/32\nStatus:           Running\nIP:               100.96.2.103\nIPs:\n  IP:           100.96.2.103\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://32a032dbaa6f378a53aba8ec0c5e12e3dd0ff209c0e6aacf48c41365cc82553f\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 29 Nov 2022 13:00:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nd6gr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-nd6gr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-1139/agnhost-primary-26cf9 to dvi-7336-1669718118-vsp1-group1-2\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Nov 29 13:00:57.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe rc agnhost-primary'
    Nov 29 13:00:57.896: INFO: stderr: ""
    Nov 29 13:00:57.897: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-1139\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-26cf9\n"
    Nov 29 13:00:57.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe service agnhost-primary'
    Nov 29 13:00:57.975: INFO: stderr: ""
    Nov 29 13:00:57.976: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-1139\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                100.67.43.245\nIPs:               100.67.43.245\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.96.2.103:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Nov 29 13:00:57.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe node dvi-7336-1669718118-vsp1-group1-0'
    Nov 29 13:00:58.066: INFO: stderr: ""
    Nov 29 13:00:58.066: INFO: stdout: "Name:               dvi-7336-1669718118-vsp1-group1-0\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=dvi-7336-1669718118-vsp1-group1-0\n                    kubernetes.io/os=linux\n                    kublr.io/location=vsp1\n                    kublr.io/node-group=group1\n                    kublr.io/node-identifier=3ee8b740-36dc-438f-9754-8e5f2a6a08dd\n                    kublr.io/node-ordinal=0\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 192.168.8.111\n                    flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"3e:dd:fa:c9:56:42\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.8.111\n                    kublr.io/agent-status:\n                      {\"clusterName\":\"dvi-7336-1669718118\",\"location\":\"vsp1\",\"nodeGroup\":\"group1\",\"nodeOrdinal\":0,\"nodeIdentifier\":\"3ee8b740-36dc-438f-9754-8e5f...\n                    kublr.io/location: vsp1\n                    kublr.io/node-group: group1\n                    kublr.io/node-identifier: 3ee8b740-36dc-438f-9754-8e5f2a6a08dd\n                    kublr.io/node-ordinal: 0\n                    kublr.io/seeder-status:\n                      {\"clusterName\":\"dvi-7336-1669718118\",\"location\":\"vsp1\",\"nodeGroup\":\"group1\",\"nodeOrdinal\":0,\"nodeIdentifier\":\"3ee8b740-36dc-438f-9754-8e5f...\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.8.111/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.96.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 29 Nov 2022 11:01:44 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  dvi-7336-1669718118-vsp1-group1-0\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 29 Nov 2022 13:00:54 +0000\nConditions:\n  Type                                  Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                                  ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable                    False   Tue, 29 Nov 2022 11:02:56 +0000   Tue, 29 Nov 2022 11:02:56 +0000   FlannelIsUp                  Flannel is running on this node\n  KublrAgentContainerEngineReady        True    Tue, 29 Nov 2022 13:00:30 +0000   Tue, 29 Nov 2022 11:01:27 +0000   DockerRunning                Docker is running\n  KublrAgentInstanceReady               True    Tue, 29 Nov 2022 13:00:29 +0000   Tue, 29 Nov 2022 11:00:56 +0000   AgentRunning                 Agent is running\n  KublrAgentKubeletReady                True    Tue, 29 Nov 2022 13:00:29 +0000   Tue, 29 Nov 2022 11:01:27 +0000   KubeletRunning               Kubelet is running\n  KublrAgentKubernetesReady             True    Tue, 29 Nov 2022 13:00:29 +0000   Tue, 29 Nov 2022 11:02:00 +0000   KubernetesRunning            Kubernetes is running\n  KublrAgentOptionalPackagesInstalled   True    Tue, 29 Nov 2022 11:00:56 +0000   Tue, 29 Nov 2022 11:00:56 +0000   AllInstalled                 All optional packages installed\n  KublrSeederAgentReady                 True    Tue, 29 Nov 2022 13:00:45 +0000   Tue, 29 Nov 2022 11:01:27 +0000   KublrAgentRunning            Kublr agent is running\n  KublrSeederInstanceReady              True    Tue, 29 Nov 2022 13:00:45 +0000   Tue, 29 Nov 2022 10:58:56 +0000   SeederRunning                Seeder is running\n  KublrSeederSecretStoreReady           True    Tue, 29 Nov 2022 13:00:45 +0000   Tue, 29 Nov 2022 10:58:56 +0000   SecretStoreOk                Secret store is running and accessible\n  MemoryPressure                        False   Tue, 29 Nov 2022 13:00:34 +0000   Tue, 29 Nov 2022 11:01:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure                          False   Tue, 29 Nov 2022 13:00:34 +0000   Tue, 29 Nov 2022 11:01:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure                           False   Tue, 29 Nov 2022 13:00:34 +0000   Tue, 29 Nov 2022 11:01:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                                 True    Tue, 29 Nov 2022 13:00:34 +0000   Tue, 29 Nov 2022 11:02:25 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  192.168.8.111\n  InternalIP:  192.168.8.111\n  Hostname:    dvi-7336-1669718118-vsp1-group1-0\nCapacity:\n  cpu:                4\n  ephemeral-storage:  40458684Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8140300Ki\n  pods:               110\nAllocatable:\n  cpu:                3900m\n  ephemeral-storage:  35139239465\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             6989324Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 a6dea97e79e344148c0d2a685dbe002d\n  System UUID:                420c5102-798a-83ae-025e-7dcbad5e315d\n  Boot ID:                    ee0a7364-cb6a-48c7-8d41-32a4f5f8b8e8\n  Kernel Version:             5.15.0-46-generic\n  OS Image:                   Ubuntu 22.04.1 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.5.9-0ubuntu3\n  Kubelet Version:            v1.25.4\n  Kube-Proxy Version:         v1.25.4\nPodCIDR:                      100.96.1.0/24\nPodCIDRs:                     100.96.1.0/24\nProviderID:                   vsphere://420c5102-798a-83ae-025e-7dcbad5e315d\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                                                                                           CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                                                                                           ------------  ----------  ---------------  -------------  ---\n  kube-system                 canal-wsz7n                                                                                                                    40m (1%)      0 (0%)      82Mi (1%)        793Mi (11%)    119m\n  kube-system                 k8s-api-haproxy-9e6900fc0eceeb505fd36c7a6be97c3945542dc93b6c45e474cf53cd41856c9b-dvi-7336-1669718118-vsp1-group1-0             1m (0%)       0 (0%)      20Mi (0%)        20Mi (0%)      118m\n  kube-system                 kube-proxy-1c4c683c4ccd28166f9c08bee20a4200d716dca216cc472b24a495790909bb84-dvi-7336-1669718118-vsp1-group1-0                  5m (0%)       250m (6%)   24Mi (0%)        512Mi (7%)     118m\n  kube-system                 kublr-node-name-reporter-cb7b5554202b8c6afbb22dbd9eeccedeb923e48d1ad193d571c8ac4fbb8a8acf-dvi-7336-1669718118-vsp1-group1-0    0 (0%)        0 (0%)      32Mi (0%)        32Mi (0%)      118m\n  kube-system                 node-local-dns-hqwqq                                                                                                           25m (0%)      0 (0%)      5Mi (0%)         30Mi (0%)      119m\n  sonobuoy                    sonobuoy                                                                                                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-d6ddd8339a884b7c-2gvbz                                                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                71m (1%)    250m (6%)\n  memory             163Mi (2%)  1387Mi (20%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
    Nov 29 13:00:58.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3385504514 --namespace=kubectl-1139 describe namespace kubectl-1139'
    Nov 29 13:00:58.149: INFO: stderr: ""
    Nov 29 13:00:58.149: INFO: stdout: "Name:         kubectl-1139\nLabels:       e2e-framework=kubectl\n              e2e-run=282b770b-3805-4cbc-9692-d81e0f561fad\n              kubernetes.io/metadata.name=kubectl-1139\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 29 13:00:58.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1139" for this suite. 11/29/22 13:00:58.152
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:00:58.156
Nov 29 13:00:58.156: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename projected 11/29/22 13:00:58.157
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:58.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:58.172
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-f419dbdf-9fc3-4c8b-b5d0-2c37162e5e7c 11/29/22 13:00:58.174
STEP: Creating a pod to test consume secrets 11/29/22 13:00:58.177
Nov 29 13:00:58.182: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03" in namespace "projected-6231" to be "Succeeded or Failed"
Nov 29 13:00:58.185: INFO: Pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03": Phase="Pending", Reason="", readiness=false. Elapsed: 3.261299ms
Nov 29 13:01:00.189: INFO: Pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006742599s
Nov 29 13:01:02.188: INFO: Pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006607423s
STEP: Saw pod success 11/29/22 13:01:02.188
Nov 29 13:01:02.189: INFO: Pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03" satisfied condition "Succeeded or Failed"
Nov 29 13:01:02.191: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/29/22 13:01:02.195
Nov 29 13:01:02.202: INFO: Waiting for pod pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03 to disappear
Nov 29 13:01:02.204: INFO: Pod pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 29 13:01:02.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6231" for this suite. 11/29/22 13:01:02.208
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":351,"skipped":6429,"failed":0}
------------------------------
• [4.055 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:00:58.156
    Nov 29 13:00:58.156: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename projected 11/29/22 13:00:58.157
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:00:58.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:00:58.172
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-f419dbdf-9fc3-4c8b-b5d0-2c37162e5e7c 11/29/22 13:00:58.174
    STEP: Creating a pod to test consume secrets 11/29/22 13:00:58.177
    Nov 29 13:00:58.182: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03" in namespace "projected-6231" to be "Succeeded or Failed"
    Nov 29 13:00:58.185: INFO: Pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03": Phase="Pending", Reason="", readiness=false. Elapsed: 3.261299ms
    Nov 29 13:01:00.189: INFO: Pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006742599s
    Nov 29 13:01:02.188: INFO: Pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006607423s
    STEP: Saw pod success 11/29/22 13:01:02.188
    Nov 29 13:01:02.189: INFO: Pod "pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03" satisfied condition "Succeeded or Failed"
    Nov 29 13:01:02.191: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 13:01:02.195
    Nov 29 13:01:02.202: INFO: Waiting for pod pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03 to disappear
    Nov 29 13:01:02.204: INFO: Pod pod-projected-secrets-21177630-de9f-4e2e-b764-463003a70f03 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 29 13:01:02.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6231" for this suite. 11/29/22 13:01:02.208
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:01:02.213
Nov 29 13:01:02.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename subpath 11/29/22 13:01:02.215
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:01:02.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:01:02.225
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/29/22 13:01:02.227
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-jxq2 11/29/22 13:01:02.232
STEP: Creating a pod to test atomic-volume-subpath 11/29/22 13:01:02.233
Nov 29 13:01:02.237: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jxq2" in namespace "subpath-1242" to be "Succeeded or Failed"
Nov 29 13:01:02.240: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.787484ms
Nov 29 13:01:04.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 2.00561724s
Nov 29 13:01:06.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 4.006187868s
Nov 29 13:01:08.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 6.00550578s
Nov 29 13:01:10.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 8.005857831s
Nov 29 13:01:12.244: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 10.006900815s
Nov 29 13:01:14.248: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 12.010568968s
Nov 29 13:01:16.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 14.006409484s
Nov 29 13:01:18.244: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 16.007246862s
Nov 29 13:01:20.244: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 18.00741943s
Nov 29 13:01:22.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 20.005495325s
Nov 29 13:01:24.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=false. Elapsed: 22.005926167s
Nov 29 13:01:26.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.005848286s
STEP: Saw pod success 11/29/22 13:01:26.243
Nov 29 13:01:26.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2" satisfied condition "Succeeded or Failed"
Nov 29 13:01:26.246: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-subpath-test-downwardapi-jxq2 container test-container-subpath-downwardapi-jxq2: <nil>
STEP: delete the pod 11/29/22 13:01:26.251
Nov 29 13:01:26.272: INFO: Waiting for pod pod-subpath-test-downwardapi-jxq2 to disappear
Nov 29 13:01:26.275: INFO: Pod pod-subpath-test-downwardapi-jxq2 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-jxq2 11/29/22 13:01:26.275
Nov 29 13:01:26.275: INFO: Deleting pod "pod-subpath-test-downwardapi-jxq2" in namespace "subpath-1242"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 29 13:01:26.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1242" for this suite. 11/29/22 13:01:26.28
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":352,"skipped":6436,"failed":0}
------------------------------
• [SLOW TEST] [24.070 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:01:02.213
    Nov 29 13:01:02.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename subpath 11/29/22 13:01:02.215
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:01:02.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:01:02.225
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/29/22 13:01:02.227
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-jxq2 11/29/22 13:01:02.232
    STEP: Creating a pod to test atomic-volume-subpath 11/29/22 13:01:02.233
    Nov 29 13:01:02.237: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jxq2" in namespace "subpath-1242" to be "Succeeded or Failed"
    Nov 29 13:01:02.240: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.787484ms
    Nov 29 13:01:04.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 2.00561724s
    Nov 29 13:01:06.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 4.006187868s
    Nov 29 13:01:08.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 6.00550578s
    Nov 29 13:01:10.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 8.005857831s
    Nov 29 13:01:12.244: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 10.006900815s
    Nov 29 13:01:14.248: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 12.010568968s
    Nov 29 13:01:16.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 14.006409484s
    Nov 29 13:01:18.244: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 16.007246862s
    Nov 29 13:01:20.244: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 18.00741943s
    Nov 29 13:01:22.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=true. Elapsed: 20.005495325s
    Nov 29 13:01:24.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Running", Reason="", readiness=false. Elapsed: 22.005926167s
    Nov 29 13:01:26.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.005848286s
    STEP: Saw pod success 11/29/22 13:01:26.243
    Nov 29 13:01:26.243: INFO: Pod "pod-subpath-test-downwardapi-jxq2" satisfied condition "Succeeded or Failed"
    Nov 29 13:01:26.246: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-subpath-test-downwardapi-jxq2 container test-container-subpath-downwardapi-jxq2: <nil>
    STEP: delete the pod 11/29/22 13:01:26.251
    Nov 29 13:01:26.272: INFO: Waiting for pod pod-subpath-test-downwardapi-jxq2 to disappear
    Nov 29 13:01:26.275: INFO: Pod pod-subpath-test-downwardapi-jxq2 no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-jxq2 11/29/22 13:01:26.275
    Nov 29 13:01:26.275: INFO: Deleting pod "pod-subpath-test-downwardapi-jxq2" in namespace "subpath-1242"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 29 13:01:26.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1242" for this suite. 11/29/22 13:01:26.28
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:01:26.285
Nov 29 13:01:26.285: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename replication-controller 11/29/22 13:01:26.286
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:01:26.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:01:26.296
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 11/29/22 13:01:26.299
STEP: When the matched label of one of its pods change 11/29/22 13:01:26.306
Nov 29 13:01:26.308: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 29 13:01:31.315: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 11/29/22 13:01:31.324
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 29 13:01:31.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-760" for this suite. 11/29/22 13:01:31.351
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":353,"skipped":6445,"failed":0}
------------------------------
• [SLOW TEST] [5.077 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:01:26.285
    Nov 29 13:01:26.285: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename replication-controller 11/29/22 13:01:26.286
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:01:26.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:01:26.296
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 11/29/22 13:01:26.299
    STEP: When the matched label of one of its pods change 11/29/22 13:01:26.306
    Nov 29 13:01:26.308: INFO: Pod name pod-release: Found 0 pods out of 1
    Nov 29 13:01:31.315: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/29/22 13:01:31.324
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 29 13:01:31.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-760" for this suite. 11/29/22 13:01:31.351
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:01:31.362
Nov 29 13:01:31.362: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename pod-network-test 11/29/22 13:01:31.363
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:01:31.38
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:01:31.383
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-2669 11/29/22 13:01:31.386
STEP: creating a selector 11/29/22 13:01:31.386
STEP: Creating the service pods in kubernetes 11/29/22 13:01:31.386
Nov 29 13:01:31.386: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 29 13:01:31.459: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2669" to be "running and ready"
Nov 29 13:01:31.473: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.409563ms
Nov 29 13:01:31.473: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 29 13:01:33.476: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017249449s
Nov 29 13:01:33.476: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:35.476: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017400352s
Nov 29 13:01:35.476: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:37.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017815799s
Nov 29 13:01:37.477: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:39.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018368466s
Nov 29 13:01:39.477: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:41.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017992061s
Nov 29 13:01:41.477: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:43.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.01850831s
Nov 29 13:01:43.477: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:45.479: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.020111477s
Nov 29 13:01:45.479: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:47.478: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.019489569s
Nov 29 13:01:47.478: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:49.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.018786628s
Nov 29 13:01:49.478: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:51.476: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.017600444s
Nov 29 13:01:51.476: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 29 13:01:53.476: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.017383131s
Nov 29 13:01:53.476: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 29 13:01:53.476: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 29 13:01:53.479: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2669" to be "running and ready"
Nov 29 13:01:53.481: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.023988ms
Nov 29 13:01:53.481: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 29 13:01:53.481: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 29 13:01:53.483: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2669" to be "running and ready"
Nov 29 13:01:53.485: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 1.649369ms
Nov 29 13:01:53.485: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 29 13:01:53.485: INFO: Pod "netserver-2" satisfied condition "running and ready"
Nov 29 13:01:53.486: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-2669" to be "running and ready"
Nov 29 13:01:53.488: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 1.543539ms
Nov 29 13:01:53.488: INFO: The phase of Pod netserver-3 is Running (Ready = true)
Nov 29 13:01:53.488: INFO: Pod "netserver-3" satisfied condition "running and ready"
STEP: Creating test pods 11/29/22 13:01:53.489
Nov 29 13:01:53.499: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2669" to be "running"
Nov 29 13:01:53.504: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.382077ms
Nov 29 13:01:55.510: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010474753s
Nov 29 13:01:55.510: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 29 13:01:55.513: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2669" to be "running"
Nov 29 13:01:55.516: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.578923ms
Nov 29 13:01:55.516: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov 29 13:01:55.518: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
Nov 29 13:01:55.518: INFO: Going to poll 100.96.1.201 on port 8081 at least 0 times, with a maximum of 46 tries before failing
Nov 29 13:01:55.520: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.201 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2669 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:01:55.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:01:55.520: INFO: ExecWithOptions: Clientset creation
Nov 29 13:01:55.520: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-2669/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.1.201+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 13:01:56.588: INFO: Found all 1 expected endpoints: [netserver-0]
Nov 29 13:01:56.588: INFO: Going to poll 100.96.3.140 on port 8081 at least 0 times, with a maximum of 46 tries before failing
Nov 29 13:01:56.590: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.3.140 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2669 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:01:56.590: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:01:56.591: INFO: ExecWithOptions: Clientset creation
Nov 29 13:01:56.591: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-2669/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.3.140+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 13:01:57.666: INFO: Found all 1 expected endpoints: [netserver-1]
Nov 29 13:01:57.666: INFO: Going to poll 100.96.2.107 on port 8081 at least 0 times, with a maximum of 46 tries before failing
Nov 29 13:01:57.670: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.2.107 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2669 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:01:57.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:01:57.670: INFO: ExecWithOptions: Clientset creation
Nov 29 13:01:57.670: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-2669/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.2.107+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 13:01:58.732: INFO: Found all 1 expected endpoints: [netserver-2]
Nov 29 13:01:58.732: INFO: Going to poll 100.96.0.117 on port 8081 at least 0 times, with a maximum of 46 tries before failing
Nov 29 13:01:58.734: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.0.117 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2669 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 29 13:01:58.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
Nov 29 13:01:58.735: INFO: ExecWithOptions: Clientset creation
Nov 29 13:01:58.735: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-2669/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.0.117+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 29 13:01:59.789: INFO: Found all 1 expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 29 13:01:59.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2669" for this suite. 11/29/22 13:01:59.792
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":354,"skipped":6459,"failed":0}
------------------------------
• [SLOW TEST] [28.433 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:01:31.362
    Nov 29 13:01:31.362: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename pod-network-test 11/29/22 13:01:31.363
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:01:31.38
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:01:31.383
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-2669 11/29/22 13:01:31.386
    STEP: creating a selector 11/29/22 13:01:31.386
    STEP: Creating the service pods in kubernetes 11/29/22 13:01:31.386
    Nov 29 13:01:31.386: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 29 13:01:31.459: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2669" to be "running and ready"
    Nov 29 13:01:31.473: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.409563ms
    Nov 29 13:01:31.473: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 29 13:01:33.476: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017249449s
    Nov 29 13:01:33.476: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:35.476: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017400352s
    Nov 29 13:01:35.476: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:37.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017815799s
    Nov 29 13:01:37.477: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:39.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018368466s
    Nov 29 13:01:39.477: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:41.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017992061s
    Nov 29 13:01:41.477: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:43.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.01850831s
    Nov 29 13:01:43.477: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:45.479: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.020111477s
    Nov 29 13:01:45.479: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:47.478: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.019489569s
    Nov 29 13:01:47.478: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:49.477: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.018786628s
    Nov 29 13:01:49.478: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:51.476: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.017600444s
    Nov 29 13:01:51.476: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 29 13:01:53.476: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.017383131s
    Nov 29 13:01:53.476: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 29 13:01:53.476: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 29 13:01:53.479: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2669" to be "running and ready"
    Nov 29 13:01:53.481: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.023988ms
    Nov 29 13:01:53.481: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 29 13:01:53.481: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 29 13:01:53.483: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2669" to be "running and ready"
    Nov 29 13:01:53.485: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 1.649369ms
    Nov 29 13:01:53.485: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 29 13:01:53.485: INFO: Pod "netserver-2" satisfied condition "running and ready"
    Nov 29 13:01:53.486: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-2669" to be "running and ready"
    Nov 29 13:01:53.488: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 1.543539ms
    Nov 29 13:01:53.488: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    Nov 29 13:01:53.488: INFO: Pod "netserver-3" satisfied condition "running and ready"
    STEP: Creating test pods 11/29/22 13:01:53.489
    Nov 29 13:01:53.499: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2669" to be "running"
    Nov 29 13:01:53.504: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.382077ms
    Nov 29 13:01:55.510: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010474753s
    Nov 29 13:01:55.510: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 29 13:01:55.513: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2669" to be "running"
    Nov 29 13:01:55.516: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.578923ms
    Nov 29 13:01:55.516: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov 29 13:01:55.518: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
    Nov 29 13:01:55.518: INFO: Going to poll 100.96.1.201 on port 8081 at least 0 times, with a maximum of 46 tries before failing
    Nov 29 13:01:55.520: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.201 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2669 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:01:55.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:01:55.520: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:01:55.520: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-2669/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.1.201+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 13:01:56.588: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov 29 13:01:56.588: INFO: Going to poll 100.96.3.140 on port 8081 at least 0 times, with a maximum of 46 tries before failing
    Nov 29 13:01:56.590: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.3.140 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2669 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:01:56.590: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:01:56.591: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:01:56.591: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-2669/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.3.140+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 13:01:57.666: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov 29 13:01:57.666: INFO: Going to poll 100.96.2.107 on port 8081 at least 0 times, with a maximum of 46 tries before failing
    Nov 29 13:01:57.670: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.2.107 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2669 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:01:57.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:01:57.670: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:01:57.670: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-2669/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.2.107+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 13:01:58.732: INFO: Found all 1 expected endpoints: [netserver-2]
    Nov 29 13:01:58.732: INFO: Going to poll 100.96.0.117 on port 8081 at least 0 times, with a maximum of 46 tries before failing
    Nov 29 13:01:58.734: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.0.117 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2669 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 29 13:01:58.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    Nov 29 13:01:58.735: INFO: ExecWithOptions: Clientset creation
    Nov 29 13:01:58.735: INFO: ExecWithOptions: execute(POST https://100.64.0.1:443/api/v1/namespaces/pod-network-test-2669/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.0.117+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 29 13:01:59.789: INFO: Found all 1 expected endpoints: [netserver-3]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 29 13:01:59.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-2669" for this suite. 11/29/22 13:01:59.792
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:01:59.797
Nov 29 13:01:59.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename container-probe 11/29/22 13:01:59.799
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:01:59.808
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:01:59.81
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063 in namespace container-probe-903 11/29/22 13:01:59.812
Nov 29 13:01:59.816: INFO: Waiting up to 5m0s for pod "liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063" in namespace "container-probe-903" to be "not pending"
Nov 29 13:01:59.826: INFO: Pod "liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063": Phase="Pending", Reason="", readiness=false. Elapsed: 9.387478ms
Nov 29 13:02:01.831: INFO: Pod "liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063": Phase="Running", Reason="", readiness=true. Elapsed: 2.014729466s
Nov 29 13:02:01.831: INFO: Pod "liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063" satisfied condition "not pending"
Nov 29 13:02:01.831: INFO: Started pod liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063 in namespace container-probe-903
STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 13:02:01.831
Nov 29 13:02:01.834: INFO: Initial restart count of pod liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063 is 0
STEP: deleting the pod 11/29/22 13:06:02.311
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 29 13:06:02.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-903" for this suite. 11/29/22 13:06:02.322
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":355,"skipped":6467,"failed":0}
------------------------------
• [SLOW TEST] [242.529 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:01:59.797
    Nov 29 13:01:59.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename container-probe 11/29/22 13:01:59.799
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:01:59.808
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:01:59.81
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063 in namespace container-probe-903 11/29/22 13:01:59.812
    Nov 29 13:01:59.816: INFO: Waiting up to 5m0s for pod "liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063" in namespace "container-probe-903" to be "not pending"
    Nov 29 13:01:59.826: INFO: Pod "liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063": Phase="Pending", Reason="", readiness=false. Elapsed: 9.387478ms
    Nov 29 13:02:01.831: INFO: Pod "liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063": Phase="Running", Reason="", readiness=true. Elapsed: 2.014729466s
    Nov 29 13:02:01.831: INFO: Pod "liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063" satisfied condition "not pending"
    Nov 29 13:02:01.831: INFO: Started pod liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063 in namespace container-probe-903
    STEP: checking the pod's current state and verifying that restartCount is present 11/29/22 13:02:01.831
    Nov 29 13:02:01.834: INFO: Initial restart count of pod liveness-c6a39ca7-54ea-4522-b2d5-2eb245f9c063 is 0
    STEP: deleting the pod 11/29/22 13:06:02.311
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 29 13:06:02.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-903" for this suite. 11/29/22 13:06:02.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:06:02.329
Nov 29 13:06:02.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename sysctl 11/29/22 13:06:02.33
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:02.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:02.343
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/29/22 13:06:02.345
STEP: Watching for error events or started pod 11/29/22 13:06:02.35
STEP: Waiting for pod completion 11/29/22 13:06:04.354
Nov 29 13:06:04.354: INFO: Waiting up to 3m0s for pod "sysctl-9b49bfae-1209-4377-b70b-27c16a26a555" in namespace "sysctl-3638" to be "completed"
Nov 29 13:06:04.356: INFO: Pod "sysctl-9b49bfae-1209-4377-b70b-27c16a26a555": Phase="Pending", Reason="", readiness=false. Elapsed: 2.357763ms
Nov 29 13:06:06.359: INFO: Pod "sysctl-9b49bfae-1209-4377-b70b-27c16a26a555": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005593146s
Nov 29 13:06:06.359: INFO: Pod "sysctl-9b49bfae-1209-4377-b70b-27c16a26a555" satisfied condition "completed"
STEP: Checking that the pod succeeded 11/29/22 13:06:06.362
STEP: Getting logs from the pod 11/29/22 13:06:06.362
STEP: Checking that the sysctl is actually updated 11/29/22 13:06:06.376
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 29 13:06:06.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-3638" for this suite. 11/29/22 13:06:06.383
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":356,"skipped":6546,"failed":0}
------------------------------
• [4.058 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:06:02.329
    Nov 29 13:06:02.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename sysctl 11/29/22 13:06:02.33
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:02.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:02.343
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/29/22 13:06:02.345
    STEP: Watching for error events or started pod 11/29/22 13:06:02.35
    STEP: Waiting for pod completion 11/29/22 13:06:04.354
    Nov 29 13:06:04.354: INFO: Waiting up to 3m0s for pod "sysctl-9b49bfae-1209-4377-b70b-27c16a26a555" in namespace "sysctl-3638" to be "completed"
    Nov 29 13:06:04.356: INFO: Pod "sysctl-9b49bfae-1209-4377-b70b-27c16a26a555": Phase="Pending", Reason="", readiness=false. Elapsed: 2.357763ms
    Nov 29 13:06:06.359: INFO: Pod "sysctl-9b49bfae-1209-4377-b70b-27c16a26a555": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005593146s
    Nov 29 13:06:06.359: INFO: Pod "sysctl-9b49bfae-1209-4377-b70b-27c16a26a555" satisfied condition "completed"
    STEP: Checking that the pod succeeded 11/29/22 13:06:06.362
    STEP: Getting logs from the pod 11/29/22 13:06:06.362
    STEP: Checking that the sysctl is actually updated 11/29/22 13:06:06.376
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 29 13:06:06.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-3638" for this suite. 11/29/22 13:06:06.383
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:06:06.387
Nov 29 13:06:06.388: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 13:06:06.388
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:06.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:06.399
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/29/22 13:06:06.406
Nov 29 13:06:06.411: INFO: Waiting up to 5m0s for pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f" in namespace "emptydir-7628" to be "Succeeded or Failed"
Nov 29 13:06:06.418: INFO: Pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.637719ms
Nov 29 13:06:08.421: INFO: Pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01065279s
Nov 29 13:06:10.426: INFO: Pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015245519s
STEP: Saw pod success 11/29/22 13:06:10.426
Nov 29 13:06:10.426: INFO: Pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f" satisfied condition "Succeeded or Failed"
Nov 29 13:06:10.429: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-d74552e6-05ce-4ae9-af2f-76677edf527f container test-container: <nil>
STEP: delete the pod 11/29/22 13:06:10.433
Nov 29 13:06:10.440: INFO: Waiting for pod pod-d74552e6-05ce-4ae9-af2f-76677edf527f to disappear
Nov 29 13:06:10.442: INFO: Pod pod-d74552e6-05ce-4ae9-af2f-76677edf527f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 13:06:10.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7628" for this suite. 11/29/22 13:06:10.445
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":357,"skipped":6555,"failed":0}
------------------------------
• [4.061 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:06:06.387
    Nov 29 13:06:06.388: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 13:06:06.388
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:06.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:06.399
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/29/22 13:06:06.406
    Nov 29 13:06:06.411: INFO: Waiting up to 5m0s for pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f" in namespace "emptydir-7628" to be "Succeeded or Failed"
    Nov 29 13:06:06.418: INFO: Pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.637719ms
    Nov 29 13:06:08.421: INFO: Pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01065279s
    Nov 29 13:06:10.426: INFO: Pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015245519s
    STEP: Saw pod success 11/29/22 13:06:10.426
    Nov 29 13:06:10.426: INFO: Pod "pod-d74552e6-05ce-4ae9-af2f-76677edf527f" satisfied condition "Succeeded or Failed"
    Nov 29 13:06:10.429: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-d74552e6-05ce-4ae9-af2f-76677edf527f container test-container: <nil>
    STEP: delete the pod 11/29/22 13:06:10.433
    Nov 29 13:06:10.440: INFO: Waiting for pod pod-d74552e6-05ce-4ae9-af2f-76677edf527f to disappear
    Nov 29 13:06:10.442: INFO: Pod pod-d74552e6-05ce-4ae9-af2f-76677edf527f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 13:06:10.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7628" for this suite. 11/29/22 13:06:10.445
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:06:10.453
Nov 29 13:06:10.453: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 13:06:10.454
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:10.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:10.465
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-df5100a3-f5ea-4489-8b3d-60e835818144 11/29/22 13:06:10.468
STEP: Creating a pod to test consume secrets 11/29/22 13:06:10.47
Nov 29 13:06:10.474: INFO: Waiting up to 5m0s for pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c" in namespace "secrets-1444" to be "Succeeded or Failed"
Nov 29 13:06:10.477: INFO: Pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.917404ms
Nov 29 13:06:12.483: INFO: Pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00872675s
Nov 29 13:06:14.481: INFO: Pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006711362s
STEP: Saw pod success 11/29/22 13:06:14.481
Nov 29 13:06:14.481: INFO: Pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c" satisfied condition "Succeeded or Failed"
Nov 29 13:06:14.483: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c container secret-volume-test: <nil>
STEP: delete the pod 11/29/22 13:06:14.487
Nov 29 13:06:14.493: INFO: Waiting for pod pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c to disappear
Nov 29 13:06:14.495: INFO: Pod pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 13:06:14.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1444" for this suite. 11/29/22 13:06:14.498
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":358,"skipped":6616,"failed":0}
------------------------------
• [4.048 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:06:10.453
    Nov 29 13:06:10.453: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 13:06:10.454
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:10.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:10.465
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-df5100a3-f5ea-4489-8b3d-60e835818144 11/29/22 13:06:10.468
    STEP: Creating a pod to test consume secrets 11/29/22 13:06:10.47
    Nov 29 13:06:10.474: INFO: Waiting up to 5m0s for pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c" in namespace "secrets-1444" to be "Succeeded or Failed"
    Nov 29 13:06:10.477: INFO: Pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.917404ms
    Nov 29 13:06:12.483: INFO: Pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00872675s
    Nov 29 13:06:14.481: INFO: Pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006711362s
    STEP: Saw pod success 11/29/22 13:06:14.481
    Nov 29 13:06:14.481: INFO: Pod "pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c" satisfied condition "Succeeded or Failed"
    Nov 29 13:06:14.483: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c container secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 13:06:14.487
    Nov 29 13:06:14.493: INFO: Waiting for pod pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c to disappear
    Nov 29 13:06:14.495: INFO: Pod pod-secrets-90b69072-3599-4bd5-82dd-bae46c169e3c no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 13:06:14.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1444" for this suite. 11/29/22 13:06:14.498
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:06:14.505
Nov 29 13:06:14.505: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 13:06:14.506
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:14.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:14.517
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 11/29/22 13:06:14.52
Nov 29 13:06:14.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: mark a version not serverd 11/29/22 13:06:21.655
STEP: check the unserved version gets removed 11/29/22 13:06:21.67
STEP: check the other version is not changed 11/29/22 13:06:24.641
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 29 13:06:30.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8324" for this suite. 11/29/22 13:06:30.192
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":359,"skipped":6655,"failed":0}
------------------------------
• [SLOW TEST] [15.691 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:06:14.505
    Nov 29 13:06:14.505: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename crd-publish-openapi 11/29/22 13:06:14.506
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:14.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:14.517
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 11/29/22 13:06:14.52
    Nov 29 13:06:14.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: mark a version not serverd 11/29/22 13:06:21.655
    STEP: check the unserved version gets removed 11/29/22 13:06:21.67
    STEP: check the other version is not changed 11/29/22 13:06:24.641
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 29 13:06:30.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8324" for this suite. 11/29/22 13:06:30.192
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:06:30.196
Nov 29 13:06:30.196: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename emptydir 11/29/22 13:06:30.197
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:30.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:30.208
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 11/29/22 13:06:30.21
Nov 29 13:06:30.214: INFO: Waiting up to 5m0s for pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818" in namespace "emptydir-4307" to be "Succeeded or Failed"
Nov 29 13:06:30.216: INFO: Pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818": Phase="Pending", Reason="", readiness=false. Elapsed: 2.238054ms
Nov 29 13:06:32.219: INFO: Pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005387573s
Nov 29 13:06:34.220: INFO: Pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006462321s
STEP: Saw pod success 11/29/22 13:06:34.22
Nov 29 13:06:34.221: INFO: Pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818" satisfied condition "Succeeded or Failed"
Nov 29 13:06:34.223: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818 container test-container: <nil>
STEP: delete the pod 11/29/22 13:06:34.228
Nov 29 13:06:34.236: INFO: Waiting for pod pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818 to disappear
Nov 29 13:06:34.241: INFO: Pod pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 29 13:06:34.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4307" for this suite. 11/29/22 13:06:34.244
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":360,"skipped":6660,"failed":0}
------------------------------
• [4.051 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:06:30.196
    Nov 29 13:06:30.196: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename emptydir 11/29/22 13:06:30.197
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:30.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:30.208
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/29/22 13:06:30.21
    Nov 29 13:06:30.214: INFO: Waiting up to 5m0s for pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818" in namespace "emptydir-4307" to be "Succeeded or Failed"
    Nov 29 13:06:30.216: INFO: Pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818": Phase="Pending", Reason="", readiness=false. Elapsed: 2.238054ms
    Nov 29 13:06:32.219: INFO: Pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005387573s
    Nov 29 13:06:34.220: INFO: Pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006462321s
    STEP: Saw pod success 11/29/22 13:06:34.22
    Nov 29 13:06:34.221: INFO: Pod "pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818" satisfied condition "Succeeded or Failed"
    Nov 29 13:06:34.223: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818 container test-container: <nil>
    STEP: delete the pod 11/29/22 13:06:34.228
    Nov 29 13:06:34.236: INFO: Waiting for pod pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818 to disappear
    Nov 29 13:06:34.241: INFO: Pod pod-fd9afa3a-bc5a-47ab-97f9-2aa4df614818 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 29 13:06:34.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4307" for this suite. 11/29/22 13:06:34.244
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:06:34.248
Nov 29 13:06:34.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename security-context-test 11/29/22 13:06:34.25
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:34.257
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:34.262
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Nov 29 13:06:34.270: INFO: Waiting up to 5m0s for pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14" in namespace "security-context-test-7774" to be "Succeeded or Failed"
Nov 29 13:06:34.273: INFO: Pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.459002ms
Nov 29 13:06:36.277: INFO: Pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006614111s
Nov 29 13:06:38.276: INFO: Pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00526194s
Nov 29 13:06:38.276: INFO: Pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 29 13:06:38.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7774" for this suite. 11/29/22 13:06:38.279
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":361,"skipped":6664,"failed":0}
------------------------------
• [4.034 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:06:34.248
    Nov 29 13:06:34.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename security-context-test 11/29/22 13:06:34.25
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:34.257
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:34.262
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Nov 29 13:06:34.270: INFO: Waiting up to 5m0s for pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14" in namespace "security-context-test-7774" to be "Succeeded or Failed"
    Nov 29 13:06:34.273: INFO: Pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.459002ms
    Nov 29 13:06:36.277: INFO: Pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006614111s
    Nov 29 13:06:38.276: INFO: Pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00526194s
    Nov 29 13:06:38.276: INFO: Pod "busybox-user-65534-0ef97f63-202e-4bf5-8122-fb4a46966d14" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 29 13:06:38.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7774" for this suite. 11/29/22 13:06:38.279
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/29/22 13:06:38.284
Nov 29 13:06:38.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
STEP: Building a namespace api object, basename secrets 11/29/22 13:06:38.285
STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:38.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:38.307
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-38be9385-23c3-4517-b2e1-2479cd39dc31 11/29/22 13:06:38.309
STEP: Creating a pod to test consume secrets 11/29/22 13:06:38.311
Nov 29 13:06:38.316: INFO: Waiting up to 5m0s for pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459" in namespace "secrets-1438" to be "Succeeded or Failed"
Nov 29 13:06:38.318: INFO: Pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459": Phase="Pending", Reason="", readiness=false. Elapsed: 2.468716ms
Nov 29 13:06:40.322: INFO: Pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005663592s
Nov 29 13:06:42.323: INFO: Pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007413997s
STEP: Saw pod success 11/29/22 13:06:42.323
Nov 29 13:06:42.323: INFO: Pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459" satisfied condition "Succeeded or Failed"
Nov 29 13:06:42.327: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459 container secret-volume-test: <nil>
STEP: delete the pod 11/29/22 13:06:42.332
Nov 29 13:06:42.339: INFO: Waiting for pod pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459 to disappear
Nov 29 13:06:42.341: INFO: Pod pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 29 13:06:42.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1438" for this suite. 11/29/22 13:06:42.344
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":362,"skipped":6692,"failed":0}
------------------------------
• [4.063 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/29/22 13:06:38.284
    Nov 29 13:06:38.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3385504514
    STEP: Building a namespace api object, basename secrets 11/29/22 13:06:38.285
    STEP: Waiting for a default service account to be provisioned in namespace 11/29/22 13:06:38.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/29/22 13:06:38.307
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-38be9385-23c3-4517-b2e1-2479cd39dc31 11/29/22 13:06:38.309
    STEP: Creating a pod to test consume secrets 11/29/22 13:06:38.311
    Nov 29 13:06:38.316: INFO: Waiting up to 5m0s for pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459" in namespace "secrets-1438" to be "Succeeded or Failed"
    Nov 29 13:06:38.318: INFO: Pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459": Phase="Pending", Reason="", readiness=false. Elapsed: 2.468716ms
    Nov 29 13:06:40.322: INFO: Pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005663592s
    Nov 29 13:06:42.323: INFO: Pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007413997s
    STEP: Saw pod success 11/29/22 13:06:42.323
    Nov 29 13:06:42.323: INFO: Pod "pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459" satisfied condition "Succeeded or Failed"
    Nov 29 13:06:42.327: INFO: Trying to get logs from node dvi-7336-1669718118-vsp1-group1-2 pod pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459 container secret-volume-test: <nil>
    STEP: delete the pod 11/29/22 13:06:42.332
    Nov 29 13:06:42.339: INFO: Waiting for pod pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459 to disappear
    Nov 29 13:06:42.341: INFO: Pod pod-secrets-357349e6-525d-4065-97da-5e1bd1a32459 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 29 13:06:42.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1438" for this suite. 11/29/22 13:06:42.344
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Nov 29 13:06:42.348: INFO: Running AfterSuite actions on all nodes
Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Nov 29 13:06:42.348: INFO: Running AfterSuite actions on node 1
Nov 29 13:06:42.348: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov 29 13:06:42.348: INFO: Running AfterSuite actions on all nodes
    Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Nov 29 13:06:42.348: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov 29 13:06:42.348: INFO: Running AfterSuite actions on node 1
    Nov 29 13:06:42.348: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.064 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5999.597 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h39m59.86320381s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

