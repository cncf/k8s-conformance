I0110 03:35:51.442855      19 e2e.go:116] Starting e2e run "746c852c-3453-440b-884c-9c980578a8f7" on Ginkgo node 1
Jan 10 03:35:51.460: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1673321751 - will randomize all specs

Will run 362 of 7066 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Jan 10 03:35:51.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
E0110 03:35:51.594528      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp 127.0.0.1:8099: connect: connection refused
E0110 03:35:51.594528      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp 127.0.0.1:8099: connect: connection refused
Jan 10 03:35:51.595: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 10 03:35:51.614: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 10 03:35:51.636: INFO: The status of Pod rke-coredns-addon-deploy-job-vp4pw is Succeeded, skipping waiting
Jan 10 03:35:51.637: INFO: The status of Pod rke-metrics-addon-deploy-job-tqspg is Succeeded, skipping waiting
Jan 10 03:35:51.637: INFO: The status of Pod rke-network-plugin-deploy-job-ks979 is Succeeded, skipping waiting
Jan 10 03:35:51.637: INFO: 8 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 10 03:35:51.637: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Jan 10 03:35:51.637: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 10 03:35:51.640: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Jan 10 03:35:51.640: INFO: e2e test version: v1.25.5
Jan 10 03:35:51.641: INFO: kube-apiserver version: v1.25.5
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Jan 10 03:35:51.641: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:35:51.660: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.067 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Jan 10 03:35:51.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    E0110 03:35:51.594528      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp 127.0.0.1:8099: connect: connection refused
    Jan 10 03:35:51.595: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Jan 10 03:35:51.614: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Jan 10 03:35:51.636: INFO: The status of Pod rke-coredns-addon-deploy-job-vp4pw is Succeeded, skipping waiting
    Jan 10 03:35:51.637: INFO: The status of Pod rke-metrics-addon-deploy-job-tqspg is Succeeded, skipping waiting
    Jan 10 03:35:51.637: INFO: The status of Pod rke-network-plugin-deploy-job-ks979 is Succeeded, skipping waiting
    Jan 10 03:35:51.637: INFO: 8 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Jan 10 03:35:51.637: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
    Jan 10 03:35:51.637: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Jan 10 03:35:51.640: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
    Jan 10 03:35:51.640: INFO: e2e test version: v1.25.5
    Jan 10 03:35:51.641: INFO: kube-apiserver version: v1.25.5
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Jan 10 03:35:51.641: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:35:51.660: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:35:51.687
Jan 10 03:35:51.687: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:35:51.689
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:35:51.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:35:51.819
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-cae0744f-72d0-46ef-b3f2-00f34f61bade 01/10/23 03:35:51.823
STEP: Creating a pod to test consume secrets 01/10/23 03:35:51.855
Jan 10 03:35:51.893: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0" in namespace "projected-2576" to be "Succeeded or Failed"
Jan 10 03:35:51.951: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 57.037054ms
Jan 10 03:35:53.956: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06296634s
Jan 10 03:35:55.955: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061085813s
Jan 10 03:35:57.954: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060656224s
Jan 10 03:35:59.955: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.061358611s
STEP: Saw pod success 01/10/23 03:35:59.955
Jan 10 03:35:59.955: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0" satisfied condition "Succeeded or Failed"
Jan 10 03:35:59.958: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0 container projected-secret-volume-test: <nil>
STEP: delete the pod 01/10/23 03:35:59.976
Jan 10 03:35:59.993: INFO: Waiting for pod pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0 to disappear
Jan 10 03:35:59.995: INFO: Pod pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 10 03:35:59.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2576" for this suite. 01/10/23 03:35:59.997
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":1,"skipped":1,"failed":0}
------------------------------
• [SLOW TEST] [8.331 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:35:51.687
    Jan 10 03:35:51.687: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:35:51.689
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:35:51.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:35:51.819
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-cae0744f-72d0-46ef-b3f2-00f34f61bade 01/10/23 03:35:51.823
    STEP: Creating a pod to test consume secrets 01/10/23 03:35:51.855
    Jan 10 03:35:51.893: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0" in namespace "projected-2576" to be "Succeeded or Failed"
    Jan 10 03:35:51.951: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 57.037054ms
    Jan 10 03:35:53.956: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06296634s
    Jan 10 03:35:55.955: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061085813s
    Jan 10 03:35:57.954: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060656224s
    Jan 10 03:35:59.955: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.061358611s
    STEP: Saw pod success 01/10/23 03:35:59.955
    Jan 10 03:35:59.955: INFO: Pod "pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0" satisfied condition "Succeeded or Failed"
    Jan 10 03:35:59.958: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0 container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 03:35:59.976
    Jan 10 03:35:59.993: INFO: Waiting for pod pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0 to disappear
    Jan 10 03:35:59.995: INFO: Pod pod-projected-secrets-7b556de4-6bde-45ac-a1d2-6bf12f791ce0 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 10 03:35:59.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2576" for this suite. 01/10/23 03:35:59.997
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:00.033
Jan 10 03:36:00.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename conformance-tests 01/10/23 03:36:00.035
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:00.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:00.144
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 01/10/23 03:36:00.17
Jan 10 03:36:00.170: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Jan 10 03:36:00.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-7199" for this suite. 01/10/23 03:36:00.222
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":2,"skipped":9,"failed":0}
------------------------------
• [0.210 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:00.033
    Jan 10 03:36:00.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename conformance-tests 01/10/23 03:36:00.035
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:00.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:00.144
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 01/10/23 03:36:00.17
    Jan 10 03:36:00.170: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Jan 10 03:36:00.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-7199" for this suite. 01/10/23 03:36:00.222
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:00.246
Jan 10 03:36:00.246: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 03:36:00.247
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:00.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:00.407
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-d3326d99-6cd9-4f0e-91de-92054d1ae382 01/10/23 03:36:00.413
STEP: Creating a pod to test consume configMaps 01/10/23 03:36:00.419
Jan 10 03:36:00.446: INFO: Waiting up to 5m0s for pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f" in namespace "configmap-8189" to be "Succeeded or Failed"
Jan 10 03:36:00.471: INFO: Pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.400096ms
Jan 10 03:36:02.475: INFO: Pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029256408s
Jan 10 03:36:04.474: INFO: Pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028285734s
STEP: Saw pod success 01/10/23 03:36:04.475
Jan 10 03:36:04.475: INFO: Pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f" satisfied condition "Succeeded or Failed"
Jan 10 03:36:04.478: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f container agnhost-container: <nil>
STEP: delete the pod 01/10/23 03:36:04.486
Jan 10 03:36:04.512: INFO: Waiting for pod pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f to disappear
Jan 10 03:36:04.530: INFO: Pod pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 03:36:04.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8189" for this suite. 01/10/23 03:36:04.534
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":3,"skipped":24,"failed":0}
------------------------------
• [4.300 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:00.246
    Jan 10 03:36:00.246: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 03:36:00.247
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:00.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:00.407
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-d3326d99-6cd9-4f0e-91de-92054d1ae382 01/10/23 03:36:00.413
    STEP: Creating a pod to test consume configMaps 01/10/23 03:36:00.419
    Jan 10 03:36:00.446: INFO: Waiting up to 5m0s for pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f" in namespace "configmap-8189" to be "Succeeded or Failed"
    Jan 10 03:36:00.471: INFO: Pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.400096ms
    Jan 10 03:36:02.475: INFO: Pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029256408s
    Jan 10 03:36:04.474: INFO: Pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028285734s
    STEP: Saw pod success 01/10/23 03:36:04.475
    Jan 10 03:36:04.475: INFO: Pod "pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f" satisfied condition "Succeeded or Failed"
    Jan 10 03:36:04.478: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 03:36:04.486
    Jan 10 03:36:04.512: INFO: Waiting for pod pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f to disappear
    Jan 10 03:36:04.530: INFO: Pod pod-configmaps-965ec7c4-cda2-498f-a922-8b98b2c31c2f no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 03:36:04.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8189" for this suite. 01/10/23 03:36:04.534
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:04.551
Jan 10 03:36:04.551: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename namespaces 01/10/23 03:36:04.552
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:04.609
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:04.629
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 01/10/23 03:36:04.637
Jan 10 03:36:04.640: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 01/10/23 03:36:04.64
Jan 10 03:36:04.652: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 01/10/23 03:36:04.652
Jan 10 03:36:04.696: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jan 10 03:36:04.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8144" for this suite. 01/10/23 03:36:04.782
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":4,"skipped":46,"failed":0}
------------------------------
• [0.301 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:04.551
    Jan 10 03:36:04.551: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename namespaces 01/10/23 03:36:04.552
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:04.609
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:04.629
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 01/10/23 03:36:04.637
    Jan 10 03:36:04.640: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 01/10/23 03:36:04.64
    Jan 10 03:36:04.652: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 01/10/23 03:36:04.652
    Jan 10 03:36:04.696: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 03:36:04.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8144" for this suite. 01/10/23 03:36:04.782
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:04.853
Jan 10 03:36:04.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:36:04.857
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:04.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:05.026
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 01/10/23 03:36:05.049
Jan 10 03:36:05.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2" in namespace "projected-6587" to be "Succeeded or Failed"
Jan 10 03:36:05.134: INFO: Pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2": Phase="Pending", Reason="", readiness=false. Elapsed: 46.196637ms
Jan 10 03:36:07.142: INFO: Pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055062255s
Jan 10 03:36:09.136: INFO: Pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048812225s
STEP: Saw pod success 01/10/23 03:36:09.136
Jan 10 03:36:09.136: INFO: Pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2" satisfied condition "Succeeded or Failed"
Jan 10 03:36:09.138: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2 container client-container: <nil>
STEP: delete the pod 01/10/23 03:36:09.146
Jan 10 03:36:09.162: INFO: Waiting for pod downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2 to disappear
Jan 10 03:36:09.165: INFO: Pod downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 03:36:09.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6587" for this suite. 01/10/23 03:36:09.169
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":5,"skipped":62,"failed":0}
------------------------------
• [4.320 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:04.853
    Jan 10 03:36:04.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:36:04.857
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:04.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:05.026
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 01/10/23 03:36:05.049
    Jan 10 03:36:05.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2" in namespace "projected-6587" to be "Succeeded or Failed"
    Jan 10 03:36:05.134: INFO: Pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2": Phase="Pending", Reason="", readiness=false. Elapsed: 46.196637ms
    Jan 10 03:36:07.142: INFO: Pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055062255s
    Jan 10 03:36:09.136: INFO: Pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048812225s
    STEP: Saw pod success 01/10/23 03:36:09.136
    Jan 10 03:36:09.136: INFO: Pod "downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2" satisfied condition "Succeeded or Failed"
    Jan 10 03:36:09.138: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2 container client-container: <nil>
    STEP: delete the pod 01/10/23 03:36:09.146
    Jan 10 03:36:09.162: INFO: Waiting for pod downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2 to disappear
    Jan 10 03:36:09.165: INFO: Pod downwardapi-volume-0f314c8f-c40b-4a5c-99df-6cc1097126d2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 03:36:09.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6587" for this suite. 01/10/23 03:36:09.169
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:09.174
Jan 10 03:36:09.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:36:09.175
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:09.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:09.212
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 01/10/23 03:36:09.218
Jan 10 03:36:09.242: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153" in namespace "projected-7933" to be "Succeeded or Failed"
Jan 10 03:36:09.260: INFO: Pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153": Phase="Pending", Reason="", readiness=false. Elapsed: 18.04153ms
Jan 10 03:36:11.265: INFO: Pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022449774s
Jan 10 03:36:13.264: INFO: Pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021968579s
STEP: Saw pod success 01/10/23 03:36:13.264
Jan 10 03:36:13.265: INFO: Pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153" satisfied condition "Succeeded or Failed"
Jan 10 03:36:13.267: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153 container client-container: <nil>
STEP: delete the pod 01/10/23 03:36:13.275
Jan 10 03:36:13.289: INFO: Waiting for pod downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153 to disappear
Jan 10 03:36:13.291: INFO: Pod downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 03:36:13.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7933" for this suite. 01/10/23 03:36:13.294
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":6,"skipped":78,"failed":0}
------------------------------
• [4.126 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:09.174
    Jan 10 03:36:09.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:36:09.175
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:09.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:09.212
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 01/10/23 03:36:09.218
    Jan 10 03:36:09.242: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153" in namespace "projected-7933" to be "Succeeded or Failed"
    Jan 10 03:36:09.260: INFO: Pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153": Phase="Pending", Reason="", readiness=false. Elapsed: 18.04153ms
    Jan 10 03:36:11.265: INFO: Pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022449774s
    Jan 10 03:36:13.264: INFO: Pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021968579s
    STEP: Saw pod success 01/10/23 03:36:13.264
    Jan 10 03:36:13.265: INFO: Pod "downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153" satisfied condition "Succeeded or Failed"
    Jan 10 03:36:13.267: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153 container client-container: <nil>
    STEP: delete the pod 01/10/23 03:36:13.275
    Jan 10 03:36:13.289: INFO: Waiting for pod downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153 to disappear
    Jan 10 03:36:13.291: INFO: Pod downwardapi-volume-1323ce1c-2b8d-441f-8198-395e81ddb153 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 03:36:13.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7933" for this suite. 01/10/23 03:36:13.294
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:13.3
Jan 10 03:36:13.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 03:36:13.301
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:13.322
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:13.329
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 01/10/23 03:36:13.333
Jan 10 03:36:13.333: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2693 proxy --unix-socket=/tmp/kubectl-proxy-unix1368520662/test'
STEP: retrieving proxy /api/ output 01/10/23 03:36:13.391
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 03:36:13.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2693" for this suite. 01/10/23 03:36:13.395
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":7,"skipped":81,"failed":0}
------------------------------
• [0.098 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:13.3
    Jan 10 03:36:13.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 03:36:13.301
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:13.322
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:13.329
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 01/10/23 03:36:13.333
    Jan 10 03:36:13.333: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2693 proxy --unix-socket=/tmp/kubectl-proxy-unix1368520662/test'
    STEP: retrieving proxy /api/ output 01/10/23 03:36:13.391
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 03:36:13.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2693" for this suite. 01/10/23 03:36:13.395
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:13.398
Jan 10 03:36:13.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 03:36:13.399
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:13.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:13.438
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 01/10/23 03:36:13.448
Jan 10 03:36:13.475: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce" in namespace "emptydir-3847" to be "running"
Jan 10 03:36:13.494: INFO: Pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce": Phase="Pending", Reason="", readiness=false. Elapsed: 19.002685ms
Jan 10 03:36:15.497: INFO: Pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021700515s
Jan 10 03:36:17.502: INFO: Pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce": Phase="Running", Reason="", readiness=false. Elapsed: 4.02715227s
Jan 10 03:36:17.502: INFO: Pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce" satisfied condition "running"
STEP: Reading file content from the nginx-container 01/10/23 03:36:17.502
Jan 10 03:36:17.503: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3847 PodName:pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:36:17.503: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:36:17.503: INFO: ExecWithOptions: Clientset creation
Jan 10 03:36:17.503: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/emptydir-3847/pods/pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Jan 10 03:36:17.612: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 03:36:17.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3847" for this suite. 01/10/23 03:36:17.616
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":8,"skipped":82,"failed":0}
------------------------------
• [4.225 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:13.398
    Jan 10 03:36:13.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 03:36:13.399
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:13.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:13.438
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 01/10/23 03:36:13.448
    Jan 10 03:36:13.475: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce" in namespace "emptydir-3847" to be "running"
    Jan 10 03:36:13.494: INFO: Pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce": Phase="Pending", Reason="", readiness=false. Elapsed: 19.002685ms
    Jan 10 03:36:15.497: INFO: Pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021700515s
    Jan 10 03:36:17.502: INFO: Pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce": Phase="Running", Reason="", readiness=false. Elapsed: 4.02715227s
    Jan 10 03:36:17.502: INFO: Pod "pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce" satisfied condition "running"
    STEP: Reading file content from the nginx-container 01/10/23 03:36:17.502
    Jan 10 03:36:17.503: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3847 PodName:pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:36:17.503: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:36:17.503: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:36:17.503: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/emptydir-3847/pods/pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Jan 10 03:36:17.612: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 03:36:17.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3847" for this suite. 01/10/23 03:36:17.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:17.625
Jan 10 03:36:17.625: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-pred 01/10/23 03:36:17.627
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:17.655
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:17.659
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jan 10 03:36:17.669: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 10 03:36:17.693: INFO: Waiting for terminating namespaces to be deleted...
Jan 10 03:36:17.696: INFO: 
Logging pods the apiserver thinks is on node cncf-cp-etcd-wk1 before test
Jan 10 03:36:17.705: INFO: fleet-agent-745f6c6b7-8rvwd from cattle-fleet-system started at 2023-01-09 10:33:25 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.705: INFO: 	Container fleet-agent ready: true, restart count 1
Jan 10 03:36:17.705: INFO: cattle-cluster-agent-5c558c4984-89k8k from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.705: INFO: 	Container cluster-register ready: true, restart count 0
Jan 10 03:36:17.705: INFO: cattle-cluster-agent-5c558c4984-rwcnh from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.705: INFO: 	Container cluster-register ready: true, restart count 10
Jan 10 03:36:17.705: INFO: cattle-node-agent-jk48f from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.705: INFO: 	Container agent ready: true, restart count 0
Jan 10 03:36:17.705: INFO: kube-api-auth-gclz6 from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.705: INFO: 	Container kube-api-auth ready: true, restart count 0
Jan 10 03:36:17.705: INFO: rancher-webhook-5d7cccbd5-27z2v from cattle-system started at 2023-01-09 10:33:12 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.705: INFO: 	Container rancher-webhook ready: true, restart count 0
Jan 10 03:36:17.705: INFO: calico-kube-controllers-85d56898c-pmz4s from kube-system started at 2023-01-09 10:31:56 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.705: INFO: 	Container calico-kube-controllers ready: true, restart count 10
Jan 10 03:36:17.706: INFO: canal-b5cw4 from kube-system started at 2023-01-09 10:31:56 +0000 UTC (2 container statuses recorded)
Jan 10 03:36:17.706: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 03:36:17.706: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 03:36:17.706: INFO: coredns-autoscaler-74d474f45c-rx5r4 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.706: INFO: 	Container autoscaler ready: true, restart count 0
Jan 10 03:36:17.706: INFO: coredns-dfb7f8fd4-nhjj8 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.706: INFO: 	Container coredns ready: true, restart count 0
Jan 10 03:36:17.706: INFO: metrics-server-c47f7c9bb-v98f6 from kube-system started at 2023-01-09 10:32:16 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.706: INFO: 	Container metrics-server ready: true, restart count 0
Jan 10 03:36:17.706: INFO: rke-coredns-addon-deploy-job-vp4pw from kube-system started at 2023-01-09 10:43:38 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.706: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Jan 10 03:36:17.706: INFO: rke-metrics-addon-deploy-job-tqspg from kube-system started at 2023-01-09 10:32:13 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.706: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Jan 10 03:36:17.706: INFO: rke-network-plugin-deploy-job-ks979 from kube-system started at 2023-01-09 10:31:53 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.706: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Jan 10 03:36:17.706: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 03:36:17.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 03:36:17.706: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 10 03:36:17.706: INFO: 
Logging pods the apiserver thinks is on node cncf-wk2 before test
Jan 10 03:36:17.714: INFO: cattle-node-agent-sbqnv from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.714: INFO: 	Container agent ready: true, restart count 0
Jan 10 03:36:17.714: INFO: pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce from emptydir-3847 started at 2023-01-10 03:36:13 +0000 UTC (2 container statuses recorded)
Jan 10 03:36:17.714: INFO: 	Container busybox-main-container ready: true, restart count 0
Jan 10 03:36:17.714: INFO: 	Container busybox-sub-container ready: false, restart count 0
Jan 10 03:36:17.714: INFO: canal-dvpz6 from kube-system started at 2023-01-09 10:33:29 +0000 UTC (2 container statuses recorded)
Jan 10 03:36:17.714: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 03:36:17.714: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 03:36:17.714: INFO: sonobuoy from sonobuoy started at 2023-01-10 03:35:32 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.714: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 10 03:36:17.714: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 03:36:17.714: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 03:36:17.714: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 10 03:36:17.714: INFO: 
Logging pods the apiserver thinks is on node cncf-wk3 before test
Jan 10 03:36:17.722: INFO: cattle-node-agent-tt8zp from cattle-system started at 2023-01-09 10:34:17 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.722: INFO: 	Container agent ready: true, restart count 0
Jan 10 03:36:17.722: INFO: canal-4dc8j from kube-system started at 2023-01-09 10:34:17 +0000 UTC (2 container statuses recorded)
Jan 10 03:36:17.722: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 03:36:17.722: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 03:36:17.722: INFO: coredns-dfb7f8fd4-qdm8v from kube-system started at 2023-01-09 11:16:48 +0000 UTC (1 container statuses recorded)
Jan 10 03:36:17.722: INFO: 	Container coredns ready: true, restart count 0
Jan 10 03:36:17.722: INFO: sonobuoy-e2e-job-fcdcc673a5c843f7 from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 03:36:17.722: INFO: 	Container e2e ready: true, restart count 0
Jan 10 03:36:17.722: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 03:36:17.722: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 03:36:17.722: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 03:36:17.722: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 01/10/23 03:36:17.723
Jan 10 03:36:17.729: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5551" to be "running"
Jan 10 03:36:17.747: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 17.883062ms
Jan 10 03:36:19.750: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02121353s
Jan 10 03:36:21.752: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.022659351s
Jan 10 03:36:21.752: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 01/10/23 03:36:21.756
STEP: Trying to apply a random label on the found node. 01/10/23 03:36:21.792
STEP: verifying the node has the label kubernetes.io/e2e-f43d164d-2839-4e3c-a42b-4907b480345d 42 01/10/23 03:36:21.859
STEP: Trying to relaunch the pod, now with labels. 01/10/23 03:36:21.873
Jan 10 03:36:21.886: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5551" to be "not pending"
Jan 10 03:36:21.923: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 36.722769ms
Jan 10 03:36:23.926: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.039964041s
Jan 10 03:36:23.926: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-f43d164d-2839-4e3c-a42b-4907b480345d off the node cncf-wk3 01/10/23 03:36:23.928
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f43d164d-2839-4e3c-a42b-4907b480345d 01/10/23 03:36:23.945
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jan 10 03:36:23.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5551" for this suite. 01/10/23 03:36:23.961
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":9,"skipped":89,"failed":0}
------------------------------
• [SLOW TEST] [6.343 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:17.625
    Jan 10 03:36:17.625: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-pred 01/10/23 03:36:17.627
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:17.655
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:17.659
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jan 10 03:36:17.669: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jan 10 03:36:17.693: INFO: Waiting for terminating namespaces to be deleted...
    Jan 10 03:36:17.696: INFO: 
    Logging pods the apiserver thinks is on node cncf-cp-etcd-wk1 before test
    Jan 10 03:36:17.705: INFO: fleet-agent-745f6c6b7-8rvwd from cattle-fleet-system started at 2023-01-09 10:33:25 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.705: INFO: 	Container fleet-agent ready: true, restart count 1
    Jan 10 03:36:17.705: INFO: cattle-cluster-agent-5c558c4984-89k8k from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.705: INFO: 	Container cluster-register ready: true, restart count 0
    Jan 10 03:36:17.705: INFO: cattle-cluster-agent-5c558c4984-rwcnh from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.705: INFO: 	Container cluster-register ready: true, restart count 10
    Jan 10 03:36:17.705: INFO: cattle-node-agent-jk48f from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.705: INFO: 	Container agent ready: true, restart count 0
    Jan 10 03:36:17.705: INFO: kube-api-auth-gclz6 from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.705: INFO: 	Container kube-api-auth ready: true, restart count 0
    Jan 10 03:36:17.705: INFO: rancher-webhook-5d7cccbd5-27z2v from cattle-system started at 2023-01-09 10:33:12 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.705: INFO: 	Container rancher-webhook ready: true, restart count 0
    Jan 10 03:36:17.705: INFO: calico-kube-controllers-85d56898c-pmz4s from kube-system started at 2023-01-09 10:31:56 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.705: INFO: 	Container calico-kube-controllers ready: true, restart count 10
    Jan 10 03:36:17.706: INFO: canal-b5cw4 from kube-system started at 2023-01-09 10:31:56 +0000 UTC (2 container statuses recorded)
    Jan 10 03:36:17.706: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 03:36:17.706: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 03:36:17.706: INFO: coredns-autoscaler-74d474f45c-rx5r4 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.706: INFO: 	Container autoscaler ready: true, restart count 0
    Jan 10 03:36:17.706: INFO: coredns-dfb7f8fd4-nhjj8 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.706: INFO: 	Container coredns ready: true, restart count 0
    Jan 10 03:36:17.706: INFO: metrics-server-c47f7c9bb-v98f6 from kube-system started at 2023-01-09 10:32:16 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.706: INFO: 	Container metrics-server ready: true, restart count 0
    Jan 10 03:36:17.706: INFO: rke-coredns-addon-deploy-job-vp4pw from kube-system started at 2023-01-09 10:43:38 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.706: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
    Jan 10 03:36:17.706: INFO: rke-metrics-addon-deploy-job-tqspg from kube-system started at 2023-01-09 10:32:13 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.706: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
    Jan 10 03:36:17.706: INFO: rke-network-plugin-deploy-job-ks979 from kube-system started at 2023-01-09 10:31:53 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.706: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
    Jan 10 03:36:17.706: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 03:36:17.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 03:36:17.706: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 10 03:36:17.706: INFO: 
    Logging pods the apiserver thinks is on node cncf-wk2 before test
    Jan 10 03:36:17.714: INFO: cattle-node-agent-sbqnv from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.714: INFO: 	Container agent ready: true, restart count 0
    Jan 10 03:36:17.714: INFO: pod-sharedvolume-26a3c6b0-9844-4e5f-80ef-469a2d5fedce from emptydir-3847 started at 2023-01-10 03:36:13 +0000 UTC (2 container statuses recorded)
    Jan 10 03:36:17.714: INFO: 	Container busybox-main-container ready: true, restart count 0
    Jan 10 03:36:17.714: INFO: 	Container busybox-sub-container ready: false, restart count 0
    Jan 10 03:36:17.714: INFO: canal-dvpz6 from kube-system started at 2023-01-09 10:33:29 +0000 UTC (2 container statuses recorded)
    Jan 10 03:36:17.714: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 03:36:17.714: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 03:36:17.714: INFO: sonobuoy from sonobuoy started at 2023-01-10 03:35:32 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.714: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jan 10 03:36:17.714: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 03:36:17.714: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 03:36:17.714: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 10 03:36:17.714: INFO: 
    Logging pods the apiserver thinks is on node cncf-wk3 before test
    Jan 10 03:36:17.722: INFO: cattle-node-agent-tt8zp from cattle-system started at 2023-01-09 10:34:17 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.722: INFO: 	Container agent ready: true, restart count 0
    Jan 10 03:36:17.722: INFO: canal-4dc8j from kube-system started at 2023-01-09 10:34:17 +0000 UTC (2 container statuses recorded)
    Jan 10 03:36:17.722: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 03:36:17.722: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 03:36:17.722: INFO: coredns-dfb7f8fd4-qdm8v from kube-system started at 2023-01-09 11:16:48 +0000 UTC (1 container statuses recorded)
    Jan 10 03:36:17.722: INFO: 	Container coredns ready: true, restart count 0
    Jan 10 03:36:17.722: INFO: sonobuoy-e2e-job-fcdcc673a5c843f7 from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 03:36:17.722: INFO: 	Container e2e ready: true, restart count 0
    Jan 10 03:36:17.722: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 03:36:17.722: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 03:36:17.722: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 03:36:17.722: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 01/10/23 03:36:17.723
    Jan 10 03:36:17.729: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5551" to be "running"
    Jan 10 03:36:17.747: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 17.883062ms
    Jan 10 03:36:19.750: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02121353s
    Jan 10 03:36:21.752: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.022659351s
    Jan 10 03:36:21.752: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 01/10/23 03:36:21.756
    STEP: Trying to apply a random label on the found node. 01/10/23 03:36:21.792
    STEP: verifying the node has the label kubernetes.io/e2e-f43d164d-2839-4e3c-a42b-4907b480345d 42 01/10/23 03:36:21.859
    STEP: Trying to relaunch the pod, now with labels. 01/10/23 03:36:21.873
    Jan 10 03:36:21.886: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5551" to be "not pending"
    Jan 10 03:36:21.923: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 36.722769ms
    Jan 10 03:36:23.926: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.039964041s
    Jan 10 03:36:23.926: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-f43d164d-2839-4e3c-a42b-4907b480345d off the node cncf-wk3 01/10/23 03:36:23.928
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-f43d164d-2839-4e3c-a42b-4907b480345d 01/10/23 03:36:23.945
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 03:36:23.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-5551" for this suite. 01/10/23 03:36:23.961
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:23.97
Jan 10 03:36:23.970: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename disruption 01/10/23 03:36:23.971
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:24.041
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:24.045
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 01/10/23 03:36:24.051
STEP: Waiting for the pdb to be processed 01/10/23 03:36:24.056
STEP: updating the pdb 01/10/23 03:36:26.062
STEP: Waiting for the pdb to be processed 01/10/23 03:36:26.072
STEP: patching the pdb 01/10/23 03:36:28.079
STEP: Waiting for the pdb to be processed 01/10/23 03:36:28.088
STEP: Waiting for the pdb to be deleted 01/10/23 03:36:28.118
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 10 03:36:28.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2820" for this suite. 01/10/23 03:36:28.123
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":10,"skipped":127,"failed":0}
------------------------------
• [4.158 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:23.97
    Jan 10 03:36:23.970: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename disruption 01/10/23 03:36:23.971
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:24.041
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:24.045
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 01/10/23 03:36:24.051
    STEP: Waiting for the pdb to be processed 01/10/23 03:36:24.056
    STEP: updating the pdb 01/10/23 03:36:26.062
    STEP: Waiting for the pdb to be processed 01/10/23 03:36:26.072
    STEP: patching the pdb 01/10/23 03:36:28.079
    STEP: Waiting for the pdb to be processed 01/10/23 03:36:28.088
    STEP: Waiting for the pdb to be deleted 01/10/23 03:36:28.118
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 10 03:36:28.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2820" for this suite. 01/10/23 03:36:28.123
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:28.13
Jan 10 03:36:28.130: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-runtime 01/10/23 03:36:28.131
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:28.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:28.169
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 01/10/23 03:36:28.173
STEP: wait for the container to reach Succeeded 01/10/23 03:36:28.191
STEP: get the container status 01/10/23 03:36:32.234
STEP: the container should be terminated 01/10/23 03:36:32.244
STEP: the termination message should be set 01/10/23 03:36:32.244
Jan 10 03:36:32.244: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 01/10/23 03:36:32.244
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 10 03:36:32.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9567" for this suite. 01/10/23 03:36:32.275
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":11,"skipped":139,"failed":0}
------------------------------
• [4.154 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:28.13
    Jan 10 03:36:28.130: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-runtime 01/10/23 03:36:28.131
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:28.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:28.169
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 01/10/23 03:36:28.173
    STEP: wait for the container to reach Succeeded 01/10/23 03:36:28.191
    STEP: get the container status 01/10/23 03:36:32.234
    STEP: the container should be terminated 01/10/23 03:36:32.244
    STEP: the termination message should be set 01/10/23 03:36:32.244
    Jan 10 03:36:32.244: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 01/10/23 03:36:32.244
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 10 03:36:32.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-9567" for this suite. 01/10/23 03:36:32.275
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:32.285
Jan 10 03:36:32.286: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 03:36:32.286
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:32.407
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:32.436
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 01/10/23 03:36:32.459
Jan 10 03:36:32.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 create -f -'
Jan 10 03:36:32.947: INFO: stderr: ""
Jan 10 03:36:32.947: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 01/10/23 03:36:32.947
Jan 10 03:36:32.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 10 03:36:33.080: INFO: stderr: ""
Jan 10 03:36:33.080: INFO: stdout: "update-demo-nautilus-pbhbw update-demo-nautilus-qgm88 "
Jan 10 03:36:33.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-pbhbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 03:36:33.179: INFO: stderr: ""
Jan 10 03:36:33.179: INFO: stdout: ""
Jan 10 03:36:33.179: INFO: update-demo-nautilus-pbhbw is created but not running
Jan 10 03:36:38.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 10 03:36:38.251: INFO: stderr: ""
Jan 10 03:36:38.251: INFO: stdout: "update-demo-nautilus-pbhbw update-demo-nautilus-qgm88 "
Jan 10 03:36:38.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-pbhbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 03:36:38.318: INFO: stderr: ""
Jan 10 03:36:38.318: INFO: stdout: ""
Jan 10 03:36:38.318: INFO: update-demo-nautilus-pbhbw is created but not running
Jan 10 03:36:43.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 10 03:36:43.398: INFO: stderr: ""
Jan 10 03:36:43.398: INFO: stdout: "update-demo-nautilus-pbhbw update-demo-nautilus-qgm88 "
Jan 10 03:36:43.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-pbhbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 03:36:43.499: INFO: stderr: ""
Jan 10 03:36:43.499: INFO: stdout: "true"
Jan 10 03:36:43.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-pbhbw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 10 03:36:43.658: INFO: stderr: ""
Jan 10 03:36:43.658: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 10 03:36:43.659: INFO: validating pod update-demo-nautilus-pbhbw
Jan 10 03:36:43.664: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 10 03:36:43.664: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 10 03:36:43.664: INFO: update-demo-nautilus-pbhbw is verified up and running
Jan 10 03:36:43.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-qgm88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 03:36:43.726: INFO: stderr: ""
Jan 10 03:36:43.726: INFO: stdout: "true"
Jan 10 03:36:43.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-qgm88 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 10 03:36:43.794: INFO: stderr: ""
Jan 10 03:36:43.794: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 10 03:36:43.794: INFO: validating pod update-demo-nautilus-qgm88
Jan 10 03:36:43.799: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 10 03:36:43.799: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 10 03:36:43.799: INFO: update-demo-nautilus-qgm88 is verified up and running
STEP: using delete to clean up resources 01/10/23 03:36:43.799
Jan 10 03:36:43.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 delete --grace-period=0 --force -f -'
Jan 10 03:36:43.867: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 03:36:43.867: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 10 03:36:43.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get rc,svc -l name=update-demo --no-headers'
Jan 10 03:36:43.991: INFO: stderr: "No resources found in kubectl-6197 namespace.\n"
Jan 10 03:36:43.991: INFO: stdout: ""
Jan 10 03:36:43.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 10 03:36:44.200: INFO: stderr: ""
Jan 10 03:36:44.200: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 03:36:44.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6197" for this suite. 01/10/23 03:36:44.205
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":12,"skipped":142,"failed":0}
------------------------------
• [SLOW TEST] [11.925 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:32.285
    Jan 10 03:36:32.286: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 03:36:32.286
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:32.407
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:32.436
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 01/10/23 03:36:32.459
    Jan 10 03:36:32.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 create -f -'
    Jan 10 03:36:32.947: INFO: stderr: ""
    Jan 10 03:36:32.947: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 01/10/23 03:36:32.947
    Jan 10 03:36:32.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 10 03:36:33.080: INFO: stderr: ""
    Jan 10 03:36:33.080: INFO: stdout: "update-demo-nautilus-pbhbw update-demo-nautilus-qgm88 "
    Jan 10 03:36:33.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-pbhbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 03:36:33.179: INFO: stderr: ""
    Jan 10 03:36:33.179: INFO: stdout: ""
    Jan 10 03:36:33.179: INFO: update-demo-nautilus-pbhbw is created but not running
    Jan 10 03:36:38.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 10 03:36:38.251: INFO: stderr: ""
    Jan 10 03:36:38.251: INFO: stdout: "update-demo-nautilus-pbhbw update-demo-nautilus-qgm88 "
    Jan 10 03:36:38.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-pbhbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 03:36:38.318: INFO: stderr: ""
    Jan 10 03:36:38.318: INFO: stdout: ""
    Jan 10 03:36:38.318: INFO: update-demo-nautilus-pbhbw is created but not running
    Jan 10 03:36:43.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 10 03:36:43.398: INFO: stderr: ""
    Jan 10 03:36:43.398: INFO: stdout: "update-demo-nautilus-pbhbw update-demo-nautilus-qgm88 "
    Jan 10 03:36:43.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-pbhbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 03:36:43.499: INFO: stderr: ""
    Jan 10 03:36:43.499: INFO: stdout: "true"
    Jan 10 03:36:43.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-pbhbw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 10 03:36:43.658: INFO: stderr: ""
    Jan 10 03:36:43.658: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 10 03:36:43.659: INFO: validating pod update-demo-nautilus-pbhbw
    Jan 10 03:36:43.664: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 10 03:36:43.664: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 10 03:36:43.664: INFO: update-demo-nautilus-pbhbw is verified up and running
    Jan 10 03:36:43.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-qgm88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 03:36:43.726: INFO: stderr: ""
    Jan 10 03:36:43.726: INFO: stdout: "true"
    Jan 10 03:36:43.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods update-demo-nautilus-qgm88 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 10 03:36:43.794: INFO: stderr: ""
    Jan 10 03:36:43.794: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 10 03:36:43.794: INFO: validating pod update-demo-nautilus-qgm88
    Jan 10 03:36:43.799: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 10 03:36:43.799: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 10 03:36:43.799: INFO: update-demo-nautilus-qgm88 is verified up and running
    STEP: using delete to clean up resources 01/10/23 03:36:43.799
    Jan 10 03:36:43.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 delete --grace-period=0 --force -f -'
    Jan 10 03:36:43.867: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 03:36:43.867: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Jan 10 03:36:43.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get rc,svc -l name=update-demo --no-headers'
    Jan 10 03:36:43.991: INFO: stderr: "No resources found in kubectl-6197 namespace.\n"
    Jan 10 03:36:43.991: INFO: stdout: ""
    Jan 10 03:36:43.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6197 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jan 10 03:36:44.200: INFO: stderr: ""
    Jan 10 03:36:44.200: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 03:36:44.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6197" for this suite. 01/10/23 03:36:44.205
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:36:44.211
Jan 10 03:36:44.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 03:36:44.212
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:44.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:44.243
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 01/10/23 03:36:44.258
STEP: Counting existing ResourceQuota 01/10/23 03:36:49.264
STEP: Creating a ResourceQuota 01/10/23 03:36:54.269
STEP: Ensuring resource quota status is calculated 01/10/23 03:36:54.276
STEP: Creating a Secret 01/10/23 03:36:56.293
STEP: Ensuring resource quota status captures secret creation 01/10/23 03:36:56.316
STEP: Deleting a secret 01/10/23 03:36:58.32
STEP: Ensuring resource quota status released usage 01/10/23 03:36:58.323
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 03:37:00.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6877" for this suite. 01/10/23 03:37:00.331
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":13,"skipped":155,"failed":0}
------------------------------
• [SLOW TEST] [16.124 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:36:44.211
    Jan 10 03:36:44.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 03:36:44.212
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:36:44.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:36:44.243
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 01/10/23 03:36:44.258
    STEP: Counting existing ResourceQuota 01/10/23 03:36:49.264
    STEP: Creating a ResourceQuota 01/10/23 03:36:54.269
    STEP: Ensuring resource quota status is calculated 01/10/23 03:36:54.276
    STEP: Creating a Secret 01/10/23 03:36:56.293
    STEP: Ensuring resource quota status captures secret creation 01/10/23 03:36:56.316
    STEP: Deleting a secret 01/10/23 03:36:58.32
    STEP: Ensuring resource quota status released usage 01/10/23 03:36:58.323
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 03:37:00.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6877" for this suite. 01/10/23 03:37:00.331
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:37:00.337
Jan 10 03:37:00.338: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename endpointslice 01/10/23 03:37:00.338
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:37:00.37
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:37:00.382
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 01/10/23 03:37:00.416
STEP: getting /apis/discovery.k8s.io 01/10/23 03:37:00.427
STEP: getting /apis/discovery.k8s.iov1 01/10/23 03:37:00.429
STEP: creating 01/10/23 03:37:00.431
STEP: getting 01/10/23 03:37:00.446
STEP: listing 01/10/23 03:37:00.448
STEP: watching 01/10/23 03:37:00.451
Jan 10 03:37:00.451: INFO: starting watch
STEP: cluster-wide listing 01/10/23 03:37:00.452
STEP: cluster-wide watching 01/10/23 03:37:00.454
Jan 10 03:37:00.454: INFO: starting watch
STEP: patching 01/10/23 03:37:00.454
STEP: updating 01/10/23 03:37:00.462
Jan 10 03:37:00.468: INFO: waiting for watch events with expected annotations
Jan 10 03:37:00.468: INFO: saw patched and updated annotations
STEP: deleting 01/10/23 03:37:00.468
STEP: deleting a collection 01/10/23 03:37:00.481
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jan 10 03:37:00.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7385" for this suite. 01/10/23 03:37:00.516
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":14,"skipped":169,"failed":0}
------------------------------
• [0.187 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:37:00.337
    Jan 10 03:37:00.338: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename endpointslice 01/10/23 03:37:00.338
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:37:00.37
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:37:00.382
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 01/10/23 03:37:00.416
    STEP: getting /apis/discovery.k8s.io 01/10/23 03:37:00.427
    STEP: getting /apis/discovery.k8s.iov1 01/10/23 03:37:00.429
    STEP: creating 01/10/23 03:37:00.431
    STEP: getting 01/10/23 03:37:00.446
    STEP: listing 01/10/23 03:37:00.448
    STEP: watching 01/10/23 03:37:00.451
    Jan 10 03:37:00.451: INFO: starting watch
    STEP: cluster-wide listing 01/10/23 03:37:00.452
    STEP: cluster-wide watching 01/10/23 03:37:00.454
    Jan 10 03:37:00.454: INFO: starting watch
    STEP: patching 01/10/23 03:37:00.454
    STEP: updating 01/10/23 03:37:00.462
    Jan 10 03:37:00.468: INFO: waiting for watch events with expected annotations
    Jan 10 03:37:00.468: INFO: saw patched and updated annotations
    STEP: deleting 01/10/23 03:37:00.468
    STEP: deleting a collection 01/10/23 03:37:00.481
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jan 10 03:37:00.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7385" for this suite. 01/10/23 03:37:00.516
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:37:00.525
Jan 10 03:37:00.526: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename statefulset 01/10/23 03:37:00.527
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:37:00.568
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:37:00.588
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2190 01/10/23 03:37:00.614
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-2190 01/10/23 03:37:00.623
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2190 01/10/23 03:37:00.651
Jan 10 03:37:00.656: INFO: Found 0 stateful pods, waiting for 1
Jan 10 03:37:10.659: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 01/10/23 03:37:10.66
Jan 10 03:37:10.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 03:37:10.820: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 03:37:10.820: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 03:37:10.820: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 03:37:10.823: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 10 03:37:20.830: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 10 03:37:20.830: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 03:37:20.841: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 10 03:37:20.841: INFO: ss-0  cncf-wk2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  }]
Jan 10 03:37:20.841: INFO: 
Jan 10 03:37:20.841: INFO: StatefulSet ss has not reached scale 3, at 1
Jan 10 03:37:21.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996869081s
Jan 10 03:37:22.872: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.969813811s
Jan 10 03:37:23.882: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.966453159s
Jan 10 03:37:24.886: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.955743636s
Jan 10 03:37:25.890: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.951745527s
Jan 10 03:37:26.894: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.947280638s
Jan 10 03:37:27.897: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943841072s
Jan 10 03:37:28.900: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.940811603s
Jan 10 03:37:29.905: INFO: Verifying statefulset ss doesn't scale past 3 for another 937.314812ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2190 01/10/23 03:37:30.906
Jan 10 03:37:30.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 03:37:31.087: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 10 03:37:31.087: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 03:37:31.087: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 03:37:31.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 03:37:31.341: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jan 10 03:37:31.341: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 03:37:31.341: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 03:37:31.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 03:37:31.667: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jan 10 03:37:31.667: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 03:37:31.667: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 03:37:31.671: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 03:37:31.671: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 03:37:31.671: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 01/10/23 03:37:31.671
Jan 10 03:37:31.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 03:37:31.825: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 03:37:31.825: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 03:37:31.825: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 03:37:31.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 03:37:31.968: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 03:37:31.968: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 03:37:31.968: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 03:37:31.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 03:37:32.147: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 03:37:32.147: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 03:37:32.147: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 03:37:32.147: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 03:37:32.149: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 10 03:37:42.155: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 10 03:37:42.155: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 10 03:37:42.155: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 10 03:37:42.175: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jan 10 03:37:42.175: INFO: ss-0  cncf-wk2          Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  }]
Jan 10 03:37:42.175: INFO: ss-1  cncf-wk3          Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  }]
Jan 10 03:37:42.175: INFO: ss-2  cncf-cp-etcd-wk1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  }]
Jan 10 03:37:42.175: INFO: 
Jan 10 03:37:42.175: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 10 03:37:43.178: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jan 10 03:37:43.178: INFO: ss-0  cncf-wk2          Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  }]
Jan 10 03:37:43.178: INFO: ss-1  cncf-wk3          Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  }]
Jan 10 03:37:43.178: INFO: ss-2  cncf-cp-etcd-wk1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  }]
Jan 10 03:37:43.178: INFO: 
Jan 10 03:37:43.178: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 10 03:37:44.181: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.983975088s
Jan 10 03:37:45.184: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.981115374s
Jan 10 03:37:46.190: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.978268461s
Jan 10 03:37:47.194: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.972003724s
Jan 10 03:37:48.197: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.968704532s
Jan 10 03:37:49.199: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.965781328s
Jan 10 03:37:50.202: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.962916555s
Jan 10 03:37:51.205: INFO: Verifying statefulset ss doesn't scale past 0 for another 960.249367ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2190 01/10/23 03:37:52.206
Jan 10 03:37:52.210: INFO: Scaling statefulset ss to 0
Jan 10 03:37:52.218: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 10 03:37:52.219: INFO: Deleting all statefulset in ns statefulset-2190
Jan 10 03:37:52.221: INFO: Scaling statefulset ss to 0
Jan 10 03:37:52.228: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 03:37:52.230: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 10 03:37:52.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2190" for this suite. 01/10/23 03:37:52.263
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":15,"skipped":173,"failed":0}
------------------------------
• [SLOW TEST] [51.744 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:37:00.525
    Jan 10 03:37:00.526: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename statefulset 01/10/23 03:37:00.527
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:37:00.568
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:37:00.588
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2190 01/10/23 03:37:00.614
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-2190 01/10/23 03:37:00.623
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2190 01/10/23 03:37:00.651
    Jan 10 03:37:00.656: INFO: Found 0 stateful pods, waiting for 1
    Jan 10 03:37:10.659: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 01/10/23 03:37:10.66
    Jan 10 03:37:10.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 03:37:10.820: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 03:37:10.820: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 03:37:10.820: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 03:37:10.823: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Jan 10 03:37:20.830: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jan 10 03:37:20.830: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 03:37:20.841: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
    Jan 10 03:37:20.841: INFO: ss-0  cncf-wk2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  }]
    Jan 10 03:37:20.841: INFO: 
    Jan 10 03:37:20.841: INFO: StatefulSet ss has not reached scale 3, at 1
    Jan 10 03:37:21.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996869081s
    Jan 10 03:37:22.872: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.969813811s
    Jan 10 03:37:23.882: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.966453159s
    Jan 10 03:37:24.886: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.955743636s
    Jan 10 03:37:25.890: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.951745527s
    Jan 10 03:37:26.894: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.947280638s
    Jan 10 03:37:27.897: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943841072s
    Jan 10 03:37:28.900: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.940811603s
    Jan 10 03:37:29.905: INFO: Verifying statefulset ss doesn't scale past 3 for another 937.314812ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2190 01/10/23 03:37:30.906
    Jan 10 03:37:30.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 03:37:31.087: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 10 03:37:31.087: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 03:37:31.087: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 03:37:31.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 03:37:31.341: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Jan 10 03:37:31.341: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 03:37:31.341: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 03:37:31.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 03:37:31.667: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Jan 10 03:37:31.667: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 03:37:31.667: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 03:37:31.671: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 03:37:31.671: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 03:37:31.671: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 01/10/23 03:37:31.671
    Jan 10 03:37:31.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 03:37:31.825: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 03:37:31.825: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 03:37:31.825: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 03:37:31.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 03:37:31.968: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 03:37:31.968: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 03:37:31.968: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 03:37:31.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-2190 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 03:37:32.147: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 03:37:32.147: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 03:37:32.147: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 03:37:32.147: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 03:37:32.149: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Jan 10 03:37:42.155: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jan 10 03:37:42.155: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Jan 10 03:37:42.155: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Jan 10 03:37:42.175: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Jan 10 03:37:42.175: INFO: ss-0  cncf-wk2          Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  }]
    Jan 10 03:37:42.175: INFO: ss-1  cncf-wk3          Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  }]
    Jan 10 03:37:42.175: INFO: ss-2  cncf-cp-etcd-wk1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  }]
    Jan 10 03:37:42.175: INFO: 
    Jan 10 03:37:42.175: INFO: StatefulSet ss has not reached scale 0, at 3
    Jan 10 03:37:43.178: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Jan 10 03:37:43.178: INFO: ss-0  cncf-wk2          Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:00 +0000 UTC  }]
    Jan 10 03:37:43.178: INFO: ss-1  cncf-wk3          Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  }]
    Jan 10 03:37:43.178: INFO: ss-2  cncf-cp-etcd-wk1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:37:20 +0000 UTC  }]
    Jan 10 03:37:43.178: INFO: 
    Jan 10 03:37:43.178: INFO: StatefulSet ss has not reached scale 0, at 3
    Jan 10 03:37:44.181: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.983975088s
    Jan 10 03:37:45.184: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.981115374s
    Jan 10 03:37:46.190: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.978268461s
    Jan 10 03:37:47.194: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.972003724s
    Jan 10 03:37:48.197: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.968704532s
    Jan 10 03:37:49.199: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.965781328s
    Jan 10 03:37:50.202: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.962916555s
    Jan 10 03:37:51.205: INFO: Verifying statefulset ss doesn't scale past 0 for another 960.249367ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2190 01/10/23 03:37:52.206
    Jan 10 03:37:52.210: INFO: Scaling statefulset ss to 0
    Jan 10 03:37:52.218: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 10 03:37:52.219: INFO: Deleting all statefulset in ns statefulset-2190
    Jan 10 03:37:52.221: INFO: Scaling statefulset ss to 0
    Jan 10 03:37:52.228: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 03:37:52.230: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 10 03:37:52.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2190" for this suite. 01/10/23 03:37:52.263
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:37:52.273
Jan 10 03:37:52.273: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:37:52.274
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:37:52.311
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:37:52.315
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-90c9c6e2-7595-4a91-abc9-026aba53ef4b 01/10/23 03:37:52.33
STEP: Creating the pod 01/10/23 03:37:52.336
Jan 10 03:37:52.372: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946" in namespace "projected-2114" to be "running and ready"
Jan 10 03:37:52.395: INFO: Pod "pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946": Phase="Pending", Reason="", readiness=false. Elapsed: 23.398049ms
Jan 10 03:37:52.396: INFO: The phase of Pod pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:37:54.400: INFO: Pod "pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946": Phase="Running", Reason="", readiness=true. Elapsed: 2.028082604s
Jan 10 03:37:54.400: INFO: The phase of Pod pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946 is Running (Ready = true)
Jan 10 03:37:54.400: INFO: Pod "pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-90c9c6e2-7595-4a91-abc9-026aba53ef4b 01/10/23 03:37:54.426
STEP: waiting to observe update in volume 01/10/23 03:37:54.433
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 03:37:56.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2114" for this suite. 01/10/23 03:37:56.455
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":16,"skipped":205,"failed":0}
------------------------------
• [4.193 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:37:52.273
    Jan 10 03:37:52.273: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:37:52.274
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:37:52.311
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:37:52.315
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-90c9c6e2-7595-4a91-abc9-026aba53ef4b 01/10/23 03:37:52.33
    STEP: Creating the pod 01/10/23 03:37:52.336
    Jan 10 03:37:52.372: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946" in namespace "projected-2114" to be "running and ready"
    Jan 10 03:37:52.395: INFO: Pod "pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946": Phase="Pending", Reason="", readiness=false. Elapsed: 23.398049ms
    Jan 10 03:37:52.396: INFO: The phase of Pod pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:37:54.400: INFO: Pod "pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946": Phase="Running", Reason="", readiness=true. Elapsed: 2.028082604s
    Jan 10 03:37:54.400: INFO: The phase of Pod pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946 is Running (Ready = true)
    Jan 10 03:37:54.400: INFO: Pod "pod-projected-configmaps-b72c82cc-fe92-4353-8447-1b3b44ae7946" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-90c9c6e2-7595-4a91-abc9-026aba53ef4b 01/10/23 03:37:54.426
    STEP: waiting to observe update in volume 01/10/23 03:37:54.433
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 03:37:56.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2114" for this suite. 01/10/23 03:37:56.455
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:37:56.468
Jan 10 03:37:56.468: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename cronjob 01/10/23 03:37:56.469
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:37:56.488
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:37:56.501
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 01/10/23 03:37:56.507
STEP: Ensuring more than one job is running at a time 01/10/23 03:37:56.519
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 01/10/23 03:39:00.524
STEP: Removing cronjob 01/10/23 03:39:00.527
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 10 03:39:00.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-874" for this suite. 01/10/23 03:39:00.536
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":17,"skipped":215,"failed":0}
------------------------------
• [SLOW TEST] [64.081 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:37:56.468
    Jan 10 03:37:56.468: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename cronjob 01/10/23 03:37:56.469
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:37:56.488
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:37:56.501
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 01/10/23 03:37:56.507
    STEP: Ensuring more than one job is running at a time 01/10/23 03:37:56.519
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 01/10/23 03:39:00.524
    STEP: Removing cronjob 01/10/23 03:39:00.527
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 10 03:39:00.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-874" for this suite. 01/10/23 03:39:00.536
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:39:00.55
Jan 10 03:39:00.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename subpath 01/10/23 03:39:00.551
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:39:00.599
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:39:00.62
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/10/23 03:39:00.623
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-h7rs 01/10/23 03:39:00.667
STEP: Creating a pod to test atomic-volume-subpath 01/10/23 03:39:00.667
Jan 10 03:39:00.699: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-h7rs" in namespace "subpath-9184" to be "Succeeded or Failed"
Jan 10 03:39:00.706: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 7.048759ms
Jan 10 03:39:02.711: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011634074s
Jan 10 03:39:04.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010533672s
Jan 10 03:39:06.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010402002s
Jan 10 03:39:08.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 8.011220871s
Jan 10 03:39:10.709: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 10.009958065s
Jan 10 03:39:12.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 12.010313202s
Jan 10 03:39:14.711: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 14.011553118s
Jan 10 03:39:16.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 16.011038756s
Jan 10 03:39:18.709: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 18.00998065s
Jan 10 03:39:20.712: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 20.012509037s
Jan 10 03:39:22.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 22.011257204s
Jan 10 03:39:24.713: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 24.013699791s
Jan 10 03:39:26.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 26.010389109s
Jan 10 03:39:28.716: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=false. Elapsed: 28.016480367s
Jan 10 03:39:30.709: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.010286881s
STEP: Saw pod success 01/10/23 03:39:30.71
Jan 10 03:39:30.710: INFO: Pod "pod-subpath-test-configmap-h7rs" satisfied condition "Succeeded or Failed"
Jan 10 03:39:30.712: INFO: Trying to get logs from node cncf-wk3 pod pod-subpath-test-configmap-h7rs container test-container-subpath-configmap-h7rs: <nil>
STEP: delete the pod 01/10/23 03:39:30.731
Jan 10 03:39:30.744: INFO: Waiting for pod pod-subpath-test-configmap-h7rs to disappear
Jan 10 03:39:30.746: INFO: Pod pod-subpath-test-configmap-h7rs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-h7rs 01/10/23 03:39:30.746
Jan 10 03:39:30.746: INFO: Deleting pod "pod-subpath-test-configmap-h7rs" in namespace "subpath-9184"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 10 03:39:30.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9184" for this suite. 01/10/23 03:39:30.751
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":18,"skipped":220,"failed":0}
------------------------------
• [SLOW TEST] [30.205 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:39:00.55
    Jan 10 03:39:00.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename subpath 01/10/23 03:39:00.551
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:39:00.599
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:39:00.62
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/10/23 03:39:00.623
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-h7rs 01/10/23 03:39:00.667
    STEP: Creating a pod to test atomic-volume-subpath 01/10/23 03:39:00.667
    Jan 10 03:39:00.699: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-h7rs" in namespace "subpath-9184" to be "Succeeded or Failed"
    Jan 10 03:39:00.706: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 7.048759ms
    Jan 10 03:39:02.711: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011634074s
    Jan 10 03:39:04.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010533672s
    Jan 10 03:39:06.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010402002s
    Jan 10 03:39:08.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 8.011220871s
    Jan 10 03:39:10.709: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 10.009958065s
    Jan 10 03:39:12.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 12.010313202s
    Jan 10 03:39:14.711: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 14.011553118s
    Jan 10 03:39:16.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 16.011038756s
    Jan 10 03:39:18.709: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 18.00998065s
    Jan 10 03:39:20.712: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 20.012509037s
    Jan 10 03:39:22.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 22.011257204s
    Jan 10 03:39:24.713: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 24.013699791s
    Jan 10 03:39:26.710: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=true. Elapsed: 26.010389109s
    Jan 10 03:39:28.716: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Running", Reason="", readiness=false. Elapsed: 28.016480367s
    Jan 10 03:39:30.709: INFO: Pod "pod-subpath-test-configmap-h7rs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.010286881s
    STEP: Saw pod success 01/10/23 03:39:30.71
    Jan 10 03:39:30.710: INFO: Pod "pod-subpath-test-configmap-h7rs" satisfied condition "Succeeded or Failed"
    Jan 10 03:39:30.712: INFO: Trying to get logs from node cncf-wk3 pod pod-subpath-test-configmap-h7rs container test-container-subpath-configmap-h7rs: <nil>
    STEP: delete the pod 01/10/23 03:39:30.731
    Jan 10 03:39:30.744: INFO: Waiting for pod pod-subpath-test-configmap-h7rs to disappear
    Jan 10 03:39:30.746: INFO: Pod pod-subpath-test-configmap-h7rs no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-h7rs 01/10/23 03:39:30.746
    Jan 10 03:39:30.746: INFO: Deleting pod "pod-subpath-test-configmap-h7rs" in namespace "subpath-9184"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 10 03:39:30.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-9184" for this suite. 01/10/23 03:39:30.751
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:39:30.762
Jan 10 03:39:30.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 03:39:30.763
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:39:30.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:39:30.793
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-5205 01/10/23 03:39:30.859
Jan 10 03:39:30.884: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5205" to be "running and ready"
Jan 10 03:39:30.894: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 9.73181ms
Jan 10 03:39:30.895: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:39:32.898: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.01340458s
Jan 10 03:39:32.898: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Jan 10 03:39:32.898: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Jan 10 03:39:32.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Jan 10 03:39:33.429: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Jan 10 03:39:33.429: INFO: stdout: "iptables"
Jan 10 03:39:33.429: INFO: proxyMode: iptables
Jan 10 03:39:33.446: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Jan 10 03:39:33.450: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-5205 01/10/23 03:39:33.451
STEP: creating replication controller affinity-clusterip-timeout in namespace services-5205 01/10/23 03:39:33.46
I0110 03:39:33.470292      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-5205, replica count: 3
I0110 03:39:36.521896      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0110 03:39:39.522592      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 03:39:39.545: INFO: Creating new exec pod
Jan 10 03:39:39.549: INFO: Waiting up to 5m0s for pod "execpod-affinity427q6" in namespace "services-5205" to be "running"
Jan 10 03:39:39.578: INFO: Pod "execpod-affinity427q6": Phase="Pending", Reason="", readiness=false. Elapsed: 28.519895ms
Jan 10 03:39:41.582: INFO: Pod "execpod-affinity427q6": Phase="Running", Reason="", readiness=true. Elapsed: 2.032421263s
Jan 10 03:39:41.582: INFO: Pod "execpod-affinity427q6" satisfied condition "running"
Jan 10 03:39:42.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Jan 10 03:39:42.797: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Jan 10 03:39:42.797: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 03:39:42.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.96.200 80'
Jan 10 03:39:42.986: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.96.200 80\nConnection to 10.43.96.200 80 port [tcp/http] succeeded!\n"
Jan 10 03:39:42.986: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 03:39:42.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.96.200:80/ ; done'
Jan 10 03:39:43.227: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n"
Jan 10 03:39:43.227: INFO: stdout: "\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p"
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.228: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.228: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.228: INFO: Received response from host: affinity-clusterip-timeout-64d8p
Jan 10 03:39:43.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.43.96.200:80/'
Jan 10 03:39:43.454: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n"
Jan 10 03:39:43.454: INFO: stdout: "affinity-clusterip-timeout-64d8p"
Jan 10 03:40:03.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.43.96.200:80/'
Jan 10 03:40:03.751: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n"
Jan 10 03:40:03.751: INFO: stdout: "affinity-clusterip-timeout-zjgc9"
Jan 10 03:40:03.751: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-5205, will wait for the garbage collector to delete the pods 01/10/23 03:40:03.806
Jan 10 03:40:03.897: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 8.494325ms
Jan 10 03:40:04.198: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 300.821839ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 03:40:06.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5205" for this suite. 01/10/23 03:40:06.464
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":19,"skipped":239,"failed":0}
------------------------------
• [SLOW TEST] [35.716 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:39:30.762
    Jan 10 03:39:30.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 03:39:30.763
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:39:30.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:39:30.793
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-5205 01/10/23 03:39:30.859
    Jan 10 03:39:30.884: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5205" to be "running and ready"
    Jan 10 03:39:30.894: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 9.73181ms
    Jan 10 03:39:30.895: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:39:32.898: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.01340458s
    Jan 10 03:39:32.898: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Jan 10 03:39:32.898: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Jan 10 03:39:32.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Jan 10 03:39:33.429: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Jan 10 03:39:33.429: INFO: stdout: "iptables"
    Jan 10 03:39:33.429: INFO: proxyMode: iptables
    Jan 10 03:39:33.446: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Jan 10 03:39:33.450: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-5205 01/10/23 03:39:33.451
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-5205 01/10/23 03:39:33.46
    I0110 03:39:33.470292      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-5205, replica count: 3
    I0110 03:39:36.521896      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0110 03:39:39.522592      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 03:39:39.545: INFO: Creating new exec pod
    Jan 10 03:39:39.549: INFO: Waiting up to 5m0s for pod "execpod-affinity427q6" in namespace "services-5205" to be "running"
    Jan 10 03:39:39.578: INFO: Pod "execpod-affinity427q6": Phase="Pending", Reason="", readiness=false. Elapsed: 28.519895ms
    Jan 10 03:39:41.582: INFO: Pod "execpod-affinity427q6": Phase="Running", Reason="", readiness=true. Elapsed: 2.032421263s
    Jan 10 03:39:41.582: INFO: Pod "execpod-affinity427q6" satisfied condition "running"
    Jan 10 03:39:42.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Jan 10 03:39:42.797: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Jan 10 03:39:42.797: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 03:39:42.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.96.200 80'
    Jan 10 03:39:42.986: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.96.200 80\nConnection to 10.43.96.200 80 port [tcp/http] succeeded!\n"
    Jan 10 03:39:42.986: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 03:39:42.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.96.200:80/ ; done'
    Jan 10 03:39:43.227: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n"
    Jan 10 03:39:43.227: INFO: stdout: "\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p\naffinity-clusterip-timeout-64d8p"
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.227: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.228: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.228: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.228: INFO: Received response from host: affinity-clusterip-timeout-64d8p
    Jan 10 03:39:43.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.43.96.200:80/'
    Jan 10 03:39:43.454: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n"
    Jan 10 03:39:43.454: INFO: stdout: "affinity-clusterip-timeout-64d8p"
    Jan 10 03:40:03.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5205 exec execpod-affinity427q6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.43.96.200:80/'
    Jan 10 03:40:03.751: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.43.96.200:80/\n"
    Jan 10 03:40:03.751: INFO: stdout: "affinity-clusterip-timeout-zjgc9"
    Jan 10 03:40:03.751: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-5205, will wait for the garbage collector to delete the pods 01/10/23 03:40:03.806
    Jan 10 03:40:03.897: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 8.494325ms
    Jan 10 03:40:04.198: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 300.821839ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 03:40:06.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5205" for this suite. 01/10/23 03:40:06.464
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:06.479
Jan 10 03:40:06.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 03:40:06.48
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:06.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:06.531
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Jan 10 03:40:06.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-8496 version'
Jan 10 03:40:06.607: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Jan 10 03:40:06.607: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:15:02Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:08:09Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 03:40:06.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8496" for this suite. 01/10/23 03:40:06.61
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":20,"skipped":253,"failed":0}
------------------------------
• [0.135 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:06.479
    Jan 10 03:40:06.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 03:40:06.48
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:06.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:06.531
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Jan 10 03:40:06.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-8496 version'
    Jan 10 03:40:06.607: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Jan 10 03:40:06.607: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:15:02Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:08:09Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 03:40:06.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8496" for this suite. 01/10/23 03:40:06.61
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:06.618
Jan 10 03:40:06.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename namespaces 01/10/23 03:40:06.619
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:06.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:06.65
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 01/10/23 03:40:06.652
STEP: patching the Namespace 01/10/23 03:40:06.685
STEP: get the Namespace and ensuring it has the label 01/10/23 03:40:06.713
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jan 10 03:40:06.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5651" for this suite. 01/10/23 03:40:06.734
STEP: Destroying namespace "nspatchtest-6f8d8608-60a0-4fe6-b049-4f12659e12d8-117" for this suite. 01/10/23 03:40:06.748
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":21,"skipped":258,"failed":0}
------------------------------
• [0.145 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:06.618
    Jan 10 03:40:06.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename namespaces 01/10/23 03:40:06.619
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:06.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:06.65
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 01/10/23 03:40:06.652
    STEP: patching the Namespace 01/10/23 03:40:06.685
    STEP: get the Namespace and ensuring it has the label 01/10/23 03:40:06.713
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 03:40:06.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-5651" for this suite. 01/10/23 03:40:06.734
    STEP: Destroying namespace "nspatchtest-6f8d8608-60a0-4fe6-b049-4f12659e12d8-117" for this suite. 01/10/23 03:40:06.748
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:06.764
Jan 10 03:40:06.764: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 03:40:06.766
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:06.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:06.795
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Jan 10 03:40:06.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:40:07.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2909" for this suite. 01/10/23 03:40:08.045
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":22,"skipped":262,"failed":0}
------------------------------
• [1.401 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:06.764
    Jan 10 03:40:06.764: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 03:40:06.766
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:06.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:06.795
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Jan 10 03:40:06.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:40:07.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2909" for this suite. 01/10/23 03:40:08.045
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:08.171
Jan 10 03:40:08.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename svc-latency 01/10/23 03:40:08.179
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:08.586
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:08.616
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Jan 10 03:40:08.656: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7558 01/10/23 03:40:08.659
I0110 03:40:08.675430      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7558, replica count: 1
I0110 03:40:09.726547      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0110 03:40:10.727747      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0110 03:40:11.728163      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 03:40:11.914: INFO: Created: latency-svc-trvmt
Jan 10 03:40:11.953: INFO: Got endpoints: latency-svc-trvmt [124.451861ms]
Jan 10 03:40:12.187: INFO: Created: latency-svc-nvg28
Jan 10 03:40:12.291: INFO: Got endpoints: latency-svc-nvg28 [337.865052ms]
Jan 10 03:40:12.456: INFO: Created: latency-svc-7zxr9
Jan 10 03:40:12.478: INFO: Created: latency-svc-nrpc4
Jan 10 03:40:12.480: INFO: Created: latency-svc-jx6j4
Jan 10 03:40:12.480: INFO: Created: latency-svc-vgdlc
Jan 10 03:40:12.480: INFO: Created: latency-svc-2gvsq
Jan 10 03:40:12.480: INFO: Created: latency-svc-4xqfc
Jan 10 03:40:12.480: INFO: Created: latency-svc-5wmd2
Jan 10 03:40:12.480: INFO: Created: latency-svc-qtpzq
Jan 10 03:40:12.481: INFO: Created: latency-svc-wk9sc
Jan 10 03:40:12.481: INFO: Created: latency-svc-cv4sn
Jan 10 03:40:12.481: INFO: Created: latency-svc-nqnqm
Jan 10 03:40:12.481: INFO: Created: latency-svc-h6kln
Jan 10 03:40:12.481: INFO: Created: latency-svc-f4nf6
Jan 10 03:40:12.482: INFO: Created: latency-svc-jp6j4
Jan 10 03:40:12.482: INFO: Created: latency-svc-sfnj5
Jan 10 03:40:12.498: INFO: Got endpoints: latency-svc-7zxr9 [536.333183ms]
Jan 10 03:40:12.498: INFO: Got endpoints: latency-svc-vgdlc [539.523479ms]
Jan 10 03:40:12.499: INFO: Got endpoints: latency-svc-nrpc4 [208.005684ms]
Jan 10 03:40:12.513: INFO: Created: latency-svc-lh4lg
Jan 10 03:40:12.514: INFO: Got endpoints: latency-svc-sfnj5 [561.125563ms]
Jan 10 03:40:12.520: INFO: Got endpoints: latency-svc-nqnqm [566.632611ms]
Jan 10 03:40:12.543: INFO: Created: latency-svc-5mf8r
Jan 10 03:40:12.546: INFO: Got endpoints: latency-svc-2gvsq [587.80244ms]
Jan 10 03:40:12.546: INFO: Got endpoints: latency-svc-f4nf6 [593.032855ms]
Jan 10 03:40:12.547: INFO: Got endpoints: latency-svc-5wmd2 [588.531081ms]
Jan 10 03:40:12.547: INFO: Got endpoints: latency-svc-cv4sn [593.098752ms]
Jan 10 03:40:12.549: INFO: Got endpoints: latency-svc-jp6j4 [595.585506ms]
Jan 10 03:40:12.560: INFO: Created: latency-svc-4zmtm
Jan 10 03:40:12.566: INFO: Created: latency-svc-tlpcg
Jan 10 03:40:12.573: INFO: Got endpoints: latency-svc-4xqfc [615.206859ms]
Jan 10 03:40:12.574: INFO: Got endpoints: latency-svc-jx6j4 [615.666002ms]
Jan 10 03:40:12.578: INFO: Got endpoints: latency-svc-h6kln [619.837115ms]
Jan 10 03:40:12.579: INFO: Got endpoints: latency-svc-qtpzq [621.095412ms]
Jan 10 03:40:12.579: INFO: Got endpoints: latency-svc-wk9sc [625.348723ms]
Jan 10 03:40:12.591: INFO: Created: latency-svc-8l6jl
Jan 10 03:40:12.638: INFO: Got endpoints: latency-svc-lh4lg [140.031512ms]
Jan 10 03:40:12.646: INFO: Got endpoints: latency-svc-tlpcg [131.456508ms]
Jan 10 03:40:12.650: INFO: Got endpoints: latency-svc-4zmtm [150.698751ms]
Jan 10 03:40:12.650: INFO: Got endpoints: latency-svc-5mf8r [151.990949ms]
Jan 10 03:40:12.661: INFO: Created: latency-svc-qb5hq
Jan 10 03:40:12.672: INFO: Got endpoints: latency-svc-8l6jl [151.712159ms]
Jan 10 03:40:12.691: INFO: Got endpoints: latency-svc-qb5hq [144.980221ms]
Jan 10 03:40:12.769: INFO: Created: latency-svc-gnbhj
Jan 10 03:40:12.769: INFO: Created: latency-svc-vwkmm
Jan 10 03:40:12.770: INFO: Created: latency-svc-bxjpx
Jan 10 03:40:12.770: INFO: Created: latency-svc-qz8f7
Jan 10 03:40:12.770: INFO: Created: latency-svc-2nhvx
Jan 10 03:40:12.770: INFO: Created: latency-svc-b64jg
Jan 10 03:40:12.770: INFO: Created: latency-svc-hb98x
Jan 10 03:40:12.771: INFO: Created: latency-svc-vm8qx
Jan 10 03:40:12.771: INFO: Created: latency-svc-k4w8t
Jan 10 03:40:12.771: INFO: Created: latency-svc-p4zqs
Jan 10 03:40:12.771: INFO: Created: latency-svc-jqpcl
Jan 10 03:40:12.771: INFO: Created: latency-svc-pmnhv
Jan 10 03:40:12.771: INFO: Created: latency-svc-dmbdq
Jan 10 03:40:12.771: INFO: Created: latency-svc-s8skn
Jan 10 03:40:12.772: INFO: Created: latency-svc-tlzpc
Jan 10 03:40:12.823: INFO: Got endpoints: latency-svc-hb98x [273.459437ms]
Jan 10 03:40:12.837: INFO: Got endpoints: latency-svc-pmnhv [258.267876ms]
Jan 10 03:40:12.837: INFO: Got endpoints: latency-svc-dmbdq [257.78936ms]
Jan 10 03:40:12.837: INFO: Got endpoints: latency-svc-jqpcl [257.742232ms]
Jan 10 03:40:12.858: INFO: Got endpoints: latency-svc-vm8qx [220.742092ms]
Jan 10 03:40:12.859: INFO: Got endpoints: latency-svc-p4zqs [212.711089ms]
Jan 10 03:40:12.878: INFO: Got endpoints: latency-svc-bxjpx [228.130343ms]
Jan 10 03:40:12.878: INFO: Got endpoints: latency-svc-vwkmm [303.986888ms]
Jan 10 03:40:12.879: INFO: Got endpoints: latency-svc-gnbhj [228.913923ms]
Jan 10 03:40:12.888: INFO: Got endpoints: latency-svc-k4w8t [196.619271ms]
Jan 10 03:40:12.891: INFO: Created: latency-svc-5jrxb
Jan 10 03:40:12.895: INFO: Got endpoints: latency-svc-2nhvx [223.69966ms]
Jan 10 03:40:12.906: INFO: Got endpoints: latency-svc-b64jg [332.617904ms]
Jan 10 03:40:12.914: INFO: Created: latency-svc-87cg6
Jan 10 03:40:12.917: INFO: Got endpoints: latency-svc-s8skn [370.328277ms]
Jan 10 03:40:12.917: INFO: Got endpoints: latency-svc-tlzpc [370.282164ms]
Jan 10 03:40:12.961: INFO: Got endpoints: latency-svc-87cg6 [123.84794ms]
Jan 10 03:40:12.961: INFO: Got endpoints: latency-svc-qz8f7 [414.383802ms]
Jan 10 03:40:12.961: INFO: Got endpoints: latency-svc-5jrxb [138.182371ms]
Jan 10 03:40:12.986: INFO: Created: latency-svc-mnjqq
Jan 10 03:40:12.997: INFO: Got endpoints: latency-svc-mnjqq [159.71262ms]
Jan 10 03:40:13.005: INFO: Created: latency-svc-v2cmm
Jan 10 03:40:13.020: INFO: Got endpoints: latency-svc-v2cmm [182.478169ms]
Jan 10 03:40:13.046: INFO: Created: latency-svc-mcztz
Jan 10 03:40:13.058: INFO: Created: latency-svc-kf5gp
Jan 10 03:40:13.061: INFO: Got endpoints: latency-svc-mcztz [201.927447ms]
Jan 10 03:40:13.075: INFO: Got endpoints: latency-svc-kf5gp [216.160377ms]
Jan 10 03:40:13.087: INFO: Created: latency-svc-p7tmx
Jan 10 03:40:13.114: INFO: Got endpoints: latency-svc-p7tmx [235.764855ms]
Jan 10 03:40:13.247: INFO: Created: latency-svc-hzpb9
Jan 10 03:40:13.247: INFO: Created: latency-svc-qmhcx
Jan 10 03:40:13.250: INFO: Created: latency-svc-pw626
Jan 10 03:40:13.250: INFO: Created: latency-svc-z787j
Jan 10 03:40:13.250: INFO: Created: latency-svc-c8bb4
Jan 10 03:40:13.250: INFO: Created: latency-svc-pljjq
Jan 10 03:40:13.250: INFO: Created: latency-svc-db5m9
Jan 10 03:40:13.250: INFO: Created: latency-svc-czst6
Jan 10 03:40:13.250: INFO: Created: latency-svc-rm2pz
Jan 10 03:40:13.251: INFO: Created: latency-svc-psfb5
Jan 10 03:40:13.251: INFO: Created: latency-svc-9fvdh
Jan 10 03:40:13.251: INFO: Created: latency-svc-b8rm7
Jan 10 03:40:13.251: INFO: Created: latency-svc-5hf2k
Jan 10 03:40:13.251: INFO: Created: latency-svc-ns788
Jan 10 03:40:13.251: INFO: Created: latency-svc-mp5n6
Jan 10 03:40:13.308: INFO: Got endpoints: latency-svc-czst6 [420.083988ms]
Jan 10 03:40:13.308: INFO: Got endpoints: latency-svc-qmhcx [412.921507ms]
Jan 10 03:40:13.313: INFO: Got endpoints: latency-svc-9fvdh [315.729796ms]
Jan 10 03:40:13.333: INFO: Got endpoints: latency-svc-rm2pz [219.236828ms]
Jan 10 03:40:13.346: INFO: Created: latency-svc-f2v7v
Jan 10 03:40:13.361: INFO: Created: latency-svc-bvd8p
Jan 10 03:40:13.366: INFO: Got endpoints: latency-svc-psfb5 [449.211268ms]
Jan 10 03:40:13.374: INFO: Created: latency-svc-w2rvv
Jan 10 03:40:13.388: INFO: Created: latency-svc-cdhvz
Jan 10 03:40:13.400: INFO: Created: latency-svc-67jst
Jan 10 03:40:13.409: INFO: Got endpoints: latency-svc-b8rm7 [490.640781ms]
Jan 10 03:40:13.451: INFO: Created: latency-svc-crg95
Jan 10 03:40:13.469: INFO: Got endpoints: latency-svc-hzpb9 [562.776896ms]
Jan 10 03:40:13.488: INFO: Created: latency-svc-p624w
Jan 10 03:40:13.525: INFO: Got endpoints: latency-svc-mp5n6 [564.403981ms]
Jan 10 03:40:13.562: INFO: Created: latency-svc-t625d
Jan 10 03:40:13.570: INFO: Got endpoints: latency-svc-z787j [607.93525ms]
Jan 10 03:40:13.589: INFO: Created: latency-svc-dqpx9
Jan 10 03:40:13.622: INFO: Got endpoints: latency-svc-c8bb4 [659.83753ms]
Jan 10 03:40:13.644: INFO: Created: latency-svc-qz2gs
Jan 10 03:40:13.656: INFO: Got endpoints: latency-svc-ns788 [777.688667ms]
Jan 10 03:40:13.669: INFO: Created: latency-svc-wlcd4
Jan 10 03:40:13.710: INFO: Got endpoints: latency-svc-db5m9 [689.874831ms]
Jan 10 03:40:13.722: INFO: Created: latency-svc-4jlnl
Jan 10 03:40:13.758: INFO: Got endpoints: latency-svc-pljjq [697.004019ms]
Jan 10 03:40:13.773: INFO: Created: latency-svc-8hwpv
Jan 10 03:40:13.813: INFO: Got endpoints: latency-svc-5hf2k [737.447286ms]
Jan 10 03:40:13.823: INFO: Created: latency-svc-s8jmr
Jan 10 03:40:13.857: INFO: Got endpoints: latency-svc-pw626 [978.399429ms]
Jan 10 03:40:13.871: INFO: Created: latency-svc-7qlzb
Jan 10 03:40:13.907: INFO: Got endpoints: latency-svc-f2v7v [598.120123ms]
Jan 10 03:40:13.931: INFO: Created: latency-svc-55t2l
Jan 10 03:40:13.956: INFO: Got endpoints: latency-svc-bvd8p [647.819524ms]
Jan 10 03:40:13.968: INFO: Created: latency-svc-66pcg
Jan 10 03:40:14.009: INFO: Got endpoints: latency-svc-w2rvv [695.888695ms]
Jan 10 03:40:14.020: INFO: Created: latency-svc-6l5r9
Jan 10 03:40:14.055: INFO: Got endpoints: latency-svc-cdhvz [721.678496ms]
Jan 10 03:40:14.065: INFO: Created: latency-svc-nbvtl
Jan 10 03:40:14.109: INFO: Got endpoints: latency-svc-67jst [742.32715ms]
Jan 10 03:40:14.119: INFO: Created: latency-svc-5r8sn
Jan 10 03:40:14.160: INFO: Got endpoints: latency-svc-crg95 [750.467024ms]
Jan 10 03:40:14.170: INFO: Created: latency-svc-89lcp
Jan 10 03:40:14.212: INFO: Got endpoints: latency-svc-p624w [741.74153ms]
Jan 10 03:40:14.237: INFO: Created: latency-svc-xrxsp
Jan 10 03:40:14.256: INFO: Got endpoints: latency-svc-t625d [722.903066ms]
Jan 10 03:40:14.268: INFO: Created: latency-svc-t4sgx
Jan 10 03:40:14.315: INFO: Got endpoints: latency-svc-dqpx9 [745.781663ms]
Jan 10 03:40:14.346: INFO: Created: latency-svc-6sw8f
Jan 10 03:40:14.357: INFO: Got endpoints: latency-svc-qz2gs [735.154932ms]
Jan 10 03:40:14.387: INFO: Created: latency-svc-whxnl
Jan 10 03:40:14.419: INFO: Got endpoints: latency-svc-wlcd4 [762.120237ms]
Jan 10 03:40:14.436: INFO: Created: latency-svc-lcpbf
Jan 10 03:40:14.465: INFO: Got endpoints: latency-svc-4jlnl [755.342282ms]
Jan 10 03:40:14.483: INFO: Created: latency-svc-5xvf8
Jan 10 03:40:14.509: INFO: Got endpoints: latency-svc-8hwpv [751.443643ms]
Jan 10 03:40:14.528: INFO: Created: latency-svc-qz8g7
Jan 10 03:40:14.557: INFO: Got endpoints: latency-svc-s8jmr [743.603064ms]
Jan 10 03:40:14.582: INFO: Created: latency-svc-zxm58
Jan 10 03:40:14.612: INFO: Got endpoints: latency-svc-7qlzb [755.023568ms]
Jan 10 03:40:14.632: INFO: Created: latency-svc-22jk4
Jan 10 03:40:14.657: INFO: Got endpoints: latency-svc-55t2l [749.947934ms]
Jan 10 03:40:14.672: INFO: Created: latency-svc-mpmfr
Jan 10 03:40:14.714: INFO: Got endpoints: latency-svc-66pcg [757.16151ms]
Jan 10 03:40:14.724: INFO: Created: latency-svc-drw54
Jan 10 03:40:14.756: INFO: Got endpoints: latency-svc-6l5r9 [747.106508ms]
Jan 10 03:40:14.769: INFO: Created: latency-svc-ltnwc
Jan 10 03:40:14.809: INFO: Got endpoints: latency-svc-nbvtl [753.411469ms]
Jan 10 03:40:14.819: INFO: Created: latency-svc-mbs2d
Jan 10 03:40:14.856: INFO: Got endpoints: latency-svc-5r8sn [746.977081ms]
Jan 10 03:40:14.868: INFO: Created: latency-svc-4q7xb
Jan 10 03:40:14.910: INFO: Got endpoints: latency-svc-89lcp [750.659481ms]
Jan 10 03:40:14.932: INFO: Created: latency-svc-hrjwt
Jan 10 03:40:14.957: INFO: Got endpoints: latency-svc-xrxsp [744.295913ms]
Jan 10 03:40:14.966: INFO: Created: latency-svc-c5w2w
Jan 10 03:40:15.014: INFO: Got endpoints: latency-svc-t4sgx [757.2459ms]
Jan 10 03:40:15.024: INFO: Created: latency-svc-gb984
Jan 10 03:40:15.058: INFO: Got endpoints: latency-svc-6sw8f [742.702563ms]
Jan 10 03:40:15.068: INFO: Created: latency-svc-x5xb5
Jan 10 03:40:15.112: INFO: Got endpoints: latency-svc-whxnl [754.509685ms]
Jan 10 03:40:15.120: INFO: Created: latency-svc-q7n6s
Jan 10 03:40:15.158: INFO: Got endpoints: latency-svc-lcpbf [738.823894ms]
Jan 10 03:40:15.169: INFO: Created: latency-svc-v8wd7
Jan 10 03:40:15.209: INFO: Got endpoints: latency-svc-5xvf8 [743.369762ms]
Jan 10 03:40:15.217: INFO: Created: latency-svc-762rf
Jan 10 03:40:15.263: INFO: Got endpoints: latency-svc-qz8g7 [753.228282ms]
Jan 10 03:40:15.272: INFO: Created: latency-svc-67464
Jan 10 03:40:15.307: INFO: Got endpoints: latency-svc-zxm58 [749.409009ms]
Jan 10 03:40:15.317: INFO: Created: latency-svc-2scd6
Jan 10 03:40:15.360: INFO: Got endpoints: latency-svc-22jk4 [748.281188ms]
Jan 10 03:40:15.369: INFO: Created: latency-svc-9zlvh
Jan 10 03:40:15.413: INFO: Got endpoints: latency-svc-mpmfr [755.633433ms]
Jan 10 03:40:15.422: INFO: Created: latency-svc-lh9rf
Jan 10 03:40:15.462: INFO: Got endpoints: latency-svc-drw54 [748.495954ms]
Jan 10 03:40:15.473: INFO: Created: latency-svc-zlt69
Jan 10 03:40:15.507: INFO: Got endpoints: latency-svc-ltnwc [750.299801ms]
Jan 10 03:40:15.518: INFO: Created: latency-svc-bbdrz
Jan 10 03:40:15.560: INFO: Got endpoints: latency-svc-mbs2d [751.524828ms]
Jan 10 03:40:15.570: INFO: Created: latency-svc-bzl4n
Jan 10 03:40:15.609: INFO: Got endpoints: latency-svc-4q7xb [752.729339ms]
Jan 10 03:40:15.616: INFO: Created: latency-svc-w8vfk
Jan 10 03:40:15.657: INFO: Got endpoints: latency-svc-hrjwt [746.344488ms]
Jan 10 03:40:15.668: INFO: Created: latency-svc-d2vfs
Jan 10 03:40:15.714: INFO: Got endpoints: latency-svc-c5w2w [756.991889ms]
Jan 10 03:40:15.720: INFO: Created: latency-svc-vtzsj
Jan 10 03:40:15.759: INFO: Got endpoints: latency-svc-gb984 [745.492735ms]
Jan 10 03:40:15.767: INFO: Created: latency-svc-2v9c9
Jan 10 03:40:15.805: INFO: Got endpoints: latency-svc-x5xb5 [746.943039ms]
Jan 10 03:40:15.824: INFO: Created: latency-svc-wgk8m
Jan 10 03:40:15.859: INFO: Got endpoints: latency-svc-q7n6s [747.133688ms]
Jan 10 03:40:15.874: INFO: Created: latency-svc-s4lxk
Jan 10 03:40:15.907: INFO: Got endpoints: latency-svc-v8wd7 [749.337558ms]
Jan 10 03:40:15.924: INFO: Created: latency-svc-57ntj
Jan 10 03:40:15.963: INFO: Got endpoints: latency-svc-762rf [754.238194ms]
Jan 10 03:40:15.975: INFO: Created: latency-svc-7844m
Jan 10 03:40:16.008: INFO: Got endpoints: latency-svc-67464 [745.029417ms]
Jan 10 03:40:16.020: INFO: Created: latency-svc-q2xrh
Jan 10 03:40:16.056: INFO: Got endpoints: latency-svc-2scd6 [748.937472ms]
Jan 10 03:40:16.069: INFO: Created: latency-svc-7thpj
Jan 10 03:40:16.111: INFO: Got endpoints: latency-svc-9zlvh [751.16584ms]
Jan 10 03:40:16.123: INFO: Created: latency-svc-gmmc5
Jan 10 03:40:16.159: INFO: Got endpoints: latency-svc-lh9rf [746.131117ms]
Jan 10 03:40:16.182: INFO: Created: latency-svc-hnt6x
Jan 10 03:40:16.210: INFO: Got endpoints: latency-svc-zlt69 [747.446065ms]
Jan 10 03:40:16.222: INFO: Created: latency-svc-vwtqw
Jan 10 03:40:16.260: INFO: Got endpoints: latency-svc-bbdrz [753.114495ms]
Jan 10 03:40:16.270: INFO: Created: latency-svc-hqlgm
Jan 10 03:40:16.312: INFO: Got endpoints: latency-svc-bzl4n [751.158198ms]
Jan 10 03:40:16.320: INFO: Created: latency-svc-vffgt
Jan 10 03:40:16.361: INFO: Got endpoints: latency-svc-w8vfk [751.721789ms]
Jan 10 03:40:16.367: INFO: Created: latency-svc-hd6js
Jan 10 03:40:16.411: INFO: Got endpoints: latency-svc-d2vfs [754.055668ms]
Jan 10 03:40:16.421: INFO: Created: latency-svc-cbjtm
Jan 10 03:40:16.461: INFO: Got endpoints: latency-svc-vtzsj [747.581721ms]
Jan 10 03:40:16.469: INFO: Created: latency-svc-wldg5
Jan 10 03:40:16.516: INFO: Got endpoints: latency-svc-2v9c9 [756.8542ms]
Jan 10 03:40:16.524: INFO: Created: latency-svc-bj8sp
Jan 10 03:40:16.559: INFO: Got endpoints: latency-svc-wgk8m [753.658346ms]
Jan 10 03:40:16.570: INFO: Created: latency-svc-sxj27
Jan 10 03:40:16.610: INFO: Got endpoints: latency-svc-s4lxk [750.687666ms]
Jan 10 03:40:16.624: INFO: Created: latency-svc-mtlhs
Jan 10 03:40:16.657: INFO: Got endpoints: latency-svc-57ntj [749.838923ms]
Jan 10 03:40:16.669: INFO: Created: latency-svc-vf8p5
Jan 10 03:40:16.712: INFO: Got endpoints: latency-svc-7844m [748.057866ms]
Jan 10 03:40:16.720: INFO: Created: latency-svc-b5rnf
Jan 10 03:40:16.757: INFO: Got endpoints: latency-svc-q2xrh [748.434815ms]
Jan 10 03:40:16.766: INFO: Created: latency-svc-6hwl7
Jan 10 03:40:16.806: INFO: Got endpoints: latency-svc-7thpj [749.971304ms]
Jan 10 03:40:16.821: INFO: Created: latency-svc-4pcww
Jan 10 03:40:16.859: INFO: Got endpoints: latency-svc-gmmc5 [747.532741ms]
Jan 10 03:40:16.868: INFO: Created: latency-svc-246h9
Jan 10 03:40:16.912: INFO: Got endpoints: latency-svc-hnt6x [753.3358ms]
Jan 10 03:40:16.942: INFO: Created: latency-svc-8hwdw
Jan 10 03:40:16.960: INFO: Got endpoints: latency-svc-vwtqw [749.685697ms]
Jan 10 03:40:16.970: INFO: Created: latency-svc-gg86r
Jan 10 03:40:17.018: INFO: Got endpoints: latency-svc-hqlgm [757.867303ms]
Jan 10 03:40:17.035: INFO: Created: latency-svc-cb45v
Jan 10 03:40:17.057: INFO: Got endpoints: latency-svc-vffgt [745.08204ms]
Jan 10 03:40:17.066: INFO: Created: latency-svc-gf5cm
Jan 10 03:40:17.108: INFO: Got endpoints: latency-svc-hd6js [747.7191ms]
Jan 10 03:40:17.118: INFO: Created: latency-svc-8qzlw
Jan 10 03:40:17.159: INFO: Got endpoints: latency-svc-cbjtm [748.56603ms]
Jan 10 03:40:17.168: INFO: Created: latency-svc-hqj9r
Jan 10 03:40:17.209: INFO: Got endpoints: latency-svc-wldg5 [747.863462ms]
Jan 10 03:40:17.219: INFO: Created: latency-svc-7bnnp
Jan 10 03:40:17.261: INFO: Got endpoints: latency-svc-bj8sp [744.883119ms]
Jan 10 03:40:17.271: INFO: Created: latency-svc-4xn9d
Jan 10 03:40:17.309: INFO: Got endpoints: latency-svc-sxj27 [749.325707ms]
Jan 10 03:40:17.318: INFO: Created: latency-svc-96wnx
Jan 10 03:40:17.359: INFO: Got endpoints: latency-svc-mtlhs [749.083324ms]
Jan 10 03:40:17.368: INFO: Created: latency-svc-qwbzp
Jan 10 03:40:17.409: INFO: Got endpoints: latency-svc-vf8p5 [751.540056ms]
Jan 10 03:40:17.422: INFO: Created: latency-svc-5rslk
Jan 10 03:40:17.461: INFO: Got endpoints: latency-svc-b5rnf [748.928801ms]
Jan 10 03:40:17.468: INFO: Created: latency-svc-znpgz
Jan 10 03:40:17.506: INFO: Got endpoints: latency-svc-6hwl7 [749.422006ms]
Jan 10 03:40:17.525: INFO: Created: latency-svc-kj92f
Jan 10 03:40:17.564: INFO: Got endpoints: latency-svc-4pcww [758.231917ms]
Jan 10 03:40:17.576: INFO: Created: latency-svc-h84dn
Jan 10 03:40:17.612: INFO: Got endpoints: latency-svc-246h9 [752.751434ms]
Jan 10 03:40:17.622: INFO: Created: latency-svc-cn9c4
Jan 10 03:40:17.658: INFO: Got endpoints: latency-svc-8hwdw [745.023994ms]
Jan 10 03:40:17.667: INFO: Created: latency-svc-ggdrp
Jan 10 03:40:17.710: INFO: Got endpoints: latency-svc-gg86r [750.49864ms]
Jan 10 03:40:17.721: INFO: Created: latency-svc-zjxlr
Jan 10 03:40:17.761: INFO: Got endpoints: latency-svc-cb45v [743.219086ms]
Jan 10 03:40:17.776: INFO: Created: latency-svc-fpbjs
Jan 10 03:40:17.807: INFO: Got endpoints: latency-svc-gf5cm [749.141038ms]
Jan 10 03:40:17.817: INFO: Created: latency-svc-qqvd8
Jan 10 03:40:17.856: INFO: Got endpoints: latency-svc-8qzlw [748.042027ms]
Jan 10 03:40:17.869: INFO: Created: latency-svc-rgkz6
Jan 10 03:40:17.907: INFO: Got endpoints: latency-svc-hqj9r [747.199325ms]
Jan 10 03:40:17.935: INFO: Created: latency-svc-gzh6t
Jan 10 03:40:17.960: INFO: Got endpoints: latency-svc-7bnnp [750.851961ms]
Jan 10 03:40:17.972: INFO: Created: latency-svc-5ksfs
Jan 10 03:40:18.008: INFO: Got endpoints: latency-svc-4xn9d [746.320253ms]
Jan 10 03:40:18.022: INFO: Created: latency-svc-v6jvf
Jan 10 03:40:18.060: INFO: Got endpoints: latency-svc-96wnx [750.997305ms]
Jan 10 03:40:18.079: INFO: Created: latency-svc-h4clp
Jan 10 03:40:18.107: INFO: Got endpoints: latency-svc-qwbzp [747.353437ms]
Jan 10 03:40:18.130: INFO: Created: latency-svc-2btnb
Jan 10 03:40:18.157: INFO: Got endpoints: latency-svc-5rslk [747.917574ms]
Jan 10 03:40:18.170: INFO: Created: latency-svc-zhmxn
Jan 10 03:40:18.210: INFO: Got endpoints: latency-svc-znpgz [748.965585ms]
Jan 10 03:40:18.221: INFO: Created: latency-svc-rvjgt
Jan 10 03:40:18.261: INFO: Got endpoints: latency-svc-kj92f [754.874977ms]
Jan 10 03:40:18.268: INFO: Created: latency-svc-7zc8s
Jan 10 03:40:18.314: INFO: Got endpoints: latency-svc-h84dn [750.043313ms]
Jan 10 03:40:18.323: INFO: Created: latency-svc-4ghm8
Jan 10 03:40:18.359: INFO: Got endpoints: latency-svc-cn9c4 [746.561566ms]
Jan 10 03:40:18.369: INFO: Created: latency-svc-692wk
Jan 10 03:40:18.407: INFO: Got endpoints: latency-svc-ggdrp [748.748166ms]
Jan 10 03:40:18.416: INFO: Created: latency-svc-4tccw
Jan 10 03:40:18.457: INFO: Got endpoints: latency-svc-zjxlr [746.51199ms]
Jan 10 03:40:18.468: INFO: Created: latency-svc-q2qzr
Jan 10 03:40:18.508: INFO: Got endpoints: latency-svc-fpbjs [746.846365ms]
Jan 10 03:40:18.518: INFO: Created: latency-svc-n6gs7
Jan 10 03:40:18.561: INFO: Got endpoints: latency-svc-qqvd8 [754.224235ms]
Jan 10 03:40:18.569: INFO: Created: latency-svc-cg7ld
Jan 10 03:40:18.610: INFO: Got endpoints: latency-svc-rgkz6 [753.525559ms]
Jan 10 03:40:18.629: INFO: Created: latency-svc-xr8ts
Jan 10 03:40:18.659: INFO: Got endpoints: latency-svc-gzh6t [752.471532ms]
Jan 10 03:40:18.669: INFO: Created: latency-svc-vptrg
Jan 10 03:40:18.707: INFO: Got endpoints: latency-svc-5ksfs [746.360027ms]
Jan 10 03:40:18.717: INFO: Created: latency-svc-47crj
Jan 10 03:40:18.762: INFO: Got endpoints: latency-svc-v6jvf [753.742749ms]
Jan 10 03:40:18.770: INFO: Created: latency-svc-nrkw6
Jan 10 03:40:18.809: INFO: Got endpoints: latency-svc-h4clp [748.414782ms]
Jan 10 03:40:18.818: INFO: Created: latency-svc-w47pp
Jan 10 03:40:18.856: INFO: Got endpoints: latency-svc-2btnb [749.103888ms]
Jan 10 03:40:18.866: INFO: Created: latency-svc-rsbw8
Jan 10 03:40:18.912: INFO: Got endpoints: latency-svc-zhmxn [754.755396ms]
Jan 10 03:40:18.922: INFO: Created: latency-svc-j8ndg
Jan 10 03:40:18.961: INFO: Got endpoints: latency-svc-rvjgt [750.478787ms]
Jan 10 03:40:18.975: INFO: Created: latency-svc-bp78p
Jan 10 03:40:19.013: INFO: Got endpoints: latency-svc-7zc8s [751.530921ms]
Jan 10 03:40:19.023: INFO: Created: latency-svc-t6wz6
Jan 10 03:40:19.058: INFO: Got endpoints: latency-svc-4ghm8 [743.632981ms]
Jan 10 03:40:19.080: INFO: Created: latency-svc-mm4lv
Jan 10 03:40:19.107: INFO: Got endpoints: latency-svc-692wk [748.108062ms]
Jan 10 03:40:19.120: INFO: Created: latency-svc-kd6rs
Jan 10 03:40:19.157: INFO: Got endpoints: latency-svc-4tccw [750.058352ms]
Jan 10 03:40:19.166: INFO: Created: latency-svc-qv5l8
Jan 10 03:40:19.209: INFO: Got endpoints: latency-svc-q2qzr [751.516748ms]
Jan 10 03:40:19.217: INFO: Created: latency-svc-dnr5p
Jan 10 03:40:19.259: INFO: Got endpoints: latency-svc-n6gs7 [750.228075ms]
Jan 10 03:40:19.268: INFO: Created: latency-svc-rqlkv
Jan 10 03:40:19.308: INFO: Got endpoints: latency-svc-cg7ld [746.636998ms]
Jan 10 03:40:19.320: INFO: Created: latency-svc-xxtkw
Jan 10 03:40:19.357: INFO: Got endpoints: latency-svc-xr8ts [747.235785ms]
Jan 10 03:40:19.365: INFO: Created: latency-svc-99m57
Jan 10 03:40:19.407: INFO: Got endpoints: latency-svc-vptrg [747.25265ms]
Jan 10 03:40:19.420: INFO: Created: latency-svc-vj5hj
Jan 10 03:40:19.458: INFO: Got endpoints: latency-svc-47crj [750.366103ms]
Jan 10 03:40:19.468: INFO: Created: latency-svc-p6d2t
Jan 10 03:40:19.509: INFO: Got endpoints: latency-svc-nrkw6 [747.276538ms]
Jan 10 03:40:19.517: INFO: Created: latency-svc-vsltd
Jan 10 03:40:19.563: INFO: Got endpoints: latency-svc-w47pp [750.826552ms]
Jan 10 03:40:19.587: INFO: Created: latency-svc-4zjq8
Jan 10 03:40:19.615: INFO: Got endpoints: latency-svc-rsbw8 [758.435482ms]
Jan 10 03:40:19.639: INFO: Created: latency-svc-qxxtb
Jan 10 03:40:19.659: INFO: Got endpoints: latency-svc-j8ndg [746.810305ms]
Jan 10 03:40:19.679: INFO: Created: latency-svc-bqnrm
Jan 10 03:40:19.706: INFO: Got endpoints: latency-svc-bp78p [745.381319ms]
Jan 10 03:40:19.716: INFO: Created: latency-svc-dfb4n
Jan 10 03:40:19.757: INFO: Got endpoints: latency-svc-t6wz6 [743.97523ms]
Jan 10 03:40:19.773: INFO: Created: latency-svc-hwzw6
Jan 10 03:40:19.807: INFO: Got endpoints: latency-svc-mm4lv [748.886188ms]
Jan 10 03:40:19.817: INFO: Created: latency-svc-bmz66
Jan 10 03:40:19.857: INFO: Got endpoints: latency-svc-kd6rs [749.720937ms]
Jan 10 03:40:19.866: INFO: Created: latency-svc-s72zc
Jan 10 03:40:19.912: INFO: Got endpoints: latency-svc-qv5l8 [755.156042ms]
Jan 10 03:40:19.925: INFO: Created: latency-svc-jlk9b
Jan 10 03:40:19.960: INFO: Got endpoints: latency-svc-dnr5p [751.003667ms]
Jan 10 03:40:19.982: INFO: Created: latency-svc-zpg8b
Jan 10 03:40:20.012: INFO: Got endpoints: latency-svc-rqlkv [752.610593ms]
Jan 10 03:40:20.020: INFO: Created: latency-svc-9v4c8
Jan 10 03:40:20.065: INFO: Got endpoints: latency-svc-xxtkw [757.184319ms]
Jan 10 03:40:20.078: INFO: Created: latency-svc-hc5jp
Jan 10 03:40:20.114: INFO: Got endpoints: latency-svc-99m57 [756.278162ms]
Jan 10 03:40:20.129: INFO: Created: latency-svc-kmbgf
Jan 10 03:40:20.160: INFO: Got endpoints: latency-svc-vj5hj [752.890332ms]
Jan 10 03:40:20.181: INFO: Created: latency-svc-98lcv
Jan 10 03:40:20.210: INFO: Got endpoints: latency-svc-p6d2t [752.641057ms]
Jan 10 03:40:20.260: INFO: Got endpoints: latency-svc-vsltd [751.031316ms]
Jan 10 03:40:20.317: INFO: Got endpoints: latency-svc-4zjq8 [753.396483ms]
Jan 10 03:40:20.357: INFO: Got endpoints: latency-svc-qxxtb [741.65171ms]
Jan 10 03:40:20.414: INFO: Got endpoints: latency-svc-bqnrm [755.086611ms]
Jan 10 03:40:20.456: INFO: Got endpoints: latency-svc-dfb4n [747.58919ms]
Jan 10 03:40:20.509: INFO: Got endpoints: latency-svc-hwzw6 [751.860243ms]
Jan 10 03:40:20.570: INFO: Got endpoints: latency-svc-bmz66 [762.879845ms]
Jan 10 03:40:20.608: INFO: Got endpoints: latency-svc-s72zc [750.959428ms]
Jan 10 03:40:20.657: INFO: Got endpoints: latency-svc-jlk9b [744.212504ms]
Jan 10 03:40:20.711: INFO: Got endpoints: latency-svc-zpg8b [751.438791ms]
Jan 10 03:40:20.756: INFO: Got endpoints: latency-svc-9v4c8 [744.184481ms]
Jan 10 03:40:20.810: INFO: Got endpoints: latency-svc-hc5jp [745.133958ms]
Jan 10 03:40:20.859: INFO: Got endpoints: latency-svc-kmbgf [745.38533ms]
Jan 10 03:40:20.910: INFO: Got endpoints: latency-svc-98lcv [750.215795ms]
Jan 10 03:40:20.910: INFO: Latencies: [123.84794ms 131.456508ms 138.182371ms 140.031512ms 144.980221ms 150.698751ms 151.712159ms 151.990949ms 159.71262ms 182.478169ms 196.619271ms 201.927447ms 208.005684ms 212.711089ms 216.160377ms 219.236828ms 220.742092ms 223.69966ms 228.130343ms 228.913923ms 235.764855ms 257.742232ms 257.78936ms 258.267876ms 273.459437ms 303.986888ms 315.729796ms 332.617904ms 337.865052ms 370.282164ms 370.328277ms 412.921507ms 414.383802ms 420.083988ms 449.211268ms 490.640781ms 536.333183ms 539.523479ms 561.125563ms 562.776896ms 564.403981ms 566.632611ms 587.80244ms 588.531081ms 593.032855ms 593.098752ms 595.585506ms 598.120123ms 607.93525ms 615.206859ms 615.666002ms 619.837115ms 621.095412ms 625.348723ms 647.819524ms 659.83753ms 689.874831ms 695.888695ms 697.004019ms 721.678496ms 722.903066ms 735.154932ms 737.447286ms 738.823894ms 741.65171ms 741.74153ms 742.32715ms 742.702563ms 743.219086ms 743.369762ms 743.603064ms 743.632981ms 743.97523ms 744.184481ms 744.212504ms 744.295913ms 744.883119ms 745.023994ms 745.029417ms 745.08204ms 745.133958ms 745.381319ms 745.38533ms 745.492735ms 745.781663ms 746.131117ms 746.320253ms 746.344488ms 746.360027ms 746.51199ms 746.561566ms 746.636998ms 746.810305ms 746.846365ms 746.943039ms 746.977081ms 747.106508ms 747.133688ms 747.199325ms 747.235785ms 747.25265ms 747.276538ms 747.353437ms 747.446065ms 747.532741ms 747.581721ms 747.58919ms 747.7191ms 747.863462ms 747.917574ms 748.042027ms 748.057866ms 748.108062ms 748.281188ms 748.414782ms 748.434815ms 748.495954ms 748.56603ms 748.748166ms 748.886188ms 748.928801ms 748.937472ms 748.965585ms 749.083324ms 749.103888ms 749.141038ms 749.325707ms 749.337558ms 749.409009ms 749.422006ms 749.685697ms 749.720937ms 749.838923ms 749.947934ms 749.971304ms 750.043313ms 750.058352ms 750.215795ms 750.228075ms 750.299801ms 750.366103ms 750.467024ms 750.478787ms 750.49864ms 750.659481ms 750.687666ms 750.826552ms 750.851961ms 750.959428ms 750.997305ms 751.003667ms 751.031316ms 751.158198ms 751.16584ms 751.438791ms 751.443643ms 751.516748ms 751.524828ms 751.530921ms 751.540056ms 751.721789ms 751.860243ms 752.471532ms 752.610593ms 752.641057ms 752.729339ms 752.751434ms 752.890332ms 753.114495ms 753.228282ms 753.3358ms 753.396483ms 753.411469ms 753.525559ms 753.658346ms 753.742749ms 754.055668ms 754.224235ms 754.238194ms 754.509685ms 754.755396ms 754.874977ms 755.023568ms 755.086611ms 755.156042ms 755.342282ms 755.633433ms 756.278162ms 756.8542ms 756.991889ms 757.16151ms 757.184319ms 757.2459ms 757.867303ms 758.231917ms 758.435482ms 762.120237ms 762.879845ms 777.688667ms 978.399429ms]
Jan 10 03:40:20.910: INFO: 50 %ile: 747.25265ms
Jan 10 03:40:20.910: INFO: 90 %ile: 754.755396ms
Jan 10 03:40:20.910: INFO: 99 %ile: 777.688667ms
Jan 10 03:40:20.910: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Jan 10 03:40:20.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7558" for this suite. 01/10/23 03:40:20.917
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":23,"skipped":295,"failed":0}
------------------------------
• [SLOW TEST] [12.758 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:08.171
    Jan 10 03:40:08.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename svc-latency 01/10/23 03:40:08.179
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:08.586
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:08.616
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Jan 10 03:40:08.656: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-7558 01/10/23 03:40:08.659
    I0110 03:40:08.675430      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7558, replica count: 1
    I0110 03:40:09.726547      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0110 03:40:10.727747      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0110 03:40:11.728163      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 03:40:11.914: INFO: Created: latency-svc-trvmt
    Jan 10 03:40:11.953: INFO: Got endpoints: latency-svc-trvmt [124.451861ms]
    Jan 10 03:40:12.187: INFO: Created: latency-svc-nvg28
    Jan 10 03:40:12.291: INFO: Got endpoints: latency-svc-nvg28 [337.865052ms]
    Jan 10 03:40:12.456: INFO: Created: latency-svc-7zxr9
    Jan 10 03:40:12.478: INFO: Created: latency-svc-nrpc4
    Jan 10 03:40:12.480: INFO: Created: latency-svc-jx6j4
    Jan 10 03:40:12.480: INFO: Created: latency-svc-vgdlc
    Jan 10 03:40:12.480: INFO: Created: latency-svc-2gvsq
    Jan 10 03:40:12.480: INFO: Created: latency-svc-4xqfc
    Jan 10 03:40:12.480: INFO: Created: latency-svc-5wmd2
    Jan 10 03:40:12.480: INFO: Created: latency-svc-qtpzq
    Jan 10 03:40:12.481: INFO: Created: latency-svc-wk9sc
    Jan 10 03:40:12.481: INFO: Created: latency-svc-cv4sn
    Jan 10 03:40:12.481: INFO: Created: latency-svc-nqnqm
    Jan 10 03:40:12.481: INFO: Created: latency-svc-h6kln
    Jan 10 03:40:12.481: INFO: Created: latency-svc-f4nf6
    Jan 10 03:40:12.482: INFO: Created: latency-svc-jp6j4
    Jan 10 03:40:12.482: INFO: Created: latency-svc-sfnj5
    Jan 10 03:40:12.498: INFO: Got endpoints: latency-svc-7zxr9 [536.333183ms]
    Jan 10 03:40:12.498: INFO: Got endpoints: latency-svc-vgdlc [539.523479ms]
    Jan 10 03:40:12.499: INFO: Got endpoints: latency-svc-nrpc4 [208.005684ms]
    Jan 10 03:40:12.513: INFO: Created: latency-svc-lh4lg
    Jan 10 03:40:12.514: INFO: Got endpoints: latency-svc-sfnj5 [561.125563ms]
    Jan 10 03:40:12.520: INFO: Got endpoints: latency-svc-nqnqm [566.632611ms]
    Jan 10 03:40:12.543: INFO: Created: latency-svc-5mf8r
    Jan 10 03:40:12.546: INFO: Got endpoints: latency-svc-2gvsq [587.80244ms]
    Jan 10 03:40:12.546: INFO: Got endpoints: latency-svc-f4nf6 [593.032855ms]
    Jan 10 03:40:12.547: INFO: Got endpoints: latency-svc-5wmd2 [588.531081ms]
    Jan 10 03:40:12.547: INFO: Got endpoints: latency-svc-cv4sn [593.098752ms]
    Jan 10 03:40:12.549: INFO: Got endpoints: latency-svc-jp6j4 [595.585506ms]
    Jan 10 03:40:12.560: INFO: Created: latency-svc-4zmtm
    Jan 10 03:40:12.566: INFO: Created: latency-svc-tlpcg
    Jan 10 03:40:12.573: INFO: Got endpoints: latency-svc-4xqfc [615.206859ms]
    Jan 10 03:40:12.574: INFO: Got endpoints: latency-svc-jx6j4 [615.666002ms]
    Jan 10 03:40:12.578: INFO: Got endpoints: latency-svc-h6kln [619.837115ms]
    Jan 10 03:40:12.579: INFO: Got endpoints: latency-svc-qtpzq [621.095412ms]
    Jan 10 03:40:12.579: INFO: Got endpoints: latency-svc-wk9sc [625.348723ms]
    Jan 10 03:40:12.591: INFO: Created: latency-svc-8l6jl
    Jan 10 03:40:12.638: INFO: Got endpoints: latency-svc-lh4lg [140.031512ms]
    Jan 10 03:40:12.646: INFO: Got endpoints: latency-svc-tlpcg [131.456508ms]
    Jan 10 03:40:12.650: INFO: Got endpoints: latency-svc-4zmtm [150.698751ms]
    Jan 10 03:40:12.650: INFO: Got endpoints: latency-svc-5mf8r [151.990949ms]
    Jan 10 03:40:12.661: INFO: Created: latency-svc-qb5hq
    Jan 10 03:40:12.672: INFO: Got endpoints: latency-svc-8l6jl [151.712159ms]
    Jan 10 03:40:12.691: INFO: Got endpoints: latency-svc-qb5hq [144.980221ms]
    Jan 10 03:40:12.769: INFO: Created: latency-svc-gnbhj
    Jan 10 03:40:12.769: INFO: Created: latency-svc-vwkmm
    Jan 10 03:40:12.770: INFO: Created: latency-svc-bxjpx
    Jan 10 03:40:12.770: INFO: Created: latency-svc-qz8f7
    Jan 10 03:40:12.770: INFO: Created: latency-svc-2nhvx
    Jan 10 03:40:12.770: INFO: Created: latency-svc-b64jg
    Jan 10 03:40:12.770: INFO: Created: latency-svc-hb98x
    Jan 10 03:40:12.771: INFO: Created: latency-svc-vm8qx
    Jan 10 03:40:12.771: INFO: Created: latency-svc-k4w8t
    Jan 10 03:40:12.771: INFO: Created: latency-svc-p4zqs
    Jan 10 03:40:12.771: INFO: Created: latency-svc-jqpcl
    Jan 10 03:40:12.771: INFO: Created: latency-svc-pmnhv
    Jan 10 03:40:12.771: INFO: Created: latency-svc-dmbdq
    Jan 10 03:40:12.771: INFO: Created: latency-svc-s8skn
    Jan 10 03:40:12.772: INFO: Created: latency-svc-tlzpc
    Jan 10 03:40:12.823: INFO: Got endpoints: latency-svc-hb98x [273.459437ms]
    Jan 10 03:40:12.837: INFO: Got endpoints: latency-svc-pmnhv [258.267876ms]
    Jan 10 03:40:12.837: INFO: Got endpoints: latency-svc-dmbdq [257.78936ms]
    Jan 10 03:40:12.837: INFO: Got endpoints: latency-svc-jqpcl [257.742232ms]
    Jan 10 03:40:12.858: INFO: Got endpoints: latency-svc-vm8qx [220.742092ms]
    Jan 10 03:40:12.859: INFO: Got endpoints: latency-svc-p4zqs [212.711089ms]
    Jan 10 03:40:12.878: INFO: Got endpoints: latency-svc-bxjpx [228.130343ms]
    Jan 10 03:40:12.878: INFO: Got endpoints: latency-svc-vwkmm [303.986888ms]
    Jan 10 03:40:12.879: INFO: Got endpoints: latency-svc-gnbhj [228.913923ms]
    Jan 10 03:40:12.888: INFO: Got endpoints: latency-svc-k4w8t [196.619271ms]
    Jan 10 03:40:12.891: INFO: Created: latency-svc-5jrxb
    Jan 10 03:40:12.895: INFO: Got endpoints: latency-svc-2nhvx [223.69966ms]
    Jan 10 03:40:12.906: INFO: Got endpoints: latency-svc-b64jg [332.617904ms]
    Jan 10 03:40:12.914: INFO: Created: latency-svc-87cg6
    Jan 10 03:40:12.917: INFO: Got endpoints: latency-svc-s8skn [370.328277ms]
    Jan 10 03:40:12.917: INFO: Got endpoints: latency-svc-tlzpc [370.282164ms]
    Jan 10 03:40:12.961: INFO: Got endpoints: latency-svc-87cg6 [123.84794ms]
    Jan 10 03:40:12.961: INFO: Got endpoints: latency-svc-qz8f7 [414.383802ms]
    Jan 10 03:40:12.961: INFO: Got endpoints: latency-svc-5jrxb [138.182371ms]
    Jan 10 03:40:12.986: INFO: Created: latency-svc-mnjqq
    Jan 10 03:40:12.997: INFO: Got endpoints: latency-svc-mnjqq [159.71262ms]
    Jan 10 03:40:13.005: INFO: Created: latency-svc-v2cmm
    Jan 10 03:40:13.020: INFO: Got endpoints: latency-svc-v2cmm [182.478169ms]
    Jan 10 03:40:13.046: INFO: Created: latency-svc-mcztz
    Jan 10 03:40:13.058: INFO: Created: latency-svc-kf5gp
    Jan 10 03:40:13.061: INFO: Got endpoints: latency-svc-mcztz [201.927447ms]
    Jan 10 03:40:13.075: INFO: Got endpoints: latency-svc-kf5gp [216.160377ms]
    Jan 10 03:40:13.087: INFO: Created: latency-svc-p7tmx
    Jan 10 03:40:13.114: INFO: Got endpoints: latency-svc-p7tmx [235.764855ms]
    Jan 10 03:40:13.247: INFO: Created: latency-svc-hzpb9
    Jan 10 03:40:13.247: INFO: Created: latency-svc-qmhcx
    Jan 10 03:40:13.250: INFO: Created: latency-svc-pw626
    Jan 10 03:40:13.250: INFO: Created: latency-svc-z787j
    Jan 10 03:40:13.250: INFO: Created: latency-svc-c8bb4
    Jan 10 03:40:13.250: INFO: Created: latency-svc-pljjq
    Jan 10 03:40:13.250: INFO: Created: latency-svc-db5m9
    Jan 10 03:40:13.250: INFO: Created: latency-svc-czst6
    Jan 10 03:40:13.250: INFO: Created: latency-svc-rm2pz
    Jan 10 03:40:13.251: INFO: Created: latency-svc-psfb5
    Jan 10 03:40:13.251: INFO: Created: latency-svc-9fvdh
    Jan 10 03:40:13.251: INFO: Created: latency-svc-b8rm7
    Jan 10 03:40:13.251: INFO: Created: latency-svc-5hf2k
    Jan 10 03:40:13.251: INFO: Created: latency-svc-ns788
    Jan 10 03:40:13.251: INFO: Created: latency-svc-mp5n6
    Jan 10 03:40:13.308: INFO: Got endpoints: latency-svc-czst6 [420.083988ms]
    Jan 10 03:40:13.308: INFO: Got endpoints: latency-svc-qmhcx [412.921507ms]
    Jan 10 03:40:13.313: INFO: Got endpoints: latency-svc-9fvdh [315.729796ms]
    Jan 10 03:40:13.333: INFO: Got endpoints: latency-svc-rm2pz [219.236828ms]
    Jan 10 03:40:13.346: INFO: Created: latency-svc-f2v7v
    Jan 10 03:40:13.361: INFO: Created: latency-svc-bvd8p
    Jan 10 03:40:13.366: INFO: Got endpoints: latency-svc-psfb5 [449.211268ms]
    Jan 10 03:40:13.374: INFO: Created: latency-svc-w2rvv
    Jan 10 03:40:13.388: INFO: Created: latency-svc-cdhvz
    Jan 10 03:40:13.400: INFO: Created: latency-svc-67jst
    Jan 10 03:40:13.409: INFO: Got endpoints: latency-svc-b8rm7 [490.640781ms]
    Jan 10 03:40:13.451: INFO: Created: latency-svc-crg95
    Jan 10 03:40:13.469: INFO: Got endpoints: latency-svc-hzpb9 [562.776896ms]
    Jan 10 03:40:13.488: INFO: Created: latency-svc-p624w
    Jan 10 03:40:13.525: INFO: Got endpoints: latency-svc-mp5n6 [564.403981ms]
    Jan 10 03:40:13.562: INFO: Created: latency-svc-t625d
    Jan 10 03:40:13.570: INFO: Got endpoints: latency-svc-z787j [607.93525ms]
    Jan 10 03:40:13.589: INFO: Created: latency-svc-dqpx9
    Jan 10 03:40:13.622: INFO: Got endpoints: latency-svc-c8bb4 [659.83753ms]
    Jan 10 03:40:13.644: INFO: Created: latency-svc-qz2gs
    Jan 10 03:40:13.656: INFO: Got endpoints: latency-svc-ns788 [777.688667ms]
    Jan 10 03:40:13.669: INFO: Created: latency-svc-wlcd4
    Jan 10 03:40:13.710: INFO: Got endpoints: latency-svc-db5m9 [689.874831ms]
    Jan 10 03:40:13.722: INFO: Created: latency-svc-4jlnl
    Jan 10 03:40:13.758: INFO: Got endpoints: latency-svc-pljjq [697.004019ms]
    Jan 10 03:40:13.773: INFO: Created: latency-svc-8hwpv
    Jan 10 03:40:13.813: INFO: Got endpoints: latency-svc-5hf2k [737.447286ms]
    Jan 10 03:40:13.823: INFO: Created: latency-svc-s8jmr
    Jan 10 03:40:13.857: INFO: Got endpoints: latency-svc-pw626 [978.399429ms]
    Jan 10 03:40:13.871: INFO: Created: latency-svc-7qlzb
    Jan 10 03:40:13.907: INFO: Got endpoints: latency-svc-f2v7v [598.120123ms]
    Jan 10 03:40:13.931: INFO: Created: latency-svc-55t2l
    Jan 10 03:40:13.956: INFO: Got endpoints: latency-svc-bvd8p [647.819524ms]
    Jan 10 03:40:13.968: INFO: Created: latency-svc-66pcg
    Jan 10 03:40:14.009: INFO: Got endpoints: latency-svc-w2rvv [695.888695ms]
    Jan 10 03:40:14.020: INFO: Created: latency-svc-6l5r9
    Jan 10 03:40:14.055: INFO: Got endpoints: latency-svc-cdhvz [721.678496ms]
    Jan 10 03:40:14.065: INFO: Created: latency-svc-nbvtl
    Jan 10 03:40:14.109: INFO: Got endpoints: latency-svc-67jst [742.32715ms]
    Jan 10 03:40:14.119: INFO: Created: latency-svc-5r8sn
    Jan 10 03:40:14.160: INFO: Got endpoints: latency-svc-crg95 [750.467024ms]
    Jan 10 03:40:14.170: INFO: Created: latency-svc-89lcp
    Jan 10 03:40:14.212: INFO: Got endpoints: latency-svc-p624w [741.74153ms]
    Jan 10 03:40:14.237: INFO: Created: latency-svc-xrxsp
    Jan 10 03:40:14.256: INFO: Got endpoints: latency-svc-t625d [722.903066ms]
    Jan 10 03:40:14.268: INFO: Created: latency-svc-t4sgx
    Jan 10 03:40:14.315: INFO: Got endpoints: latency-svc-dqpx9 [745.781663ms]
    Jan 10 03:40:14.346: INFO: Created: latency-svc-6sw8f
    Jan 10 03:40:14.357: INFO: Got endpoints: latency-svc-qz2gs [735.154932ms]
    Jan 10 03:40:14.387: INFO: Created: latency-svc-whxnl
    Jan 10 03:40:14.419: INFO: Got endpoints: latency-svc-wlcd4 [762.120237ms]
    Jan 10 03:40:14.436: INFO: Created: latency-svc-lcpbf
    Jan 10 03:40:14.465: INFO: Got endpoints: latency-svc-4jlnl [755.342282ms]
    Jan 10 03:40:14.483: INFO: Created: latency-svc-5xvf8
    Jan 10 03:40:14.509: INFO: Got endpoints: latency-svc-8hwpv [751.443643ms]
    Jan 10 03:40:14.528: INFO: Created: latency-svc-qz8g7
    Jan 10 03:40:14.557: INFO: Got endpoints: latency-svc-s8jmr [743.603064ms]
    Jan 10 03:40:14.582: INFO: Created: latency-svc-zxm58
    Jan 10 03:40:14.612: INFO: Got endpoints: latency-svc-7qlzb [755.023568ms]
    Jan 10 03:40:14.632: INFO: Created: latency-svc-22jk4
    Jan 10 03:40:14.657: INFO: Got endpoints: latency-svc-55t2l [749.947934ms]
    Jan 10 03:40:14.672: INFO: Created: latency-svc-mpmfr
    Jan 10 03:40:14.714: INFO: Got endpoints: latency-svc-66pcg [757.16151ms]
    Jan 10 03:40:14.724: INFO: Created: latency-svc-drw54
    Jan 10 03:40:14.756: INFO: Got endpoints: latency-svc-6l5r9 [747.106508ms]
    Jan 10 03:40:14.769: INFO: Created: latency-svc-ltnwc
    Jan 10 03:40:14.809: INFO: Got endpoints: latency-svc-nbvtl [753.411469ms]
    Jan 10 03:40:14.819: INFO: Created: latency-svc-mbs2d
    Jan 10 03:40:14.856: INFO: Got endpoints: latency-svc-5r8sn [746.977081ms]
    Jan 10 03:40:14.868: INFO: Created: latency-svc-4q7xb
    Jan 10 03:40:14.910: INFO: Got endpoints: latency-svc-89lcp [750.659481ms]
    Jan 10 03:40:14.932: INFO: Created: latency-svc-hrjwt
    Jan 10 03:40:14.957: INFO: Got endpoints: latency-svc-xrxsp [744.295913ms]
    Jan 10 03:40:14.966: INFO: Created: latency-svc-c5w2w
    Jan 10 03:40:15.014: INFO: Got endpoints: latency-svc-t4sgx [757.2459ms]
    Jan 10 03:40:15.024: INFO: Created: latency-svc-gb984
    Jan 10 03:40:15.058: INFO: Got endpoints: latency-svc-6sw8f [742.702563ms]
    Jan 10 03:40:15.068: INFO: Created: latency-svc-x5xb5
    Jan 10 03:40:15.112: INFO: Got endpoints: latency-svc-whxnl [754.509685ms]
    Jan 10 03:40:15.120: INFO: Created: latency-svc-q7n6s
    Jan 10 03:40:15.158: INFO: Got endpoints: latency-svc-lcpbf [738.823894ms]
    Jan 10 03:40:15.169: INFO: Created: latency-svc-v8wd7
    Jan 10 03:40:15.209: INFO: Got endpoints: latency-svc-5xvf8 [743.369762ms]
    Jan 10 03:40:15.217: INFO: Created: latency-svc-762rf
    Jan 10 03:40:15.263: INFO: Got endpoints: latency-svc-qz8g7 [753.228282ms]
    Jan 10 03:40:15.272: INFO: Created: latency-svc-67464
    Jan 10 03:40:15.307: INFO: Got endpoints: latency-svc-zxm58 [749.409009ms]
    Jan 10 03:40:15.317: INFO: Created: latency-svc-2scd6
    Jan 10 03:40:15.360: INFO: Got endpoints: latency-svc-22jk4 [748.281188ms]
    Jan 10 03:40:15.369: INFO: Created: latency-svc-9zlvh
    Jan 10 03:40:15.413: INFO: Got endpoints: latency-svc-mpmfr [755.633433ms]
    Jan 10 03:40:15.422: INFO: Created: latency-svc-lh9rf
    Jan 10 03:40:15.462: INFO: Got endpoints: latency-svc-drw54 [748.495954ms]
    Jan 10 03:40:15.473: INFO: Created: latency-svc-zlt69
    Jan 10 03:40:15.507: INFO: Got endpoints: latency-svc-ltnwc [750.299801ms]
    Jan 10 03:40:15.518: INFO: Created: latency-svc-bbdrz
    Jan 10 03:40:15.560: INFO: Got endpoints: latency-svc-mbs2d [751.524828ms]
    Jan 10 03:40:15.570: INFO: Created: latency-svc-bzl4n
    Jan 10 03:40:15.609: INFO: Got endpoints: latency-svc-4q7xb [752.729339ms]
    Jan 10 03:40:15.616: INFO: Created: latency-svc-w8vfk
    Jan 10 03:40:15.657: INFO: Got endpoints: latency-svc-hrjwt [746.344488ms]
    Jan 10 03:40:15.668: INFO: Created: latency-svc-d2vfs
    Jan 10 03:40:15.714: INFO: Got endpoints: latency-svc-c5w2w [756.991889ms]
    Jan 10 03:40:15.720: INFO: Created: latency-svc-vtzsj
    Jan 10 03:40:15.759: INFO: Got endpoints: latency-svc-gb984 [745.492735ms]
    Jan 10 03:40:15.767: INFO: Created: latency-svc-2v9c9
    Jan 10 03:40:15.805: INFO: Got endpoints: latency-svc-x5xb5 [746.943039ms]
    Jan 10 03:40:15.824: INFO: Created: latency-svc-wgk8m
    Jan 10 03:40:15.859: INFO: Got endpoints: latency-svc-q7n6s [747.133688ms]
    Jan 10 03:40:15.874: INFO: Created: latency-svc-s4lxk
    Jan 10 03:40:15.907: INFO: Got endpoints: latency-svc-v8wd7 [749.337558ms]
    Jan 10 03:40:15.924: INFO: Created: latency-svc-57ntj
    Jan 10 03:40:15.963: INFO: Got endpoints: latency-svc-762rf [754.238194ms]
    Jan 10 03:40:15.975: INFO: Created: latency-svc-7844m
    Jan 10 03:40:16.008: INFO: Got endpoints: latency-svc-67464 [745.029417ms]
    Jan 10 03:40:16.020: INFO: Created: latency-svc-q2xrh
    Jan 10 03:40:16.056: INFO: Got endpoints: latency-svc-2scd6 [748.937472ms]
    Jan 10 03:40:16.069: INFO: Created: latency-svc-7thpj
    Jan 10 03:40:16.111: INFO: Got endpoints: latency-svc-9zlvh [751.16584ms]
    Jan 10 03:40:16.123: INFO: Created: latency-svc-gmmc5
    Jan 10 03:40:16.159: INFO: Got endpoints: latency-svc-lh9rf [746.131117ms]
    Jan 10 03:40:16.182: INFO: Created: latency-svc-hnt6x
    Jan 10 03:40:16.210: INFO: Got endpoints: latency-svc-zlt69 [747.446065ms]
    Jan 10 03:40:16.222: INFO: Created: latency-svc-vwtqw
    Jan 10 03:40:16.260: INFO: Got endpoints: latency-svc-bbdrz [753.114495ms]
    Jan 10 03:40:16.270: INFO: Created: latency-svc-hqlgm
    Jan 10 03:40:16.312: INFO: Got endpoints: latency-svc-bzl4n [751.158198ms]
    Jan 10 03:40:16.320: INFO: Created: latency-svc-vffgt
    Jan 10 03:40:16.361: INFO: Got endpoints: latency-svc-w8vfk [751.721789ms]
    Jan 10 03:40:16.367: INFO: Created: latency-svc-hd6js
    Jan 10 03:40:16.411: INFO: Got endpoints: latency-svc-d2vfs [754.055668ms]
    Jan 10 03:40:16.421: INFO: Created: latency-svc-cbjtm
    Jan 10 03:40:16.461: INFO: Got endpoints: latency-svc-vtzsj [747.581721ms]
    Jan 10 03:40:16.469: INFO: Created: latency-svc-wldg5
    Jan 10 03:40:16.516: INFO: Got endpoints: latency-svc-2v9c9 [756.8542ms]
    Jan 10 03:40:16.524: INFO: Created: latency-svc-bj8sp
    Jan 10 03:40:16.559: INFO: Got endpoints: latency-svc-wgk8m [753.658346ms]
    Jan 10 03:40:16.570: INFO: Created: latency-svc-sxj27
    Jan 10 03:40:16.610: INFO: Got endpoints: latency-svc-s4lxk [750.687666ms]
    Jan 10 03:40:16.624: INFO: Created: latency-svc-mtlhs
    Jan 10 03:40:16.657: INFO: Got endpoints: latency-svc-57ntj [749.838923ms]
    Jan 10 03:40:16.669: INFO: Created: latency-svc-vf8p5
    Jan 10 03:40:16.712: INFO: Got endpoints: latency-svc-7844m [748.057866ms]
    Jan 10 03:40:16.720: INFO: Created: latency-svc-b5rnf
    Jan 10 03:40:16.757: INFO: Got endpoints: latency-svc-q2xrh [748.434815ms]
    Jan 10 03:40:16.766: INFO: Created: latency-svc-6hwl7
    Jan 10 03:40:16.806: INFO: Got endpoints: latency-svc-7thpj [749.971304ms]
    Jan 10 03:40:16.821: INFO: Created: latency-svc-4pcww
    Jan 10 03:40:16.859: INFO: Got endpoints: latency-svc-gmmc5 [747.532741ms]
    Jan 10 03:40:16.868: INFO: Created: latency-svc-246h9
    Jan 10 03:40:16.912: INFO: Got endpoints: latency-svc-hnt6x [753.3358ms]
    Jan 10 03:40:16.942: INFO: Created: latency-svc-8hwdw
    Jan 10 03:40:16.960: INFO: Got endpoints: latency-svc-vwtqw [749.685697ms]
    Jan 10 03:40:16.970: INFO: Created: latency-svc-gg86r
    Jan 10 03:40:17.018: INFO: Got endpoints: latency-svc-hqlgm [757.867303ms]
    Jan 10 03:40:17.035: INFO: Created: latency-svc-cb45v
    Jan 10 03:40:17.057: INFO: Got endpoints: latency-svc-vffgt [745.08204ms]
    Jan 10 03:40:17.066: INFO: Created: latency-svc-gf5cm
    Jan 10 03:40:17.108: INFO: Got endpoints: latency-svc-hd6js [747.7191ms]
    Jan 10 03:40:17.118: INFO: Created: latency-svc-8qzlw
    Jan 10 03:40:17.159: INFO: Got endpoints: latency-svc-cbjtm [748.56603ms]
    Jan 10 03:40:17.168: INFO: Created: latency-svc-hqj9r
    Jan 10 03:40:17.209: INFO: Got endpoints: latency-svc-wldg5 [747.863462ms]
    Jan 10 03:40:17.219: INFO: Created: latency-svc-7bnnp
    Jan 10 03:40:17.261: INFO: Got endpoints: latency-svc-bj8sp [744.883119ms]
    Jan 10 03:40:17.271: INFO: Created: latency-svc-4xn9d
    Jan 10 03:40:17.309: INFO: Got endpoints: latency-svc-sxj27 [749.325707ms]
    Jan 10 03:40:17.318: INFO: Created: latency-svc-96wnx
    Jan 10 03:40:17.359: INFO: Got endpoints: latency-svc-mtlhs [749.083324ms]
    Jan 10 03:40:17.368: INFO: Created: latency-svc-qwbzp
    Jan 10 03:40:17.409: INFO: Got endpoints: latency-svc-vf8p5 [751.540056ms]
    Jan 10 03:40:17.422: INFO: Created: latency-svc-5rslk
    Jan 10 03:40:17.461: INFO: Got endpoints: latency-svc-b5rnf [748.928801ms]
    Jan 10 03:40:17.468: INFO: Created: latency-svc-znpgz
    Jan 10 03:40:17.506: INFO: Got endpoints: latency-svc-6hwl7 [749.422006ms]
    Jan 10 03:40:17.525: INFO: Created: latency-svc-kj92f
    Jan 10 03:40:17.564: INFO: Got endpoints: latency-svc-4pcww [758.231917ms]
    Jan 10 03:40:17.576: INFO: Created: latency-svc-h84dn
    Jan 10 03:40:17.612: INFO: Got endpoints: latency-svc-246h9 [752.751434ms]
    Jan 10 03:40:17.622: INFO: Created: latency-svc-cn9c4
    Jan 10 03:40:17.658: INFO: Got endpoints: latency-svc-8hwdw [745.023994ms]
    Jan 10 03:40:17.667: INFO: Created: latency-svc-ggdrp
    Jan 10 03:40:17.710: INFO: Got endpoints: latency-svc-gg86r [750.49864ms]
    Jan 10 03:40:17.721: INFO: Created: latency-svc-zjxlr
    Jan 10 03:40:17.761: INFO: Got endpoints: latency-svc-cb45v [743.219086ms]
    Jan 10 03:40:17.776: INFO: Created: latency-svc-fpbjs
    Jan 10 03:40:17.807: INFO: Got endpoints: latency-svc-gf5cm [749.141038ms]
    Jan 10 03:40:17.817: INFO: Created: latency-svc-qqvd8
    Jan 10 03:40:17.856: INFO: Got endpoints: latency-svc-8qzlw [748.042027ms]
    Jan 10 03:40:17.869: INFO: Created: latency-svc-rgkz6
    Jan 10 03:40:17.907: INFO: Got endpoints: latency-svc-hqj9r [747.199325ms]
    Jan 10 03:40:17.935: INFO: Created: latency-svc-gzh6t
    Jan 10 03:40:17.960: INFO: Got endpoints: latency-svc-7bnnp [750.851961ms]
    Jan 10 03:40:17.972: INFO: Created: latency-svc-5ksfs
    Jan 10 03:40:18.008: INFO: Got endpoints: latency-svc-4xn9d [746.320253ms]
    Jan 10 03:40:18.022: INFO: Created: latency-svc-v6jvf
    Jan 10 03:40:18.060: INFO: Got endpoints: latency-svc-96wnx [750.997305ms]
    Jan 10 03:40:18.079: INFO: Created: latency-svc-h4clp
    Jan 10 03:40:18.107: INFO: Got endpoints: latency-svc-qwbzp [747.353437ms]
    Jan 10 03:40:18.130: INFO: Created: latency-svc-2btnb
    Jan 10 03:40:18.157: INFO: Got endpoints: latency-svc-5rslk [747.917574ms]
    Jan 10 03:40:18.170: INFO: Created: latency-svc-zhmxn
    Jan 10 03:40:18.210: INFO: Got endpoints: latency-svc-znpgz [748.965585ms]
    Jan 10 03:40:18.221: INFO: Created: latency-svc-rvjgt
    Jan 10 03:40:18.261: INFO: Got endpoints: latency-svc-kj92f [754.874977ms]
    Jan 10 03:40:18.268: INFO: Created: latency-svc-7zc8s
    Jan 10 03:40:18.314: INFO: Got endpoints: latency-svc-h84dn [750.043313ms]
    Jan 10 03:40:18.323: INFO: Created: latency-svc-4ghm8
    Jan 10 03:40:18.359: INFO: Got endpoints: latency-svc-cn9c4 [746.561566ms]
    Jan 10 03:40:18.369: INFO: Created: latency-svc-692wk
    Jan 10 03:40:18.407: INFO: Got endpoints: latency-svc-ggdrp [748.748166ms]
    Jan 10 03:40:18.416: INFO: Created: latency-svc-4tccw
    Jan 10 03:40:18.457: INFO: Got endpoints: latency-svc-zjxlr [746.51199ms]
    Jan 10 03:40:18.468: INFO: Created: latency-svc-q2qzr
    Jan 10 03:40:18.508: INFO: Got endpoints: latency-svc-fpbjs [746.846365ms]
    Jan 10 03:40:18.518: INFO: Created: latency-svc-n6gs7
    Jan 10 03:40:18.561: INFO: Got endpoints: latency-svc-qqvd8 [754.224235ms]
    Jan 10 03:40:18.569: INFO: Created: latency-svc-cg7ld
    Jan 10 03:40:18.610: INFO: Got endpoints: latency-svc-rgkz6 [753.525559ms]
    Jan 10 03:40:18.629: INFO: Created: latency-svc-xr8ts
    Jan 10 03:40:18.659: INFO: Got endpoints: latency-svc-gzh6t [752.471532ms]
    Jan 10 03:40:18.669: INFO: Created: latency-svc-vptrg
    Jan 10 03:40:18.707: INFO: Got endpoints: latency-svc-5ksfs [746.360027ms]
    Jan 10 03:40:18.717: INFO: Created: latency-svc-47crj
    Jan 10 03:40:18.762: INFO: Got endpoints: latency-svc-v6jvf [753.742749ms]
    Jan 10 03:40:18.770: INFO: Created: latency-svc-nrkw6
    Jan 10 03:40:18.809: INFO: Got endpoints: latency-svc-h4clp [748.414782ms]
    Jan 10 03:40:18.818: INFO: Created: latency-svc-w47pp
    Jan 10 03:40:18.856: INFO: Got endpoints: latency-svc-2btnb [749.103888ms]
    Jan 10 03:40:18.866: INFO: Created: latency-svc-rsbw8
    Jan 10 03:40:18.912: INFO: Got endpoints: latency-svc-zhmxn [754.755396ms]
    Jan 10 03:40:18.922: INFO: Created: latency-svc-j8ndg
    Jan 10 03:40:18.961: INFO: Got endpoints: latency-svc-rvjgt [750.478787ms]
    Jan 10 03:40:18.975: INFO: Created: latency-svc-bp78p
    Jan 10 03:40:19.013: INFO: Got endpoints: latency-svc-7zc8s [751.530921ms]
    Jan 10 03:40:19.023: INFO: Created: latency-svc-t6wz6
    Jan 10 03:40:19.058: INFO: Got endpoints: latency-svc-4ghm8 [743.632981ms]
    Jan 10 03:40:19.080: INFO: Created: latency-svc-mm4lv
    Jan 10 03:40:19.107: INFO: Got endpoints: latency-svc-692wk [748.108062ms]
    Jan 10 03:40:19.120: INFO: Created: latency-svc-kd6rs
    Jan 10 03:40:19.157: INFO: Got endpoints: latency-svc-4tccw [750.058352ms]
    Jan 10 03:40:19.166: INFO: Created: latency-svc-qv5l8
    Jan 10 03:40:19.209: INFO: Got endpoints: latency-svc-q2qzr [751.516748ms]
    Jan 10 03:40:19.217: INFO: Created: latency-svc-dnr5p
    Jan 10 03:40:19.259: INFO: Got endpoints: latency-svc-n6gs7 [750.228075ms]
    Jan 10 03:40:19.268: INFO: Created: latency-svc-rqlkv
    Jan 10 03:40:19.308: INFO: Got endpoints: latency-svc-cg7ld [746.636998ms]
    Jan 10 03:40:19.320: INFO: Created: latency-svc-xxtkw
    Jan 10 03:40:19.357: INFO: Got endpoints: latency-svc-xr8ts [747.235785ms]
    Jan 10 03:40:19.365: INFO: Created: latency-svc-99m57
    Jan 10 03:40:19.407: INFO: Got endpoints: latency-svc-vptrg [747.25265ms]
    Jan 10 03:40:19.420: INFO: Created: latency-svc-vj5hj
    Jan 10 03:40:19.458: INFO: Got endpoints: latency-svc-47crj [750.366103ms]
    Jan 10 03:40:19.468: INFO: Created: latency-svc-p6d2t
    Jan 10 03:40:19.509: INFO: Got endpoints: latency-svc-nrkw6 [747.276538ms]
    Jan 10 03:40:19.517: INFO: Created: latency-svc-vsltd
    Jan 10 03:40:19.563: INFO: Got endpoints: latency-svc-w47pp [750.826552ms]
    Jan 10 03:40:19.587: INFO: Created: latency-svc-4zjq8
    Jan 10 03:40:19.615: INFO: Got endpoints: latency-svc-rsbw8 [758.435482ms]
    Jan 10 03:40:19.639: INFO: Created: latency-svc-qxxtb
    Jan 10 03:40:19.659: INFO: Got endpoints: latency-svc-j8ndg [746.810305ms]
    Jan 10 03:40:19.679: INFO: Created: latency-svc-bqnrm
    Jan 10 03:40:19.706: INFO: Got endpoints: latency-svc-bp78p [745.381319ms]
    Jan 10 03:40:19.716: INFO: Created: latency-svc-dfb4n
    Jan 10 03:40:19.757: INFO: Got endpoints: latency-svc-t6wz6 [743.97523ms]
    Jan 10 03:40:19.773: INFO: Created: latency-svc-hwzw6
    Jan 10 03:40:19.807: INFO: Got endpoints: latency-svc-mm4lv [748.886188ms]
    Jan 10 03:40:19.817: INFO: Created: latency-svc-bmz66
    Jan 10 03:40:19.857: INFO: Got endpoints: latency-svc-kd6rs [749.720937ms]
    Jan 10 03:40:19.866: INFO: Created: latency-svc-s72zc
    Jan 10 03:40:19.912: INFO: Got endpoints: latency-svc-qv5l8 [755.156042ms]
    Jan 10 03:40:19.925: INFO: Created: latency-svc-jlk9b
    Jan 10 03:40:19.960: INFO: Got endpoints: latency-svc-dnr5p [751.003667ms]
    Jan 10 03:40:19.982: INFO: Created: latency-svc-zpg8b
    Jan 10 03:40:20.012: INFO: Got endpoints: latency-svc-rqlkv [752.610593ms]
    Jan 10 03:40:20.020: INFO: Created: latency-svc-9v4c8
    Jan 10 03:40:20.065: INFO: Got endpoints: latency-svc-xxtkw [757.184319ms]
    Jan 10 03:40:20.078: INFO: Created: latency-svc-hc5jp
    Jan 10 03:40:20.114: INFO: Got endpoints: latency-svc-99m57 [756.278162ms]
    Jan 10 03:40:20.129: INFO: Created: latency-svc-kmbgf
    Jan 10 03:40:20.160: INFO: Got endpoints: latency-svc-vj5hj [752.890332ms]
    Jan 10 03:40:20.181: INFO: Created: latency-svc-98lcv
    Jan 10 03:40:20.210: INFO: Got endpoints: latency-svc-p6d2t [752.641057ms]
    Jan 10 03:40:20.260: INFO: Got endpoints: latency-svc-vsltd [751.031316ms]
    Jan 10 03:40:20.317: INFO: Got endpoints: latency-svc-4zjq8 [753.396483ms]
    Jan 10 03:40:20.357: INFO: Got endpoints: latency-svc-qxxtb [741.65171ms]
    Jan 10 03:40:20.414: INFO: Got endpoints: latency-svc-bqnrm [755.086611ms]
    Jan 10 03:40:20.456: INFO: Got endpoints: latency-svc-dfb4n [747.58919ms]
    Jan 10 03:40:20.509: INFO: Got endpoints: latency-svc-hwzw6 [751.860243ms]
    Jan 10 03:40:20.570: INFO: Got endpoints: latency-svc-bmz66 [762.879845ms]
    Jan 10 03:40:20.608: INFO: Got endpoints: latency-svc-s72zc [750.959428ms]
    Jan 10 03:40:20.657: INFO: Got endpoints: latency-svc-jlk9b [744.212504ms]
    Jan 10 03:40:20.711: INFO: Got endpoints: latency-svc-zpg8b [751.438791ms]
    Jan 10 03:40:20.756: INFO: Got endpoints: latency-svc-9v4c8 [744.184481ms]
    Jan 10 03:40:20.810: INFO: Got endpoints: latency-svc-hc5jp [745.133958ms]
    Jan 10 03:40:20.859: INFO: Got endpoints: latency-svc-kmbgf [745.38533ms]
    Jan 10 03:40:20.910: INFO: Got endpoints: latency-svc-98lcv [750.215795ms]
    Jan 10 03:40:20.910: INFO: Latencies: [123.84794ms 131.456508ms 138.182371ms 140.031512ms 144.980221ms 150.698751ms 151.712159ms 151.990949ms 159.71262ms 182.478169ms 196.619271ms 201.927447ms 208.005684ms 212.711089ms 216.160377ms 219.236828ms 220.742092ms 223.69966ms 228.130343ms 228.913923ms 235.764855ms 257.742232ms 257.78936ms 258.267876ms 273.459437ms 303.986888ms 315.729796ms 332.617904ms 337.865052ms 370.282164ms 370.328277ms 412.921507ms 414.383802ms 420.083988ms 449.211268ms 490.640781ms 536.333183ms 539.523479ms 561.125563ms 562.776896ms 564.403981ms 566.632611ms 587.80244ms 588.531081ms 593.032855ms 593.098752ms 595.585506ms 598.120123ms 607.93525ms 615.206859ms 615.666002ms 619.837115ms 621.095412ms 625.348723ms 647.819524ms 659.83753ms 689.874831ms 695.888695ms 697.004019ms 721.678496ms 722.903066ms 735.154932ms 737.447286ms 738.823894ms 741.65171ms 741.74153ms 742.32715ms 742.702563ms 743.219086ms 743.369762ms 743.603064ms 743.632981ms 743.97523ms 744.184481ms 744.212504ms 744.295913ms 744.883119ms 745.023994ms 745.029417ms 745.08204ms 745.133958ms 745.381319ms 745.38533ms 745.492735ms 745.781663ms 746.131117ms 746.320253ms 746.344488ms 746.360027ms 746.51199ms 746.561566ms 746.636998ms 746.810305ms 746.846365ms 746.943039ms 746.977081ms 747.106508ms 747.133688ms 747.199325ms 747.235785ms 747.25265ms 747.276538ms 747.353437ms 747.446065ms 747.532741ms 747.581721ms 747.58919ms 747.7191ms 747.863462ms 747.917574ms 748.042027ms 748.057866ms 748.108062ms 748.281188ms 748.414782ms 748.434815ms 748.495954ms 748.56603ms 748.748166ms 748.886188ms 748.928801ms 748.937472ms 748.965585ms 749.083324ms 749.103888ms 749.141038ms 749.325707ms 749.337558ms 749.409009ms 749.422006ms 749.685697ms 749.720937ms 749.838923ms 749.947934ms 749.971304ms 750.043313ms 750.058352ms 750.215795ms 750.228075ms 750.299801ms 750.366103ms 750.467024ms 750.478787ms 750.49864ms 750.659481ms 750.687666ms 750.826552ms 750.851961ms 750.959428ms 750.997305ms 751.003667ms 751.031316ms 751.158198ms 751.16584ms 751.438791ms 751.443643ms 751.516748ms 751.524828ms 751.530921ms 751.540056ms 751.721789ms 751.860243ms 752.471532ms 752.610593ms 752.641057ms 752.729339ms 752.751434ms 752.890332ms 753.114495ms 753.228282ms 753.3358ms 753.396483ms 753.411469ms 753.525559ms 753.658346ms 753.742749ms 754.055668ms 754.224235ms 754.238194ms 754.509685ms 754.755396ms 754.874977ms 755.023568ms 755.086611ms 755.156042ms 755.342282ms 755.633433ms 756.278162ms 756.8542ms 756.991889ms 757.16151ms 757.184319ms 757.2459ms 757.867303ms 758.231917ms 758.435482ms 762.120237ms 762.879845ms 777.688667ms 978.399429ms]
    Jan 10 03:40:20.910: INFO: 50 %ile: 747.25265ms
    Jan 10 03:40:20.910: INFO: 90 %ile: 754.755396ms
    Jan 10 03:40:20.910: INFO: 99 %ile: 777.688667ms
    Jan 10 03:40:20.910: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Jan 10 03:40:20.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-7558" for this suite. 01/10/23 03:40:20.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:20.93
Jan 10 03:40:20.930: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replicaset 01/10/23 03:40:20.931
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:20.972
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:20.976
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 01/10/23 03:40:21.001
STEP: Verify that the required pods have come up. 01/10/23 03:40:21.016
Jan 10 03:40:21.019: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 10 03:40:26.136: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/10/23 03:40:26.136
STEP: Getting /status 01/10/23 03:40:26.137
Jan 10 03:40:26.232: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 01/10/23 03:40:26.232
Jan 10 03:40:26.440: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 01/10/23 03:40:26.44
Jan 10 03:40:26.458: INFO: Observed &ReplicaSet event: ADDED
Jan 10 03:40:26.458: INFO: Observed &ReplicaSet event: MODIFIED
Jan 10 03:40:26.458: INFO: Observed &ReplicaSet event: MODIFIED
Jan 10 03:40:26.458: INFO: Observed &ReplicaSet event: MODIFIED
Jan 10 03:40:26.458: INFO: Found replicaset test-rs in namespace replicaset-211 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jan 10 03:40:26.458: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 01/10/23 03:40:26.458
Jan 10 03:40:26.458: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jan 10 03:40:26.517: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 01/10/23 03:40:26.517
Jan 10 03:40:26.523: INFO: Observed &ReplicaSet event: ADDED
Jan 10 03:40:26.523: INFO: Observed &ReplicaSet event: MODIFIED
Jan 10 03:40:26.523: INFO: Observed &ReplicaSet event: MODIFIED
Jan 10 03:40:26.523: INFO: Observed &ReplicaSet event: MODIFIED
Jan 10 03:40:26.523: INFO: Observed replicaset test-rs in namespace replicaset-211 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jan 10 03:40:26.524: INFO: Observed &ReplicaSet event: MODIFIED
Jan 10 03:40:26.524: INFO: Found replicaset test-rs in namespace replicaset-211 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Jan 10 03:40:26.524: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 10 03:40:26.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-211" for this suite. 01/10/23 03:40:26.534
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":24,"skipped":305,"failed":0}
------------------------------
• [SLOW TEST] [5.639 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:20.93
    Jan 10 03:40:20.930: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replicaset 01/10/23 03:40:20.931
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:20.972
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:20.976
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 01/10/23 03:40:21.001
    STEP: Verify that the required pods have come up. 01/10/23 03:40:21.016
    Jan 10 03:40:21.019: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jan 10 03:40:26.136: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/10/23 03:40:26.136
    STEP: Getting /status 01/10/23 03:40:26.137
    Jan 10 03:40:26.232: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 01/10/23 03:40:26.232
    Jan 10 03:40:26.440: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 01/10/23 03:40:26.44
    Jan 10 03:40:26.458: INFO: Observed &ReplicaSet event: ADDED
    Jan 10 03:40:26.458: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 10 03:40:26.458: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 10 03:40:26.458: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 10 03:40:26.458: INFO: Found replicaset test-rs in namespace replicaset-211 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jan 10 03:40:26.458: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 01/10/23 03:40:26.458
    Jan 10 03:40:26.458: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jan 10 03:40:26.517: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 01/10/23 03:40:26.517
    Jan 10 03:40:26.523: INFO: Observed &ReplicaSet event: ADDED
    Jan 10 03:40:26.523: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 10 03:40:26.523: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 10 03:40:26.523: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 10 03:40:26.523: INFO: Observed replicaset test-rs in namespace replicaset-211 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jan 10 03:40:26.524: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 10 03:40:26.524: INFO: Found replicaset test-rs in namespace replicaset-211 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Jan 10 03:40:26.524: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 10 03:40:26.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-211" for this suite. 01/10/23 03:40:26.534
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:26.577
Jan 10 03:40:26.577: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:40:26.578
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:26.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:26.781
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 01/10/23 03:40:26.797
Jan 10 03:40:26.847: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c" in namespace "projected-7963" to be "Succeeded or Failed"
Jan 10 03:40:26.861: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.810674ms
Jan 10 03:40:28.869: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021201908s
Jan 10 03:40:30.902: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055005999s
Jan 10 03:40:32.864: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016620542s
STEP: Saw pod success 01/10/23 03:40:32.864
Jan 10 03:40:32.864: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c" satisfied condition "Succeeded or Failed"
Jan 10 03:40:32.867: INFO: Trying to get logs from node cncf-wk3 pod downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c container client-container: <nil>
STEP: delete the pod 01/10/23 03:40:32.873
Jan 10 03:40:32.880: INFO: Waiting for pod downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c to disappear
Jan 10 03:40:32.888: INFO: Pod downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 03:40:32.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7963" for this suite. 01/10/23 03:40:32.894
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":25,"skipped":345,"failed":0}
------------------------------
• [SLOW TEST] [6.324 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:26.577
    Jan 10 03:40:26.577: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:40:26.578
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:26.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:26.781
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 01/10/23 03:40:26.797
    Jan 10 03:40:26.847: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c" in namespace "projected-7963" to be "Succeeded or Failed"
    Jan 10 03:40:26.861: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.810674ms
    Jan 10 03:40:28.869: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021201908s
    Jan 10 03:40:30.902: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055005999s
    Jan 10 03:40:32.864: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016620542s
    STEP: Saw pod success 01/10/23 03:40:32.864
    Jan 10 03:40:32.864: INFO: Pod "downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c" satisfied condition "Succeeded or Failed"
    Jan 10 03:40:32.867: INFO: Trying to get logs from node cncf-wk3 pod downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c container client-container: <nil>
    STEP: delete the pod 01/10/23 03:40:32.873
    Jan 10 03:40:32.880: INFO: Waiting for pod downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c to disappear
    Jan 10 03:40:32.888: INFO: Pod downwardapi-volume-5ba2b47a-1f90-4975-882d-fd8997b3716c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 03:40:32.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7963" for this suite. 01/10/23 03:40:32.894
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:32.905
Jan 10 03:40:32.905: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replicaset 01/10/23 03:40:32.906
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:32.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:32.961
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 01/10/23 03:40:32.966
Jan 10 03:40:32.977: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-4187" to be "running and ready"
Jan 10 03:40:32.988: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 11.075105ms
Jan 10 03:40:32.989: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:40:34.993: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.016170965s
Jan 10 03:40:34.993: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Jan 10 03:40:34.993: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 01/10/23 03:40:34.996
STEP: Then the orphan pod is adopted 01/10/23 03:40:35.017
STEP: When the matched label of one of its pods change 01/10/23 03:40:36.036
Jan 10 03:40:36.039: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 01/10/23 03:40:36.047
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 10 03:40:37.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4187" for this suite. 01/10/23 03:40:37.057
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":26,"skipped":398,"failed":0}
------------------------------
• [4.159 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:32.905
    Jan 10 03:40:32.905: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replicaset 01/10/23 03:40:32.906
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:32.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:32.961
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 01/10/23 03:40:32.966
    Jan 10 03:40:32.977: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-4187" to be "running and ready"
    Jan 10 03:40:32.988: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 11.075105ms
    Jan 10 03:40:32.989: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:40:34.993: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.016170965s
    Jan 10 03:40:34.993: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Jan 10 03:40:34.993: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 01/10/23 03:40:34.996
    STEP: Then the orphan pod is adopted 01/10/23 03:40:35.017
    STEP: When the matched label of one of its pods change 01/10/23 03:40:36.036
    Jan 10 03:40:36.039: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 01/10/23 03:40:36.047
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 10 03:40:37.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4187" for this suite. 01/10/23 03:40:37.057
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:37.066
Jan 10 03:40:37.067: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replication-controller 01/10/23 03:40:37.067
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:37.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:37.098
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5 01/10/23 03:40:37.106
Jan 10 03:40:37.119: INFO: Pod name my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5: Found 0 pods out of 1
Jan 10 03:40:42.129: INFO: Pod name my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5: Found 1 pods out of 1
Jan 10 03:40:42.129: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5" are running
Jan 10 03:40:42.129: INFO: Waiting up to 5m0s for pod "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f" in namespace "replication-controller-2048" to be "running"
Jan 10 03:40:42.144: INFO: Pod "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f": Phase="Running", Reason="", readiness=true. Elapsed: 15.642784ms
Jan 10 03:40:42.144: INFO: Pod "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f" satisfied condition "running"
Jan 10 03:40:42.144: INFO: Pod "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 03:40:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 03:40:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 03:40:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 03:40:37 +0000 UTC Reason: Message:}])
Jan 10 03:40:42.145: INFO: Trying to dial the pod
Jan 10 03:40:47.155: INFO: Controller my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5: Got expected result from replica 1 [my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f]: "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 10 03:40:47.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2048" for this suite. 01/10/23 03:40:47.158
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":27,"skipped":427,"failed":0}
------------------------------
• [SLOW TEST] [10.103 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:37.066
    Jan 10 03:40:37.067: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replication-controller 01/10/23 03:40:37.067
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:37.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:37.098
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5 01/10/23 03:40:37.106
    Jan 10 03:40:37.119: INFO: Pod name my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5: Found 0 pods out of 1
    Jan 10 03:40:42.129: INFO: Pod name my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5: Found 1 pods out of 1
    Jan 10 03:40:42.129: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5" are running
    Jan 10 03:40:42.129: INFO: Waiting up to 5m0s for pod "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f" in namespace "replication-controller-2048" to be "running"
    Jan 10 03:40:42.144: INFO: Pod "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f": Phase="Running", Reason="", readiness=true. Elapsed: 15.642784ms
    Jan 10 03:40:42.144: INFO: Pod "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f" satisfied condition "running"
    Jan 10 03:40:42.144: INFO: Pod "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 03:40:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 03:40:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 03:40:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 03:40:37 +0000 UTC Reason: Message:}])
    Jan 10 03:40:42.145: INFO: Trying to dial the pod
    Jan 10 03:40:47.155: INFO: Controller my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5: Got expected result from replica 1 [my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f]: "my-hostname-basic-2adbf70c-61d4-4c1e-a5a6-9d68a57958c5-vsm7f", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 10 03:40:47.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2048" for this suite. 01/10/23 03:40:47.158
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:47.171
Jan 10 03:40:47.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 03:40:47.172
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:47.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:47.257
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 01/10/23 03:40:47.273
Jan 10 03:40:47.306: INFO: Waiting up to 5m0s for pod "pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d" in namespace "pods-2007" to be "running and ready"
Jan 10 03:40:47.339: INFO: Pod "pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d": Phase="Pending", Reason="", readiness=false. Elapsed: 32.527328ms
Jan 10 03:40:47.339: INFO: The phase of Pod pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:40:49.342: INFO: Pod "pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d": Phase="Running", Reason="", readiness=true. Elapsed: 2.035696065s
Jan 10 03:40:49.342: INFO: The phase of Pod pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d is Running (Ready = true)
Jan 10 03:40:49.342: INFO: Pod "pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d" satisfied condition "running and ready"
Jan 10 03:40:49.346: INFO: Pod pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d has hostIP: 172.31.3.44
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 03:40:49.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2007" for this suite. 01/10/23 03:40:49.349
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":28,"skipped":427,"failed":0}
------------------------------
• [2.184 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:47.171
    Jan 10 03:40:47.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 03:40:47.172
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:47.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:47.257
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 01/10/23 03:40:47.273
    Jan 10 03:40:47.306: INFO: Waiting up to 5m0s for pod "pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d" in namespace "pods-2007" to be "running and ready"
    Jan 10 03:40:47.339: INFO: Pod "pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d": Phase="Pending", Reason="", readiness=false. Elapsed: 32.527328ms
    Jan 10 03:40:47.339: INFO: The phase of Pod pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:40:49.342: INFO: Pod "pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d": Phase="Running", Reason="", readiness=true. Elapsed: 2.035696065s
    Jan 10 03:40:49.342: INFO: The phase of Pod pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d is Running (Ready = true)
    Jan 10 03:40:49.342: INFO: Pod "pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d" satisfied condition "running and ready"
    Jan 10 03:40:49.346: INFO: Pod pod-hostip-f786b6de-24ed-416a-8a98-fd5c264fe21d has hostIP: 172.31.3.44
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 03:40:49.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2007" for this suite. 01/10/23 03:40:49.349
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:40:49.356
Jan 10 03:40:49.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 03:40:49.357
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:49.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:49.384
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 01/10/23 03:40:49.388
Jan 10 03:40:49.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: mark a version not serverd 01/10/23 03:40:59.276
STEP: check the unserved version gets removed 01/10/23 03:40:59.326
STEP: check the other version is not changed 01/10/23 03:41:03.784
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:41:11.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6391" for this suite. 01/10/23 03:41:11.028
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":29,"skipped":431,"failed":0}
------------------------------
• [SLOW TEST] [21.678 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:40:49.356
    Jan 10 03:40:49.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 03:40:49.357
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:40:49.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:40:49.384
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 01/10/23 03:40:49.388
    Jan 10 03:40:49.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: mark a version not serverd 01/10/23 03:40:59.276
    STEP: check the unserved version gets removed 01/10/23 03:40:59.326
    STEP: check the other version is not changed 01/10/23 03:41:03.784
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:41:11.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6391" for this suite. 01/10/23 03:41:11.028
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:11.042
Jan 10 03:41:11.043: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename cronjob 01/10/23 03:41:11.043
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:11.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:11.082
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 01/10/23 03:41:11.084
STEP: creating 01/10/23 03:41:11.085
STEP: getting 01/10/23 03:41:11.088
STEP: listing 01/10/23 03:41:11.091
STEP: watching 01/10/23 03:41:11.095
Jan 10 03:41:11.096: INFO: starting watch
STEP: cluster-wide listing 01/10/23 03:41:11.097
STEP: cluster-wide watching 01/10/23 03:41:11.101
Jan 10 03:41:11.101: INFO: starting watch
STEP: patching 01/10/23 03:41:11.107
STEP: updating 01/10/23 03:41:11.118
Jan 10 03:41:11.134: INFO: waiting for watch events with expected annotations
Jan 10 03:41:11.134: INFO: saw patched and updated annotations
STEP: patching /status 01/10/23 03:41:11.135
STEP: updating /status 01/10/23 03:41:11.142
STEP: get /status 01/10/23 03:41:11.148
STEP: deleting 01/10/23 03:41:11.15
STEP: deleting a collection 01/10/23 03:41:11.161
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 10 03:41:11.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2124" for this suite. 01/10/23 03:41:11.172
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":30,"skipped":461,"failed":0}
------------------------------
• [0.139 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:11.042
    Jan 10 03:41:11.043: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename cronjob 01/10/23 03:41:11.043
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:11.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:11.082
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 01/10/23 03:41:11.084
    STEP: creating 01/10/23 03:41:11.085
    STEP: getting 01/10/23 03:41:11.088
    STEP: listing 01/10/23 03:41:11.091
    STEP: watching 01/10/23 03:41:11.095
    Jan 10 03:41:11.096: INFO: starting watch
    STEP: cluster-wide listing 01/10/23 03:41:11.097
    STEP: cluster-wide watching 01/10/23 03:41:11.101
    Jan 10 03:41:11.101: INFO: starting watch
    STEP: patching 01/10/23 03:41:11.107
    STEP: updating 01/10/23 03:41:11.118
    Jan 10 03:41:11.134: INFO: waiting for watch events with expected annotations
    Jan 10 03:41:11.134: INFO: saw patched and updated annotations
    STEP: patching /status 01/10/23 03:41:11.135
    STEP: updating /status 01/10/23 03:41:11.142
    STEP: get /status 01/10/23 03:41:11.148
    STEP: deleting 01/10/23 03:41:11.15
    STEP: deleting a collection 01/10/23 03:41:11.161
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 10 03:41:11.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2124" for this suite. 01/10/23 03:41:11.172
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:11.184
Jan 10 03:41:11.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 03:41:11.186
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:11.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:11.222
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-08567a4d-095d-4c8f-b04e-edcda24dc062 01/10/23 03:41:11.231
STEP: Creating the pod 01/10/23 03:41:11.237
Jan 10 03:41:11.245: INFO: Waiting up to 5m0s for pod "pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c" in namespace "configmap-807" to be "running and ready"
Jan 10 03:41:11.252: INFO: Pod "pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.810594ms
Jan 10 03:41:11.252: INFO: The phase of Pod pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:41:13.256: INFO: Pod "pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.010492292s
Jan 10 03:41:13.256: INFO: The phase of Pod pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c is Running (Ready = true)
Jan 10 03:41:13.256: INFO: Pod "pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-08567a4d-095d-4c8f-b04e-edcda24dc062 01/10/23 03:41:13.274
STEP: waiting to observe update in volume 01/10/23 03:41:13.279
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 03:41:15.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-807" for this suite. 01/10/23 03:41:15.296
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":31,"skipped":465,"failed":0}
------------------------------
• [4.116 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:11.184
    Jan 10 03:41:11.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 03:41:11.186
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:11.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:11.222
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-08567a4d-095d-4c8f-b04e-edcda24dc062 01/10/23 03:41:11.231
    STEP: Creating the pod 01/10/23 03:41:11.237
    Jan 10 03:41:11.245: INFO: Waiting up to 5m0s for pod "pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c" in namespace "configmap-807" to be "running and ready"
    Jan 10 03:41:11.252: INFO: Pod "pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.810594ms
    Jan 10 03:41:11.252: INFO: The phase of Pod pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:41:13.256: INFO: Pod "pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.010492292s
    Jan 10 03:41:13.256: INFO: The phase of Pod pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c is Running (Ready = true)
    Jan 10 03:41:13.256: INFO: Pod "pod-configmaps-7fa1042f-8552-437e-b613-ed6a43ba2a6c" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-08567a4d-095d-4c8f-b04e-edcda24dc062 01/10/23 03:41:13.274
    STEP: waiting to observe update in volume 01/10/23 03:41:13.279
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 03:41:15.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-807" for this suite. 01/10/23 03:41:15.296
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:15.304
Jan 10 03:41:15.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 03:41:15.305
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:15.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:15.338
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 01/10/23 03:41:15.342
Jan 10 03:41:15.363: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0" in namespace "downward-api-5891" to be "Succeeded or Failed"
Jan 10 03:41:15.383: INFO: Pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0": Phase="Pending", Reason="", readiness=false. Elapsed: 19.641988ms
Jan 10 03:41:17.388: INFO: Pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024666868s
Jan 10 03:41:19.388: INFO: Pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025430512s
STEP: Saw pod success 01/10/23 03:41:19.389
Jan 10 03:41:19.389: INFO: Pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0" satisfied condition "Succeeded or Failed"
Jan 10 03:41:19.391: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0 container client-container: <nil>
STEP: delete the pod 01/10/23 03:41:19.397
Jan 10 03:41:19.422: INFO: Waiting for pod downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0 to disappear
Jan 10 03:41:19.426: INFO: Pod downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 03:41:19.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5891" for this suite. 01/10/23 03:41:19.43
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":32,"skipped":465,"failed":0}
------------------------------
• [4.131 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:15.304
    Jan 10 03:41:15.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 03:41:15.305
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:15.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:15.338
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 01/10/23 03:41:15.342
    Jan 10 03:41:15.363: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0" in namespace "downward-api-5891" to be "Succeeded or Failed"
    Jan 10 03:41:15.383: INFO: Pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0": Phase="Pending", Reason="", readiness=false. Elapsed: 19.641988ms
    Jan 10 03:41:17.388: INFO: Pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024666868s
    Jan 10 03:41:19.388: INFO: Pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025430512s
    STEP: Saw pod success 01/10/23 03:41:19.389
    Jan 10 03:41:19.389: INFO: Pod "downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0" satisfied condition "Succeeded or Failed"
    Jan 10 03:41:19.391: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0 container client-container: <nil>
    STEP: delete the pod 01/10/23 03:41:19.397
    Jan 10 03:41:19.422: INFO: Waiting for pod downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0 to disappear
    Jan 10 03:41:19.426: INFO: Pod downwardapi-volume-bb2ed7a1-32b7-44e8-a7a6-4636eb01efd0 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 03:41:19.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5891" for this suite. 01/10/23 03:41:19.43
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:19.441
Jan 10 03:41:19.441: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename var-expansion 01/10/23 03:41:19.442
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:19.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:19.479
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Jan 10 03:41:19.492: INFO: Waiting up to 2m0s for pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619" in namespace "var-expansion-1994" to be "container 0 failed with reason CreateContainerConfigError"
Jan 10 03:41:19.508: INFO: Pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619": Phase="Pending", Reason="", readiness=false. Elapsed: 15.763191ms
Jan 10 03:41:21.513: INFO: Pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020318997s
Jan 10 03:41:21.513: INFO: Pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Jan 10 03:41:21.513: INFO: Deleting pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619" in namespace "var-expansion-1994"
Jan 10 03:41:21.518: INFO: Wait up to 5m0s for pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 10 03:41:25.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1994" for this suite. 01/10/23 03:41:25.532
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":33,"skipped":498,"failed":0}
------------------------------
• [SLOW TEST] [6.103 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:19.441
    Jan 10 03:41:19.441: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename var-expansion 01/10/23 03:41:19.442
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:19.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:19.479
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Jan 10 03:41:19.492: INFO: Waiting up to 2m0s for pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619" in namespace "var-expansion-1994" to be "container 0 failed with reason CreateContainerConfigError"
    Jan 10 03:41:19.508: INFO: Pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619": Phase="Pending", Reason="", readiness=false. Elapsed: 15.763191ms
    Jan 10 03:41:21.513: INFO: Pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020318997s
    Jan 10 03:41:21.513: INFO: Pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Jan 10 03:41:21.513: INFO: Deleting pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619" in namespace "var-expansion-1994"
    Jan 10 03:41:21.518: INFO: Wait up to 5m0s for pod "var-expansion-72d418fa-99c5-4c09-b750-157df1743619" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 10 03:41:25.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1994" for this suite. 01/10/23 03:41:25.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:25.55
Jan 10 03:41:25.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 03:41:25.551
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:25.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:25.582
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 01/10/23 03:41:25.624
Jan 10 03:41:25.636: INFO: Waiting up to 5m0s for pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3" in namespace "downward-api-9333" to be "running and ready"
Jan 10 03:41:25.658: INFO: Pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3": Phase="Pending", Reason="", readiness=false. Elapsed: 21.775665ms
Jan 10 03:41:25.658: INFO: The phase of Pod annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:41:27.662: INFO: Pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.026337626s
Jan 10 03:41:27.662: INFO: The phase of Pod annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3 is Running (Ready = true)
Jan 10 03:41:27.662: INFO: Pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3" satisfied condition "running and ready"
Jan 10 03:41:28.182: INFO: Successfully updated pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 03:41:32.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9333" for this suite. 01/10/23 03:41:32.211
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":34,"skipped":515,"failed":0}
------------------------------
• [SLOW TEST] [6.667 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:25.55
    Jan 10 03:41:25.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 03:41:25.551
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:25.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:25.582
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 01/10/23 03:41:25.624
    Jan 10 03:41:25.636: INFO: Waiting up to 5m0s for pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3" in namespace "downward-api-9333" to be "running and ready"
    Jan 10 03:41:25.658: INFO: Pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3": Phase="Pending", Reason="", readiness=false. Elapsed: 21.775665ms
    Jan 10 03:41:25.658: INFO: The phase of Pod annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:41:27.662: INFO: Pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.026337626s
    Jan 10 03:41:27.662: INFO: The phase of Pod annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3 is Running (Ready = true)
    Jan 10 03:41:27.662: INFO: Pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3" satisfied condition "running and ready"
    Jan 10 03:41:28.182: INFO: Successfully updated pod "annotationupdate618d8623-37ba-4fe9-87c6-c2cadef4b4e3"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 03:41:32.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9333" for this suite. 01/10/23 03:41:32.211
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:32.22
Jan 10 03:41:32.220: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 03:41:32.221
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:32.249
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:32.255
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/10/23 03:41:32.258
Jan 10 03:41:32.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6177 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Jan 10 03:41:32.385: INFO: stderr: ""
Jan 10 03:41:32.385: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 01/10/23 03:41:32.385
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Jan 10 03:41:32.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6177 delete pods e2e-test-httpd-pod'
Jan 10 03:41:34.673: INFO: stderr: ""
Jan 10 03:41:34.673: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 03:41:34.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6177" for this suite. 01/10/23 03:41:34.678
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":35,"skipped":546,"failed":0}
------------------------------
• [2.463 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:32.22
    Jan 10 03:41:32.220: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 03:41:32.221
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:32.249
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:32.255
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/10/23 03:41:32.258
    Jan 10 03:41:32.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6177 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Jan 10 03:41:32.385: INFO: stderr: ""
    Jan 10 03:41:32.385: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 01/10/23 03:41:32.385
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Jan 10 03:41:32.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6177 delete pods e2e-test-httpd-pod'
    Jan 10 03:41:34.673: INFO: stderr: ""
    Jan 10 03:41:34.673: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 03:41:34.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6177" for this suite. 01/10/23 03:41:34.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:34.684
Jan 10 03:41:34.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename containers 01/10/23 03:41:34.685
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:34.723
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:34.727
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 01/10/23 03:41:34.735
Jan 10 03:41:34.752: INFO: Waiting up to 5m0s for pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b" in namespace "containers-4238" to be "Succeeded or Failed"
Jan 10 03:41:34.762: INFO: Pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.642926ms
Jan 10 03:41:36.765: INFO: Pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012972239s
Jan 10 03:41:38.767: INFO: Pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01461426s
STEP: Saw pod success 01/10/23 03:41:38.767
Jan 10 03:41:38.768: INFO: Pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b" satisfied condition "Succeeded or Failed"
Jan 10 03:41:38.773: INFO: Trying to get logs from node cncf-wk2 pod client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b container agnhost-container: <nil>
STEP: delete the pod 01/10/23 03:41:38.781
Jan 10 03:41:38.794: INFO: Waiting for pod client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b to disappear
Jan 10 03:41:38.797: INFO: Pod client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jan 10 03:41:38.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4238" for this suite. 01/10/23 03:41:38.801
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":36,"skipped":578,"failed":0}
------------------------------
• [4.122 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:34.684
    Jan 10 03:41:34.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename containers 01/10/23 03:41:34.685
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:34.723
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:34.727
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 01/10/23 03:41:34.735
    Jan 10 03:41:34.752: INFO: Waiting up to 5m0s for pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b" in namespace "containers-4238" to be "Succeeded or Failed"
    Jan 10 03:41:34.762: INFO: Pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.642926ms
    Jan 10 03:41:36.765: INFO: Pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012972239s
    Jan 10 03:41:38.767: INFO: Pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01461426s
    STEP: Saw pod success 01/10/23 03:41:38.767
    Jan 10 03:41:38.768: INFO: Pod "client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b" satisfied condition "Succeeded or Failed"
    Jan 10 03:41:38.773: INFO: Trying to get logs from node cncf-wk2 pod client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 03:41:38.781
    Jan 10 03:41:38.794: INFO: Waiting for pod client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b to disappear
    Jan 10 03:41:38.797: INFO: Pod client-containers-8e9e4a42-5628-4fa0-a331-490f4d4cc68b no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jan 10 03:41:38.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-4238" for this suite. 01/10/23 03:41:38.801
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:38.81
Jan 10 03:41:38.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 03:41:38.813
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:38.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:38.839
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 01/10/23 03:41:38.841
Jan 10 03:41:38.851: INFO: Waiting up to 5m0s for pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab" in namespace "emptydir-2925" to be "Succeeded or Failed"
Jan 10 03:41:38.861: INFO: Pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab": Phase="Pending", Reason="", readiness=false. Elapsed: 10.572499ms
Jan 10 03:41:40.864: INFO: Pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab": Phase="Running", Reason="", readiness=false. Elapsed: 2.013791192s
Jan 10 03:41:42.864: INFO: Pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013483892s
STEP: Saw pod success 01/10/23 03:41:42.864
Jan 10 03:41:42.864: INFO: Pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab" satisfied condition "Succeeded or Failed"
Jan 10 03:41:42.867: INFO: Trying to get logs from node cncf-wk2 pod pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab container test-container: <nil>
STEP: delete the pod 01/10/23 03:41:42.872
Jan 10 03:41:42.882: INFO: Waiting for pod pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab to disappear
Jan 10 03:41:42.885: INFO: Pod pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 03:41:42.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2925" for this suite. 01/10/23 03:41:42.889
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":37,"skipped":589,"failed":0}
------------------------------
• [4.084 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:38.81
    Jan 10 03:41:38.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 03:41:38.813
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:38.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:38.839
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 01/10/23 03:41:38.841
    Jan 10 03:41:38.851: INFO: Waiting up to 5m0s for pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab" in namespace "emptydir-2925" to be "Succeeded or Failed"
    Jan 10 03:41:38.861: INFO: Pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab": Phase="Pending", Reason="", readiness=false. Elapsed: 10.572499ms
    Jan 10 03:41:40.864: INFO: Pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab": Phase="Running", Reason="", readiness=false. Elapsed: 2.013791192s
    Jan 10 03:41:42.864: INFO: Pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013483892s
    STEP: Saw pod success 01/10/23 03:41:42.864
    Jan 10 03:41:42.864: INFO: Pod "pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab" satisfied condition "Succeeded or Failed"
    Jan 10 03:41:42.867: INFO: Trying to get logs from node cncf-wk2 pod pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab container test-container: <nil>
    STEP: delete the pod 01/10/23 03:41:42.872
    Jan 10 03:41:42.882: INFO: Waiting for pod pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab to disappear
    Jan 10 03:41:42.885: INFO: Pod pod-6d4300df-d2e8-4a0a-928f-aeb02a7db9ab no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 03:41:42.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2925" for this suite. 01/10/23 03:41:42.889
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:42.899
Jan 10 03:41:42.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-webhook 01/10/23 03:41:42.9
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:42.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:42.961
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 01/10/23 03:41:42.97
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 01/10/23 03:41:43.213
STEP: Deploying the custom resource conversion webhook pod 01/10/23 03:41:43.222
STEP: Wait for the deployment to be ready 01/10/23 03:41:43.256
Jan 10 03:41:43.267: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 01/10/23 03:41:45.278
STEP: Verifying the service has paired with the endpoint 01/10/23 03:41:45.31
Jan 10 03:41:46.310: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Jan 10 03:41:46.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Creating a v1 custom resource 01/10/23 03:41:49.515
STEP: v2 custom resource should be converted 01/10/23 03:41:49.52
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:41:50.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9951" for this suite. 01/10/23 03:41:50.112
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":38,"skipped":608,"failed":0}
------------------------------
• [SLOW TEST] [7.380 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:42.899
    Jan 10 03:41:42.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-webhook 01/10/23 03:41:42.9
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:42.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:42.961
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 01/10/23 03:41:42.97
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 01/10/23 03:41:43.213
    STEP: Deploying the custom resource conversion webhook pod 01/10/23 03:41:43.222
    STEP: Wait for the deployment to be ready 01/10/23 03:41:43.256
    Jan 10 03:41:43.267: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 01/10/23 03:41:45.278
    STEP: Verifying the service has paired with the endpoint 01/10/23 03:41:45.31
    Jan 10 03:41:46.310: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Jan 10 03:41:46.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Creating a v1 custom resource 01/10/23 03:41:49.515
    STEP: v2 custom resource should be converted 01/10/23 03:41:49.52
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:41:50.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-9951" for this suite. 01/10/23 03:41:50.112
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:50.283
Jan 10 03:41:50.283: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename deployment 01/10/23 03:41:50.285
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:50.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:50.436
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Jan 10 03:41:50.500: INFO: Creating simple deployment test-new-deployment
Jan 10 03:41:50.632: INFO: deployment "test-new-deployment" doesn't have the required revision set
Jan 10 03:41:52.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 3, 41, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 41, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 3, 41, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 41, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 01/10/23 03:41:54.662
STEP: updating a scale subresource 01/10/23 03:41:54.665
STEP: verifying the deployment Spec.Replicas was modified 01/10/23 03:41:54.679
STEP: Patch a scale subresource 01/10/23 03:41:54.692
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 10 03:41:54.837: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-4723  73cdcb90-2346-4d54-91eb-39f52ffde3d1 212010 3 2023-01-10 03:41:50 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-01-10 03:41:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:41:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00498c218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-10 03:41:53 +0000 UTC,LastTransitionTime:2023-01-10 03:41:53 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-01-10 03:41:53 +0000 UTC,LastTransitionTime:2023-01-10 03:41:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jan 10 03:41:54.854: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-4723  82b02ba8-e2c6-4676-b477-1d9dcba80367 212017 2 2023-01-10 03:41:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 73cdcb90-2346-4d54-91eb-39f52ffde3d1 0xc004941fd7 0xc004941fd8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 03:41:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"73cdcb90-2346-4d54-91eb-39f52ffde3d1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:41:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049b2088 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 10 03:41:54.873: INFO: Pod "test-new-deployment-845c8977d9-9dpfs" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-9dpfs test-new-deployment-845c8977d9- deployment-4723  cd1f83d5-c20d-44ca-845e-186b1bb47d6f 211998 0 2023-01-10 03:41:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:062eb0e9eba6caa5153bee695ad21795896820e57cd347b523154b64e94417a4 cni.projectcalico.org/podIP:10.42.1.30/32 cni.projectcalico.org/podIPs:10.42.1.30/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 82b02ba8-e2c6-4676-b477-1d9dcba80367 0xc00498c847 0xc00498c848}] [] [{kube-controller-manager Update v1 2023-01-10 03:41:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"82b02ba8-e2c6-4676-b477-1d9dcba80367\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:41:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.30\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sx4r9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sx4r9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.30,StartTime:2023-01-10 03:41:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:41:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://6b7223ac1a958c93931905c6e61ae20ca9cec5685daa20a41d5683826626a3c5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:41:54.874: INFO: Pod "test-new-deployment-845c8977d9-q6bml" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-q6bml test-new-deployment-845c8977d9- deployment-4723  0fd54678-bc45-4e34-9c5d-54fc91b62680 212018 0 2023-01-10 03:41:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 82b02ba8-e2c6-4676-b477-1d9dcba80367 0xc00498cc20 0xc00498cc21}] [] [{kube-controller-manager Update v1 2023-01-10 03:41:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"82b02ba8-e2c6-4676-b477-1d9dcba80367\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:41:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nqgq6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nqgq6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:,StartTime:2023-01-10 03:41:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 10 03:41:54.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4723" for this suite. 01/10/23 03:41:54.892
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":39,"skipped":620,"failed":0}
------------------------------
• [4.641 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:50.283
    Jan 10 03:41:50.283: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename deployment 01/10/23 03:41:50.285
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:50.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:50.436
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Jan 10 03:41:50.500: INFO: Creating simple deployment test-new-deployment
    Jan 10 03:41:50.632: INFO: deployment "test-new-deployment" doesn't have the required revision set
    Jan 10 03:41:52.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 3, 41, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 41, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 3, 41, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 41, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 01/10/23 03:41:54.662
    STEP: updating a scale subresource 01/10/23 03:41:54.665
    STEP: verifying the deployment Spec.Replicas was modified 01/10/23 03:41:54.679
    STEP: Patch a scale subresource 01/10/23 03:41:54.692
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 10 03:41:54.837: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-4723  73cdcb90-2346-4d54-91eb-39f52ffde3d1 212010 3 2023-01-10 03:41:50 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-01-10 03:41:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:41:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00498c218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-10 03:41:53 +0000 UTC,LastTransitionTime:2023-01-10 03:41:53 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-01-10 03:41:53 +0000 UTC,LastTransitionTime:2023-01-10 03:41:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jan 10 03:41:54.854: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-4723  82b02ba8-e2c6-4676-b477-1d9dcba80367 212017 2 2023-01-10 03:41:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 73cdcb90-2346-4d54-91eb-39f52ffde3d1 0xc004941fd7 0xc004941fd8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 03:41:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"73cdcb90-2346-4d54-91eb-39f52ffde3d1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:41:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049b2088 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 03:41:54.873: INFO: Pod "test-new-deployment-845c8977d9-9dpfs" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-9dpfs test-new-deployment-845c8977d9- deployment-4723  cd1f83d5-c20d-44ca-845e-186b1bb47d6f 211998 0 2023-01-10 03:41:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:062eb0e9eba6caa5153bee695ad21795896820e57cd347b523154b64e94417a4 cni.projectcalico.org/podIP:10.42.1.30/32 cni.projectcalico.org/podIPs:10.42.1.30/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 82b02ba8-e2c6-4676-b477-1d9dcba80367 0xc00498c847 0xc00498c848}] [] [{kube-controller-manager Update v1 2023-01-10 03:41:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"82b02ba8-e2c6-4676-b477-1d9dcba80367\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:41:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:41:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.30\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sx4r9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sx4r9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.30,StartTime:2023-01-10 03:41:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:41:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://6b7223ac1a958c93931905c6e61ae20ca9cec5685daa20a41d5683826626a3c5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:41:54.874: INFO: Pod "test-new-deployment-845c8977d9-q6bml" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-q6bml test-new-deployment-845c8977d9- deployment-4723  0fd54678-bc45-4e34-9c5d-54fc91b62680 212018 0 2023-01-10 03:41:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 82b02ba8-e2c6-4676-b477-1d9dcba80367 0xc00498cc20 0xc00498cc21}] [] [{kube-controller-manager Update v1 2023-01-10 03:41:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"82b02ba8-e2c6-4676-b477-1d9dcba80367\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:41:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nqgq6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nqgq6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:41:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:,StartTime:2023-01-10 03:41:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 10 03:41:54.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4723" for this suite. 01/10/23 03:41:54.892
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:54.929
Jan 10 03:41:54.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 03:41:54.93
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:55.011
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:55.017
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 01/10/23 03:41:55.026
STEP: watching for the Service to be added 01/10/23 03:41:55.04
Jan 10 03:41:55.054: INFO: Found Service test-service-9zd9p in namespace services-1114 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Jan 10 03:41:55.054: INFO: Service test-service-9zd9p created
STEP: Getting /status 01/10/23 03:41:55.055
Jan 10 03:41:55.107: INFO: Service test-service-9zd9p has LoadBalancer: {[]}
STEP: patching the ServiceStatus 01/10/23 03:41:55.107
STEP: watching for the Service to be patched 01/10/23 03:41:55.151
Jan 10 03:41:55.156: INFO: observed Service test-service-9zd9p in namespace services-1114 with annotations: map[] & LoadBalancer: {[]}
Jan 10 03:41:55.156: INFO: Found Service test-service-9zd9p in namespace services-1114 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Jan 10 03:41:55.157: INFO: Service test-service-9zd9p has service status patched
STEP: updating the ServiceStatus 01/10/23 03:41:55.157
Jan 10 03:41:55.201: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 01/10/23 03:41:55.202
Jan 10 03:41:55.238: INFO: Observed Service test-service-9zd9p in namespace services-1114 with annotations: map[] & Conditions: {[]}
Jan 10 03:41:55.248: INFO: Observed event: &Service{ObjectMeta:{test-service-9zd9p  services-1114  65afef32-b526-4039-8cb4-254f8d752cc6 212039 0 2023-01-10 03:41:55 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-01-10 03:41:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-01-10 03:41:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.43.92.228,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.43.92.228],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Jan 10 03:41:55.250: INFO: Found Service test-service-9zd9p in namespace services-1114 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jan 10 03:41:55.250: INFO: Service test-service-9zd9p has service status updated
STEP: patching the service 01/10/23 03:41:55.251
STEP: watching for the Service to be patched 01/10/23 03:41:55.299
Jan 10 03:41:55.301: INFO: observed Service test-service-9zd9p in namespace services-1114 with labels: map[test-service-static:true]
Jan 10 03:41:55.302: INFO: observed Service test-service-9zd9p in namespace services-1114 with labels: map[test-service-static:true]
Jan 10 03:41:55.302: INFO: observed Service test-service-9zd9p in namespace services-1114 with labels: map[test-service-static:true]
Jan 10 03:41:55.302: INFO: Found Service test-service-9zd9p in namespace services-1114 with labels: map[test-service:patched test-service-static:true]
Jan 10 03:41:55.302: INFO: Service test-service-9zd9p patched
STEP: deleting the service 01/10/23 03:41:55.302
STEP: watching for the Service to be deleted 01/10/23 03:41:55.314
Jan 10 03:41:55.319: INFO: Observed event: ADDED
Jan 10 03:41:55.320: INFO: Observed event: MODIFIED
Jan 10 03:41:55.320: INFO: Observed event: MODIFIED
Jan 10 03:41:55.320: INFO: Observed event: MODIFIED
Jan 10 03:41:55.321: INFO: Found Service test-service-9zd9p in namespace services-1114 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Jan 10 03:41:55.321: INFO: Service test-service-9zd9p deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 03:41:55.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1114" for this suite. 01/10/23 03:41:55.326
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":40,"skipped":630,"failed":0}
------------------------------
• [0.405 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:54.929
    Jan 10 03:41:54.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 03:41:54.93
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:55.011
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:55.017
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 01/10/23 03:41:55.026
    STEP: watching for the Service to be added 01/10/23 03:41:55.04
    Jan 10 03:41:55.054: INFO: Found Service test-service-9zd9p in namespace services-1114 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Jan 10 03:41:55.054: INFO: Service test-service-9zd9p created
    STEP: Getting /status 01/10/23 03:41:55.055
    Jan 10 03:41:55.107: INFO: Service test-service-9zd9p has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 01/10/23 03:41:55.107
    STEP: watching for the Service to be patched 01/10/23 03:41:55.151
    Jan 10 03:41:55.156: INFO: observed Service test-service-9zd9p in namespace services-1114 with annotations: map[] & LoadBalancer: {[]}
    Jan 10 03:41:55.156: INFO: Found Service test-service-9zd9p in namespace services-1114 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Jan 10 03:41:55.157: INFO: Service test-service-9zd9p has service status patched
    STEP: updating the ServiceStatus 01/10/23 03:41:55.157
    Jan 10 03:41:55.201: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 01/10/23 03:41:55.202
    Jan 10 03:41:55.238: INFO: Observed Service test-service-9zd9p in namespace services-1114 with annotations: map[] & Conditions: {[]}
    Jan 10 03:41:55.248: INFO: Observed event: &Service{ObjectMeta:{test-service-9zd9p  services-1114  65afef32-b526-4039-8cb4-254f8d752cc6 212039 0 2023-01-10 03:41:55 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-01-10 03:41:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-01-10 03:41:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.43.92.228,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.43.92.228],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Jan 10 03:41:55.250: INFO: Found Service test-service-9zd9p in namespace services-1114 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jan 10 03:41:55.250: INFO: Service test-service-9zd9p has service status updated
    STEP: patching the service 01/10/23 03:41:55.251
    STEP: watching for the Service to be patched 01/10/23 03:41:55.299
    Jan 10 03:41:55.301: INFO: observed Service test-service-9zd9p in namespace services-1114 with labels: map[test-service-static:true]
    Jan 10 03:41:55.302: INFO: observed Service test-service-9zd9p in namespace services-1114 with labels: map[test-service-static:true]
    Jan 10 03:41:55.302: INFO: observed Service test-service-9zd9p in namespace services-1114 with labels: map[test-service-static:true]
    Jan 10 03:41:55.302: INFO: Found Service test-service-9zd9p in namespace services-1114 with labels: map[test-service:patched test-service-static:true]
    Jan 10 03:41:55.302: INFO: Service test-service-9zd9p patched
    STEP: deleting the service 01/10/23 03:41:55.302
    STEP: watching for the Service to be deleted 01/10/23 03:41:55.314
    Jan 10 03:41:55.319: INFO: Observed event: ADDED
    Jan 10 03:41:55.320: INFO: Observed event: MODIFIED
    Jan 10 03:41:55.320: INFO: Observed event: MODIFIED
    Jan 10 03:41:55.320: INFO: Observed event: MODIFIED
    Jan 10 03:41:55.321: INFO: Found Service test-service-9zd9p in namespace services-1114 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Jan 10 03:41:55.321: INFO: Service test-service-9zd9p deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 03:41:55.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1114" for this suite. 01/10/23 03:41:55.326
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:41:55.334
Jan 10 03:41:55.335: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename job 01/10/23 03:41:55.339
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:55.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:55.389
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 01/10/23 03:41:55.395
STEP: Ensuring active pods == parallelism 01/10/23 03:41:55.404
STEP: delete a job 01/10/23 03:41:59.414
STEP: deleting Job.batch foo in namespace job-1295, will wait for the garbage collector to delete the pods 01/10/23 03:41:59.414
Jan 10 03:41:59.478: INFO: Deleting Job.batch foo took: 7.731289ms
Jan 10 03:41:59.578: INFO: Terminating Job.batch foo pods took: 100.183471ms
STEP: Ensuring job was deleted 01/10/23 03:42:31.279
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 10 03:42:31.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1295" for this suite. 01/10/23 03:42:31.287
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":41,"skipped":637,"failed":0}
------------------------------
• [SLOW TEST] [35.959 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:41:55.334
    Jan 10 03:41:55.335: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename job 01/10/23 03:41:55.339
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:41:55.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:41:55.389
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 01/10/23 03:41:55.395
    STEP: Ensuring active pods == parallelism 01/10/23 03:41:55.404
    STEP: delete a job 01/10/23 03:41:59.414
    STEP: deleting Job.batch foo in namespace job-1295, will wait for the garbage collector to delete the pods 01/10/23 03:41:59.414
    Jan 10 03:41:59.478: INFO: Deleting Job.batch foo took: 7.731289ms
    Jan 10 03:41:59.578: INFO: Terminating Job.batch foo pods took: 100.183471ms
    STEP: Ensuring job was deleted 01/10/23 03:42:31.279
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 10 03:42:31.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1295" for this suite. 01/10/23 03:42:31.287
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:31.298
Jan 10 03:42:31.298: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename containers 01/10/23 03:42:31.298
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:31.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:31.334
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 01/10/23 03:42:31.338
Jan 10 03:42:31.351: INFO: Waiting up to 5m0s for pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6" in namespace "containers-4008" to be "Succeeded or Failed"
Jan 10 03:42:31.366: INFO: Pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.672186ms
Jan 10 03:42:33.368: INFO: Pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017318988s
Jan 10 03:42:35.370: INFO: Pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019074793s
STEP: Saw pod success 01/10/23 03:42:35.37
Jan 10 03:42:35.370: INFO: Pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6" satisfied condition "Succeeded or Failed"
Jan 10 03:42:35.374: INFO: Trying to get logs from node cncf-wk2 pod client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 03:42:35.382
Jan 10 03:42:35.407: INFO: Waiting for pod client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6 to disappear
Jan 10 03:42:35.410: INFO: Pod client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jan 10 03:42:35.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4008" for this suite. 01/10/23 03:42:35.415
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":42,"skipped":665,"failed":0}
------------------------------
• [4.130 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:31.298
    Jan 10 03:42:31.298: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename containers 01/10/23 03:42:31.298
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:31.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:31.334
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 01/10/23 03:42:31.338
    Jan 10 03:42:31.351: INFO: Waiting up to 5m0s for pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6" in namespace "containers-4008" to be "Succeeded or Failed"
    Jan 10 03:42:31.366: INFO: Pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.672186ms
    Jan 10 03:42:33.368: INFO: Pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017318988s
    Jan 10 03:42:35.370: INFO: Pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019074793s
    STEP: Saw pod success 01/10/23 03:42:35.37
    Jan 10 03:42:35.370: INFO: Pod "client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6" satisfied condition "Succeeded or Failed"
    Jan 10 03:42:35.374: INFO: Trying to get logs from node cncf-wk2 pod client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 03:42:35.382
    Jan 10 03:42:35.407: INFO: Waiting for pod client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6 to disappear
    Jan 10 03:42:35.410: INFO: Pod client-containers-cef0080d-a571-4475-b064-0b0f2bcd02a6 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jan 10 03:42:35.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-4008" for this suite. 01/10/23 03:42:35.415
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:35.454
Jan 10 03:42:35.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 03:42:35.457
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:35.48
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:35.483
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 01/10/23 03:42:35.488
Jan 10 03:42:35.500: INFO: Waiting up to 5m0s for pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b" in namespace "downward-api-7941" to be "Succeeded or Failed"
Jan 10 03:42:35.509: INFO: Pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.321316ms
Jan 10 03:42:37.512: INFO: Pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011592906s
Jan 10 03:42:39.512: INFO: Pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01161523s
STEP: Saw pod success 01/10/23 03:42:39.512
Jan 10 03:42:39.512: INFO: Pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b" satisfied condition "Succeeded or Failed"
Jan 10 03:42:39.515: INFO: Trying to get logs from node cncf-wk2 pod downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b container dapi-container: <nil>
STEP: delete the pod 01/10/23 03:42:39.525
Jan 10 03:42:39.532: INFO: Waiting for pod downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b to disappear
Jan 10 03:42:39.538: INFO: Pod downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 10 03:42:39.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7941" for this suite. 01/10/23 03:42:39.542
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":43,"skipped":686,"failed":0}
------------------------------
• [4.094 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:35.454
    Jan 10 03:42:35.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 03:42:35.457
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:35.48
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:35.483
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 01/10/23 03:42:35.488
    Jan 10 03:42:35.500: INFO: Waiting up to 5m0s for pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b" in namespace "downward-api-7941" to be "Succeeded or Failed"
    Jan 10 03:42:35.509: INFO: Pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.321316ms
    Jan 10 03:42:37.512: INFO: Pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011592906s
    Jan 10 03:42:39.512: INFO: Pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01161523s
    STEP: Saw pod success 01/10/23 03:42:39.512
    Jan 10 03:42:39.512: INFO: Pod "downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b" satisfied condition "Succeeded or Failed"
    Jan 10 03:42:39.515: INFO: Trying to get logs from node cncf-wk2 pod downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b container dapi-container: <nil>
    STEP: delete the pod 01/10/23 03:42:39.525
    Jan 10 03:42:39.532: INFO: Waiting for pod downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b to disappear
    Jan 10 03:42:39.538: INFO: Pod downward-api-f1de747f-86fa-40e6-8048-ce6b2ff0149b no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 10 03:42:39.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7941" for this suite. 01/10/23 03:42:39.542
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:39.552
Jan 10 03:42:39.552: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sysctl 01/10/23 03:42:39.553
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:39.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:39.606
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 01/10/23 03:42:39.609
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 10 03:42:39.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8772" for this suite. 01/10/23 03:42:39.634
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":44,"skipped":701,"failed":0}
------------------------------
• [0.110 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:39.552
    Jan 10 03:42:39.552: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sysctl 01/10/23 03:42:39.553
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:39.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:39.606
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 01/10/23 03:42:39.609
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 10 03:42:39.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-8772" for this suite. 01/10/23 03:42:39.634
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:39.662
Jan 10 03:42:39.662: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename runtimeclass 01/10/23 03:42:39.665
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:39.788
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:39.799
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Jan 10 03:42:39.822: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-120 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 10 03:42:39.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-120" for this suite. 01/10/23 03:42:39.848
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":45,"skipped":712,"failed":0}
------------------------------
• [0.195 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:39.662
    Jan 10 03:42:39.662: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename runtimeclass 01/10/23 03:42:39.665
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:39.788
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:39.799
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Jan 10 03:42:39.822: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-120 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 10 03:42:39.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-120" for this suite. 01/10/23 03:42:39.848
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:39.858
Jan 10 03:42:39.858: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 03:42:39.859
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:39.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:39.897
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 01/10/23 03:42:39.903
Jan 10 03:42:39.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6263 create -f -'
Jan 10 03:42:41.523: INFO: stderr: ""
Jan 10 03:42:41.523: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 01/10/23 03:42:41.523
Jan 10 03:42:41.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6263 diff -f -'
Jan 10 03:42:41.788: INFO: rc: 1
Jan 10 03:42:41.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6263 delete -f -'
Jan 10 03:42:41.876: INFO: stderr: ""
Jan 10 03:42:41.876: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 03:42:41.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6263" for this suite. 01/10/23 03:42:41.885
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":46,"skipped":729,"failed":0}
------------------------------
• [2.033 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:39.858
    Jan 10 03:42:39.858: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 03:42:39.859
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:39.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:39.897
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 01/10/23 03:42:39.903
    Jan 10 03:42:39.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6263 create -f -'
    Jan 10 03:42:41.523: INFO: stderr: ""
    Jan 10 03:42:41.523: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 01/10/23 03:42:41.523
    Jan 10 03:42:41.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6263 diff -f -'
    Jan 10 03:42:41.788: INFO: rc: 1
    Jan 10 03:42:41.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6263 delete -f -'
    Jan 10 03:42:41.876: INFO: stderr: ""
    Jan 10 03:42:41.876: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 03:42:41.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6263" for this suite. 01/10/23 03:42:41.885
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:41.892
Jan 10 03:42:41.892: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 03:42:41.893
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:41.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:41.93
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 01/10/23 03:42:41.944
STEP: Creating a ResourceQuota 01/10/23 03:42:46.947
STEP: Ensuring resource quota status is calculated 01/10/23 03:42:46.952
STEP: Creating a ReplicaSet 01/10/23 03:42:48.955
STEP: Ensuring resource quota status captures replicaset creation 01/10/23 03:42:48.965
STEP: Deleting a ReplicaSet 01/10/23 03:42:50.974
STEP: Ensuring resource quota status released usage 01/10/23 03:42:50.982
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 03:42:52.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8978" for this suite. 01/10/23 03:42:52.988
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":47,"skipped":749,"failed":0}
------------------------------
• [SLOW TEST] [11.100 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:41.892
    Jan 10 03:42:41.892: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 03:42:41.893
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:41.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:41.93
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 01/10/23 03:42:41.944
    STEP: Creating a ResourceQuota 01/10/23 03:42:46.947
    STEP: Ensuring resource quota status is calculated 01/10/23 03:42:46.952
    STEP: Creating a ReplicaSet 01/10/23 03:42:48.955
    STEP: Ensuring resource quota status captures replicaset creation 01/10/23 03:42:48.965
    STEP: Deleting a ReplicaSet 01/10/23 03:42:50.974
    STEP: Ensuring resource quota status released usage 01/10/23 03:42:50.982
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 03:42:52.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8978" for this suite. 01/10/23 03:42:52.988
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:52.996
Jan 10 03:42:52.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename lease-test 01/10/23 03:42:52.997
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:53.027
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:53.033
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Jan 10 03:42:53.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-5480" for this suite. 01/10/23 03:42:53.113
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":48,"skipped":765,"failed":0}
------------------------------
• [0.127 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:52.996
    Jan 10 03:42:52.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename lease-test 01/10/23 03:42:52.997
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:53.027
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:53.033
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Jan 10 03:42:53.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-5480" for this suite. 01/10/23 03:42:53.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:53.127
Jan 10 03:42:53.127: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename security-context 01/10/23 03:42:53.128
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:53.162
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:53.173
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 01/10/23 03:42:53.199
Jan 10 03:42:53.236: INFO: Waiting up to 5m0s for pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f" in namespace "security-context-7691" to be "Succeeded or Failed"
Jan 10 03:42:53.260: INFO: Pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.959278ms
Jan 10 03:42:55.264: INFO: Pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02689206s
Jan 10 03:42:57.263: INFO: Pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025844559s
STEP: Saw pod success 01/10/23 03:42:57.263
Jan 10 03:42:57.263: INFO: Pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f" satisfied condition "Succeeded or Failed"
Jan 10 03:42:57.265: INFO: Trying to get logs from node cncf-wk2 pod security-context-c3b594e9-813f-4933-9f82-0b87963f304f container test-container: <nil>
STEP: delete the pod 01/10/23 03:42:57.271
Jan 10 03:42:57.280: INFO: Waiting for pod security-context-c3b594e9-813f-4933-9f82-0b87963f304f to disappear
Jan 10 03:42:57.282: INFO: Pod security-context-c3b594e9-813f-4933-9f82-0b87963f304f no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 10 03:42:57.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7691" for this suite. 01/10/23 03:42:57.285
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":49,"skipped":771,"failed":0}
------------------------------
• [4.164 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:53.127
    Jan 10 03:42:53.127: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename security-context 01/10/23 03:42:53.128
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:53.162
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:53.173
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 01/10/23 03:42:53.199
    Jan 10 03:42:53.236: INFO: Waiting up to 5m0s for pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f" in namespace "security-context-7691" to be "Succeeded or Failed"
    Jan 10 03:42:53.260: INFO: Pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.959278ms
    Jan 10 03:42:55.264: INFO: Pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02689206s
    Jan 10 03:42:57.263: INFO: Pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025844559s
    STEP: Saw pod success 01/10/23 03:42:57.263
    Jan 10 03:42:57.263: INFO: Pod "security-context-c3b594e9-813f-4933-9f82-0b87963f304f" satisfied condition "Succeeded or Failed"
    Jan 10 03:42:57.265: INFO: Trying to get logs from node cncf-wk2 pod security-context-c3b594e9-813f-4933-9f82-0b87963f304f container test-container: <nil>
    STEP: delete the pod 01/10/23 03:42:57.271
    Jan 10 03:42:57.280: INFO: Waiting for pod security-context-c3b594e9-813f-4933-9f82-0b87963f304f to disappear
    Jan 10 03:42:57.282: INFO: Pod security-context-c3b594e9-813f-4933-9f82-0b87963f304f no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 10 03:42:57.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-7691" for this suite. 01/10/23 03:42:57.285
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:42:57.292
Jan 10 03:42:57.292: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename var-expansion 01/10/23 03:42:57.293
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:57.314
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:57.322
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Jan 10 03:42:57.339: INFO: Waiting up to 2m0s for pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e" in namespace "var-expansion-9156" to be "container 0 failed with reason CreateContainerConfigError"
Jan 10 03:42:57.353: INFO: Pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.752787ms
Jan 10 03:42:59.360: INFO: Pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021092927s
Jan 10 03:42:59.360: INFO: Pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Jan 10 03:42:59.360: INFO: Deleting pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e" in namespace "var-expansion-9156"
Jan 10 03:42:59.366: INFO: Wait up to 5m0s for pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 10 03:43:03.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9156" for this suite. 01/10/23 03:43:03.378
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":50,"skipped":778,"failed":0}
------------------------------
• [SLOW TEST] [6.090 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:42:57.292
    Jan 10 03:42:57.292: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename var-expansion 01/10/23 03:42:57.293
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:42:57.314
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:42:57.322
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Jan 10 03:42:57.339: INFO: Waiting up to 2m0s for pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e" in namespace "var-expansion-9156" to be "container 0 failed with reason CreateContainerConfigError"
    Jan 10 03:42:57.353: INFO: Pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.752787ms
    Jan 10 03:42:59.360: INFO: Pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021092927s
    Jan 10 03:42:59.360: INFO: Pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Jan 10 03:42:59.360: INFO: Deleting pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e" in namespace "var-expansion-9156"
    Jan 10 03:42:59.366: INFO: Wait up to 5m0s for pod "var-expansion-1c180372-65c9-42a8-b6cf-ebce0001f09e" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 10 03:43:03.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9156" for this suite. 01/10/23 03:43:03.378
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:43:03.384
Jan 10 03:43:03.385: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename gc 01/10/23 03:43:03.385
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:03.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:03.43
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 01/10/23 03:43:03.456
STEP: create the rc2 01/10/23 03:43:03.46
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 01/10/23 03:43:08.679
STEP: delete the rc simpletest-rc-to-be-deleted 01/10/23 03:43:14.796
STEP: wait for the rc to be deleted 01/10/23 03:43:14.869
Jan 10 03:43:20.325: INFO: 70 pods remaining
Jan 10 03:43:20.326: INFO: 70 pods has nil DeletionTimestamp
Jan 10 03:43:20.326: INFO: 
Jan 10 03:43:25.330: INFO: 50 pods remaining
Jan 10 03:43:25.330: INFO: 50 pods has nil DeletionTimestamp
Jan 10 03:43:25.330: INFO: 
STEP: Gathering metrics 01/10/23 03:43:29.928
W0110 03:43:29.943041      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 10 03:43:29.943: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Jan 10 03:43:29.943: INFO: Deleting pod "simpletest-rc-to-be-deleted-25lfx" in namespace "gc-581"
Jan 10 03:43:29.967: INFO: Deleting pod "simpletest-rc-to-be-deleted-2p9jp" in namespace "gc-581"
Jan 10 03:43:30.034: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tdg8" in namespace "gc-581"
Jan 10 03:43:30.126: INFO: Deleting pod "simpletest-rc-to-be-deleted-428kn" in namespace "gc-581"
Jan 10 03:43:30.282: INFO: Deleting pod "simpletest-rc-to-be-deleted-4f6ck" in namespace "gc-581"
Jan 10 03:43:30.360: INFO: Deleting pod "simpletest-rc-to-be-deleted-4pzkq" in namespace "gc-581"
Jan 10 03:43:30.406: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rk9w" in namespace "gc-581"
Jan 10 03:43:30.477: INFO: Deleting pod "simpletest-rc-to-be-deleted-4sk5j" in namespace "gc-581"
Jan 10 03:43:30.509: INFO: Deleting pod "simpletest-rc-to-be-deleted-4spbm" in namespace "gc-581"
Jan 10 03:43:30.625: INFO: Deleting pod "simpletest-rc-to-be-deleted-4svlt" in namespace "gc-581"
Jan 10 03:43:30.687: INFO: Deleting pod "simpletest-rc-to-be-deleted-4z9c6" in namespace "gc-581"
Jan 10 03:43:30.791: INFO: Deleting pod "simpletest-rc-to-be-deleted-5s2pq" in namespace "gc-581"
Jan 10 03:43:30.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zg54" in namespace "gc-581"
Jan 10 03:43:31.091: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bvmp" in namespace "gc-581"
Jan 10 03:43:31.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k45f" in namespace "gc-581"
Jan 10 03:43:31.234: INFO: Deleting pod "simpletest-rc-to-be-deleted-6njlz" in namespace "gc-581"
Jan 10 03:43:31.292: INFO: Deleting pod "simpletest-rc-to-be-deleted-6ztlg" in namespace "gc-581"
Jan 10 03:43:31.471: INFO: Deleting pod "simpletest-rc-to-be-deleted-7f5gg" in namespace "gc-581"
Jan 10 03:43:31.553: INFO: Deleting pod "simpletest-rc-to-be-deleted-86mpx" in namespace "gc-581"
Jan 10 03:43:31.663: INFO: Deleting pod "simpletest-rc-to-be-deleted-8lgvk" in namespace "gc-581"
Jan 10 03:43:31.731: INFO: Deleting pod "simpletest-rc-to-be-deleted-8wrwh" in namespace "gc-581"
Jan 10 03:43:31.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-95zcf" in namespace "gc-581"
Jan 10 03:43:31.868: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jgmf" in namespace "gc-581"
Jan 10 03:43:31.926: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnwwp" in namespace "gc-581"
Jan 10 03:43:31.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnxt6" in namespace "gc-581"
Jan 10 03:43:31.995: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqj8g" in namespace "gc-581"
Jan 10 03:43:32.120: INFO: Deleting pod "simpletest-rc-to-be-deleted-bztlr" in namespace "gc-581"
Jan 10 03:43:32.165: INFO: Deleting pod "simpletest-rc-to-be-deleted-c866x" in namespace "gc-581"
Jan 10 03:43:32.202: INFO: Deleting pod "simpletest-rc-to-be-deleted-cf54m" in namespace "gc-581"
Jan 10 03:43:32.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-chc85" in namespace "gc-581"
Jan 10 03:43:32.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-czzcm" in namespace "gc-581"
Jan 10 03:43:32.399: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5xlz" in namespace "gc-581"
Jan 10 03:43:32.422: INFO: Deleting pod "simpletest-rc-to-be-deleted-f6pkl" in namespace "gc-581"
Jan 10 03:43:32.433: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjwx5" in namespace "gc-581"
Jan 10 03:43:32.449: INFO: Deleting pod "simpletest-rc-to-be-deleted-fq9j4" in namespace "gc-581"
Jan 10 03:43:32.482: INFO: Deleting pod "simpletest-rc-to-be-deleted-frndb" in namespace "gc-581"
Jan 10 03:43:32.538: INFO: Deleting pod "simpletest-rc-to-be-deleted-fs6dq" in namespace "gc-581"
Jan 10 03:43:32.595: INFO: Deleting pod "simpletest-rc-to-be-deleted-g5l2w" in namespace "gc-581"
Jan 10 03:43:32.633: INFO: Deleting pod "simpletest-rc-to-be-deleted-g7n7v" in namespace "gc-581"
Jan 10 03:43:32.728: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfl2z" in namespace "gc-581"
Jan 10 03:43:32.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-hlkgk" in namespace "gc-581"
Jan 10 03:43:33.035: INFO: Deleting pod "simpletest-rc-to-be-deleted-hv9cf" in namespace "gc-581"
Jan 10 03:43:33.088: INFO: Deleting pod "simpletest-rc-to-be-deleted-hzf9s" in namespace "gc-581"
Jan 10 03:43:33.103: INFO: Deleting pod "simpletest-rc-to-be-deleted-j4hvb" in namespace "gc-581"
Jan 10 03:43:33.159: INFO: Deleting pod "simpletest-rc-to-be-deleted-j6mn4" in namespace "gc-581"
Jan 10 03:43:33.246: INFO: Deleting pod "simpletest-rc-to-be-deleted-j8dlj" in namespace "gc-581"
Jan 10 03:43:33.339: INFO: Deleting pod "simpletest-rc-to-be-deleted-j8n94" in namespace "gc-581"
Jan 10 03:43:33.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-jg5g4" in namespace "gc-581"
Jan 10 03:43:33.422: INFO: Deleting pod "simpletest-rc-to-be-deleted-jsffm" in namespace "gc-581"
Jan 10 03:43:33.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-jv8gf" in namespace "gc-581"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 10 03:43:33.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-581" for this suite. 01/10/23 03:43:33.56
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":51,"skipped":780,"failed":0}
------------------------------
• [SLOW TEST] [30.205 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:43:03.384
    Jan 10 03:43:03.385: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename gc 01/10/23 03:43:03.385
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:03.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:03.43
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 01/10/23 03:43:03.456
    STEP: create the rc2 01/10/23 03:43:03.46
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 01/10/23 03:43:08.679
    STEP: delete the rc simpletest-rc-to-be-deleted 01/10/23 03:43:14.796
    STEP: wait for the rc to be deleted 01/10/23 03:43:14.869
    Jan 10 03:43:20.325: INFO: 70 pods remaining
    Jan 10 03:43:20.326: INFO: 70 pods has nil DeletionTimestamp
    Jan 10 03:43:20.326: INFO: 
    Jan 10 03:43:25.330: INFO: 50 pods remaining
    Jan 10 03:43:25.330: INFO: 50 pods has nil DeletionTimestamp
    Jan 10 03:43:25.330: INFO: 
    STEP: Gathering metrics 01/10/23 03:43:29.928
    W0110 03:43:29.943041      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 10 03:43:29.943: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Jan 10 03:43:29.943: INFO: Deleting pod "simpletest-rc-to-be-deleted-25lfx" in namespace "gc-581"
    Jan 10 03:43:29.967: INFO: Deleting pod "simpletest-rc-to-be-deleted-2p9jp" in namespace "gc-581"
    Jan 10 03:43:30.034: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tdg8" in namespace "gc-581"
    Jan 10 03:43:30.126: INFO: Deleting pod "simpletest-rc-to-be-deleted-428kn" in namespace "gc-581"
    Jan 10 03:43:30.282: INFO: Deleting pod "simpletest-rc-to-be-deleted-4f6ck" in namespace "gc-581"
    Jan 10 03:43:30.360: INFO: Deleting pod "simpletest-rc-to-be-deleted-4pzkq" in namespace "gc-581"
    Jan 10 03:43:30.406: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rk9w" in namespace "gc-581"
    Jan 10 03:43:30.477: INFO: Deleting pod "simpletest-rc-to-be-deleted-4sk5j" in namespace "gc-581"
    Jan 10 03:43:30.509: INFO: Deleting pod "simpletest-rc-to-be-deleted-4spbm" in namespace "gc-581"
    Jan 10 03:43:30.625: INFO: Deleting pod "simpletest-rc-to-be-deleted-4svlt" in namespace "gc-581"
    Jan 10 03:43:30.687: INFO: Deleting pod "simpletest-rc-to-be-deleted-4z9c6" in namespace "gc-581"
    Jan 10 03:43:30.791: INFO: Deleting pod "simpletest-rc-to-be-deleted-5s2pq" in namespace "gc-581"
    Jan 10 03:43:30.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zg54" in namespace "gc-581"
    Jan 10 03:43:31.091: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bvmp" in namespace "gc-581"
    Jan 10 03:43:31.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k45f" in namespace "gc-581"
    Jan 10 03:43:31.234: INFO: Deleting pod "simpletest-rc-to-be-deleted-6njlz" in namespace "gc-581"
    Jan 10 03:43:31.292: INFO: Deleting pod "simpletest-rc-to-be-deleted-6ztlg" in namespace "gc-581"
    Jan 10 03:43:31.471: INFO: Deleting pod "simpletest-rc-to-be-deleted-7f5gg" in namespace "gc-581"
    Jan 10 03:43:31.553: INFO: Deleting pod "simpletest-rc-to-be-deleted-86mpx" in namespace "gc-581"
    Jan 10 03:43:31.663: INFO: Deleting pod "simpletest-rc-to-be-deleted-8lgvk" in namespace "gc-581"
    Jan 10 03:43:31.731: INFO: Deleting pod "simpletest-rc-to-be-deleted-8wrwh" in namespace "gc-581"
    Jan 10 03:43:31.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-95zcf" in namespace "gc-581"
    Jan 10 03:43:31.868: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jgmf" in namespace "gc-581"
    Jan 10 03:43:31.926: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnwwp" in namespace "gc-581"
    Jan 10 03:43:31.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnxt6" in namespace "gc-581"
    Jan 10 03:43:31.995: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqj8g" in namespace "gc-581"
    Jan 10 03:43:32.120: INFO: Deleting pod "simpletest-rc-to-be-deleted-bztlr" in namespace "gc-581"
    Jan 10 03:43:32.165: INFO: Deleting pod "simpletest-rc-to-be-deleted-c866x" in namespace "gc-581"
    Jan 10 03:43:32.202: INFO: Deleting pod "simpletest-rc-to-be-deleted-cf54m" in namespace "gc-581"
    Jan 10 03:43:32.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-chc85" in namespace "gc-581"
    Jan 10 03:43:32.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-czzcm" in namespace "gc-581"
    Jan 10 03:43:32.399: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5xlz" in namespace "gc-581"
    Jan 10 03:43:32.422: INFO: Deleting pod "simpletest-rc-to-be-deleted-f6pkl" in namespace "gc-581"
    Jan 10 03:43:32.433: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjwx5" in namespace "gc-581"
    Jan 10 03:43:32.449: INFO: Deleting pod "simpletest-rc-to-be-deleted-fq9j4" in namespace "gc-581"
    Jan 10 03:43:32.482: INFO: Deleting pod "simpletest-rc-to-be-deleted-frndb" in namespace "gc-581"
    Jan 10 03:43:32.538: INFO: Deleting pod "simpletest-rc-to-be-deleted-fs6dq" in namespace "gc-581"
    Jan 10 03:43:32.595: INFO: Deleting pod "simpletest-rc-to-be-deleted-g5l2w" in namespace "gc-581"
    Jan 10 03:43:32.633: INFO: Deleting pod "simpletest-rc-to-be-deleted-g7n7v" in namespace "gc-581"
    Jan 10 03:43:32.728: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfl2z" in namespace "gc-581"
    Jan 10 03:43:32.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-hlkgk" in namespace "gc-581"
    Jan 10 03:43:33.035: INFO: Deleting pod "simpletest-rc-to-be-deleted-hv9cf" in namespace "gc-581"
    Jan 10 03:43:33.088: INFO: Deleting pod "simpletest-rc-to-be-deleted-hzf9s" in namespace "gc-581"
    Jan 10 03:43:33.103: INFO: Deleting pod "simpletest-rc-to-be-deleted-j4hvb" in namespace "gc-581"
    Jan 10 03:43:33.159: INFO: Deleting pod "simpletest-rc-to-be-deleted-j6mn4" in namespace "gc-581"
    Jan 10 03:43:33.246: INFO: Deleting pod "simpletest-rc-to-be-deleted-j8dlj" in namespace "gc-581"
    Jan 10 03:43:33.339: INFO: Deleting pod "simpletest-rc-to-be-deleted-j8n94" in namespace "gc-581"
    Jan 10 03:43:33.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-jg5g4" in namespace "gc-581"
    Jan 10 03:43:33.422: INFO: Deleting pod "simpletest-rc-to-be-deleted-jsffm" in namespace "gc-581"
    Jan 10 03:43:33.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-jv8gf" in namespace "gc-581"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 10 03:43:33.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-581" for this suite. 01/10/23 03:43:33.56
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:43:33.677
Jan 10 03:43:33.684: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename init-container 01/10/23 03:43:33.698
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:33.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:33.829
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 01/10/23 03:43:33.887
Jan 10 03:43:33.887: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 10 03:43:38.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7954" for this suite. 01/10/23 03:43:38.477
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":52,"skipped":785,"failed":0}
------------------------------
• [4.826 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:43:33.677
    Jan 10 03:43:33.684: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename init-container 01/10/23 03:43:33.698
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:33.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:33.829
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 01/10/23 03:43:33.887
    Jan 10 03:43:33.887: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 10 03:43:38.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-7954" for this suite. 01/10/23 03:43:38.477
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:43:38.504
Jan 10 03:43:38.504: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:43:38.505
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:38.569
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:38.581
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 01/10/23 03:43:38.638
Jan 10 03:43:38.811: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0" in namespace "projected-6567" to be "Succeeded or Failed"
Jan 10 03:43:38.874: INFO: Pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0": Phase="Pending", Reason="", readiness=false. Elapsed: 62.353691ms
Jan 10 03:43:40.898: INFO: Pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087015271s
Jan 10 03:43:42.877: INFO: Pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06529912s
STEP: Saw pod success 01/10/23 03:43:42.877
Jan 10 03:43:42.877: INFO: Pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0" satisfied condition "Succeeded or Failed"
Jan 10 03:43:42.879: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0 container client-container: <nil>
STEP: delete the pod 01/10/23 03:43:42.889
Jan 10 03:43:42.909: INFO: Waiting for pod downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0 to disappear
Jan 10 03:43:42.911: INFO: Pod downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 03:43:42.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6567" for this suite. 01/10/23 03:43:42.917
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":53,"skipped":793,"failed":0}
------------------------------
• [4.419 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:43:38.504
    Jan 10 03:43:38.504: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:43:38.505
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:38.569
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:38.581
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 01/10/23 03:43:38.638
    Jan 10 03:43:38.811: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0" in namespace "projected-6567" to be "Succeeded or Failed"
    Jan 10 03:43:38.874: INFO: Pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0": Phase="Pending", Reason="", readiness=false. Elapsed: 62.353691ms
    Jan 10 03:43:40.898: INFO: Pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087015271s
    Jan 10 03:43:42.877: INFO: Pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06529912s
    STEP: Saw pod success 01/10/23 03:43:42.877
    Jan 10 03:43:42.877: INFO: Pod "downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0" satisfied condition "Succeeded or Failed"
    Jan 10 03:43:42.879: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0 container client-container: <nil>
    STEP: delete the pod 01/10/23 03:43:42.889
    Jan 10 03:43:42.909: INFO: Waiting for pod downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0 to disappear
    Jan 10 03:43:42.911: INFO: Pod downwardapi-volume-69ac7fed-45df-4371-8ff3-d185d28205d0 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 03:43:42.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6567" for this suite. 01/10/23 03:43:42.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:43:42.932
Jan 10 03:43:42.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 03:43:42.933
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:43.105
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:43.113
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 03:43:43.289
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 03:43:44.218
STEP: Deploying the webhook pod 01/10/23 03:43:44.224
STEP: Wait for the deployment to be ready 01/10/23 03:43:44.237
Jan 10 03:43:44.250: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 03:43:46.262
STEP: Verifying the service has paired with the endpoint 01/10/23 03:43:46.273
Jan 10 03:43:47.274: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 01/10/23 03:43:47.277
STEP: create a pod that should be updated by the webhook 01/10/23 03:43:47.318
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:43:47.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8525" for this suite. 01/10/23 03:43:47.479
STEP: Destroying namespace "webhook-8525-markers" for this suite. 01/10/23 03:43:47.496
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":54,"skipped":836,"failed":0}
------------------------------
• [4.679 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:43:42.932
    Jan 10 03:43:42.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 03:43:42.933
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:43.105
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:43.113
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 03:43:43.289
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 03:43:44.218
    STEP: Deploying the webhook pod 01/10/23 03:43:44.224
    STEP: Wait for the deployment to be ready 01/10/23 03:43:44.237
    Jan 10 03:43:44.250: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 03:43:46.262
    STEP: Verifying the service has paired with the endpoint 01/10/23 03:43:46.273
    Jan 10 03:43:47.274: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 01/10/23 03:43:47.277
    STEP: create a pod that should be updated by the webhook 01/10/23 03:43:47.318
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:43:47.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8525" for this suite. 01/10/23 03:43:47.479
    STEP: Destroying namespace "webhook-8525-markers" for this suite. 01/10/23 03:43:47.496
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:43:47.615
Jan 10 03:43:47.615: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:43:47.616
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:47.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:47.825
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 01/10/23 03:43:47.846
Jan 10 03:43:47.877: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7" in namespace "projected-2261" to be "Succeeded or Failed"
Jan 10 03:43:47.891: INFO: Pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.856196ms
Jan 10 03:43:49.895: INFO: Pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018090102s
Jan 10 03:43:51.894: INFO: Pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017293387s
STEP: Saw pod success 01/10/23 03:43:51.894
Jan 10 03:43:51.894: INFO: Pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7" satisfied condition "Succeeded or Failed"
Jan 10 03:43:51.897: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7 container client-container: <nil>
STEP: delete the pod 01/10/23 03:43:51.904
Jan 10 03:43:51.915: INFO: Waiting for pod downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7 to disappear
Jan 10 03:43:51.918: INFO: Pod downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 03:43:51.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2261" for this suite. 01/10/23 03:43:51.923
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":55,"skipped":852,"failed":0}
------------------------------
• [4.317 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:43:47.615
    Jan 10 03:43:47.615: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:43:47.616
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:47.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:47.825
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 01/10/23 03:43:47.846
    Jan 10 03:43:47.877: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7" in namespace "projected-2261" to be "Succeeded or Failed"
    Jan 10 03:43:47.891: INFO: Pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.856196ms
    Jan 10 03:43:49.895: INFO: Pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018090102s
    Jan 10 03:43:51.894: INFO: Pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017293387s
    STEP: Saw pod success 01/10/23 03:43:51.894
    Jan 10 03:43:51.894: INFO: Pod "downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7" satisfied condition "Succeeded or Failed"
    Jan 10 03:43:51.897: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7 container client-container: <nil>
    STEP: delete the pod 01/10/23 03:43:51.904
    Jan 10 03:43:51.915: INFO: Waiting for pod downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7 to disappear
    Jan 10 03:43:51.918: INFO: Pod downwardapi-volume-65068b76-ea63-4242-a489-b4054456d5c7 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 03:43:51.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2261" for this suite. 01/10/23 03:43:51.923
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:43:51.935
Jan 10 03:43:51.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename runtimeclass 01/10/23 03:43:51.936
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:51.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:51.975
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 10 03:43:51.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6706" for this suite. 01/10/23 03:43:51.999
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":56,"skipped":879,"failed":0}
------------------------------
• [0.090 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:43:51.935
    Jan 10 03:43:51.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename runtimeclass 01/10/23 03:43:51.936
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:51.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:51.975
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 10 03:43:51.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6706" for this suite. 01/10/23 03:43:51.999
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:43:52.038
Jan 10 03:43:52.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-probe 01/10/23 03:43:52.042
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:52.137
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:52.181
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df in namespace container-probe-6074 01/10/23 03:43:52.189
Jan 10 03:43:52.203: INFO: Waiting up to 5m0s for pod "busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df" in namespace "container-probe-6074" to be "not pending"
Jan 10 03:43:52.211: INFO: Pod "busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df": Phase="Pending", Reason="", readiness=false. Elapsed: 8.029934ms
Jan 10 03:43:54.215: INFO: Pod "busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df": Phase="Running", Reason="", readiness=true. Elapsed: 2.011767794s
Jan 10 03:43:54.215: INFO: Pod "busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df" satisfied condition "not pending"
Jan 10 03:43:54.215: INFO: Started pod busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df in namespace container-probe-6074
STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 03:43:54.215
Jan 10 03:43:54.217: INFO: Initial restart count of pod busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df is 0
STEP: deleting the pod 01/10/23 03:47:54.818
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 10 03:47:54.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6074" for this suite. 01/10/23 03:47:54.862
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":57,"skipped":920,"failed":0}
------------------------------
• [SLOW TEST] [242.838 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:43:52.038
    Jan 10 03:43:52.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-probe 01/10/23 03:43:52.042
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:43:52.137
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:43:52.181
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df in namespace container-probe-6074 01/10/23 03:43:52.189
    Jan 10 03:43:52.203: INFO: Waiting up to 5m0s for pod "busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df" in namespace "container-probe-6074" to be "not pending"
    Jan 10 03:43:52.211: INFO: Pod "busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df": Phase="Pending", Reason="", readiness=false. Elapsed: 8.029934ms
    Jan 10 03:43:54.215: INFO: Pod "busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df": Phase="Running", Reason="", readiness=true. Elapsed: 2.011767794s
    Jan 10 03:43:54.215: INFO: Pod "busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df" satisfied condition "not pending"
    Jan 10 03:43:54.215: INFO: Started pod busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df in namespace container-probe-6074
    STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 03:43:54.215
    Jan 10 03:43:54.217: INFO: Initial restart count of pod busybox-6f253150-56e3-45a4-a0d4-c71faa98b2df is 0
    STEP: deleting the pod 01/10/23 03:47:54.818
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 10 03:47:54.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6074" for this suite. 01/10/23 03:47:54.862
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:47:54.882
Jan 10 03:47:54.882: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename endpointslice 01/10/23 03:47:54.884
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:47:54.952
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:47:54.965
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 01/10/23 03:48:00.311
STEP: referencing matching pods with named port 01/10/23 03:48:05.318
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 01/10/23 03:48:10.328
STEP: recreating EndpointSlices after they've been deleted 01/10/23 03:48:15.34
Jan 10 03:48:15.358: INFO: EndpointSlice for Service endpointslice-660/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jan 10 03:48:25.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-660" for this suite. 01/10/23 03:48:25.381
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":58,"skipped":974,"failed":0}
------------------------------
• [SLOW TEST] [30.535 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:47:54.882
    Jan 10 03:47:54.882: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename endpointslice 01/10/23 03:47:54.884
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:47:54.952
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:47:54.965
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 01/10/23 03:48:00.311
    STEP: referencing matching pods with named port 01/10/23 03:48:05.318
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 01/10/23 03:48:10.328
    STEP: recreating EndpointSlices after they've been deleted 01/10/23 03:48:15.34
    Jan 10 03:48:15.358: INFO: EndpointSlice for Service endpointslice-660/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jan 10 03:48:25.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-660" for this suite. 01/10/23 03:48:25.381
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:48:25.42
Jan 10 03:48:25.420: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 03:48:25.421
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:25.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:25.515
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 01/10/23 03:48:25.534
Jan 10 03:48:25.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9" in namespace "downward-api-1101" to be "Succeeded or Failed"
Jan 10 03:48:25.684: INFO: Pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 98.564556ms
Jan 10 03:48:27.688: INFO: Pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101983782s
Jan 10 03:48:29.689: INFO: Pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.103621924s
STEP: Saw pod success 01/10/23 03:48:29.69
Jan 10 03:48:29.690: INFO: Pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9" satisfied condition "Succeeded or Failed"
Jan 10 03:48:29.692: INFO: Trying to get logs from node cncf-wk3 pod downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9 container client-container: <nil>
STEP: delete the pod 01/10/23 03:48:29.706
Jan 10 03:48:29.717: INFO: Waiting for pod downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9 to disappear
Jan 10 03:48:29.719: INFO: Pod downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 03:48:29.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1101" for this suite. 01/10/23 03:48:29.723
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":59,"skipped":1008,"failed":0}
------------------------------
• [4.306 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:48:25.42
    Jan 10 03:48:25.420: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 03:48:25.421
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:25.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:25.515
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 01/10/23 03:48:25.534
    Jan 10 03:48:25.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9" in namespace "downward-api-1101" to be "Succeeded or Failed"
    Jan 10 03:48:25.684: INFO: Pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 98.564556ms
    Jan 10 03:48:27.688: INFO: Pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101983782s
    Jan 10 03:48:29.689: INFO: Pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.103621924s
    STEP: Saw pod success 01/10/23 03:48:29.69
    Jan 10 03:48:29.690: INFO: Pod "downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9" satisfied condition "Succeeded or Failed"
    Jan 10 03:48:29.692: INFO: Trying to get logs from node cncf-wk3 pod downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9 container client-container: <nil>
    STEP: delete the pod 01/10/23 03:48:29.706
    Jan 10 03:48:29.717: INFO: Waiting for pod downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9 to disappear
    Jan 10 03:48:29.719: INFO: Pod downwardapi-volume-2134d2ac-e9ff-428d-bf42-1be513e05bd9 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 03:48:29.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1101" for this suite. 01/10/23 03:48:29.723
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:48:29.727
Jan 10 03:48:29.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 03:48:29.728
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:29.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:29.759
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Jan 10 03:48:29.763: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/10/23 03:48:34.213
Jan 10 03:48:34.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 create -f -'
Jan 10 03:48:34.903: INFO: stderr: ""
Jan 10 03:48:34.903: INFO: stdout: "e2e-test-crd-publish-openapi-6604-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jan 10 03:48:34.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 delete e2e-test-crd-publish-openapi-6604-crds test-cr'
Jan 10 03:48:34.976: INFO: stderr: ""
Jan 10 03:48:34.976: INFO: stdout: "e2e-test-crd-publish-openapi-6604-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Jan 10 03:48:34.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 apply -f -'
Jan 10 03:48:35.215: INFO: stderr: ""
Jan 10 03:48:35.216: INFO: stdout: "e2e-test-crd-publish-openapi-6604-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jan 10 03:48:35.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 delete e2e-test-crd-publish-openapi-6604-crds test-cr'
Jan 10 03:48:35.287: INFO: stderr: ""
Jan 10 03:48:35.287: INFO: stdout: "e2e-test-crd-publish-openapi-6604-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 01/10/23 03:48:35.287
Jan 10 03:48:35.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 explain e2e-test-crd-publish-openapi-6604-crds'
Jan 10 03:48:35.516: INFO: stderr: ""
Jan 10 03:48:35.516: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6604-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:48:39.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4485" for this suite. 01/10/23 03:48:39.881
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":60,"skipped":1026,"failed":0}
------------------------------
• [SLOW TEST] [10.160 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:48:29.727
    Jan 10 03:48:29.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 03:48:29.728
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:29.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:29.759
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Jan 10 03:48:29.763: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/10/23 03:48:34.213
    Jan 10 03:48:34.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 create -f -'
    Jan 10 03:48:34.903: INFO: stderr: ""
    Jan 10 03:48:34.903: INFO: stdout: "e2e-test-crd-publish-openapi-6604-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Jan 10 03:48:34.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 delete e2e-test-crd-publish-openapi-6604-crds test-cr'
    Jan 10 03:48:34.976: INFO: stderr: ""
    Jan 10 03:48:34.976: INFO: stdout: "e2e-test-crd-publish-openapi-6604-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Jan 10 03:48:34.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 apply -f -'
    Jan 10 03:48:35.215: INFO: stderr: ""
    Jan 10 03:48:35.216: INFO: stdout: "e2e-test-crd-publish-openapi-6604-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Jan 10 03:48:35.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 delete e2e-test-crd-publish-openapi-6604-crds test-cr'
    Jan 10 03:48:35.287: INFO: stderr: ""
    Jan 10 03:48:35.287: INFO: stdout: "e2e-test-crd-publish-openapi-6604-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 01/10/23 03:48:35.287
    Jan 10 03:48:35.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-4485 explain e2e-test-crd-publish-openapi-6604-crds'
    Jan 10 03:48:35.516: INFO: stderr: ""
    Jan 10 03:48:35.516: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6604-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:48:39.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4485" for this suite. 01/10/23 03:48:39.881
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:48:39.889
Jan 10 03:48:39.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename limitrange 01/10/23 03:48:39.89
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:39.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:39.912
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 01/10/23 03:48:39.926
STEP: Setting up watch 01/10/23 03:48:39.926
STEP: Submitting a LimitRange 01/10/23 03:48:40.042
STEP: Verifying LimitRange creation was observed 01/10/23 03:48:40.048
STEP: Fetching the LimitRange to ensure it has proper values 01/10/23 03:48:40.049
Jan 10 03:48:40.051: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jan 10 03:48:40.051: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 01/10/23 03:48:40.051
STEP: Ensuring Pod has resource requirements applied from LimitRange 01/10/23 03:48:40.056
Jan 10 03:48:40.059: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jan 10 03:48:40.059: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 01/10/23 03:48:40.059
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 01/10/23 03:48:40.074
Jan 10 03:48:40.082: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Jan 10 03:48:40.082: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 01/10/23 03:48:40.082
STEP: Failing to create a Pod with more than max resources 01/10/23 03:48:40.086
STEP: Updating a LimitRange 01/10/23 03:48:40.089
STEP: Verifying LimitRange updating is effective 01/10/23 03:48:40.108
STEP: Creating a Pod with less than former min resources 01/10/23 03:48:42.116
STEP: Failing to create a Pod with more than max resources 01/10/23 03:48:42.174
STEP: Deleting a LimitRange 01/10/23 03:48:42.218
STEP: Verifying the LimitRange was deleted 01/10/23 03:48:42.291
Jan 10 03:48:47.298: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 01/10/23 03:48:47.298
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Jan 10 03:48:47.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-8815" for this suite. 01/10/23 03:48:47.319
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":61,"skipped":1055,"failed":0}
------------------------------
• [SLOW TEST] [7.447 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:48:39.889
    Jan 10 03:48:39.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename limitrange 01/10/23 03:48:39.89
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:39.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:39.912
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 01/10/23 03:48:39.926
    STEP: Setting up watch 01/10/23 03:48:39.926
    STEP: Submitting a LimitRange 01/10/23 03:48:40.042
    STEP: Verifying LimitRange creation was observed 01/10/23 03:48:40.048
    STEP: Fetching the LimitRange to ensure it has proper values 01/10/23 03:48:40.049
    Jan 10 03:48:40.051: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Jan 10 03:48:40.051: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 01/10/23 03:48:40.051
    STEP: Ensuring Pod has resource requirements applied from LimitRange 01/10/23 03:48:40.056
    Jan 10 03:48:40.059: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Jan 10 03:48:40.059: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 01/10/23 03:48:40.059
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 01/10/23 03:48:40.074
    Jan 10 03:48:40.082: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Jan 10 03:48:40.082: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 01/10/23 03:48:40.082
    STEP: Failing to create a Pod with more than max resources 01/10/23 03:48:40.086
    STEP: Updating a LimitRange 01/10/23 03:48:40.089
    STEP: Verifying LimitRange updating is effective 01/10/23 03:48:40.108
    STEP: Creating a Pod with less than former min resources 01/10/23 03:48:42.116
    STEP: Failing to create a Pod with more than max resources 01/10/23 03:48:42.174
    STEP: Deleting a LimitRange 01/10/23 03:48:42.218
    STEP: Verifying the LimitRange was deleted 01/10/23 03:48:42.291
    Jan 10 03:48:47.298: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 01/10/23 03:48:47.298
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Jan 10 03:48:47.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-8815" for this suite. 01/10/23 03:48:47.319
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:48:47.337
Jan 10 03:48:47.337: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:48:47.338
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:47.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:47.383
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-a8124e3d-7edb-447d-8473-fecb483dceb9 01/10/23 03:48:47.391
STEP: Creating a pod to test consume configMaps 01/10/23 03:48:47.4
Jan 10 03:48:47.423: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4" in namespace "projected-4822" to be "Succeeded or Failed"
Jan 10 03:48:47.449: INFO: Pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.369809ms
Jan 10 03:48:49.452: INFO: Pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028703055s
Jan 10 03:48:51.453: INFO: Pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029406927s
STEP: Saw pod success 01/10/23 03:48:51.453
Jan 10 03:48:51.453: INFO: Pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4" satisfied condition "Succeeded or Failed"
Jan 10 03:48:51.455: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 03:48:51.469
Jan 10 03:48:51.479: INFO: Waiting for pod pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4 to disappear
Jan 10 03:48:51.483: INFO: Pod pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 03:48:51.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4822" for this suite. 01/10/23 03:48:51.487
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":62,"skipped":1064,"failed":0}
------------------------------
• [4.154 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:48:47.337
    Jan 10 03:48:47.337: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:48:47.338
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:47.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:47.383
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-a8124e3d-7edb-447d-8473-fecb483dceb9 01/10/23 03:48:47.391
    STEP: Creating a pod to test consume configMaps 01/10/23 03:48:47.4
    Jan 10 03:48:47.423: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4" in namespace "projected-4822" to be "Succeeded or Failed"
    Jan 10 03:48:47.449: INFO: Pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.369809ms
    Jan 10 03:48:49.452: INFO: Pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028703055s
    Jan 10 03:48:51.453: INFO: Pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029406927s
    STEP: Saw pod success 01/10/23 03:48:51.453
    Jan 10 03:48:51.453: INFO: Pod "pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4" satisfied condition "Succeeded or Failed"
    Jan 10 03:48:51.455: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 03:48:51.469
    Jan 10 03:48:51.479: INFO: Waiting for pod pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4 to disappear
    Jan 10 03:48:51.483: INFO: Pod pod-projected-configmaps-4619222b-27f6-4c52-8916-329cf3ba43b4 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 03:48:51.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4822" for this suite. 01/10/23 03:48:51.487
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:48:51.494
Jan 10 03:48:51.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 03:48:51.495
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:51.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:51.527
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1128 01/10/23 03:48:51.53
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 01/10/23 03:48:51.553
STEP: creating service externalsvc in namespace services-1128 01/10/23 03:48:51.554
STEP: creating replication controller externalsvc in namespace services-1128 01/10/23 03:48:51.582
I0110 03:48:51.600496      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1128, replica count: 2
I0110 03:48:54.650810      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 01/10/23 03:48:54.653
Jan 10 03:48:54.663: INFO: Creating new exec pod
Jan 10 03:48:54.678: INFO: Waiting up to 5m0s for pod "execpodjh55v" in namespace "services-1128" to be "running"
Jan 10 03:48:54.693: INFO: Pod "execpodjh55v": Phase="Pending", Reason="", readiness=false. Elapsed: 14.741308ms
Jan 10 03:48:56.696: INFO: Pod "execpodjh55v": Phase="Running", Reason="", readiness=true. Elapsed: 2.018319481s
Jan 10 03:48:56.696: INFO: Pod "execpodjh55v" satisfied condition "running"
Jan 10 03:48:56.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1128 exec execpodjh55v -- /bin/sh -x -c nslookup clusterip-service.services-1128.svc.cluster.local'
Jan 10 03:48:56.894: INFO: stderr: "+ nslookup clusterip-service.services-1128.svc.cluster.local\n"
Jan 10 03:48:56.894: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nclusterip-service.services-1128.svc.cluster.local\tcanonical name = externalsvc.services-1128.svc.cluster.local.\nName:\texternalsvc.services-1128.svc.cluster.local\nAddress: 10.43.233.56\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1128, will wait for the garbage collector to delete the pods 01/10/23 03:48:56.894
Jan 10 03:48:56.966: INFO: Deleting ReplicationController externalsvc took: 16.901186ms
Jan 10 03:48:57.067: INFO: Terminating ReplicationController externalsvc pods took: 101.199684ms
Jan 10 03:48:58.984: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 03:48:59.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1128" for this suite. 01/10/23 03:48:59.005
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":63,"skipped":1072,"failed":0}
------------------------------
• [SLOW TEST] [7.518 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:48:51.494
    Jan 10 03:48:51.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 03:48:51.495
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:51.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:51.527
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1128 01/10/23 03:48:51.53
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 01/10/23 03:48:51.553
    STEP: creating service externalsvc in namespace services-1128 01/10/23 03:48:51.554
    STEP: creating replication controller externalsvc in namespace services-1128 01/10/23 03:48:51.582
    I0110 03:48:51.600496      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1128, replica count: 2
    I0110 03:48:54.650810      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 01/10/23 03:48:54.653
    Jan 10 03:48:54.663: INFO: Creating new exec pod
    Jan 10 03:48:54.678: INFO: Waiting up to 5m0s for pod "execpodjh55v" in namespace "services-1128" to be "running"
    Jan 10 03:48:54.693: INFO: Pod "execpodjh55v": Phase="Pending", Reason="", readiness=false. Elapsed: 14.741308ms
    Jan 10 03:48:56.696: INFO: Pod "execpodjh55v": Phase="Running", Reason="", readiness=true. Elapsed: 2.018319481s
    Jan 10 03:48:56.696: INFO: Pod "execpodjh55v" satisfied condition "running"
    Jan 10 03:48:56.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1128 exec execpodjh55v -- /bin/sh -x -c nslookup clusterip-service.services-1128.svc.cluster.local'
    Jan 10 03:48:56.894: INFO: stderr: "+ nslookup clusterip-service.services-1128.svc.cluster.local\n"
    Jan 10 03:48:56.894: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nclusterip-service.services-1128.svc.cluster.local\tcanonical name = externalsvc.services-1128.svc.cluster.local.\nName:\texternalsvc.services-1128.svc.cluster.local\nAddress: 10.43.233.56\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-1128, will wait for the garbage collector to delete the pods 01/10/23 03:48:56.894
    Jan 10 03:48:56.966: INFO: Deleting ReplicationController externalsvc took: 16.901186ms
    Jan 10 03:48:57.067: INFO: Terminating ReplicationController externalsvc pods took: 101.199684ms
    Jan 10 03:48:58.984: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 03:48:59.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1128" for this suite. 01/10/23 03:48:59.005
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:48:59.015
Jan 10 03:48:59.015: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename csistoragecapacity 01/10/23 03:48:59.016
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:59.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:59.049
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 01/10/23 03:48:59.053
STEP: getting /apis/storage.k8s.io 01/10/23 03:48:59.055
STEP: getting /apis/storage.k8s.io/v1 01/10/23 03:48:59.056
STEP: creating 01/10/23 03:48:59.058
STEP: watching 01/10/23 03:48:59.087
Jan 10 03:48:59.087: INFO: starting watch
STEP: getting 01/10/23 03:48:59.101
STEP: listing in namespace 01/10/23 03:48:59.105
STEP: listing across namespaces 01/10/23 03:48:59.112
STEP: patching 01/10/23 03:48:59.122
STEP: updating 01/10/23 03:48:59.128
Jan 10 03:48:59.135: INFO: waiting for watch events with expected annotations in namespace
Jan 10 03:48:59.135: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 01/10/23 03:48:59.135
STEP: deleting a collection 01/10/23 03:48:59.146
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Jan 10 03:48:59.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-7273" for this suite. 01/10/23 03:48:59.158
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":64,"skipped":1083,"failed":0}
------------------------------
• [0.147 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:48:59.015
    Jan 10 03:48:59.015: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename csistoragecapacity 01/10/23 03:48:59.016
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:59.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:59.049
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 01/10/23 03:48:59.053
    STEP: getting /apis/storage.k8s.io 01/10/23 03:48:59.055
    STEP: getting /apis/storage.k8s.io/v1 01/10/23 03:48:59.056
    STEP: creating 01/10/23 03:48:59.058
    STEP: watching 01/10/23 03:48:59.087
    Jan 10 03:48:59.087: INFO: starting watch
    STEP: getting 01/10/23 03:48:59.101
    STEP: listing in namespace 01/10/23 03:48:59.105
    STEP: listing across namespaces 01/10/23 03:48:59.112
    STEP: patching 01/10/23 03:48:59.122
    STEP: updating 01/10/23 03:48:59.128
    Jan 10 03:48:59.135: INFO: waiting for watch events with expected annotations in namespace
    Jan 10 03:48:59.135: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 01/10/23 03:48:59.135
    STEP: deleting a collection 01/10/23 03:48:59.146
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Jan 10 03:48:59.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-7273" for this suite. 01/10/23 03:48:59.158
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:48:59.164
Jan 10 03:48:59.164: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-probe 01/10/23 03:48:59.169
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:59.234
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:59.238
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef in namespace container-probe-2069 01/10/23 03:48:59.243
Jan 10 03:48:59.256: INFO: Waiting up to 5m0s for pod "test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef" in namespace "container-probe-2069" to be "not pending"
Jan 10 03:48:59.266: INFO: Pod "test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef": Phase="Pending", Reason="", readiness=false. Elapsed: 10.65262ms
Jan 10 03:49:01.285: INFO: Pod "test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef": Phase="Running", Reason="", readiness=true. Elapsed: 2.029613111s
Jan 10 03:49:01.285: INFO: Pod "test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef" satisfied condition "not pending"
Jan 10 03:49:01.285: INFO: Started pod test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef in namespace container-probe-2069
STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 03:49:01.285
Jan 10 03:49:01.295: INFO: Initial restart count of pod test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef is 0
STEP: deleting the pod 01/10/23 03:53:01.818
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 10 03:53:01.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2069" for this suite. 01/10/23 03:53:01.873
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":65,"skipped":1084,"failed":0}
------------------------------
• [SLOW TEST] [242.731 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:48:59.164
    Jan 10 03:48:59.164: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-probe 01/10/23 03:48:59.169
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:48:59.234
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:48:59.238
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef in namespace container-probe-2069 01/10/23 03:48:59.243
    Jan 10 03:48:59.256: INFO: Waiting up to 5m0s for pod "test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef" in namespace "container-probe-2069" to be "not pending"
    Jan 10 03:48:59.266: INFO: Pod "test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef": Phase="Pending", Reason="", readiness=false. Elapsed: 10.65262ms
    Jan 10 03:49:01.285: INFO: Pod "test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef": Phase="Running", Reason="", readiness=true. Elapsed: 2.029613111s
    Jan 10 03:49:01.285: INFO: Pod "test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef" satisfied condition "not pending"
    Jan 10 03:49:01.285: INFO: Started pod test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef in namespace container-probe-2069
    STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 03:49:01.285
    Jan 10 03:49:01.295: INFO: Initial restart count of pod test-webserver-3cd26441-abdc-4c11-87c5-f5e28d50aaef is 0
    STEP: deleting the pod 01/10/23 03:53:01.818
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 10 03:53:01.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2069" for this suite. 01/10/23 03:53:01.873
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:01.897
Jan 10 03:53:01.897: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename job 01/10/23 03:53:01.898
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:01.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:02.011
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 01/10/23 03:53:02.034
STEP: Ensuring job reaches completions 01/10/23 03:53:02.074
STEP: Ensuring pods with index for job exist 01/10/23 03:53:12.095
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 10 03:53:12.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1116" for this suite. 01/10/23 03:53:12.123
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":66,"skipped":1098,"failed":0}
------------------------------
• [SLOW TEST] [10.241 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:01.897
    Jan 10 03:53:01.897: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename job 01/10/23 03:53:01.898
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:01.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:02.011
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 01/10/23 03:53:02.034
    STEP: Ensuring job reaches completions 01/10/23 03:53:02.074
    STEP: Ensuring pods with index for job exist 01/10/23 03:53:12.095
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 10 03:53:12.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1116" for this suite. 01/10/23 03:53:12.123
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:12.139
Jan 10 03:53:12.140: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 03:53:12.14
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:12.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:12.295
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 01/10/23 03:53:12.357
STEP: Getting a ResourceQuota 01/10/23 03:53:12.387
STEP: Listing all ResourceQuotas with LabelSelector 01/10/23 03:53:12.4
STEP: Patching the ResourceQuota 01/10/23 03:53:12.407
STEP: Deleting a Collection of ResourceQuotas 01/10/23 03:53:12.438
STEP: Verifying the deleted ResourceQuota 01/10/23 03:53:12.485
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 03:53:12.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3298" for this suite. 01/10/23 03:53:12.53
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":67,"skipped":1098,"failed":0}
------------------------------
• [0.432 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:12.139
    Jan 10 03:53:12.140: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 03:53:12.14
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:12.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:12.295
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 01/10/23 03:53:12.357
    STEP: Getting a ResourceQuota 01/10/23 03:53:12.387
    STEP: Listing all ResourceQuotas with LabelSelector 01/10/23 03:53:12.4
    STEP: Patching the ResourceQuota 01/10/23 03:53:12.407
    STEP: Deleting a Collection of ResourceQuotas 01/10/23 03:53:12.438
    STEP: Verifying the deleted ResourceQuota 01/10/23 03:53:12.485
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 03:53:12.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3298" for this suite. 01/10/23 03:53:12.53
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:12.576
Jan 10 03:53:12.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 03:53:12.578
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:12.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:12.701
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 01/10/23 03:53:12.713
Jan 10 03:53:12.713: INFO: namespace kubectl-6122
Jan 10 03:53:12.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6122 create -f -'
Jan 10 03:53:13.621: INFO: stderr: ""
Jan 10 03:53:13.621: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 01/10/23 03:53:13.621
Jan 10 03:53:14.625: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 03:53:14.625: INFO: Found 0 / 1
Jan 10 03:53:15.625: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 03:53:15.625: INFO: Found 1 / 1
Jan 10 03:53:15.625: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 10 03:53:15.628: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 03:53:15.628: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 10 03:53:15.628: INFO: wait on agnhost-primary startup in kubectl-6122 
Jan 10 03:53:15.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6122 logs agnhost-primary-9sxqf agnhost-primary'
Jan 10 03:53:15.748: INFO: stderr: ""
Jan 10 03:53:15.748: INFO: stdout: "Paused\n"
STEP: exposing RC 01/10/23 03:53:15.748
Jan 10 03:53:15.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6122 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Jan 10 03:53:15.845: INFO: stderr: ""
Jan 10 03:53:15.845: INFO: stdout: "service/rm2 exposed\n"
Jan 10 03:53:15.865: INFO: Service rm2 in namespace kubectl-6122 found.
STEP: exposing service 01/10/23 03:53:17.869
Jan 10 03:53:17.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6122 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Jan 10 03:53:17.985: INFO: stderr: ""
Jan 10 03:53:17.985: INFO: stdout: "service/rm3 exposed\n"
Jan 10 03:53:17.992: INFO: Service rm3 in namespace kubectl-6122 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 03:53:19.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6122" for this suite. 01/10/23 03:53:20
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":68,"skipped":1116,"failed":0}
------------------------------
• [SLOW TEST] [7.428 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:12.576
    Jan 10 03:53:12.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 03:53:12.578
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:12.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:12.701
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 01/10/23 03:53:12.713
    Jan 10 03:53:12.713: INFO: namespace kubectl-6122
    Jan 10 03:53:12.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6122 create -f -'
    Jan 10 03:53:13.621: INFO: stderr: ""
    Jan 10 03:53:13.621: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 01/10/23 03:53:13.621
    Jan 10 03:53:14.625: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 03:53:14.625: INFO: Found 0 / 1
    Jan 10 03:53:15.625: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 03:53:15.625: INFO: Found 1 / 1
    Jan 10 03:53:15.625: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Jan 10 03:53:15.628: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 03:53:15.628: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jan 10 03:53:15.628: INFO: wait on agnhost-primary startup in kubectl-6122 
    Jan 10 03:53:15.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6122 logs agnhost-primary-9sxqf agnhost-primary'
    Jan 10 03:53:15.748: INFO: stderr: ""
    Jan 10 03:53:15.748: INFO: stdout: "Paused\n"
    STEP: exposing RC 01/10/23 03:53:15.748
    Jan 10 03:53:15.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6122 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Jan 10 03:53:15.845: INFO: stderr: ""
    Jan 10 03:53:15.845: INFO: stdout: "service/rm2 exposed\n"
    Jan 10 03:53:15.865: INFO: Service rm2 in namespace kubectl-6122 found.
    STEP: exposing service 01/10/23 03:53:17.869
    Jan 10 03:53:17.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6122 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Jan 10 03:53:17.985: INFO: stderr: ""
    Jan 10 03:53:17.985: INFO: stdout: "service/rm3 exposed\n"
    Jan 10 03:53:17.992: INFO: Service rm3 in namespace kubectl-6122 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 03:53:19.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6122" for this suite. 01/10/23 03:53:20
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:20.005
Jan 10 03:53:20.005: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 03:53:20.006
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:20.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:20.034
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-0788d014-a132-4762-b4a3-10366bc0e599 01/10/23 03:53:20.048
STEP: Creating secret with name s-test-opt-upd-9077f607-f89e-4e3c-9c6d-39c49ee4d8f3 01/10/23 03:53:20.066
STEP: Creating the pod 01/10/23 03:53:20.07
Jan 10 03:53:20.080: INFO: Waiting up to 5m0s for pod "pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9" in namespace "secrets-8035" to be "running and ready"
Jan 10 03:53:20.087: INFO: Pod "pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.119388ms
Jan 10 03:53:20.087: INFO: The phase of Pod pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:53:22.091: INFO: Pod "pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9": Phase="Running", Reason="", readiness=true. Elapsed: 2.010440677s
Jan 10 03:53:22.091: INFO: The phase of Pod pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9 is Running (Ready = true)
Jan 10 03:53:22.091: INFO: Pod "pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-0788d014-a132-4762-b4a3-10366bc0e599 01/10/23 03:53:22.113
STEP: Updating secret s-test-opt-upd-9077f607-f89e-4e3c-9c6d-39c49ee4d8f3 01/10/23 03:53:22.116
STEP: Creating secret with name s-test-opt-create-13c776a1-a04e-486d-918a-3aba8849858e 01/10/23 03:53:22.121
STEP: waiting to observe update in volume 01/10/23 03:53:22.126
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 03:53:24.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8035" for this suite. 01/10/23 03:53:24.163
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":69,"skipped":1124,"failed":0}
------------------------------
• [4.165 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:20.005
    Jan 10 03:53:20.005: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 03:53:20.006
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:20.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:20.034
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-0788d014-a132-4762-b4a3-10366bc0e599 01/10/23 03:53:20.048
    STEP: Creating secret with name s-test-opt-upd-9077f607-f89e-4e3c-9c6d-39c49ee4d8f3 01/10/23 03:53:20.066
    STEP: Creating the pod 01/10/23 03:53:20.07
    Jan 10 03:53:20.080: INFO: Waiting up to 5m0s for pod "pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9" in namespace "secrets-8035" to be "running and ready"
    Jan 10 03:53:20.087: INFO: Pod "pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.119388ms
    Jan 10 03:53:20.087: INFO: The phase of Pod pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:53:22.091: INFO: Pod "pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9": Phase="Running", Reason="", readiness=true. Elapsed: 2.010440677s
    Jan 10 03:53:22.091: INFO: The phase of Pod pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9 is Running (Ready = true)
    Jan 10 03:53:22.091: INFO: Pod "pod-secrets-9fe46f63-5023-41aa-a2f2-1b25be301de9" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-0788d014-a132-4762-b4a3-10366bc0e599 01/10/23 03:53:22.113
    STEP: Updating secret s-test-opt-upd-9077f607-f89e-4e3c-9c6d-39c49ee4d8f3 01/10/23 03:53:22.116
    STEP: Creating secret with name s-test-opt-create-13c776a1-a04e-486d-918a-3aba8849858e 01/10/23 03:53:22.121
    STEP: waiting to observe update in volume 01/10/23 03:53:22.126
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 03:53:24.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8035" for this suite. 01/10/23 03:53:24.163
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:24.176
Jan 10 03:53:24.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename job 01/10/23 03:53:24.177
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:24.203
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:24.208
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 01/10/23 03:53:24.211
STEP: Ensuring job reaches completions 01/10/23 03:53:24.218
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 10 03:53:40.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7506" for this suite. 01/10/23 03:53:40.224
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":70,"skipped":1143,"failed":0}
------------------------------
• [SLOW TEST] [16.053 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:24.176
    Jan 10 03:53:24.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename job 01/10/23 03:53:24.177
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:24.203
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:24.208
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 01/10/23 03:53:24.211
    STEP: Ensuring job reaches completions 01/10/23 03:53:24.218
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 10 03:53:40.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7506" for this suite. 01/10/23 03:53:40.224
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:40.238
Jan 10 03:53:40.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename certificates 01/10/23 03:53:40.243
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:40.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:40.29
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 01/10/23 03:53:40.846
STEP: getting /apis/certificates.k8s.io 01/10/23 03:53:40.848
STEP: getting /apis/certificates.k8s.io/v1 01/10/23 03:53:40.849
STEP: creating 01/10/23 03:53:40.85
STEP: getting 01/10/23 03:53:40.873
STEP: listing 01/10/23 03:53:40.877
STEP: watching 01/10/23 03:53:40.88
Jan 10 03:53:40.881: INFO: starting watch
STEP: patching 01/10/23 03:53:40.882
STEP: updating 01/10/23 03:53:40.888
Jan 10 03:53:40.892: INFO: waiting for watch events with expected annotations
Jan 10 03:53:40.892: INFO: saw patched and updated annotations
STEP: getting /approval 01/10/23 03:53:40.892
STEP: patching /approval 01/10/23 03:53:40.896
STEP: updating /approval 01/10/23 03:53:40.902
STEP: getting /status 01/10/23 03:53:40.906
STEP: patching /status 01/10/23 03:53:40.908
STEP: updating /status 01/10/23 03:53:40.92
STEP: deleting 01/10/23 03:53:40.936
STEP: deleting a collection 01/10/23 03:53:40.952
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:53:40.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-5667" for this suite. 01/10/23 03:53:40.966
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":71,"skipped":1168,"failed":0}
------------------------------
• [0.735 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:40.238
    Jan 10 03:53:40.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename certificates 01/10/23 03:53:40.243
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:40.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:40.29
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 01/10/23 03:53:40.846
    STEP: getting /apis/certificates.k8s.io 01/10/23 03:53:40.848
    STEP: getting /apis/certificates.k8s.io/v1 01/10/23 03:53:40.849
    STEP: creating 01/10/23 03:53:40.85
    STEP: getting 01/10/23 03:53:40.873
    STEP: listing 01/10/23 03:53:40.877
    STEP: watching 01/10/23 03:53:40.88
    Jan 10 03:53:40.881: INFO: starting watch
    STEP: patching 01/10/23 03:53:40.882
    STEP: updating 01/10/23 03:53:40.888
    Jan 10 03:53:40.892: INFO: waiting for watch events with expected annotations
    Jan 10 03:53:40.892: INFO: saw patched and updated annotations
    STEP: getting /approval 01/10/23 03:53:40.892
    STEP: patching /approval 01/10/23 03:53:40.896
    STEP: updating /approval 01/10/23 03:53:40.902
    STEP: getting /status 01/10/23 03:53:40.906
    STEP: patching /status 01/10/23 03:53:40.908
    STEP: updating /status 01/10/23 03:53:40.92
    STEP: deleting 01/10/23 03:53:40.936
    STEP: deleting a collection 01/10/23 03:53:40.952
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:53:40.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-5667" for this suite. 01/10/23 03:53:40.966
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:40.978
Jan 10 03:53:40.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 01/10/23 03:53:40.98
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:41.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:41.032
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 01/10/23 03:53:41.036
STEP: Creating hostNetwork=false pod 01/10/23 03:53:41.036
Jan 10 03:53:41.060: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-7223" to be "running and ready"
Jan 10 03:53:41.063: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.143962ms
Jan 10 03:53:41.063: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:53:43.073: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012901493s
Jan 10 03:53:43.073: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:53:45.067: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007046305s
Jan 10 03:53:45.067: INFO: The phase of Pod test-pod is Running (Ready = true)
Jan 10 03:53:45.067: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 01/10/23 03:53:45.069
Jan 10 03:53:45.073: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-7223" to be "running and ready"
Jan 10 03:53:45.079: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.384221ms
Jan 10 03:53:45.079: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:53:47.084: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01060149s
Jan 10 03:53:47.084: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Jan 10 03:53:47.084: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 01/10/23 03:53:47.087
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 01/10/23 03:53:47.087
Jan 10 03:53:47.087: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.089: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.089: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jan 10 03:53:47.205: INFO: Exec stderr: ""
Jan 10 03:53:47.205: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.205: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.206: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.206: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jan 10 03:53:47.294: INFO: Exec stderr: ""
Jan 10 03:53:47.294: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.295: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.295: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jan 10 03:53:47.414: INFO: Exec stderr: ""
Jan 10 03:53:47.415: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.415: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.416: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.416: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jan 10 03:53:47.534: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 01/10/23 03:53:47.535
Jan 10 03:53:47.535: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.535: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.536: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.536: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jan 10 03:53:47.623: INFO: Exec stderr: ""
Jan 10 03:53:47.623: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.624: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.624: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.625: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jan 10 03:53:47.701: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 01/10/23 03:53:47.701
Jan 10 03:53:47.701: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.702: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.702: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jan 10 03:53:47.815: INFO: Exec stderr: ""
Jan 10 03:53:47.816: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.816: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.816: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jan 10 03:53:47.902: INFO: Exec stderr: ""
Jan 10 03:53:47.902: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.902: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.903: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.903: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jan 10 03:53:47.971: INFO: Exec stderr: ""
Jan 10 03:53:47.972: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:53:47.972: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:53:47.972: INFO: ExecWithOptions: Clientset creation
Jan 10 03:53:47.972: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jan 10 03:53:48.100: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Jan 10 03:53:48.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-7223" for this suite. 01/10/23 03:53:48.117
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":72,"skipped":1196,"failed":0}
------------------------------
• [SLOW TEST] [7.145 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:40.978
    Jan 10 03:53:40.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 01/10/23 03:53:40.98
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:41.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:41.032
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 01/10/23 03:53:41.036
    STEP: Creating hostNetwork=false pod 01/10/23 03:53:41.036
    Jan 10 03:53:41.060: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-7223" to be "running and ready"
    Jan 10 03:53:41.063: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.143962ms
    Jan 10 03:53:41.063: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:53:43.073: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012901493s
    Jan 10 03:53:43.073: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:53:45.067: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007046305s
    Jan 10 03:53:45.067: INFO: The phase of Pod test-pod is Running (Ready = true)
    Jan 10 03:53:45.067: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 01/10/23 03:53:45.069
    Jan 10 03:53:45.073: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-7223" to be "running and ready"
    Jan 10 03:53:45.079: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.384221ms
    Jan 10 03:53:45.079: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:53:47.084: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01060149s
    Jan 10 03:53:47.084: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Jan 10 03:53:47.084: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 01/10/23 03:53:47.087
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 01/10/23 03:53:47.087
    Jan 10 03:53:47.087: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.089: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.089: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jan 10 03:53:47.205: INFO: Exec stderr: ""
    Jan 10 03:53:47.205: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.205: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.206: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.206: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jan 10 03:53:47.294: INFO: Exec stderr: ""
    Jan 10 03:53:47.294: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.295: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.295: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jan 10 03:53:47.414: INFO: Exec stderr: ""
    Jan 10 03:53:47.415: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.415: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.416: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.416: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jan 10 03:53:47.534: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 01/10/23 03:53:47.535
    Jan 10 03:53:47.535: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.535: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.536: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.536: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Jan 10 03:53:47.623: INFO: Exec stderr: ""
    Jan 10 03:53:47.623: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.624: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.624: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.625: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Jan 10 03:53:47.701: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 01/10/23 03:53:47.701
    Jan 10 03:53:47.701: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.702: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.702: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jan 10 03:53:47.815: INFO: Exec stderr: ""
    Jan 10 03:53:47.816: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.816: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.816: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jan 10 03:53:47.902: INFO: Exec stderr: ""
    Jan 10 03:53:47.902: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.902: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.903: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.903: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jan 10 03:53:47.971: INFO: Exec stderr: ""
    Jan 10 03:53:47.972: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7223 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:53:47.972: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:53:47.972: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:53:47.972: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7223/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jan 10 03:53:48.100: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Jan 10 03:53:48.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-7223" for this suite. 01/10/23 03:53:48.117
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:48.131
Jan 10 03:53:48.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-runtime 01/10/23 03:53:48.132
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:48.165
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:48.176
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 01/10/23 03:53:48.183
STEP: wait for the container to reach Failed 01/10/23 03:53:48.199
STEP: get the container status 01/10/23 03:53:52.239
STEP: the container should be terminated 01/10/23 03:53:52.241
STEP: the termination message should be set 01/10/23 03:53:52.241
Jan 10 03:53:52.241: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 01/10/23 03:53:52.241
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 10 03:53:52.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-324" for this suite. 01/10/23 03:53:52.254
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":73,"skipped":1256,"failed":0}
------------------------------
• [4.127 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:48.131
    Jan 10 03:53:48.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-runtime 01/10/23 03:53:48.132
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:48.165
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:48.176
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 01/10/23 03:53:48.183
    STEP: wait for the container to reach Failed 01/10/23 03:53:48.199
    STEP: get the container status 01/10/23 03:53:52.239
    STEP: the container should be terminated 01/10/23 03:53:52.241
    STEP: the termination message should be set 01/10/23 03:53:52.241
    Jan 10 03:53:52.241: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 01/10/23 03:53:52.241
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 10 03:53:52.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-324" for this suite. 01/10/23 03:53:52.254
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:53:52.258
Jan 10 03:53:52.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename gc 01/10/23 03:53:52.26
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:52.3
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:52.31
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 01/10/23 03:53:52.35
STEP: delete the rc 01/10/23 03:53:57.382
STEP: wait for all pods to be garbage collected 01/10/23 03:53:57.396
STEP: Gathering metrics 01/10/23 03:54:02.402
W0110 03:54:02.406356      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 10 03:54:02.406: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 10 03:54:02.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6926" for this suite. 01/10/23 03:54:02.409
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":74,"skipped":1256,"failed":0}
------------------------------
• [SLOW TEST] [10.156 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:53:52.258
    Jan 10 03:53:52.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename gc 01/10/23 03:53:52.26
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:53:52.3
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:53:52.31
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 01/10/23 03:53:52.35
    STEP: delete the rc 01/10/23 03:53:57.382
    STEP: wait for all pods to be garbage collected 01/10/23 03:53:57.396
    STEP: Gathering metrics 01/10/23 03:54:02.402
    W0110 03:54:02.406356      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 10 03:54:02.406: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 10 03:54:02.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-6926" for this suite. 01/10/23 03:54:02.409
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:54:02.416
Jan 10 03:54:02.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-probe 01/10/23 03:54:02.423
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:54:02.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:54:02.463
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-572b5dd6-1709-4fce-a588-1b200a265b00 in namespace container-probe-1975 01/10/23 03:54:02.483
Jan 10 03:54:02.497: INFO: Waiting up to 5m0s for pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00" in namespace "container-probe-1975" to be "not pending"
Jan 10 03:54:02.506: INFO: Pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00": Phase="Pending", Reason="", readiness=false. Elapsed: 8.30056ms
Jan 10 03:54:04.514: INFO: Pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016412503s
Jan 10 03:54:06.512: INFO: Pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00": Phase="Running", Reason="", readiness=true. Elapsed: 4.01454146s
Jan 10 03:54:06.512: INFO: Pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00" satisfied condition "not pending"
Jan 10 03:54:06.512: INFO: Started pod busybox-572b5dd6-1709-4fce-a588-1b200a265b00 in namespace container-probe-1975
STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 03:54:06.512
Jan 10 03:54:06.519: INFO: Initial restart count of pod busybox-572b5dd6-1709-4fce-a588-1b200a265b00 is 0
Jan 10 03:54:54.615: INFO: Restart count of pod container-probe-1975/busybox-572b5dd6-1709-4fce-a588-1b200a265b00 is now 1 (48.095526804s elapsed)
STEP: deleting the pod 01/10/23 03:54:54.615
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 10 03:54:54.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1975" for this suite. 01/10/23 03:54:54.687
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":75,"skipped":1273,"failed":0}
------------------------------
• [SLOW TEST] [52.277 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:54:02.416
    Jan 10 03:54:02.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-probe 01/10/23 03:54:02.423
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:54:02.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:54:02.463
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-572b5dd6-1709-4fce-a588-1b200a265b00 in namespace container-probe-1975 01/10/23 03:54:02.483
    Jan 10 03:54:02.497: INFO: Waiting up to 5m0s for pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00" in namespace "container-probe-1975" to be "not pending"
    Jan 10 03:54:02.506: INFO: Pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00": Phase="Pending", Reason="", readiness=false. Elapsed: 8.30056ms
    Jan 10 03:54:04.514: INFO: Pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016412503s
    Jan 10 03:54:06.512: INFO: Pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00": Phase="Running", Reason="", readiness=true. Elapsed: 4.01454146s
    Jan 10 03:54:06.512: INFO: Pod "busybox-572b5dd6-1709-4fce-a588-1b200a265b00" satisfied condition "not pending"
    Jan 10 03:54:06.512: INFO: Started pod busybox-572b5dd6-1709-4fce-a588-1b200a265b00 in namespace container-probe-1975
    STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 03:54:06.512
    Jan 10 03:54:06.519: INFO: Initial restart count of pod busybox-572b5dd6-1709-4fce-a588-1b200a265b00 is 0
    Jan 10 03:54:54.615: INFO: Restart count of pod container-probe-1975/busybox-572b5dd6-1709-4fce-a588-1b200a265b00 is now 1 (48.095526804s elapsed)
    STEP: deleting the pod 01/10/23 03:54:54.615
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 10 03:54:54.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1975" for this suite. 01/10/23 03:54:54.687
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:54:54.694
Jan 10 03:54:54.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 03:54:54.695
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:54:54.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:54:54.777
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 01/10/23 03:54:54.78
Jan 10 03:54:54.780: INFO: Creating e2e-svc-a-ddvdk
Jan 10 03:54:54.789: INFO: Creating e2e-svc-b-w46jk
Jan 10 03:54:54.848: INFO: Creating e2e-svc-c-zq8fv
STEP: deleting service collection 01/10/23 03:54:54.896
Jan 10 03:54:55.031: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 03:54:55.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4118" for this suite. 01/10/23 03:54:55.044
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":76,"skipped":1283,"failed":0}
------------------------------
• [0.383 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:54:54.694
    Jan 10 03:54:54.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 03:54:54.695
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:54:54.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:54:54.777
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 01/10/23 03:54:54.78
    Jan 10 03:54:54.780: INFO: Creating e2e-svc-a-ddvdk
    Jan 10 03:54:54.789: INFO: Creating e2e-svc-b-w46jk
    Jan 10 03:54:54.848: INFO: Creating e2e-svc-c-zq8fv
    STEP: deleting service collection 01/10/23 03:54:54.896
    Jan 10 03:54:55.031: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 03:54:55.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4118" for this suite. 01/10/23 03:54:55.044
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:54:55.079
Jan 10 03:54:55.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename var-expansion 01/10/23 03:54:55.08
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:54:55.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:54:55.183
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 01/10/23 03:54:55.186
Jan 10 03:54:55.284: INFO: Waiting up to 5m0s for pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950" in namespace "var-expansion-6758" to be "Succeeded or Failed"
Jan 10 03:54:55.345: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950": Phase="Pending", Reason="", readiness=false. Elapsed: 60.309362ms
Jan 10 03:54:57.348: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063623032s
Jan 10 03:54:59.349: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950": Phase="Pending", Reason="", readiness=false. Elapsed: 4.064844632s
Jan 10 03:55:01.350: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.065953523s
STEP: Saw pod success 01/10/23 03:55:01.351
Jan 10 03:55:01.351: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950" satisfied condition "Succeeded or Failed"
Jan 10 03:55:01.353: INFO: Trying to get logs from node cncf-wk2 pod var-expansion-419c2864-1295-406b-9002-9c844c3ba950 container dapi-container: <nil>
STEP: delete the pod 01/10/23 03:55:01.425
Jan 10 03:55:01.447: INFO: Waiting for pod var-expansion-419c2864-1295-406b-9002-9c844c3ba950 to disappear
Jan 10 03:55:01.452: INFO: Pod var-expansion-419c2864-1295-406b-9002-9c844c3ba950 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 10 03:55:01.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6758" for this suite. 01/10/23 03:55:01.457
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":77,"skipped":1288,"failed":0}
------------------------------
• [SLOW TEST] [6.386 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:54:55.079
    Jan 10 03:54:55.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename var-expansion 01/10/23 03:54:55.08
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:54:55.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:54:55.183
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 01/10/23 03:54:55.186
    Jan 10 03:54:55.284: INFO: Waiting up to 5m0s for pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950" in namespace "var-expansion-6758" to be "Succeeded or Failed"
    Jan 10 03:54:55.345: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950": Phase="Pending", Reason="", readiness=false. Elapsed: 60.309362ms
    Jan 10 03:54:57.348: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063623032s
    Jan 10 03:54:59.349: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950": Phase="Pending", Reason="", readiness=false. Elapsed: 4.064844632s
    Jan 10 03:55:01.350: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.065953523s
    STEP: Saw pod success 01/10/23 03:55:01.351
    Jan 10 03:55:01.351: INFO: Pod "var-expansion-419c2864-1295-406b-9002-9c844c3ba950" satisfied condition "Succeeded or Failed"
    Jan 10 03:55:01.353: INFO: Trying to get logs from node cncf-wk2 pod var-expansion-419c2864-1295-406b-9002-9c844c3ba950 container dapi-container: <nil>
    STEP: delete the pod 01/10/23 03:55:01.425
    Jan 10 03:55:01.447: INFO: Waiting for pod var-expansion-419c2864-1295-406b-9002-9c844c3ba950 to disappear
    Jan 10 03:55:01.452: INFO: Pod var-expansion-419c2864-1295-406b-9002-9c844c3ba950 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 10 03:55:01.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6758" for this suite. 01/10/23 03:55:01.457
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:55:01.466
Jan 10 03:55:01.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replicaset 01/10/23 03:55:01.467
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:01.528
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:01.551
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Jan 10 03:55:01.622: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 10 03:55:06.626: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/10/23 03:55:06.626
STEP: Scaling up "test-rs" replicaset  01/10/23 03:55:06.627
Jan 10 03:55:06.640: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 01/10/23 03:55:06.64
W0110 03:55:06.659500      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jan 10 03:55:06.663: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 1, AvailableReplicas 1
Jan 10 03:55:06.720: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 1, AvailableReplicas 1
Jan 10 03:55:06.739: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 1, AvailableReplicas 1
Jan 10 03:55:06.757: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 1, AvailableReplicas 1
Jan 10 03:55:08.735: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 2, AvailableReplicas 2
Jan 10 03:55:10.010: INFO: observed Replicaset test-rs in namespace replicaset-1170 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 10 03:55:10.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1170" for this suite. 01/10/23 03:55:10.014
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":78,"skipped":1290,"failed":0}
------------------------------
• [SLOW TEST] [8.554 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:55:01.466
    Jan 10 03:55:01.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replicaset 01/10/23 03:55:01.467
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:01.528
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:01.551
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Jan 10 03:55:01.622: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jan 10 03:55:06.626: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/10/23 03:55:06.626
    STEP: Scaling up "test-rs" replicaset  01/10/23 03:55:06.627
    Jan 10 03:55:06.640: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 01/10/23 03:55:06.64
    W0110 03:55:06.659500      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jan 10 03:55:06.663: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 1, AvailableReplicas 1
    Jan 10 03:55:06.720: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 1, AvailableReplicas 1
    Jan 10 03:55:06.739: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 1, AvailableReplicas 1
    Jan 10 03:55:06.757: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 1, AvailableReplicas 1
    Jan 10 03:55:08.735: INFO: observed ReplicaSet test-rs in namespace replicaset-1170 with ReadyReplicas 2, AvailableReplicas 2
    Jan 10 03:55:10.010: INFO: observed Replicaset test-rs in namespace replicaset-1170 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 10 03:55:10.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1170" for this suite. 01/10/23 03:55:10.014
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:55:10.034
Jan 10 03:55:10.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replication-controller 01/10/23 03:55:10.035
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:10.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:10.057
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Jan 10 03:55:10.064: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 01/10/23 03:55:11.076
STEP: Checking rc "condition-test" has the desired failure condition set 01/10/23 03:55:11.083
STEP: Scaling down rc "condition-test" to satisfy pod quota 01/10/23 03:55:12.096
Jan 10 03:55:12.124: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 01/10/23 03:55:12.124
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 10 03:55:12.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1721" for this suite. 01/10/23 03:55:12.143
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":79,"skipped":1303,"failed":0}
------------------------------
• [2.135 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:55:10.034
    Jan 10 03:55:10.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replication-controller 01/10/23 03:55:10.035
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:10.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:10.057
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Jan 10 03:55:10.064: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 01/10/23 03:55:11.076
    STEP: Checking rc "condition-test" has the desired failure condition set 01/10/23 03:55:11.083
    STEP: Scaling down rc "condition-test" to satisfy pod quota 01/10/23 03:55:12.096
    Jan 10 03:55:12.124: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 01/10/23 03:55:12.124
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 10 03:55:12.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1721" for this suite. 01/10/23 03:55:12.143
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:55:12.17
Jan 10 03:55:12.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 03:55:12.171
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:12.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:12.207
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 01/10/23 03:55:12.21
STEP: Creating a ResourceQuota 01/10/23 03:55:17.229
STEP: Ensuring resource quota status is calculated 01/10/23 03:55:17.245
STEP: Creating a ReplicationController 01/10/23 03:55:19.254
STEP: Ensuring resource quota status captures replication controller creation 01/10/23 03:55:19.269
STEP: Deleting a ReplicationController 01/10/23 03:55:21.274
STEP: Ensuring resource quota status released usage 01/10/23 03:55:21.289
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 03:55:23.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9094" for this suite. 01/10/23 03:55:23.295
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":80,"skipped":1347,"failed":0}
------------------------------
• [SLOW TEST] [11.133 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:55:12.17
    Jan 10 03:55:12.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 03:55:12.171
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:12.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:12.207
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 01/10/23 03:55:12.21
    STEP: Creating a ResourceQuota 01/10/23 03:55:17.229
    STEP: Ensuring resource quota status is calculated 01/10/23 03:55:17.245
    STEP: Creating a ReplicationController 01/10/23 03:55:19.254
    STEP: Ensuring resource quota status captures replication controller creation 01/10/23 03:55:19.269
    STEP: Deleting a ReplicationController 01/10/23 03:55:21.274
    STEP: Ensuring resource quota status released usage 01/10/23 03:55:21.289
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 03:55:23.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9094" for this suite. 01/10/23 03:55:23.295
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:55:23.31
Jan 10 03:55:23.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename runtimeclass 01/10/23 03:55:23.311
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:23.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:23.39
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 01/10/23 03:55:23.4
STEP: getting /apis/node.k8s.io 01/10/23 03:55:23.402
STEP: getting /apis/node.k8s.io/v1 01/10/23 03:55:23.403
STEP: creating 01/10/23 03:55:23.404
STEP: watching 01/10/23 03:55:23.415
Jan 10 03:55:23.415: INFO: starting watch
STEP: getting 01/10/23 03:55:23.419
STEP: listing 01/10/23 03:55:23.421
STEP: patching 01/10/23 03:55:23.424
STEP: updating 01/10/23 03:55:23.428
Jan 10 03:55:23.432: INFO: waiting for watch events with expected annotations
STEP: deleting 01/10/23 03:55:23.432
STEP: deleting a collection 01/10/23 03:55:23.448
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 10 03:55:23.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8093" for this suite. 01/10/23 03:55:23.462
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":81,"skipped":1362,"failed":0}
------------------------------
• [0.163 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:55:23.31
    Jan 10 03:55:23.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename runtimeclass 01/10/23 03:55:23.311
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:23.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:23.39
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 01/10/23 03:55:23.4
    STEP: getting /apis/node.k8s.io 01/10/23 03:55:23.402
    STEP: getting /apis/node.k8s.io/v1 01/10/23 03:55:23.403
    STEP: creating 01/10/23 03:55:23.404
    STEP: watching 01/10/23 03:55:23.415
    Jan 10 03:55:23.415: INFO: starting watch
    STEP: getting 01/10/23 03:55:23.419
    STEP: listing 01/10/23 03:55:23.421
    STEP: patching 01/10/23 03:55:23.424
    STEP: updating 01/10/23 03:55:23.428
    Jan 10 03:55:23.432: INFO: waiting for watch events with expected annotations
    STEP: deleting 01/10/23 03:55:23.432
    STEP: deleting a collection 01/10/23 03:55:23.448
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 10 03:55:23.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8093" for this suite. 01/10/23 03:55:23.462
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:55:23.476
Jan 10 03:55:23.476: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pod-network-test 01/10/23 03:55:23.479
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:23.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:23.595
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-9834 01/10/23 03:55:23.609
STEP: creating a selector 01/10/23 03:55:23.609
STEP: Creating the service pods in kubernetes 01/10/23 03:55:23.609
Jan 10 03:55:23.609: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jan 10 03:55:23.681: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9834" to be "running and ready"
Jan 10 03:55:23.707: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.383579ms
Jan 10 03:55:23.707: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:55:25.710: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.029181543s
Jan 10 03:55:25.710: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:27.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.029891914s
Jan 10 03:55:27.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:29.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.029644492s
Jan 10 03:55:29.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:31.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.03042473s
Jan 10 03:55:31.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:33.712: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.03105394s
Jan 10 03:55:33.712: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:35.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.030026397s
Jan 10 03:55:35.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:37.712: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.030816298s
Jan 10 03:55:37.712: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:39.710: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.029302475s
Jan 10 03:55:39.710: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:41.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.030273033s
Jan 10 03:55:41.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:43.712: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.031366355s
Jan 10 03:55:43.712: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 03:55:45.712: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.030897806s
Jan 10 03:55:45.712: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jan 10 03:55:45.712: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jan 10 03:55:45.714: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9834" to be "running and ready"
Jan 10 03:55:45.716: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 1.76076ms
Jan 10 03:55:45.716: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jan 10 03:55:45.716: INFO: Pod "netserver-1" satisfied condition "running and ready"
Jan 10 03:55:45.718: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9834" to be "running and ready"
Jan 10 03:55:45.719: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 1.684883ms
Jan 10 03:55:45.719: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Jan 10 03:55:45.719: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 01/10/23 03:55:45.721
Jan 10 03:55:45.744: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9834" to be "running"
Jan 10 03:55:45.756: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.933358ms
Jan 10 03:55:47.758: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.0145398s
Jan 10 03:55:47.758: INFO: Pod "test-container-pod" satisfied condition "running"
Jan 10 03:55:47.760: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9834" to be "running"
Jan 10 03:55:47.762: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 1.78053ms
Jan 10 03:55:47.762: INFO: Pod "host-test-container-pod" satisfied condition "running"
Jan 10 03:55:47.764: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jan 10 03:55:47.765: INFO: Going to poll 10.42.0.39 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jan 10 03:55:47.766: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.39:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9834 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:55:47.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:55:47.767: INFO: ExecWithOptions: Clientset creation
Jan 10 03:55:47.767: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-9834/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.0.39%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 10 03:55:47.851: INFO: Found all 1 expected endpoints: [netserver-0]
Jan 10 03:55:47.851: INFO: Going to poll 10.42.1.98 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jan 10 03:55:47.854: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.98:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9834 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:55:47.854: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:55:47.854: INFO: ExecWithOptions: Clientset creation
Jan 10 03:55:47.854: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-9834/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.1.98%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 10 03:55:47.937: INFO: Found all 1 expected endpoints: [netserver-1]
Jan 10 03:55:47.937: INFO: Going to poll 10.42.2.51 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jan 10 03:55:47.940: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.2.51:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9834 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:55:47.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:55:47.940: INFO: ExecWithOptions: Clientset creation
Jan 10 03:55:47.940: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-9834/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.2.51%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 10 03:55:48.011: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jan 10 03:55:48.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9834" for this suite. 01/10/23 03:55:48.016
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":82,"skipped":1369,"failed":0}
------------------------------
• [SLOW TEST] [24.549 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:55:23.476
    Jan 10 03:55:23.476: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pod-network-test 01/10/23 03:55:23.479
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:23.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:23.595
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-9834 01/10/23 03:55:23.609
    STEP: creating a selector 01/10/23 03:55:23.609
    STEP: Creating the service pods in kubernetes 01/10/23 03:55:23.609
    Jan 10 03:55:23.609: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jan 10 03:55:23.681: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9834" to be "running and ready"
    Jan 10 03:55:23.707: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.383579ms
    Jan 10 03:55:23.707: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:55:25.710: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.029181543s
    Jan 10 03:55:25.710: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:27.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.029891914s
    Jan 10 03:55:27.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:29.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.029644492s
    Jan 10 03:55:29.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:31.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.03042473s
    Jan 10 03:55:31.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:33.712: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.03105394s
    Jan 10 03:55:33.712: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:35.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.030026397s
    Jan 10 03:55:35.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:37.712: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.030816298s
    Jan 10 03:55:37.712: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:39.710: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.029302475s
    Jan 10 03:55:39.710: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:41.711: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.030273033s
    Jan 10 03:55:41.711: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:43.712: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.031366355s
    Jan 10 03:55:43.712: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 03:55:45.712: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.030897806s
    Jan 10 03:55:45.712: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jan 10 03:55:45.712: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jan 10 03:55:45.714: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9834" to be "running and ready"
    Jan 10 03:55:45.716: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 1.76076ms
    Jan 10 03:55:45.716: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jan 10 03:55:45.716: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Jan 10 03:55:45.718: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9834" to be "running and ready"
    Jan 10 03:55:45.719: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 1.684883ms
    Jan 10 03:55:45.719: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Jan 10 03:55:45.719: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 01/10/23 03:55:45.721
    Jan 10 03:55:45.744: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9834" to be "running"
    Jan 10 03:55:45.756: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.933358ms
    Jan 10 03:55:47.758: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.0145398s
    Jan 10 03:55:47.758: INFO: Pod "test-container-pod" satisfied condition "running"
    Jan 10 03:55:47.760: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9834" to be "running"
    Jan 10 03:55:47.762: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 1.78053ms
    Jan 10 03:55:47.762: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Jan 10 03:55:47.764: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Jan 10 03:55:47.765: INFO: Going to poll 10.42.0.39 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Jan 10 03:55:47.766: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.39:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9834 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:55:47.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:55:47.767: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:55:47.767: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-9834/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.0.39%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 10 03:55:47.851: INFO: Found all 1 expected endpoints: [netserver-0]
    Jan 10 03:55:47.851: INFO: Going to poll 10.42.1.98 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Jan 10 03:55:47.854: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.98:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9834 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:55:47.854: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:55:47.854: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:55:47.854: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-9834/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.1.98%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 10 03:55:47.937: INFO: Found all 1 expected endpoints: [netserver-1]
    Jan 10 03:55:47.937: INFO: Going to poll 10.42.2.51 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Jan 10 03:55:47.940: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.2.51:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9834 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:55:47.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:55:47.940: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:55:47.940: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-9834/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.2.51%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 10 03:55:48.011: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jan 10 03:55:48.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9834" for this suite. 01/10/23 03:55:48.016
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:55:48.025
Jan 10 03:55:48.026: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename deployment 01/10/23 03:55:48.027
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:48.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:48.095
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Jan 10 03:55:48.107: INFO: Creating deployment "webserver-deployment"
Jan 10 03:55:48.125: INFO: Waiting for observed generation 1
Jan 10 03:55:50.150: INFO: Waiting for all required pods to come up
Jan 10 03:55:50.154: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 01/10/23 03:55:50.154
Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zbwdr" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2z6fm" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bqkxv" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bxghp" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-clxhg" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-d2h9k" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-lrkcq" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.156: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-prkm4" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.156: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tzdtt" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.156: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vvm2k" in namespace "deployment-8366" to be "running"
Jan 10 03:55:50.168: INFO: Pod "webserver-deployment-845c8977d9-bxghp": Phase="Pending", Reason="", readiness=false. Elapsed: 13.293178ms
Jan 10 03:55:50.173: INFO: Pod "webserver-deployment-845c8977d9-bqkxv": Phase="Pending", Reason="", readiness=false. Elapsed: 17.868151ms
Jan 10 03:55:50.173: INFO: Pod "webserver-deployment-845c8977d9-zbwdr": Phase="Pending", Reason="", readiness=false. Elapsed: 18.308364ms
Jan 10 03:55:50.173: INFO: Pod "webserver-deployment-845c8977d9-2z6fm": Phase="Pending", Reason="", readiness=false. Elapsed: 18.445074ms
Jan 10 03:55:50.178: INFO: Pod "webserver-deployment-845c8977d9-tzdtt": Phase="Pending", Reason="", readiness=false. Elapsed: 22.654387ms
Jan 10 03:55:50.179: INFO: Pod "webserver-deployment-845c8977d9-clxhg": Phase="Pending", Reason="", readiness=false. Elapsed: 23.495513ms
Jan 10 03:55:50.184: INFO: Pod "webserver-deployment-845c8977d9-prkm4": Phase="Pending", Reason="", readiness=false. Elapsed: 28.862223ms
Jan 10 03:55:50.185: INFO: Pod "webserver-deployment-845c8977d9-d2h9k": Phase="Pending", Reason="", readiness=false. Elapsed: 29.368662ms
Jan 10 03:55:50.185: INFO: Pod "webserver-deployment-845c8977d9-lrkcq": Phase="Pending", Reason="", readiness=false. Elapsed: 29.281327ms
Jan 10 03:55:50.187: INFO: Pod "webserver-deployment-845c8977d9-vvm2k": Phase="Pending", Reason="", readiness=false. Elapsed: 31.566038ms
Jan 10 03:55:52.174: INFO: Pod "webserver-deployment-845c8977d9-bxghp": Phase="Running", Reason="", readiness=true. Elapsed: 2.019228637s
Jan 10 03:55:52.174: INFO: Pod "webserver-deployment-845c8977d9-bxghp" satisfied condition "running"
Jan 10 03:55:52.176: INFO: Pod "webserver-deployment-845c8977d9-zbwdr": Phase="Running", Reason="", readiness=true. Elapsed: 2.021821649s
Jan 10 03:55:52.177: INFO: Pod "webserver-deployment-845c8977d9-zbwdr" satisfied condition "running"
Jan 10 03:55:52.177: INFO: Pod "webserver-deployment-845c8977d9-bqkxv": Phase="Running", Reason="", readiness=true. Elapsed: 2.021976399s
Jan 10 03:55:52.177: INFO: Pod "webserver-deployment-845c8977d9-bqkxv" satisfied condition "running"
Jan 10 03:55:52.178: INFO: Pod "webserver-deployment-845c8977d9-2z6fm": Phase="Running", Reason="", readiness=true. Elapsed: 2.022691279s
Jan 10 03:55:52.178: INFO: Pod "webserver-deployment-845c8977d9-2z6fm" satisfied condition "running"
Jan 10 03:55:52.184: INFO: Pod "webserver-deployment-845c8977d9-tzdtt": Phase="Running", Reason="", readiness=true. Elapsed: 2.028504865s
Jan 10 03:55:52.184: INFO: Pod "webserver-deployment-845c8977d9-tzdtt" satisfied condition "running"
Jan 10 03:55:52.185: INFO: Pod "webserver-deployment-845c8977d9-clxhg": Phase="Running", Reason="", readiness=true. Elapsed: 2.029607363s
Jan 10 03:55:52.185: INFO: Pod "webserver-deployment-845c8977d9-clxhg" satisfied condition "running"
Jan 10 03:55:52.187: INFO: Pod "webserver-deployment-845c8977d9-prkm4": Phase="Running", Reason="", readiness=true. Elapsed: 2.030975068s
Jan 10 03:55:52.187: INFO: Pod "webserver-deployment-845c8977d9-prkm4" satisfied condition "running"
Jan 10 03:55:52.188: INFO: Pod "webserver-deployment-845c8977d9-d2h9k": Phase="Running", Reason="", readiness=true. Elapsed: 2.032703818s
Jan 10 03:55:52.188: INFO: Pod "webserver-deployment-845c8977d9-d2h9k" satisfied condition "running"
Jan 10 03:55:52.189: INFO: Pod "webserver-deployment-845c8977d9-lrkcq": Phase="Running", Reason="", readiness=true. Elapsed: 2.033678807s
Jan 10 03:55:52.189: INFO: Pod "webserver-deployment-845c8977d9-lrkcq" satisfied condition "running"
Jan 10 03:55:52.190: INFO: Pod "webserver-deployment-845c8977d9-vvm2k": Phase="Running", Reason="", readiness=true. Elapsed: 2.034140322s
Jan 10 03:55:52.190: INFO: Pod "webserver-deployment-845c8977d9-vvm2k" satisfied condition "running"
Jan 10 03:55:52.190: INFO: Waiting for deployment "webserver-deployment" to complete
Jan 10 03:55:52.194: INFO: Updating deployment "webserver-deployment" with a non-existent image
Jan 10 03:55:52.200: INFO: Updating deployment webserver-deployment
Jan 10 03:55:52.200: INFO: Waiting for observed generation 2
Jan 10 03:55:54.208: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 10 03:55:54.210: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 10 03:55:54.212: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jan 10 03:55:54.216: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 10 03:55:54.217: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 10 03:55:54.218: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jan 10 03:55:54.221: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Jan 10 03:55:54.221: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Jan 10 03:55:54.226: INFO: Updating deployment webserver-deployment
Jan 10 03:55:54.226: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Jan 10 03:55:54.230: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 10 03:55:56.254: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 10 03:55:56.273: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8366  1642d533-1988-4a50-b95f-e48406fccba8 218699 3 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037de218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-01-10 03:55:54 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-01-10 03:55:54 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Jan 10 03:55:56.290: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-8366  db204632-da53-4b5e-bc34-8dd0113b0f05 218695 3 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 1642d533-1988-4a50-b95f-e48406fccba8 0xc0057f3747 0xc0057f3748}] [] [{kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1642d533-1988-4a50-b95f-e48406fccba8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0057f37e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 10 03:55:56.295: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Jan 10 03:55:56.295: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-8366  1f88b859-4b15-4d23-9aa6-5b0c281e507c 218670 3 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 1642d533-1988-4a50-b95f-e48406fccba8 0xc0057f3847 0xc0057f3848}] [] [{kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1642d533-1988-4a50-b95f-e48406fccba8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0057f38d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Jan 10 03:55:56.337: INFO: Pod "webserver-deployment-69b7448995-5vd2k" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-5vd2k webserver-deployment-69b7448995- deployment-8366  d5a72c09-ba84-4b59-8446-e6f9793018f6 218739 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0057f3de7 0xc0057f3de8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-96rbr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-96rbr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.337: INFO: Pod "webserver-deployment-69b7448995-67b95" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-67b95 webserver-deployment-69b7448995- deployment-8366  92ff8156-4eb1-4c6e-82ee-a854580759c2 218686 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0057f3fd7 0xc0057f3fd8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-czcbr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-czcbr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.338: INFO: Pod "webserver-deployment-69b7448995-6brc8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-6brc8 webserver-deployment-69b7448995- deployment-8366  7d25ccbb-c373-4618-900a-209b3997aaa0 218603 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:cf6f9301192f6af4e81d7cfac316f20ed42fb1c0ee36ec8ec42706317f234eed cni.projectcalico.org/podIP:10.42.0.43/32 cni.projectcalico.org/podIPs:10.42.0.43/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6227 0xc0038c6228}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.43\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wdsf4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wdsf4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:10.42.0.43,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.338: INFO: Pod "webserver-deployment-69b7448995-dgx72" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-dgx72 webserver-deployment-69b7448995- deployment-8366  cd298eb0-461c-47d8-8677-8fcc8dd04df9 218747 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:564a4aa26438e2533e666941d0ab8461f71eace5504a26f4e5292fc9fecff458 cni.projectcalico.org/podIP:10.42.2.57/32 cni.projectcalico.org/podIPs:10.42.2.57/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c64a0 0xc0038c64a1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.57\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-265hb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-265hb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.57,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.57,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.338: INFO: Pod "webserver-deployment-69b7448995-jk77b" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jk77b webserver-deployment-69b7448995- deployment-8366  023e329b-0931-4531-b21b-915516d97cd5 218694 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c66d0 0xc0038c66d1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4nksk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4nksk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.338: INFO: Pod "webserver-deployment-69b7448995-mccmr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mccmr webserver-deployment-69b7448995- deployment-8366  24f1c570-5bef-4e56-af7d-dd358f7a500a 218612 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:4f19e6a8041a8439dd928ca85e423ab9e9450a916dcb293163367e8b29dd1d43 cni.projectcalico.org/podIP:10.42.1.104/32 cni.projectcalico.org/podIPs:10.42.1.104/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6860 0xc0038c6861}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.104\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2t4qc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2t4qc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.104,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.104,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.339: INFO: Pod "webserver-deployment-69b7448995-mkd96" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mkd96 webserver-deployment-69b7448995- deployment-8366  d5c440a4-6c5c-4c86-8cd7-3dcf87278d73 218731 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:32318b2d9a56685422c87180d0023ce6393b16279d944bd49bdee317bbc8b80d cni.projectcalico.org/podIP:10.42.2.56/32 cni.projectcalico.org/podIPs:10.42.2.56/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6ab0 0xc0038c6ab1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.56\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tcrhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tcrhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.56,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.56,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.339: INFO: Pod "webserver-deployment-69b7448995-mkxsz" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mkxsz webserver-deployment-69b7448995- deployment-8366  b18061de-f894-4c9b-abd8-c3078d5648e8 218690 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6ce0 0xc0038c6ce1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zrcf5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zrcf5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.339: INFO: Pod "webserver-deployment-69b7448995-p5vjs" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-p5vjs webserver-deployment-69b7448995- deployment-8366  f9210d8a-024d-435e-920f-3d592ee89ffb 218655 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6e50 0xc0038c6e51}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5dvpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5dvpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.339: INFO: Pod "webserver-deployment-69b7448995-tz2km" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-tz2km webserver-deployment-69b7448995- deployment-8366  7cc63bfa-6ece-47b7-8b2e-da1cf9cc14a5 218611 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:7cb956909c0eb27113c2d9adf66d1906fbf688174006956f956bd8e50332353a cni.projectcalico.org/podIP:10.42.1.103/32 cni.projectcalico.org/podIPs:10.42.1.103/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6ff0 0xc0038c6ff1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.103\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pmtpf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pmtpf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.103,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.340: INFO: Pod "webserver-deployment-69b7448995-wqh44" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wqh44 webserver-deployment-69b7448995- deployment-8366  4905b456-9b23-4e3f-a6a0-994281508f02 218685 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c7220 0xc0038c7221}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7tjfn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7tjfn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.340: INFO: Pod "webserver-deployment-69b7448995-x6qvh" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-x6qvh webserver-deployment-69b7448995- deployment-8366  f10b70c0-db5a-4ba4-825f-074ee4645738 218748 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c73a0 0xc0038c73a1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rqm4v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rqm4v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.340: INFO: Pod "webserver-deployment-69b7448995-ztplz" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-ztplz webserver-deployment-69b7448995- deployment-8366  62c7eca0-b031-4061-b03e-d0e14e86d54d 218741 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c7597 0xc0038c7598}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h8gw5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h8gw5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.341: INFO: Pod "webserver-deployment-845c8977d9-2gqxt" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2gqxt webserver-deployment-845c8977d9- deployment-8366  bc1b18a7-7649-48c3-a798-a4765765c42f 218658 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c7787 0xc0038c7788}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bfhvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bfhvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.341: INFO: Pod "webserver-deployment-845c8977d9-8ft2c" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8ft2c webserver-deployment-845c8977d9- deployment-8366  65f8b853-33e8-4a38-98f4-be7d027fb8f2 218649 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c78f0 0xc0038c78f1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8t6zd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8t6zd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.341: INFO: Pod "webserver-deployment-845c8977d9-bqkxv" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bqkxv webserver-deployment-845c8977d9- deployment-8366  4f1cb5ec-c8bd-4be0-8c2e-a52c992c4a24 218460 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d9569d2764d2686e4ce2aafd7d8b3152b5294fd8013aca71a061e2b19896954a cni.projectcalico.org/podIP:10.42.0.42/32 cni.projectcalico.org/podIPs:10.42.0.42/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c7a70 0xc0038c7a71}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gw2l4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gw2l4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:10.42.0.42,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://e9f558ef91e02c3c2b31d37063f710a411663f18ddd9e289bfebbb27febfdc4d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.341: INFO: Pod "webserver-deployment-845c8977d9-bxghp" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bxghp webserver-deployment-845c8977d9- deployment-8366  e01799f5-2cf6-4bc5-9c8a-a699c78689e3 218466 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ab4231e9a698294f081412efa431098d4f0694ecc40fb20778d78f469a4d001e cni.projectcalico.org/podIP:10.42.0.40/32 cni.projectcalico.org/podIPs:10.42.0.40/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c7ca0 0xc0038c7ca1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hv98t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hv98t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:10.42.0.40,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://d562abae4e3bf9c6bf818bf86330e4cfb2d55bbbedd5cf8063fe57d3108b768b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.342: INFO: Pod "webserver-deployment-845c8977d9-ccmqs" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ccmqs webserver-deployment-845c8977d9- deployment-8366  1e1e201b-c075-4f61-b2c9-c3e454e958a7 218746 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4dc9311d90532950b082b09f018356564cb6e2d788755269c3083c6ff5408440 cni.projectcalico.org/podIP:10.42.2.58/32 cni.projectcalico.org/podIPs:10.42.2.58/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c7ed0 0xc0038c7ed1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tlmz6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tlmz6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.342: INFO: Pod "webserver-deployment-845c8977d9-ck4hs" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ck4hs webserver-deployment-845c8977d9- deployment-8366  67016e88-cf6a-4202-af55-172c17915de6 218661 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e0b7 0xc00372e0b8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c9zwx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c9zwx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.342: INFO: Pod "webserver-deployment-845c8977d9-clxhg" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-clxhg webserver-deployment-845c8977d9- deployment-8366  5673358a-7d87-4b15-81c6-d03576ec177a 218463 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:692c71b99818e5546b641dc0fadc2006f6ce9a56291dc3ad8dd83682808219c9 cni.projectcalico.org/podIP:10.42.0.41/32 cni.projectcalico.org/podIPs:10.42.0.41/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e240 0xc00372e241}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4cnpv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4cnpv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:10.42.0.41,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://293865e22eeecde9403758c4e82e368587d4abc8561a91d8926e27282302d568,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.342: INFO: Pod "webserver-deployment-845c8977d9-gcz6r" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gcz6r webserver-deployment-845c8977d9- deployment-8366  c8883a0f-fd1c-4a17-ad3d-79873da2eac0 218744 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3f29331abe439820c6ecab53ebb2c25b63c5d33ef7b10dbe4a0ac45b364d7864 cni.projectcalico.org/podIP:10.42.1.106/32 cni.projectcalico.org/podIPs:10.42.1.106/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e460 0xc00372e461}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wc44n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wc44n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.351: INFO: Pod "webserver-deployment-845c8977d9-lrkcq" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-lrkcq webserver-deployment-845c8977d9- deployment-8366  ac5bd763-8908-47e4-9de2-2f4d2994a647 218475 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:783333039a1c4e8fec6b999dd774ab955348c2d5edd3da7ed35bda5c43750808 cni.projectcalico.org/podIP:10.42.2.55/32 cni.projectcalico.org/podIPs:10.42.2.55/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e600 0xc00372e601}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.55\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rcjvt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rcjvt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.55,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://81d96ef42778b96100acc4897d1a0bda5de7b42e6b324c177456ccfdc2d15e7e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.55,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-pj2fp" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-pj2fp webserver-deployment-845c8977d9- deployment-8366  3d67a61e-8fab-4c42-a5fb-185533558a1e 218751 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:10648721d9df3afc6991ceb563c565272b728d0fc03a74ab705b569cb840022a cni.projectcalico.org/podIP:10.42.2.59/32 cni.projectcalico.org/podIPs:10.42.2.59/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e830 0xc00372e831}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sdxcd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sdxcd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-prkm4" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-prkm4 webserver-deployment-845c8977d9- deployment-8366  22cfb9a2-777e-4166-960c-da4e229b8bfc 218469 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b5077aed2ea3a969e781693bde1069b95184e7ecb4b236754c822dc3ac36a88d cni.projectcalico.org/podIP:10.42.1.101/32 cni.projectcalico.org/podIPs:10.42.1.101/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e9e0 0xc00372e9e1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.101\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vsdw4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vsdw4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.101,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://e7bdc5cd4855f44693d81638c5582c6897aab547180f71342eead97921804e7e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-t45fx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-t45fx webserver-deployment-845c8977d9- deployment-8366  d496ee88-94c6-4ccd-9fab-e9c3277df28b 218752 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:93dfc63742f82087a1673e7ee50b8eb7ff963c5a240193717c9c3033084da526 cni.projectcalico.org/podIP:10.42.2.60/32 cni.projectcalico.org/podIPs:10.42.2.60/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372ec27 0xc00372ec28}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j87wj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j87wj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-tv6c6" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tv6c6 webserver-deployment-845c8977d9- deployment-8366  5eac7991-6840-45ed-bbc8-3e6c9bf398b8 218730 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372edd0 0xc00372edd1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-76hzq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-76hzq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-tzdtt" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tzdtt webserver-deployment-845c8977d9- deployment-8366  5deb54df-4a3c-4d62-a7c6-bacc8869d9b4 218476 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:fbd287347bf5b01c4374568e47fabe30357a27e4503858ba0b25bc843747968b cni.projectcalico.org/podIP:10.42.1.100/32 cni.projectcalico.org/podIPs:10.42.1.100/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372efb7 0xc00372efb8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.100\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4nlgl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4nlgl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.100,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://248d5281fa852e041367935e5baa8cd43ad0e3cda5e80bf5d027da85a10045c3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.353: INFO: Pod "webserver-deployment-845c8977d9-vhp9t" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vhp9t webserver-deployment-845c8977d9- deployment-8366  e14819ef-6bc2-4ef9-bce3-feb05c126db0 218740 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:805c970054796bb83669bc6b160cf7a6e773ba1999dd67844d17fad982645894 cni.projectcalico.org/podIP:10.42.1.105/32 cni.projectcalico.org/podIPs:10.42.1.105/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f1e7 0xc00372f1e8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwgjq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwgjq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.353: INFO: Pod "webserver-deployment-845c8977d9-vvm2k" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vvm2k webserver-deployment-845c8977d9- deployment-8366  e29335ae-c508-417b-a313-41c276b5c3d4 218487 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d733c4921a9a021b58274fff6af50b28e49ba26ae960f9a7b646ada059096e4b cni.projectcalico.org/podIP:10.42.2.54/32 cni.projectcalico.org/podIPs:10.42.2.54/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f390 0xc00372f391}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.54\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bc97v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bc97v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.54,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://b4cd789c518509d3ae296aef653f9221ffbf65cb3c85ccb5ec9e459adcd46c8a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.353: INFO: Pod "webserver-deployment-845c8977d9-wgswm" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wgswm webserver-deployment-845c8977d9- deployment-8366  6fadd43d-ef68-4a9a-9cbf-c3f6cbc2f473 218716 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f590 0xc00372f591}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dm9dp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dm9dp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.353: INFO: Pod "webserver-deployment-845c8977d9-x7wkx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-x7wkx webserver-deployment-845c8977d9- deployment-8366  5db07607-8afe-418c-b8ad-072696653dc7 218705 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f757 0xc00372f758}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jx6tl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jx6tl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.354: INFO: Pod "webserver-deployment-845c8977d9-zbwdr" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zbwdr webserver-deployment-845c8977d9- deployment-8366  8544633b-d2cc-43ba-bdfc-7380fd2e9afb 218478 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1c59d896bcac37bcd02783d535f2ef551a9d190a39e12bc3053f4b5fdc0ea4fc cni.projectcalico.org/podIP:10.42.2.53/32 cni.projectcalico.org/podIPs:10.42.2.53/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f947 0xc00372f948}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ffczq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ffczq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.53,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://2ae8dc4025d2b79149051891be91fab03abc35dd63ed3467f177a988a19b960f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 03:55:56.354: INFO: Pod "webserver-deployment-845c8977d9-zrll9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zrll9 webserver-deployment-845c8977d9- deployment-8366  c34ddc98-1534-4d3b-84a1-028769a16bc7 218757 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:14cc7159e6c2ed27ac1e619caa563ac55a7b51b416eb727f339bbfd730453107 cni.projectcalico.org/podIP:10.42.1.107/32 cni.projectcalico.org/podIPs:10.42.1.107/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372fb70 0xc00372fb71}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l2p6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l2p6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 10 03:55:56.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8366" for this suite. 01/10/23 03:55:56.399
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":83,"skipped":1387,"failed":0}
------------------------------
• [SLOW TEST] [8.456 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:55:48.025
    Jan 10 03:55:48.026: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename deployment 01/10/23 03:55:48.027
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:48.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:48.095
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Jan 10 03:55:48.107: INFO: Creating deployment "webserver-deployment"
    Jan 10 03:55:48.125: INFO: Waiting for observed generation 1
    Jan 10 03:55:50.150: INFO: Waiting for all required pods to come up
    Jan 10 03:55:50.154: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 01/10/23 03:55:50.154
    Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zbwdr" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2z6fm" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bqkxv" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bxghp" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-clxhg" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-d2h9k" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.155: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-lrkcq" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.156: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-prkm4" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.156: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tzdtt" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.156: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vvm2k" in namespace "deployment-8366" to be "running"
    Jan 10 03:55:50.168: INFO: Pod "webserver-deployment-845c8977d9-bxghp": Phase="Pending", Reason="", readiness=false. Elapsed: 13.293178ms
    Jan 10 03:55:50.173: INFO: Pod "webserver-deployment-845c8977d9-bqkxv": Phase="Pending", Reason="", readiness=false. Elapsed: 17.868151ms
    Jan 10 03:55:50.173: INFO: Pod "webserver-deployment-845c8977d9-zbwdr": Phase="Pending", Reason="", readiness=false. Elapsed: 18.308364ms
    Jan 10 03:55:50.173: INFO: Pod "webserver-deployment-845c8977d9-2z6fm": Phase="Pending", Reason="", readiness=false. Elapsed: 18.445074ms
    Jan 10 03:55:50.178: INFO: Pod "webserver-deployment-845c8977d9-tzdtt": Phase="Pending", Reason="", readiness=false. Elapsed: 22.654387ms
    Jan 10 03:55:50.179: INFO: Pod "webserver-deployment-845c8977d9-clxhg": Phase="Pending", Reason="", readiness=false. Elapsed: 23.495513ms
    Jan 10 03:55:50.184: INFO: Pod "webserver-deployment-845c8977d9-prkm4": Phase="Pending", Reason="", readiness=false. Elapsed: 28.862223ms
    Jan 10 03:55:50.185: INFO: Pod "webserver-deployment-845c8977d9-d2h9k": Phase="Pending", Reason="", readiness=false. Elapsed: 29.368662ms
    Jan 10 03:55:50.185: INFO: Pod "webserver-deployment-845c8977d9-lrkcq": Phase="Pending", Reason="", readiness=false. Elapsed: 29.281327ms
    Jan 10 03:55:50.187: INFO: Pod "webserver-deployment-845c8977d9-vvm2k": Phase="Pending", Reason="", readiness=false. Elapsed: 31.566038ms
    Jan 10 03:55:52.174: INFO: Pod "webserver-deployment-845c8977d9-bxghp": Phase="Running", Reason="", readiness=true. Elapsed: 2.019228637s
    Jan 10 03:55:52.174: INFO: Pod "webserver-deployment-845c8977d9-bxghp" satisfied condition "running"
    Jan 10 03:55:52.176: INFO: Pod "webserver-deployment-845c8977d9-zbwdr": Phase="Running", Reason="", readiness=true. Elapsed: 2.021821649s
    Jan 10 03:55:52.177: INFO: Pod "webserver-deployment-845c8977d9-zbwdr" satisfied condition "running"
    Jan 10 03:55:52.177: INFO: Pod "webserver-deployment-845c8977d9-bqkxv": Phase="Running", Reason="", readiness=true. Elapsed: 2.021976399s
    Jan 10 03:55:52.177: INFO: Pod "webserver-deployment-845c8977d9-bqkxv" satisfied condition "running"
    Jan 10 03:55:52.178: INFO: Pod "webserver-deployment-845c8977d9-2z6fm": Phase="Running", Reason="", readiness=true. Elapsed: 2.022691279s
    Jan 10 03:55:52.178: INFO: Pod "webserver-deployment-845c8977d9-2z6fm" satisfied condition "running"
    Jan 10 03:55:52.184: INFO: Pod "webserver-deployment-845c8977d9-tzdtt": Phase="Running", Reason="", readiness=true. Elapsed: 2.028504865s
    Jan 10 03:55:52.184: INFO: Pod "webserver-deployment-845c8977d9-tzdtt" satisfied condition "running"
    Jan 10 03:55:52.185: INFO: Pod "webserver-deployment-845c8977d9-clxhg": Phase="Running", Reason="", readiness=true. Elapsed: 2.029607363s
    Jan 10 03:55:52.185: INFO: Pod "webserver-deployment-845c8977d9-clxhg" satisfied condition "running"
    Jan 10 03:55:52.187: INFO: Pod "webserver-deployment-845c8977d9-prkm4": Phase="Running", Reason="", readiness=true. Elapsed: 2.030975068s
    Jan 10 03:55:52.187: INFO: Pod "webserver-deployment-845c8977d9-prkm4" satisfied condition "running"
    Jan 10 03:55:52.188: INFO: Pod "webserver-deployment-845c8977d9-d2h9k": Phase="Running", Reason="", readiness=true. Elapsed: 2.032703818s
    Jan 10 03:55:52.188: INFO: Pod "webserver-deployment-845c8977d9-d2h9k" satisfied condition "running"
    Jan 10 03:55:52.189: INFO: Pod "webserver-deployment-845c8977d9-lrkcq": Phase="Running", Reason="", readiness=true. Elapsed: 2.033678807s
    Jan 10 03:55:52.189: INFO: Pod "webserver-deployment-845c8977d9-lrkcq" satisfied condition "running"
    Jan 10 03:55:52.190: INFO: Pod "webserver-deployment-845c8977d9-vvm2k": Phase="Running", Reason="", readiness=true. Elapsed: 2.034140322s
    Jan 10 03:55:52.190: INFO: Pod "webserver-deployment-845c8977d9-vvm2k" satisfied condition "running"
    Jan 10 03:55:52.190: INFO: Waiting for deployment "webserver-deployment" to complete
    Jan 10 03:55:52.194: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Jan 10 03:55:52.200: INFO: Updating deployment webserver-deployment
    Jan 10 03:55:52.200: INFO: Waiting for observed generation 2
    Jan 10 03:55:54.208: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Jan 10 03:55:54.210: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Jan 10 03:55:54.212: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Jan 10 03:55:54.216: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Jan 10 03:55:54.217: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Jan 10 03:55:54.218: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Jan 10 03:55:54.221: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Jan 10 03:55:54.221: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Jan 10 03:55:54.226: INFO: Updating deployment webserver-deployment
    Jan 10 03:55:54.226: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Jan 10 03:55:54.230: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Jan 10 03:55:56.254: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 10 03:55:56.273: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-8366  1642d533-1988-4a50-b95f-e48406fccba8 218699 3 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037de218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-01-10 03:55:54 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-01-10 03:55:54 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Jan 10 03:55:56.290: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-8366  db204632-da53-4b5e-bc34-8dd0113b0f05 218695 3 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 1642d533-1988-4a50-b95f-e48406fccba8 0xc0057f3747 0xc0057f3748}] [] [{kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1642d533-1988-4a50-b95f-e48406fccba8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0057f37e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 03:55:56.295: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Jan 10 03:55:56.295: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-8366  1f88b859-4b15-4d23-9aa6-5b0c281e507c 218670 3 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 1642d533-1988-4a50-b95f-e48406fccba8 0xc0057f3847 0xc0057f3848}] [] [{kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1642d533-1988-4a50-b95f-e48406fccba8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0057f38d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 03:55:56.337: INFO: Pod "webserver-deployment-69b7448995-5vd2k" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-5vd2k webserver-deployment-69b7448995- deployment-8366  d5a72c09-ba84-4b59-8446-e6f9793018f6 218739 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0057f3de7 0xc0057f3de8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-96rbr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-96rbr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.337: INFO: Pod "webserver-deployment-69b7448995-67b95" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-67b95 webserver-deployment-69b7448995- deployment-8366  92ff8156-4eb1-4c6e-82ee-a854580759c2 218686 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0057f3fd7 0xc0057f3fd8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-czcbr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-czcbr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.338: INFO: Pod "webserver-deployment-69b7448995-6brc8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-6brc8 webserver-deployment-69b7448995- deployment-8366  7d25ccbb-c373-4618-900a-209b3997aaa0 218603 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:cf6f9301192f6af4e81d7cfac316f20ed42fb1c0ee36ec8ec42706317f234eed cni.projectcalico.org/podIP:10.42.0.43/32 cni.projectcalico.org/podIPs:10.42.0.43/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6227 0xc0038c6228}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.43\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wdsf4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wdsf4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:10.42.0.43,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.338: INFO: Pod "webserver-deployment-69b7448995-dgx72" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-dgx72 webserver-deployment-69b7448995- deployment-8366  cd298eb0-461c-47d8-8677-8fcc8dd04df9 218747 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:564a4aa26438e2533e666941d0ab8461f71eace5504a26f4e5292fc9fecff458 cni.projectcalico.org/podIP:10.42.2.57/32 cni.projectcalico.org/podIPs:10.42.2.57/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c64a0 0xc0038c64a1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.57\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-265hb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-265hb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.57,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.57,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.338: INFO: Pod "webserver-deployment-69b7448995-jk77b" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jk77b webserver-deployment-69b7448995- deployment-8366  023e329b-0931-4531-b21b-915516d97cd5 218694 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c66d0 0xc0038c66d1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4nksk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4nksk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.338: INFO: Pod "webserver-deployment-69b7448995-mccmr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mccmr webserver-deployment-69b7448995- deployment-8366  24f1c570-5bef-4e56-af7d-dd358f7a500a 218612 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:4f19e6a8041a8439dd928ca85e423ab9e9450a916dcb293163367e8b29dd1d43 cni.projectcalico.org/podIP:10.42.1.104/32 cni.projectcalico.org/podIPs:10.42.1.104/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6860 0xc0038c6861}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.104\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2t4qc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2t4qc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.104,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.104,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.339: INFO: Pod "webserver-deployment-69b7448995-mkd96" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mkd96 webserver-deployment-69b7448995- deployment-8366  d5c440a4-6c5c-4c86-8cd7-3dcf87278d73 218731 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:32318b2d9a56685422c87180d0023ce6393b16279d944bd49bdee317bbc8b80d cni.projectcalico.org/podIP:10.42.2.56/32 cni.projectcalico.org/podIPs:10.42.2.56/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6ab0 0xc0038c6ab1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.56\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tcrhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tcrhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.56,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.56,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.339: INFO: Pod "webserver-deployment-69b7448995-mkxsz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mkxsz webserver-deployment-69b7448995- deployment-8366  b18061de-f894-4c9b-abd8-c3078d5648e8 218690 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6ce0 0xc0038c6ce1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zrcf5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zrcf5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.339: INFO: Pod "webserver-deployment-69b7448995-p5vjs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-p5vjs webserver-deployment-69b7448995- deployment-8366  f9210d8a-024d-435e-920f-3d592ee89ffb 218655 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6e50 0xc0038c6e51}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5dvpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5dvpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.339: INFO: Pod "webserver-deployment-69b7448995-tz2km" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-tz2km webserver-deployment-69b7448995- deployment-8366  7cc63bfa-6ece-47b7-8b2e-da1cf9cc14a5 218611 0 2023-01-10 03:55:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:7cb956909c0eb27113c2d9adf66d1906fbf688174006956f956bd8e50332353a cni.projectcalico.org/podIP:10.42.1.103/32 cni.projectcalico.org/podIPs:10.42.1.103/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c6ff0 0xc0038c6ff1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.103\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pmtpf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pmtpf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.103,StartTime:2023-01-10 03:55:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.340: INFO: Pod "webserver-deployment-69b7448995-wqh44" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wqh44 webserver-deployment-69b7448995- deployment-8366  4905b456-9b23-4e3f-a6a0-994281508f02 218685 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c7220 0xc0038c7221}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7tjfn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7tjfn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.340: INFO: Pod "webserver-deployment-69b7448995-x6qvh" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-x6qvh webserver-deployment-69b7448995- deployment-8366  f10b70c0-db5a-4ba4-825f-074ee4645738 218748 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c73a0 0xc0038c73a1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rqm4v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rqm4v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.340: INFO: Pod "webserver-deployment-69b7448995-ztplz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-ztplz webserver-deployment-69b7448995- deployment-8366  62c7eca0-b031-4061-b03e-d0e14e86d54d 218741 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db204632-da53-4b5e-bc34-8dd0113b0f05 0xc0038c7597 0xc0038c7598}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db204632-da53-4b5e-bc34-8dd0113b0f05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h8gw5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h8gw5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.341: INFO: Pod "webserver-deployment-845c8977d9-2gqxt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2gqxt webserver-deployment-845c8977d9- deployment-8366  bc1b18a7-7649-48c3-a798-a4765765c42f 218658 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c7787 0xc0038c7788}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bfhvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bfhvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.341: INFO: Pod "webserver-deployment-845c8977d9-8ft2c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8ft2c webserver-deployment-845c8977d9- deployment-8366  65f8b853-33e8-4a38-98f4-be7d027fb8f2 218649 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c78f0 0xc0038c78f1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8t6zd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8t6zd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.341: INFO: Pod "webserver-deployment-845c8977d9-bqkxv" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bqkxv webserver-deployment-845c8977d9- deployment-8366  4f1cb5ec-c8bd-4be0-8c2e-a52c992c4a24 218460 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d9569d2764d2686e4ce2aafd7d8b3152b5294fd8013aca71a061e2b19896954a cni.projectcalico.org/podIP:10.42.0.42/32 cni.projectcalico.org/podIPs:10.42.0.42/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c7a70 0xc0038c7a71}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gw2l4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gw2l4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:10.42.0.42,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://e9f558ef91e02c3c2b31d37063f710a411663f18ddd9e289bfebbb27febfdc4d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.341: INFO: Pod "webserver-deployment-845c8977d9-bxghp" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bxghp webserver-deployment-845c8977d9- deployment-8366  e01799f5-2cf6-4bc5-9c8a-a699c78689e3 218466 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ab4231e9a698294f081412efa431098d4f0694ecc40fb20778d78f469a4d001e cni.projectcalico.org/podIP:10.42.0.40/32 cni.projectcalico.org/podIPs:10.42.0.40/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c7ca0 0xc0038c7ca1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hv98t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hv98t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:10.42.0.40,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://d562abae4e3bf9c6bf818bf86330e4cfb2d55bbbedd5cf8063fe57d3108b768b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.342: INFO: Pod "webserver-deployment-845c8977d9-ccmqs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ccmqs webserver-deployment-845c8977d9- deployment-8366  1e1e201b-c075-4f61-b2c9-c3e454e958a7 218746 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4dc9311d90532950b082b09f018356564cb6e2d788755269c3083c6ff5408440 cni.projectcalico.org/podIP:10.42.2.58/32 cni.projectcalico.org/podIPs:10.42.2.58/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc0038c7ed0 0xc0038c7ed1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tlmz6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tlmz6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.342: INFO: Pod "webserver-deployment-845c8977d9-ck4hs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ck4hs webserver-deployment-845c8977d9- deployment-8366  67016e88-cf6a-4202-af55-172c17915de6 218661 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e0b7 0xc00372e0b8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c9zwx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c9zwx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.342: INFO: Pod "webserver-deployment-845c8977d9-clxhg" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-clxhg webserver-deployment-845c8977d9- deployment-8366  5673358a-7d87-4b15-81c6-d03576ec177a 218463 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:692c71b99818e5546b641dc0fadc2006f6ce9a56291dc3ad8dd83682808219c9 cni.projectcalico.org/podIP:10.42.0.41/32 cni.projectcalico.org/podIPs:10.42.0.41/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e240 0xc00372e241}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4cnpv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4cnpv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:10.42.0.41,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://293865e22eeecde9403758c4e82e368587d4abc8561a91d8926e27282302d568,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.342: INFO: Pod "webserver-deployment-845c8977d9-gcz6r" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gcz6r webserver-deployment-845c8977d9- deployment-8366  c8883a0f-fd1c-4a17-ad3d-79873da2eac0 218744 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3f29331abe439820c6ecab53ebb2c25b63c5d33ef7b10dbe4a0ac45b364d7864 cni.projectcalico.org/podIP:10.42.1.106/32 cni.projectcalico.org/podIPs:10.42.1.106/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e460 0xc00372e461}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wc44n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wc44n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.351: INFO: Pod "webserver-deployment-845c8977d9-lrkcq" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-lrkcq webserver-deployment-845c8977d9- deployment-8366  ac5bd763-8908-47e4-9de2-2f4d2994a647 218475 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:783333039a1c4e8fec6b999dd774ab955348c2d5edd3da7ed35bda5c43750808 cni.projectcalico.org/podIP:10.42.2.55/32 cni.projectcalico.org/podIPs:10.42.2.55/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e600 0xc00372e601}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.55\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rcjvt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rcjvt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.55,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://81d96ef42778b96100acc4897d1a0bda5de7b42e6b324c177456ccfdc2d15e7e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.55,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-pj2fp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-pj2fp webserver-deployment-845c8977d9- deployment-8366  3d67a61e-8fab-4c42-a5fb-185533558a1e 218751 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:10648721d9df3afc6991ceb563c565272b728d0fc03a74ab705b569cb840022a cni.projectcalico.org/podIP:10.42.2.59/32 cni.projectcalico.org/podIPs:10.42.2.59/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e830 0xc00372e831}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sdxcd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sdxcd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-prkm4" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-prkm4 webserver-deployment-845c8977d9- deployment-8366  22cfb9a2-777e-4166-960c-da4e229b8bfc 218469 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b5077aed2ea3a969e781693bde1069b95184e7ecb4b236754c822dc3ac36a88d cni.projectcalico.org/podIP:10.42.1.101/32 cni.projectcalico.org/podIPs:10.42.1.101/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372e9e0 0xc00372e9e1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.101\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vsdw4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vsdw4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.101,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://e7bdc5cd4855f44693d81638c5582c6897aab547180f71342eead97921804e7e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-t45fx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-t45fx webserver-deployment-845c8977d9- deployment-8366  d496ee88-94c6-4ccd-9fab-e9c3277df28b 218752 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:93dfc63742f82087a1673e7ee50b8eb7ff963c5a240193717c9c3033084da526 cni.projectcalico.org/podIP:10.42.2.60/32 cni.projectcalico.org/podIPs:10.42.2.60/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372ec27 0xc00372ec28}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j87wj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j87wj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-tv6c6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tv6c6 webserver-deployment-845c8977d9- deployment-8366  5eac7991-6840-45ed-bbc8-3e6c9bf398b8 218730 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372edd0 0xc00372edd1}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-76hzq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-76hzq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.352: INFO: Pod "webserver-deployment-845c8977d9-tzdtt" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tzdtt webserver-deployment-845c8977d9- deployment-8366  5deb54df-4a3c-4d62-a7c6-bacc8869d9b4 218476 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:fbd287347bf5b01c4374568e47fabe30357a27e4503858ba0b25bc843747968b cni.projectcalico.org/podIP:10.42.1.100/32 cni.projectcalico.org/podIPs:10.42.1.100/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372efb7 0xc00372efb8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.100\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4nlgl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4nlgl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.100,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://248d5281fa852e041367935e5baa8cd43ad0e3cda5e80bf5d027da85a10045c3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.353: INFO: Pod "webserver-deployment-845c8977d9-vhp9t" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vhp9t webserver-deployment-845c8977d9- deployment-8366  e14819ef-6bc2-4ef9-bce3-feb05c126db0 218740 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:805c970054796bb83669bc6b160cf7a6e773ba1999dd67844d17fad982645894 cni.projectcalico.org/podIP:10.42.1.105/32 cni.projectcalico.org/podIPs:10.42.1.105/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f1e7 0xc00372f1e8}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwgjq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwgjq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.353: INFO: Pod "webserver-deployment-845c8977d9-vvm2k" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vvm2k webserver-deployment-845c8977d9- deployment-8366  e29335ae-c508-417b-a313-41c276b5c3d4 218487 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d733c4921a9a021b58274fff6af50b28e49ba26ae960f9a7b646ada059096e4b cni.projectcalico.org/podIP:10.42.2.54/32 cni.projectcalico.org/podIPs:10.42.2.54/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f390 0xc00372f391}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.54\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bc97v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bc97v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.54,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://b4cd789c518509d3ae296aef653f9221ffbf65cb3c85ccb5ec9e459adcd46c8a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.353: INFO: Pod "webserver-deployment-845c8977d9-wgswm" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wgswm webserver-deployment-845c8977d9- deployment-8366  6fadd43d-ef68-4a9a-9cbf-c3f6cbc2f473 218716 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f590 0xc00372f591}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dm9dp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dm9dp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.353: INFO: Pod "webserver-deployment-845c8977d9-x7wkx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-x7wkx webserver-deployment-845c8977d9- deployment-8366  5db07607-8afe-418c-b8ad-072696653dc7 218705 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f757 0xc00372f758}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jx6tl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jx6tl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-cp-etcd-wk1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.15.218,PodIP:,StartTime:2023-01-10 03:55:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.354: INFO: Pod "webserver-deployment-845c8977d9-zbwdr" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zbwdr webserver-deployment-845c8977d9- deployment-8366  8544633b-d2cc-43ba-bdfc-7380fd2e9afb 218478 0 2023-01-10 03:55:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1c59d896bcac37bcd02783d535f2ef551a9d190a39e12bc3053f4b5fdc0ea4fc cni.projectcalico.org/podIP:10.42.2.53/32 cni.projectcalico.org/podIPs:10.42.2.53/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372f947 0xc00372f948}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 03:55:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ffczq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ffczq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.53,StartTime:2023-01-10 03:55:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 03:55:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://2ae8dc4025d2b79149051891be91fab03abc35dd63ed3467f177a988a19b960f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 03:55:56.354: INFO: Pod "webserver-deployment-845c8977d9-zrll9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zrll9 webserver-deployment-845c8977d9- deployment-8366  c34ddc98-1534-4d3b-84a1-028769a16bc7 218757 0 2023-01-10 03:55:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:14cc7159e6c2ed27ac1e619caa563ac55a7b51b416eb727f339bbfd730453107 cni.projectcalico.org/podIP:10.42.1.107/32 cni.projectcalico.org/podIPs:10.42.1.107/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1f88b859-4b15-4d23-9aa6-5b0c281e507c 0xc00372fb70 0xc00372fb71}] [] [{kube-controller-manager Update v1 2023-01-10 03:55:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f88b859-4b15-4d23-9aa6-5b0c281e507c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 03:55:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l2p6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l2p6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 03:55:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 10 03:55:56.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8366" for this suite. 01/10/23 03:55:56.399
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:55:56.515
Jan 10 03:55:56.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 03:55:56.546
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:56.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:56.642
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 03:55:56.856
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 03:55:57.388
STEP: Deploying the webhook pod 01/10/23 03:55:57.464
STEP: Wait for the deployment to be ready 01/10/23 03:55:57.546
Jan 10 03:55:57.622: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 10 03:55:59.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 03:56:01.719: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 03:56:03.636: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/10/23 03:56:05.633
STEP: Verifying the service has paired with the endpoint 01/10/23 03:56:05.644
Jan 10 03:56:06.645: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 01/10/23 03:56:06.702
STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 03:56:06.744
STEP: Deleting the collection of validation webhooks 01/10/23 03:56:06.783
STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 03:56:06.836
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:56:06.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9449" for this suite. 01/10/23 03:56:06.849
STEP: Destroying namespace "webhook-9449-markers" for this suite. 01/10/23 03:56:06.858
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":84,"skipped":1394,"failed":0}
------------------------------
• [SLOW TEST] [10.417 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:55:56.515
    Jan 10 03:55:56.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 03:55:56.546
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:55:56.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:55:56.642
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 03:55:56.856
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 03:55:57.388
    STEP: Deploying the webhook pod 01/10/23 03:55:57.464
    STEP: Wait for the deployment to be ready 01/10/23 03:55:57.546
    Jan 10 03:55:57.622: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 10 03:55:59.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 03:56:01.719: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 03:56:03.636: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 3, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/10/23 03:56:05.633
    STEP: Verifying the service has paired with the endpoint 01/10/23 03:56:05.644
    Jan 10 03:56:06.645: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 01/10/23 03:56:06.702
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 03:56:06.744
    STEP: Deleting the collection of validation webhooks 01/10/23 03:56:06.783
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 03:56:06.836
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:56:06.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9449" for this suite. 01/10/23 03:56:06.849
    STEP: Destroying namespace "webhook-9449-markers" for this suite. 01/10/23 03:56:06.858
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:56:06.94
Jan 10 03:56:06.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-probe 01/10/23 03:56:06.941
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:07.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:07.021
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d in namespace container-probe-2945 01/10/23 03:56:07.027
Jan 10 03:56:07.046: INFO: Waiting up to 5m0s for pod "liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d" in namespace "container-probe-2945" to be "not pending"
Jan 10 03:56:07.055: INFO: Pod "liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.355634ms
Jan 10 03:56:09.058: INFO: Pod "liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d": Phase="Running", Reason="", readiness=true. Elapsed: 2.011423613s
Jan 10 03:56:09.058: INFO: Pod "liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d" satisfied condition "not pending"
Jan 10 03:56:09.058: INFO: Started pod liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d in namespace container-probe-2945
STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 03:56:09.058
Jan 10 03:56:09.061: INFO: Initial restart count of pod liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d is 0
Jan 10 03:56:29.105: INFO: Restart count of pod container-probe-2945/liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d is now 1 (20.044435961s elapsed)
STEP: deleting the pod 01/10/23 03:56:29.105
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 10 03:56:29.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2945" for this suite. 01/10/23 03:56:29.12
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":85,"skipped":1400,"failed":0}
------------------------------
• [SLOW TEST] [22.185 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:56:06.94
    Jan 10 03:56:06.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-probe 01/10/23 03:56:06.941
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:07.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:07.021
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d in namespace container-probe-2945 01/10/23 03:56:07.027
    Jan 10 03:56:07.046: INFO: Waiting up to 5m0s for pod "liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d" in namespace "container-probe-2945" to be "not pending"
    Jan 10 03:56:07.055: INFO: Pod "liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.355634ms
    Jan 10 03:56:09.058: INFO: Pod "liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d": Phase="Running", Reason="", readiness=true. Elapsed: 2.011423613s
    Jan 10 03:56:09.058: INFO: Pod "liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d" satisfied condition "not pending"
    Jan 10 03:56:09.058: INFO: Started pod liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d in namespace container-probe-2945
    STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 03:56:09.058
    Jan 10 03:56:09.061: INFO: Initial restart count of pod liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d is 0
    Jan 10 03:56:29.105: INFO: Restart count of pod container-probe-2945/liveness-aaad99a7-7bbd-439a-a03a-e3107b05065d is now 1 (20.044435961s elapsed)
    STEP: deleting the pod 01/10/23 03:56:29.105
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 10 03:56:29.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2945" for this suite. 01/10/23 03:56:29.12
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:56:29.125
Jan 10 03:56:29.125: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 03:56:29.126
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:29.154
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:29.165
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-c0344a27-87fb-4f82-8a79-79d413077a7d 01/10/23 03:56:29.169
STEP: Creating a pod to test consume configMaps 01/10/23 03:56:29.176
Jan 10 03:56:29.193: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2" in namespace "projected-4583" to be "Succeeded or Failed"
Jan 10 03:56:29.198: INFO: Pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.052795ms
Jan 10 03:56:31.201: INFO: Pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007937006s
Jan 10 03:56:33.202: INFO: Pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008549522s
STEP: Saw pod success 01/10/23 03:56:33.202
Jan 10 03:56:33.202: INFO: Pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2" satisfied condition "Succeeded or Failed"
Jan 10 03:56:33.204: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 03:56:33.217
Jan 10 03:56:33.227: INFO: Waiting for pod pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2 to disappear
Jan 10 03:56:33.229: INFO: Pod pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 03:56:33.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4583" for this suite. 01/10/23 03:56:33.232
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":86,"skipped":1407,"failed":0}
------------------------------
• [4.113 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:56:29.125
    Jan 10 03:56:29.125: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 03:56:29.126
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:29.154
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:29.165
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-c0344a27-87fb-4f82-8a79-79d413077a7d 01/10/23 03:56:29.169
    STEP: Creating a pod to test consume configMaps 01/10/23 03:56:29.176
    Jan 10 03:56:29.193: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2" in namespace "projected-4583" to be "Succeeded or Failed"
    Jan 10 03:56:29.198: INFO: Pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.052795ms
    Jan 10 03:56:31.201: INFO: Pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007937006s
    Jan 10 03:56:33.202: INFO: Pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008549522s
    STEP: Saw pod success 01/10/23 03:56:33.202
    Jan 10 03:56:33.202: INFO: Pod "pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2" satisfied condition "Succeeded or Failed"
    Jan 10 03:56:33.204: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 03:56:33.217
    Jan 10 03:56:33.227: INFO: Waiting for pod pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2 to disappear
    Jan 10 03:56:33.229: INFO: Pod pod-projected-configmaps-49e80d58-ce5c-46fe-aa90-e36d4ad1dfb2 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 03:56:33.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4583" for this suite. 01/10/23 03:56:33.232
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:56:33.242
Jan 10 03:56:33.242: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 03:56:33.243
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:33.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:33.268
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7237 01/10/23 03:56:33.272
STEP: changing the ExternalName service to type=NodePort 01/10/23 03:56:33.285
STEP: creating replication controller externalname-service in namespace services-7237 01/10/23 03:56:33.336
I0110 03:56:33.363434      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7237, replica count: 2
I0110 03:56:36.415930      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 03:56:36.415: INFO: Creating new exec pod
Jan 10 03:56:36.421: INFO: Waiting up to 5m0s for pod "execpodhf2jn" in namespace "services-7237" to be "running"
Jan 10 03:56:36.425: INFO: Pod "execpodhf2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.552333ms
Jan 10 03:56:38.428: INFO: Pod "execpodhf2jn": Phase="Running", Reason="", readiness=true. Elapsed: 2.006721387s
Jan 10 03:56:38.428: INFO: Pod "execpodhf2jn" satisfied condition "running"
Jan 10 03:56:39.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jan 10 03:56:39.592: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jan 10 03:56:39.592: INFO: stdout: "externalname-service-wklfq"
Jan 10 03:56:39.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.120.3 80'
Jan 10 03:56:39.737: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.120.3 80\nConnection to 10.43.120.3 80 port [tcp/http] succeeded!\n"
Jan 10 03:56:39.737: INFO: stdout: ""
Jan 10 03:56:40.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.120.3 80'
Jan 10 03:56:40.890: INFO: stderr: "+ nc -v -t -w 2+  10.43.120.3 80\necho hostName\nConnection to 10.43.120.3 80 port [tcp/http] succeeded!\n"
Jan 10 03:56:40.890: INFO: stdout: "externalname-service-ph8x9"
Jan 10 03:56:40.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.15.218 31704'
Jan 10 03:56:41.067: INFO: stderr: "+ + ncecho hostName\n -v -t -w 2 172.31.15.218 31704\nConnection to 172.31.15.218 31704 port [tcp/*] succeeded!\n"
Jan 10 03:56:41.067: INFO: stdout: "externalname-service-ph8x9"
Jan 10 03:56:41.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 31704'
Jan 10 03:56:41.276: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 31704\nConnection to 172.31.3.44 31704 port [tcp/*] succeeded!\n"
Jan 10 03:56:41.276: INFO: stdout: ""
Jan 10 03:56:42.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 31704'
Jan 10 03:56:42.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 31704\nConnection to 172.31.3.44 31704 port [tcp/*] succeeded!\n"
Jan 10 03:56:42.455: INFO: stdout: "externalname-service-ph8x9"
Jan 10 03:56:42.455: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 03:56:42.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7237" for this suite. 01/10/23 03:56:42.506
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":87,"skipped":1416,"failed":0}
------------------------------
• [SLOW TEST] [9.271 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:56:33.242
    Jan 10 03:56:33.242: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 03:56:33.243
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:33.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:33.268
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-7237 01/10/23 03:56:33.272
    STEP: changing the ExternalName service to type=NodePort 01/10/23 03:56:33.285
    STEP: creating replication controller externalname-service in namespace services-7237 01/10/23 03:56:33.336
    I0110 03:56:33.363434      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7237, replica count: 2
    I0110 03:56:36.415930      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 03:56:36.415: INFO: Creating new exec pod
    Jan 10 03:56:36.421: INFO: Waiting up to 5m0s for pod "execpodhf2jn" in namespace "services-7237" to be "running"
    Jan 10 03:56:36.425: INFO: Pod "execpodhf2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.552333ms
    Jan 10 03:56:38.428: INFO: Pod "execpodhf2jn": Phase="Running", Reason="", readiness=true. Elapsed: 2.006721387s
    Jan 10 03:56:38.428: INFO: Pod "execpodhf2jn" satisfied condition "running"
    Jan 10 03:56:39.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jan 10 03:56:39.592: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jan 10 03:56:39.592: INFO: stdout: "externalname-service-wklfq"
    Jan 10 03:56:39.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.120.3 80'
    Jan 10 03:56:39.737: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.120.3 80\nConnection to 10.43.120.3 80 port [tcp/http] succeeded!\n"
    Jan 10 03:56:39.737: INFO: stdout: ""
    Jan 10 03:56:40.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.120.3 80'
    Jan 10 03:56:40.890: INFO: stderr: "+ nc -v -t -w 2+  10.43.120.3 80\necho hostName\nConnection to 10.43.120.3 80 port [tcp/http] succeeded!\n"
    Jan 10 03:56:40.890: INFO: stdout: "externalname-service-ph8x9"
    Jan 10 03:56:40.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.15.218 31704'
    Jan 10 03:56:41.067: INFO: stderr: "+ + ncecho hostName\n -v -t -w 2 172.31.15.218 31704\nConnection to 172.31.15.218 31704 port [tcp/*] succeeded!\n"
    Jan 10 03:56:41.067: INFO: stdout: "externalname-service-ph8x9"
    Jan 10 03:56:41.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 31704'
    Jan 10 03:56:41.276: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 31704\nConnection to 172.31.3.44 31704 port [tcp/*] succeeded!\n"
    Jan 10 03:56:41.276: INFO: stdout: ""
    Jan 10 03:56:42.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7237 exec execpodhf2jn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 31704'
    Jan 10 03:56:42.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 31704\nConnection to 172.31.3.44 31704 port [tcp/*] succeeded!\n"
    Jan 10 03:56:42.455: INFO: stdout: "externalname-service-ph8x9"
    Jan 10 03:56:42.455: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 03:56:42.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7237" for this suite. 01/10/23 03:56:42.506
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:56:42.513
Jan 10 03:56:42.513: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 03:56:42.514
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:42.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:42.556
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Jan 10 03:56:42.570: INFO: Waiting up to 5m0s for pod "server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f" in namespace "pods-1222" to be "running and ready"
Jan 10 03:56:42.582: INFO: Pod "server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.840177ms
Jan 10 03:56:42.582: INFO: The phase of Pod server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f is Pending, waiting for it to be Running (with Ready = true)
Jan 10 03:56:44.585: INFO: Pod "server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f": Phase="Running", Reason="", readiness=true. Elapsed: 2.015316941s
Jan 10 03:56:44.585: INFO: The phase of Pod server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f is Running (Ready = true)
Jan 10 03:56:44.585: INFO: Pod "server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f" satisfied condition "running and ready"
Jan 10 03:56:44.610: INFO: Waiting up to 5m0s for pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003" in namespace "pods-1222" to be "Succeeded or Failed"
Jan 10 03:56:44.622: INFO: Pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003": Phase="Pending", Reason="", readiness=false. Elapsed: 11.864759ms
Jan 10 03:56:46.630: INFO: Pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020252966s
Jan 10 03:56:48.625: INFO: Pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015007069s
STEP: Saw pod success 01/10/23 03:56:48.625
Jan 10 03:56:48.625: INFO: Pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003" satisfied condition "Succeeded or Failed"
Jan 10 03:56:48.627: INFO: Trying to get logs from node cncf-wk3 pod client-envvars-61393702-c394-4a3f-9100-46b725a77003 container env3cont: <nil>
STEP: delete the pod 01/10/23 03:56:48.641
Jan 10 03:56:48.653: INFO: Waiting for pod client-envvars-61393702-c394-4a3f-9100-46b725a77003 to disappear
Jan 10 03:56:48.655: INFO: Pod client-envvars-61393702-c394-4a3f-9100-46b725a77003 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 03:56:48.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1222" for this suite. 01/10/23 03:56:48.658
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":88,"skipped":1422,"failed":0}
------------------------------
• [SLOW TEST] [6.152 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:56:42.513
    Jan 10 03:56:42.513: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 03:56:42.514
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:42.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:42.556
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Jan 10 03:56:42.570: INFO: Waiting up to 5m0s for pod "server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f" in namespace "pods-1222" to be "running and ready"
    Jan 10 03:56:42.582: INFO: Pod "server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.840177ms
    Jan 10 03:56:42.582: INFO: The phase of Pod server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 03:56:44.585: INFO: Pod "server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f": Phase="Running", Reason="", readiness=true. Elapsed: 2.015316941s
    Jan 10 03:56:44.585: INFO: The phase of Pod server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f is Running (Ready = true)
    Jan 10 03:56:44.585: INFO: Pod "server-envvars-f22846ad-42c4-4650-afcb-ce93bfde137f" satisfied condition "running and ready"
    Jan 10 03:56:44.610: INFO: Waiting up to 5m0s for pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003" in namespace "pods-1222" to be "Succeeded or Failed"
    Jan 10 03:56:44.622: INFO: Pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003": Phase="Pending", Reason="", readiness=false. Elapsed: 11.864759ms
    Jan 10 03:56:46.630: INFO: Pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020252966s
    Jan 10 03:56:48.625: INFO: Pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015007069s
    STEP: Saw pod success 01/10/23 03:56:48.625
    Jan 10 03:56:48.625: INFO: Pod "client-envvars-61393702-c394-4a3f-9100-46b725a77003" satisfied condition "Succeeded or Failed"
    Jan 10 03:56:48.627: INFO: Trying to get logs from node cncf-wk3 pod client-envvars-61393702-c394-4a3f-9100-46b725a77003 container env3cont: <nil>
    STEP: delete the pod 01/10/23 03:56:48.641
    Jan 10 03:56:48.653: INFO: Waiting for pod client-envvars-61393702-c394-4a3f-9100-46b725a77003 to disappear
    Jan 10 03:56:48.655: INFO: Pod client-envvars-61393702-c394-4a3f-9100-46b725a77003 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 03:56:48.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1222" for this suite. 01/10/23 03:56:48.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:56:48.669
Jan 10 03:56:48.669: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 03:56:48.67
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:48.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:48.713
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Jan 10 03:56:48.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:56:50.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2510" for this suite. 01/10/23 03:56:50.642
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":89,"skipped":1446,"failed":0}
------------------------------
• [1.983 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:56:48.669
    Jan 10 03:56:48.669: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 03:56:48.67
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:48.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:48.713
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Jan 10 03:56:48.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:56:50.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2510" for this suite. 01/10/23 03:56:50.642
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:56:50.652
Jan 10 03:56:50.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename taint-single-pod 01/10/23 03:56:50.654
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:50.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:50.677
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Jan 10 03:56:50.680: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 10 03:57:50.715: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Jan 10 03:57:50.718: INFO: Starting informer...
STEP: Starting pod... 01/10/23 03:57:50.718
Jan 10 03:57:50.736: INFO: Pod is running on cncf-wk2. Tainting Node
STEP: Trying to apply a taint on the Node 01/10/23 03:57:50.736
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/10/23 03:57:50.756
STEP: Waiting short time to make sure Pod is queued for deletion 01/10/23 03:57:50.763
Jan 10 03:57:50.764: INFO: Pod wasn't evicted. Proceeding
Jan 10 03:57:50.764: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/10/23 03:57:50.79
STEP: Waiting some time to make sure that toleration time passed. 01/10/23 03:57:50.8
Jan 10 03:59:05.804: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Jan 10 03:59:05.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-7927" for this suite. 01/10/23 03:59:05.808
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":90,"skipped":1450,"failed":0}
------------------------------
• [SLOW TEST] [135.183 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:56:50.652
    Jan 10 03:56:50.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename taint-single-pod 01/10/23 03:56:50.654
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:56:50.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:56:50.677
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Jan 10 03:56:50.680: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 10 03:57:50.715: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Jan 10 03:57:50.718: INFO: Starting informer...
    STEP: Starting pod... 01/10/23 03:57:50.718
    Jan 10 03:57:50.736: INFO: Pod is running on cncf-wk2. Tainting Node
    STEP: Trying to apply a taint on the Node 01/10/23 03:57:50.736
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/10/23 03:57:50.756
    STEP: Waiting short time to make sure Pod is queued for deletion 01/10/23 03:57:50.763
    Jan 10 03:57:50.764: INFO: Pod wasn't evicted. Proceeding
    Jan 10 03:57:50.764: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/10/23 03:57:50.79
    STEP: Waiting some time to make sure that toleration time passed. 01/10/23 03:57:50.8
    Jan 10 03:59:05.804: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 03:59:05.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-7927" for this suite. 01/10/23 03:59:05.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:59:05.838
Jan 10 03:59:05.843: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 03:59:05.846
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:05.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:05.901
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 03:59:06.004
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 03:59:06.569
STEP: Deploying the webhook pod 01/10/23 03:59:06.575
STEP: Wait for the deployment to be ready 01/10/23 03:59:06.594
Jan 10 03:59:06.601: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 01/10/23 03:59:08.609
STEP: Verifying the service has paired with the endpoint 01/10/23 03:59:08.622
Jan 10 03:59:09.623: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 01/10/23 03:59:09.626
STEP: create a pod 01/10/23 03:59:09.642
Jan 10 03:59:09.646: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-8183" to be "running"
Jan 10 03:59:09.654: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.05047ms
Jan 10 03:59:11.658: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010923471s
Jan 10 03:59:11.658: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 01/10/23 03:59:11.658
Jan 10 03:59:11.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=webhook-8183 attach --namespace=webhook-8183 to-be-attached-pod -i -c=container1'
Jan 10 03:59:11.733: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 03:59:11.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8183" for this suite. 01/10/23 03:59:11.739
STEP: Destroying namespace "webhook-8183-markers" for this suite. 01/10/23 03:59:11.744
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":91,"skipped":1462,"failed":0}
------------------------------
• [SLOW TEST] [5.967 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:59:05.838
    Jan 10 03:59:05.843: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 03:59:05.846
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:05.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:05.901
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 03:59:06.004
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 03:59:06.569
    STEP: Deploying the webhook pod 01/10/23 03:59:06.575
    STEP: Wait for the deployment to be ready 01/10/23 03:59:06.594
    Jan 10 03:59:06.601: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 01/10/23 03:59:08.609
    STEP: Verifying the service has paired with the endpoint 01/10/23 03:59:08.622
    Jan 10 03:59:09.623: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 01/10/23 03:59:09.626
    STEP: create a pod 01/10/23 03:59:09.642
    Jan 10 03:59:09.646: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-8183" to be "running"
    Jan 10 03:59:09.654: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.05047ms
    Jan 10 03:59:11.658: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010923471s
    Jan 10 03:59:11.658: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 01/10/23 03:59:11.658
    Jan 10 03:59:11.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=webhook-8183 attach --namespace=webhook-8183 to-be-attached-pod -i -c=container1'
    Jan 10 03:59:11.733: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 03:59:11.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8183" for this suite. 01/10/23 03:59:11.739
    STEP: Destroying namespace "webhook-8183-markers" for this suite. 01/10/23 03:59:11.744
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:59:11.811
Jan 10 03:59:11.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename events 01/10/23 03:59:11.812
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:11.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:11.862
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 01/10/23 03:59:11.898
STEP: listing all events in all namespaces 01/10/23 03:59:11.913
STEP: patching the test event 01/10/23 03:59:11.99
STEP: fetching the test event 01/10/23 03:59:12.032
STEP: updating the test event 01/10/23 03:59:12.037
STEP: getting the test event 01/10/23 03:59:12.052
STEP: deleting the test event 01/10/23 03:59:12.055
STEP: listing all events in all namespaces 01/10/23 03:59:12.068
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Jan 10 03:59:12.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6538" for this suite. 01/10/23 03:59:12.077
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":92,"skipped":1529,"failed":0}
------------------------------
• [0.276 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:59:11.811
    Jan 10 03:59:11.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename events 01/10/23 03:59:11.812
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:11.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:11.862
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 01/10/23 03:59:11.898
    STEP: listing all events in all namespaces 01/10/23 03:59:11.913
    STEP: patching the test event 01/10/23 03:59:11.99
    STEP: fetching the test event 01/10/23 03:59:12.032
    STEP: updating the test event 01/10/23 03:59:12.037
    STEP: getting the test event 01/10/23 03:59:12.052
    STEP: deleting the test event 01/10/23 03:59:12.055
    STEP: listing all events in all namespaces 01/10/23 03:59:12.068
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Jan 10 03:59:12.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6538" for this suite. 01/10/23 03:59:12.077
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:59:12.095
Jan 10 03:59:12.096: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 03:59:12.096
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:12.15
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:12.155
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 01/10/23 03:59:12.172
Jan 10 03:59:12.206: INFO: Waiting up to 5m0s for pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb" in namespace "emptydir-1512" to be "Succeeded or Failed"
Jan 10 03:59:12.248: INFO: Pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb": Phase="Pending", Reason="", readiness=false. Elapsed: 42.314119ms
Jan 10 03:59:14.255: INFO: Pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048478379s
Jan 10 03:59:16.252: INFO: Pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046411725s
STEP: Saw pod success 01/10/23 03:59:16.252
Jan 10 03:59:16.253: INFO: Pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb" satisfied condition "Succeeded or Failed"
Jan 10 03:59:16.263: INFO: Trying to get logs from node cncf-wk2 pod pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb container test-container: <nil>
STEP: delete the pod 01/10/23 03:59:16.283
Jan 10 03:59:16.311: INFO: Waiting for pod pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb to disappear
Jan 10 03:59:16.313: INFO: Pod pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 03:59:16.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1512" for this suite. 01/10/23 03:59:16.32
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":93,"skipped":1553,"failed":0}
------------------------------
• [4.236 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:59:12.095
    Jan 10 03:59:12.096: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 03:59:12.096
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:12.15
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:12.155
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 01/10/23 03:59:12.172
    Jan 10 03:59:12.206: INFO: Waiting up to 5m0s for pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb" in namespace "emptydir-1512" to be "Succeeded or Failed"
    Jan 10 03:59:12.248: INFO: Pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb": Phase="Pending", Reason="", readiness=false. Elapsed: 42.314119ms
    Jan 10 03:59:14.255: INFO: Pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048478379s
    Jan 10 03:59:16.252: INFO: Pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046411725s
    STEP: Saw pod success 01/10/23 03:59:16.252
    Jan 10 03:59:16.253: INFO: Pod "pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb" satisfied condition "Succeeded or Failed"
    Jan 10 03:59:16.263: INFO: Trying to get logs from node cncf-wk2 pod pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb container test-container: <nil>
    STEP: delete the pod 01/10/23 03:59:16.283
    Jan 10 03:59:16.311: INFO: Waiting for pod pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb to disappear
    Jan 10 03:59:16.313: INFO: Pod pod-a9fadd1a-8410-4f14-b754-ff37fda5eedb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 03:59:16.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1512" for this suite. 01/10/23 03:59:16.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:59:16.339
Jan 10 03:59:16.339: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 03:59:16.34
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:16.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:16.405
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 01/10/23 03:59:16.444
STEP: watching for Pod to be ready 01/10/23 03:59:16.468
Jan 10 03:59:16.474: INFO: observed Pod pod-test in namespace pods-5922 in phase Pending with labels: map[test-pod-static:true] & conditions []
Jan 10 03:59:16.474: INFO: observed Pod pod-test in namespace pods-5922 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  }]
Jan 10 03:59:16.496: INFO: observed Pod pod-test in namespace pods-5922 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  }]
Jan 10 03:59:17.223: INFO: observed Pod pod-test in namespace pods-5922 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  }]
Jan 10 03:59:17.522: INFO: Found Pod pod-test in namespace pods-5922 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 01/10/23 03:59:17.526
STEP: getting the Pod and ensuring that it's patched 01/10/23 03:59:17.536
STEP: replacing the Pod's status Ready condition to False 01/10/23 03:59:17.538
STEP: check the Pod again to ensure its Ready conditions are False 01/10/23 03:59:17.547
STEP: deleting the Pod via a Collection with a LabelSelector 01/10/23 03:59:17.548
STEP: watching for the Pod to be deleted 01/10/23 03:59:17.555
Jan 10 03:59:17.562: INFO: observed event type MODIFIED
Jan 10 03:59:19.548: INFO: observed event type MODIFIED
Jan 10 03:59:19.690: INFO: observed event type MODIFIED
Jan 10 03:59:20.558: INFO: observed event type MODIFIED
Jan 10 03:59:20.570: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 03:59:20.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5922" for this suite. 01/10/23 03:59:20.582
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":94,"skipped":1603,"failed":0}
------------------------------
• [4.248 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:59:16.339
    Jan 10 03:59:16.339: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 03:59:16.34
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:16.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:16.405
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 01/10/23 03:59:16.444
    STEP: watching for Pod to be ready 01/10/23 03:59:16.468
    Jan 10 03:59:16.474: INFO: observed Pod pod-test in namespace pods-5922 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Jan 10 03:59:16.474: INFO: observed Pod pod-test in namespace pods-5922 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  }]
    Jan 10 03:59:16.496: INFO: observed Pod pod-test in namespace pods-5922 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  }]
    Jan 10 03:59:17.223: INFO: observed Pod pod-test in namespace pods-5922 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  }]
    Jan 10 03:59:17.522: INFO: Found Pod pod-test in namespace pods-5922 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:16 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 01/10/23 03:59:17.526
    STEP: getting the Pod and ensuring that it's patched 01/10/23 03:59:17.536
    STEP: replacing the Pod's status Ready condition to False 01/10/23 03:59:17.538
    STEP: check the Pod again to ensure its Ready conditions are False 01/10/23 03:59:17.547
    STEP: deleting the Pod via a Collection with a LabelSelector 01/10/23 03:59:17.548
    STEP: watching for the Pod to be deleted 01/10/23 03:59:17.555
    Jan 10 03:59:17.562: INFO: observed event type MODIFIED
    Jan 10 03:59:19.548: INFO: observed event type MODIFIED
    Jan 10 03:59:19.690: INFO: observed event type MODIFIED
    Jan 10 03:59:20.558: INFO: observed event type MODIFIED
    Jan 10 03:59:20.570: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 03:59:20.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5922" for this suite. 01/10/23 03:59:20.582
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:59:20.59
Jan 10 03:59:20.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 03:59:20.591
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:20.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:20.629
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 01/10/23 03:59:20.632
Jan 10 03:59:20.656: INFO: Waiting up to 5m0s for pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114" in namespace "emptydir-9400" to be "Succeeded or Failed"
Jan 10 03:59:20.677: INFO: Pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114": Phase="Pending", Reason="", readiness=false. Elapsed: 21.37128ms
Jan 10 03:59:22.682: INFO: Pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025813598s
Jan 10 03:59:24.680: INFO: Pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024660571s
STEP: Saw pod success 01/10/23 03:59:24.68
Jan 10 03:59:24.681: INFO: Pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114" satisfied condition "Succeeded or Failed"
Jan 10 03:59:24.683: INFO: Trying to get logs from node cncf-wk2 pod pod-88e0504d-bc77-4716-b334-f74a1d5d5114 container test-container: <nil>
STEP: delete the pod 01/10/23 03:59:24.69
Jan 10 03:59:24.701: INFO: Waiting for pod pod-88e0504d-bc77-4716-b334-f74a1d5d5114 to disappear
Jan 10 03:59:24.703: INFO: Pod pod-88e0504d-bc77-4716-b334-f74a1d5d5114 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 03:59:24.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9400" for this suite. 01/10/23 03:59:24.707
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":95,"skipped":1646,"failed":0}
------------------------------
• [4.122 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:59:20.59
    Jan 10 03:59:20.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 03:59:20.591
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:20.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:20.629
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 01/10/23 03:59:20.632
    Jan 10 03:59:20.656: INFO: Waiting up to 5m0s for pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114" in namespace "emptydir-9400" to be "Succeeded or Failed"
    Jan 10 03:59:20.677: INFO: Pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114": Phase="Pending", Reason="", readiness=false. Elapsed: 21.37128ms
    Jan 10 03:59:22.682: INFO: Pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025813598s
    Jan 10 03:59:24.680: INFO: Pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024660571s
    STEP: Saw pod success 01/10/23 03:59:24.68
    Jan 10 03:59:24.681: INFO: Pod "pod-88e0504d-bc77-4716-b334-f74a1d5d5114" satisfied condition "Succeeded or Failed"
    Jan 10 03:59:24.683: INFO: Trying to get logs from node cncf-wk2 pod pod-88e0504d-bc77-4716-b334-f74a1d5d5114 container test-container: <nil>
    STEP: delete the pod 01/10/23 03:59:24.69
    Jan 10 03:59:24.701: INFO: Waiting for pod pod-88e0504d-bc77-4716-b334-f74a1d5d5114 to disappear
    Jan 10 03:59:24.703: INFO: Pod pod-88e0504d-bc77-4716-b334-f74a1d5d5114 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 03:59:24.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9400" for this suite. 01/10/23 03:59:24.707
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:59:24.725
Jan 10 03:59:24.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 03:59:24.726
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:24.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:24.753
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 01/10/23 03:59:24.756
Jan 10 03:59:24.763: INFO: created test-pod-1
Jan 10 03:59:24.775: INFO: created test-pod-2
Jan 10 03:59:24.784: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 01/10/23 03:59:24.784
Jan 10 03:59:24.784: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-497' to be running and ready
Jan 10 03:59:24.824: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 10 03:59:24.824: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 10 03:59:24.824: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 10 03:59:24.824: INFO: 0 / 3 pods in namespace 'pods-497' are running and ready (0 seconds elapsed)
Jan 10 03:59:24.824: INFO: expected 0 pod replicas in namespace 'pods-497', 0 are Running and Ready.
Jan 10 03:59:24.824: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
Jan 10 03:59:24.824: INFO: test-pod-1  cncf-wk2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  }]
Jan 10 03:59:24.824: INFO: test-pod-2  cncf-wk2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  }]
Jan 10 03:59:24.824: INFO: test-pod-3  cncf-wk3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  }]
Jan 10 03:59:24.824: INFO: 
Jan 10 03:59:26.831: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 10 03:59:26.831: INFO: 2 / 3 pods in namespace 'pods-497' are running and ready (2 seconds elapsed)
Jan 10 03:59:26.831: INFO: expected 0 pod replicas in namespace 'pods-497', 0 are Running and Ready.
Jan 10 03:59:26.831: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
Jan 10 03:59:26.831: INFO: test-pod-3  cncf-wk3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  }]
Jan 10 03:59:26.831: INFO: 
Jan 10 03:59:28.836: INFO: 3 / 3 pods in namespace 'pods-497' are running and ready (4 seconds elapsed)
Jan 10 03:59:28.836: INFO: expected 0 pod replicas in namespace 'pods-497', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 01/10/23 03:59:28.9
Jan 10 03:59:28.920: INFO: Pod quantity 3 is different from expected quantity 0
Jan 10 03:59:29.930: INFO: Pod quantity 2 is different from expected quantity 0
Jan 10 03:59:30.930: INFO: Pod quantity 1 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 03:59:31.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-497" for this suite. 01/10/23 03:59:31.926
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":96,"skipped":1649,"failed":0}
------------------------------
• [SLOW TEST] [7.208 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:59:24.725
    Jan 10 03:59:24.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 03:59:24.726
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:24.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:24.753
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 01/10/23 03:59:24.756
    Jan 10 03:59:24.763: INFO: created test-pod-1
    Jan 10 03:59:24.775: INFO: created test-pod-2
    Jan 10 03:59:24.784: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 01/10/23 03:59:24.784
    Jan 10 03:59:24.784: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-497' to be running and ready
    Jan 10 03:59:24.824: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 10 03:59:24.824: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 10 03:59:24.824: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 10 03:59:24.824: INFO: 0 / 3 pods in namespace 'pods-497' are running and ready (0 seconds elapsed)
    Jan 10 03:59:24.824: INFO: expected 0 pod replicas in namespace 'pods-497', 0 are Running and Ready.
    Jan 10 03:59:24.824: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
    Jan 10 03:59:24.824: INFO: test-pod-1  cncf-wk2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  }]
    Jan 10 03:59:24.824: INFO: test-pod-2  cncf-wk2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  }]
    Jan 10 03:59:24.824: INFO: test-pod-3  cncf-wk3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  }]
    Jan 10 03:59:24.824: INFO: 
    Jan 10 03:59:26.831: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 10 03:59:26.831: INFO: 2 / 3 pods in namespace 'pods-497' are running and ready (2 seconds elapsed)
    Jan 10 03:59:26.831: INFO: expected 0 pod replicas in namespace 'pods-497', 0 are Running and Ready.
    Jan 10 03:59:26.831: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
    Jan 10 03:59:26.831: INFO: test-pod-3  cncf-wk3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-10 03:59:24 +0000 UTC  }]
    Jan 10 03:59:26.831: INFO: 
    Jan 10 03:59:28.836: INFO: 3 / 3 pods in namespace 'pods-497' are running and ready (4 seconds elapsed)
    Jan 10 03:59:28.836: INFO: expected 0 pod replicas in namespace 'pods-497', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 01/10/23 03:59:28.9
    Jan 10 03:59:28.920: INFO: Pod quantity 3 is different from expected quantity 0
    Jan 10 03:59:29.930: INFO: Pod quantity 2 is different from expected quantity 0
    Jan 10 03:59:30.930: INFO: Pod quantity 1 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 03:59:31.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-497" for this suite. 01/10/23 03:59:31.926
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:59:31.935
Jan 10 03:59:31.935: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename disruption 01/10/23 03:59:31.936
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:31.956
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:31.961
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 01/10/23 03:59:31.965
STEP: Waiting for the pdb to be processed 01/10/23 03:59:31.97
STEP: First trying to evict a pod which shouldn't be evictable 01/10/23 03:59:32.03
STEP: Waiting for all pods to be running 01/10/23 03:59:32.031
Jan 10 03:59:32.039: INFO: pods: 0 < 3
Jan 10 03:59:34.046: INFO: running pods: 2 < 3
STEP: locating a running pod 01/10/23 03:59:36.046
STEP: Updating the pdb to allow a pod to be evicted 01/10/23 03:59:36.057
STEP: Waiting for the pdb to be processed 01/10/23 03:59:36.063
STEP: Trying to evict the same pod we tried earlier which should now be evictable 01/10/23 03:59:38.07
STEP: Waiting for all pods to be running 01/10/23 03:59:38.07
STEP: Waiting for the pdb to observed all healthy pods 01/10/23 03:59:38.08
STEP: Patching the pdb to disallow a pod to be evicted 01/10/23 03:59:38.111
STEP: Waiting for the pdb to be processed 01/10/23 03:59:38.178
STEP: Waiting for all pods to be running 01/10/23 03:59:38.197
Jan 10 03:59:38.202: INFO: running pods: 2 < 3
STEP: locating a running pod 01/10/23 03:59:40.206
STEP: Deleting the pdb to allow a pod to be evicted 01/10/23 03:59:40.212
STEP: Waiting for the pdb to be deleted 01/10/23 03:59:40.216
STEP: Trying to evict the same pod we tried earlier which should now be evictable 01/10/23 03:59:40.218
STEP: Waiting for all pods to be running 01/10/23 03:59:40.218
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 10 03:59:40.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5398" for this suite. 01/10/23 03:59:40.236
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":97,"skipped":1651,"failed":0}
------------------------------
• [SLOW TEST] [8.319 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:59:31.935
    Jan 10 03:59:31.935: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename disruption 01/10/23 03:59:31.936
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:31.956
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:31.961
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 01/10/23 03:59:31.965
    STEP: Waiting for the pdb to be processed 01/10/23 03:59:31.97
    STEP: First trying to evict a pod which shouldn't be evictable 01/10/23 03:59:32.03
    STEP: Waiting for all pods to be running 01/10/23 03:59:32.031
    Jan 10 03:59:32.039: INFO: pods: 0 < 3
    Jan 10 03:59:34.046: INFO: running pods: 2 < 3
    STEP: locating a running pod 01/10/23 03:59:36.046
    STEP: Updating the pdb to allow a pod to be evicted 01/10/23 03:59:36.057
    STEP: Waiting for the pdb to be processed 01/10/23 03:59:36.063
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 01/10/23 03:59:38.07
    STEP: Waiting for all pods to be running 01/10/23 03:59:38.07
    STEP: Waiting for the pdb to observed all healthy pods 01/10/23 03:59:38.08
    STEP: Patching the pdb to disallow a pod to be evicted 01/10/23 03:59:38.111
    STEP: Waiting for the pdb to be processed 01/10/23 03:59:38.178
    STEP: Waiting for all pods to be running 01/10/23 03:59:38.197
    Jan 10 03:59:38.202: INFO: running pods: 2 < 3
    STEP: locating a running pod 01/10/23 03:59:40.206
    STEP: Deleting the pdb to allow a pod to be evicted 01/10/23 03:59:40.212
    STEP: Waiting for the pdb to be deleted 01/10/23 03:59:40.216
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 01/10/23 03:59:40.218
    STEP: Waiting for all pods to be running 01/10/23 03:59:40.218
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 10 03:59:40.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5398" for this suite. 01/10/23 03:59:40.236
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 03:59:40.259
Jan 10 03:59:40.259: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename var-expansion 01/10/23 03:59:40.26
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:40.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:40.337
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 01/10/23 03:59:40.343
STEP: waiting for pod running 01/10/23 03:59:40.362
Jan 10 03:59:40.362: INFO: Waiting up to 2m0s for pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" in namespace "var-expansion-4587" to be "running"
Jan 10 03:59:40.368: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.84863ms
Jan 10 03:59:42.372: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.009626801s
Jan 10 03:59:42.372: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" satisfied condition "running"
STEP: creating a file in subpath 01/10/23 03:59:42.372
Jan 10 03:59:42.374: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4587 PodName:var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:59:42.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:59:42.375: INFO: ExecWithOptions: Clientset creation
Jan 10 03:59:42.375: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/var-expansion-4587/pods/var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 01/10/23 03:59:42.442
Jan 10 03:59:42.445: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4587 PodName:var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 03:59:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 03:59:42.446: INFO: ExecWithOptions: Clientset creation
Jan 10 03:59:42.446: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/var-expansion-4587/pods/var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 01/10/23 03:59:42.524
Jan 10 03:59:43.067: INFO: Successfully updated pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0"
STEP: waiting for annotated pod running 01/10/23 03:59:43.067
Jan 10 03:59:43.067: INFO: Waiting up to 2m0s for pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" in namespace "var-expansion-4587" to be "running"
Jan 10 03:59:43.070: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.354682ms
Jan 10 03:59:43.070: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" satisfied condition "running"
STEP: deleting the pod gracefully 01/10/23 03:59:43.07
Jan 10 03:59:43.070: INFO: Deleting pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" in namespace "var-expansion-4587"
Jan 10 03:59:43.075: INFO: Wait up to 5m0s for pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 10 04:00:15.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4587" for this suite. 01/10/23 04:00:15.09
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":98,"skipped":1655,"failed":0}
------------------------------
• [SLOW TEST] [34.839 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 03:59:40.259
    Jan 10 03:59:40.259: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename var-expansion 01/10/23 03:59:40.26
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 03:59:40.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 03:59:40.337
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 01/10/23 03:59:40.343
    STEP: waiting for pod running 01/10/23 03:59:40.362
    Jan 10 03:59:40.362: INFO: Waiting up to 2m0s for pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" in namespace "var-expansion-4587" to be "running"
    Jan 10 03:59:40.368: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.84863ms
    Jan 10 03:59:42.372: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.009626801s
    Jan 10 03:59:42.372: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" satisfied condition "running"
    STEP: creating a file in subpath 01/10/23 03:59:42.372
    Jan 10 03:59:42.374: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4587 PodName:var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:59:42.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:59:42.375: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:59:42.375: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/var-expansion-4587/pods/var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 01/10/23 03:59:42.442
    Jan 10 03:59:42.445: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4587 PodName:var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 03:59:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 03:59:42.446: INFO: ExecWithOptions: Clientset creation
    Jan 10 03:59:42.446: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/var-expansion-4587/pods/var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 01/10/23 03:59:42.524
    Jan 10 03:59:43.067: INFO: Successfully updated pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0"
    STEP: waiting for annotated pod running 01/10/23 03:59:43.067
    Jan 10 03:59:43.067: INFO: Waiting up to 2m0s for pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" in namespace "var-expansion-4587" to be "running"
    Jan 10 03:59:43.070: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.354682ms
    Jan 10 03:59:43.070: INFO: Pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" satisfied condition "running"
    STEP: deleting the pod gracefully 01/10/23 03:59:43.07
    Jan 10 03:59:43.070: INFO: Deleting pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" in namespace "var-expansion-4587"
    Jan 10 03:59:43.075: INFO: Wait up to 5m0s for pod "var-expansion-feed8700-11db-4241-ae2e-64d6f91160d0" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 10 04:00:15.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4587" for this suite. 01/10/23 04:00:15.09
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:15.101
Jan 10 04:00:15.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename statefulset 01/10/23 04:00:15.102
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:15.154
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:15.178
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3397 01/10/23 04:00:15.186
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-3397 01/10/23 04:00:15.203
Jan 10 04:00:15.285: INFO: Found 0 stateful pods, waiting for 1
Jan 10 04:00:25.290: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 01/10/23 04:00:25.302
STEP: updating a scale subresource 01/10/23 04:00:25.306
STEP: verifying the statefulset Spec.Replicas was modified 01/10/23 04:00:25.316
STEP: Patch a scale subresource 01/10/23 04:00:25.323
STEP: verifying the statefulset Spec.Replicas was modified 01/10/23 04:00:25.339
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 10 04:00:25.347: INFO: Deleting all statefulset in ns statefulset-3397
Jan 10 04:00:25.362: INFO: Scaling statefulset ss to 0
Jan 10 04:00:35.482: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 04:00:35.485: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 10 04:00:35.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3397" for this suite. 01/10/23 04:00:35.503
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":99,"skipped":1695,"failed":0}
------------------------------
• [SLOW TEST] [20.425 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:15.101
    Jan 10 04:00:15.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename statefulset 01/10/23 04:00:15.102
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:15.154
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:15.178
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3397 01/10/23 04:00:15.186
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-3397 01/10/23 04:00:15.203
    Jan 10 04:00:15.285: INFO: Found 0 stateful pods, waiting for 1
    Jan 10 04:00:25.290: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 01/10/23 04:00:25.302
    STEP: updating a scale subresource 01/10/23 04:00:25.306
    STEP: verifying the statefulset Spec.Replicas was modified 01/10/23 04:00:25.316
    STEP: Patch a scale subresource 01/10/23 04:00:25.323
    STEP: verifying the statefulset Spec.Replicas was modified 01/10/23 04:00:25.339
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 10 04:00:25.347: INFO: Deleting all statefulset in ns statefulset-3397
    Jan 10 04:00:25.362: INFO: Scaling statefulset ss to 0
    Jan 10 04:00:35.482: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 04:00:35.485: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 10 04:00:35.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3397" for this suite. 01/10/23 04:00:35.503
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:35.531
Jan 10 04:00:35.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:00:35.533
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:35.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:35.602
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-23c60948-b505-440a-aed9-6c14d8297897 01/10/23 04:00:35.616
STEP: Creating a pod to test consume configMaps 01/10/23 04:00:35.629
Jan 10 04:00:35.646: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401" in namespace "configmap-3293" to be "Succeeded or Failed"
Jan 10 04:00:35.662: INFO: Pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401": Phase="Pending", Reason="", readiness=false. Elapsed: 15.301353ms
Jan 10 04:00:37.665: INFO: Pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01818719s
Jan 10 04:00:39.665: INFO: Pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018615358s
STEP: Saw pod success 01/10/23 04:00:39.665
Jan 10 04:00:39.665: INFO: Pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401" satisfied condition "Succeeded or Failed"
Jan 10 04:00:39.670: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:00:39.681
Jan 10 04:00:39.694: INFO: Waiting for pod pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401 to disappear
Jan 10 04:00:39.697: INFO: Pod pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:00:39.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3293" for this suite. 01/10/23 04:00:39.702
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":100,"skipped":1760,"failed":0}
------------------------------
• [4.183 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:35.531
    Jan 10 04:00:35.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:00:35.533
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:35.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:35.602
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-23c60948-b505-440a-aed9-6c14d8297897 01/10/23 04:00:35.616
    STEP: Creating a pod to test consume configMaps 01/10/23 04:00:35.629
    Jan 10 04:00:35.646: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401" in namespace "configmap-3293" to be "Succeeded or Failed"
    Jan 10 04:00:35.662: INFO: Pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401": Phase="Pending", Reason="", readiness=false. Elapsed: 15.301353ms
    Jan 10 04:00:37.665: INFO: Pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01818719s
    Jan 10 04:00:39.665: INFO: Pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018615358s
    STEP: Saw pod success 01/10/23 04:00:39.665
    Jan 10 04:00:39.665: INFO: Pod "pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401" satisfied condition "Succeeded or Failed"
    Jan 10 04:00:39.670: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:00:39.681
    Jan 10 04:00:39.694: INFO: Waiting for pod pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401 to disappear
    Jan 10 04:00:39.697: INFO: Pod pod-configmaps-9b7809e0-54a6-488d-b2ef-491ac8b05401 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:00:39.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3293" for this suite. 01/10/23 04:00:39.702
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:39.718
Jan 10 04:00:39.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 04:00:39.719
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:39.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:39.759
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 01/10/23 04:00:39.765
STEP: submitting the pod to kubernetes 01/10/23 04:00:39.765
Jan 10 04:00:39.792: INFO: Waiting up to 5m0s for pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24" in namespace "pods-4273" to be "running and ready"
Jan 10 04:00:39.828: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24": Phase="Pending", Reason="", readiness=false. Elapsed: 35.975098ms
Jan 10 04:00:39.829: INFO: The phase of Pod pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:00:41.832: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24": Phase="Running", Reason="", readiness=true. Elapsed: 2.03997135s
Jan 10 04:00:41.833: INFO: The phase of Pod pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24 is Running (Ready = true)
Jan 10 04:00:41.833: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 01/10/23 04:00:41.835
STEP: updating the pod 01/10/23 04:00:41.838
Jan 10 04:00:42.346: INFO: Successfully updated pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24"
Jan 10 04:00:42.346: INFO: Waiting up to 5m0s for pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24" in namespace "pods-4273" to be "running"
Jan 10 04:00:42.348: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24": Phase="Running", Reason="", readiness=true. Elapsed: 2.364921ms
Jan 10 04:00:42.348: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 01/10/23 04:00:42.348
Jan 10 04:00:42.351: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 04:00:42.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4273" for this suite. 01/10/23 04:00:42.358
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":101,"skipped":1770,"failed":0}
------------------------------
• [2.647 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:39.718
    Jan 10 04:00:39.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 04:00:39.719
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:39.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:39.759
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 01/10/23 04:00:39.765
    STEP: submitting the pod to kubernetes 01/10/23 04:00:39.765
    Jan 10 04:00:39.792: INFO: Waiting up to 5m0s for pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24" in namespace "pods-4273" to be "running and ready"
    Jan 10 04:00:39.828: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24": Phase="Pending", Reason="", readiness=false. Elapsed: 35.975098ms
    Jan 10 04:00:39.829: INFO: The phase of Pod pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:00:41.832: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24": Phase="Running", Reason="", readiness=true. Elapsed: 2.03997135s
    Jan 10 04:00:41.833: INFO: The phase of Pod pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24 is Running (Ready = true)
    Jan 10 04:00:41.833: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 01/10/23 04:00:41.835
    STEP: updating the pod 01/10/23 04:00:41.838
    Jan 10 04:00:42.346: INFO: Successfully updated pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24"
    Jan 10 04:00:42.346: INFO: Waiting up to 5m0s for pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24" in namespace "pods-4273" to be "running"
    Jan 10 04:00:42.348: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24": Phase="Running", Reason="", readiness=true. Elapsed: 2.364921ms
    Jan 10 04:00:42.348: INFO: Pod "pod-update-893ee4ad-a395-4787-9cc1-0ba24eaade24" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 01/10/23 04:00:42.348
    Jan 10 04:00:42.351: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 04:00:42.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4273" for this suite. 01/10/23 04:00:42.358
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:42.366
Jan 10 04:00:42.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:00:42.366
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:42.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:42.423
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:00:42.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4998" for this suite. 01/10/23 04:00:42.449
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":102,"skipped":1775,"failed":0}
------------------------------
• [0.096 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:42.366
    Jan 10 04:00:42.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:00:42.366
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:42.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:42.423
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:00:42.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4998" for this suite. 01/10/23 04:00:42.449
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:42.473
Jan 10 04:00:42.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 04:00:42.479
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:42.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:42.519
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 01/10/23 04:00:42.523
Jan 10 04:00:42.523: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6289 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 01/10/23 04:00:42.587
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 04:00:42.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6289" for this suite. 01/10/23 04:00:42.609
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":103,"skipped":1801,"failed":0}
------------------------------
• [0.149 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:42.473
    Jan 10 04:00:42.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 04:00:42.479
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:42.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:42.519
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 01/10/23 04:00:42.523
    Jan 10 04:00:42.523: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-6289 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 01/10/23 04:00:42.587
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 04:00:42.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6289" for this suite. 01/10/23 04:00:42.609
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:42.627
Jan 10 04:00:42.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename deployment 01/10/23 04:00:42.628
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:42.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:42.677
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Jan 10 04:00:42.696: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 10 04:00:47.703: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/10/23 04:00:47.703
Jan 10 04:00:47.703: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 01/10/23 04:00:47.721
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 10 04:00:47.739: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2169  41aea911-5f4a-4830-b003-7b158e91ce9b 221063 1 2023-01-10 04:00:47 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-01-10 04:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003acf478 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Jan 10 04:00:47.752: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-2169  c1495532-21a9-44ee-88c6-d77a556b758d 221066 1 2023-01-10 04:00:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 41aea911-5f4a-4830-b003-7b158e91ce9b 0xc003acf8f7 0xc003acf8f8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"41aea911-5f4a-4830-b003-7b158e91ce9b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003acf988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:00:47.752: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 10 04:00:47.752: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2169  ffc071b1-74dc-4b6c-80c4-40e28ba6f1aa 221064 1 2023-01-10 04:00:42 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 41aea911-5f4a-4830-b003-7b158e91ce9b 0xc003acf7c7 0xc003acf7c8}] [] [{e2e.test Update apps/v1 2023-01-10 04:00:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:00:43 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-01-10 04:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"41aea911-5f4a-4830-b003-7b158e91ce9b\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003acf888 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:00:47.776: INFO: Pod "test-cleanup-controller-297bb" is available:
&Pod{ObjectMeta:{test-cleanup-controller-297bb test-cleanup-controller- deployment-2169  92b5050c-58ed-462d-aca5-afbad43753d0 221030 0 2023-01-10 04:00:42 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:c2b46dd756e0b4753763edb7a770251fad1773fcac1fb2d9b7cca863634565d3 cni.projectcalico.org/podIP:10.42.1.131/32 cni.projectcalico.org/podIPs:10.42.1.131/32] [{apps/v1 ReplicaSet test-cleanup-controller ffc071b1-74dc-4b6c-80c4-40e28ba6f1aa 0xc0001a57a7 0xc0001a57a8}] [] [{kube-controller-manager Update v1 2023-01-10 04:00:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ffc071b1-74dc-4b6c-80c4-40e28ba6f1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:00:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:00:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.131\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fdm7w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fdm7w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:00:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:00:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:00:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:00:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.131,StartTime:2023-01-10 04:00:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:00:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://c95498085a8d444bbc0eba14567f0216dfb2165940dfb7123d020ffec9673e66,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 04:00:47.778: INFO: Pod "test-cleanup-deployment-69cb9c5497-c5s52" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-c5s52 test-cleanup-deployment-69cb9c5497- deployment-2169  71ad67bc-ed63-4f28-93c1-e18c3e70df84 221067 0 2023-01-10 04:00:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 c1495532-21a9-44ee-88c6-d77a556b758d 0xc0037de077 0xc0037de078}] [] [{kube-controller-manager Update v1 2023-01-10 04:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c1495532-21a9-44ee-88c6-d77a556b758d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5l92f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5l92f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 10 04:00:47.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2169" for this suite. 01/10/23 04:00:47.848
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":104,"skipped":1803,"failed":0}
------------------------------
• [SLOW TEST] [5.238 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:42.627
    Jan 10 04:00:42.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename deployment 01/10/23 04:00:42.628
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:42.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:42.677
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Jan 10 04:00:42.696: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Jan 10 04:00:47.703: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/10/23 04:00:47.703
    Jan 10 04:00:47.703: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 01/10/23 04:00:47.721
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 10 04:00:47.739: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2169  41aea911-5f4a-4830-b003-7b158e91ce9b 221063 1 2023-01-10 04:00:47 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-01-10 04:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003acf478 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Jan 10 04:00:47.752: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-2169  c1495532-21a9-44ee-88c6-d77a556b758d 221066 1 2023-01-10 04:00:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 41aea911-5f4a-4830-b003-7b158e91ce9b 0xc003acf8f7 0xc003acf8f8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"41aea911-5f4a-4830-b003-7b158e91ce9b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003acf988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:00:47.752: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Jan 10 04:00:47.752: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2169  ffc071b1-74dc-4b6c-80c4-40e28ba6f1aa 221064 1 2023-01-10 04:00:42 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 41aea911-5f4a-4830-b003-7b158e91ce9b 0xc003acf7c7 0xc003acf7c8}] [] [{e2e.test Update apps/v1 2023-01-10 04:00:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:00:43 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-01-10 04:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"41aea911-5f4a-4830-b003-7b158e91ce9b\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003acf888 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:00:47.776: INFO: Pod "test-cleanup-controller-297bb" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-297bb test-cleanup-controller- deployment-2169  92b5050c-58ed-462d-aca5-afbad43753d0 221030 0 2023-01-10 04:00:42 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:c2b46dd756e0b4753763edb7a770251fad1773fcac1fb2d9b7cca863634565d3 cni.projectcalico.org/podIP:10.42.1.131/32 cni.projectcalico.org/podIPs:10.42.1.131/32] [{apps/v1 ReplicaSet test-cleanup-controller ffc071b1-74dc-4b6c-80c4-40e28ba6f1aa 0xc0001a57a7 0xc0001a57a8}] [] [{kube-controller-manager Update v1 2023-01-10 04:00:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ffc071b1-74dc-4b6c-80c4-40e28ba6f1aa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:00:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:00:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.131\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fdm7w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fdm7w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:00:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:00:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:00:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:00:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.131,StartTime:2023-01-10 04:00:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:00:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://c95498085a8d444bbc0eba14567f0216dfb2165940dfb7123d020ffec9673e66,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 04:00:47.778: INFO: Pod "test-cleanup-deployment-69cb9c5497-c5s52" is not available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-c5s52 test-cleanup-deployment-69cb9c5497- deployment-2169  71ad67bc-ed63-4f28-93c1-e18c3e70df84 221067 0 2023-01-10 04:00:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 c1495532-21a9-44ee-88c6-d77a556b758d 0xc0037de077 0xc0037de078}] [] [{kube-controller-manager Update v1 2023-01-10 04:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c1495532-21a9-44ee-88c6-d77a556b758d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5l92f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5l92f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 10 04:00:47.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2169" for this suite. 01/10/23 04:00:47.848
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:47.867
Jan 10 04:00:47.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:00:47.868
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:47.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:47.972
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-e0770455-487b-48f9-9f23-3f10f95336de 01/10/23 04:00:47.975
STEP: Creating a pod to test consume secrets 01/10/23 04:00:47.988
Jan 10 04:00:48.016: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d" in namespace "projected-5053" to be "Succeeded or Failed"
Jan 10 04:00:48.026: INFO: Pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.144264ms
Jan 10 04:00:50.030: INFO: Pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013876251s
Jan 10 04:00:52.030: INFO: Pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013759249s
STEP: Saw pod success 01/10/23 04:00:52.03
Jan 10 04:00:52.030: INFO: Pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d" satisfied condition "Succeeded or Failed"
Jan 10 04:00:52.034: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d container projected-secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:00:52.047
Jan 10 04:00:52.055: INFO: Waiting for pod pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d to disappear
Jan 10 04:00:52.058: INFO: Pod pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 10 04:00:52.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5053" for this suite. 01/10/23 04:00:52.065
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":105,"skipped":1836,"failed":0}
------------------------------
• [4.206 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:47.867
    Jan 10 04:00:47.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:00:47.868
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:47.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:47.972
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-e0770455-487b-48f9-9f23-3f10f95336de 01/10/23 04:00:47.975
    STEP: Creating a pod to test consume secrets 01/10/23 04:00:47.988
    Jan 10 04:00:48.016: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d" in namespace "projected-5053" to be "Succeeded or Failed"
    Jan 10 04:00:48.026: INFO: Pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.144264ms
    Jan 10 04:00:50.030: INFO: Pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013876251s
    Jan 10 04:00:52.030: INFO: Pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013759249s
    STEP: Saw pod success 01/10/23 04:00:52.03
    Jan 10 04:00:52.030: INFO: Pod "pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d" satisfied condition "Succeeded or Failed"
    Jan 10 04:00:52.034: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:00:52.047
    Jan 10 04:00:52.055: INFO: Waiting for pod pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d to disappear
    Jan 10 04:00:52.058: INFO: Pod pod-projected-secrets-3abf51c8-3d38-44b7-9e10-92f36eb0207d no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 10 04:00:52.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5053" for this suite. 01/10/23 04:00:52.065
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:52.077
Jan 10 04:00:52.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:00:52.078
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:52.106
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:52.11
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 01/10/23 04:00:52.154
Jan 10 04:00:52.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4" in namespace "downward-api-3964" to be "Succeeded or Failed"
Jan 10 04:00:52.191: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.38146ms
Jan 10 04:00:54.197: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017322279s
Jan 10 04:00:56.196: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016208111s
Jan 10 04:00:58.194: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014735585s
STEP: Saw pod success 01/10/23 04:00:58.194
Jan 10 04:00:58.194: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4" satisfied condition "Succeeded or Failed"
Jan 10 04:00:58.197: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4 container client-container: <nil>
STEP: delete the pod 01/10/23 04:00:58.203
Jan 10 04:00:58.221: INFO: Waiting for pod downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4 to disappear
Jan 10 04:00:58.234: INFO: Pod downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 04:00:58.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3964" for this suite. 01/10/23 04:00:58.239
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":106,"skipped":1888,"failed":0}
------------------------------
• [SLOW TEST] [6.170 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:52.077
    Jan 10 04:00:52.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:00:52.078
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:52.106
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:52.11
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 01/10/23 04:00:52.154
    Jan 10 04:00:52.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4" in namespace "downward-api-3964" to be "Succeeded or Failed"
    Jan 10 04:00:52.191: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.38146ms
    Jan 10 04:00:54.197: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017322279s
    Jan 10 04:00:56.196: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016208111s
    Jan 10 04:00:58.194: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014735585s
    STEP: Saw pod success 01/10/23 04:00:58.194
    Jan 10 04:00:58.194: INFO: Pod "downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4" satisfied condition "Succeeded or Failed"
    Jan 10 04:00:58.197: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4 container client-container: <nil>
    STEP: delete the pod 01/10/23 04:00:58.203
    Jan 10 04:00:58.221: INFO: Waiting for pod downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4 to disappear
    Jan 10 04:00:58.234: INFO: Pod downwardapi-volume-bc4f1e7e-5a3e-4643-a4dd-9812cafe85a4 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 04:00:58.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3964" for this suite. 01/10/23 04:00:58.239
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:00:58.253
Jan 10 04:00:58.253: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:00:58.256
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:58.322
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:58.329
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 01/10/23 04:00:58.34
Jan 10 04:00:58.341: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 01/10/23 04:01:14.522
Jan 10 04:01:14.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:01:17.129: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:01:29.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6641" for this suite. 01/10/23 04:01:29.709
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":107,"skipped":1897,"failed":0}
------------------------------
• [SLOW TEST] [31.465 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:00:58.253
    Jan 10 04:00:58.253: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:00:58.256
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:00:58.322
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:00:58.329
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 01/10/23 04:00:58.34
    Jan 10 04:00:58.341: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 01/10/23 04:01:14.522
    Jan 10 04:01:14.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:01:17.129: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:01:29.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6641" for this suite. 01/10/23 04:01:29.709
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:29.718
Jan 10 04:01:29.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:01:29.72
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:29.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:29.781
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-dd90b3e9-2814-475d-863a-b60ff73436a2 01/10/23 04:01:29.784
STEP: Creating a pod to test consume secrets 01/10/23 04:01:29.79
Jan 10 04:01:29.805: INFO: Waiting up to 5m0s for pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f" in namespace "secrets-9803" to be "Succeeded or Failed"
Jan 10 04:01:29.814: INFO: Pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.435816ms
Jan 10 04:01:31.818: INFO: Pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012993994s
Jan 10 04:01:33.820: INFO: Pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015400315s
STEP: Saw pod success 01/10/23 04:01:33.821
Jan 10 04:01:33.821: INFO: Pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f" satisfied condition "Succeeded or Failed"
Jan 10 04:01:33.823: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f container secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:01:33.83
Jan 10 04:01:33.842: INFO: Waiting for pod pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f to disappear
Jan 10 04:01:33.850: INFO: Pod pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:01:33.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9803" for this suite. 01/10/23 04:01:33.856
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":108,"skipped":1901,"failed":0}
------------------------------
• [4.145 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:29.718
    Jan 10 04:01:29.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:01:29.72
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:29.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:29.781
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-dd90b3e9-2814-475d-863a-b60ff73436a2 01/10/23 04:01:29.784
    STEP: Creating a pod to test consume secrets 01/10/23 04:01:29.79
    Jan 10 04:01:29.805: INFO: Waiting up to 5m0s for pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f" in namespace "secrets-9803" to be "Succeeded or Failed"
    Jan 10 04:01:29.814: INFO: Pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.435816ms
    Jan 10 04:01:31.818: INFO: Pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012993994s
    Jan 10 04:01:33.820: INFO: Pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015400315s
    STEP: Saw pod success 01/10/23 04:01:33.821
    Jan 10 04:01:33.821: INFO: Pod "pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f" satisfied condition "Succeeded or Failed"
    Jan 10 04:01:33.823: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f container secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:01:33.83
    Jan 10 04:01:33.842: INFO: Waiting for pod pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f to disappear
    Jan 10 04:01:33.850: INFO: Pod pod-secrets-a471e032-864d-4152-85b3-cfc97f7c0a7f no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:01:33.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9803" for this suite. 01/10/23 04:01:33.856
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:33.871
Jan 10 04:01:33.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:01:33.872
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:33.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:33.987
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:01:34.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7486" for this suite. 01/10/23 04:01:34.094
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":109,"skipped":1966,"failed":0}
------------------------------
• [0.232 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:33.871
    Jan 10 04:01:33.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:01:33.872
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:33.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:33.987
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:01:34.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7486" for this suite. 01/10/23 04:01:34.094
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:34.108
Jan 10 04:01:34.108: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:01:34.108
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:34.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:34.138
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:01:34.187
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:01:34.658
STEP: Deploying the webhook pod 01/10/23 04:01:34.665
STEP: Wait for the deployment to be ready 01/10/23 04:01:34.678
Jan 10 04:01:34.683: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 01/10/23 04:01:36.692
STEP: Verifying the service has paired with the endpoint 01/10/23 04:01:36.702
Jan 10 04:01:37.703: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 01/10/23 04:01:37.705
STEP: Updating a mutating webhook configuration's rules to not include the create operation 01/10/23 04:01:37.724
STEP: Creating a configMap that should not be mutated 01/10/23 04:01:37.729
STEP: Patching a mutating webhook configuration's rules to include the create operation 01/10/23 04:01:37.74
STEP: Creating a configMap that should be mutated 01/10/23 04:01:37.748
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:01:37.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6286" for this suite. 01/10/23 04:01:37.773
STEP: Destroying namespace "webhook-6286-markers" for this suite. 01/10/23 04:01:37.783
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":110,"skipped":2013,"failed":0}
------------------------------
• [3.775 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:34.108
    Jan 10 04:01:34.108: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:01:34.108
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:34.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:34.138
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:01:34.187
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:01:34.658
    STEP: Deploying the webhook pod 01/10/23 04:01:34.665
    STEP: Wait for the deployment to be ready 01/10/23 04:01:34.678
    Jan 10 04:01:34.683: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 01/10/23 04:01:36.692
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:01:36.702
    Jan 10 04:01:37.703: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 01/10/23 04:01:37.705
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 01/10/23 04:01:37.724
    STEP: Creating a configMap that should not be mutated 01/10/23 04:01:37.729
    STEP: Patching a mutating webhook configuration's rules to include the create operation 01/10/23 04:01:37.74
    STEP: Creating a configMap that should be mutated 01/10/23 04:01:37.748
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:01:37.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6286" for this suite. 01/10/23 04:01:37.773
    STEP: Destroying namespace "webhook-6286-markers" for this suite. 01/10/23 04:01:37.783
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:37.883
Jan 10 04:01:37.883: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename containers 01/10/23 04:01:37.884
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:37.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:37.971
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Jan 10 04:01:37.987: INFO: Waiting up to 5m0s for pod "client-containers-2313ef24-7dfe-46cc-a84d-e363271a6d69" in namespace "containers-745" to be "running"
Jan 10 04:01:38.008: INFO: Pod "client-containers-2313ef24-7dfe-46cc-a84d-e363271a6d69": Phase="Pending", Reason="", readiness=false. Elapsed: 21.253418ms
Jan 10 04:01:40.013: INFO: Pod "client-containers-2313ef24-7dfe-46cc-a84d-e363271a6d69": Phase="Running", Reason="", readiness=true. Elapsed: 2.025934348s
Jan 10 04:01:40.013: INFO: Pod "client-containers-2313ef24-7dfe-46cc-a84d-e363271a6d69" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jan 10 04:01:40.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-745" for this suite. 01/10/23 04:01:40.026
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":111,"skipped":2013,"failed":0}
------------------------------
• [2.154 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:37.883
    Jan 10 04:01:37.883: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename containers 01/10/23 04:01:37.884
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:37.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:37.971
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Jan 10 04:01:37.987: INFO: Waiting up to 5m0s for pod "client-containers-2313ef24-7dfe-46cc-a84d-e363271a6d69" in namespace "containers-745" to be "running"
    Jan 10 04:01:38.008: INFO: Pod "client-containers-2313ef24-7dfe-46cc-a84d-e363271a6d69": Phase="Pending", Reason="", readiness=false. Elapsed: 21.253418ms
    Jan 10 04:01:40.013: INFO: Pod "client-containers-2313ef24-7dfe-46cc-a84d-e363271a6d69": Phase="Running", Reason="", readiness=true. Elapsed: 2.025934348s
    Jan 10 04:01:40.013: INFO: Pod "client-containers-2313ef24-7dfe-46cc-a84d-e363271a6d69" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jan 10 04:01:40.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-745" for this suite. 01/10/23 04:01:40.026
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:40.041
Jan 10 04:01:40.041: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-runtime 01/10/23 04:01:40.042
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:40.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:40.069
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 01/10/23 04:01:40.074
STEP: wait for the container to reach Succeeded 01/10/23 04:01:40.081
STEP: get the container status 01/10/23 04:01:45.146
STEP: the container should be terminated 01/10/23 04:01:45.149
STEP: the termination message should be set 01/10/23 04:01:45.149
Jan 10 04:01:45.149: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 01/10/23 04:01:45.149
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 10 04:01:45.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4678" for this suite. 01/10/23 04:01:45.172
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":112,"skipped":2022,"failed":0}
------------------------------
• [SLOW TEST] [5.144 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:40.041
    Jan 10 04:01:40.041: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-runtime 01/10/23 04:01:40.042
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:40.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:40.069
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 01/10/23 04:01:40.074
    STEP: wait for the container to reach Succeeded 01/10/23 04:01:40.081
    STEP: get the container status 01/10/23 04:01:45.146
    STEP: the container should be terminated 01/10/23 04:01:45.149
    STEP: the termination message should be set 01/10/23 04:01:45.149
    Jan 10 04:01:45.149: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 01/10/23 04:01:45.149
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 10 04:01:45.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4678" for this suite. 01/10/23 04:01:45.172
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:45.186
Jan 10 04:01:45.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename disruption 01/10/23 04:01:45.188
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:45.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:45.263
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 01/10/23 04:01:45.278
STEP: Waiting for all pods to be running 01/10/23 04:01:45.344
Jan 10 04:01:45.355: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 10 04:01:47.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3166" for this suite. 01/10/23 04:01:47.363
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":113,"skipped":2031,"failed":0}
------------------------------
• [2.183 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:45.186
    Jan 10 04:01:45.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename disruption 01/10/23 04:01:45.188
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:45.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:45.263
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 01/10/23 04:01:45.278
    STEP: Waiting for all pods to be running 01/10/23 04:01:45.344
    Jan 10 04:01:45.355: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 10 04:01:47.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3166" for this suite. 01/10/23 04:01:47.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:47.374
Jan 10 04:01:47.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 04:01:47.375
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:47.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:47.401
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 01/10/23 04:01:47.407
STEP: Creating a ResourceQuota 01/10/23 04:01:52.41
STEP: Ensuring resource quota status is calculated 01/10/23 04:01:52.415
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 04:01:54.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1631" for this suite. 01/10/23 04:01:54.42
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":114,"skipped":2037,"failed":0}
------------------------------
• [SLOW TEST] [7.053 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:47.374
    Jan 10 04:01:47.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 04:01:47.375
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:47.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:47.401
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 01/10/23 04:01:47.407
    STEP: Creating a ResourceQuota 01/10/23 04:01:52.41
    STEP: Ensuring resource quota status is calculated 01/10/23 04:01:52.415
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 04:01:54.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1631" for this suite. 01/10/23 04:01:54.42
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:54.432
Jan 10 04:01:54.432: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename discovery 01/10/23 04:01:54.433
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:54.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:54.479
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 01/10/23 04:01:54.483
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Jan 10 04:01:54.993: INFO: Checking APIGroup: apiregistration.k8s.io
Jan 10 04:01:54.994: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Jan 10 04:01:54.994: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Jan 10 04:01:54.994: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Jan 10 04:01:54.994: INFO: Checking APIGroup: apps
Jan 10 04:01:54.996: INFO: PreferredVersion.GroupVersion: apps/v1
Jan 10 04:01:54.996: INFO: Versions found [{apps/v1 v1}]
Jan 10 04:01:54.996: INFO: apps/v1 matches apps/v1
Jan 10 04:01:54.996: INFO: Checking APIGroup: events.k8s.io
Jan 10 04:01:54.997: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Jan 10 04:01:54.997: INFO: Versions found [{events.k8s.io/v1 v1}]
Jan 10 04:01:54.997: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Jan 10 04:01:54.997: INFO: Checking APIGroup: authentication.k8s.io
Jan 10 04:01:54.998: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Jan 10 04:01:54.998: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Jan 10 04:01:54.998: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Jan 10 04:01:54.998: INFO: Checking APIGroup: authorization.k8s.io
Jan 10 04:01:54.999: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Jan 10 04:01:54.999: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Jan 10 04:01:54.999: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Jan 10 04:01:54.999: INFO: Checking APIGroup: autoscaling
Jan 10 04:01:54.999: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Jan 10 04:01:54.999: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Jan 10 04:01:55.000: INFO: autoscaling/v2 matches autoscaling/v2
Jan 10 04:01:55.000: INFO: Checking APIGroup: batch
Jan 10 04:01:55.002: INFO: PreferredVersion.GroupVersion: batch/v1
Jan 10 04:01:55.003: INFO: Versions found [{batch/v1 v1}]
Jan 10 04:01:55.003: INFO: batch/v1 matches batch/v1
Jan 10 04:01:55.003: INFO: Checking APIGroup: certificates.k8s.io
Jan 10 04:01:55.004: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Jan 10 04:01:55.004: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Jan 10 04:01:55.004: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Jan 10 04:01:55.004: INFO: Checking APIGroup: networking.k8s.io
Jan 10 04:01:55.005: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Jan 10 04:01:55.005: INFO: Versions found [{networking.k8s.io/v1 v1}]
Jan 10 04:01:55.005: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Jan 10 04:01:55.005: INFO: Checking APIGroup: policy
Jan 10 04:01:55.005: INFO: PreferredVersion.GroupVersion: policy/v1
Jan 10 04:01:55.005: INFO: Versions found [{policy/v1 v1}]
Jan 10 04:01:55.005: INFO: policy/v1 matches policy/v1
Jan 10 04:01:55.005: INFO: Checking APIGroup: rbac.authorization.k8s.io
Jan 10 04:01:55.006: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Jan 10 04:01:55.006: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Jan 10 04:01:55.006: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Jan 10 04:01:55.006: INFO: Checking APIGroup: storage.k8s.io
Jan 10 04:01:55.007: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Jan 10 04:01:55.007: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Jan 10 04:01:55.007: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Jan 10 04:01:55.007: INFO: Checking APIGroup: admissionregistration.k8s.io
Jan 10 04:01:55.008: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Jan 10 04:01:55.008: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Jan 10 04:01:55.008: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Jan 10 04:01:55.008: INFO: Checking APIGroup: apiextensions.k8s.io
Jan 10 04:01:55.009: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Jan 10 04:01:55.009: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Jan 10 04:01:55.009: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Jan 10 04:01:55.009: INFO: Checking APIGroup: scheduling.k8s.io
Jan 10 04:01:55.010: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Jan 10 04:01:55.010: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Jan 10 04:01:55.010: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Jan 10 04:01:55.010: INFO: Checking APIGroup: coordination.k8s.io
Jan 10 04:01:55.011: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Jan 10 04:01:55.011: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Jan 10 04:01:55.011: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Jan 10 04:01:55.011: INFO: Checking APIGroup: node.k8s.io
Jan 10 04:01:55.012: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Jan 10 04:01:55.012: INFO: Versions found [{node.k8s.io/v1 v1}]
Jan 10 04:01:55.012: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Jan 10 04:01:55.012: INFO: Checking APIGroup: discovery.k8s.io
Jan 10 04:01:55.012: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Jan 10 04:01:55.012: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Jan 10 04:01:55.012: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Jan 10 04:01:55.012: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Jan 10 04:01:55.013: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Jan 10 04:01:55.013: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Jan 10 04:01:55.013: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Jan 10 04:01:55.013: INFO: Checking APIGroup: catalog.cattle.io
Jan 10 04:01:55.014: INFO: PreferredVersion.GroupVersion: catalog.cattle.io/v1
Jan 10 04:01:55.014: INFO: Versions found [{catalog.cattle.io/v1 v1}]
Jan 10 04:01:55.014: INFO: catalog.cattle.io/v1 matches catalog.cattle.io/v1
Jan 10 04:01:55.014: INFO: Checking APIGroup: crd.projectcalico.org
Jan 10 04:01:55.015: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Jan 10 04:01:55.015: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Jan 10 04:01:55.015: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Jan 10 04:01:55.015: INFO: Checking APIGroup: ui.cattle.io
Jan 10 04:01:55.015: INFO: PreferredVersion.GroupVersion: ui.cattle.io/v1
Jan 10 04:01:55.015: INFO: Versions found [{ui.cattle.io/v1 v1}]
Jan 10 04:01:55.015: INFO: ui.cattle.io/v1 matches ui.cattle.io/v1
Jan 10 04:01:55.015: INFO: Checking APIGroup: cluster.cattle.io
Jan 10 04:01:55.016: INFO: PreferredVersion.GroupVersion: cluster.cattle.io/v3
Jan 10 04:01:55.016: INFO: Versions found [{cluster.cattle.io/v3 v3}]
Jan 10 04:01:55.016: INFO: cluster.cattle.io/v3 matches cluster.cattle.io/v3
Jan 10 04:01:55.016: INFO: Checking APIGroup: management.cattle.io
Jan 10 04:01:55.018: INFO: PreferredVersion.GroupVersion: management.cattle.io/v3
Jan 10 04:01:55.018: INFO: Versions found [{management.cattle.io/v3 v3}]
Jan 10 04:01:55.018: INFO: management.cattle.io/v3 matches management.cattle.io/v3
Jan 10 04:01:55.018: INFO: Checking APIGroup: metrics.k8s.io
Jan 10 04:01:55.018: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Jan 10 04:01:55.018: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Jan 10 04:01:55.018: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Jan 10 04:01:55.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-2386" for this suite. 01/10/23 04:01:55.021
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":115,"skipped":2056,"failed":0}
------------------------------
• [0.613 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:54.432
    Jan 10 04:01:54.432: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename discovery 01/10/23 04:01:54.433
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:54.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:54.479
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 01/10/23 04:01:54.483
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Jan 10 04:01:54.993: INFO: Checking APIGroup: apiregistration.k8s.io
    Jan 10 04:01:54.994: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Jan 10 04:01:54.994: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Jan 10 04:01:54.994: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Jan 10 04:01:54.994: INFO: Checking APIGroup: apps
    Jan 10 04:01:54.996: INFO: PreferredVersion.GroupVersion: apps/v1
    Jan 10 04:01:54.996: INFO: Versions found [{apps/v1 v1}]
    Jan 10 04:01:54.996: INFO: apps/v1 matches apps/v1
    Jan 10 04:01:54.996: INFO: Checking APIGroup: events.k8s.io
    Jan 10 04:01:54.997: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Jan 10 04:01:54.997: INFO: Versions found [{events.k8s.io/v1 v1}]
    Jan 10 04:01:54.997: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Jan 10 04:01:54.997: INFO: Checking APIGroup: authentication.k8s.io
    Jan 10 04:01:54.998: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Jan 10 04:01:54.998: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Jan 10 04:01:54.998: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Jan 10 04:01:54.998: INFO: Checking APIGroup: authorization.k8s.io
    Jan 10 04:01:54.999: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Jan 10 04:01:54.999: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Jan 10 04:01:54.999: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Jan 10 04:01:54.999: INFO: Checking APIGroup: autoscaling
    Jan 10 04:01:54.999: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Jan 10 04:01:54.999: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Jan 10 04:01:55.000: INFO: autoscaling/v2 matches autoscaling/v2
    Jan 10 04:01:55.000: INFO: Checking APIGroup: batch
    Jan 10 04:01:55.002: INFO: PreferredVersion.GroupVersion: batch/v1
    Jan 10 04:01:55.003: INFO: Versions found [{batch/v1 v1}]
    Jan 10 04:01:55.003: INFO: batch/v1 matches batch/v1
    Jan 10 04:01:55.003: INFO: Checking APIGroup: certificates.k8s.io
    Jan 10 04:01:55.004: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Jan 10 04:01:55.004: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Jan 10 04:01:55.004: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Jan 10 04:01:55.004: INFO: Checking APIGroup: networking.k8s.io
    Jan 10 04:01:55.005: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Jan 10 04:01:55.005: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Jan 10 04:01:55.005: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Jan 10 04:01:55.005: INFO: Checking APIGroup: policy
    Jan 10 04:01:55.005: INFO: PreferredVersion.GroupVersion: policy/v1
    Jan 10 04:01:55.005: INFO: Versions found [{policy/v1 v1}]
    Jan 10 04:01:55.005: INFO: policy/v1 matches policy/v1
    Jan 10 04:01:55.005: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Jan 10 04:01:55.006: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Jan 10 04:01:55.006: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Jan 10 04:01:55.006: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Jan 10 04:01:55.006: INFO: Checking APIGroup: storage.k8s.io
    Jan 10 04:01:55.007: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Jan 10 04:01:55.007: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Jan 10 04:01:55.007: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Jan 10 04:01:55.007: INFO: Checking APIGroup: admissionregistration.k8s.io
    Jan 10 04:01:55.008: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Jan 10 04:01:55.008: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Jan 10 04:01:55.008: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Jan 10 04:01:55.008: INFO: Checking APIGroup: apiextensions.k8s.io
    Jan 10 04:01:55.009: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Jan 10 04:01:55.009: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Jan 10 04:01:55.009: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Jan 10 04:01:55.009: INFO: Checking APIGroup: scheduling.k8s.io
    Jan 10 04:01:55.010: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Jan 10 04:01:55.010: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Jan 10 04:01:55.010: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Jan 10 04:01:55.010: INFO: Checking APIGroup: coordination.k8s.io
    Jan 10 04:01:55.011: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Jan 10 04:01:55.011: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Jan 10 04:01:55.011: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Jan 10 04:01:55.011: INFO: Checking APIGroup: node.k8s.io
    Jan 10 04:01:55.012: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Jan 10 04:01:55.012: INFO: Versions found [{node.k8s.io/v1 v1}]
    Jan 10 04:01:55.012: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Jan 10 04:01:55.012: INFO: Checking APIGroup: discovery.k8s.io
    Jan 10 04:01:55.012: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Jan 10 04:01:55.012: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Jan 10 04:01:55.012: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Jan 10 04:01:55.012: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Jan 10 04:01:55.013: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Jan 10 04:01:55.013: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Jan 10 04:01:55.013: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Jan 10 04:01:55.013: INFO: Checking APIGroup: catalog.cattle.io
    Jan 10 04:01:55.014: INFO: PreferredVersion.GroupVersion: catalog.cattle.io/v1
    Jan 10 04:01:55.014: INFO: Versions found [{catalog.cattle.io/v1 v1}]
    Jan 10 04:01:55.014: INFO: catalog.cattle.io/v1 matches catalog.cattle.io/v1
    Jan 10 04:01:55.014: INFO: Checking APIGroup: crd.projectcalico.org
    Jan 10 04:01:55.015: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Jan 10 04:01:55.015: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Jan 10 04:01:55.015: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Jan 10 04:01:55.015: INFO: Checking APIGroup: ui.cattle.io
    Jan 10 04:01:55.015: INFO: PreferredVersion.GroupVersion: ui.cattle.io/v1
    Jan 10 04:01:55.015: INFO: Versions found [{ui.cattle.io/v1 v1}]
    Jan 10 04:01:55.015: INFO: ui.cattle.io/v1 matches ui.cattle.io/v1
    Jan 10 04:01:55.015: INFO: Checking APIGroup: cluster.cattle.io
    Jan 10 04:01:55.016: INFO: PreferredVersion.GroupVersion: cluster.cattle.io/v3
    Jan 10 04:01:55.016: INFO: Versions found [{cluster.cattle.io/v3 v3}]
    Jan 10 04:01:55.016: INFO: cluster.cattle.io/v3 matches cluster.cattle.io/v3
    Jan 10 04:01:55.016: INFO: Checking APIGroup: management.cattle.io
    Jan 10 04:01:55.018: INFO: PreferredVersion.GroupVersion: management.cattle.io/v3
    Jan 10 04:01:55.018: INFO: Versions found [{management.cattle.io/v3 v3}]
    Jan 10 04:01:55.018: INFO: management.cattle.io/v3 matches management.cattle.io/v3
    Jan 10 04:01:55.018: INFO: Checking APIGroup: metrics.k8s.io
    Jan 10 04:01:55.018: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Jan 10 04:01:55.018: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Jan 10 04:01:55.018: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Jan 10 04:01:55.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-2386" for this suite. 01/10/23 04:01:55.021
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:55.05
Jan 10 04:01:55.050: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replication-controller 01/10/23 04:01:55.051
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:55.127
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:55.135
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 01/10/23 04:01:55.144
STEP: waiting for RC to be added 01/10/23 04:01:55.155
STEP: waiting for available Replicas 01/10/23 04:01:55.155
STEP: patching ReplicationController 01/10/23 04:01:56.443
STEP: waiting for RC to be modified 01/10/23 04:01:56.453
STEP: patching ReplicationController status 01/10/23 04:01:56.454
STEP: waiting for RC to be modified 01/10/23 04:01:56.461
STEP: waiting for available Replicas 01/10/23 04:01:56.461
STEP: fetching ReplicationController status 01/10/23 04:01:56.464
STEP: patching ReplicationController scale 01/10/23 04:01:56.466
STEP: waiting for RC to be modified 01/10/23 04:01:56.473
STEP: waiting for ReplicationController's scale to be the max amount 01/10/23 04:01:56.473
STEP: fetching ReplicationController; ensuring that it's patched 01/10/23 04:01:58.265
STEP: updating ReplicationController status 01/10/23 04:01:58.27
STEP: waiting for RC to be modified 01/10/23 04:01:58.276
STEP: listing all ReplicationControllers 01/10/23 04:01:58.276
STEP: checking that ReplicationController has expected values 01/10/23 04:01:58.279
STEP: deleting ReplicationControllers by collection 01/10/23 04:01:58.279
STEP: waiting for ReplicationController to have a DELETED watchEvent 01/10/23 04:01:58.299
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 10 04:01:58.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4196" for this suite. 01/10/23 04:01:58.495
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":116,"skipped":2112,"failed":0}
------------------------------
• [3.451 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:55.05
    Jan 10 04:01:55.050: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replication-controller 01/10/23 04:01:55.051
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:55.127
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:55.135
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 01/10/23 04:01:55.144
    STEP: waiting for RC to be added 01/10/23 04:01:55.155
    STEP: waiting for available Replicas 01/10/23 04:01:55.155
    STEP: patching ReplicationController 01/10/23 04:01:56.443
    STEP: waiting for RC to be modified 01/10/23 04:01:56.453
    STEP: patching ReplicationController status 01/10/23 04:01:56.454
    STEP: waiting for RC to be modified 01/10/23 04:01:56.461
    STEP: waiting for available Replicas 01/10/23 04:01:56.461
    STEP: fetching ReplicationController status 01/10/23 04:01:56.464
    STEP: patching ReplicationController scale 01/10/23 04:01:56.466
    STEP: waiting for RC to be modified 01/10/23 04:01:56.473
    STEP: waiting for ReplicationController's scale to be the max amount 01/10/23 04:01:56.473
    STEP: fetching ReplicationController; ensuring that it's patched 01/10/23 04:01:58.265
    STEP: updating ReplicationController status 01/10/23 04:01:58.27
    STEP: waiting for RC to be modified 01/10/23 04:01:58.276
    STEP: listing all ReplicationControllers 01/10/23 04:01:58.276
    STEP: checking that ReplicationController has expected values 01/10/23 04:01:58.279
    STEP: deleting ReplicationControllers by collection 01/10/23 04:01:58.279
    STEP: waiting for ReplicationController to have a DELETED watchEvent 01/10/23 04:01:58.299
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 10 04:01:58.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4196" for this suite. 01/10/23 04:01:58.495
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:58.503
Jan 10 04:01:58.503: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename gc 01/10/23 04:01:58.504
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:58.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:58.554
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 01/10/23 04:01:58.559
STEP: Wait for the Deployment to create new ReplicaSet 01/10/23 04:01:58.564
STEP: delete the deployment 01/10/23 04:01:59.072
STEP: wait for all rs to be garbage collected 01/10/23 04:01:59.077
STEP: expected 0 rs, got 1 rs 01/10/23 04:01:59.081
STEP: expected 0 pods, got 2 pods 01/10/23 04:01:59.085
STEP: Gathering metrics 01/10/23 04:01:59.612
W0110 04:01:59.626018      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 10 04:01:59.626: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 10 04:01:59.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4033" for this suite. 01/10/23 04:01:59.641
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":117,"skipped":2113,"failed":0}
------------------------------
• [1.151 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:58.503
    Jan 10 04:01:58.503: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename gc 01/10/23 04:01:58.504
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:58.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:58.554
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 01/10/23 04:01:58.559
    STEP: Wait for the Deployment to create new ReplicaSet 01/10/23 04:01:58.564
    STEP: delete the deployment 01/10/23 04:01:59.072
    STEP: wait for all rs to be garbage collected 01/10/23 04:01:59.077
    STEP: expected 0 rs, got 1 rs 01/10/23 04:01:59.081
    STEP: expected 0 pods, got 2 pods 01/10/23 04:01:59.085
    STEP: Gathering metrics 01/10/23 04:01:59.612
    W0110 04:01:59.626018      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 10 04:01:59.626: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 10 04:01:59.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4033" for this suite. 01/10/23 04:01:59.641
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:01:59.654
Jan 10 04:01:59.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-watch 01/10/23 04:01:59.655
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:59.766
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:59.781
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Jan 10 04:01:59.783: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Creating first CR  01/10/23 04:02:02.375
Jan 10 04:02:02.387: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:02Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:02Z]] name:name1 resourceVersion:221877 uid:dfd05e0f-08aa-4539-a99a-2db23382a6d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 01/10/23 04:02:12.388
Jan 10 04:02:12.392: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:12Z]] name:name2 resourceVersion:221947 uid:1371c3a4-e6cf-45bc-b5a2-c5c957378e3a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 01/10/23 04:02:22.392
Jan 10 04:02:22.399: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:22Z]] name:name1 resourceVersion:221983 uid:dfd05e0f-08aa-4539-a99a-2db23382a6d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 01/10/23 04:02:32.404
Jan 10 04:02:32.410: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:32Z]] name:name2 resourceVersion:222018 uid:1371c3a4-e6cf-45bc-b5a2-c5c957378e3a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 01/10/23 04:02:42.411
Jan 10 04:02:42.417: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:22Z]] name:name1 resourceVersion:222052 uid:dfd05e0f-08aa-4539-a99a-2db23382a6d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 01/10/23 04:02:52.417
Jan 10 04:02:52.423: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:32Z]] name:name2 resourceVersion:222087 uid:1371c3a4-e6cf-45bc-b5a2-c5c957378e3a] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:03:02.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-6221" for this suite. 01/10/23 04:03:02.962
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":118,"skipped":2114,"failed":0}
------------------------------
• [SLOW TEST] [63.346 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:01:59.654
    Jan 10 04:01:59.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-watch 01/10/23 04:01:59.655
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:01:59.766
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:01:59.781
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Jan 10 04:01:59.783: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Creating first CR  01/10/23 04:02:02.375
    Jan 10 04:02:02.387: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:02Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:02Z]] name:name1 resourceVersion:221877 uid:dfd05e0f-08aa-4539-a99a-2db23382a6d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 01/10/23 04:02:12.388
    Jan 10 04:02:12.392: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:12Z]] name:name2 resourceVersion:221947 uid:1371c3a4-e6cf-45bc-b5a2-c5c957378e3a] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 01/10/23 04:02:22.392
    Jan 10 04:02:22.399: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:22Z]] name:name1 resourceVersion:221983 uid:dfd05e0f-08aa-4539-a99a-2db23382a6d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 01/10/23 04:02:32.404
    Jan 10 04:02:32.410: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:32Z]] name:name2 resourceVersion:222018 uid:1371c3a4-e6cf-45bc-b5a2-c5c957378e3a] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 01/10/23 04:02:42.411
    Jan 10 04:02:42.417: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:22Z]] name:name1 resourceVersion:222052 uid:dfd05e0f-08aa-4539-a99a-2db23382a6d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 01/10/23 04:02:52.417
    Jan 10 04:02:52.423: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-10T04:02:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-10T04:02:32Z]] name:name2 resourceVersion:222087 uid:1371c3a4-e6cf-45bc-b5a2-c5c957378e3a] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:03:02.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-6221" for this suite. 01/10/23 04:03:02.962
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:03.01
Jan 10 04:03:03.010: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:03:03.011
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:03.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:03.219
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-8761/secret-test-21b68b5f-92fd-4f4a-84ff-09ff2a7f9c77 01/10/23 04:03:03.233
STEP: Creating a pod to test consume secrets 01/10/23 04:03:03.254
Jan 10 04:03:03.296: INFO: Waiting up to 5m0s for pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b" in namespace "secrets-8761" to be "Succeeded or Failed"
Jan 10 04:03:03.336: INFO: Pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b": Phase="Pending", Reason="", readiness=false. Elapsed: 39.901637ms
Jan 10 04:03:05.342: INFO: Pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0461704s
Jan 10 04:03:07.340: INFO: Pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044123679s
STEP: Saw pod success 01/10/23 04:03:07.34
Jan 10 04:03:07.341: INFO: Pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b" satisfied condition "Succeeded or Failed"
Jan 10 04:03:07.344: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b container env-test: <nil>
STEP: delete the pod 01/10/23 04:03:07.35
Jan 10 04:03:07.363: INFO: Waiting for pod pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b to disappear
Jan 10 04:03:07.366: INFO: Pod pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:03:07.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8761" for this suite. 01/10/23 04:03:07.371
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":119,"skipped":2134,"failed":0}
------------------------------
• [4.367 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:03.01
    Jan 10 04:03:03.010: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:03:03.011
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:03.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:03.219
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-8761/secret-test-21b68b5f-92fd-4f4a-84ff-09ff2a7f9c77 01/10/23 04:03:03.233
    STEP: Creating a pod to test consume secrets 01/10/23 04:03:03.254
    Jan 10 04:03:03.296: INFO: Waiting up to 5m0s for pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b" in namespace "secrets-8761" to be "Succeeded or Failed"
    Jan 10 04:03:03.336: INFO: Pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b": Phase="Pending", Reason="", readiness=false. Elapsed: 39.901637ms
    Jan 10 04:03:05.342: INFO: Pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0461704s
    Jan 10 04:03:07.340: INFO: Pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044123679s
    STEP: Saw pod success 01/10/23 04:03:07.34
    Jan 10 04:03:07.341: INFO: Pod "pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b" satisfied condition "Succeeded or Failed"
    Jan 10 04:03:07.344: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b container env-test: <nil>
    STEP: delete the pod 01/10/23 04:03:07.35
    Jan 10 04:03:07.363: INFO: Waiting for pod pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b to disappear
    Jan 10 04:03:07.366: INFO: Pod pod-configmaps-b4a1bfa1-2724-46b5-851a-27caaa6dba2b no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:03:07.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8761" for this suite. 01/10/23 04:03:07.371
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:07.385
Jan 10 04:03:07.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename job 01/10/23 04:03:07.387
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:07.415
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:07.428
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 01/10/23 04:03:07.433
STEP: Ensure pods equal to paralellism count is attached to the job 01/10/23 04:03:07.447
STEP: patching /status 01/10/23 04:03:11.45
STEP: updating /status 01/10/23 04:03:11.46
STEP: get /status 01/10/23 04:03:11.465
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 10 04:03:11.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5346" for this suite. 01/10/23 04:03:11.471
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":120,"skipped":2187,"failed":0}
------------------------------
• [4.092 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:07.385
    Jan 10 04:03:07.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename job 01/10/23 04:03:07.387
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:07.415
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:07.428
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 01/10/23 04:03:07.433
    STEP: Ensure pods equal to paralellism count is attached to the job 01/10/23 04:03:07.447
    STEP: patching /status 01/10/23 04:03:11.45
    STEP: updating /status 01/10/23 04:03:11.46
    STEP: get /status 01/10/23 04:03:11.465
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 10 04:03:11.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5346" for this suite. 01/10/23 04:03:11.471
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:11.48
Jan 10 04:03:11.480: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 04:03:11.481
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:11.5
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:11.507
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 01/10/23 04:03:11.51
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 01/10/23 04:03:11.512
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 01/10/23 04:03:11.512
STEP: fetching the /apis/apiextensions.k8s.io discovery document 01/10/23 04:03:11.512
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 01/10/23 04:03:11.513
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 01/10/23 04:03:11.513
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 01/10/23 04:03:11.514
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:03:11.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-140" for this suite. 01/10/23 04:03:11.521
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":121,"skipped":2190,"failed":0}
------------------------------
• [0.048 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:11.48
    Jan 10 04:03:11.480: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 04:03:11.481
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:11.5
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:11.507
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 01/10/23 04:03:11.51
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 01/10/23 04:03:11.512
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 01/10/23 04:03:11.512
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 01/10/23 04:03:11.512
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 01/10/23 04:03:11.513
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 01/10/23 04:03:11.513
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 01/10/23 04:03:11.514
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:03:11.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-140" for this suite. 01/10/23 04:03:11.521
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:11.528
Jan 10 04:03:11.529: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename runtimeclass 01/10/23 04:03:11.53
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:11.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:11.56
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Jan 10 04:03:11.573: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-149 to be scheduled
Jan 10 04:03:11.577: INFO: 1 pods are not scheduled: [runtimeclass-149/test-runtimeclass-runtimeclass-149-preconfigured-handler-vgdcq(be9f406f-f6a4-45b2-a234-b12f922690c0)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 10 04:03:13.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-149" for this suite. 01/10/23 04:03:13.601
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":122,"skipped":2197,"failed":0}
------------------------------
• [2.103 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:11.528
    Jan 10 04:03:11.529: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename runtimeclass 01/10/23 04:03:11.53
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:11.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:11.56
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Jan 10 04:03:11.573: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-149 to be scheduled
    Jan 10 04:03:11.577: INFO: 1 pods are not scheduled: [runtimeclass-149/test-runtimeclass-runtimeclass-149-preconfigured-handler-vgdcq(be9f406f-f6a4-45b2-a234-b12f922690c0)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 10 04:03:13.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-149" for this suite. 01/10/23 04:03:13.601
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:13.674
Jan 10 04:03:13.674: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-lifecycle-hook 01/10/23 04:03:13.677
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:13.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:13.756
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 01/10/23 04:03:13.773
Jan 10 04:03:13.793: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3832" to be "running and ready"
Jan 10 04:03:13.822: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 28.352544ms
Jan 10 04:03:13.822: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:03:15.826: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.03262134s
Jan 10 04:03:15.826: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jan 10 04:03:15.826: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 01/10/23 04:03:15.828
Jan 10 04:03:15.831: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-3832" to be "running and ready"
Jan 10 04:03:15.841: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 9.826422ms
Jan 10 04:03:15.841: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:03:17.846: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01406142s
Jan 10 04:03:17.846: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:03:19.845: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.013689511s
Jan 10 04:03:19.845: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Jan 10 04:03:19.845: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 01/10/23 04:03:19.847
STEP: delete the pod with lifecycle hook 01/10/23 04:03:19.861
Jan 10 04:03:19.874: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 10 04:03:19.877: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 10 04:03:21.878: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 10 04:03:21.881: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jan 10 04:03:21.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3832" for this suite. 01/10/23 04:03:21.884
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":123,"skipped":2218,"failed":0}
------------------------------
• [SLOW TEST] [8.218 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:13.674
    Jan 10 04:03:13.674: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-lifecycle-hook 01/10/23 04:03:13.677
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:13.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:13.756
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 01/10/23 04:03:13.773
    Jan 10 04:03:13.793: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3832" to be "running and ready"
    Jan 10 04:03:13.822: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 28.352544ms
    Jan 10 04:03:13.822: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:03:15.826: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.03262134s
    Jan 10 04:03:15.826: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jan 10 04:03:15.826: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 01/10/23 04:03:15.828
    Jan 10 04:03:15.831: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-3832" to be "running and ready"
    Jan 10 04:03:15.841: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 9.826422ms
    Jan 10 04:03:15.841: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:03:17.846: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01406142s
    Jan 10 04:03:17.846: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:03:19.845: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.013689511s
    Jan 10 04:03:19.845: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Jan 10 04:03:19.845: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 01/10/23 04:03:19.847
    STEP: delete the pod with lifecycle hook 01/10/23 04:03:19.861
    Jan 10 04:03:19.874: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Jan 10 04:03:19.877: INFO: Pod pod-with-poststart-exec-hook still exists
    Jan 10 04:03:21.878: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Jan 10 04:03:21.881: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jan 10 04:03:21.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3832" for this suite. 01/10/23 04:03:21.884
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:21.893
Jan 10 04:03:21.893: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:03:21.897
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:21.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:21.946
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 01/10/23 04:03:21.95
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:03:21.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6223" for this suite. 01/10/23 04:03:21.965
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":124,"skipped":2219,"failed":0}
------------------------------
• [0.083 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:21.893
    Jan 10 04:03:21.893: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:03:21.897
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:21.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:21.946
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 01/10/23 04:03:21.95
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:03:21.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6223" for this suite. 01/10/23 04:03:21.965
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:21.995
Jan 10 04:03:21.995: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir-wrapper 01/10/23 04:03:22.002
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:22.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:22.048
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Jan 10 04:03:22.148: INFO: Waiting up to 5m0s for pod "pod-secrets-55e52a6d-0187-4573-be61-c7726766816b" in namespace "emptydir-wrapper-3656" to be "running and ready"
Jan 10 04:03:22.172: INFO: Pod "pod-secrets-55e52a6d-0187-4573-be61-c7726766816b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.996603ms
Jan 10 04:03:22.172: INFO: The phase of Pod pod-secrets-55e52a6d-0187-4573-be61-c7726766816b is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:03:24.175: INFO: Pod "pod-secrets-55e52a6d-0187-4573-be61-c7726766816b": Phase="Running", Reason="", readiness=true. Elapsed: 2.026904209s
Jan 10 04:03:24.175: INFO: The phase of Pod pod-secrets-55e52a6d-0187-4573-be61-c7726766816b is Running (Ready = true)
Jan 10 04:03:24.175: INFO: Pod "pod-secrets-55e52a6d-0187-4573-be61-c7726766816b" satisfied condition "running and ready"
STEP: Cleaning up the secret 01/10/23 04:03:24.179
STEP: Cleaning up the configmap 01/10/23 04:03:24.188
STEP: Cleaning up the pod 01/10/23 04:03:24.195
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Jan 10 04:03:24.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3656" for this suite. 01/10/23 04:03:24.219
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":125,"skipped":2267,"failed":0}
------------------------------
• [2.230 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:21.995
    Jan 10 04:03:21.995: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir-wrapper 01/10/23 04:03:22.002
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:22.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:22.048
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Jan 10 04:03:22.148: INFO: Waiting up to 5m0s for pod "pod-secrets-55e52a6d-0187-4573-be61-c7726766816b" in namespace "emptydir-wrapper-3656" to be "running and ready"
    Jan 10 04:03:22.172: INFO: Pod "pod-secrets-55e52a6d-0187-4573-be61-c7726766816b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.996603ms
    Jan 10 04:03:22.172: INFO: The phase of Pod pod-secrets-55e52a6d-0187-4573-be61-c7726766816b is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:03:24.175: INFO: Pod "pod-secrets-55e52a6d-0187-4573-be61-c7726766816b": Phase="Running", Reason="", readiness=true. Elapsed: 2.026904209s
    Jan 10 04:03:24.175: INFO: The phase of Pod pod-secrets-55e52a6d-0187-4573-be61-c7726766816b is Running (Ready = true)
    Jan 10 04:03:24.175: INFO: Pod "pod-secrets-55e52a6d-0187-4573-be61-c7726766816b" satisfied condition "running and ready"
    STEP: Cleaning up the secret 01/10/23 04:03:24.179
    STEP: Cleaning up the configmap 01/10/23 04:03:24.188
    STEP: Cleaning up the pod 01/10/23 04:03:24.195
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:03:24.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-3656" for this suite. 01/10/23 04:03:24.219
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:24.229
Jan 10 04:03:24.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename security-context-test 01/10/23 04:03:24.23
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:24.292
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:24.307
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Jan 10 04:03:24.364: INFO: Waiting up to 5m0s for pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413" in namespace "security-context-test-7769" to be "Succeeded or Failed"
Jan 10 04:03:24.387: INFO: Pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413": Phase="Pending", Reason="", readiness=false. Elapsed: 22.388873ms
Jan 10 04:03:26.391: INFO: Pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026271582s
Jan 10 04:03:28.392: INFO: Pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027189175s
Jan 10 04:03:28.392: INFO: Pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 10 04:03:28.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7769" for this suite. 01/10/23 04:03:28.396
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":126,"skipped":2285,"failed":0}
------------------------------
• [4.175 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:24.229
    Jan 10 04:03:24.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename security-context-test 01/10/23 04:03:24.23
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:24.292
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:24.307
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Jan 10 04:03:24.364: INFO: Waiting up to 5m0s for pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413" in namespace "security-context-test-7769" to be "Succeeded or Failed"
    Jan 10 04:03:24.387: INFO: Pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413": Phase="Pending", Reason="", readiness=false. Elapsed: 22.388873ms
    Jan 10 04:03:26.391: INFO: Pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026271582s
    Jan 10 04:03:28.392: INFO: Pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027189175s
    Jan 10 04:03:28.392: INFO: Pod "busybox-user-65534-4d1195c5-ad5a-46b4-8c88-46d64fb19413" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 10 04:03:28.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7769" for this suite. 01/10/23 04:03:28.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:28.417
Jan 10 04:03:28.417: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pod-network-test 01/10/23 04:03:28.418
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:28.436
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:28.452
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-2410 01/10/23 04:03:28.456
STEP: creating a selector 01/10/23 04:03:28.457
STEP: Creating the service pods in kubernetes 01/10/23 04:03:28.457
Jan 10 04:03:28.457: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jan 10 04:03:28.540: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2410" to be "running and ready"
Jan 10 04:03:28.565: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 25.414447ms
Jan 10 04:03:28.566: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:03:30.569: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029007191s
Jan 10 04:03:30.569: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:03:32.569: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.028801838s
Jan 10 04:03:32.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:34.569: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.028661671s
Jan 10 04:03:34.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:36.571: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.030728704s
Jan 10 04:03:36.571: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:38.568: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.028459265s
Jan 10 04:03:38.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:40.570: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.030118647s
Jan 10 04:03:40.570: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:42.568: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.028351448s
Jan 10 04:03:42.568: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:44.568: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.028478353s
Jan 10 04:03:44.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:46.569: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.029512735s
Jan 10 04:03:46.570: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:48.569: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.029432243s
Jan 10 04:03:48.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:03:50.571: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.030806478s
Jan 10 04:03:50.571: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jan 10 04:03:50.571: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jan 10 04:03:50.573: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2410" to be "running and ready"
Jan 10 04:03:50.577: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.356293ms
Jan 10 04:03:50.577: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jan 10 04:03:50.577: INFO: Pod "netserver-1" satisfied condition "running and ready"
Jan 10 04:03:50.581: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2410" to be "running and ready"
Jan 10 04:03:50.586: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.393421ms
Jan 10 04:03:50.586: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Jan 10 04:03:50.586: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 01/10/23 04:03:50.592
Jan 10 04:03:50.622: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2410" to be "running"
Jan 10 04:03:50.647: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.901258ms
Jan 10 04:03:52.651: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028598827s
Jan 10 04:03:54.659: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.036817936s
Jan 10 04:03:54.659: INFO: Pod "test-container-pod" satisfied condition "running"
Jan 10 04:03:54.661: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2410" to be "running"
Jan 10 04:03:54.663: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.178786ms
Jan 10 04:03:54.663: INFO: Pod "host-test-container-pod" satisfied condition "running"
Jan 10 04:03:54.668: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jan 10 04:03:54.668: INFO: Going to poll 10.42.0.52 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jan 10 04:03:54.670: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.0.52 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2410 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:03:54.670: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:03:54.671: INFO: ExecWithOptions: Clientset creation
Jan 10 04:03:54.671: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-2410/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.0.52+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 10 04:03:55.832: INFO: Found all 1 expected endpoints: [netserver-0]
Jan 10 04:03:55.832: INFO: Going to poll 10.42.1.147 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jan 10 04:03:55.836: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.1.147 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2410 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:03:55.836: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:03:55.836: INFO: ExecWithOptions: Clientset creation
Jan 10 04:03:55.836: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-2410/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.1.147+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 10 04:03:56.979: INFO: Found all 1 expected endpoints: [netserver-1]
Jan 10 04:03:56.979: INFO: Going to poll 10.42.2.73 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jan 10 04:03:56.983: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.2.73 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2410 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:03:56.983: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:03:56.983: INFO: ExecWithOptions: Clientset creation
Jan 10 04:03:56.984: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-2410/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.2.73+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 10 04:03:58.106: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jan 10 04:03:58.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2410" for this suite. 01/10/23 04:03:58.113
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":127,"skipped":2318,"failed":0}
------------------------------
• [SLOW TEST] [29.701 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:28.417
    Jan 10 04:03:28.417: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pod-network-test 01/10/23 04:03:28.418
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:28.436
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:28.452
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-2410 01/10/23 04:03:28.456
    STEP: creating a selector 01/10/23 04:03:28.457
    STEP: Creating the service pods in kubernetes 01/10/23 04:03:28.457
    Jan 10 04:03:28.457: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jan 10 04:03:28.540: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2410" to be "running and ready"
    Jan 10 04:03:28.565: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 25.414447ms
    Jan 10 04:03:28.566: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:03:30.569: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029007191s
    Jan 10 04:03:30.569: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:03:32.569: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.028801838s
    Jan 10 04:03:32.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:34.569: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.028661671s
    Jan 10 04:03:34.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:36.571: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.030728704s
    Jan 10 04:03:36.571: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:38.568: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.028459265s
    Jan 10 04:03:38.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:40.570: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.030118647s
    Jan 10 04:03:40.570: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:42.568: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.028351448s
    Jan 10 04:03:42.568: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:44.568: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.028478353s
    Jan 10 04:03:44.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:46.569: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.029512735s
    Jan 10 04:03:46.570: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:48.569: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.029432243s
    Jan 10 04:03:48.569: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:03:50.571: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.030806478s
    Jan 10 04:03:50.571: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jan 10 04:03:50.571: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jan 10 04:03:50.573: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2410" to be "running and ready"
    Jan 10 04:03:50.577: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.356293ms
    Jan 10 04:03:50.577: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jan 10 04:03:50.577: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Jan 10 04:03:50.581: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2410" to be "running and ready"
    Jan 10 04:03:50.586: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.393421ms
    Jan 10 04:03:50.586: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Jan 10 04:03:50.586: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 01/10/23 04:03:50.592
    Jan 10 04:03:50.622: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2410" to be "running"
    Jan 10 04:03:50.647: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.901258ms
    Jan 10 04:03:52.651: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028598827s
    Jan 10 04:03:54.659: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.036817936s
    Jan 10 04:03:54.659: INFO: Pod "test-container-pod" satisfied condition "running"
    Jan 10 04:03:54.661: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2410" to be "running"
    Jan 10 04:03:54.663: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.178786ms
    Jan 10 04:03:54.663: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Jan 10 04:03:54.668: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Jan 10 04:03:54.668: INFO: Going to poll 10.42.0.52 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Jan 10 04:03:54.670: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.0.52 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2410 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:03:54.670: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:03:54.671: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:03:54.671: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-2410/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.0.52+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 10 04:03:55.832: INFO: Found all 1 expected endpoints: [netserver-0]
    Jan 10 04:03:55.832: INFO: Going to poll 10.42.1.147 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Jan 10 04:03:55.836: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.1.147 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2410 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:03:55.836: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:03:55.836: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:03:55.836: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-2410/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.1.147+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 10 04:03:56.979: INFO: Found all 1 expected endpoints: [netserver-1]
    Jan 10 04:03:56.979: INFO: Going to poll 10.42.2.73 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Jan 10 04:03:56.983: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.2.73 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2410 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:03:56.983: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:03:56.983: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:03:56.984: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-2410/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.2.73+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 10 04:03:58.106: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jan 10 04:03:58.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-2410" for this suite. 01/10/23 04:03:58.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:03:58.119
Jan 10 04:03:58.119: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:03:58.121
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:58.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:58.162
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:03:58.21
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:03:59.255
STEP: Deploying the webhook pod 01/10/23 04:03:59.261
STEP: Wait for the deployment to be ready 01/10/23 04:03:59.276
Jan 10 04:03:59.288: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 04:04:01.3
STEP: Verifying the service has paired with the endpoint 01/10/23 04:04:01.314
Jan 10 04:04:02.315: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Jan 10 04:04:02.319: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-356-crds.webhook.example.com via the AdmissionRegistration API 01/10/23 04:04:02.889
STEP: Creating a custom resource that should be mutated by the webhook 01/10/23 04:04:03.121
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:04:06.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2410" for this suite. 01/10/23 04:04:06.022
STEP: Destroying namespace "webhook-2410-markers" for this suite. 01/10/23 04:04:06.04
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":128,"skipped":2336,"failed":0}
------------------------------
• [SLOW TEST] [8.246 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:03:58.119
    Jan 10 04:03:58.119: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:03:58.121
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:03:58.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:03:58.162
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:03:58.21
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:03:59.255
    STEP: Deploying the webhook pod 01/10/23 04:03:59.261
    STEP: Wait for the deployment to be ready 01/10/23 04:03:59.276
    Jan 10 04:03:59.288: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 04:04:01.3
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:04:01.314
    Jan 10 04:04:02.315: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Jan 10 04:04:02.319: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-356-crds.webhook.example.com via the AdmissionRegistration API 01/10/23 04:04:02.889
    STEP: Creating a custom resource that should be mutated by the webhook 01/10/23 04:04:03.121
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:04:06.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2410" for this suite. 01/10/23 04:04:06.022
    STEP: Destroying namespace "webhook-2410-markers" for this suite. 01/10/23 04:04:06.04
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:06.368
Jan 10 04:04:06.368: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:04:06.368
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:06.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:06.602
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4591 01/10/23 04:04:06.631
STEP: changing the ExternalName service to type=ClusterIP 01/10/23 04:04:06.678
STEP: creating replication controller externalname-service in namespace services-4591 01/10/23 04:04:06.767
I0110 04:04:06.778013      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4591, replica count: 2
I0110 04:04:09.831106      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 04:04:09.831: INFO: Creating new exec pod
Jan 10 04:04:09.836: INFO: Waiting up to 5m0s for pod "execpod8pm97" in namespace "services-4591" to be "running"
Jan 10 04:04:09.846: INFO: Pod "execpod8pm97": Phase="Pending", Reason="", readiness=false. Elapsed: 10.18304ms
Jan 10 04:04:11.867: INFO: Pod "execpod8pm97": Phase="Running", Reason="", readiness=true. Elapsed: 2.030869047s
Jan 10 04:04:11.867: INFO: Pod "execpod8pm97" satisfied condition "running"
Jan 10 04:04:12.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4591 exec execpod8pm97 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jan 10 04:04:13.031: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jan 10 04:04:13.032: INFO: stdout: "externalname-service-f7pmr"
Jan 10 04:04:13.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4591 exec execpod8pm97 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.14.102 80'
Jan 10 04:04:13.244: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.14.102 80\nConnection to 10.43.14.102 80 port [tcp/http] succeeded!\n"
Jan 10 04:04:13.244: INFO: stdout: ""
Jan 10 04:04:14.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4591 exec execpod8pm97 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.14.102 80'
Jan 10 04:04:14.469: INFO: stderr: "+ nc -v -t -w 2 10.43.14.102 80\nConnection to 10.43.14.102 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Jan 10 04:04:14.469: INFO: stdout: ""
Jan 10 04:04:15.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4591 exec execpod8pm97 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.14.102 80'
Jan 10 04:04:15.393: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.14.102 80\nConnection to 10.43.14.102 80 port [tcp/http] succeeded!\n"
Jan 10 04:04:15.393: INFO: stdout: "externalname-service-f7pmr"
Jan 10 04:04:15.393: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:04:15.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4591" for this suite. 01/10/23 04:04:15.417
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":129,"skipped":2344,"failed":0}
------------------------------
• [SLOW TEST] [9.065 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:06.368
    Jan 10 04:04:06.368: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:04:06.368
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:06.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:06.602
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-4591 01/10/23 04:04:06.631
    STEP: changing the ExternalName service to type=ClusterIP 01/10/23 04:04:06.678
    STEP: creating replication controller externalname-service in namespace services-4591 01/10/23 04:04:06.767
    I0110 04:04:06.778013      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4591, replica count: 2
    I0110 04:04:09.831106      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 04:04:09.831: INFO: Creating new exec pod
    Jan 10 04:04:09.836: INFO: Waiting up to 5m0s for pod "execpod8pm97" in namespace "services-4591" to be "running"
    Jan 10 04:04:09.846: INFO: Pod "execpod8pm97": Phase="Pending", Reason="", readiness=false. Elapsed: 10.18304ms
    Jan 10 04:04:11.867: INFO: Pod "execpod8pm97": Phase="Running", Reason="", readiness=true. Elapsed: 2.030869047s
    Jan 10 04:04:11.867: INFO: Pod "execpod8pm97" satisfied condition "running"
    Jan 10 04:04:12.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4591 exec execpod8pm97 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jan 10 04:04:13.031: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jan 10 04:04:13.032: INFO: stdout: "externalname-service-f7pmr"
    Jan 10 04:04:13.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4591 exec execpod8pm97 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.14.102 80'
    Jan 10 04:04:13.244: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.14.102 80\nConnection to 10.43.14.102 80 port [tcp/http] succeeded!\n"
    Jan 10 04:04:13.244: INFO: stdout: ""
    Jan 10 04:04:14.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4591 exec execpod8pm97 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.14.102 80'
    Jan 10 04:04:14.469: INFO: stderr: "+ nc -v -t -w 2 10.43.14.102 80\nConnection to 10.43.14.102 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Jan 10 04:04:14.469: INFO: stdout: ""
    Jan 10 04:04:15.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4591 exec execpod8pm97 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.14.102 80'
    Jan 10 04:04:15.393: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.14.102 80\nConnection to 10.43.14.102 80 port [tcp/http] succeeded!\n"
    Jan 10 04:04:15.393: INFO: stdout: "externalname-service-f7pmr"
    Jan 10 04:04:15.393: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:04:15.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4591" for this suite. 01/10/23 04:04:15.417
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:15.434
Jan 10 04:04:15.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename daemonsets 01/10/23 04:04:15.436
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:15.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:15.488
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 01/10/23 04:04:15.587
STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:04:15.598
Jan 10 04:04:15.623: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:04:15.623: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:04:16.644: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:04:16.644: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:04:17.629: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 04:04:17.629: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
Jan 10 04:04:18.629: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 04:04:18.629: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 01/10/23 04:04:18.631
Jan 10 04:04:18.634: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 01/10/23 04:04:18.634
Jan 10 04:04:18.643: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 01/10/23 04:04:18.643
Jan 10 04:04:18.645: INFO: Observed &DaemonSet event: ADDED
Jan 10 04:04:18.645: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.646: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.646: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.646: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.646: INFO: Found daemon set daemon-set in namespace daemonsets-8158 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jan 10 04:04:18.647: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 01/10/23 04:04:18.647
STEP: watching for the daemon set status to be patched 01/10/23 04:04:18.653
Jan 10 04:04:18.655: INFO: Observed &DaemonSet event: ADDED
Jan 10 04:04:18.655: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.656: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.656: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.656: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.656: INFO: Observed daemon set daemon-set in namespace daemonsets-8158 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jan 10 04:04:18.656: INFO: Observed &DaemonSet event: MODIFIED
Jan 10 04:04:18.657: INFO: Found daemon set daemon-set in namespace daemonsets-8158 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Jan 10 04:04:18.657: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/10/23 04:04:18.661
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8158, will wait for the garbage collector to delete the pods 01/10/23 04:04:18.661
Jan 10 04:04:18.725: INFO: Deleting DaemonSet.extensions daemon-set took: 10.837158ms
Jan 10 04:04:18.826: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.775193ms
Jan 10 04:04:21.631: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:04:21.631: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 10 04:04:21.641: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"223008"},"items":null}

Jan 10 04:04:21.648: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"223008"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:04:21.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8158" for this suite. 01/10/23 04:04:21.668
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":130,"skipped":2388,"failed":0}
------------------------------
• [SLOW TEST] [6.240 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:15.434
    Jan 10 04:04:15.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename daemonsets 01/10/23 04:04:15.436
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:15.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:15.488
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 01/10/23 04:04:15.587
    STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:04:15.598
    Jan 10 04:04:15.623: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:04:15.623: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:04:16.644: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:04:16.644: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:04:17.629: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 04:04:17.629: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
    Jan 10 04:04:18.629: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 04:04:18.629: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 01/10/23 04:04:18.631
    Jan 10 04:04:18.634: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 01/10/23 04:04:18.634
    Jan 10 04:04:18.643: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 01/10/23 04:04:18.643
    Jan 10 04:04:18.645: INFO: Observed &DaemonSet event: ADDED
    Jan 10 04:04:18.645: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.646: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.646: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.646: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.646: INFO: Found daemon set daemon-set in namespace daemonsets-8158 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jan 10 04:04:18.647: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 01/10/23 04:04:18.647
    STEP: watching for the daemon set status to be patched 01/10/23 04:04:18.653
    Jan 10 04:04:18.655: INFO: Observed &DaemonSet event: ADDED
    Jan 10 04:04:18.655: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.656: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.656: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.656: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.656: INFO: Observed daemon set daemon-set in namespace daemonsets-8158 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jan 10 04:04:18.656: INFO: Observed &DaemonSet event: MODIFIED
    Jan 10 04:04:18.657: INFO: Found daemon set daemon-set in namespace daemonsets-8158 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Jan 10 04:04:18.657: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/10/23 04:04:18.661
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8158, will wait for the garbage collector to delete the pods 01/10/23 04:04:18.661
    Jan 10 04:04:18.725: INFO: Deleting DaemonSet.extensions daemon-set took: 10.837158ms
    Jan 10 04:04:18.826: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.775193ms
    Jan 10 04:04:21.631: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:04:21.631: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 10 04:04:21.641: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"223008"},"items":null}

    Jan 10 04:04:21.648: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"223008"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:04:21.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8158" for this suite. 01/10/23 04:04:21.668
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:21.688
Jan 10 04:04:21.688: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 04:04:21.691
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:21.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:21.726
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 01/10/23 04:04:21.756
Jan 10 04:04:21.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Jan 10 04:04:21.956: INFO: stderr: ""
Jan 10 04:04:21.956: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 01/10/23 04:04:21.956
Jan 10 04:04:21.956: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Jan 10 04:04:21.956: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2575" to be "running and ready, or succeeded"
Jan 10 04:04:21.967: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.920911ms
Jan 10 04:04:21.967: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'cncf-wk2' to be 'Running' but was 'Pending'
Jan 10 04:04:23.969: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.013342254s
Jan 10 04:04:23.969: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Jan 10 04:04:23.969: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 01/10/23 04:04:23.969
Jan 10 04:04:23.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator'
Jan 10 04:04:24.111: INFO: stderr: ""
Jan 10 04:04:24.111: INFO: stdout: "I0110 04:04:22.838037       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/jhtg 502\nI0110 04:04:23.038123       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/5r28 299\nI0110 04:04:23.238969       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/p8f9 437\nI0110 04:04:23.438155       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/6sg 354\nI0110 04:04:23.638582       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/f2fj 344\nI0110 04:04:23.839046       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/hfkp 497\nI0110 04:04:24.038353       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tt6 396\n"
STEP: limiting log lines 01/10/23 04:04:24.111
Jan 10 04:04:24.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --tail=1'
Jan 10 04:04:24.211: INFO: stderr: ""
Jan 10 04:04:24.211: INFO: stdout: "I0110 04:04:24.038353       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tt6 396\n"
Jan 10 04:04:24.211: INFO: got output "I0110 04:04:24.038353       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tt6 396\n"
STEP: limiting log bytes 01/10/23 04:04:24.211
Jan 10 04:04:24.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --limit-bytes=1'
Jan 10 04:04:24.298: INFO: stderr: ""
Jan 10 04:04:24.298: INFO: stdout: "I"
Jan 10 04:04:24.298: INFO: got output "I"
STEP: exposing timestamps 01/10/23 04:04:24.298
Jan 10 04:04:24.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --tail=1 --timestamps'
Jan 10 04:04:24.376: INFO: stderr: ""
Jan 10 04:04:24.376: INFO: stdout: "2023-01-10T04:04:24.238926906Z I0110 04:04:24.238776       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/xhpt 446\n"
Jan 10 04:04:24.376: INFO: got output "2023-01-10T04:04:24.238926906Z I0110 04:04:24.238776       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/xhpt 446\n"
STEP: restricting to a time range 01/10/23 04:04:24.376
Jan 10 04:04:26.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --since=1s'
Jan 10 04:04:27.068: INFO: stderr: ""
Jan 10 04:04:27.068: INFO: stdout: "I0110 04:04:26.238446       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/fjv 225\nI0110 04:04:26.438851       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/s4kk 592\nI0110 04:04:26.638149       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/fk9 429\nI0110 04:04:26.838524       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/x925 459\nI0110 04:04:27.039020       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/svfh 296\n"
Jan 10 04:04:27.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --since=24h'
Jan 10 04:04:27.191: INFO: stderr: ""
Jan 10 04:04:27.191: INFO: stdout: "I0110 04:04:22.838037       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/jhtg 502\nI0110 04:04:23.038123       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/5r28 299\nI0110 04:04:23.238969       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/p8f9 437\nI0110 04:04:23.438155       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/6sg 354\nI0110 04:04:23.638582       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/f2fj 344\nI0110 04:04:23.839046       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/hfkp 497\nI0110 04:04:24.038353       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tt6 396\nI0110 04:04:24.238776       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/xhpt 446\nI0110 04:04:24.438172       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/m9fx 361\nI0110 04:04:24.638517       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/7fc 324\nI0110 04:04:24.838858       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/ms4w 458\nI0110 04:04:25.038161       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/c964 533\nI0110 04:04:25.238533       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/s2qn 511\nI0110 04:04:25.438906       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/w9l 485\nI0110 04:04:25.638236       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/47pc 568\nI0110 04:04:25.838369       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/tnpd 230\nI0110 04:04:26.038862       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/stpl 481\nI0110 04:04:26.238446       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/fjv 225\nI0110 04:04:26.438851       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/s4kk 592\nI0110 04:04:26.638149       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/fk9 429\nI0110 04:04:26.838524       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/x925 459\nI0110 04:04:27.039020       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/svfh 296\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Jan 10 04:04:27.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 delete pod logs-generator'
Jan 10 04:04:27.968: INFO: stderr: ""
Jan 10 04:04:27.968: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 04:04:27.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2575" for this suite. 01/10/23 04:04:27.971
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":131,"skipped":2403,"failed":0}
------------------------------
• [SLOW TEST] [6.288 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:21.688
    Jan 10 04:04:21.688: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 04:04:21.691
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:21.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:21.726
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 01/10/23 04:04:21.756
    Jan 10 04:04:21.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Jan 10 04:04:21.956: INFO: stderr: ""
    Jan 10 04:04:21.956: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 01/10/23 04:04:21.956
    Jan 10 04:04:21.956: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Jan 10 04:04:21.956: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2575" to be "running and ready, or succeeded"
    Jan 10 04:04:21.967: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.920911ms
    Jan 10 04:04:21.967: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'cncf-wk2' to be 'Running' but was 'Pending'
    Jan 10 04:04:23.969: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.013342254s
    Jan 10 04:04:23.969: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Jan 10 04:04:23.969: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 01/10/23 04:04:23.969
    Jan 10 04:04:23.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator'
    Jan 10 04:04:24.111: INFO: stderr: ""
    Jan 10 04:04:24.111: INFO: stdout: "I0110 04:04:22.838037       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/jhtg 502\nI0110 04:04:23.038123       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/5r28 299\nI0110 04:04:23.238969       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/p8f9 437\nI0110 04:04:23.438155       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/6sg 354\nI0110 04:04:23.638582       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/f2fj 344\nI0110 04:04:23.839046       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/hfkp 497\nI0110 04:04:24.038353       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tt6 396\n"
    STEP: limiting log lines 01/10/23 04:04:24.111
    Jan 10 04:04:24.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --tail=1'
    Jan 10 04:04:24.211: INFO: stderr: ""
    Jan 10 04:04:24.211: INFO: stdout: "I0110 04:04:24.038353       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tt6 396\n"
    Jan 10 04:04:24.211: INFO: got output "I0110 04:04:24.038353       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tt6 396\n"
    STEP: limiting log bytes 01/10/23 04:04:24.211
    Jan 10 04:04:24.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --limit-bytes=1'
    Jan 10 04:04:24.298: INFO: stderr: ""
    Jan 10 04:04:24.298: INFO: stdout: "I"
    Jan 10 04:04:24.298: INFO: got output "I"
    STEP: exposing timestamps 01/10/23 04:04:24.298
    Jan 10 04:04:24.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --tail=1 --timestamps'
    Jan 10 04:04:24.376: INFO: stderr: ""
    Jan 10 04:04:24.376: INFO: stdout: "2023-01-10T04:04:24.238926906Z I0110 04:04:24.238776       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/xhpt 446\n"
    Jan 10 04:04:24.376: INFO: got output "2023-01-10T04:04:24.238926906Z I0110 04:04:24.238776       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/xhpt 446\n"
    STEP: restricting to a time range 01/10/23 04:04:24.376
    Jan 10 04:04:26.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --since=1s'
    Jan 10 04:04:27.068: INFO: stderr: ""
    Jan 10 04:04:27.068: INFO: stdout: "I0110 04:04:26.238446       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/fjv 225\nI0110 04:04:26.438851       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/s4kk 592\nI0110 04:04:26.638149       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/fk9 429\nI0110 04:04:26.838524       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/x925 459\nI0110 04:04:27.039020       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/svfh 296\n"
    Jan 10 04:04:27.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 logs logs-generator logs-generator --since=24h'
    Jan 10 04:04:27.191: INFO: stderr: ""
    Jan 10 04:04:27.191: INFO: stdout: "I0110 04:04:22.838037       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/jhtg 502\nI0110 04:04:23.038123       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/5r28 299\nI0110 04:04:23.238969       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/p8f9 437\nI0110 04:04:23.438155       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/6sg 354\nI0110 04:04:23.638582       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/f2fj 344\nI0110 04:04:23.839046       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/hfkp 497\nI0110 04:04:24.038353       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/tt6 396\nI0110 04:04:24.238776       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/xhpt 446\nI0110 04:04:24.438172       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/m9fx 361\nI0110 04:04:24.638517       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/7fc 324\nI0110 04:04:24.838858       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/ms4w 458\nI0110 04:04:25.038161       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/c964 533\nI0110 04:04:25.238533       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/s2qn 511\nI0110 04:04:25.438906       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/w9l 485\nI0110 04:04:25.638236       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/47pc 568\nI0110 04:04:25.838369       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/tnpd 230\nI0110 04:04:26.038862       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/stpl 481\nI0110 04:04:26.238446       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/fjv 225\nI0110 04:04:26.438851       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/s4kk 592\nI0110 04:04:26.638149       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/fk9 429\nI0110 04:04:26.838524       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/x925 459\nI0110 04:04:27.039020       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/svfh 296\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Jan 10 04:04:27.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2575 delete pod logs-generator'
    Jan 10 04:04:27.968: INFO: stderr: ""
    Jan 10 04:04:27.968: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 04:04:27.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2575" for this suite. 01/10/23 04:04:27.971
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:27.977
Jan 10 04:04:27.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:04:27.978
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:27.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:28.001
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 01/10/23 04:04:28.012
Jan 10 04:04:28.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07" in namespace "projected-9257" to be "Succeeded or Failed"
Jan 10 04:04:28.031: INFO: Pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07": Phase="Pending", Reason="", readiness=false. Elapsed: 6.148734ms
Jan 10 04:04:30.034: INFO: Pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009840013s
Jan 10 04:04:32.036: INFO: Pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011101202s
STEP: Saw pod success 01/10/23 04:04:32.036
Jan 10 04:04:32.036: INFO: Pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07" satisfied condition "Succeeded or Failed"
Jan 10 04:04:32.041: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07 container client-container: <nil>
STEP: delete the pod 01/10/23 04:04:32.05
Jan 10 04:04:32.068: INFO: Waiting for pod downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07 to disappear
Jan 10 04:04:32.075: INFO: Pod downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 04:04:32.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9257" for this suite. 01/10/23 04:04:32.079
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":132,"skipped":2413,"failed":0}
------------------------------
• [4.110 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:27.977
    Jan 10 04:04:27.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:04:27.978
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:27.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:28.001
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 01/10/23 04:04:28.012
    Jan 10 04:04:28.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07" in namespace "projected-9257" to be "Succeeded or Failed"
    Jan 10 04:04:28.031: INFO: Pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07": Phase="Pending", Reason="", readiness=false. Elapsed: 6.148734ms
    Jan 10 04:04:30.034: INFO: Pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009840013s
    Jan 10 04:04:32.036: INFO: Pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011101202s
    STEP: Saw pod success 01/10/23 04:04:32.036
    Jan 10 04:04:32.036: INFO: Pod "downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07" satisfied condition "Succeeded or Failed"
    Jan 10 04:04:32.041: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07 container client-container: <nil>
    STEP: delete the pod 01/10/23 04:04:32.05
    Jan 10 04:04:32.068: INFO: Waiting for pod downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07 to disappear
    Jan 10 04:04:32.075: INFO: Pod downwardapi-volume-98b65eaa-ef8a-4ed5-a31f-b6e1e3109c07 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 04:04:32.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9257" for this suite. 01/10/23 04:04:32.079
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:32.089
Jan 10 04:04:32.089: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:04:32.091
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:32.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:32.216
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-dc687dec-c1c5-4ea0-9d72-fec14a2a07e7 01/10/23 04:04:32.219
STEP: Creating a pod to test consume secrets 01/10/23 04:04:32.238
Jan 10 04:04:32.247: INFO: Waiting up to 5m0s for pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089" in namespace "secrets-7254" to be "Succeeded or Failed"
Jan 10 04:04:32.269: INFO: Pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089": Phase="Pending", Reason="", readiness=false. Elapsed: 22.551675ms
Jan 10 04:04:34.274: INFO: Pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027017571s
Jan 10 04:04:36.273: INFO: Pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026585495s
STEP: Saw pod success 01/10/23 04:04:36.273
Jan 10 04:04:36.274: INFO: Pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089" satisfied condition "Succeeded or Failed"
Jan 10 04:04:36.276: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089 container secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:04:36.282
Jan 10 04:04:36.292: INFO: Waiting for pod pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089 to disappear
Jan 10 04:04:36.296: INFO: Pod pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:04:36.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7254" for this suite. 01/10/23 04:04:36.299
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":133,"skipped":2421,"failed":0}
------------------------------
• [4.217 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:32.089
    Jan 10 04:04:32.089: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:04:32.091
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:32.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:32.216
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-dc687dec-c1c5-4ea0-9d72-fec14a2a07e7 01/10/23 04:04:32.219
    STEP: Creating a pod to test consume secrets 01/10/23 04:04:32.238
    Jan 10 04:04:32.247: INFO: Waiting up to 5m0s for pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089" in namespace "secrets-7254" to be "Succeeded or Failed"
    Jan 10 04:04:32.269: INFO: Pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089": Phase="Pending", Reason="", readiness=false. Elapsed: 22.551675ms
    Jan 10 04:04:34.274: INFO: Pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027017571s
    Jan 10 04:04:36.273: INFO: Pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026585495s
    STEP: Saw pod success 01/10/23 04:04:36.273
    Jan 10 04:04:36.274: INFO: Pod "pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089" satisfied condition "Succeeded or Failed"
    Jan 10 04:04:36.276: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089 container secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:04:36.282
    Jan 10 04:04:36.292: INFO: Waiting for pod pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089 to disappear
    Jan 10 04:04:36.296: INFO: Pod pod-secrets-df101d7b-bf88-4a5c-8f97-95637c2bf089 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:04:36.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7254" for this suite. 01/10/23 04:04:36.299
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:36.31
Jan 10 04:04:36.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:04:36.311
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:36.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:36.353
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 01/10/23 04:04:36.357
Jan 10 04:04:36.381: INFO: Waiting up to 5m0s for pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279" in namespace "emptydir-8664" to be "Succeeded or Failed"
Jan 10 04:04:36.407: INFO: Pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279": Phase="Pending", Reason="", readiness=false. Elapsed: 25.573221ms
Jan 10 04:04:38.410: INFO: Pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0290487s
Jan 10 04:04:40.410: INFO: Pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028695659s
STEP: Saw pod success 01/10/23 04:04:40.41
Jan 10 04:04:40.410: INFO: Pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279" satisfied condition "Succeeded or Failed"
Jan 10 04:04:40.412: INFO: Trying to get logs from node cncf-wk2 pod pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279 container test-container: <nil>
STEP: delete the pod 01/10/23 04:04:40.418
Jan 10 04:04:40.429: INFO: Waiting for pod pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279 to disappear
Jan 10 04:04:40.432: INFO: Pod pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:04:40.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8664" for this suite. 01/10/23 04:04:40.435
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":134,"skipped":2439,"failed":0}
------------------------------
• [4.129 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:36.31
    Jan 10 04:04:36.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:04:36.311
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:36.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:36.353
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 01/10/23 04:04:36.357
    Jan 10 04:04:36.381: INFO: Waiting up to 5m0s for pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279" in namespace "emptydir-8664" to be "Succeeded or Failed"
    Jan 10 04:04:36.407: INFO: Pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279": Phase="Pending", Reason="", readiness=false. Elapsed: 25.573221ms
    Jan 10 04:04:38.410: INFO: Pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0290487s
    Jan 10 04:04:40.410: INFO: Pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028695659s
    STEP: Saw pod success 01/10/23 04:04:40.41
    Jan 10 04:04:40.410: INFO: Pod "pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279" satisfied condition "Succeeded or Failed"
    Jan 10 04:04:40.412: INFO: Trying to get logs from node cncf-wk2 pod pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279 container test-container: <nil>
    STEP: delete the pod 01/10/23 04:04:40.418
    Jan 10 04:04:40.429: INFO: Waiting for pod pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279 to disappear
    Jan 10 04:04:40.432: INFO: Pod pod-4a88d8f3-39c2-4b81-85d4-acdbca32c279 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:04:40.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8664" for this suite. 01/10/23 04:04:40.435
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:40.443
Jan 10 04:04:40.443: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename podtemplate 01/10/23 04:04:40.444
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:40.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:40.562
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jan 10 04:04:40.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-3110" for this suite. 01/10/23 04:04:40.632
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":135,"skipped":2452,"failed":0}
------------------------------
• [0.194 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:40.443
    Jan 10 04:04:40.443: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename podtemplate 01/10/23 04:04:40.444
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:40.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:40.562
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jan 10 04:04:40.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-3110" for this suite. 01/10/23 04:04:40.632
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:40.644
Jan 10 04:04:40.644: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename hostport 01/10/23 04:04:40.645
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:40.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:40.73
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 01/10/23 04:04:40.738
Jan 10 04:04:40.749: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-1037" to be "running and ready"
Jan 10 04:04:40.755: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.22647ms
Jan 10 04:04:40.755: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:04:42.758: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009634613s
Jan 10 04:04:42.759: INFO: The phase of Pod pod1 is Running (Ready = true)
Jan 10 04:04:42.759: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.7.114 on the node which pod1 resides and expect scheduled 01/10/23 04:04:42.759
Jan 10 04:04:42.764: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-1037" to be "running and ready"
Jan 10 04:04:42.768: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.368711ms
Jan 10 04:04:42.768: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:04:44.774: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009394619s
Jan 10 04:04:44.774: INFO: The phase of Pod pod2 is Running (Ready = true)
Jan 10 04:04:44.774: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.7.114 but use UDP protocol on the node which pod2 resides 01/10/23 04:04:44.774
Jan 10 04:04:44.789: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-1037" to be "running and ready"
Jan 10 04:04:44.810: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.158515ms
Jan 10 04:04:44.810: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:04:46.814: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.024037392s
Jan 10 04:04:46.814: INFO: The phase of Pod pod3 is Running (Ready = true)
Jan 10 04:04:46.814: INFO: Pod "pod3" satisfied condition "running and ready"
Jan 10 04:04:46.820: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-1037" to be "running and ready"
Jan 10 04:04:46.825: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095471ms
Jan 10 04:04:46.825: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:04:48.829: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.00929108s
Jan 10 04:04:48.829: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Jan 10 04:04:48.829: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 01/10/23 04:04:48.831
Jan 10 04:04:48.831: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.7.114 http://127.0.0.1:54323/hostname] Namespace:hostport-1037 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:04:48.831: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:04:48.832: INFO: ExecWithOptions: Clientset creation
Jan 10 04:04:48.832: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1037/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.7.114+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.7.114, port: 54323 01/10/23 04:04:48.918
Jan 10 04:04:48.918: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.7.114:54323/hostname] Namespace:hostport-1037 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:04:48.918: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:04:48.919: INFO: ExecWithOptions: Clientset creation
Jan 10 04:04:48.920: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1037/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.7.114%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.7.114, port: 54323 UDP 01/10/23 04:04:49.059
Jan 10 04:04:49.059: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.7.114 54323] Namespace:hostport-1037 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:04:49.059: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:04:49.060: INFO: ExecWithOptions: Clientset creation
Jan 10 04:04:49.060: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1037/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.7.114+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Jan 10 04:04:54.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-1037" for this suite. 01/10/23 04:04:54.162
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":136,"skipped":2485,"failed":0}
------------------------------
• [SLOW TEST] [13.521 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:40.644
    Jan 10 04:04:40.644: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename hostport 01/10/23 04:04:40.645
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:40.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:40.73
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 01/10/23 04:04:40.738
    Jan 10 04:04:40.749: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-1037" to be "running and ready"
    Jan 10 04:04:40.755: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.22647ms
    Jan 10 04:04:40.755: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:04:42.758: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009634613s
    Jan 10 04:04:42.759: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jan 10 04:04:42.759: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.7.114 on the node which pod1 resides and expect scheduled 01/10/23 04:04:42.759
    Jan 10 04:04:42.764: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-1037" to be "running and ready"
    Jan 10 04:04:42.768: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.368711ms
    Jan 10 04:04:42.768: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:04:44.774: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009394619s
    Jan 10 04:04:44.774: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jan 10 04:04:44.774: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.7.114 but use UDP protocol on the node which pod2 resides 01/10/23 04:04:44.774
    Jan 10 04:04:44.789: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-1037" to be "running and ready"
    Jan 10 04:04:44.810: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.158515ms
    Jan 10 04:04:44.810: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:04:46.814: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.024037392s
    Jan 10 04:04:46.814: INFO: The phase of Pod pod3 is Running (Ready = true)
    Jan 10 04:04:46.814: INFO: Pod "pod3" satisfied condition "running and ready"
    Jan 10 04:04:46.820: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-1037" to be "running and ready"
    Jan 10 04:04:46.825: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095471ms
    Jan 10 04:04:46.825: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:04:48.829: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.00929108s
    Jan 10 04:04:48.829: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Jan 10 04:04:48.829: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 01/10/23 04:04:48.831
    Jan 10 04:04:48.831: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.7.114 http://127.0.0.1:54323/hostname] Namespace:hostport-1037 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:04:48.831: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:04:48.832: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:04:48.832: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1037/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.7.114+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.7.114, port: 54323 01/10/23 04:04:48.918
    Jan 10 04:04:48.918: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.7.114:54323/hostname] Namespace:hostport-1037 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:04:48.918: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:04:48.919: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:04:48.920: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1037/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.7.114%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.7.114, port: 54323 UDP 01/10/23 04:04:49.059
    Jan 10 04:04:49.059: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.7.114 54323] Namespace:hostport-1037 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:04:49.059: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:04:49.060: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:04:49.060: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-1037/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.7.114+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Jan 10 04:04:54.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-1037" for this suite. 01/10/23 04:04:54.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:54.168
Jan 10 04:04:54.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename ingressclass 01/10/23 04:04:54.169
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:54.201
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:54.208
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 01/10/23 04:04:54.213
STEP: getting /apis/networking.k8s.io 01/10/23 04:04:54.222
STEP: getting /apis/networking.k8s.iov1 01/10/23 04:04:54.225
STEP: creating 01/10/23 04:04:54.232
STEP: getting 01/10/23 04:04:54.253
STEP: listing 01/10/23 04:04:54.255
STEP: watching 01/10/23 04:04:54.257
Jan 10 04:04:54.258: INFO: starting watch
STEP: patching 01/10/23 04:04:54.259
STEP: updating 01/10/23 04:04:54.266
Jan 10 04:04:54.276: INFO: waiting for watch events with expected annotations
Jan 10 04:04:54.276: INFO: saw patched and updated annotations
STEP: deleting 01/10/23 04:04:54.276
STEP: deleting a collection 01/10/23 04:04:54.301
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Jan 10 04:04:54.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-5196" for this suite. 01/10/23 04:04:54.329
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":137,"skipped":2496,"failed":0}
------------------------------
• [0.172 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:54.168
    Jan 10 04:04:54.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename ingressclass 01/10/23 04:04:54.169
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:54.201
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:54.208
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 01/10/23 04:04:54.213
    STEP: getting /apis/networking.k8s.io 01/10/23 04:04:54.222
    STEP: getting /apis/networking.k8s.iov1 01/10/23 04:04:54.225
    STEP: creating 01/10/23 04:04:54.232
    STEP: getting 01/10/23 04:04:54.253
    STEP: listing 01/10/23 04:04:54.255
    STEP: watching 01/10/23 04:04:54.257
    Jan 10 04:04:54.258: INFO: starting watch
    STEP: patching 01/10/23 04:04:54.259
    STEP: updating 01/10/23 04:04:54.266
    Jan 10 04:04:54.276: INFO: waiting for watch events with expected annotations
    Jan 10 04:04:54.276: INFO: saw patched and updated annotations
    STEP: deleting 01/10/23 04:04:54.276
    STEP: deleting a collection 01/10/23 04:04:54.301
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Jan 10 04:04:54.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-5196" for this suite. 01/10/23 04:04:54.329
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:54.341
Jan 10 04:04:54.341: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:04:54.342
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:54.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:54.432
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-3cc3ea91-643b-4ebc-a9ee-8c295ea49e36 01/10/23 04:04:54.437
STEP: Creating a pod to test consume secrets 01/10/23 04:04:54.463
Jan 10 04:04:54.507: INFO: Waiting up to 5m0s for pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35" in namespace "secrets-5802" to be "Succeeded or Failed"
Jan 10 04:04:54.529: INFO: Pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35": Phase="Pending", Reason="", readiness=false. Elapsed: 21.517139ms
Jan 10 04:04:56.533: INFO: Pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025346189s
Jan 10 04:04:58.534: INFO: Pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026218601s
STEP: Saw pod success 01/10/23 04:04:58.534
Jan 10 04:04:58.534: INFO: Pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35" satisfied condition "Succeeded or Failed"
Jan 10 04:04:58.536: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35 container secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:04:58.542
Jan 10 04:04:58.549: INFO: Waiting for pod pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35 to disappear
Jan 10 04:04:58.556: INFO: Pod pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:04:58.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5802" for this suite. 01/10/23 04:04:58.559
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":138,"skipped":2505,"failed":0}
------------------------------
• [4.224 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:54.341
    Jan 10 04:04:54.341: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:04:54.342
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:54.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:54.432
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-3cc3ea91-643b-4ebc-a9ee-8c295ea49e36 01/10/23 04:04:54.437
    STEP: Creating a pod to test consume secrets 01/10/23 04:04:54.463
    Jan 10 04:04:54.507: INFO: Waiting up to 5m0s for pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35" in namespace "secrets-5802" to be "Succeeded or Failed"
    Jan 10 04:04:54.529: INFO: Pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35": Phase="Pending", Reason="", readiness=false. Elapsed: 21.517139ms
    Jan 10 04:04:56.533: INFO: Pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025346189s
    Jan 10 04:04:58.534: INFO: Pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026218601s
    STEP: Saw pod success 01/10/23 04:04:58.534
    Jan 10 04:04:58.534: INFO: Pod "pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35" satisfied condition "Succeeded or Failed"
    Jan 10 04:04:58.536: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35 container secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:04:58.542
    Jan 10 04:04:58.549: INFO: Waiting for pod pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35 to disappear
    Jan 10 04:04:58.556: INFO: Pod pod-secrets-5c64670a-eb9f-4fc7-ae99-89e1d272dd35 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:04:58.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5802" for this suite. 01/10/23 04:04:58.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:04:58.566
Jan 10 04:04:58.566: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:04:58.567
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:58.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:58.59
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-2938 01/10/23 04:04:58.593
STEP: creating service affinity-clusterip in namespace services-2938 01/10/23 04:04:58.593
STEP: creating replication controller affinity-clusterip in namespace services-2938 01/10/23 04:04:58.604
I0110 04:04:58.630531      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-2938, replica count: 3
I0110 04:05:01.681599      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 04:05:01.687: INFO: Creating new exec pod
Jan 10 04:05:01.690: INFO: Waiting up to 5m0s for pod "execpod-affinity8j8m6" in namespace "services-2938" to be "running"
Jan 10 04:05:01.697: INFO: Pod "execpod-affinity8j8m6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.337881ms
Jan 10 04:05:03.722: INFO: Pod "execpod-affinity8j8m6": Phase="Running", Reason="", readiness=true. Elapsed: 2.032153312s
Jan 10 04:05:03.723: INFO: Pod "execpod-affinity8j8m6" satisfied condition "running"
Jan 10 04:05:04.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2938 exec execpod-affinity8j8m6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Jan 10 04:05:04.947: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Jan 10 04:05:04.947: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:05:04.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2938 exec execpod-affinity8j8m6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.6.30 80'
Jan 10 04:05:05.184: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.6.30 80\nConnection to 10.43.6.30 80 port [tcp/http] succeeded!\n"
Jan 10 04:05:05.184: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:05:05.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2938 exec execpod-affinity8j8m6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.6.30:80/ ; done'
Jan 10 04:05:05.559: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n"
Jan 10 04:05:05.559: INFO: stdout: "\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6"
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
Jan 10 04:05:05.559: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-2938, will wait for the garbage collector to delete the pods 01/10/23 04:05:05.612
Jan 10 04:05:05.693: INFO: Deleting ReplicationController affinity-clusterip took: 9.21919ms
Jan 10 04:05:05.893: INFO: Terminating ReplicationController affinity-clusterip pods took: 200.493114ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:05:08.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2938" for this suite. 01/10/23 04:05:08.317
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":139,"skipped":2512,"failed":0}
------------------------------
• [SLOW TEST] [9.759 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:04:58.566
    Jan 10 04:04:58.566: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:04:58.567
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:04:58.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:04:58.59
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-2938 01/10/23 04:04:58.593
    STEP: creating service affinity-clusterip in namespace services-2938 01/10/23 04:04:58.593
    STEP: creating replication controller affinity-clusterip in namespace services-2938 01/10/23 04:04:58.604
    I0110 04:04:58.630531      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-2938, replica count: 3
    I0110 04:05:01.681599      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 04:05:01.687: INFO: Creating new exec pod
    Jan 10 04:05:01.690: INFO: Waiting up to 5m0s for pod "execpod-affinity8j8m6" in namespace "services-2938" to be "running"
    Jan 10 04:05:01.697: INFO: Pod "execpod-affinity8j8m6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.337881ms
    Jan 10 04:05:03.722: INFO: Pod "execpod-affinity8j8m6": Phase="Running", Reason="", readiness=true. Elapsed: 2.032153312s
    Jan 10 04:05:03.723: INFO: Pod "execpod-affinity8j8m6" satisfied condition "running"
    Jan 10 04:05:04.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2938 exec execpod-affinity8j8m6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Jan 10 04:05:04.947: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Jan 10 04:05:04.947: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:05:04.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2938 exec execpod-affinity8j8m6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.6.30 80'
    Jan 10 04:05:05.184: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.6.30 80\nConnection to 10.43.6.30 80 port [tcp/http] succeeded!\n"
    Jan 10 04:05:05.184: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:05:05.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2938 exec execpod-affinity8j8m6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.6.30:80/ ; done'
    Jan 10 04:05:05.559: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.6.30:80/\n"
    Jan 10 04:05:05.559: INFO: stdout: "\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6\naffinity-clusterip-6k7v6"
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Received response from host: affinity-clusterip-6k7v6
    Jan 10 04:05:05.559: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-2938, will wait for the garbage collector to delete the pods 01/10/23 04:05:05.612
    Jan 10 04:05:05.693: INFO: Deleting ReplicationController affinity-clusterip took: 9.21919ms
    Jan 10 04:05:05.893: INFO: Terminating ReplicationController affinity-clusterip pods took: 200.493114ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:05:08.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2938" for this suite. 01/10/23 04:05:08.317
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:08.33
Jan 10 04:05:08.330: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename endpointslice 01/10/23 04:05:08.331
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:08.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:08.369
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jan 10 04:05:10.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1854" for this suite. 01/10/23 04:05:10.737
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":140,"skipped":2518,"failed":0}
------------------------------
• [2.416 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:08.33
    Jan 10 04:05:08.330: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename endpointslice 01/10/23 04:05:08.331
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:08.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:08.369
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jan 10 04:05:10.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-1854" for this suite. 01/10/23 04:05:10.737
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:10.747
Jan 10 04:05:10.748: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 04:05:10.748
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:10.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:10.82
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Jan 10 04:05:10.831: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:05:14.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6157" for this suite. 01/10/23 04:05:14.216
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":141,"skipped":2526,"failed":0}
------------------------------
• [3.473 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:10.747
    Jan 10 04:05:10.748: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 04:05:10.748
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:10.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:10.82
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Jan 10 04:05:10.831: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:05:14.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-6157" for this suite. 01/10/23 04:05:14.216
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:14.221
Jan 10 04:05:14.221: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 04:05:14.222
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:14.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:14.273
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 01/10/23 04:05:14.292
Jan 10 04:05:14.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-8621 cluster-info'
Jan 10 04:05:14.385: INFO: stderr: ""
Jan 10 04:05:14.385: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 04:05:14.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8621" for this suite. 01/10/23 04:05:14.392
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":142,"skipped":2530,"failed":0}
------------------------------
• [0.175 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:14.221
    Jan 10 04:05:14.221: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 04:05:14.222
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:14.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:14.273
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 01/10/23 04:05:14.292
    Jan 10 04:05:14.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-8621 cluster-info'
    Jan 10 04:05:14.385: INFO: stderr: ""
    Jan 10 04:05:14.385: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 04:05:14.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8621" for this suite. 01/10/23 04:05:14.392
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:14.395
Jan 10 04:05:14.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename dns 01/10/23 04:05:14.397
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:14.433
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:14.438
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 01/10/23 04:05:14.478
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3684 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3684;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3684 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3684;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3684.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3684.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3684.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3684.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3684.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3684.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3684.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3684.svc;check="$$(dig +notcp +noall +answer +search 190.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.190_tcp@PTR;sleep 1; done
 01/10/23 04:05:14.526
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3684 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3684;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3684 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3684;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3684.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3684.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3684.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3684.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3684.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3684.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3684.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3684.svc;check="$$(dig +notcp +noall +answer +search 190.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.190_tcp@PTR;sleep 1; done
 01/10/23 04:05:14.526
STEP: creating a pod to probe DNS 01/10/23 04:05:14.527
STEP: submitting the pod to kubernetes 01/10/23 04:05:14.527
Jan 10 04:05:14.573: INFO: Waiting up to 15m0s for pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e" in namespace "dns-3684" to be "running"
Jan 10 04:05:14.582: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.29146ms
Jan 10 04:05:16.585: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011908766s
Jan 10 04:05:18.586: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0120666s
Jan 10 04:05:20.585: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011502135s
Jan 10 04:05:22.586: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012121362s
Jan 10 04:05:24.586: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Running", Reason="", readiness=true. Elapsed: 10.012044139s
Jan 10 04:05:24.586: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e" satisfied condition "running"
STEP: retrieving the pod 01/10/23 04:05:24.586
STEP: looking for the results for each expected name from probers 01/10/23 04:05:24.588
Jan 10 04:05:24.591: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.593: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.595: INFO: Unable to read wheezy_udp@dns-test-service.dns-3684 from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.598: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3684 from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.600: INFO: Unable to read wheezy_udp@dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.602: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.604: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.606: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.617: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.619: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.621: INFO: Unable to read jessie_udp@dns-test-service.dns-3684 from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.622: INFO: Unable to read jessie_tcp@dns-test-service.dns-3684 from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.625: INFO: Unable to read jessie_udp@dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.627: INFO: Unable to read jessie_tcp@dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.629: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.631: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
Jan 10 04:05:24.644: INFO: Lookups using dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3684 wheezy_tcp@dns-test-service.dns-3684 wheezy_udp@dns-test-service.dns-3684.svc wheezy_tcp@dns-test-service.dns-3684.svc wheezy_udp@_http._tcp.dns-test-service.dns-3684.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3684.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3684 jessie_tcp@dns-test-service.dns-3684 jessie_udp@dns-test-service.dns-3684.svc jessie_tcp@dns-test-service.dns-3684.svc jessie_udp@_http._tcp.dns-test-service.dns-3684.svc jessie_tcp@_http._tcp.dns-test-service.dns-3684.svc]

Jan 10 04:05:29.738: INFO: DNS probes using dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e succeeded

STEP: deleting the pod 01/10/23 04:05:29.738
STEP: deleting the test service 01/10/23 04:05:29.761
STEP: deleting the test headless service 01/10/23 04:05:29.837
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 10 04:05:29.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3684" for this suite. 01/10/23 04:05:29.855
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":143,"skipped":2531,"failed":0}
------------------------------
• [SLOW TEST] [15.468 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:14.395
    Jan 10 04:05:14.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename dns 01/10/23 04:05:14.397
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:14.433
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:14.438
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 01/10/23 04:05:14.478
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3684 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3684;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3684 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3684;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3684.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3684.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3684.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3684.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3684.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3684.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3684.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3684.svc;check="$$(dig +notcp +noall +answer +search 190.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.190_tcp@PTR;sleep 1; done
     01/10/23 04:05:14.526
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3684 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3684;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3684 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3684;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3684.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3684.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3684.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3684.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3684.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3684.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3684.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3684.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3684.svc;check="$$(dig +notcp +noall +answer +search 190.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.190_tcp@PTR;sleep 1; done
     01/10/23 04:05:14.526
    STEP: creating a pod to probe DNS 01/10/23 04:05:14.527
    STEP: submitting the pod to kubernetes 01/10/23 04:05:14.527
    Jan 10 04:05:14.573: INFO: Waiting up to 15m0s for pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e" in namespace "dns-3684" to be "running"
    Jan 10 04:05:14.582: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.29146ms
    Jan 10 04:05:16.585: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011908766s
    Jan 10 04:05:18.586: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0120666s
    Jan 10 04:05:20.585: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011502135s
    Jan 10 04:05:22.586: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012121362s
    Jan 10 04:05:24.586: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e": Phase="Running", Reason="", readiness=true. Elapsed: 10.012044139s
    Jan 10 04:05:24.586: INFO: Pod "dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 04:05:24.586
    STEP: looking for the results for each expected name from probers 01/10/23 04:05:24.588
    Jan 10 04:05:24.591: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.593: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.595: INFO: Unable to read wheezy_udp@dns-test-service.dns-3684 from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.598: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3684 from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.600: INFO: Unable to read wheezy_udp@dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.602: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.604: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.606: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.617: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.619: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.621: INFO: Unable to read jessie_udp@dns-test-service.dns-3684 from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.622: INFO: Unable to read jessie_tcp@dns-test-service.dns-3684 from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.625: INFO: Unable to read jessie_udp@dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.627: INFO: Unable to read jessie_tcp@dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.629: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.631: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3684.svc from pod dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e: the server could not find the requested resource (get pods dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e)
    Jan 10 04:05:24.644: INFO: Lookups using dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3684 wheezy_tcp@dns-test-service.dns-3684 wheezy_udp@dns-test-service.dns-3684.svc wheezy_tcp@dns-test-service.dns-3684.svc wheezy_udp@_http._tcp.dns-test-service.dns-3684.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3684.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3684 jessie_tcp@dns-test-service.dns-3684 jessie_udp@dns-test-service.dns-3684.svc jessie_tcp@dns-test-service.dns-3684.svc jessie_udp@_http._tcp.dns-test-service.dns-3684.svc jessie_tcp@_http._tcp.dns-test-service.dns-3684.svc]

    Jan 10 04:05:29.738: INFO: DNS probes using dns-3684/dns-test-3d3e7f1d-a873-49dc-b773-0b252de09a5e succeeded

    STEP: deleting the pod 01/10/23 04:05:29.738
    STEP: deleting the test service 01/10/23 04:05:29.761
    STEP: deleting the test headless service 01/10/23 04:05:29.837
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 10 04:05:29.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3684" for this suite. 01/10/23 04:05:29.855
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:29.865
Jan 10 04:05:29.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename statefulset 01/10/23 04:05:29.867
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:29.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:29.901
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3120 01/10/23 04:05:29.906
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 01/10/23 04:05:29.913
STEP: Creating pod with conflicting port in namespace statefulset-3120 01/10/23 04:05:29.926
STEP: Waiting until pod test-pod will start running in namespace statefulset-3120 01/10/23 04:05:29.962
Jan 10 04:05:29.963: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-3120" to be "running"
Jan 10 04:05:29.978: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.55275ms
Jan 10 04:05:31.983: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019993053s
Jan 10 04:05:31.983: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-3120 01/10/23 04:05:31.983
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3120 01/10/23 04:05:31.988
Jan 10 04:05:32.000: INFO: Observed stateful pod in namespace: statefulset-3120, name: ss-0, uid: 15aea177-e19f-4c7e-b8e7-7c8272adbecf, status phase: Pending. Waiting for statefulset controller to delete.
Jan 10 04:05:32.021: INFO: Observed stateful pod in namespace: statefulset-3120, name: ss-0, uid: 15aea177-e19f-4c7e-b8e7-7c8272adbecf, status phase: Failed. Waiting for statefulset controller to delete.
Jan 10 04:05:32.029: INFO: Observed stateful pod in namespace: statefulset-3120, name: ss-0, uid: 15aea177-e19f-4c7e-b8e7-7c8272adbecf, status phase: Failed. Waiting for statefulset controller to delete.
Jan 10 04:05:32.039: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3120
STEP: Removing pod with conflicting port in namespace statefulset-3120 01/10/23 04:05:32.039
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3120 and will be in running state 01/10/23 04:05:32.059
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 10 04:05:34.074: INFO: Deleting all statefulset in ns statefulset-3120
Jan 10 04:05:34.076: INFO: Scaling statefulset ss to 0
Jan 10 04:05:44.097: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 04:05:44.099: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 10 04:05:44.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3120" for this suite. 01/10/23 04:05:44.112
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":144,"skipped":2535,"failed":0}
------------------------------
• [SLOW TEST] [14.252 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:29.865
    Jan 10 04:05:29.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename statefulset 01/10/23 04:05:29.867
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:29.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:29.901
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3120 01/10/23 04:05:29.906
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 01/10/23 04:05:29.913
    STEP: Creating pod with conflicting port in namespace statefulset-3120 01/10/23 04:05:29.926
    STEP: Waiting until pod test-pod will start running in namespace statefulset-3120 01/10/23 04:05:29.962
    Jan 10 04:05:29.963: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-3120" to be "running"
    Jan 10 04:05:29.978: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.55275ms
    Jan 10 04:05:31.983: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019993053s
    Jan 10 04:05:31.983: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-3120 01/10/23 04:05:31.983
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3120 01/10/23 04:05:31.988
    Jan 10 04:05:32.000: INFO: Observed stateful pod in namespace: statefulset-3120, name: ss-0, uid: 15aea177-e19f-4c7e-b8e7-7c8272adbecf, status phase: Pending. Waiting for statefulset controller to delete.
    Jan 10 04:05:32.021: INFO: Observed stateful pod in namespace: statefulset-3120, name: ss-0, uid: 15aea177-e19f-4c7e-b8e7-7c8272adbecf, status phase: Failed. Waiting for statefulset controller to delete.
    Jan 10 04:05:32.029: INFO: Observed stateful pod in namespace: statefulset-3120, name: ss-0, uid: 15aea177-e19f-4c7e-b8e7-7c8272adbecf, status phase: Failed. Waiting for statefulset controller to delete.
    Jan 10 04:05:32.039: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3120
    STEP: Removing pod with conflicting port in namespace statefulset-3120 01/10/23 04:05:32.039
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3120 and will be in running state 01/10/23 04:05:32.059
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 10 04:05:34.074: INFO: Deleting all statefulset in ns statefulset-3120
    Jan 10 04:05:34.076: INFO: Scaling statefulset ss to 0
    Jan 10 04:05:44.097: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 04:05:44.099: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 10 04:05:44.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3120" for this suite. 01/10/23 04:05:44.112
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:44.12
Jan 10 04:05:44.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-lifecycle-hook 01/10/23 04:05:44.121
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:44.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:44.157
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 01/10/23 04:05:44.182
Jan 10 04:05:44.215: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5628" to be "running and ready"
Jan 10 04:05:44.275: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 60.55762ms
Jan 10 04:05:44.275: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:05:46.279: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.064683653s
Jan 10 04:05:46.279: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jan 10 04:05:46.279: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 01/10/23 04:05:46.283
Jan 10 04:05:46.290: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-5628" to be "running and ready"
Jan 10 04:05:46.330: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 39.754929ms
Jan 10 04:05:46.330: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:05:48.333: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042262897s
Jan 10 04:05:48.333: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:05:50.333: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.042899678s
Jan 10 04:05:50.333: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Jan 10 04:05:50.333: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 01/10/23 04:05:50.336
Jan 10 04:05:50.342: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 10 04:05:50.349: INFO: Pod pod-with-prestop-http-hook still exists
Jan 10 04:05:52.353: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 10 04:05:52.355: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 01/10/23 04:05:52.355
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jan 10 04:05:52.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5628" for this suite. 01/10/23 04:05:52.379
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":145,"skipped":2543,"failed":0}
------------------------------
• [SLOW TEST] [8.265 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:44.12
    Jan 10 04:05:44.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-lifecycle-hook 01/10/23 04:05:44.121
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:44.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:44.157
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 01/10/23 04:05:44.182
    Jan 10 04:05:44.215: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5628" to be "running and ready"
    Jan 10 04:05:44.275: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 60.55762ms
    Jan 10 04:05:44.275: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:05:46.279: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.064683653s
    Jan 10 04:05:46.279: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jan 10 04:05:46.279: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 01/10/23 04:05:46.283
    Jan 10 04:05:46.290: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-5628" to be "running and ready"
    Jan 10 04:05:46.330: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 39.754929ms
    Jan 10 04:05:46.330: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:05:48.333: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042262897s
    Jan 10 04:05:48.333: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:05:50.333: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.042899678s
    Jan 10 04:05:50.333: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Jan 10 04:05:50.333: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 01/10/23 04:05:50.336
    Jan 10 04:05:50.342: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Jan 10 04:05:50.349: INFO: Pod pod-with-prestop-http-hook still exists
    Jan 10 04:05:52.353: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Jan 10 04:05:52.355: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 01/10/23 04:05:52.355
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jan 10 04:05:52.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-5628" for this suite. 01/10/23 04:05:52.379
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:52.386
Jan 10 04:05:52.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename endpointslice 01/10/23 04:05:52.387
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:52.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:52.422
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Jan 10 04:05:52.440: INFO: Endpoints addresses: [172.31.15.218] , ports: [6443]
Jan 10 04:05:52.440: INFO: EndpointSlices addresses: [172.31.15.218] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jan 10 04:05:52.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1159" for this suite. 01/10/23 04:05:52.444
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":146,"skipped":2553,"failed":0}
------------------------------
• [0.065 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:52.386
    Jan 10 04:05:52.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename endpointslice 01/10/23 04:05:52.387
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:52.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:52.422
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Jan 10 04:05:52.440: INFO: Endpoints addresses: [172.31.15.218] , ports: [6443]
    Jan 10 04:05:52.440: INFO: EndpointSlices addresses: [172.31.15.218] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jan 10 04:05:52.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-1159" for this suite. 01/10/23 04:05:52.444
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:52.465
Jan 10 04:05:52.465: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:05:52.466
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:52.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:52.494
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 01/10/23 04:05:52.499
Jan 10 04:05:52.514: INFO: Waiting up to 5m0s for pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699" in namespace "downward-api-3853" to be "Succeeded or Failed"
Jan 10 04:05:52.523: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699": Phase="Pending", Reason="", readiness=false. Elapsed: 8.763653ms
Jan 10 04:05:54.526: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012469617s
Jan 10 04:05:56.526: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012486664s
Jan 10 04:05:58.525: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011355524s
STEP: Saw pod success 01/10/23 04:05:58.525
Jan 10 04:05:58.525: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699" satisfied condition "Succeeded or Failed"
Jan 10 04:05:58.528: INFO: Trying to get logs from node cncf-wk2 pod downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699 container dapi-container: <nil>
STEP: delete the pod 01/10/23 04:05:58.537
Jan 10 04:05:58.550: INFO: Waiting for pod downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699 to disappear
Jan 10 04:05:58.555: INFO: Pod downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 10 04:05:58.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3853" for this suite. 01/10/23 04:05:58.558
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":147,"skipped":2554,"failed":0}
------------------------------
• [SLOW TEST] [6.099 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:52.465
    Jan 10 04:05:52.465: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:05:52.466
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:52.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:52.494
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 01/10/23 04:05:52.499
    Jan 10 04:05:52.514: INFO: Waiting up to 5m0s for pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699" in namespace "downward-api-3853" to be "Succeeded or Failed"
    Jan 10 04:05:52.523: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699": Phase="Pending", Reason="", readiness=false. Elapsed: 8.763653ms
    Jan 10 04:05:54.526: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012469617s
    Jan 10 04:05:56.526: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012486664s
    Jan 10 04:05:58.525: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011355524s
    STEP: Saw pod success 01/10/23 04:05:58.525
    Jan 10 04:05:58.525: INFO: Pod "downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699" satisfied condition "Succeeded or Failed"
    Jan 10 04:05:58.528: INFO: Trying to get logs from node cncf-wk2 pod downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699 container dapi-container: <nil>
    STEP: delete the pod 01/10/23 04:05:58.537
    Jan 10 04:05:58.550: INFO: Waiting for pod downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699 to disappear
    Jan 10 04:05:58.555: INFO: Pod downward-api-5139e489-cdd9-46f8-8cb7-8c70f5760699 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 10 04:05:58.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3853" for this suite. 01/10/23 04:05:58.558
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:58.565
Jan 10 04:05:58.565: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename disruption 01/10/23 04:05:58.566
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:58.592
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:58.596
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:05:58.602
Jan 10 04:05:58.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename disruption-2 01/10/23 04:05:58.604
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:58.685
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:58.704
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 01/10/23 04:05:58.712
STEP: Waiting for the pdb to be processed 01/10/23 04:05:58.738
STEP: Waiting for the pdb to be processed 01/10/23 04:05:58.749
STEP: listing a collection of PDBs across all namespaces 01/10/23 04:06:00.757
STEP: listing a collection of PDBs in namespace disruption-388 01/10/23 04:06:00.76
STEP: deleting a collection of PDBs 01/10/23 04:06:00.765
STEP: Waiting for the PDB collection to be deleted 01/10/23 04:06:00.772
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Jan 10 04:06:00.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-9992" for this suite. 01/10/23 04:06:00.782
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 10 04:06:00.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-388" for this suite. 01/10/23 04:06:00.802
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":148,"skipped":2565,"failed":0}
------------------------------
• [2.272 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:58.565
    Jan 10 04:05:58.565: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename disruption 01/10/23 04:05:58.566
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:58.592
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:58.596
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:05:58.602
    Jan 10 04:05:58.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename disruption-2 01/10/23 04:05:58.604
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:05:58.685
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:05:58.704
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 01/10/23 04:05:58.712
    STEP: Waiting for the pdb to be processed 01/10/23 04:05:58.738
    STEP: Waiting for the pdb to be processed 01/10/23 04:05:58.749
    STEP: listing a collection of PDBs across all namespaces 01/10/23 04:06:00.757
    STEP: listing a collection of PDBs in namespace disruption-388 01/10/23 04:06:00.76
    STEP: deleting a collection of PDBs 01/10/23 04:06:00.765
    STEP: Waiting for the PDB collection to be deleted 01/10/23 04:06:00.772
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Jan 10 04:06:00.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-9992" for this suite. 01/10/23 04:06:00.782
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 10 04:06:00.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-388" for this suite. 01/10/23 04:06:00.802
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:06:00.852
Jan 10 04:06:00.852: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:06:00.853
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:00.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:00.893
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:06:00.999
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:06:01.642
STEP: Deploying the webhook pod 01/10/23 04:06:01.649
STEP: Wait for the deployment to be ready 01/10/23 04:06:01.676
Jan 10 04:06:01.730: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 10 04:06:03.745: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 6, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 6, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 6, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 6, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/10/23 04:06:05.749
STEP: Verifying the service has paired with the endpoint 01/10/23 04:06:05.774
Jan 10 04:06:06.775: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Jan 10 04:06:06.777: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-345-crds.webhook.example.com via the AdmissionRegistration API 01/10/23 04:06:07.323
STEP: Creating a custom resource while v1 is storage version 01/10/23 04:06:07.391
STEP: Patching Custom Resource Definition to set v2 as storage 01/10/23 04:06:09.494
STEP: Patching the custom resource while v2 is storage version 01/10/23 04:06:09.52
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:06:10.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-509" for this suite. 01/10/23 04:06:10.098
STEP: Destroying namespace "webhook-509-markers" for this suite. 01/10/23 04:06:10.116
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":149,"skipped":2590,"failed":0}
------------------------------
• [SLOW TEST] [9.452 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:06:00.852
    Jan 10 04:06:00.852: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:06:00.853
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:00.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:00.893
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:06:00.999
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:06:01.642
    STEP: Deploying the webhook pod 01/10/23 04:06:01.649
    STEP: Wait for the deployment to be ready 01/10/23 04:06:01.676
    Jan 10 04:06:01.730: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 10 04:06:03.745: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 6, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 6, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 6, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 6, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/10/23 04:06:05.749
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:06:05.774
    Jan 10 04:06:06.775: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Jan 10 04:06:06.777: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-345-crds.webhook.example.com via the AdmissionRegistration API 01/10/23 04:06:07.323
    STEP: Creating a custom resource while v1 is storage version 01/10/23 04:06:07.391
    STEP: Patching Custom Resource Definition to set v2 as storage 01/10/23 04:06:09.494
    STEP: Patching the custom resource while v2 is storage version 01/10/23 04:06:09.52
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:06:10.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-509" for this suite. 01/10/23 04:06:10.098
    STEP: Destroying namespace "webhook-509-markers" for this suite. 01/10/23 04:06:10.116
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:06:10.316
Jan 10 04:06:10.317: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:06:10.318
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:10.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:10.437
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-1114 01/10/23 04:06:10.451
STEP: creating replication controller nodeport-test in namespace services-1114 01/10/23 04:06:10.512
I0110 04:06:10.548882      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1114, replica count: 2
I0110 04:06:13.599900      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 04:06:13.599: INFO: Creating new exec pod
Jan 10 04:06:13.603: INFO: Waiting up to 5m0s for pod "execpodgh8t5" in namespace "services-1114" to be "running"
Jan 10 04:06:13.613: INFO: Pod "execpodgh8t5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.328479ms
Jan 10 04:06:15.615: INFO: Pod "execpodgh8t5": Phase="Running", Reason="", readiness=true. Elapsed: 2.01224655s
Jan 10 04:06:15.616: INFO: Pod "execpodgh8t5" satisfied condition "running"
Jan 10 04:06:16.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jan 10 04:06:16.785: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jan 10 04:06:16.785: INFO: stdout: ""
Jan 10 04:06:17.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jan 10 04:06:18.089: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jan 10 04:06:18.089: INFO: stdout: ""
Jan 10 04:06:18.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jan 10 04:06:18.959: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jan 10 04:06:18.959: INFO: stdout: ""
Jan 10 04:06:19.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jan 10 04:06:20.023: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jan 10 04:06:20.023: INFO: stdout: "nodeport-test-rh7hx"
Jan 10 04:06:20.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.192.181 80'
Jan 10 04:06:20.214: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.192.181 80\nConnection to 10.43.192.181 80 port [tcp/http] succeeded!\n"
Jan 10 04:06:20.214: INFO: stdout: ""
Jan 10 04:06:21.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.192.181 80'
Jan 10 04:06:21.396: INFO: stderr: "+ nc -v -t -w 2 10.43.192.181 80\n+ echo hostName\nConnection to 10.43.192.181 80 port [tcp/http] succeeded!\n"
Jan 10 04:06:21.396: INFO: stdout: "nodeport-test-rh7hx"
Jan 10 04:06:21.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 30141'
Jan 10 04:06:21.610: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 30141\nConnection to 172.31.3.44 30141 port [tcp/*] succeeded!\n"
Jan 10 04:06:21.610: INFO: stdout: ""
Jan 10 04:06:22.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 30141'
Jan 10 04:06:22.741: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 30141\nConnection to 172.31.3.44 30141 port [tcp/*] succeeded!\n"
Jan 10 04:06:22.741: INFO: stdout: "nodeport-test-bwx9n"
Jan 10 04:06:22.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.114 30141'
Jan 10 04:06:22.896: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.7.114 30141\nConnection to 172.31.7.114 30141 port [tcp/*] succeeded!\n"
Jan 10 04:06:22.896: INFO: stdout: "nodeport-test-bwx9n"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:06:22.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1114" for this suite. 01/10/23 04:06:22.9
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":150,"skipped":2619,"failed":0}
------------------------------
• [SLOW TEST] [12.594 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:06:10.316
    Jan 10 04:06:10.317: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:06:10.318
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:10.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:10.437
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-1114 01/10/23 04:06:10.451
    STEP: creating replication controller nodeport-test in namespace services-1114 01/10/23 04:06:10.512
    I0110 04:06:10.548882      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1114, replica count: 2
    I0110 04:06:13.599900      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 04:06:13.599: INFO: Creating new exec pod
    Jan 10 04:06:13.603: INFO: Waiting up to 5m0s for pod "execpodgh8t5" in namespace "services-1114" to be "running"
    Jan 10 04:06:13.613: INFO: Pod "execpodgh8t5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.328479ms
    Jan 10 04:06:15.615: INFO: Pod "execpodgh8t5": Phase="Running", Reason="", readiness=true. Elapsed: 2.01224655s
    Jan 10 04:06:15.616: INFO: Pod "execpodgh8t5" satisfied condition "running"
    Jan 10 04:06:16.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Jan 10 04:06:16.785: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Jan 10 04:06:16.785: INFO: stdout: ""
    Jan 10 04:06:17.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Jan 10 04:06:18.089: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Jan 10 04:06:18.089: INFO: stdout: ""
    Jan 10 04:06:18.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Jan 10 04:06:18.959: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Jan 10 04:06:18.959: INFO: stdout: ""
    Jan 10 04:06:19.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Jan 10 04:06:20.023: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Jan 10 04:06:20.023: INFO: stdout: "nodeport-test-rh7hx"
    Jan 10 04:06:20.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.192.181 80'
    Jan 10 04:06:20.214: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.192.181 80\nConnection to 10.43.192.181 80 port [tcp/http] succeeded!\n"
    Jan 10 04:06:20.214: INFO: stdout: ""
    Jan 10 04:06:21.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.192.181 80'
    Jan 10 04:06:21.396: INFO: stderr: "+ nc -v -t -w 2 10.43.192.181 80\n+ echo hostName\nConnection to 10.43.192.181 80 port [tcp/http] succeeded!\n"
    Jan 10 04:06:21.396: INFO: stdout: "nodeport-test-rh7hx"
    Jan 10 04:06:21.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 30141'
    Jan 10 04:06:21.610: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 30141\nConnection to 172.31.3.44 30141 port [tcp/*] succeeded!\n"
    Jan 10 04:06:21.610: INFO: stdout: ""
    Jan 10 04:06:22.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 30141'
    Jan 10 04:06:22.741: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 30141\nConnection to 172.31.3.44 30141 port [tcp/*] succeeded!\n"
    Jan 10 04:06:22.741: INFO: stdout: "nodeport-test-bwx9n"
    Jan 10 04:06:22.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-1114 exec execpodgh8t5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.114 30141'
    Jan 10 04:06:22.896: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.7.114 30141\nConnection to 172.31.7.114 30141 port [tcp/*] succeeded!\n"
    Jan 10 04:06:22.896: INFO: stdout: "nodeport-test-bwx9n"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:06:22.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1114" for this suite. 01/10/23 04:06:22.9
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:06:22.908
Jan 10 04:06:22.909: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename gc 01/10/23 04:06:22.91
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:22.948
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:22.961
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 01/10/23 04:06:22.972
STEP: delete the rc 01/10/23 04:06:28.145
STEP: wait for the rc to be deleted 01/10/23 04:06:28.31
Jan 10 04:06:29.877: INFO: 80 pods remaining
Jan 10 04:06:29.877: INFO: 80 pods has nil DeletionTimestamp
Jan 10 04:06:29.877: INFO: 
Jan 10 04:06:30.734: INFO: 76 pods remaining
Jan 10 04:06:30.734: INFO: 71 pods has nil DeletionTimestamp
Jan 10 04:06:30.734: INFO: 
Jan 10 04:06:32.913: INFO: 56 pods remaining
Jan 10 04:06:32.913: INFO: 53 pods has nil DeletionTimestamp
Jan 10 04:06:32.913: INFO: 
Jan 10 04:06:34.114: INFO: 40 pods remaining
Jan 10 04:06:34.114: INFO: 40 pods has nil DeletionTimestamp
Jan 10 04:06:34.114: INFO: 
Jan 10 04:06:35.500: INFO: 24 pods remaining
Jan 10 04:06:35.500: INFO: 21 pods has nil DeletionTimestamp
Jan 10 04:06:35.500: INFO: 
Jan 10 04:06:37.209: INFO: 16 pods remaining
Jan 10 04:06:37.209: INFO: 8 pods has nil DeletionTimestamp
Jan 10 04:06:37.209: INFO: 
Jan 10 04:06:37.786: INFO: 2 pods remaining
Jan 10 04:06:37.786: INFO: 0 pods has nil DeletionTimestamp
Jan 10 04:06:37.786: INFO: 
Jan 10 04:06:38.410: INFO: 0 pods remaining
Jan 10 04:06:38.410: INFO: 0 pods has nil DeletionTimestamp
Jan 10 04:06:38.410: INFO: 
STEP: Gathering metrics 01/10/23 04:06:39.356
W0110 04:06:39.376141      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 10 04:06:39.376: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 10 04:06:39.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-75" for this suite. 01/10/23 04:06:39.397
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":151,"skipped":2619,"failed":0}
------------------------------
• [SLOW TEST] [16.501 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:06:22.908
    Jan 10 04:06:22.909: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename gc 01/10/23 04:06:22.91
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:22.948
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:22.961
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 01/10/23 04:06:22.972
    STEP: delete the rc 01/10/23 04:06:28.145
    STEP: wait for the rc to be deleted 01/10/23 04:06:28.31
    Jan 10 04:06:29.877: INFO: 80 pods remaining
    Jan 10 04:06:29.877: INFO: 80 pods has nil DeletionTimestamp
    Jan 10 04:06:29.877: INFO: 
    Jan 10 04:06:30.734: INFO: 76 pods remaining
    Jan 10 04:06:30.734: INFO: 71 pods has nil DeletionTimestamp
    Jan 10 04:06:30.734: INFO: 
    Jan 10 04:06:32.913: INFO: 56 pods remaining
    Jan 10 04:06:32.913: INFO: 53 pods has nil DeletionTimestamp
    Jan 10 04:06:32.913: INFO: 
    Jan 10 04:06:34.114: INFO: 40 pods remaining
    Jan 10 04:06:34.114: INFO: 40 pods has nil DeletionTimestamp
    Jan 10 04:06:34.114: INFO: 
    Jan 10 04:06:35.500: INFO: 24 pods remaining
    Jan 10 04:06:35.500: INFO: 21 pods has nil DeletionTimestamp
    Jan 10 04:06:35.500: INFO: 
    Jan 10 04:06:37.209: INFO: 16 pods remaining
    Jan 10 04:06:37.209: INFO: 8 pods has nil DeletionTimestamp
    Jan 10 04:06:37.209: INFO: 
    Jan 10 04:06:37.786: INFO: 2 pods remaining
    Jan 10 04:06:37.786: INFO: 0 pods has nil DeletionTimestamp
    Jan 10 04:06:37.786: INFO: 
    Jan 10 04:06:38.410: INFO: 0 pods remaining
    Jan 10 04:06:38.410: INFO: 0 pods has nil DeletionTimestamp
    Jan 10 04:06:38.410: INFO: 
    STEP: Gathering metrics 01/10/23 04:06:39.356
    W0110 04:06:39.376141      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 10 04:06:39.376: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 10 04:06:39.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-75" for this suite. 01/10/23 04:06:39.397
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:06:39.412
Jan 10 04:06:39.412: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename runtimeclass 01/10/23 04:06:39.424
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:39.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:39.824
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-4000-delete-me 01/10/23 04:06:39.962
STEP: Waiting for the RuntimeClass to disappear 01/10/23 04:06:40.001
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 10 04:06:40.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4000" for this suite. 01/10/23 04:06:40.322
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":152,"skipped":2623,"failed":0}
------------------------------
• [1.060 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:06:39.412
    Jan 10 04:06:39.412: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename runtimeclass 01/10/23 04:06:39.424
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:39.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:39.824
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-4000-delete-me 01/10/23 04:06:39.962
    STEP: Waiting for the RuntimeClass to disappear 01/10/23 04:06:40.001
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 10 04:06:40.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4000" for this suite. 01/10/23 04:06:40.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:06:40.473
Jan 10 04:06:40.474: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pod-network-test 01/10/23 04:06:40.474
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:40.67
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:40.715
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-5934 01/10/23 04:06:40.743
STEP: creating a selector 01/10/23 04:06:40.743
STEP: Creating the service pods in kubernetes 01/10/23 04:06:40.743
Jan 10 04:06:40.743: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jan 10 04:06:41.141: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5934" to be "running and ready"
Jan 10 04:06:41.194: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 53.026033ms
Jan 10 04:06:41.194: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:06:43.204: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063382268s
Jan 10 04:06:43.204: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:06:45.221: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.080412602s
Jan 10 04:06:45.221: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:06:47.213: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.072383021s
Jan 10 04:06:47.213: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:06:49.199: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.058057672s
Jan 10 04:06:49.199: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:06:51.199: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.058117993s
Jan 10 04:06:51.199: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:06:53.202: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.06100344s
Jan 10 04:06:53.202: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:06:55.197: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.056454837s
Jan 10 04:06:55.197: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:06:57.197: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.056346482s
Jan 10 04:06:57.197: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:06:59.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.058405339s
Jan 10 04:06:59.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:07:01.210: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.06926233s
Jan 10 04:07:01.210: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:07:03.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.05815702s
Jan 10 04:07:03.199: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jan 10 04:07:03.199: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jan 10 04:07:03.202: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5934" to be "running and ready"
Jan 10 04:07:03.208: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.631088ms
Jan 10 04:07:03.208: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jan 10 04:07:03.208: INFO: Pod "netserver-1" satisfied condition "running and ready"
Jan 10 04:07:03.212: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5934" to be "running and ready"
Jan 10 04:07:03.216: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.56282ms
Jan 10 04:07:03.216: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Jan 10 04:07:03.216: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 01/10/23 04:07:03.221
Jan 10 04:07:03.230: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5934" to be "running"
Jan 10 04:07:03.237: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.733687ms
Jan 10 04:07:05.242: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01192067s
Jan 10 04:07:05.242: INFO: Pod "test-container-pod" satisfied condition "running"
Jan 10 04:07:05.245: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jan 10 04:07:05.246: INFO: Breadth first check of 10.42.0.61 on host 172.31.15.218...
Jan 10 04:07:05.248: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.182:9080/dial?request=hostname&protocol=http&host=10.42.0.61&port=8083&tries=1'] Namespace:pod-network-test-5934 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:07:05.248: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:07:05.248: INFO: ExecWithOptions: Clientset creation
Jan 10 04:07:05.249: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-5934/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.182%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.0.61%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 10 04:07:05.353: INFO: Waiting for responses: map[]
Jan 10 04:07:05.353: INFO: reached 10.42.0.61 after 0/1 tries
Jan 10 04:07:05.353: INFO: Breadth first check of 10.42.1.181 on host 172.31.3.44...
Jan 10 04:07:05.356: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.182:9080/dial?request=hostname&protocol=http&host=10.42.1.181&port=8083&tries=1'] Namespace:pod-network-test-5934 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:07:05.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:07:05.357: INFO: ExecWithOptions: Clientset creation
Jan 10 04:07:05.357: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-5934/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.182%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.1.181%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 10 04:07:05.437: INFO: Waiting for responses: map[]
Jan 10 04:07:05.437: INFO: reached 10.42.1.181 after 0/1 tries
Jan 10 04:07:05.437: INFO: Breadth first check of 10.42.2.100 on host 172.31.7.114...
Jan 10 04:07:05.440: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.182:9080/dial?request=hostname&protocol=http&host=10.42.2.100&port=8083&tries=1'] Namespace:pod-network-test-5934 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:07:05.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:07:05.440: INFO: ExecWithOptions: Clientset creation
Jan 10 04:07:05.441: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-5934/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.182%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.2.100%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 10 04:07:05.516: INFO: Waiting for responses: map[]
Jan 10 04:07:05.516: INFO: reached 10.42.2.100 after 0/1 tries
Jan 10 04:07:05.516: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jan 10 04:07:05.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5934" for this suite. 01/10/23 04:07:05.519
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":153,"skipped":2641,"failed":0}
------------------------------
• [SLOW TEST] [25.049 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:06:40.473
    Jan 10 04:06:40.474: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pod-network-test 01/10/23 04:06:40.474
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:06:40.67
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:06:40.715
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-5934 01/10/23 04:06:40.743
    STEP: creating a selector 01/10/23 04:06:40.743
    STEP: Creating the service pods in kubernetes 01/10/23 04:06:40.743
    Jan 10 04:06:40.743: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jan 10 04:06:41.141: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5934" to be "running and ready"
    Jan 10 04:06:41.194: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 53.026033ms
    Jan 10 04:06:41.194: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:06:43.204: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063382268s
    Jan 10 04:06:43.204: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:06:45.221: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.080412602s
    Jan 10 04:06:45.221: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:06:47.213: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.072383021s
    Jan 10 04:06:47.213: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:06:49.199: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.058057672s
    Jan 10 04:06:49.199: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:06:51.199: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.058117993s
    Jan 10 04:06:51.199: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:06:53.202: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.06100344s
    Jan 10 04:06:53.202: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:06:55.197: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.056454837s
    Jan 10 04:06:55.197: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:06:57.197: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.056346482s
    Jan 10 04:06:57.197: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:06:59.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.058405339s
    Jan 10 04:06:59.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:07:01.210: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.06926233s
    Jan 10 04:07:01.210: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:07:03.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.05815702s
    Jan 10 04:07:03.199: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jan 10 04:07:03.199: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jan 10 04:07:03.202: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5934" to be "running and ready"
    Jan 10 04:07:03.208: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.631088ms
    Jan 10 04:07:03.208: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jan 10 04:07:03.208: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Jan 10 04:07:03.212: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5934" to be "running and ready"
    Jan 10 04:07:03.216: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.56282ms
    Jan 10 04:07:03.216: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Jan 10 04:07:03.216: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 01/10/23 04:07:03.221
    Jan 10 04:07:03.230: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5934" to be "running"
    Jan 10 04:07:03.237: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.733687ms
    Jan 10 04:07:05.242: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01192067s
    Jan 10 04:07:05.242: INFO: Pod "test-container-pod" satisfied condition "running"
    Jan 10 04:07:05.245: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Jan 10 04:07:05.246: INFO: Breadth first check of 10.42.0.61 on host 172.31.15.218...
    Jan 10 04:07:05.248: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.182:9080/dial?request=hostname&protocol=http&host=10.42.0.61&port=8083&tries=1'] Namespace:pod-network-test-5934 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:07:05.248: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:07:05.248: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:07:05.249: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-5934/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.182%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.0.61%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 10 04:07:05.353: INFO: Waiting for responses: map[]
    Jan 10 04:07:05.353: INFO: reached 10.42.0.61 after 0/1 tries
    Jan 10 04:07:05.353: INFO: Breadth first check of 10.42.1.181 on host 172.31.3.44...
    Jan 10 04:07:05.356: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.182:9080/dial?request=hostname&protocol=http&host=10.42.1.181&port=8083&tries=1'] Namespace:pod-network-test-5934 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:07:05.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:07:05.357: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:07:05.357: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-5934/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.182%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.1.181%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 10 04:07:05.437: INFO: Waiting for responses: map[]
    Jan 10 04:07:05.437: INFO: reached 10.42.1.181 after 0/1 tries
    Jan 10 04:07:05.437: INFO: Breadth first check of 10.42.2.100 on host 172.31.7.114...
    Jan 10 04:07:05.440: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.182:9080/dial?request=hostname&protocol=http&host=10.42.2.100&port=8083&tries=1'] Namespace:pod-network-test-5934 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:07:05.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:07:05.440: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:07:05.441: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-5934/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.182%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.2.100%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 10 04:07:05.516: INFO: Waiting for responses: map[]
    Jan 10 04:07:05.516: INFO: reached 10.42.2.100 after 0/1 tries
    Jan 10 04:07:05.516: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jan 10 04:07:05.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5934" for this suite. 01/10/23 04:07:05.519
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:07:05.523
Jan 10 04:07:05.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:07:05.525
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:05.561
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:05.566
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 01/10/23 04:07:05.573
Jan 10 04:07:05.593: INFO: Waiting up to 5m0s for pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922" in namespace "emptydir-391" to be "Succeeded or Failed"
Jan 10 04:07:05.615: INFO: Pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922": Phase="Pending", Reason="", readiness=false. Elapsed: 21.811066ms
Jan 10 04:07:07.620: INFO: Pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027433513s
Jan 10 04:07:09.618: INFO: Pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024774533s
STEP: Saw pod success 01/10/23 04:07:09.618
Jan 10 04:07:09.618: INFO: Pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922" satisfied condition "Succeeded or Failed"
Jan 10 04:07:09.621: INFO: Trying to get logs from node cncf-wk2 pod pod-814192b5-eb04-4c37-81ba-77d7a5d4b922 container test-container: <nil>
STEP: delete the pod 01/10/23 04:07:09.629
Jan 10 04:07:09.652: INFO: Waiting for pod pod-814192b5-eb04-4c37-81ba-77d7a5d4b922 to disappear
Jan 10 04:07:09.661: INFO: Pod pod-814192b5-eb04-4c37-81ba-77d7a5d4b922 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:07:09.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-391" for this suite. 01/10/23 04:07:09.666
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":154,"skipped":2648,"failed":0}
------------------------------
• [4.150 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:07:05.523
    Jan 10 04:07:05.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:07:05.525
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:05.561
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:05.566
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 01/10/23 04:07:05.573
    Jan 10 04:07:05.593: INFO: Waiting up to 5m0s for pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922" in namespace "emptydir-391" to be "Succeeded or Failed"
    Jan 10 04:07:05.615: INFO: Pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922": Phase="Pending", Reason="", readiness=false. Elapsed: 21.811066ms
    Jan 10 04:07:07.620: INFO: Pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027433513s
    Jan 10 04:07:09.618: INFO: Pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024774533s
    STEP: Saw pod success 01/10/23 04:07:09.618
    Jan 10 04:07:09.618: INFO: Pod "pod-814192b5-eb04-4c37-81ba-77d7a5d4b922" satisfied condition "Succeeded or Failed"
    Jan 10 04:07:09.621: INFO: Trying to get logs from node cncf-wk2 pod pod-814192b5-eb04-4c37-81ba-77d7a5d4b922 container test-container: <nil>
    STEP: delete the pod 01/10/23 04:07:09.629
    Jan 10 04:07:09.652: INFO: Waiting for pod pod-814192b5-eb04-4c37-81ba-77d7a5d4b922 to disappear
    Jan 10 04:07:09.661: INFO: Pod pod-814192b5-eb04-4c37-81ba-77d7a5d4b922 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:07:09.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-391" for this suite. 01/10/23 04:07:09.666
  << End Captured GinkgoWriter Output
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:07:09.678
Jan 10 04:07:09.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename svcaccounts 01/10/23 04:07:09.679
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:09.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:09.781
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Jan 10 04:07:09.806: INFO: Got root ca configmap in namespace "svcaccounts-2044"
Jan 10 04:07:09.820: INFO: Deleted root ca configmap in namespace "svcaccounts-2044"
STEP: waiting for a new root ca configmap created 01/10/23 04:07:10.321
Jan 10 04:07:10.323: INFO: Recreated root ca configmap in namespace "svcaccounts-2044"
Jan 10 04:07:10.329: INFO: Updated root ca configmap in namespace "svcaccounts-2044"
STEP: waiting for the root ca configmap reconciled 01/10/23 04:07:10.83
Jan 10 04:07:10.839: INFO: Reconciled root ca configmap in namespace "svcaccounts-2044"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 10 04:07:10.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2044" for this suite. 01/10/23 04:07:10.894
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":155,"skipped":2648,"failed":0}
------------------------------
• [1.237 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:07:09.678
    Jan 10 04:07:09.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename svcaccounts 01/10/23 04:07:09.679
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:09.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:09.781
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Jan 10 04:07:09.806: INFO: Got root ca configmap in namespace "svcaccounts-2044"
    Jan 10 04:07:09.820: INFO: Deleted root ca configmap in namespace "svcaccounts-2044"
    STEP: waiting for a new root ca configmap created 01/10/23 04:07:10.321
    Jan 10 04:07:10.323: INFO: Recreated root ca configmap in namespace "svcaccounts-2044"
    Jan 10 04:07:10.329: INFO: Updated root ca configmap in namespace "svcaccounts-2044"
    STEP: waiting for the root ca configmap reconciled 01/10/23 04:07:10.83
    Jan 10 04:07:10.839: INFO: Reconciled root ca configmap in namespace "svcaccounts-2044"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 10 04:07:10.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2044" for this suite. 01/10/23 04:07:10.894
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:07:10.935
Jan 10 04:07:10.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:07:10.941
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:11.007
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:11.018
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 01/10/23 04:07:11.02
Jan 10 04:07:11.044: INFO: Waiting up to 5m0s for pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2" in namespace "emptydir-2867" to be "Succeeded or Failed"
Jan 10 04:07:11.070: INFO: Pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.197632ms
Jan 10 04:07:13.073: INFO: Pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029303471s
Jan 10 04:07:15.079: INFO: Pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035320395s
STEP: Saw pod success 01/10/23 04:07:15.079
Jan 10 04:07:15.079: INFO: Pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2" satisfied condition "Succeeded or Failed"
Jan 10 04:07:15.094: INFO: Trying to get logs from node cncf-wk2 pod pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2 container test-container: <nil>
STEP: delete the pod 01/10/23 04:07:15.111
Jan 10 04:07:15.136: INFO: Waiting for pod pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2 to disappear
Jan 10 04:07:15.142: INFO: Pod pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:07:15.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2867" for this suite. 01/10/23 04:07:15.168
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":156,"skipped":2649,"failed":0}
------------------------------
• [4.244 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:07:10.935
    Jan 10 04:07:10.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:07:10.941
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:11.007
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:11.018
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 01/10/23 04:07:11.02
    Jan 10 04:07:11.044: INFO: Waiting up to 5m0s for pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2" in namespace "emptydir-2867" to be "Succeeded or Failed"
    Jan 10 04:07:11.070: INFO: Pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.197632ms
    Jan 10 04:07:13.073: INFO: Pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029303471s
    Jan 10 04:07:15.079: INFO: Pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035320395s
    STEP: Saw pod success 01/10/23 04:07:15.079
    Jan 10 04:07:15.079: INFO: Pod "pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2" satisfied condition "Succeeded or Failed"
    Jan 10 04:07:15.094: INFO: Trying to get logs from node cncf-wk2 pod pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2 container test-container: <nil>
    STEP: delete the pod 01/10/23 04:07:15.111
    Jan 10 04:07:15.136: INFO: Waiting for pod pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2 to disappear
    Jan 10 04:07:15.142: INFO: Pod pod-ab61fe44-efad-4bab-adfe-2d0f268ebde2 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:07:15.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2867" for this suite. 01/10/23 04:07:15.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:07:15.185
Jan 10 04:07:15.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename ingress 01/10/23 04:07:15.186
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:15.218
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:15.24
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 01/10/23 04:07:15.259
STEP: getting /apis/networking.k8s.io 01/10/23 04:07:15.271
STEP: getting /apis/networking.k8s.iov1 01/10/23 04:07:15.273
STEP: creating 01/10/23 04:07:15.275
STEP: getting 01/10/23 04:07:15.334
STEP: listing 01/10/23 04:07:15.337
STEP: watching 01/10/23 04:07:15.34
Jan 10 04:07:15.340: INFO: starting watch
STEP: cluster-wide listing 01/10/23 04:07:15.343
STEP: cluster-wide watching 01/10/23 04:07:15.348
Jan 10 04:07:15.348: INFO: starting watch
STEP: patching 01/10/23 04:07:15.35
STEP: updating 01/10/23 04:07:15.362
Jan 10 04:07:15.371: INFO: waiting for watch events with expected annotations
Jan 10 04:07:15.371: INFO: saw patched and updated annotations
STEP: patching /status 01/10/23 04:07:15.372
STEP: updating /status 01/10/23 04:07:15.376
STEP: get /status 01/10/23 04:07:15.383
STEP: deleting 01/10/23 04:07:15.386
STEP: deleting a collection 01/10/23 04:07:15.396
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Jan 10 04:07:15.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-5640" for this suite. 01/10/23 04:07:15.422
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":157,"skipped":2681,"failed":0}
------------------------------
• [0.247 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:07:15.185
    Jan 10 04:07:15.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename ingress 01/10/23 04:07:15.186
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:15.218
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:15.24
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 01/10/23 04:07:15.259
    STEP: getting /apis/networking.k8s.io 01/10/23 04:07:15.271
    STEP: getting /apis/networking.k8s.iov1 01/10/23 04:07:15.273
    STEP: creating 01/10/23 04:07:15.275
    STEP: getting 01/10/23 04:07:15.334
    STEP: listing 01/10/23 04:07:15.337
    STEP: watching 01/10/23 04:07:15.34
    Jan 10 04:07:15.340: INFO: starting watch
    STEP: cluster-wide listing 01/10/23 04:07:15.343
    STEP: cluster-wide watching 01/10/23 04:07:15.348
    Jan 10 04:07:15.348: INFO: starting watch
    STEP: patching 01/10/23 04:07:15.35
    STEP: updating 01/10/23 04:07:15.362
    Jan 10 04:07:15.371: INFO: waiting for watch events with expected annotations
    Jan 10 04:07:15.371: INFO: saw patched and updated annotations
    STEP: patching /status 01/10/23 04:07:15.372
    STEP: updating /status 01/10/23 04:07:15.376
    STEP: get /status 01/10/23 04:07:15.383
    STEP: deleting 01/10/23 04:07:15.386
    STEP: deleting a collection 01/10/23 04:07:15.396
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Jan 10 04:07:15.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-5640" for this suite. 01/10/23 04:07:15.422
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:07:15.433
Jan 10 04:07:15.433: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:07:15.434
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:15.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:15.496
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-4235 01/10/23 04:07:15.5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[] 01/10/23 04:07:15.525
Jan 10 04:07:15.549: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Jan 10 04:07:16.563: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4235 01/10/23 04:07:16.564
Jan 10 04:07:16.578: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4235" to be "running and ready"
Jan 10 04:07:16.594: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 15.488099ms
Jan 10 04:07:16.594: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:07:18.597: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018383103s
Jan 10 04:07:18.597: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:07:20.603: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.024101709s
Jan 10 04:07:20.603: INFO: The phase of Pod pod1 is Running (Ready = true)
Jan 10 04:07:20.603: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[pod1:[100]] 01/10/23 04:07:20.614
Jan 10 04:07:20.625: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-4235 01/10/23 04:07:20.625
Jan 10 04:07:20.639: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4235" to be "running and ready"
Jan 10 04:07:20.647: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.371281ms
Jan 10 04:07:20.647: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:07:22.655: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.01507845s
Jan 10 04:07:22.655: INFO: The phase of Pod pod2 is Running (Ready = true)
Jan 10 04:07:22.655: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[pod1:[100] pod2:[101]] 01/10/23 04:07:22.66
Jan 10 04:07:22.673: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 01/10/23 04:07:22.673
Jan 10 04:07:22.674: INFO: Creating new exec pod
Jan 10 04:07:22.678: INFO: Waiting up to 5m0s for pod "execpodq8clz" in namespace "services-4235" to be "running"
Jan 10 04:07:22.685: INFO: Pod "execpodq8clz": Phase="Pending", Reason="", readiness=false. Elapsed: 6.645853ms
Jan 10 04:07:24.688: INFO: Pod "execpodq8clz": Phase="Running", Reason="", readiness=true. Elapsed: 2.009756714s
Jan 10 04:07:24.688: INFO: Pod "execpodq8clz" satisfied condition "running"
Jan 10 04:07:25.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4235 exec execpodq8clz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Jan 10 04:07:25.863: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Jan 10 04:07:25.863: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:07:25.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4235 exec execpodq8clz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.122.206 80'
Jan 10 04:07:26.055: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.122.206 80\nConnection to 10.43.122.206 80 port [tcp/http] succeeded!\n"
Jan 10 04:07:26.055: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:07:26.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4235 exec execpodq8clz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Jan 10 04:07:26.205: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Jan 10 04:07:26.205: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:07:26.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4235 exec execpodq8clz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.122.206 81'
Jan 10 04:07:26.413: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.122.206 81\nConnection to 10.43.122.206 81 port [tcp/*] succeeded!\n"
Jan 10 04:07:26.413: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4235 01/10/23 04:07:26.413
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[pod2:[101]] 01/10/23 04:07:26.492
Jan 10 04:07:26.708: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-4235 01/10/23 04:07:26.708
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[] 01/10/23 04:07:26.826
Jan 10 04:07:27.943: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:07:27.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4235" for this suite. 01/10/23 04:07:27.974
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":158,"skipped":2716,"failed":0}
------------------------------
• [SLOW TEST] [12.556 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:07:15.433
    Jan 10 04:07:15.433: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:07:15.434
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:15.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:15.496
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-4235 01/10/23 04:07:15.5
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[] 01/10/23 04:07:15.525
    Jan 10 04:07:15.549: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Jan 10 04:07:16.563: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-4235 01/10/23 04:07:16.564
    Jan 10 04:07:16.578: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4235" to be "running and ready"
    Jan 10 04:07:16.594: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 15.488099ms
    Jan 10 04:07:16.594: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:07:18.597: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018383103s
    Jan 10 04:07:18.597: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:07:20.603: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.024101709s
    Jan 10 04:07:20.603: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jan 10 04:07:20.603: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[pod1:[100]] 01/10/23 04:07:20.614
    Jan 10 04:07:20.625: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-4235 01/10/23 04:07:20.625
    Jan 10 04:07:20.639: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4235" to be "running and ready"
    Jan 10 04:07:20.647: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.371281ms
    Jan 10 04:07:20.647: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:07:22.655: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.01507845s
    Jan 10 04:07:22.655: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jan 10 04:07:22.655: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[pod1:[100] pod2:[101]] 01/10/23 04:07:22.66
    Jan 10 04:07:22.673: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 01/10/23 04:07:22.673
    Jan 10 04:07:22.674: INFO: Creating new exec pod
    Jan 10 04:07:22.678: INFO: Waiting up to 5m0s for pod "execpodq8clz" in namespace "services-4235" to be "running"
    Jan 10 04:07:22.685: INFO: Pod "execpodq8clz": Phase="Pending", Reason="", readiness=false. Elapsed: 6.645853ms
    Jan 10 04:07:24.688: INFO: Pod "execpodq8clz": Phase="Running", Reason="", readiness=true. Elapsed: 2.009756714s
    Jan 10 04:07:24.688: INFO: Pod "execpodq8clz" satisfied condition "running"
    Jan 10 04:07:25.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4235 exec execpodq8clz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Jan 10 04:07:25.863: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Jan 10 04:07:25.863: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:07:25.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4235 exec execpodq8clz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.122.206 80'
    Jan 10 04:07:26.055: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.122.206 80\nConnection to 10.43.122.206 80 port [tcp/http] succeeded!\n"
    Jan 10 04:07:26.055: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:07:26.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4235 exec execpodq8clz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Jan 10 04:07:26.205: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Jan 10 04:07:26.205: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:07:26.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-4235 exec execpodq8clz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.122.206 81'
    Jan 10 04:07:26.413: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.122.206 81\nConnection to 10.43.122.206 81 port [tcp/*] succeeded!\n"
    Jan 10 04:07:26.413: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-4235 01/10/23 04:07:26.413
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[pod2:[101]] 01/10/23 04:07:26.492
    Jan 10 04:07:26.708: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-4235 01/10/23 04:07:26.708
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4235 to expose endpoints map[] 01/10/23 04:07:26.826
    Jan 10 04:07:27.943: INFO: successfully validated that service multi-endpoint-test in namespace services-4235 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:07:27.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4235" for this suite. 01/10/23 04:07:27.974
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:07:27.991
Jan 10 04:07:27.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:07:27.992
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:28.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:28.077
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Jan 10 04:07:28.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/10/23 04:07:30.634
Jan 10 04:07:30.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 --namespace=crd-publish-openapi-5288 create -f -'
Jan 10 04:07:31.576: INFO: stderr: ""
Jan 10 04:07:31.576: INFO: stdout: "e2e-test-crd-publish-openapi-5429-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jan 10 04:07:31.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 --namespace=crd-publish-openapi-5288 delete e2e-test-crd-publish-openapi-5429-crds test-cr'
Jan 10 04:07:31.666: INFO: stderr: ""
Jan 10 04:07:31.666: INFO: stdout: "e2e-test-crd-publish-openapi-5429-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Jan 10 04:07:31.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 --namespace=crd-publish-openapi-5288 apply -f -'
Jan 10 04:07:31.925: INFO: stderr: ""
Jan 10 04:07:31.925: INFO: stdout: "e2e-test-crd-publish-openapi-5429-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jan 10 04:07:31.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 --namespace=crd-publish-openapi-5288 delete e2e-test-crd-publish-openapi-5429-crds test-cr'
Jan 10 04:07:32.009: INFO: stderr: ""
Jan 10 04:07:32.009: INFO: stdout: "e2e-test-crd-publish-openapi-5429-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 01/10/23 04:07:32.009
Jan 10 04:07:32.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 explain e2e-test-crd-publish-openapi-5429-crds'
Jan 10 04:07:32.381: INFO: stderr: ""
Jan 10 04:07:32.381: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5429-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:07:36.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5288" for this suite. 01/10/23 04:07:36.526
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":159,"skipped":2722,"failed":0}
------------------------------
• [SLOW TEST] [8.540 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:07:27.991
    Jan 10 04:07:27.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:07:27.992
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:28.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:28.077
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Jan 10 04:07:28.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/10/23 04:07:30.634
    Jan 10 04:07:30.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 --namespace=crd-publish-openapi-5288 create -f -'
    Jan 10 04:07:31.576: INFO: stderr: ""
    Jan 10 04:07:31.576: INFO: stdout: "e2e-test-crd-publish-openapi-5429-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Jan 10 04:07:31.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 --namespace=crd-publish-openapi-5288 delete e2e-test-crd-publish-openapi-5429-crds test-cr'
    Jan 10 04:07:31.666: INFO: stderr: ""
    Jan 10 04:07:31.666: INFO: stdout: "e2e-test-crd-publish-openapi-5429-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Jan 10 04:07:31.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 --namespace=crd-publish-openapi-5288 apply -f -'
    Jan 10 04:07:31.925: INFO: stderr: ""
    Jan 10 04:07:31.925: INFO: stdout: "e2e-test-crd-publish-openapi-5429-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Jan 10 04:07:31.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 --namespace=crd-publish-openapi-5288 delete e2e-test-crd-publish-openapi-5429-crds test-cr'
    Jan 10 04:07:32.009: INFO: stderr: ""
    Jan 10 04:07:32.009: INFO: stdout: "e2e-test-crd-publish-openapi-5429-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 01/10/23 04:07:32.009
    Jan 10 04:07:32.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-5288 explain e2e-test-crd-publish-openapi-5429-crds'
    Jan 10 04:07:32.381: INFO: stderr: ""
    Jan 10 04:07:32.381: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5429-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:07:36.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5288" for this suite. 01/10/23 04:07:36.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:07:36.535
Jan 10 04:07:36.535: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-webhook 01/10/23 04:07:36.536
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:36.567
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:36.571
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 01/10/23 04:07:36.58
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 01/10/23 04:07:37.065
STEP: Deploying the custom resource conversion webhook pod 01/10/23 04:07:37.076
STEP: Wait for the deployment to be ready 01/10/23 04:07:37.103
Jan 10 04:07:37.121: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Jan 10 04:07:39.136: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 7, 37, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 7, 37, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 7, 37, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 7, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/10/23 04:07:41.14
STEP: Verifying the service has paired with the endpoint 01/10/23 04:07:41.154
Jan 10 04:07:42.155: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Jan 10 04:07:42.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Creating a v1 custom resource 01/10/23 04:07:44.81
STEP: Create a v2 custom resource 01/10/23 04:07:44.826
STEP: List CRs in v1 01/10/23 04:07:44.887
STEP: List CRs in v2 01/10/23 04:07:44.89
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:07:45.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7609" for this suite. 01/10/23 04:07:45.532
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":160,"skipped":2742,"failed":0}
------------------------------
• [SLOW TEST] [9.370 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:07:36.535
    Jan 10 04:07:36.535: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-webhook 01/10/23 04:07:36.536
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:36.567
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:36.571
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 01/10/23 04:07:36.58
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 01/10/23 04:07:37.065
    STEP: Deploying the custom resource conversion webhook pod 01/10/23 04:07:37.076
    STEP: Wait for the deployment to be ready 01/10/23 04:07:37.103
    Jan 10 04:07:37.121: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Jan 10 04:07:39.136: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 7, 37, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 7, 37, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 7, 37, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 7, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/10/23 04:07:41.14
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:07:41.154
    Jan 10 04:07:42.155: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Jan 10 04:07:42.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Creating a v1 custom resource 01/10/23 04:07:44.81
    STEP: Create a v2 custom resource 01/10/23 04:07:44.826
    STEP: List CRs in v1 01/10/23 04:07:44.887
    STEP: List CRs in v2 01/10/23 04:07:44.89
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:07:45.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-7609" for this suite. 01/10/23 04:07:45.532
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:07:45.914
Jan 10 04:07:45.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-probe 01/10/23 04:07:45.916
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:46.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:46.062
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9 in namespace container-probe-9114 01/10/23 04:07:46.077
Jan 10 04:07:46.093: INFO: Waiting up to 5m0s for pod "liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9" in namespace "container-probe-9114" to be "not pending"
Jan 10 04:07:46.109: INFO: Pod "liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.973401ms
Jan 10 04:07:48.119: INFO: Pod "liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9": Phase="Running", Reason="", readiness=true. Elapsed: 2.026331871s
Jan 10 04:07:48.119: INFO: Pod "liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9" satisfied condition "not pending"
Jan 10 04:07:48.119: INFO: Started pod liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9 in namespace container-probe-9114
STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 04:07:48.119
Jan 10 04:07:48.122: INFO: Initial restart count of pod liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9 is 0
STEP: deleting the pod 01/10/23 04:11:48.771
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 10 04:11:48.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9114" for this suite. 01/10/23 04:11:48.791
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":161,"skipped":2795,"failed":0}
------------------------------
• [SLOW TEST] [242.885 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:07:45.914
    Jan 10 04:07:45.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-probe 01/10/23 04:07:45.916
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:07:46.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:07:46.062
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9 in namespace container-probe-9114 01/10/23 04:07:46.077
    Jan 10 04:07:46.093: INFO: Waiting up to 5m0s for pod "liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9" in namespace "container-probe-9114" to be "not pending"
    Jan 10 04:07:46.109: INFO: Pod "liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.973401ms
    Jan 10 04:07:48.119: INFO: Pod "liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9": Phase="Running", Reason="", readiness=true. Elapsed: 2.026331871s
    Jan 10 04:07:48.119: INFO: Pod "liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9" satisfied condition "not pending"
    Jan 10 04:07:48.119: INFO: Started pod liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9 in namespace container-probe-9114
    STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 04:07:48.119
    Jan 10 04:07:48.122: INFO: Initial restart count of pod liveness-213dd7a0-a59d-448d-a32d-8e3e893e0ac9 is 0
    STEP: deleting the pod 01/10/23 04:11:48.771
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 10 04:11:48.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9114" for this suite. 01/10/23 04:11:48.791
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:11:48.806
Jan 10 04:11:48.807: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:11:48.807
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:11:48.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:11:48.842
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-75dc352a-0c6a-487e-a43b-ea57c1460b3a 01/10/23 04:11:48.853
STEP: Creating a pod to test consume secrets 01/10/23 04:11:48.869
Jan 10 04:11:48.882: INFO: Waiting up to 5m0s for pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc" in namespace "secrets-140" to be "Succeeded or Failed"
Jan 10 04:11:48.886: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.242426ms
Jan 10 04:11:50.890: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007026114s
Jan 10 04:11:52.910: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027207497s
Jan 10 04:11:54.892: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008591758s
STEP: Saw pod success 01/10/23 04:11:54.892
Jan 10 04:11:54.892: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc" satisfied condition "Succeeded or Failed"
Jan 10 04:11:54.898: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc container secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:11:54.913
Jan 10 04:11:54.923: INFO: Waiting for pod pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc to disappear
Jan 10 04:11:54.930: INFO: Pod pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:11:54.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-140" for this suite. 01/10/23 04:11:54.938
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":162,"skipped":2824,"failed":0}
------------------------------
• [SLOW TEST] [6.140 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:11:48.806
    Jan 10 04:11:48.807: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:11:48.807
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:11:48.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:11:48.842
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-75dc352a-0c6a-487e-a43b-ea57c1460b3a 01/10/23 04:11:48.853
    STEP: Creating a pod to test consume secrets 01/10/23 04:11:48.869
    Jan 10 04:11:48.882: INFO: Waiting up to 5m0s for pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc" in namespace "secrets-140" to be "Succeeded or Failed"
    Jan 10 04:11:48.886: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.242426ms
    Jan 10 04:11:50.890: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007026114s
    Jan 10 04:11:52.910: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027207497s
    Jan 10 04:11:54.892: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008591758s
    STEP: Saw pod success 01/10/23 04:11:54.892
    Jan 10 04:11:54.892: INFO: Pod "pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc" satisfied condition "Succeeded or Failed"
    Jan 10 04:11:54.898: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc container secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:11:54.913
    Jan 10 04:11:54.923: INFO: Waiting for pod pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc to disappear
    Jan 10 04:11:54.930: INFO: Pod pod-secrets-fb9b7753-3197-49f1-8aed-0cf373b9f5fc no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:11:54.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-140" for this suite. 01/10/23 04:11:54.938
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:11:54.948
Jan 10 04:11:54.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename dns 01/10/23 04:11:54.949
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:11:54.975
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:11:54.98
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 01/10/23 04:11:54.982
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
 01/10/23 04:11:54.997
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
 01/10/23 04:11:54.997
STEP: creating a pod to probe DNS 01/10/23 04:11:54.997
STEP: submitting the pod to kubernetes 01/10/23 04:11:54.997
Jan 10 04:11:55.011: INFO: Waiting up to 15m0s for pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b" in namespace "dns-7178" to be "running"
Jan 10 04:11:55.016: INFO: Pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.670682ms
Jan 10 04:11:57.020: INFO: Pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009357361s
Jan 10 04:11:59.020: INFO: Pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b": Phase="Running", Reason="", readiness=true. Elapsed: 4.008777849s
Jan 10 04:11:59.020: INFO: Pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b" satisfied condition "running"
STEP: retrieving the pod 01/10/23 04:11:59.02
STEP: looking for the results for each expected name from probers 01/10/23 04:11:59.022
Jan 10 04:11:59.028: INFO: DNS probes using dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b succeeded

STEP: deleting the pod 01/10/23 04:11:59.029
STEP: changing the externalName to bar.example.com 01/10/23 04:11:59.038
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
 01/10/23 04:11:59.046
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
 01/10/23 04:11:59.047
STEP: creating a second pod to probe DNS 01/10/23 04:11:59.048
STEP: submitting the pod to kubernetes 01/10/23 04:11:59.048
Jan 10 04:11:59.053: INFO: Waiting up to 15m0s for pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3" in namespace "dns-7178" to be "running"
Jan 10 04:11:59.058: INFO: Pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.325025ms
Jan 10 04:12:01.062: INFO: Pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009686304s
Jan 10 04:12:03.061: INFO: Pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3": Phase="Running", Reason="", readiness=true. Elapsed: 4.008576979s
Jan 10 04:12:03.061: INFO: Pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3" satisfied condition "running"
STEP: retrieving the pod 01/10/23 04:12:03.061
STEP: looking for the results for each expected name from probers 01/10/23 04:12:03.064
Jan 10 04:12:03.078: INFO: DNS probes using dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3 succeeded

STEP: deleting the pod 01/10/23 04:12:03.078
STEP: changing the service to type=ClusterIP 01/10/23 04:12:03.094
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
 01/10/23 04:12:03.115
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
 01/10/23 04:12:03.115
STEP: creating a third pod to probe DNS 01/10/23 04:12:03.115
STEP: submitting the pod to kubernetes 01/10/23 04:12:03.121
Jan 10 04:12:03.144: INFO: Waiting up to 15m0s for pod "dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd" in namespace "dns-7178" to be "running"
Jan 10 04:12:03.163: INFO: Pod "dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.443925ms
Jan 10 04:12:05.168: INFO: Pod "dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd": Phase="Running", Reason="", readiness=true. Elapsed: 2.023357903s
Jan 10 04:12:05.168: INFO: Pod "dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd" satisfied condition "running"
STEP: retrieving the pod 01/10/23 04:12:05.168
STEP: looking for the results for each expected name from probers 01/10/23 04:12:05.171
Jan 10 04:12:05.185: INFO: DNS probes using dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd succeeded

STEP: deleting the pod 01/10/23 04:12:05.185
STEP: deleting the test externalName service 01/10/23 04:12:05.195
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 10 04:12:05.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7178" for this suite. 01/10/23 04:12:05.254
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":163,"skipped":2831,"failed":0}
------------------------------
• [SLOW TEST] [10.321 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:11:54.948
    Jan 10 04:11:54.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename dns 01/10/23 04:11:54.949
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:11:54.975
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:11:54.98
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 01/10/23 04:11:54.982
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
     01/10/23 04:11:54.997
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
     01/10/23 04:11:54.997
    STEP: creating a pod to probe DNS 01/10/23 04:11:54.997
    STEP: submitting the pod to kubernetes 01/10/23 04:11:54.997
    Jan 10 04:11:55.011: INFO: Waiting up to 15m0s for pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b" in namespace "dns-7178" to be "running"
    Jan 10 04:11:55.016: INFO: Pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.670682ms
    Jan 10 04:11:57.020: INFO: Pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009357361s
    Jan 10 04:11:59.020: INFO: Pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b": Phase="Running", Reason="", readiness=true. Elapsed: 4.008777849s
    Jan 10 04:11:59.020: INFO: Pod "dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 04:11:59.02
    STEP: looking for the results for each expected name from probers 01/10/23 04:11:59.022
    Jan 10 04:11:59.028: INFO: DNS probes using dns-test-d948d327-2e4e-4f66-b3c7-29a2309e3e0b succeeded

    STEP: deleting the pod 01/10/23 04:11:59.029
    STEP: changing the externalName to bar.example.com 01/10/23 04:11:59.038
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
     01/10/23 04:11:59.046
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
     01/10/23 04:11:59.047
    STEP: creating a second pod to probe DNS 01/10/23 04:11:59.048
    STEP: submitting the pod to kubernetes 01/10/23 04:11:59.048
    Jan 10 04:11:59.053: INFO: Waiting up to 15m0s for pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3" in namespace "dns-7178" to be "running"
    Jan 10 04:11:59.058: INFO: Pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.325025ms
    Jan 10 04:12:01.062: INFO: Pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009686304s
    Jan 10 04:12:03.061: INFO: Pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3": Phase="Running", Reason="", readiness=true. Elapsed: 4.008576979s
    Jan 10 04:12:03.061: INFO: Pod "dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 04:12:03.061
    STEP: looking for the results for each expected name from probers 01/10/23 04:12:03.064
    Jan 10 04:12:03.078: INFO: DNS probes using dns-test-8e91e94b-535b-46d8-a4d8-b69a8c25a1a3 succeeded

    STEP: deleting the pod 01/10/23 04:12:03.078
    STEP: changing the service to type=ClusterIP 01/10/23 04:12:03.094
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
     01/10/23 04:12:03.115
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7178.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7178.svc.cluster.local; sleep 1; done
     01/10/23 04:12:03.115
    STEP: creating a third pod to probe DNS 01/10/23 04:12:03.115
    STEP: submitting the pod to kubernetes 01/10/23 04:12:03.121
    Jan 10 04:12:03.144: INFO: Waiting up to 15m0s for pod "dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd" in namespace "dns-7178" to be "running"
    Jan 10 04:12:03.163: INFO: Pod "dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.443925ms
    Jan 10 04:12:05.168: INFO: Pod "dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd": Phase="Running", Reason="", readiness=true. Elapsed: 2.023357903s
    Jan 10 04:12:05.168: INFO: Pod "dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 04:12:05.168
    STEP: looking for the results for each expected name from probers 01/10/23 04:12:05.171
    Jan 10 04:12:05.185: INFO: DNS probes using dns-test-30f95be5-ade7-44ed-81b7-7ba0d4eebefd succeeded

    STEP: deleting the pod 01/10/23 04:12:05.185
    STEP: deleting the test externalName service 01/10/23 04:12:05.195
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 10 04:12:05.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7178" for this suite. 01/10/23 04:12:05.254
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:12:05.27
Jan 10 04:12:05.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename aggregator 01/10/23 04:12:05.271
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:12:05.364
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:12:05.389
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Jan 10 04:12:05.394: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 01/10/23 04:12:05.394
Jan 10 04:12:05.975: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jan 10 04:12:08.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:10.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:12.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:14.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:16.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:18.169: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:20.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:22.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:24.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:26.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:28.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:12:30.320: INFO: Waited 116.282913ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 01/10/23 04:12:30.366
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 01/10/23 04:12:30.368
STEP: List APIServices 01/10/23 04:12:30.374
Jan 10 04:12:30.379: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Jan 10 04:12:30.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3516" for this suite. 01/10/23 04:12:30.815
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":164,"skipped":2831,"failed":0}
------------------------------
• [SLOW TEST] [25.593 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:12:05.27
    Jan 10 04:12:05.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename aggregator 01/10/23 04:12:05.271
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:12:05.364
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:12:05.389
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Jan 10 04:12:05.394: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 01/10/23 04:12:05.394
    Jan 10 04:12:05.975: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Jan 10 04:12:08.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:10.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:12.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:14.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:16.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:18.169: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:20.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:22.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:24.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:26.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:28.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 12, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 12, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:12:30.320: INFO: Waited 116.282913ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 01/10/23 04:12:30.366
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 01/10/23 04:12:30.368
    STEP: List APIServices 01/10/23 04:12:30.374
    Jan 10 04:12:30.379: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Jan 10 04:12:30.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-3516" for this suite. 01/10/23 04:12:30.815
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:12:30.864
Jan 10 04:12:30.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 04:12:30.865
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:12:30.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:12:30.994
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 01/10/23 04:12:31.029
STEP: Creating a ResourceQuota 01/10/23 04:12:36.033
STEP: Ensuring resource quota status is calculated 01/10/23 04:12:36.039
STEP: Creating a Service 01/10/23 04:12:38.042
STEP: Creating a NodePort Service 01/10/23 04:12:38.055
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 01/10/23 04:12:38.136
STEP: Ensuring resource quota status captures service creation 01/10/23 04:12:38.246
STEP: Deleting Services 01/10/23 04:12:40.253
STEP: Ensuring resource quota status released usage 01/10/23 04:12:40.323
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 04:12:42.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-30" for this suite. 01/10/23 04:12:42.33
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":165,"skipped":2835,"failed":0}
------------------------------
• [SLOW TEST] [11.469 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:12:30.864
    Jan 10 04:12:30.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 04:12:30.865
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:12:30.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:12:30.994
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 01/10/23 04:12:31.029
    STEP: Creating a ResourceQuota 01/10/23 04:12:36.033
    STEP: Ensuring resource quota status is calculated 01/10/23 04:12:36.039
    STEP: Creating a Service 01/10/23 04:12:38.042
    STEP: Creating a NodePort Service 01/10/23 04:12:38.055
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 01/10/23 04:12:38.136
    STEP: Ensuring resource quota status captures service creation 01/10/23 04:12:38.246
    STEP: Deleting Services 01/10/23 04:12:40.253
    STEP: Ensuring resource quota status released usage 01/10/23 04:12:40.323
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 04:12:42.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-30" for this suite. 01/10/23 04:12:42.33
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:12:42.335
Jan 10 04:12:42.335: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-preemption 01/10/23 04:12:42.336
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:12:42.36
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:12:42.367
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jan 10 04:12:42.393: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 10 04:13:42.428: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 01/10/23 04:13:42.436
Jan 10 04:13:42.482: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jan 10 04:13:42.510: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jan 10 04:13:42.591: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jan 10 04:13:42.618: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Jan 10 04:13:42.675: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Jan 10 04:13:42.687: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 01/10/23 04:13:42.687
Jan 10 04:13:42.687: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4433" to be "running"
Jan 10 04:13:42.720: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 32.767735ms
Jan 10 04:13:44.726: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038725263s
Jan 10 04:13:46.725: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.038586477s
Jan 10 04:13:46.726: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Jan 10 04:13:46.726: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
Jan 10 04:13:46.728: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.304554ms
Jan 10 04:13:46.728: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Jan 10 04:13:46.728: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
Jan 10 04:13:46.730: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 1.902648ms
Jan 10 04:13:48.739: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.01071258s
Jan 10 04:13:48.739: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Jan 10 04:13:48.739: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
Jan 10 04:13:48.741: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.388572ms
Jan 10 04:13:48.742: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Jan 10 04:13:48.742: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
Jan 10 04:13:48.751: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.749362ms
Jan 10 04:13:50.754: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012508788s
Jan 10 04:13:52.754: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.01246322s
Jan 10 04:13:52.754: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Jan 10 04:13:52.754: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
Jan 10 04:13:52.757: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.278367ms
Jan 10 04:13:52.757: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 01/10/23 04:13:52.757
Jan 10 04:13:52.761: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4433" to be "running"
Jan 10 04:13:52.764: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.381828ms
Jan 10 04:13:54.768: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006253571s
Jan 10 04:13:56.768: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006169702s
Jan 10 04:13:58.773: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011287923s
Jan 10 04:14:00.772: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.010065253s
Jan 10 04:14:00.772: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:14:00.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4433" for this suite. 01/10/23 04:14:00.801
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":166,"skipped":2846,"failed":0}
------------------------------
• [SLOW TEST] [78.677 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:12:42.335
    Jan 10 04:12:42.335: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-preemption 01/10/23 04:12:42.336
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:12:42.36
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:12:42.367
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jan 10 04:12:42.393: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 10 04:13:42.428: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 01/10/23 04:13:42.436
    Jan 10 04:13:42.482: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Jan 10 04:13:42.510: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Jan 10 04:13:42.591: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Jan 10 04:13:42.618: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Jan 10 04:13:42.675: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Jan 10 04:13:42.687: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 01/10/23 04:13:42.687
    Jan 10 04:13:42.687: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4433" to be "running"
    Jan 10 04:13:42.720: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 32.767735ms
    Jan 10 04:13:44.726: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038725263s
    Jan 10 04:13:46.725: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.038586477s
    Jan 10 04:13:46.726: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Jan 10 04:13:46.726: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
    Jan 10 04:13:46.728: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.304554ms
    Jan 10 04:13:46.728: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Jan 10 04:13:46.728: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
    Jan 10 04:13:46.730: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 1.902648ms
    Jan 10 04:13:48.739: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.01071258s
    Jan 10 04:13:48.739: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Jan 10 04:13:48.739: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
    Jan 10 04:13:48.741: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.388572ms
    Jan 10 04:13:48.742: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Jan 10 04:13:48.742: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
    Jan 10 04:13:48.751: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.749362ms
    Jan 10 04:13:50.754: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012508788s
    Jan 10 04:13:52.754: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.01246322s
    Jan 10 04:13:52.754: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Jan 10 04:13:52.754: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4433" to be "running"
    Jan 10 04:13:52.757: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.278367ms
    Jan 10 04:13:52.757: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 01/10/23 04:13:52.757
    Jan 10 04:13:52.761: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4433" to be "running"
    Jan 10 04:13:52.764: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.381828ms
    Jan 10 04:13:54.768: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006253571s
    Jan 10 04:13:56.768: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006169702s
    Jan 10 04:13:58.773: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011287923s
    Jan 10 04:14:00.772: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.010065253s
    Jan 10 04:14:00.772: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:14:00.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4433" for this suite. 01/10/23 04:14:00.801
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:01.015
Jan 10 04:14:01.015: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename dns 01/10/23 04:14:01.021
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:01.042
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:01.046
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 01/10/23 04:14:01.056
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 01/10/23 04:14:01.056
STEP: creating a pod to probe DNS 01/10/23 04:14:01.056
STEP: submitting the pod to kubernetes 01/10/23 04:14:01.057
Jan 10 04:14:01.068: INFO: Waiting up to 15m0s for pod "dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5" in namespace "dns-3290" to be "running"
Jan 10 04:14:01.084: INFO: Pod "dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.836692ms
Jan 10 04:14:03.088: INFO: Pod "dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.020914262s
Jan 10 04:14:03.089: INFO: Pod "dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5" satisfied condition "running"
STEP: retrieving the pod 01/10/23 04:14:03.089
STEP: looking for the results for each expected name from probers 01/10/23 04:14:03.092
Jan 10 04:14:03.113: INFO: DNS probes using dns-3290/dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5 succeeded

STEP: deleting the pod 01/10/23 04:14:03.113
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 10 04:14:03.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3290" for this suite. 01/10/23 04:14:03.144
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":167,"skipped":2884,"failed":0}
------------------------------
• [2.144 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:01.015
    Jan 10 04:14:01.015: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename dns 01/10/23 04:14:01.021
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:01.042
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:01.046
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     01/10/23 04:14:01.056
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     01/10/23 04:14:01.056
    STEP: creating a pod to probe DNS 01/10/23 04:14:01.056
    STEP: submitting the pod to kubernetes 01/10/23 04:14:01.057
    Jan 10 04:14:01.068: INFO: Waiting up to 15m0s for pod "dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5" in namespace "dns-3290" to be "running"
    Jan 10 04:14:01.084: INFO: Pod "dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.836692ms
    Jan 10 04:14:03.088: INFO: Pod "dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.020914262s
    Jan 10 04:14:03.089: INFO: Pod "dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 04:14:03.089
    STEP: looking for the results for each expected name from probers 01/10/23 04:14:03.092
    Jan 10 04:14:03.113: INFO: DNS probes using dns-3290/dns-test-d7c34685-0b97-491a-8fd4-7aa3249597f5 succeeded

    STEP: deleting the pod 01/10/23 04:14:03.113
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 10 04:14:03.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3290" for this suite. 01/10/23 04:14:03.144
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:03.16
Jan 10 04:14:03.161: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename proxy 01/10/23 04:14:03.161
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:03.244
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:03.254
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Jan 10 04:14:03.267: INFO: Creating pod...
Jan 10 04:14:03.285: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2413" to be "running"
Jan 10 04:14:03.299: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 14.273491ms
Jan 10 04:14:05.303: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.0182824s
Jan 10 04:14:05.303: INFO: Pod "agnhost" satisfied condition "running"
Jan 10 04:14:05.303: INFO: Creating service...
Jan 10 04:14:05.330: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/DELETE
Jan 10 04:14:05.356: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jan 10 04:14:05.356: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/GET
Jan 10 04:14:05.362: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jan 10 04:14:05.362: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/HEAD
Jan 10 04:14:05.373: INFO: http.Client request:HEAD | StatusCode:200
Jan 10 04:14:05.373: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/OPTIONS
Jan 10 04:14:05.389: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jan 10 04:14:05.390: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/PATCH
Jan 10 04:14:05.399: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jan 10 04:14:05.399: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/POST
Jan 10 04:14:05.403: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jan 10 04:14:05.403: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/PUT
Jan 10 04:14:05.421: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jan 10 04:14:05.421: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/DELETE
Jan 10 04:14:05.431: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jan 10 04:14:05.431: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/GET
Jan 10 04:14:05.441: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jan 10 04:14:05.441: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/HEAD
Jan 10 04:14:05.448: INFO: http.Client request:HEAD | StatusCode:200
Jan 10 04:14:05.449: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/OPTIONS
Jan 10 04:14:05.455: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jan 10 04:14:05.456: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/PATCH
Jan 10 04:14:05.462: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jan 10 04:14:05.462: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/POST
Jan 10 04:14:05.467: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jan 10 04:14:05.468: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/PUT
Jan 10 04:14:05.473: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jan 10 04:14:05.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2413" for this suite. 01/10/23 04:14:05.478
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":168,"skipped":2890,"failed":0}
------------------------------
• [2.333 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:03.16
    Jan 10 04:14:03.161: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename proxy 01/10/23 04:14:03.161
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:03.244
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:03.254
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Jan 10 04:14:03.267: INFO: Creating pod...
    Jan 10 04:14:03.285: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2413" to be "running"
    Jan 10 04:14:03.299: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 14.273491ms
    Jan 10 04:14:05.303: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.0182824s
    Jan 10 04:14:05.303: INFO: Pod "agnhost" satisfied condition "running"
    Jan 10 04:14:05.303: INFO: Creating service...
    Jan 10 04:14:05.330: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/DELETE
    Jan 10 04:14:05.356: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jan 10 04:14:05.356: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/GET
    Jan 10 04:14:05.362: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Jan 10 04:14:05.362: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/HEAD
    Jan 10 04:14:05.373: INFO: http.Client request:HEAD | StatusCode:200
    Jan 10 04:14:05.373: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/OPTIONS
    Jan 10 04:14:05.389: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jan 10 04:14:05.390: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/PATCH
    Jan 10 04:14:05.399: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jan 10 04:14:05.399: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/POST
    Jan 10 04:14:05.403: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jan 10 04:14:05.403: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/pods/agnhost/proxy/some/path/with/PUT
    Jan 10 04:14:05.421: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jan 10 04:14:05.421: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/DELETE
    Jan 10 04:14:05.431: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jan 10 04:14:05.431: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/GET
    Jan 10 04:14:05.441: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Jan 10 04:14:05.441: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/HEAD
    Jan 10 04:14:05.448: INFO: http.Client request:HEAD | StatusCode:200
    Jan 10 04:14:05.449: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/OPTIONS
    Jan 10 04:14:05.455: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jan 10 04:14:05.456: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/PATCH
    Jan 10 04:14:05.462: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jan 10 04:14:05.462: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/POST
    Jan 10 04:14:05.467: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jan 10 04:14:05.468: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2413/services/test-service/proxy/some/path/with/PUT
    Jan 10 04:14:05.473: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jan 10 04:14:05.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-2413" for this suite. 01/10/23 04:14:05.478
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:05.499
Jan 10 04:14:05.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:14:05.5
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:05.585
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:05.632
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:14:05.692
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:14:06.054
STEP: Deploying the webhook pod 01/10/23 04:14:06.083
STEP: Wait for the deployment to be ready 01/10/23 04:14:06.123
Jan 10 04:14:06.174: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 04:14:08.197
STEP: Verifying the service has paired with the endpoint 01/10/23 04:14:08.214
Jan 10 04:14:09.215: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 01/10/23 04:14:09.219
STEP: create a configmap that should be updated by the webhook 01/10/23 04:14:09.236
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:14:09.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8192" for this suite. 01/10/23 04:14:09.26
STEP: Destroying namespace "webhook-8192-markers" for this suite. 01/10/23 04:14:09.279
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":169,"skipped":2945,"failed":0}
------------------------------
• [3.883 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:05.499
    Jan 10 04:14:05.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:14:05.5
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:05.585
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:05.632
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:14:05.692
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:14:06.054
    STEP: Deploying the webhook pod 01/10/23 04:14:06.083
    STEP: Wait for the deployment to be ready 01/10/23 04:14:06.123
    Jan 10 04:14:06.174: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 04:14:08.197
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:14:08.214
    Jan 10 04:14:09.215: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 01/10/23 04:14:09.219
    STEP: create a configmap that should be updated by the webhook 01/10/23 04:14:09.236
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:14:09.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8192" for this suite. 01/10/23 04:14:09.26
    STEP: Destroying namespace "webhook-8192-markers" for this suite. 01/10/23 04:14:09.279
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:09.397
Jan 10 04:14:09.397: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replicaset 01/10/23 04:14:09.398
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:09.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:09.495
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 01/10/23 04:14:09.498
Jan 10 04:14:09.509: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 10 04:14:14.520: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/10/23 04:14:14.52
STEP: getting scale subresource 01/10/23 04:14:14.52
STEP: updating a scale subresource 01/10/23 04:14:14.528
STEP: verifying the replicaset Spec.Replicas was modified 01/10/23 04:14:14.542
STEP: Patch a scale subresource 01/10/23 04:14:14.57
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 10 04:14:14.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2172" for this suite. 01/10/23 04:14:14.655
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":170,"skipped":2963,"failed":0}
------------------------------
• [SLOW TEST] [5.284 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:09.397
    Jan 10 04:14:09.397: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replicaset 01/10/23 04:14:09.398
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:09.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:09.495
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 01/10/23 04:14:09.498
    Jan 10 04:14:09.509: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jan 10 04:14:14.520: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/10/23 04:14:14.52
    STEP: getting scale subresource 01/10/23 04:14:14.52
    STEP: updating a scale subresource 01/10/23 04:14:14.528
    STEP: verifying the replicaset Spec.Replicas was modified 01/10/23 04:14:14.542
    STEP: Patch a scale subresource 01/10/23 04:14:14.57
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 10 04:14:14.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2172" for this suite. 01/10/23 04:14:14.655
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:14.683
Jan 10 04:14:14.684: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename watch 01/10/23 04:14:14.684
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:14.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:14.781
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 01/10/23 04:14:14.784
STEP: creating a new configmap 01/10/23 04:14:14.786
STEP: modifying the configmap once 01/10/23 04:14:14.805
STEP: closing the watch once it receives two notifications 01/10/23 04:14:14.833
Jan 10 04:14:14.833: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9603  5ea03a63-b5f8-4103-a889-ff409ac2ee76 228054 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:14:14.835: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9603  5ea03a63-b5f8-4103-a889-ff409ac2ee76 228056 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 01/10/23 04:14:14.835
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 01/10/23 04:14:14.851
STEP: deleting the configmap 01/10/23 04:14:14.86
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 01/10/23 04:14:14.867
Jan 10 04:14:14.868: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9603  5ea03a63-b5f8-4103-a889-ff409ac2ee76 228058 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:14:14.868: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9603  5ea03a63-b5f8-4103-a889-ff409ac2ee76 228060 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 10 04:14:14.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9603" for this suite. 01/10/23 04:14:14.877
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":171,"skipped":2968,"failed":0}
------------------------------
• [0.211 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:14.683
    Jan 10 04:14:14.684: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename watch 01/10/23 04:14:14.684
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:14.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:14.781
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 01/10/23 04:14:14.784
    STEP: creating a new configmap 01/10/23 04:14:14.786
    STEP: modifying the configmap once 01/10/23 04:14:14.805
    STEP: closing the watch once it receives two notifications 01/10/23 04:14:14.833
    Jan 10 04:14:14.833: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9603  5ea03a63-b5f8-4103-a889-ff409ac2ee76 228054 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:14:14.835: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9603  5ea03a63-b5f8-4103-a889-ff409ac2ee76 228056 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 01/10/23 04:14:14.835
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 01/10/23 04:14:14.851
    STEP: deleting the configmap 01/10/23 04:14:14.86
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 01/10/23 04:14:14.867
    Jan 10 04:14:14.868: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9603  5ea03a63-b5f8-4103-a889-ff409ac2ee76 228058 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:14:14.868: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9603  5ea03a63-b5f8-4103-a889-ff409ac2ee76 228060 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 10 04:14:14.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9603" for this suite. 01/10/23 04:14:14.877
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:14.901
Jan 10 04:14:14.901: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename watch 01/10/23 04:14:14.902
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:14.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:14.971
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 01/10/23 04:14:14.989
STEP: modifying the configmap once 01/10/23 04:14:15.003
STEP: modifying the configmap a second time 01/10/23 04:14:15.022
STEP: deleting the configmap 01/10/23 04:14:15.039
STEP: creating a watch on configmaps from the resource version returned by the first update 01/10/23 04:14:15.051
STEP: Expecting to observe notifications for all changes to the configmap after the first update 01/10/23 04:14:15.057
Jan 10 04:14:15.057: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6198  cb60db32-ee50-4b4d-87ce-ce094a50aed1 228078 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:15 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:14:15.057: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6198  cb60db32-ee50-4b4d-87ce-ce094a50aed1 228079 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:15 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 10 04:14:15.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6198" for this suite. 01/10/23 04:14:15.064
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":172,"skipped":2975,"failed":0}
------------------------------
• [0.197 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:14.901
    Jan 10 04:14:14.901: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename watch 01/10/23 04:14:14.902
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:14.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:14.971
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 01/10/23 04:14:14.989
    STEP: modifying the configmap once 01/10/23 04:14:15.003
    STEP: modifying the configmap a second time 01/10/23 04:14:15.022
    STEP: deleting the configmap 01/10/23 04:14:15.039
    STEP: creating a watch on configmaps from the resource version returned by the first update 01/10/23 04:14:15.051
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 01/10/23 04:14:15.057
    Jan 10 04:14:15.057: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6198  cb60db32-ee50-4b4d-87ce-ce094a50aed1 228078 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:15 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:14:15.057: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6198  cb60db32-ee50-4b4d-87ce-ce094a50aed1 228079 0 2023-01-10 04:14:14 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-01-10 04:14:15 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 10 04:14:15.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-6198" for this suite. 01/10/23 04:14:15.064
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:15.119
Jan 10 04:14:15.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:14:15.126
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:15.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:15.17
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Jan 10 04:14:15.175: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/10/23 04:14:19.088
Jan 10 04:14:19.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 create -f -'
Jan 10 04:14:20.749: INFO: stderr: ""
Jan 10 04:14:20.749: INFO: stdout: "e2e-test-crd-publish-openapi-2317-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jan 10 04:14:20.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 delete e2e-test-crd-publish-openapi-2317-crds test-cr'
Jan 10 04:14:20.829: INFO: stderr: ""
Jan 10 04:14:20.829: INFO: stdout: "e2e-test-crd-publish-openapi-2317-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Jan 10 04:14:20.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 apply -f -'
Jan 10 04:14:21.219: INFO: stderr: ""
Jan 10 04:14:21.219: INFO: stdout: "e2e-test-crd-publish-openapi-2317-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jan 10 04:14:21.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 delete e2e-test-crd-publish-openapi-2317-crds test-cr'
Jan 10 04:14:21.306: INFO: stderr: ""
Jan 10 04:14:21.306: INFO: stdout: "e2e-test-crd-publish-openapi-2317-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 01/10/23 04:14:21.306
Jan 10 04:14:21.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 explain e2e-test-crd-publish-openapi-2317-crds'
Jan 10 04:14:21.696: INFO: stderr: ""
Jan 10 04:14:21.696: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2317-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:14:24.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-393" for this suite. 01/10/23 04:14:24.196
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":173,"skipped":2984,"failed":0}
------------------------------
• [SLOW TEST] [9.082 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:15.119
    Jan 10 04:14:15.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:14:15.126
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:15.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:15.17
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Jan 10 04:14:15.175: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/10/23 04:14:19.088
    Jan 10 04:14:19.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 create -f -'
    Jan 10 04:14:20.749: INFO: stderr: ""
    Jan 10 04:14:20.749: INFO: stdout: "e2e-test-crd-publish-openapi-2317-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Jan 10 04:14:20.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 delete e2e-test-crd-publish-openapi-2317-crds test-cr'
    Jan 10 04:14:20.829: INFO: stderr: ""
    Jan 10 04:14:20.829: INFO: stdout: "e2e-test-crd-publish-openapi-2317-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Jan 10 04:14:20.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 apply -f -'
    Jan 10 04:14:21.219: INFO: stderr: ""
    Jan 10 04:14:21.219: INFO: stdout: "e2e-test-crd-publish-openapi-2317-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Jan 10 04:14:21.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 delete e2e-test-crd-publish-openapi-2317-crds test-cr'
    Jan 10 04:14:21.306: INFO: stderr: ""
    Jan 10 04:14:21.306: INFO: stdout: "e2e-test-crd-publish-openapi-2317-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 01/10/23 04:14:21.306
    Jan 10 04:14:21.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-393 explain e2e-test-crd-publish-openapi-2317-crds'
    Jan 10 04:14:21.696: INFO: stderr: ""
    Jan 10 04:14:21.696: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2317-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:14:24.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-393" for this suite. 01/10/23 04:14:24.196
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:24.202
Jan 10 04:14:24.202: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:14:24.203
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:24.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:24.238
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 01/10/23 04:14:24.241
Jan 10 04:14:24.248: INFO: Waiting up to 5m0s for pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc" in namespace "emptydir-1580" to be "Succeeded or Failed"
Jan 10 04:14:24.261: INFO: Pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.291831ms
Jan 10 04:14:26.265: INFO: Pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016498948s
Jan 10 04:14:28.265: INFO: Pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016476547s
STEP: Saw pod success 01/10/23 04:14:28.265
Jan 10 04:14:28.265: INFO: Pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc" satisfied condition "Succeeded or Failed"
Jan 10 04:14:28.274: INFO: Trying to get logs from node cncf-wk2 pod pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc container test-container: <nil>
STEP: delete the pod 01/10/23 04:14:28.289
Jan 10 04:14:28.302: INFO: Waiting for pod pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc to disappear
Jan 10 04:14:28.312: INFO: Pod pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:14:28.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1580" for this suite. 01/10/23 04:14:28.315
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":174,"skipped":2991,"failed":0}
------------------------------
• [4.119 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:24.202
    Jan 10 04:14:24.202: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:14:24.203
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:24.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:24.238
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 01/10/23 04:14:24.241
    Jan 10 04:14:24.248: INFO: Waiting up to 5m0s for pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc" in namespace "emptydir-1580" to be "Succeeded or Failed"
    Jan 10 04:14:24.261: INFO: Pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.291831ms
    Jan 10 04:14:26.265: INFO: Pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016498948s
    Jan 10 04:14:28.265: INFO: Pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016476547s
    STEP: Saw pod success 01/10/23 04:14:28.265
    Jan 10 04:14:28.265: INFO: Pod "pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc" satisfied condition "Succeeded or Failed"
    Jan 10 04:14:28.274: INFO: Trying to get logs from node cncf-wk2 pod pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc container test-container: <nil>
    STEP: delete the pod 01/10/23 04:14:28.289
    Jan 10 04:14:28.302: INFO: Waiting for pod pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc to disappear
    Jan 10 04:14:28.312: INFO: Pod pod-958c82fb-3e76-4e26-ad5b-4d8606f2a2cc no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:14:28.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1580" for this suite. 01/10/23 04:14:28.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:28.326
Jan 10 04:14:28.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename daemonsets 01/10/23 04:14:28.326
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:28.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:28.358
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Jan 10 04:14:28.433: INFO: Create a RollingUpdate DaemonSet
Jan 10 04:14:28.442: INFO: Check that daemon pods launch on every node of the cluster
Jan 10 04:14:28.459: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:14:28.459: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:14:29.515: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:14:29.515: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:14:30.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 10 04:14:30.468: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:14:31.471: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 04:14:31.471: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Jan 10 04:14:31.471: INFO: Update the DaemonSet to trigger a rollout
Jan 10 04:14:31.484: INFO: Updating DaemonSet daemon-set
Jan 10 04:14:34.508: INFO: Roll back the DaemonSet before rollout is complete
Jan 10 04:14:34.531: INFO: Updating DaemonSet daemon-set
Jan 10 04:14:34.531: INFO: Make sure DaemonSet rollback is complete
Jan 10 04:14:37.571: INFO: Pod daemon-set-5579t is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/10/23 04:14:37.58
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2815, will wait for the garbage collector to delete the pods 01/10/23 04:14:37.58
Jan 10 04:14:37.637: INFO: Deleting DaemonSet.extensions daemon-set took: 3.702232ms
Jan 10 04:14:37.737: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.61742ms
Jan 10 04:14:39.841: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:14:39.841: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 10 04:14:39.843: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"228369"},"items":null}

Jan 10 04:14:39.846: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"228369"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:14:39.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2815" for this suite. 01/10/23 04:14:39.859
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":175,"skipped":3012,"failed":0}
------------------------------
• [SLOW TEST] [11.540 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:28.326
    Jan 10 04:14:28.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename daemonsets 01/10/23 04:14:28.326
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:28.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:28.358
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Jan 10 04:14:28.433: INFO: Create a RollingUpdate DaemonSet
    Jan 10 04:14:28.442: INFO: Check that daemon pods launch on every node of the cluster
    Jan 10 04:14:28.459: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:14:28.459: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:14:29.515: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:14:29.515: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:14:30.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 10 04:14:30.468: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:14:31.471: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 04:14:31.471: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Jan 10 04:14:31.471: INFO: Update the DaemonSet to trigger a rollout
    Jan 10 04:14:31.484: INFO: Updating DaemonSet daemon-set
    Jan 10 04:14:34.508: INFO: Roll back the DaemonSet before rollout is complete
    Jan 10 04:14:34.531: INFO: Updating DaemonSet daemon-set
    Jan 10 04:14:34.531: INFO: Make sure DaemonSet rollback is complete
    Jan 10 04:14:37.571: INFO: Pod daemon-set-5579t is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/10/23 04:14:37.58
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2815, will wait for the garbage collector to delete the pods 01/10/23 04:14:37.58
    Jan 10 04:14:37.637: INFO: Deleting DaemonSet.extensions daemon-set took: 3.702232ms
    Jan 10 04:14:37.737: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.61742ms
    Jan 10 04:14:39.841: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:14:39.841: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 10 04:14:39.843: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"228369"},"items":null}

    Jan 10 04:14:39.846: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"228369"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:14:39.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2815" for this suite. 01/10/23 04:14:39.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:39.867
Jan 10 04:14:39.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename init-container 01/10/23 04:14:39.868
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:39.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:39.905
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 01/10/23 04:14:39.913
Jan 10 04:14:39.913: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 10 04:14:45.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9654" for this suite. 01/10/23 04:14:45.354
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":176,"skipped":3023,"failed":0}
------------------------------
• [SLOW TEST] [5.495 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:39.867
    Jan 10 04:14:39.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename init-container 01/10/23 04:14:39.868
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:39.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:39.905
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 01/10/23 04:14:39.913
    Jan 10 04:14:39.913: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 10 04:14:45.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9654" for this suite. 01/10/23 04:14:45.354
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:14:45.364
Jan 10 04:14:45.364: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:14:45.365
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:45.412
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:45.421
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 01/10/23 04:14:45.437
Jan 10 04:14:45.437: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:14:49.413: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:15:05.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3642" for this suite. 01/10/23 04:15:05.548
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":177,"skipped":3023,"failed":0}
------------------------------
• [SLOW TEST] [20.191 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:14:45.364
    Jan 10 04:14:45.364: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:14:45.365
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:14:45.412
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:14:45.421
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 01/10/23 04:14:45.437
    Jan 10 04:14:45.437: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:14:49.413: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:15:05.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3642" for this suite. 01/10/23 04:15:05.548
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:05.557
Jan 10 04:15:05.557: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename events 01/10/23 04:15:05.558
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:05.589
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:05.592
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 01/10/23 04:15:05.597
STEP: listing events in all namespaces 01/10/23 04:15:05.612
STEP: listing events in test namespace 01/10/23 04:15:05.616
STEP: listing events with field selection filtering on source 01/10/23 04:15:05.622
STEP: listing events with field selection filtering on reportingController 01/10/23 04:15:05.628
STEP: getting the test event 01/10/23 04:15:05.631
STEP: patching the test event 01/10/23 04:15:05.633
STEP: getting the test event 01/10/23 04:15:05.65
STEP: updating the test event 01/10/23 04:15:05.653
STEP: getting the test event 01/10/23 04:15:05.659
STEP: deleting the test event 01/10/23 04:15:05.663
STEP: listing events in all namespaces 01/10/23 04:15:05.672
STEP: listing events in test namespace 01/10/23 04:15:05.675
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Jan 10 04:15:05.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6033" for this suite. 01/10/23 04:15:05.694
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":178,"skipped":3040,"failed":0}
------------------------------
• [0.142 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:05.557
    Jan 10 04:15:05.557: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename events 01/10/23 04:15:05.558
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:05.589
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:05.592
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 01/10/23 04:15:05.597
    STEP: listing events in all namespaces 01/10/23 04:15:05.612
    STEP: listing events in test namespace 01/10/23 04:15:05.616
    STEP: listing events with field selection filtering on source 01/10/23 04:15:05.622
    STEP: listing events with field selection filtering on reportingController 01/10/23 04:15:05.628
    STEP: getting the test event 01/10/23 04:15:05.631
    STEP: patching the test event 01/10/23 04:15:05.633
    STEP: getting the test event 01/10/23 04:15:05.65
    STEP: updating the test event 01/10/23 04:15:05.653
    STEP: getting the test event 01/10/23 04:15:05.659
    STEP: deleting the test event 01/10/23 04:15:05.663
    STEP: listing events in all namespaces 01/10/23 04:15:05.672
    STEP: listing events in test namespace 01/10/23 04:15:05.675
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Jan 10 04:15:05.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6033" for this suite. 01/10/23 04:15:05.694
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:05.7
Jan 10 04:15:05.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replication-controller 01/10/23 04:15:05.702
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:05.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:05.761
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 01/10/23 04:15:05.764
Jan 10 04:15:05.783: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-4728" to be "running and ready"
Jan 10 04:15:05.796: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 12.724885ms
Jan 10 04:15:05.796: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:15:07.800: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.016904192s
Jan 10 04:15:07.800: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Jan 10 04:15:07.800: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 01/10/23 04:15:07.803
STEP: Then the orphan pod is adopted 01/10/23 04:15:07.81
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 10 04:15:08.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4728" for this suite. 01/10/23 04:15:08.822
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":179,"skipped":3071,"failed":0}
------------------------------
• [3.131 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:05.7
    Jan 10 04:15:05.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replication-controller 01/10/23 04:15:05.702
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:05.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:05.761
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 01/10/23 04:15:05.764
    Jan 10 04:15:05.783: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-4728" to be "running and ready"
    Jan 10 04:15:05.796: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 12.724885ms
    Jan 10 04:15:05.796: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:15:07.800: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.016904192s
    Jan 10 04:15:07.800: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Jan 10 04:15:07.800: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 01/10/23 04:15:07.803
    STEP: Then the orphan pod is adopted 01/10/23 04:15:07.81
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 10 04:15:08.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4728" for this suite. 01/10/23 04:15:08.822
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:08.832
Jan 10 04:15:08.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:15:08.833
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:08.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:08.874
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 01/10/23 04:15:08.882
Jan 10 04:15:08.900: INFO: Waiting up to 5m0s for pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120" in namespace "emptydir-5719" to be "Succeeded or Failed"
Jan 10 04:15:08.908: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120": Phase="Pending", Reason="", readiness=false. Elapsed: 8.167722ms
Jan 10 04:15:10.912: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012468739s
Jan 10 04:15:12.913: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013080192s
Jan 10 04:15:14.920: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020497612s
STEP: Saw pod success 01/10/23 04:15:14.92
Jan 10 04:15:14.920: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120" satisfied condition "Succeeded or Failed"
Jan 10 04:15:14.928: INFO: Trying to get logs from node cncf-wk2 pod pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120 container test-container: <nil>
STEP: delete the pod 01/10/23 04:15:14.942
Jan 10 04:15:14.953: INFO: Waiting for pod pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120 to disappear
Jan 10 04:15:14.957: INFO: Pod pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:15:14.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5719" for this suite. 01/10/23 04:15:14.963
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":180,"skipped":3074,"failed":0}
------------------------------
• [SLOW TEST] [6.134 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:08.832
    Jan 10 04:15:08.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:15:08.833
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:08.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:08.874
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 01/10/23 04:15:08.882
    Jan 10 04:15:08.900: INFO: Waiting up to 5m0s for pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120" in namespace "emptydir-5719" to be "Succeeded or Failed"
    Jan 10 04:15:08.908: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120": Phase="Pending", Reason="", readiness=false. Elapsed: 8.167722ms
    Jan 10 04:15:10.912: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012468739s
    Jan 10 04:15:12.913: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013080192s
    Jan 10 04:15:14.920: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020497612s
    STEP: Saw pod success 01/10/23 04:15:14.92
    Jan 10 04:15:14.920: INFO: Pod "pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120" satisfied condition "Succeeded or Failed"
    Jan 10 04:15:14.928: INFO: Trying to get logs from node cncf-wk2 pod pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120 container test-container: <nil>
    STEP: delete the pod 01/10/23 04:15:14.942
    Jan 10 04:15:14.953: INFO: Waiting for pod pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120 to disappear
    Jan 10 04:15:14.957: INFO: Pod pod-7f22660f-7a4c-45b4-8d55-e56c4b30a120 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:15:14.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5719" for this suite. 01/10/23 04:15:14.963
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:14.969
Jan 10 04:15:14.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename dns 01/10/23 04:15:14.97
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:14.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:14.995
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 01/10/23 04:15:15.017
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6081.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6081.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 39.80.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.80.39_udp@PTR;check="$$(dig +tcp +noall +answer +search 39.80.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.80.39_tcp@PTR;sleep 1; done
 01/10/23 04:15:15.064
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6081.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6081.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 39.80.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.80.39_udp@PTR;check="$$(dig +tcp +noall +answer +search 39.80.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.80.39_tcp@PTR;sleep 1; done
 01/10/23 04:15:15.064
STEP: creating a pod to probe DNS 01/10/23 04:15:15.065
STEP: submitting the pod to kubernetes 01/10/23 04:15:15.065
Jan 10 04:15:15.113: INFO: Waiting up to 15m0s for pod "dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6" in namespace "dns-6081" to be "running"
Jan 10 04:15:15.132: INFO: Pod "dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 19.068283ms
Jan 10 04:15:17.140: INFO: Pod "dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6": Phase="Running", Reason="", readiness=true. Elapsed: 2.026856718s
Jan 10 04:15:17.140: INFO: Pod "dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6" satisfied condition "running"
STEP: retrieving the pod 01/10/23 04:15:17.14
STEP: looking for the results for each expected name from probers 01/10/23 04:15:17.144
Jan 10 04:15:17.148: INFO: Unable to read wheezy_udp@dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
Jan 10 04:15:17.151: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
Jan 10 04:15:17.154: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
Jan 10 04:15:17.156: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
Jan 10 04:15:17.169: INFO: Unable to read jessie_udp@dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
Jan 10 04:15:17.171: INFO: Unable to read jessie_tcp@dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
Jan 10 04:15:17.173: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
Jan 10 04:15:17.175: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
Jan 10 04:15:17.184: INFO: Lookups using dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6 failed for: [wheezy_udp@dns-test-service.dns-6081.svc.cluster.local wheezy_tcp@dns-test-service.dns-6081.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local jessie_udp@dns-test-service.dns-6081.svc.cluster.local jessie_tcp@dns-test-service.dns-6081.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local]

Jan 10 04:15:22.234: INFO: DNS probes using dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6 succeeded

STEP: deleting the pod 01/10/23 04:15:22.235
STEP: deleting the test service 01/10/23 04:15:22.267
STEP: deleting the test headless service 01/10/23 04:15:22.336
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 10 04:15:22.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6081" for this suite. 01/10/23 04:15:22.428
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":181,"skipped":3095,"failed":0}
------------------------------
• [SLOW TEST] [7.507 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:14.969
    Jan 10 04:15:14.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename dns 01/10/23 04:15:14.97
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:14.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:14.995
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 01/10/23 04:15:15.017
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6081.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6081.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 39.80.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.80.39_udp@PTR;check="$$(dig +tcp +noall +answer +search 39.80.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.80.39_tcp@PTR;sleep 1; done
     01/10/23 04:15:15.064
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6081.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6081.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6081.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6081.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6081.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 39.80.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.80.39_udp@PTR;check="$$(dig +tcp +noall +answer +search 39.80.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.80.39_tcp@PTR;sleep 1; done
     01/10/23 04:15:15.064
    STEP: creating a pod to probe DNS 01/10/23 04:15:15.065
    STEP: submitting the pod to kubernetes 01/10/23 04:15:15.065
    Jan 10 04:15:15.113: INFO: Waiting up to 15m0s for pod "dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6" in namespace "dns-6081" to be "running"
    Jan 10 04:15:15.132: INFO: Pod "dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 19.068283ms
    Jan 10 04:15:17.140: INFO: Pod "dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6": Phase="Running", Reason="", readiness=true. Elapsed: 2.026856718s
    Jan 10 04:15:17.140: INFO: Pod "dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 04:15:17.14
    STEP: looking for the results for each expected name from probers 01/10/23 04:15:17.144
    Jan 10 04:15:17.148: INFO: Unable to read wheezy_udp@dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
    Jan 10 04:15:17.151: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
    Jan 10 04:15:17.154: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
    Jan 10 04:15:17.156: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
    Jan 10 04:15:17.169: INFO: Unable to read jessie_udp@dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
    Jan 10 04:15:17.171: INFO: Unable to read jessie_tcp@dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
    Jan 10 04:15:17.173: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
    Jan 10 04:15:17.175: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local from pod dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6: the server could not find the requested resource (get pods dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6)
    Jan 10 04:15:17.184: INFO: Lookups using dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6 failed for: [wheezy_udp@dns-test-service.dns-6081.svc.cluster.local wheezy_tcp@dns-test-service.dns-6081.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local jessie_udp@dns-test-service.dns-6081.svc.cluster.local jessie_tcp@dns-test-service.dns-6081.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6081.svc.cluster.local]

    Jan 10 04:15:22.234: INFO: DNS probes using dns-6081/dns-test-25d9b329-4fa1-4733-a2f9-94e5ddb0b1a6 succeeded

    STEP: deleting the pod 01/10/23 04:15:22.235
    STEP: deleting the test service 01/10/23 04:15:22.267
    STEP: deleting the test headless service 01/10/23 04:15:22.336
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 10 04:15:22.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6081" for this suite. 01/10/23 04:15:22.428
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:22.478
Jan 10 04:15:22.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename daemonsets 01/10/23 04:15:22.479
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:22.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:22.578
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 01/10/23 04:15:22.702
STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:15:22.71
Jan 10 04:15:22.727: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:15:22.727: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:15:23.791: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:15:23.791: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:15:24.733: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 04:15:24.733: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
Jan 10 04:15:25.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 04:15:25.743: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 01/10/23 04:15:25.75
Jan 10 04:15:25.788: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 04:15:25.788: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 01/10/23 04:15:25.788
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/10/23 04:15:25.795
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7727, will wait for the garbage collector to delete the pods 01/10/23 04:15:25.795
Jan 10 04:15:25.902: INFO: Deleting DaemonSet.extensions daemon-set took: 45.000085ms
Jan 10 04:15:26.103: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.102292ms
Jan 10 04:15:29.006: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:15:29.006: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 10 04:15:29.019: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"228887"},"items":null}

Jan 10 04:15:29.021: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"228887"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:15:29.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7727" for this suite. 01/10/23 04:15:29.064
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":182,"skipped":3098,"failed":0}
------------------------------
• [SLOW TEST] [6.595 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:22.478
    Jan 10 04:15:22.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename daemonsets 01/10/23 04:15:22.479
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:22.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:22.578
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 01/10/23 04:15:22.702
    STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:15:22.71
    Jan 10 04:15:22.727: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:15:22.727: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:15:23.791: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:15:23.791: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:15:24.733: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 04:15:24.733: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
    Jan 10 04:15:25.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 04:15:25.743: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 01/10/23 04:15:25.75
    Jan 10 04:15:25.788: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 04:15:25.788: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 01/10/23 04:15:25.788
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/10/23 04:15:25.795
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7727, will wait for the garbage collector to delete the pods 01/10/23 04:15:25.795
    Jan 10 04:15:25.902: INFO: Deleting DaemonSet.extensions daemon-set took: 45.000085ms
    Jan 10 04:15:26.103: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.102292ms
    Jan 10 04:15:29.006: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:15:29.006: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 10 04:15:29.019: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"228887"},"items":null}

    Jan 10 04:15:29.021: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"228887"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:15:29.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7727" for this suite. 01/10/23 04:15:29.064
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:29.08
Jan 10 04:15:29.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:15:29.081
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:29.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:29.165
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 01/10/23 04:15:29.176
Jan 10 04:15:29.238: INFO: Waiting up to 5m0s for pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889" in namespace "emptydir-7376" to be "Succeeded or Failed"
Jan 10 04:15:29.241: INFO: Pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298307ms
Jan 10 04:15:31.245: INFO: Pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006327525s
Jan 10 04:15:33.245: INFO: Pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006791137s
STEP: Saw pod success 01/10/23 04:15:33.245
Jan 10 04:15:33.245: INFO: Pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889" satisfied condition "Succeeded or Failed"
Jan 10 04:15:33.248: INFO: Trying to get logs from node cncf-wk2 pod pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889 container test-container: <nil>
STEP: delete the pod 01/10/23 04:15:33.255
Jan 10 04:15:33.267: INFO: Waiting for pod pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889 to disappear
Jan 10 04:15:33.273: INFO: Pod pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:15:33.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7376" for this suite. 01/10/23 04:15:33.277
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":183,"skipped":3147,"failed":0}
------------------------------
• [4.207 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:29.08
    Jan 10 04:15:29.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:15:29.081
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:29.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:29.165
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 01/10/23 04:15:29.176
    Jan 10 04:15:29.238: INFO: Waiting up to 5m0s for pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889" in namespace "emptydir-7376" to be "Succeeded or Failed"
    Jan 10 04:15:29.241: INFO: Pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298307ms
    Jan 10 04:15:31.245: INFO: Pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006327525s
    Jan 10 04:15:33.245: INFO: Pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006791137s
    STEP: Saw pod success 01/10/23 04:15:33.245
    Jan 10 04:15:33.245: INFO: Pod "pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889" satisfied condition "Succeeded or Failed"
    Jan 10 04:15:33.248: INFO: Trying to get logs from node cncf-wk2 pod pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889 container test-container: <nil>
    STEP: delete the pod 01/10/23 04:15:33.255
    Jan 10 04:15:33.267: INFO: Waiting for pod pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889 to disappear
    Jan 10 04:15:33.273: INFO: Pod pod-fa34dfa6-4cd2-4ef5-a923-f868992f9889 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:15:33.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7376" for this suite. 01/10/23 04:15:33.277
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:33.288
Jan 10 04:15:33.288: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename svcaccounts 01/10/23 04:15:33.288
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:33.33
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:33.339
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Jan 10 04:15:33.382: INFO: created pod pod-service-account-defaultsa
Jan 10 04:15:33.382: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 10 04:15:33.408: INFO: created pod pod-service-account-mountsa
Jan 10 04:15:33.408: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 10 04:15:33.426: INFO: created pod pod-service-account-nomountsa
Jan 10 04:15:33.426: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 10 04:15:33.477: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 10 04:15:33.477: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 10 04:15:33.592: INFO: created pod pod-service-account-mountsa-mountspec
Jan 10 04:15:33.598: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 10 04:15:33.669: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 10 04:15:33.669: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 10 04:15:33.690: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 10 04:15:33.690: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 10 04:15:33.703: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 10 04:15:33.703: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 10 04:15:33.722: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 10 04:15:33.722: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 10 04:15:33.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7804" for this suite. 01/10/23 04:15:33.736
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":184,"skipped":3148,"failed":0}
------------------------------
• [0.464 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:33.288
    Jan 10 04:15:33.288: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename svcaccounts 01/10/23 04:15:33.288
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:33.33
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:33.339
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Jan 10 04:15:33.382: INFO: created pod pod-service-account-defaultsa
    Jan 10 04:15:33.382: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Jan 10 04:15:33.408: INFO: created pod pod-service-account-mountsa
    Jan 10 04:15:33.408: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Jan 10 04:15:33.426: INFO: created pod pod-service-account-nomountsa
    Jan 10 04:15:33.426: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Jan 10 04:15:33.477: INFO: created pod pod-service-account-defaultsa-mountspec
    Jan 10 04:15:33.477: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Jan 10 04:15:33.592: INFO: created pod pod-service-account-mountsa-mountspec
    Jan 10 04:15:33.598: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Jan 10 04:15:33.669: INFO: created pod pod-service-account-nomountsa-mountspec
    Jan 10 04:15:33.669: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Jan 10 04:15:33.690: INFO: created pod pod-service-account-defaultsa-nomountspec
    Jan 10 04:15:33.690: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Jan 10 04:15:33.703: INFO: created pod pod-service-account-mountsa-nomountspec
    Jan 10 04:15:33.703: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Jan 10 04:15:33.722: INFO: created pod pod-service-account-nomountsa-nomountspec
    Jan 10 04:15:33.722: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 10 04:15:33.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7804" for this suite. 01/10/23 04:15:33.736
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:33.754
Jan 10 04:15:33.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename deployment 01/10/23 04:15:33.755
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:33.795
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:33.802
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Jan 10 04:15:33.823: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 10 04:15:38.833: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/10/23 04:15:38.834
Jan 10 04:15:38.835: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 10 04:15:40.840: INFO: Creating deployment "test-rollover-deployment"
Jan 10 04:15:40.849: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 10 04:15:42.856: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 10 04:15:42.861: INFO: Ensure that both replica sets have 1 created replica
Jan 10 04:15:42.865: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 10 04:15:42.872: INFO: Updating deployment test-rollover-deployment
Jan 10 04:15:42.872: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 10 04:15:44.880: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 10 04:15:44.889: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 10 04:15:44.900: INFO: all replica sets need to contain the pod-template-hash label
Jan 10 04:15:44.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:15:46.906: INFO: all replica sets need to contain the pod-template-hash label
Jan 10 04:15:46.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:15:48.907: INFO: all replica sets need to contain the pod-template-hash label
Jan 10 04:15:48.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:15:50.907: INFO: all replica sets need to contain the pod-template-hash label
Jan 10 04:15:50.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:15:52.909: INFO: all replica sets need to contain the pod-template-hash label
Jan 10 04:15:52.909: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 04:15:54.923: INFO: 
Jan 10 04:15:54.923: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 10 04:15:54.941: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5156  753bb748-3919-48ce-9066-6fecae63bd49 229220 2 2023-01-10 04:15:40 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005d22b78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-10 04:15:40 +0000 UTC,LastTransitionTime:2023-01-10 04:15:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-01-10 04:15:54 +0000 UTC,LastTransitionTime:2023-01-10 04:15:40 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jan 10 04:15:54.953: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-5156  ff67adb8-d967-4b9a-b6cb-ee4e6488908f 229210 2 2023-01-10 04:15:42 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 753bb748-3919-48ce-9066-6fecae63bd49 0xc005d52157 0xc005d52158}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"753bb748-3919-48ce-9066-6fecae63bd49\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005d52218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:15:54.953: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 10 04:15:54.953: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5156  c067abc5-c19b-467a-a00f-8ffecaf1398f 229219 2 2023-01-10 04:15:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 753bb748-3919-48ce-9066-6fecae63bd49 0xc005cf7da7 0xc005cf7da8}] [] [{e2e.test Update apps/v1 2023-01-10 04:15:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"753bb748-3919-48ce-9066-6fecae63bd49\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:54 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005cf7f08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:15:54.953: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-5156  ebe0fa1e-d6b7-481e-a18f-93c66c5dc387 229147 2 2023-01-10 04:15:40 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 753bb748-3919-48ce-9066-6fecae63bd49 0xc005cf7fb7 0xc005cf7fb8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"753bb748-3919-48ce-9066-6fecae63bd49\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005d520e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:15:54.957: INFO: Pod "test-rollover-deployment-6d45fd857b-ctkwn" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-ctkwn test-rollover-deployment-6d45fd857b- deployment-5156  a11c4077-1d48-4470-9aba-4d2d6a39436b 229169 0 2023-01-10 04:15:42 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:b8b21e804aba030b4ac84f2b51465cf0ef3acb5c090fb0233cb92b4a55e6a1a8 cni.projectcalico.org/podIP:10.42.1.214/32 cni.projectcalico.org/podIPs:10.42.1.214/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b ff67adb8-d967-4b9a-b6cb-ee4e6488908f 0xc005d23137 0xc005d23138}] [] [{kube-controller-manager Update v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff67adb8-d967-4b9a-b6cb-ee4e6488908f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:15:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:15:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.214\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6vw76,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6vw76,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:15:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:15:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:15:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:15:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.214,StartTime:2023-01-10 04:15:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:15:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:docker://63d8507d66cd6d76c161272d5d0aaf31016d53063c81211a9bbaae563a596aca,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.214,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 10 04:15:54.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5156" for this suite. 01/10/23 04:15:54.96
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":185,"skipped":3172,"failed":0}
------------------------------
• [SLOW TEST] [21.212 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:33.754
    Jan 10 04:15:33.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename deployment 01/10/23 04:15:33.755
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:33.795
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:33.802
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Jan 10 04:15:33.823: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Jan 10 04:15:38.833: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/10/23 04:15:38.834
    Jan 10 04:15:38.835: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Jan 10 04:15:40.840: INFO: Creating deployment "test-rollover-deployment"
    Jan 10 04:15:40.849: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Jan 10 04:15:42.856: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Jan 10 04:15:42.861: INFO: Ensure that both replica sets have 1 created replica
    Jan 10 04:15:42.865: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Jan 10 04:15:42.872: INFO: Updating deployment test-rollover-deployment
    Jan 10 04:15:42.872: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Jan 10 04:15:44.880: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Jan 10 04:15:44.889: INFO: Make sure deployment "test-rollover-deployment" is complete
    Jan 10 04:15:44.900: INFO: all replica sets need to contain the pod-template-hash label
    Jan 10 04:15:44.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:15:46.906: INFO: all replica sets need to contain the pod-template-hash label
    Jan 10 04:15:46.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:15:48.907: INFO: all replica sets need to contain the pod-template-hash label
    Jan 10 04:15:48.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:15:50.907: INFO: all replica sets need to contain the pod-template-hash label
    Jan 10 04:15:50.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:15:52.909: INFO: all replica sets need to contain the pod-template-hash label
    Jan 10 04:15:52.909: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 15, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 10 04:15:54.923: INFO: 
    Jan 10 04:15:54.923: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 10 04:15:54.941: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-5156  753bb748-3919-48ce-9066-6fecae63bd49 229220 2 2023-01-10 04:15:40 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005d22b78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-10 04:15:40 +0000 UTC,LastTransitionTime:2023-01-10 04:15:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-01-10 04:15:54 +0000 UTC,LastTransitionTime:2023-01-10 04:15:40 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jan 10 04:15:54.953: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-5156  ff67adb8-d967-4b9a-b6cb-ee4e6488908f 229210 2 2023-01-10 04:15:42 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 753bb748-3919-48ce-9066-6fecae63bd49 0xc005d52157 0xc005d52158}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"753bb748-3919-48ce-9066-6fecae63bd49\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005d52218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:15:54.953: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Jan 10 04:15:54.953: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5156  c067abc5-c19b-467a-a00f-8ffecaf1398f 229219 2 2023-01-10 04:15:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 753bb748-3919-48ce-9066-6fecae63bd49 0xc005cf7da7 0xc005cf7da8}] [] [{e2e.test Update apps/v1 2023-01-10 04:15:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"753bb748-3919-48ce-9066-6fecae63bd49\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:54 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005cf7f08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:15:54.953: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-5156  ebe0fa1e-d6b7-481e-a18f-93c66c5dc387 229147 2 2023-01-10 04:15:40 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 753bb748-3919-48ce-9066-6fecae63bd49 0xc005cf7fb7 0xc005cf7fb8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"753bb748-3919-48ce-9066-6fecae63bd49\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005d520e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:15:54.957: INFO: Pod "test-rollover-deployment-6d45fd857b-ctkwn" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-ctkwn test-rollover-deployment-6d45fd857b- deployment-5156  a11c4077-1d48-4470-9aba-4d2d6a39436b 229169 0 2023-01-10 04:15:42 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:b8b21e804aba030b4ac84f2b51465cf0ef3acb5c090fb0233cb92b4a55e6a1a8 cni.projectcalico.org/podIP:10.42.1.214/32 cni.projectcalico.org/podIPs:10.42.1.214/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b ff67adb8-d967-4b9a-b6cb-ee4e6488908f 0xc005d23137 0xc005d23138}] [] [{kube-controller-manager Update v1 2023-01-10 04:15:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff67adb8-d967-4b9a-b6cb-ee4e6488908f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:15:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:15:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.214\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6vw76,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6vw76,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:15:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:15:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:15:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:15:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.214,StartTime:2023-01-10 04:15:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:15:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:docker://63d8507d66cd6d76c161272d5d0aaf31016d53063c81211a9bbaae563a596aca,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.214,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 10 04:15:54.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5156" for this suite. 01/10/23 04:15:54.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:54.969
Jan 10 04:15:54.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename podtemplate 01/10/23 04:15:54.97
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:55.014
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:55.032
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 01/10/23 04:15:55.045
STEP: Replace a pod template 01/10/23 04:15:55.055
Jan 10 04:15:55.071: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jan 10 04:15:55.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7725" for this suite. 01/10/23 04:15:55.082
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":186,"skipped":3210,"failed":0}
------------------------------
• [0.131 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:54.969
    Jan 10 04:15:54.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename podtemplate 01/10/23 04:15:54.97
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:55.014
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:55.032
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 01/10/23 04:15:55.045
    STEP: Replace a pod template 01/10/23 04:15:55.055
    Jan 10 04:15:55.071: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jan 10 04:15:55.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-7725" for this suite. 01/10/23 04:15:55.082
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:55.104
Jan 10 04:15:55.104: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:15:55.104
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:55.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:55.195
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-827170f9-e7cf-407a-9641-7ff5f2240f46 01/10/23 04:15:55.199
STEP: Creating a pod to test consume configMaps 01/10/23 04:15:55.202
Jan 10 04:15:55.214: INFO: Waiting up to 5m0s for pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356" in namespace "configmap-519" to be "Succeeded or Failed"
Jan 10 04:15:55.222: INFO: Pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356": Phase="Pending", Reason="", readiness=false. Elapsed: 7.945299ms
Jan 10 04:15:57.237: INFO: Pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0223198s
Jan 10 04:15:59.226: INFO: Pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011784245s
STEP: Saw pod success 01/10/23 04:15:59.226
Jan 10 04:15:59.226: INFO: Pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356" satisfied condition "Succeeded or Failed"
Jan 10 04:15:59.228: INFO: Trying to get logs from node cncf-wk3 pod pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:15:59.245
Jan 10 04:15:59.255: INFO: Waiting for pod pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356 to disappear
Jan 10 04:15:59.258: INFO: Pod pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:15:59.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-519" for this suite. 01/10/23 04:15:59.262
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":187,"skipped":3235,"failed":0}
------------------------------
• [4.162 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:55.104
    Jan 10 04:15:55.104: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:15:55.104
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:55.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:55.195
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-827170f9-e7cf-407a-9641-7ff5f2240f46 01/10/23 04:15:55.199
    STEP: Creating a pod to test consume configMaps 01/10/23 04:15:55.202
    Jan 10 04:15:55.214: INFO: Waiting up to 5m0s for pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356" in namespace "configmap-519" to be "Succeeded or Failed"
    Jan 10 04:15:55.222: INFO: Pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356": Phase="Pending", Reason="", readiness=false. Elapsed: 7.945299ms
    Jan 10 04:15:57.237: INFO: Pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0223198s
    Jan 10 04:15:59.226: INFO: Pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011784245s
    STEP: Saw pod success 01/10/23 04:15:59.226
    Jan 10 04:15:59.226: INFO: Pod "pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356" satisfied condition "Succeeded or Failed"
    Jan 10 04:15:59.228: INFO: Trying to get logs from node cncf-wk3 pod pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:15:59.245
    Jan 10 04:15:59.255: INFO: Waiting for pod pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356 to disappear
    Jan 10 04:15:59.258: INFO: Pod pod-configmaps-8bc33295-84ae-43e6-b8ba-269711ea7356 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:15:59.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-519" for this suite. 01/10/23 04:15:59.262
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:15:59.271
Jan 10 04:15:59.272: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename deployment 01/10/23 04:15:59.272
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:59.352
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:59.357
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 01/10/23 04:15:59.378
STEP: waiting for Deployment to be created 01/10/23 04:15:59.385
STEP: waiting for all Replicas to be Ready 01/10/23 04:15:59.386
Jan 10 04:15:59.390: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 10 04:15:59.390: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 10 04:15:59.400: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 10 04:15:59.400: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 10 04:15:59.500: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 10 04:15:59.500: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 10 04:15:59.626: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 10 04:15:59.626: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 10 04:16:01.083: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jan 10 04:16:01.084: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jan 10 04:16:01.699: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 01/10/23 04:16:01.699
W0110 04:16:01.706101      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jan 10 04:16:01.708: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 01/10/23 04:16:01.708
Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:01.728: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:01.728: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:01.754: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:01.754: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:01.766: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:01.766: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:01.791: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:01.791: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:03.768: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:03.768: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:03.794: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
STEP: listing Deployments 01/10/23 04:16:03.794
Jan 10 04:16:03.798: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 01/10/23 04:16:03.798
Jan 10 04:16:03.816: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 01/10/23 04:16:03.816
Jan 10 04:16:03.846: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:03.847: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:03.905: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:04.106: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:04.179: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:05.200: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:05.848: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:05.895: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:05.920: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jan 10 04:16:07.209: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 01/10/23 04:16:07.259
STEP: fetching the DeploymentStatus 01/10/23 04:16:07.266
Jan 10 04:16:07.271: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:07.271: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:07.271: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:07.271: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 3
Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 3
STEP: deleting the Deployment 01/10/23 04:16:07.272
Jan 10 04:16:07.282: INFO: observed event type MODIFIED
Jan 10 04:16:07.283: INFO: observed event type MODIFIED
Jan 10 04:16:07.283: INFO: observed event type MODIFIED
Jan 10 04:16:07.283: INFO: observed event type MODIFIED
Jan 10 04:16:07.284: INFO: observed event type MODIFIED
Jan 10 04:16:07.284: INFO: observed event type MODIFIED
Jan 10 04:16:07.284: INFO: observed event type MODIFIED
Jan 10 04:16:07.284: INFO: observed event type MODIFIED
Jan 10 04:16:07.284: INFO: observed event type MODIFIED
Jan 10 04:16:07.284: INFO: observed event type MODIFIED
Jan 10 04:16:07.284: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 10 04:16:07.287: INFO: Log out all the ReplicaSets if there is no deployment created
Jan 10 04:16:07.292: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-9879  c04e23d1-3a47-4471-beb1-fa3abc820660 229506 4 2023-01-10 04:16:01 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 2172e222-4e84-4cd3-abc6-6a71d56e8f0e 0xc0026bf367 0xc0026bf368}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2172e222-4e84-4cd3-abc6-6a71d56e8f0e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:07 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026bf520 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Jan 10 04:16:07.302: INFO: pod: "test-deployment-54cc775c4b-lbbwd":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-lbbwd test-deployment-54cc775c4b- deployment-9879  bd0d74d4-adbb-4a18-aad0-eb4afd99caa5 229502 0 2023-01-10 04:16:03 +0000 UTC 2023-01-10 04:16:08 +0000 UTC 0xc004f40888 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:5fcb660e9bdc1cdabc300bf3d008024ae43d6da0e104962f3ae6543fe2f7c175 cni.projectcalico.org/podIP:10.42.2.113/32 cni.projectcalico.org/podIPs:10.42.2.113/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b c04e23d1-3a47-4471-beb1-fa3abc820660 0xc004f408f7 0xc004f408f8}] [] [{kube-controller-manager Update v1 2023-01-10 04:16:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c04e23d1-3a47-4471-beb1-fa3abc820660\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:16:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:16:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8k9bp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8k9bp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.113,StartTime:2023-01-10 04:16:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:16:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:docker-pullable://registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:docker://0000c400f887483fe6d8e923dba9b379c4a7fbf158e829afe3e3b3cdf93a6e93,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jan 10 04:16:07.302: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-9879  40fea364-6c6e-48d3-88b5-62fa5ebb72f7 229498 2 2023-01-10 04:16:03 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 2172e222-4e84-4cd3-abc6-6a71d56e8f0e 0xc0026bf5f7 0xc0026bf5f8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2172e222-4e84-4cd3-abc6-6a71d56e8f0e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:07 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026bf730 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Jan 10 04:16:07.319: INFO: pod: "test-deployment-7c7d8d58c8-mjlzx":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-mjlzx test-deployment-7c7d8d58c8- deployment-9879  898e780e-99d8-43db-9abb-afe4cdb00888 229512 0 2023-01-10 04:16:03 +0000 UTC 2023-01-10 04:16:08 +0000 UTC 0xc004f9e3a8 map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:97a7662a987b1b16bda861eb35eb81bf35eee9180b212c48d99511ff28d77090 cni.projectcalico.org/podIP:10.42.1.217/32 cni.projectcalico.org/podIPs:10.42.1.217/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 40fea364-6c6e-48d3-88b5-62fa5ebb72f7 0xc004f9e4c7 0xc004f9e4c8}] [] [{kube-controller-manager Update v1 2023-01-10 04:16:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"40fea364-6c6e-48d3-88b5-62fa5ebb72f7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:16:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:16:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.217\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2qvzz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2qvzz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.217,StartTime:2023-01-10 04:16:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:16:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://656fcaa87dcfd381407c202f483472bc303a683609d3701e2be7b2b459d12d32,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.217,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jan 10 04:16:07.320: INFO: pod: "test-deployment-7c7d8d58c8-pfkr4":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-pfkr4 test-deployment-7c7d8d58c8- deployment-9879  e7811a5d-7672-42c9-b48e-899526f47e1e 229513 0 2023-01-10 04:16:05 +0000 UTC 2023-01-10 04:16:08 +0000 UTC 0xc004f9e890 map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:e00a707df254f1cbfc49b1005a6622ce0274c618afb1fff914ab6d155e675ee6 cni.projectcalico.org/podIP:10.42.2.114/32 cni.projectcalico.org/podIPs:10.42.2.114/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 40fea364-6c6e-48d3-88b5-62fa5ebb72f7 0xc004f9e907 0xc004f9e908}] [] [{kube-controller-manager Update v1 2023-01-10 04:16:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"40fea364-6c6e-48d3-88b5-62fa5ebb72f7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:16:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:16:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.114\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kc7fh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kc7fh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.114,StartTime:2023-01-10 04:16:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:16:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://f5547e94ea85dfc0f439d5558bae51dda72e04e47d7e0bd84f040940b67c81f0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.114,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jan 10 04:16:07.326: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-9879  777e5aa1-3185-41a9-8fe9-e428168e2e08 229406 3 2023-01-10 04:15:59 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 2172e222-4e84-4cd3-abc6-6a71d56e8f0e 0xc0026bf7c7 0xc0026bf7c8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2172e222-4e84-4cd3-abc6-6a71d56e8f0e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026bfa30 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 10 04:16:07.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9879" for this suite. 01/10/23 04:16:07.345
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":188,"skipped":3258,"failed":0}
------------------------------
• [SLOW TEST] [8.081 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:15:59.271
    Jan 10 04:15:59.272: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename deployment 01/10/23 04:15:59.272
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:15:59.352
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:15:59.357
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 01/10/23 04:15:59.378
    STEP: waiting for Deployment to be created 01/10/23 04:15:59.385
    STEP: waiting for all Replicas to be Ready 01/10/23 04:15:59.386
    Jan 10 04:15:59.390: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 10 04:15:59.390: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 10 04:15:59.400: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 10 04:15:59.400: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 10 04:15:59.500: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 10 04:15:59.500: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 10 04:15:59.626: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 10 04:15:59.626: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 10 04:16:01.083: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Jan 10 04:16:01.084: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Jan 10 04:16:01.699: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 01/10/23 04:16:01.699
    W0110 04:16:01.706101      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jan 10 04:16:01.708: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 01/10/23 04:16:01.708
    Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
    Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
    Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
    Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
    Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
    Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
    Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
    Jan 10 04:16:01.711: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 0
    Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:01.712: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:01.728: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:01.728: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:01.754: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:01.754: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:01.766: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:01.766: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:01.791: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:01.791: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:03.768: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:03.768: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:03.794: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    STEP: listing Deployments 01/10/23 04:16:03.794
    Jan 10 04:16:03.798: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 01/10/23 04:16:03.798
    Jan 10 04:16:03.816: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 01/10/23 04:16:03.816
    Jan 10 04:16:03.846: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:03.847: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:03.905: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:04.106: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:04.179: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:05.200: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:05.848: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:05.895: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:05.920: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 10 04:16:07.209: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 01/10/23 04:16:07.259
    STEP: fetching the DeploymentStatus 01/10/23 04:16:07.266
    Jan 10 04:16:07.271: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:07.271: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:07.271: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:07.271: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 1
    Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 3
    Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 2
    Jan 10 04:16:07.272: INFO: observed Deployment test-deployment in namespace deployment-9879 with ReadyReplicas 3
    STEP: deleting the Deployment 01/10/23 04:16:07.272
    Jan 10 04:16:07.282: INFO: observed event type MODIFIED
    Jan 10 04:16:07.283: INFO: observed event type MODIFIED
    Jan 10 04:16:07.283: INFO: observed event type MODIFIED
    Jan 10 04:16:07.283: INFO: observed event type MODIFIED
    Jan 10 04:16:07.284: INFO: observed event type MODIFIED
    Jan 10 04:16:07.284: INFO: observed event type MODIFIED
    Jan 10 04:16:07.284: INFO: observed event type MODIFIED
    Jan 10 04:16:07.284: INFO: observed event type MODIFIED
    Jan 10 04:16:07.284: INFO: observed event type MODIFIED
    Jan 10 04:16:07.284: INFO: observed event type MODIFIED
    Jan 10 04:16:07.284: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 10 04:16:07.287: INFO: Log out all the ReplicaSets if there is no deployment created
    Jan 10 04:16:07.292: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-9879  c04e23d1-3a47-4471-beb1-fa3abc820660 229506 4 2023-01-10 04:16:01 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 2172e222-4e84-4cd3-abc6-6a71d56e8f0e 0xc0026bf367 0xc0026bf368}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2172e222-4e84-4cd3-abc6-6a71d56e8f0e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:07 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026bf520 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Jan 10 04:16:07.302: INFO: pod: "test-deployment-54cc775c4b-lbbwd":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-lbbwd test-deployment-54cc775c4b- deployment-9879  bd0d74d4-adbb-4a18-aad0-eb4afd99caa5 229502 0 2023-01-10 04:16:03 +0000 UTC 2023-01-10 04:16:08 +0000 UTC 0xc004f40888 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:5fcb660e9bdc1cdabc300bf3d008024ae43d6da0e104962f3ae6543fe2f7c175 cni.projectcalico.org/podIP:10.42.2.113/32 cni.projectcalico.org/podIPs:10.42.2.113/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b c04e23d1-3a47-4471-beb1-fa3abc820660 0xc004f408f7 0xc004f408f8}] [] [{kube-controller-manager Update v1 2023-01-10 04:16:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c04e23d1-3a47-4471-beb1-fa3abc820660\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:16:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:16:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8k9bp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8k9bp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.113,StartTime:2023-01-10 04:16:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:16:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:docker-pullable://registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:docker://0000c400f887483fe6d8e923dba9b379c4a7fbf158e829afe3e3b3cdf93a6e93,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jan 10 04:16:07.302: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-9879  40fea364-6c6e-48d3-88b5-62fa5ebb72f7 229498 2 2023-01-10 04:16:03 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 2172e222-4e84-4cd3-abc6-6a71d56e8f0e 0xc0026bf5f7 0xc0026bf5f8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2172e222-4e84-4cd3-abc6-6a71d56e8f0e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:07 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026bf730 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Jan 10 04:16:07.319: INFO: pod: "test-deployment-7c7d8d58c8-mjlzx":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-mjlzx test-deployment-7c7d8d58c8- deployment-9879  898e780e-99d8-43db-9abb-afe4cdb00888 229512 0 2023-01-10 04:16:03 +0000 UTC 2023-01-10 04:16:08 +0000 UTC 0xc004f9e3a8 map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:97a7662a987b1b16bda861eb35eb81bf35eee9180b212c48d99511ff28d77090 cni.projectcalico.org/podIP:10.42.1.217/32 cni.projectcalico.org/podIPs:10.42.1.217/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 40fea364-6c6e-48d3-88b5-62fa5ebb72f7 0xc004f9e4c7 0xc004f9e4c8}] [] [{kube-controller-manager Update v1 2023-01-10 04:16:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"40fea364-6c6e-48d3-88b5-62fa5ebb72f7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:16:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:16:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.217\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2qvzz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2qvzz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.217,StartTime:2023-01-10 04:16:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:16:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://656fcaa87dcfd381407c202f483472bc303a683609d3701e2be7b2b459d12d32,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.217,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jan 10 04:16:07.320: INFO: pod: "test-deployment-7c7d8d58c8-pfkr4":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-pfkr4 test-deployment-7c7d8d58c8- deployment-9879  e7811a5d-7672-42c9-b48e-899526f47e1e 229513 0 2023-01-10 04:16:05 +0000 UTC 2023-01-10 04:16:08 +0000 UTC 0xc004f9e890 map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:e00a707df254f1cbfc49b1005a6622ce0274c618afb1fff914ab6d155e675ee6 cni.projectcalico.org/podIP:10.42.2.114/32 cni.projectcalico.org/podIPs:10.42.2.114/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 40fea364-6c6e-48d3-88b5-62fa5ebb72f7 0xc004f9e907 0xc004f9e908}] [] [{kube-controller-manager Update v1 2023-01-10 04:16:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"40fea364-6c6e-48d3-88b5-62fa5ebb72f7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:16:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:16:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.114\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kc7fh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kc7fh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.114,StartTime:2023-01-10 04:16:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:16:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://f5547e94ea85dfc0f439d5558bae51dda72e04e47d7e0bd84f040940b67c81f0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.114,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jan 10 04:16:07.326: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-9879  777e5aa1-3185-41a9-8fe9-e428168e2e08 229406 3 2023-01-10 04:15:59 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 2172e222-4e84-4cd3-abc6-6a71d56e8f0e 0xc0026bf7c7 0xc0026bf7c8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2172e222-4e84-4cd3-abc6-6a71d56e8f0e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026bfa30 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 10 04:16:07.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9879" for this suite. 01/10/23 04:16:07.345
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:16:07.36
Jan 10 04:16:07.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename deployment 01/10/23 04:16:07.362
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:16:07.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:16:07.413
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Jan 10 04:16:07.418: INFO: Creating deployment "test-recreate-deployment"
Jan 10 04:16:07.431: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 10 04:16:07.468: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jan 10 04:16:09.476: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 10 04:16:09.480: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 10 04:16:09.493: INFO: Updating deployment test-recreate-deployment
Jan 10 04:16:09.493: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 10 04:16:09.667: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-1486  3118c10f-524f-4344-a87d-ed6c57866090 229585 2 2023-01-10 04:16:07 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ccb358 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-01-10 04:16:09 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-01-10 04:16:09 +0000 UTC,LastTransitionTime:2023-01-10 04:16:07 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Jan 10 04:16:09.670: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-1486  ba1ffc47-7382-49c2-87fe-e0fbea531daa 229584 1 2023-01-10 04:16:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 3118c10f-524f-4344-a87d-ed6c57866090 0xc006c90540 0xc006c90541}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3118c10f-524f-4344-a87d-ed6c57866090\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006c90668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:16:09.671: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 10 04:16:09.671: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-1486  1ce08654-d19a-463c-aaaa-d4bc508510c0 229573 2 2023-01-10 04:16:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 3118c10f-524f-4344-a87d-ed6c57866090 0xc006c90317 0xc006c90318}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3118c10f-524f-4344-a87d-ed6c57866090\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006c90498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:16:09.675: INFO: Pod "test-recreate-deployment-9d58999df-47z5t" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-47z5t test-recreate-deployment-9d58999df- deployment-1486  01deabab-a13b-4784-b3c7-f16e76b66de6 229583 0 2023-01-10 04:16:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df ba1ffc47-7382-49c2-87fe-e0fbea531daa 0xc004ccbc50 0xc004ccbc51}] [] [{kube-controller-manager Update v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba1ffc47-7382-49c2-87fe-e0fbea531daa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k2gvm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k2gvm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:,StartTime:2023-01-10 04:16:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 10 04:16:09.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1486" for this suite. 01/10/23 04:16:09.679
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":189,"skipped":3269,"failed":0}
------------------------------
• [2.331 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:16:07.36
    Jan 10 04:16:07.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename deployment 01/10/23 04:16:07.362
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:16:07.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:16:07.413
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Jan 10 04:16:07.418: INFO: Creating deployment "test-recreate-deployment"
    Jan 10 04:16:07.431: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Jan 10 04:16:07.468: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Jan 10 04:16:09.476: INFO: Waiting deployment "test-recreate-deployment" to complete
    Jan 10 04:16:09.480: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Jan 10 04:16:09.493: INFO: Updating deployment test-recreate-deployment
    Jan 10 04:16:09.493: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 10 04:16:09.667: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-1486  3118c10f-524f-4344-a87d-ed6c57866090 229585 2 2023-01-10 04:16:07 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ccb358 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-01-10 04:16:09 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-01-10 04:16:09 +0000 UTC,LastTransitionTime:2023-01-10 04:16:07 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Jan 10 04:16:09.670: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-1486  ba1ffc47-7382-49c2-87fe-e0fbea531daa 229584 1 2023-01-10 04:16:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 3118c10f-524f-4344-a87d-ed6c57866090 0xc006c90540 0xc006c90541}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3118c10f-524f-4344-a87d-ed6c57866090\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006c90668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:16:09.671: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Jan 10 04:16:09.671: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-1486  1ce08654-d19a-463c-aaaa-d4bc508510c0 229573 2 2023-01-10 04:16:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 3118c10f-524f-4344-a87d-ed6c57866090 0xc006c90317 0xc006c90318}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3118c10f-524f-4344-a87d-ed6c57866090\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006c90498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:16:09.675: INFO: Pod "test-recreate-deployment-9d58999df-47z5t" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-47z5t test-recreate-deployment-9d58999df- deployment-1486  01deabab-a13b-4784-b3c7-f16e76b66de6 229583 0 2023-01-10 04:16:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df ba1ffc47-7382-49c2-87fe-e0fbea531daa 0xc004ccbc50 0xc004ccbc51}] [] [{kube-controller-manager Update v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba1ffc47-7382-49c2-87fe-e0fbea531daa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-10 04:16:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k2gvm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k2gvm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:16:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:,StartTime:2023-01-10 04:16:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 10 04:16:09.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1486" for this suite. 01/10/23 04:16:09.679
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:16:09.695
Jan 10 04:16:09.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename var-expansion 01/10/23 04:16:09.704
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:16:09.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:16:09.751
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 01/10/23 04:16:09.754
Jan 10 04:16:09.772: INFO: Waiting up to 2m0s for pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" in namespace "var-expansion-8573" to be "running"
Jan 10 04:16:09.789: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 16.560186ms
Jan 10 04:16:11.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019711086s
Jan 10 04:16:13.795: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022640218s
Jan 10 04:16:15.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021537513s
Jan 10 04:16:17.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022223035s
Jan 10 04:16:19.798: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026017196s
Jan 10 04:16:21.802: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 12.030021823s
Jan 10 04:16:23.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 14.020275181s
Jan 10 04:16:25.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 16.021591226s
Jan 10 04:16:27.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 18.020206377s
Jan 10 04:16:29.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 20.021565989s
Jan 10 04:16:31.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 22.020907918s
Jan 10 04:16:33.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 24.02215457s
Jan 10 04:16:35.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 26.020276326s
Jan 10 04:16:37.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 28.022213367s
Jan 10 04:16:39.797: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 30.024756944s
Jan 10 04:16:41.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 32.020424523s
Jan 10 04:16:43.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 34.021237937s
Jan 10 04:16:45.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 36.020248834s
Jan 10 04:16:47.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 38.020229311s
Jan 10 04:16:49.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 40.021028652s
Jan 10 04:16:51.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 42.020494109s
Jan 10 04:16:53.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 44.02022974s
Jan 10 04:16:55.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 46.019705676s
Jan 10 04:16:57.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 48.0198887s
Jan 10 04:16:59.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 50.019728184s
Jan 10 04:17:01.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 52.019860496s
Jan 10 04:17:03.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 54.02053984s
Jan 10 04:17:05.824: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 56.052495689s
Jan 10 04:17:07.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 58.019705959s
Jan 10 04:17:09.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.019914378s
Jan 10 04:17:11.791: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.019465555s
Jan 10 04:17:13.800: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.028442429s
Jan 10 04:17:15.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.020024526s
Jan 10 04:17:17.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.020286253s
Jan 10 04:17:19.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.020858496s
Jan 10 04:17:21.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.020474028s
Jan 10 04:17:23.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.020024566s
Jan 10 04:17:25.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.020006086s
Jan 10 04:17:27.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.020312238s
Jan 10 04:17:29.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.019777003s
Jan 10 04:17:31.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.019554825s
Jan 10 04:17:33.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.021535325s
Jan 10 04:17:35.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.020887653s
Jan 10 04:17:37.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.020155331s
Jan 10 04:17:39.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.020896908s
Jan 10 04:17:41.795: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.023254966s
Jan 10 04:17:43.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.020478732s
Jan 10 04:17:45.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.020392081s
Jan 10 04:17:47.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.020143757s
Jan 10 04:17:49.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.020373944s
Jan 10 04:17:51.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.021572628s
Jan 10 04:17:53.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.02106789s
Jan 10 04:17:55.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.02203871s
Jan 10 04:17:57.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.02009194s
Jan 10 04:17:59.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.020716637s
Jan 10 04:18:01.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.020690071s
Jan 10 04:18:03.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.02129163s
Jan 10 04:18:05.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.020576823s
Jan 10 04:18:07.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.021113533s
Jan 10 04:18:09.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.0217758s
Jan 10 04:18:09.797: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.024752759s
STEP: updating the pod 01/10/23 04:18:09.797
Jan 10 04:18:10.311: INFO: Successfully updated pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda"
STEP: waiting for pod running 01/10/23 04:18:10.311
Jan 10 04:18:10.311: INFO: Waiting up to 2m0s for pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" in namespace "var-expansion-8573" to be "running"
Jan 10 04:18:10.316: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725325ms
Jan 10 04:18:12.321: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Running", Reason="", readiness=true. Elapsed: 2.010436495s
Jan 10 04:18:12.321: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" satisfied condition "running"
STEP: deleting the pod gracefully 01/10/23 04:18:12.321
Jan 10 04:18:12.322: INFO: Deleting pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" in namespace "var-expansion-8573"
Jan 10 04:18:12.345: INFO: Wait up to 5m0s for pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 10 04:18:44.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8573" for this suite. 01/10/23 04:18:44.357
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":190,"skipped":3276,"failed":0}
------------------------------
• [SLOW TEST] [154.670 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:16:09.695
    Jan 10 04:16:09.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename var-expansion 01/10/23 04:16:09.704
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:16:09.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:16:09.751
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 01/10/23 04:16:09.754
    Jan 10 04:16:09.772: INFO: Waiting up to 2m0s for pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" in namespace "var-expansion-8573" to be "running"
    Jan 10 04:16:09.789: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 16.560186ms
    Jan 10 04:16:11.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019711086s
    Jan 10 04:16:13.795: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022640218s
    Jan 10 04:16:15.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021537513s
    Jan 10 04:16:17.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022223035s
    Jan 10 04:16:19.798: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026017196s
    Jan 10 04:16:21.802: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 12.030021823s
    Jan 10 04:16:23.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 14.020275181s
    Jan 10 04:16:25.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 16.021591226s
    Jan 10 04:16:27.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 18.020206377s
    Jan 10 04:16:29.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 20.021565989s
    Jan 10 04:16:31.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 22.020907918s
    Jan 10 04:16:33.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 24.02215457s
    Jan 10 04:16:35.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 26.020276326s
    Jan 10 04:16:37.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 28.022213367s
    Jan 10 04:16:39.797: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 30.024756944s
    Jan 10 04:16:41.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 32.020424523s
    Jan 10 04:16:43.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 34.021237937s
    Jan 10 04:16:45.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 36.020248834s
    Jan 10 04:16:47.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 38.020229311s
    Jan 10 04:16:49.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 40.021028652s
    Jan 10 04:16:51.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 42.020494109s
    Jan 10 04:16:53.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 44.02022974s
    Jan 10 04:16:55.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 46.019705676s
    Jan 10 04:16:57.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 48.0198887s
    Jan 10 04:16:59.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 50.019728184s
    Jan 10 04:17:01.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 52.019860496s
    Jan 10 04:17:03.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 54.02053984s
    Jan 10 04:17:05.824: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 56.052495689s
    Jan 10 04:17:07.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 58.019705959s
    Jan 10 04:17:09.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.019914378s
    Jan 10 04:17:11.791: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.019465555s
    Jan 10 04:17:13.800: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.028442429s
    Jan 10 04:17:15.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.020024526s
    Jan 10 04:17:17.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.020286253s
    Jan 10 04:17:19.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.020858496s
    Jan 10 04:17:21.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.020474028s
    Jan 10 04:17:23.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.020024566s
    Jan 10 04:17:25.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.020006086s
    Jan 10 04:17:27.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.020312238s
    Jan 10 04:17:29.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.019777003s
    Jan 10 04:17:31.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.019554825s
    Jan 10 04:17:33.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.021535325s
    Jan 10 04:17:35.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.020887653s
    Jan 10 04:17:37.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.020155331s
    Jan 10 04:17:39.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.020896908s
    Jan 10 04:17:41.795: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.023254966s
    Jan 10 04:17:43.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.020478732s
    Jan 10 04:17:45.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.020392081s
    Jan 10 04:17:47.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.020143757s
    Jan 10 04:17:49.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.020373944s
    Jan 10 04:17:51.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.021572628s
    Jan 10 04:17:53.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.02106789s
    Jan 10 04:17:55.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.02203871s
    Jan 10 04:17:57.792: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.02009194s
    Jan 10 04:17:59.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.020716637s
    Jan 10 04:18:01.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.020690071s
    Jan 10 04:18:03.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.02129163s
    Jan 10 04:18:05.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.020576823s
    Jan 10 04:18:07.793: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.021113533s
    Jan 10 04:18:09.794: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.0217758s
    Jan 10 04:18:09.797: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.024752759s
    STEP: updating the pod 01/10/23 04:18:09.797
    Jan 10 04:18:10.311: INFO: Successfully updated pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda"
    STEP: waiting for pod running 01/10/23 04:18:10.311
    Jan 10 04:18:10.311: INFO: Waiting up to 2m0s for pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" in namespace "var-expansion-8573" to be "running"
    Jan 10 04:18:10.316: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725325ms
    Jan 10 04:18:12.321: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda": Phase="Running", Reason="", readiness=true. Elapsed: 2.010436495s
    Jan 10 04:18:12.321: INFO: Pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" satisfied condition "running"
    STEP: deleting the pod gracefully 01/10/23 04:18:12.321
    Jan 10 04:18:12.322: INFO: Deleting pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" in namespace "var-expansion-8573"
    Jan 10 04:18:12.345: INFO: Wait up to 5m0s for pod "var-expansion-5890cf75-e107-4a69-8d62-0fc658038eda" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 10 04:18:44.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8573" for this suite. 01/10/23 04:18:44.357
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:18:44.366
Jan 10 04:18:44.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:18:44.367
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:18:44.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:18:44.413
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-fcfe395e-99df-42d2-a47d-666560ebdb1a 01/10/23 04:18:44.457
STEP: Creating a pod to test consume configMaps 01/10/23 04:18:44.47
Jan 10 04:18:44.492: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697" in namespace "projected-7488" to be "Succeeded or Failed"
Jan 10 04:18:44.513: INFO: Pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697": Phase="Pending", Reason="", readiness=false. Elapsed: 21.114799ms
Jan 10 04:18:46.517: INFO: Pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025624424s
Jan 10 04:18:48.520: INFO: Pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028046128s
STEP: Saw pod success 01/10/23 04:18:48.52
Jan 10 04:18:48.520: INFO: Pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697" satisfied condition "Succeeded or Failed"
Jan 10 04:18:48.523: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:18:48.542
Jan 10 04:18:48.559: INFO: Waiting for pod pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697 to disappear
Jan 10 04:18:48.564: INFO: Pod pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 04:18:48.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7488" for this suite. 01/10/23 04:18:48.568
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":191,"skipped":3283,"failed":0}
------------------------------
• [4.212 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:18:44.366
    Jan 10 04:18:44.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:18:44.367
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:18:44.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:18:44.413
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-fcfe395e-99df-42d2-a47d-666560ebdb1a 01/10/23 04:18:44.457
    STEP: Creating a pod to test consume configMaps 01/10/23 04:18:44.47
    Jan 10 04:18:44.492: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697" in namespace "projected-7488" to be "Succeeded or Failed"
    Jan 10 04:18:44.513: INFO: Pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697": Phase="Pending", Reason="", readiness=false. Elapsed: 21.114799ms
    Jan 10 04:18:46.517: INFO: Pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025624424s
    Jan 10 04:18:48.520: INFO: Pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028046128s
    STEP: Saw pod success 01/10/23 04:18:48.52
    Jan 10 04:18:48.520: INFO: Pod "pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697" satisfied condition "Succeeded or Failed"
    Jan 10 04:18:48.523: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:18:48.542
    Jan 10 04:18:48.559: INFO: Waiting for pod pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697 to disappear
    Jan 10 04:18:48.564: INFO: Pod pod-projected-configmaps-92cdb2e8-27fd-4af4-ac84-16e4f5a7f697 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 04:18:48.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7488" for this suite. 01/10/23 04:18:48.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:18:48.587
Jan 10 04:18:48.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:18:48.591
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:18:48.611
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:18:48.615
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 01/10/23 04:18:48.618
Jan 10 04:18:48.628: INFO: Waiting up to 5m0s for pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c" in namespace "downward-api-6722" to be "Succeeded or Failed"
Jan 10 04:18:48.632: INFO: Pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.167276ms
Jan 10 04:18:50.642: INFO: Pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013859693s
Jan 10 04:18:52.636: INFO: Pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007720033s
STEP: Saw pod success 01/10/23 04:18:52.636
Jan 10 04:18:52.636: INFO: Pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c" satisfied condition "Succeeded or Failed"
Jan 10 04:18:52.639: INFO: Trying to get logs from node cncf-wk2 pod downward-api-fac09002-21f8-4710-aa21-bea72f9e761c container dapi-container: <nil>
STEP: delete the pod 01/10/23 04:18:52.647
Jan 10 04:18:52.663: INFO: Waiting for pod downward-api-fac09002-21f8-4710-aa21-bea72f9e761c to disappear
Jan 10 04:18:52.668: INFO: Pod downward-api-fac09002-21f8-4710-aa21-bea72f9e761c no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 10 04:18:52.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6722" for this suite. 01/10/23 04:18:52.671
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":192,"skipped":3334,"failed":0}
------------------------------
• [4.092 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:18:48.587
    Jan 10 04:18:48.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:18:48.591
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:18:48.611
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:18:48.615
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 01/10/23 04:18:48.618
    Jan 10 04:18:48.628: INFO: Waiting up to 5m0s for pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c" in namespace "downward-api-6722" to be "Succeeded or Failed"
    Jan 10 04:18:48.632: INFO: Pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.167276ms
    Jan 10 04:18:50.642: INFO: Pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013859693s
    Jan 10 04:18:52.636: INFO: Pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007720033s
    STEP: Saw pod success 01/10/23 04:18:52.636
    Jan 10 04:18:52.636: INFO: Pod "downward-api-fac09002-21f8-4710-aa21-bea72f9e761c" satisfied condition "Succeeded or Failed"
    Jan 10 04:18:52.639: INFO: Trying to get logs from node cncf-wk2 pod downward-api-fac09002-21f8-4710-aa21-bea72f9e761c container dapi-container: <nil>
    STEP: delete the pod 01/10/23 04:18:52.647
    Jan 10 04:18:52.663: INFO: Waiting for pod downward-api-fac09002-21f8-4710-aa21-bea72f9e761c to disappear
    Jan 10 04:18:52.668: INFO: Pod downward-api-fac09002-21f8-4710-aa21-bea72f9e761c no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 10 04:18:52.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6722" for this suite. 01/10/23 04:18:52.671
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:18:52.685
Jan 10 04:18:52.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename statefulset 01/10/23 04:18:52.687
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:18:52.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:18:52.718
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6034 01/10/23 04:18:52.722
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 01/10/23 04:18:52.735
Jan 10 04:18:52.758: INFO: Found 0 stateful pods, waiting for 3
Jan 10 04:19:02.770: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 04:19:02.770: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 04:19:02.770: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 04:19:02.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-6034 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 04:19:03.017: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 04:19:03.017: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 04:19:03.017: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 01/10/23 04:19:13.046
Jan 10 04:19:13.087: INFO: Updating stateful set ss2
STEP: Creating a new revision 01/10/23 04:19:13.087
STEP: Updating Pods in reverse ordinal order 01/10/23 04:19:23.154
Jan 10 04:19:23.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-6034 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 04:19:23.364: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 10 04:19:23.364: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 04:19:23.364: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 04:19:43.379: INFO: Waiting for StatefulSet statefulset-6034/ss2 to complete update
STEP: Rolling back to a previous revision 01/10/23 04:19:53.386
Jan 10 04:19:53.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-6034 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 04:19:53.720: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 04:19:53.720: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 04:19:53.720: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 04:20:03.762: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 01/10/23 04:20:13.78
Jan 10 04:20:13.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-6034 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 04:20:14.078: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 10 04:20:14.078: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 04:20:14.078: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 04:20:24.110: INFO: Waiting for StatefulSet statefulset-6034/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 10 04:20:34.120: INFO: Deleting all statefulset in ns statefulset-6034
Jan 10 04:20:34.124: INFO: Scaling statefulset ss2 to 0
Jan 10 04:20:44.150: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 04:20:44.153: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 10 04:20:44.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6034" for this suite. 01/10/23 04:20:44.193
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":193,"skipped":3338,"failed":0}
------------------------------
• [SLOW TEST] [111.515 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:18:52.685
    Jan 10 04:18:52.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename statefulset 01/10/23 04:18:52.687
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:18:52.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:18:52.718
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6034 01/10/23 04:18:52.722
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 01/10/23 04:18:52.735
    Jan 10 04:18:52.758: INFO: Found 0 stateful pods, waiting for 3
    Jan 10 04:19:02.770: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 04:19:02.770: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 04:19:02.770: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 04:19:02.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-6034 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 04:19:03.017: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 04:19:03.017: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 04:19:03.017: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 01/10/23 04:19:13.046
    Jan 10 04:19:13.087: INFO: Updating stateful set ss2
    STEP: Creating a new revision 01/10/23 04:19:13.087
    STEP: Updating Pods in reverse ordinal order 01/10/23 04:19:23.154
    Jan 10 04:19:23.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-6034 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 04:19:23.364: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 10 04:19:23.364: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 04:19:23.364: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 04:19:43.379: INFO: Waiting for StatefulSet statefulset-6034/ss2 to complete update
    STEP: Rolling back to a previous revision 01/10/23 04:19:53.386
    Jan 10 04:19:53.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-6034 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 04:19:53.720: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 04:19:53.720: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 04:19:53.720: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 04:20:03.762: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 01/10/23 04:20:13.78
    Jan 10 04:20:13.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-6034 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 04:20:14.078: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 10 04:20:14.078: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 04:20:14.078: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 04:20:24.110: INFO: Waiting for StatefulSet statefulset-6034/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 10 04:20:34.120: INFO: Deleting all statefulset in ns statefulset-6034
    Jan 10 04:20:34.124: INFO: Scaling statefulset ss2 to 0
    Jan 10 04:20:44.150: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 04:20:44.153: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 10 04:20:44.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6034" for this suite. 01/10/23 04:20:44.193
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:20:44.203
Jan 10 04:20:44.203: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename podtemplate 01/10/23 04:20:44.204
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:20:44.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:20:44.337
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 01/10/23 04:20:44.364
Jan 10 04:20:44.408: INFO: created test-podtemplate-1
Jan 10 04:20:44.429: INFO: created test-podtemplate-2
Jan 10 04:20:44.514: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 01/10/23 04:20:44.514
STEP: delete collection of pod templates 01/10/23 04:20:44.518
Jan 10 04:20:44.518: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 01/10/23 04:20:44.606
Jan 10 04:20:44.606: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jan 10 04:20:44.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7272" for this suite. 01/10/23 04:20:44.616
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":194,"skipped":3352,"failed":0}
------------------------------
• [0.418 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:20:44.203
    Jan 10 04:20:44.203: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename podtemplate 01/10/23 04:20:44.204
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:20:44.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:20:44.337
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 01/10/23 04:20:44.364
    Jan 10 04:20:44.408: INFO: created test-podtemplate-1
    Jan 10 04:20:44.429: INFO: created test-podtemplate-2
    Jan 10 04:20:44.514: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 01/10/23 04:20:44.514
    STEP: delete collection of pod templates 01/10/23 04:20:44.518
    Jan 10 04:20:44.518: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 01/10/23 04:20:44.606
    Jan 10 04:20:44.606: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jan 10 04:20:44.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-7272" for this suite. 01/10/23 04:20:44.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:20:44.622
Jan 10 04:20:44.623: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 04:20:44.624
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:20:44.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:20:44.7
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 01/10/23 04:20:44.702
STEP: Creating a ResourceQuota 01/10/23 04:20:49.74
STEP: Ensuring resource quota status is calculated 01/10/23 04:20:49.767
STEP: Creating a Pod that fits quota 01/10/23 04:20:51.771
STEP: Ensuring ResourceQuota status captures the pod usage 01/10/23 04:20:51.811
STEP: Not allowing a pod to be created that exceeds remaining quota 01/10/23 04:20:53.815
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 01/10/23 04:20:53.818
STEP: Ensuring a pod cannot update its resource requirements 01/10/23 04:20:53.821
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 01/10/23 04:20:53.825
STEP: Deleting the pod 01/10/23 04:20:55.827
STEP: Ensuring resource quota status released the pod usage 01/10/23 04:20:55.853
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 04:20:57.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2973" for this suite. 01/10/23 04:20:57.859
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":195,"skipped":3361,"failed":0}
------------------------------
• [SLOW TEST] [13.240 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:20:44.622
    Jan 10 04:20:44.623: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 04:20:44.624
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:20:44.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:20:44.7
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 01/10/23 04:20:44.702
    STEP: Creating a ResourceQuota 01/10/23 04:20:49.74
    STEP: Ensuring resource quota status is calculated 01/10/23 04:20:49.767
    STEP: Creating a Pod that fits quota 01/10/23 04:20:51.771
    STEP: Ensuring ResourceQuota status captures the pod usage 01/10/23 04:20:51.811
    STEP: Not allowing a pod to be created that exceeds remaining quota 01/10/23 04:20:53.815
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 01/10/23 04:20:53.818
    STEP: Ensuring a pod cannot update its resource requirements 01/10/23 04:20:53.821
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 01/10/23 04:20:53.825
    STEP: Deleting the pod 01/10/23 04:20:55.827
    STEP: Ensuring resource quota status released the pod usage 01/10/23 04:20:55.853
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 04:20:57.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2973" for this suite. 01/10/23 04:20:57.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:20:57.863
Jan 10 04:20:57.863: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename cronjob 01/10/23 04:20:57.864
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:20:57.884
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:20:57.889
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 01/10/23 04:20:57.895
STEP: Ensuring no jobs are scheduled 01/10/23 04:20:57.901
STEP: Ensuring no job exists by listing jobs explicitly 01/10/23 04:25:57.906
STEP: Removing cronjob 01/10/23 04:25:57.907
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 10 04:25:57.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-447" for this suite. 01/10/23 04:25:57.914
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":196,"skipped":3371,"failed":0}
------------------------------
• [SLOW TEST] [300.056 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:20:57.863
    Jan 10 04:20:57.863: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename cronjob 01/10/23 04:20:57.864
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:20:57.884
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:20:57.889
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 01/10/23 04:20:57.895
    STEP: Ensuring no jobs are scheduled 01/10/23 04:20:57.901
    STEP: Ensuring no job exists by listing jobs explicitly 01/10/23 04:25:57.906
    STEP: Removing cronjob 01/10/23 04:25:57.907
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 10 04:25:57.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-447" for this suite. 01/10/23 04:25:57.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:25:57.92
Jan 10 04:25:57.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename controllerrevisions 01/10/23 04:25:57.92
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:25:57.948
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:25:57.956
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-8nwl7-daemon-set" 01/10/23 04:25:57.997
STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:25:58.006
Jan 10 04:25:58.034: INFO: Number of nodes with available pods controlled by daemonset e2e-8nwl7-daemon-set: 0
Jan 10 04:25:58.034: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:25:59.058: INFO: Number of nodes with available pods controlled by daemonset e2e-8nwl7-daemon-set: 0
Jan 10 04:25:59.058: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:26:00.041: INFO: Number of nodes with available pods controlled by daemonset e2e-8nwl7-daemon-set: 3
Jan 10 04:26:00.041: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-8nwl7-daemon-set
STEP: Confirm DaemonSet "e2e-8nwl7-daemon-set" successfully created with "daemonset-name=e2e-8nwl7-daemon-set" label 01/10/23 04:26:00.044
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-8nwl7-daemon-set" 01/10/23 04:26:00.049
Jan 10 04:26:00.053: INFO: Located ControllerRevision: "e2e-8nwl7-daemon-set-665c9b98d9"
STEP: Patching ControllerRevision "e2e-8nwl7-daemon-set-665c9b98d9" 01/10/23 04:26:00.055
Jan 10 04:26:00.061: INFO: e2e-8nwl7-daemon-set-665c9b98d9 has been patched
STEP: Create a new ControllerRevision 01/10/23 04:26:00.061
Jan 10 04:26:00.065: INFO: Created ControllerRevision: e2e-8nwl7-daemon-set-b5b675bd9
STEP: Confirm that there are two ControllerRevisions 01/10/23 04:26:00.065
Jan 10 04:26:00.065: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 10 04:26:00.071: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-8nwl7-daemon-set-665c9b98d9" 01/10/23 04:26:00.071
STEP: Confirm that there is only one ControllerRevision 01/10/23 04:26:00.081
Jan 10 04:26:00.081: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 10 04:26:00.084: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-8nwl7-daemon-set-b5b675bd9" 01/10/23 04:26:00.087
Jan 10 04:26:00.098: INFO: e2e-8nwl7-daemon-set-b5b675bd9 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 01/10/23 04:26:00.098
W0110 04:26:00.107949      19 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 01/10/23 04:26:00.108
Jan 10 04:26:00.108: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 10 04:26:01.117: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 10 04:26:01.120: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-8nwl7-daemon-set-b5b675bd9=updated" 01/10/23 04:26:01.121
STEP: Confirm that there is only one ControllerRevision 01/10/23 04:26:01.129
Jan 10 04:26:01.129: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 10 04:26:01.132: INFO: Found 1 ControllerRevisions
Jan 10 04:26:01.135: INFO: ControllerRevision "e2e-8nwl7-daemon-set-6cb8d6479b" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-8nwl7-daemon-set" 01/10/23 04:26:01.143
STEP: deleting DaemonSet.extensions e2e-8nwl7-daemon-set in namespace controllerrevisions-5220, will wait for the garbage collector to delete the pods 01/10/23 04:26:01.144
Jan 10 04:26:01.205: INFO: Deleting DaemonSet.extensions e2e-8nwl7-daemon-set took: 7.062234ms
Jan 10 04:26:01.305: INFO: Terminating DaemonSet.extensions e2e-8nwl7-daemon-set pods took: 100.387245ms
Jan 10 04:26:03.210: INFO: Number of nodes with available pods controlled by daemonset e2e-8nwl7-daemon-set: 0
Jan 10 04:26:03.210: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-8nwl7-daemon-set
Jan 10 04:26:03.217: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"232362"},"items":null}

Jan 10 04:26:03.220: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"232362"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:26:03.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-5220" for this suite. 01/10/23 04:26:03.254
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":197,"skipped":3389,"failed":0}
------------------------------
• [SLOW TEST] [5.343 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:25:57.92
    Jan 10 04:25:57.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename controllerrevisions 01/10/23 04:25:57.92
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:25:57.948
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:25:57.956
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-8nwl7-daemon-set" 01/10/23 04:25:57.997
    STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:25:58.006
    Jan 10 04:25:58.034: INFO: Number of nodes with available pods controlled by daemonset e2e-8nwl7-daemon-set: 0
    Jan 10 04:25:58.034: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:25:59.058: INFO: Number of nodes with available pods controlled by daemonset e2e-8nwl7-daemon-set: 0
    Jan 10 04:25:59.058: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:26:00.041: INFO: Number of nodes with available pods controlled by daemonset e2e-8nwl7-daemon-set: 3
    Jan 10 04:26:00.041: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-8nwl7-daemon-set
    STEP: Confirm DaemonSet "e2e-8nwl7-daemon-set" successfully created with "daemonset-name=e2e-8nwl7-daemon-set" label 01/10/23 04:26:00.044
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-8nwl7-daemon-set" 01/10/23 04:26:00.049
    Jan 10 04:26:00.053: INFO: Located ControllerRevision: "e2e-8nwl7-daemon-set-665c9b98d9"
    STEP: Patching ControllerRevision "e2e-8nwl7-daemon-set-665c9b98d9" 01/10/23 04:26:00.055
    Jan 10 04:26:00.061: INFO: e2e-8nwl7-daemon-set-665c9b98d9 has been patched
    STEP: Create a new ControllerRevision 01/10/23 04:26:00.061
    Jan 10 04:26:00.065: INFO: Created ControllerRevision: e2e-8nwl7-daemon-set-b5b675bd9
    STEP: Confirm that there are two ControllerRevisions 01/10/23 04:26:00.065
    Jan 10 04:26:00.065: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 10 04:26:00.071: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-8nwl7-daemon-set-665c9b98d9" 01/10/23 04:26:00.071
    STEP: Confirm that there is only one ControllerRevision 01/10/23 04:26:00.081
    Jan 10 04:26:00.081: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 10 04:26:00.084: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-8nwl7-daemon-set-b5b675bd9" 01/10/23 04:26:00.087
    Jan 10 04:26:00.098: INFO: e2e-8nwl7-daemon-set-b5b675bd9 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 01/10/23 04:26:00.098
    W0110 04:26:00.107949      19 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 01/10/23 04:26:00.108
    Jan 10 04:26:00.108: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 10 04:26:01.117: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 10 04:26:01.120: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-8nwl7-daemon-set-b5b675bd9=updated" 01/10/23 04:26:01.121
    STEP: Confirm that there is only one ControllerRevision 01/10/23 04:26:01.129
    Jan 10 04:26:01.129: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 10 04:26:01.132: INFO: Found 1 ControllerRevisions
    Jan 10 04:26:01.135: INFO: ControllerRevision "e2e-8nwl7-daemon-set-6cb8d6479b" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-8nwl7-daemon-set" 01/10/23 04:26:01.143
    STEP: deleting DaemonSet.extensions e2e-8nwl7-daemon-set in namespace controllerrevisions-5220, will wait for the garbage collector to delete the pods 01/10/23 04:26:01.144
    Jan 10 04:26:01.205: INFO: Deleting DaemonSet.extensions e2e-8nwl7-daemon-set took: 7.062234ms
    Jan 10 04:26:01.305: INFO: Terminating DaemonSet.extensions e2e-8nwl7-daemon-set pods took: 100.387245ms
    Jan 10 04:26:03.210: INFO: Number of nodes with available pods controlled by daemonset e2e-8nwl7-daemon-set: 0
    Jan 10 04:26:03.210: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-8nwl7-daemon-set
    Jan 10 04:26:03.217: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"232362"},"items":null}

    Jan 10 04:26:03.220: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"232362"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:26:03.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-5220" for this suite. 01/10/23 04:26:03.254
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:26:03.264
Jan 10 04:26:03.265: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename subpath 01/10/23 04:26:03.266
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:26:03.311
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:26:03.317
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/10/23 04:26:03.322
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-8trn 01/10/23 04:26:03.362
STEP: Creating a pod to test atomic-volume-subpath 01/10/23 04:26:03.362
Jan 10 04:26:03.384: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8trn" in namespace "subpath-6108" to be "Succeeded or Failed"
Jan 10 04:26:03.397: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.613049ms
Jan 10 04:26:05.400: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 2.016368095s
Jan 10 04:26:07.401: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 4.016529741s
Jan 10 04:26:09.400: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 6.015865582s
Jan 10 04:26:11.405: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 8.020591639s
Jan 10 04:26:13.400: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 10.016118285s
Jan 10 04:26:15.401: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 12.016607876s
Jan 10 04:26:17.403: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 14.018678217s
Jan 10 04:26:19.406: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 16.02164062s
Jan 10 04:26:21.401: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 18.016526131s
Jan 10 04:26:23.404: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 20.019468944s
Jan 10 04:26:25.408: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=false. Elapsed: 22.024167504s
Jan 10 04:26:27.400: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.016321213s
STEP: Saw pod success 01/10/23 04:26:27.4
Jan 10 04:26:27.401: INFO: Pod "pod-subpath-test-projected-8trn" satisfied condition "Succeeded or Failed"
Jan 10 04:26:27.403: INFO: Trying to get logs from node cncf-wk2 pod pod-subpath-test-projected-8trn container test-container-subpath-projected-8trn: <nil>
STEP: delete the pod 01/10/23 04:26:27.416
Jan 10 04:26:27.429: INFO: Waiting for pod pod-subpath-test-projected-8trn to disappear
Jan 10 04:26:27.432: INFO: Pod pod-subpath-test-projected-8trn no longer exists
STEP: Deleting pod pod-subpath-test-projected-8trn 01/10/23 04:26:27.432
Jan 10 04:26:27.432: INFO: Deleting pod "pod-subpath-test-projected-8trn" in namespace "subpath-6108"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 10 04:26:27.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6108" for this suite. 01/10/23 04:26:27.437
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":198,"skipped":3400,"failed":0}
------------------------------
• [SLOW TEST] [24.177 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:26:03.264
    Jan 10 04:26:03.265: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename subpath 01/10/23 04:26:03.266
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:26:03.311
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:26:03.317
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/10/23 04:26:03.322
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-8trn 01/10/23 04:26:03.362
    STEP: Creating a pod to test atomic-volume-subpath 01/10/23 04:26:03.362
    Jan 10 04:26:03.384: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8trn" in namespace "subpath-6108" to be "Succeeded or Failed"
    Jan 10 04:26:03.397: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.613049ms
    Jan 10 04:26:05.400: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 2.016368095s
    Jan 10 04:26:07.401: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 4.016529741s
    Jan 10 04:26:09.400: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 6.015865582s
    Jan 10 04:26:11.405: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 8.020591639s
    Jan 10 04:26:13.400: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 10.016118285s
    Jan 10 04:26:15.401: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 12.016607876s
    Jan 10 04:26:17.403: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 14.018678217s
    Jan 10 04:26:19.406: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 16.02164062s
    Jan 10 04:26:21.401: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 18.016526131s
    Jan 10 04:26:23.404: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=true. Elapsed: 20.019468944s
    Jan 10 04:26:25.408: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Running", Reason="", readiness=false. Elapsed: 22.024167504s
    Jan 10 04:26:27.400: INFO: Pod "pod-subpath-test-projected-8trn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.016321213s
    STEP: Saw pod success 01/10/23 04:26:27.4
    Jan 10 04:26:27.401: INFO: Pod "pod-subpath-test-projected-8trn" satisfied condition "Succeeded or Failed"
    Jan 10 04:26:27.403: INFO: Trying to get logs from node cncf-wk2 pod pod-subpath-test-projected-8trn container test-container-subpath-projected-8trn: <nil>
    STEP: delete the pod 01/10/23 04:26:27.416
    Jan 10 04:26:27.429: INFO: Waiting for pod pod-subpath-test-projected-8trn to disappear
    Jan 10 04:26:27.432: INFO: Pod pod-subpath-test-projected-8trn no longer exists
    STEP: Deleting pod pod-subpath-test-projected-8trn 01/10/23 04:26:27.432
    Jan 10 04:26:27.432: INFO: Deleting pod "pod-subpath-test-projected-8trn" in namespace "subpath-6108"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 10 04:26:27.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6108" for this suite. 01/10/23 04:26:27.437
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:26:27.444
Jan 10 04:26:27.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 04:26:27.445
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:26:27.468
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:26:27.474
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/10/23 04:26:27.476
Jan 10 04:26:27.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5175 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jan 10 04:26:27.565: INFO: stderr: ""
Jan 10 04:26:27.565: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 01/10/23 04:26:27.565
STEP: verifying the pod e2e-test-httpd-pod was created 01/10/23 04:26:32.616
Jan 10 04:26:32.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5175 get pod e2e-test-httpd-pod -o json'
Jan 10 04:26:32.726: INFO: stderr: ""
Jan 10 04:26:32.726: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"ef8256b89d99937f3a4ce0e14ca4f3ef206fc9b36766b19348d723546f1dcf9e\",\n            \"cni.projectcalico.org/podIP\": \"10.42.1.227/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.42.1.227/32\"\n        },\n        \"creationTimestamp\": \"2023-01-10T04:26:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5175\",\n        \"resourceVersion\": \"232522\",\n        \"uid\": \"e00b5daf-a7b0-48be-b1ec-5894531879b3\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-bczcp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"cncf-wk2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-bczcp\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-10T04:26:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-10T04:26:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-10T04:26:28Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-10T04:26:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://87fa2499c657c41bdba5f137590f25dac97272848dc966ba1032b887cb02ad62\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-01-10T04:26:28Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.3.44\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.1.227\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.42.1.227\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-01-10T04:26:27Z\"\n    }\n}\n"
STEP: replace the image in the pod 01/10/23 04:26:32.727
Jan 10 04:26:32.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5175 replace -f -'
Jan 10 04:26:33.422: INFO: stderr: ""
Jan 10 04:26:33.422: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 01/10/23 04:26:33.422
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Jan 10 04:26:33.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5175 delete pods e2e-test-httpd-pod'
Jan 10 04:26:34.780: INFO: stderr: ""
Jan 10 04:26:34.780: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 04:26:34.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5175" for this suite. 01/10/23 04:26:34.784
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":199,"skipped":3402,"failed":0}
------------------------------
• [SLOW TEST] [7.343 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:26:27.444
    Jan 10 04:26:27.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 04:26:27.445
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:26:27.468
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:26:27.474
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/10/23 04:26:27.476
    Jan 10 04:26:27.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5175 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Jan 10 04:26:27.565: INFO: stderr: ""
    Jan 10 04:26:27.565: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 01/10/23 04:26:27.565
    STEP: verifying the pod e2e-test-httpd-pod was created 01/10/23 04:26:32.616
    Jan 10 04:26:32.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5175 get pod e2e-test-httpd-pod -o json'
    Jan 10 04:26:32.726: INFO: stderr: ""
    Jan 10 04:26:32.726: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"ef8256b89d99937f3a4ce0e14ca4f3ef206fc9b36766b19348d723546f1dcf9e\",\n            \"cni.projectcalico.org/podIP\": \"10.42.1.227/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.42.1.227/32\"\n        },\n        \"creationTimestamp\": \"2023-01-10T04:26:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5175\",\n        \"resourceVersion\": \"232522\",\n        \"uid\": \"e00b5daf-a7b0-48be-b1ec-5894531879b3\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-bczcp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"cncf-wk2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-bczcp\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-10T04:26:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-10T04:26:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-10T04:26:28Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-10T04:26:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://87fa2499c657c41bdba5f137590f25dac97272848dc966ba1032b887cb02ad62\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-01-10T04:26:28Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.3.44\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.1.227\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.42.1.227\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-01-10T04:26:27Z\"\n    }\n}\n"
    STEP: replace the image in the pod 01/10/23 04:26:32.727
    Jan 10 04:26:32.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5175 replace -f -'
    Jan 10 04:26:33.422: INFO: stderr: ""
    Jan 10 04:26:33.422: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 01/10/23 04:26:33.422
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Jan 10 04:26:33.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5175 delete pods e2e-test-httpd-pod'
    Jan 10 04:26:34.780: INFO: stderr: ""
    Jan 10 04:26:34.780: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 04:26:34.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5175" for this suite. 01/10/23 04:26:34.784
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:26:34.788
Jan 10 04:26:34.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename statefulset 01/10/23 04:26:34.789
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:26:34.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:26:34.828
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9432 01/10/23 04:26:34.834
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 01/10/23 04:26:34.843
STEP: Creating stateful set ss in namespace statefulset-9432 01/10/23 04:26:34.853
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9432 01/10/23 04:26:34.875
Jan 10 04:26:34.879: INFO: Found 0 stateful pods, waiting for 1
Jan 10 04:26:44.883: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 01/10/23 04:26:44.883
Jan 10 04:26:44.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 04:26:45.060: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 04:26:45.060: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 04:26:45.060: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 04:26:45.063: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 10 04:26:55.069: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 10 04:26:55.069: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 04:26:55.095: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999969s
Jan 10 04:26:56.098: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99020576s
Jan 10 04:26:57.102: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987587405s
Jan 10 04:26:58.105: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983112544s
Jan 10 04:26:59.109: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979665422s
Jan 10 04:27:00.113: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.976695182s
Jan 10 04:27:01.116: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.97273586s
Jan 10 04:27:02.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.968999913s
Jan 10 04:27:03.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.96125839s
Jan 10 04:27:04.130: INFO: Verifying statefulset ss doesn't scale past 1 for another 958.592134ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9432 01/10/23 04:27:05.13
Jan 10 04:27:05.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 04:27:05.538: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 10 04:27:05.538: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 04:27:05.538: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 04:27:05.542: INFO: Found 1 stateful pods, waiting for 3
Jan 10 04:27:15.552: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 04:27:15.552: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 04:27:15.552: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 01/10/23 04:27:15.552
STEP: Scale down will halt with unhealthy stateful pod 01/10/23 04:27:15.552
Jan 10 04:27:15.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 04:27:15.957: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 04:27:15.957: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 04:27:15.957: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 04:27:15.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 04:27:16.329: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 04:27:16.329: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 04:27:16.329: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 04:27:16.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 10 04:27:16.626: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 10 04:27:16.626: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 10 04:27:16.626: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 10 04:27:16.626: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 04:27:16.630: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 10 04:27:26.641: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 10 04:27:26.641: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 10 04:27:26.641: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 10 04:27:26.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999421s
Jan 10 04:27:27.658: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997156442s
Jan 10 04:27:28.662: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992138002s
Jan 10 04:27:29.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988599918s
Jan 10 04:27:30.670: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984511049s
Jan 10 04:27:31.678: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980078403s
Jan 10 04:27:32.683: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972136279s
Jan 10 04:27:33.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967093769s
Jan 10 04:27:34.689: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963938691s
Jan 10 04:27:35.697: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.091562ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9432 01/10/23 04:27:36.698
Jan 10 04:27:36.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 04:27:36.839: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 10 04:27:36.839: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 04:27:36.839: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 04:27:36.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 04:27:37.021: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 10 04:27:37.021: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 04:27:37.021: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 04:27:37.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 10 04:27:37.191: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 10 04:27:37.191: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 10 04:27:37.191: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 10 04:27:37.191: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 01/10/23 04:27:47.203
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 10 04:27:47.203: INFO: Deleting all statefulset in ns statefulset-9432
Jan 10 04:27:47.205: INFO: Scaling statefulset ss to 0
Jan 10 04:27:47.213: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 04:27:47.215: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 10 04:27:47.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9432" for this suite. 01/10/23 04:27:47.25
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":200,"skipped":3407,"failed":0}
------------------------------
• [SLOW TEST] [72.468 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:26:34.788
    Jan 10 04:26:34.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename statefulset 01/10/23 04:26:34.789
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:26:34.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:26:34.828
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9432 01/10/23 04:26:34.834
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 01/10/23 04:26:34.843
    STEP: Creating stateful set ss in namespace statefulset-9432 01/10/23 04:26:34.853
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9432 01/10/23 04:26:34.875
    Jan 10 04:26:34.879: INFO: Found 0 stateful pods, waiting for 1
    Jan 10 04:26:44.883: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 01/10/23 04:26:44.883
    Jan 10 04:26:44.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 04:26:45.060: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 04:26:45.060: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 04:26:45.060: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 04:26:45.063: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Jan 10 04:26:55.069: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jan 10 04:26:55.069: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 04:26:55.095: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999969s
    Jan 10 04:26:56.098: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99020576s
    Jan 10 04:26:57.102: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987587405s
    Jan 10 04:26:58.105: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983112544s
    Jan 10 04:26:59.109: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979665422s
    Jan 10 04:27:00.113: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.976695182s
    Jan 10 04:27:01.116: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.97273586s
    Jan 10 04:27:02.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.968999913s
    Jan 10 04:27:03.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.96125839s
    Jan 10 04:27:04.130: INFO: Verifying statefulset ss doesn't scale past 1 for another 958.592134ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9432 01/10/23 04:27:05.13
    Jan 10 04:27:05.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 04:27:05.538: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 10 04:27:05.538: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 04:27:05.538: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 04:27:05.542: INFO: Found 1 stateful pods, waiting for 3
    Jan 10 04:27:15.552: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 04:27:15.552: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 04:27:15.552: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 01/10/23 04:27:15.552
    STEP: Scale down will halt with unhealthy stateful pod 01/10/23 04:27:15.552
    Jan 10 04:27:15.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 04:27:15.957: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 04:27:15.957: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 04:27:15.957: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 04:27:15.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 04:27:16.329: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 04:27:16.329: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 04:27:16.329: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 04:27:16.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 10 04:27:16.626: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 10 04:27:16.626: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 10 04:27:16.626: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 10 04:27:16.626: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 04:27:16.630: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Jan 10 04:27:26.641: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jan 10 04:27:26.641: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Jan 10 04:27:26.641: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Jan 10 04:27:26.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999421s
    Jan 10 04:27:27.658: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997156442s
    Jan 10 04:27:28.662: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992138002s
    Jan 10 04:27:29.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988599918s
    Jan 10 04:27:30.670: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984511049s
    Jan 10 04:27:31.678: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980078403s
    Jan 10 04:27:32.683: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972136279s
    Jan 10 04:27:33.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967093769s
    Jan 10 04:27:34.689: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963938691s
    Jan 10 04:27:35.697: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.091562ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9432 01/10/23 04:27:36.698
    Jan 10 04:27:36.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 04:27:36.839: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 10 04:27:36.839: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 04:27:36.839: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 04:27:36.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 04:27:37.021: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 10 04:27:37.021: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 04:27:37.021: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 04:27:37.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=statefulset-9432 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 10 04:27:37.191: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 10 04:27:37.191: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 10 04:27:37.191: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 10 04:27:37.191: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 01/10/23 04:27:47.203
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 10 04:27:47.203: INFO: Deleting all statefulset in ns statefulset-9432
    Jan 10 04:27:47.205: INFO: Scaling statefulset ss to 0
    Jan 10 04:27:47.213: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 04:27:47.215: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 10 04:27:47.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9432" for this suite. 01/10/23 04:27:47.25
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:27:47.26
Jan 10 04:27:47.260: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename cronjob 01/10/23 04:27:47.261
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:27:47.286
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:27:47.298
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 01/10/23 04:27:47.3
STEP: Ensuring a job is scheduled 01/10/23 04:27:47.31
STEP: Ensuring exactly one is scheduled 01/10/23 04:28:01.314
STEP: Ensuring exactly one running job exists by listing jobs explicitly 01/10/23 04:28:01.316
STEP: Ensuring no more jobs are scheduled 01/10/23 04:28:01.318
STEP: Removing cronjob 01/10/23 04:33:01.328
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 10 04:33:01.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7747" for this suite. 01/10/23 04:33:01.378
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":201,"skipped":3437,"failed":0}
------------------------------
• [SLOW TEST] [314.136 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:27:47.26
    Jan 10 04:27:47.260: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename cronjob 01/10/23 04:27:47.261
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:27:47.286
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:27:47.298
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 01/10/23 04:27:47.3
    STEP: Ensuring a job is scheduled 01/10/23 04:27:47.31
    STEP: Ensuring exactly one is scheduled 01/10/23 04:28:01.314
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 01/10/23 04:28:01.316
    STEP: Ensuring no more jobs are scheduled 01/10/23 04:28:01.318
    STEP: Removing cronjob 01/10/23 04:33:01.328
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 10 04:33:01.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7747" for this suite. 01/10/23 04:33:01.378
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:33:01.408
Jan 10 04:33:01.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename ephemeral-containers-test 01/10/23 04:33:01.411
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:01.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:01.487
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 01/10/23 04:33:01.491
Jan 10 04:33:01.509: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4544" to be "running and ready"
Jan 10 04:33:01.526: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 16.395709ms
Jan 10 04:33:01.526: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:33:03.532: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.022926988s
Jan 10 04:33:03.532: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Jan 10 04:33:03.532: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 01/10/23 04:33:03.537
Jan 10 04:33:03.617: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4544" to be "container debugger running"
Jan 10 04:33:03.654: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 37.189061ms
Jan 10 04:33:05.657: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.040655367s
Jan 10 04:33:07.662: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.045009603s
Jan 10 04:33:07.665: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 01/10/23 04:33:07.665
Jan 10 04:33:07.666: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4544 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:33:07.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:33:07.667: INFO: ExecWithOptions: Clientset creation
Jan 10 04:33:07.668: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/ephemeral-containers-test-4544/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Jan 10 04:33:07.827: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 10 04:33:07.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-4544" for this suite. 01/10/23 04:33:07.856
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":202,"skipped":3440,"failed":0}
------------------------------
• [SLOW TEST] [6.458 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:33:01.408
    Jan 10 04:33:01.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename ephemeral-containers-test 01/10/23 04:33:01.411
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:01.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:01.487
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 01/10/23 04:33:01.491
    Jan 10 04:33:01.509: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4544" to be "running and ready"
    Jan 10 04:33:01.526: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 16.395709ms
    Jan 10 04:33:01.526: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:33:03.532: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.022926988s
    Jan 10 04:33:03.532: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Jan 10 04:33:03.532: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 01/10/23 04:33:03.537
    Jan 10 04:33:03.617: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4544" to be "container debugger running"
    Jan 10 04:33:03.654: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 37.189061ms
    Jan 10 04:33:05.657: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.040655367s
    Jan 10 04:33:07.662: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.045009603s
    Jan 10 04:33:07.665: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 01/10/23 04:33:07.665
    Jan 10 04:33:07.666: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4544 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:33:07.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:33:07.667: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:33:07.668: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/ephemeral-containers-test-4544/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Jan 10 04:33:07.827: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 10 04:33:07.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-4544" for this suite. 01/10/23 04:33:07.856
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:33:07.867
Jan 10 04:33:07.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename subpath 01/10/23 04:33:07.868
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:07.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:07.907
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/10/23 04:33:07.925
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-7l6l 01/10/23 04:33:07.952
STEP: Creating a pod to test atomic-volume-subpath 01/10/23 04:33:07.952
Jan 10 04:33:07.975: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-7l6l" in namespace "subpath-790" to be "Succeeded or Failed"
Jan 10 04:33:07.991: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Pending", Reason="", readiness=false. Elapsed: 16.054489ms
Jan 10 04:33:09.996: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 2.020732987s
Jan 10 04:33:11.996: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 4.020567028s
Jan 10 04:33:13.994: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 6.019166352s
Jan 10 04:33:15.997: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 8.021481892s
Jan 10 04:33:17.996: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 10.020224869s
Jan 10 04:33:19.994: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 12.019015707s
Jan 10 04:33:21.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 14.019427189s
Jan 10 04:33:23.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 16.019195102s
Jan 10 04:33:25.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 18.019797861s
Jan 10 04:33:27.996: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 20.020438207s
Jan 10 04:33:29.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=false. Elapsed: 22.019471196s
Jan 10 04:33:31.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.019868581s
STEP: Saw pod success 01/10/23 04:33:31.995
Jan 10 04:33:31.995: INFO: Pod "pod-subpath-test-secret-7l6l" satisfied condition "Succeeded or Failed"
Jan 10 04:33:31.998: INFO: Trying to get logs from node cncf-wk2 pod pod-subpath-test-secret-7l6l container test-container-subpath-secret-7l6l: <nil>
STEP: delete the pod 01/10/23 04:33:32.004
Jan 10 04:33:32.018: INFO: Waiting for pod pod-subpath-test-secret-7l6l to disappear
Jan 10 04:33:32.020: INFO: Pod pod-subpath-test-secret-7l6l no longer exists
STEP: Deleting pod pod-subpath-test-secret-7l6l 01/10/23 04:33:32.02
Jan 10 04:33:32.020: INFO: Deleting pod "pod-subpath-test-secret-7l6l" in namespace "subpath-790"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 10 04:33:32.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-790" for this suite. 01/10/23 04:33:32.026
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":203,"skipped":3444,"failed":0}
------------------------------
• [SLOW TEST] [24.164 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:33:07.867
    Jan 10 04:33:07.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename subpath 01/10/23 04:33:07.868
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:07.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:07.907
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/10/23 04:33:07.925
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-7l6l 01/10/23 04:33:07.952
    STEP: Creating a pod to test atomic-volume-subpath 01/10/23 04:33:07.952
    Jan 10 04:33:07.975: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-7l6l" in namespace "subpath-790" to be "Succeeded or Failed"
    Jan 10 04:33:07.991: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Pending", Reason="", readiness=false. Elapsed: 16.054489ms
    Jan 10 04:33:09.996: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 2.020732987s
    Jan 10 04:33:11.996: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 4.020567028s
    Jan 10 04:33:13.994: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 6.019166352s
    Jan 10 04:33:15.997: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 8.021481892s
    Jan 10 04:33:17.996: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 10.020224869s
    Jan 10 04:33:19.994: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 12.019015707s
    Jan 10 04:33:21.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 14.019427189s
    Jan 10 04:33:23.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 16.019195102s
    Jan 10 04:33:25.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 18.019797861s
    Jan 10 04:33:27.996: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=true. Elapsed: 20.020438207s
    Jan 10 04:33:29.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Running", Reason="", readiness=false. Elapsed: 22.019471196s
    Jan 10 04:33:31.995: INFO: Pod "pod-subpath-test-secret-7l6l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.019868581s
    STEP: Saw pod success 01/10/23 04:33:31.995
    Jan 10 04:33:31.995: INFO: Pod "pod-subpath-test-secret-7l6l" satisfied condition "Succeeded or Failed"
    Jan 10 04:33:31.998: INFO: Trying to get logs from node cncf-wk2 pod pod-subpath-test-secret-7l6l container test-container-subpath-secret-7l6l: <nil>
    STEP: delete the pod 01/10/23 04:33:32.004
    Jan 10 04:33:32.018: INFO: Waiting for pod pod-subpath-test-secret-7l6l to disappear
    Jan 10 04:33:32.020: INFO: Pod pod-subpath-test-secret-7l6l no longer exists
    STEP: Deleting pod pod-subpath-test-secret-7l6l 01/10/23 04:33:32.02
    Jan 10 04:33:32.020: INFO: Deleting pod "pod-subpath-test-secret-7l6l" in namespace "subpath-790"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 10 04:33:32.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-790" for this suite. 01/10/23 04:33:32.026
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:33:32.032
Jan 10 04:33:32.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:33:32.033
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:32.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:32.13
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-f09ef4ea-35d9-4de4-9441-b105139d260a 01/10/23 04:33:32.135
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:33:32.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3173" for this suite. 01/10/23 04:33:32.142
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":204,"skipped":3446,"failed":0}
------------------------------
• [0.117 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:33:32.032
    Jan 10 04:33:32.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:33:32.033
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:32.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:32.13
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-f09ef4ea-35d9-4de4-9441-b105139d260a 01/10/23 04:33:32.135
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:33:32.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3173" for this suite. 01/10/23 04:33:32.142
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:33:32.152
Jan 10 04:33:32.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:33:32.153
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:32.193
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:32.201
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 01/10/23 04:33:32.207
Jan 10 04:33:32.220: INFO: Waiting up to 5m0s for pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474" in namespace "downward-api-940" to be "Succeeded or Failed"
Jan 10 04:33:32.225: INFO: Pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474": Phase="Pending", Reason="", readiness=false. Elapsed: 4.598596ms
Jan 10 04:33:34.229: INFO: Pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008554929s
Jan 10 04:33:36.231: INFO: Pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010311833s
STEP: Saw pod success 01/10/23 04:33:36.231
Jan 10 04:33:36.231: INFO: Pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474" satisfied condition "Succeeded or Failed"
Jan 10 04:33:36.234: INFO: Trying to get logs from node cncf-wk2 pod downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474 container dapi-container: <nil>
STEP: delete the pod 01/10/23 04:33:36.24
Jan 10 04:33:36.248: INFO: Waiting for pod downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474 to disappear
Jan 10 04:33:36.251: INFO: Pod downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 10 04:33:36.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-940" for this suite. 01/10/23 04:33:36.255
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":205,"skipped":3461,"failed":0}
------------------------------
• [4.109 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:33:32.152
    Jan 10 04:33:32.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:33:32.153
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:32.193
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:32.201
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 01/10/23 04:33:32.207
    Jan 10 04:33:32.220: INFO: Waiting up to 5m0s for pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474" in namespace "downward-api-940" to be "Succeeded or Failed"
    Jan 10 04:33:32.225: INFO: Pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474": Phase="Pending", Reason="", readiness=false. Elapsed: 4.598596ms
    Jan 10 04:33:34.229: INFO: Pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008554929s
    Jan 10 04:33:36.231: INFO: Pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010311833s
    STEP: Saw pod success 01/10/23 04:33:36.231
    Jan 10 04:33:36.231: INFO: Pod "downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474" satisfied condition "Succeeded or Failed"
    Jan 10 04:33:36.234: INFO: Trying to get logs from node cncf-wk2 pod downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474 container dapi-container: <nil>
    STEP: delete the pod 01/10/23 04:33:36.24
    Jan 10 04:33:36.248: INFO: Waiting for pod downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474 to disappear
    Jan 10 04:33:36.251: INFO: Pod downward-api-955ff3e0-e6e9-45aa-9771-33ceaad9e474 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 10 04:33:36.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-940" for this suite. 01/10/23 04:33:36.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:33:36.262
Jan 10 04:33:36.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:33:36.263
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:36.303
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:36.311
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-5983 01/10/23 04:33:36.322
STEP: creating service affinity-nodeport in namespace services-5983 01/10/23 04:33:36.323
STEP: creating replication controller affinity-nodeport in namespace services-5983 01/10/23 04:33:36.353
I0110 04:33:36.384965      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5983, replica count: 3
I0110 04:33:39.435679      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 04:33:39.443: INFO: Creating new exec pod
Jan 10 04:33:39.450: INFO: Waiting up to 5m0s for pod "execpod-affinitycw5gb" in namespace "services-5983" to be "running"
Jan 10 04:33:39.463: INFO: Pod "execpod-affinitycw5gb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.804404ms
Jan 10 04:33:41.467: INFO: Pod "execpod-affinitycw5gb": Phase="Running", Reason="", readiness=true. Elapsed: 2.016169708s
Jan 10 04:33:41.467: INFO: Pod "execpod-affinitycw5gb" satisfied condition "running"
Jan 10 04:33:42.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Jan 10 04:33:42.644: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Jan 10 04:33:42.644: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:33:42.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.133.172 80'
Jan 10 04:33:42.847: INFO: stderr: "+ nc -v -t -w 2 10.43.133.172 80\nConnection to 10.43.133.172 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Jan 10 04:33:42.847: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:33:42.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.114 32554'
Jan 10 04:33:43.147: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.7.114 32554\nConnection to 172.31.7.114 32554 port [tcp/*] succeeded!\n"
Jan 10 04:33:43.147: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:33:43.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.15.218 32554'
Jan 10 04:33:43.322: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.15.218 32554\nConnection to 172.31.15.218 32554 port [tcp/*] succeeded!\n"
Jan 10 04:33:43.322: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:33:43.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.15.218:32554/ ; done'
Jan 10 04:33:43.702: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n"
Jan 10 04:33:43.702: INFO: stdout: "\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8"
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
Jan 10 04:33:43.702: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-5983, will wait for the garbage collector to delete the pods 01/10/23 04:33:43.762
Jan 10 04:33:43.892: INFO: Deleting ReplicationController affinity-nodeport took: 52.309175ms
Jan 10 04:33:44.193: INFO: Terminating ReplicationController affinity-nodeport pods took: 301.122046ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:33:46.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5983" for this suite. 01/10/23 04:33:46.637
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":206,"skipped":3481,"failed":0}
------------------------------
• [SLOW TEST] [10.384 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:33:36.262
    Jan 10 04:33:36.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:33:36.263
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:36.303
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:36.311
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-5983 01/10/23 04:33:36.322
    STEP: creating service affinity-nodeport in namespace services-5983 01/10/23 04:33:36.323
    STEP: creating replication controller affinity-nodeport in namespace services-5983 01/10/23 04:33:36.353
    I0110 04:33:36.384965      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5983, replica count: 3
    I0110 04:33:39.435679      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 04:33:39.443: INFO: Creating new exec pod
    Jan 10 04:33:39.450: INFO: Waiting up to 5m0s for pod "execpod-affinitycw5gb" in namespace "services-5983" to be "running"
    Jan 10 04:33:39.463: INFO: Pod "execpod-affinitycw5gb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.804404ms
    Jan 10 04:33:41.467: INFO: Pod "execpod-affinitycw5gb": Phase="Running", Reason="", readiness=true. Elapsed: 2.016169708s
    Jan 10 04:33:41.467: INFO: Pod "execpod-affinitycw5gb" satisfied condition "running"
    Jan 10 04:33:42.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Jan 10 04:33:42.644: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Jan 10 04:33:42.644: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:33:42.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.133.172 80'
    Jan 10 04:33:42.847: INFO: stderr: "+ nc -v -t -w 2 10.43.133.172 80\nConnection to 10.43.133.172 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Jan 10 04:33:42.847: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:33:42.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.114 32554'
    Jan 10 04:33:43.147: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.7.114 32554\nConnection to 172.31.7.114 32554 port [tcp/*] succeeded!\n"
    Jan 10 04:33:43.147: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:33:43.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.15.218 32554'
    Jan 10 04:33:43.322: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.15.218 32554\nConnection to 172.31.15.218 32554 port [tcp/*] succeeded!\n"
    Jan 10 04:33:43.322: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:33:43.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5983 exec execpod-affinitycw5gb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.15.218:32554/ ; done'
    Jan 10 04:33:43.702: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:32554/\n"
    Jan 10 04:33:43.702: INFO: stdout: "\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8\naffinity-nodeport-4glk8"
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Received response from host: affinity-nodeport-4glk8
    Jan 10 04:33:43.702: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-5983, will wait for the garbage collector to delete the pods 01/10/23 04:33:43.762
    Jan 10 04:33:43.892: INFO: Deleting ReplicationController affinity-nodeport took: 52.309175ms
    Jan 10 04:33:44.193: INFO: Terminating ReplicationController affinity-nodeport pods took: 301.122046ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:33:46.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5983" for this suite. 01/10/23 04:33:46.637
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:33:46.657
Jan 10 04:33:46.658: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:33:46.659
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:46.692
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:46.698
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 01/10/23 04:33:46.7
Jan 10 04:33:46.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134" in namespace "downward-api-9679" to be "Succeeded or Failed"
Jan 10 04:33:46.732: INFO: Pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134": Phase="Pending", Reason="", readiness=false. Elapsed: 17.92663ms
Jan 10 04:33:48.735: INFO: Pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020721359s
Jan 10 04:33:50.736: INFO: Pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022234838s
STEP: Saw pod success 01/10/23 04:33:50.736
Jan 10 04:33:50.736: INFO: Pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134" satisfied condition "Succeeded or Failed"
Jan 10 04:33:50.739: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134 container client-container: <nil>
STEP: delete the pod 01/10/23 04:33:50.756
Jan 10 04:33:50.765: INFO: Waiting for pod downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134 to disappear
Jan 10 04:33:50.768: INFO: Pod downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 04:33:50.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9679" for this suite. 01/10/23 04:33:50.772
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":207,"skipped":3497,"failed":0}
------------------------------
• [4.119 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:33:46.657
    Jan 10 04:33:46.658: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:33:46.659
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:46.692
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:46.698
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 01/10/23 04:33:46.7
    Jan 10 04:33:46.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134" in namespace "downward-api-9679" to be "Succeeded or Failed"
    Jan 10 04:33:46.732: INFO: Pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134": Phase="Pending", Reason="", readiness=false. Elapsed: 17.92663ms
    Jan 10 04:33:48.735: INFO: Pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020721359s
    Jan 10 04:33:50.736: INFO: Pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022234838s
    STEP: Saw pod success 01/10/23 04:33:50.736
    Jan 10 04:33:50.736: INFO: Pod "downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134" satisfied condition "Succeeded or Failed"
    Jan 10 04:33:50.739: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134 container client-container: <nil>
    STEP: delete the pod 01/10/23 04:33:50.756
    Jan 10 04:33:50.765: INFO: Waiting for pod downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134 to disappear
    Jan 10 04:33:50.768: INFO: Pod downwardapi-volume-6bb73818-2e25-42b2-965f-da36f3f4f134 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 04:33:50.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9679" for this suite. 01/10/23 04:33:50.772
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:33:50.792
Jan 10 04:33:50.793: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:33:50.793
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:50.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:50.862
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-210 01/10/23 04:33:50.886
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[] 01/10/23 04:33:50.91
Jan 10 04:33:50.944: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Jan 10 04:33:51.955: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-210 01/10/23 04:33:51.955
Jan 10 04:33:51.960: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-210" to be "running and ready"
Jan 10 04:33:51.970: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.099839ms
Jan 10 04:33:51.970: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:33:53.974: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013262929s
Jan 10 04:33:53.974: INFO: The phase of Pod pod1 is Running (Ready = true)
Jan 10 04:33:53.974: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[pod1:[80]] 01/10/23 04:33:53.976
Jan 10 04:33:53.981: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 01/10/23 04:33:53.981
Jan 10 04:33:53.981: INFO: Creating new exec pod
Jan 10 04:33:53.990: INFO: Waiting up to 5m0s for pod "execpodxp7lw" in namespace "services-210" to be "running"
Jan 10 04:33:54.007: INFO: Pod "execpodxp7lw": Phase="Pending", Reason="", readiness=false. Elapsed: 17.243856ms
Jan 10 04:33:56.012: INFO: Pod "execpodxp7lw": Phase="Running", Reason="", readiness=true. Elapsed: 2.022194758s
Jan 10 04:33:56.012: INFO: Pod "execpodxp7lw" satisfied condition "running"
Jan 10 04:33:57.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jan 10 04:33:57.238: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jan 10 04:33:57.238: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:33:57.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.220.22 80'
Jan 10 04:33:57.384: INFO: stderr: "+ nc -v -t -w 2 10.43.220.22 80\nConnection to 10.43.220.22 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Jan 10 04:33:57.384: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-210 01/10/23 04:33:57.384
Jan 10 04:33:57.394: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-210" to be "running and ready"
Jan 10 04:33:57.410: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.061534ms
Jan 10 04:33:57.410: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:33:59.413: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.018806363s
Jan 10 04:33:59.413: INFO: The phase of Pod pod2 is Running (Ready = true)
Jan 10 04:33:59.413: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[pod1:[80] pod2:[80]] 01/10/23 04:33:59.415
Jan 10 04:33:59.422: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 01/10/23 04:33:59.422
Jan 10 04:34:00.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jan 10 04:34:00.585: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jan 10 04:34:00.585: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:34:00.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.220.22 80'
Jan 10 04:34:00.760: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.220.22 80\nConnection to 10.43.220.22 80 port [tcp/http] succeeded!\n"
Jan 10 04:34:00.760: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-210 01/10/23 04:34:00.76
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[pod2:[80]] 01/10/23 04:34:00.776
Jan 10 04:34:00.826: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 01/10/23 04:34:00.826
Jan 10 04:34:01.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jan 10 04:34:02.016: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jan 10 04:34:02.016: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:34:02.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.220.22 80'
Jan 10 04:34:02.279: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.220.22 80\nConnection to 10.43.220.22 80 port [tcp/http] succeeded!\n"
Jan 10 04:34:02.279: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-210 01/10/23 04:34:02.279
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[] 01/10/23 04:34:02.325
Jan 10 04:34:02.387: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:34:02.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-210" for this suite. 01/10/23 04:34:02.437
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":208,"skipped":3569,"failed":0}
------------------------------
• [SLOW TEST] [11.659 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:33:50.792
    Jan 10 04:33:50.793: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:33:50.793
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:33:50.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:33:50.862
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-210 01/10/23 04:33:50.886
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[] 01/10/23 04:33:50.91
    Jan 10 04:33:50.944: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
    Jan 10 04:33:51.955: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-210 01/10/23 04:33:51.955
    Jan 10 04:33:51.960: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-210" to be "running and ready"
    Jan 10 04:33:51.970: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.099839ms
    Jan 10 04:33:51.970: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:33:53.974: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013262929s
    Jan 10 04:33:53.974: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jan 10 04:33:53.974: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[pod1:[80]] 01/10/23 04:33:53.976
    Jan 10 04:33:53.981: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 01/10/23 04:33:53.981
    Jan 10 04:33:53.981: INFO: Creating new exec pod
    Jan 10 04:33:53.990: INFO: Waiting up to 5m0s for pod "execpodxp7lw" in namespace "services-210" to be "running"
    Jan 10 04:33:54.007: INFO: Pod "execpodxp7lw": Phase="Pending", Reason="", readiness=false. Elapsed: 17.243856ms
    Jan 10 04:33:56.012: INFO: Pod "execpodxp7lw": Phase="Running", Reason="", readiness=true. Elapsed: 2.022194758s
    Jan 10 04:33:56.012: INFO: Pod "execpodxp7lw" satisfied condition "running"
    Jan 10 04:33:57.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jan 10 04:33:57.238: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jan 10 04:33:57.238: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:33:57.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.220.22 80'
    Jan 10 04:33:57.384: INFO: stderr: "+ nc -v -t -w 2 10.43.220.22 80\nConnection to 10.43.220.22 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Jan 10 04:33:57.384: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-210 01/10/23 04:33:57.384
    Jan 10 04:33:57.394: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-210" to be "running and ready"
    Jan 10 04:33:57.410: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.061534ms
    Jan 10 04:33:57.410: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:33:59.413: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.018806363s
    Jan 10 04:33:59.413: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jan 10 04:33:59.413: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[pod1:[80] pod2:[80]] 01/10/23 04:33:59.415
    Jan 10 04:33:59.422: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 01/10/23 04:33:59.422
    Jan 10 04:34:00.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jan 10 04:34:00.585: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jan 10 04:34:00.585: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:34:00.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.220.22 80'
    Jan 10 04:34:00.760: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.220.22 80\nConnection to 10.43.220.22 80 port [tcp/http] succeeded!\n"
    Jan 10 04:34:00.760: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-210 01/10/23 04:34:00.76
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[pod2:[80]] 01/10/23 04:34:00.776
    Jan 10 04:34:00.826: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 01/10/23 04:34:00.826
    Jan 10 04:34:01.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jan 10 04:34:02.016: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jan 10 04:34:02.016: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:34:02.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-210 exec execpodxp7lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.220.22 80'
    Jan 10 04:34:02.279: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.220.22 80\nConnection to 10.43.220.22 80 port [tcp/http] succeeded!\n"
    Jan 10 04:34:02.279: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-210 01/10/23 04:34:02.279
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-210 to expose endpoints map[] 01/10/23 04:34:02.325
    Jan 10 04:34:02.387: INFO: successfully validated that service endpoint-test2 in namespace services-210 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:34:02.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-210" for this suite. 01/10/23 04:34:02.437
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:34:02.482
Jan 10 04:34:02.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename watch 01/10/23 04:34:02.488
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:02.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:02.525
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 01/10/23 04:34:02.538
STEP: creating a watch on configmaps with label B 01/10/23 04:34:02.539
STEP: creating a watch on configmaps with label A or B 01/10/23 04:34:02.546
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 01/10/23 04:34:02.548
Jan 10 04:34:02.553: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234731 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:34:02.553: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234731 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 01/10/23 04:34:02.553
Jan 10 04:34:02.566: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234733 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:34:02.566: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234733 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 01/10/23 04:34:02.566
Jan 10 04:34:02.573: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234734 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:34:02.573: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234734 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 01/10/23 04:34:02.574
Jan 10 04:34:02.577: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234735 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:34:02.578: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234735 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 01/10/23 04:34:02.578
Jan 10 04:34:02.582: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6728  ed79c710-58dc-436f-a02e-24bf4021e3ff 234736 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:34:02.582: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6728  ed79c710-58dc-436f-a02e-24bf4021e3ff 234736 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 01/10/23 04:34:12.582
Jan 10 04:34:12.588: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6728  ed79c710-58dc-436f-a02e-24bf4021e3ff 234793 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:34:12.588: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6728  ed79c710-58dc-436f-a02e-24bf4021e3ff 234793 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 10 04:34:22.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6728" for this suite. 01/10/23 04:34:22.592
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":209,"skipped":3594,"failed":0}
------------------------------
• [SLOW TEST] [20.114 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:34:02.482
    Jan 10 04:34:02.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename watch 01/10/23 04:34:02.488
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:02.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:02.525
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 01/10/23 04:34:02.538
    STEP: creating a watch on configmaps with label B 01/10/23 04:34:02.539
    STEP: creating a watch on configmaps with label A or B 01/10/23 04:34:02.546
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 01/10/23 04:34:02.548
    Jan 10 04:34:02.553: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234731 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:34:02.553: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234731 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 01/10/23 04:34:02.553
    Jan 10 04:34:02.566: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234733 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:34:02.566: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234733 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 01/10/23 04:34:02.566
    Jan 10 04:34:02.573: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234734 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:34:02.573: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234734 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 01/10/23 04:34:02.574
    Jan 10 04:34:02.577: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234735 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:34:02.578: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6728  cac3cb6d-4400-40fb-b902-f80258f6b2a7 234735 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 01/10/23 04:34:02.578
    Jan 10 04:34:02.582: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6728  ed79c710-58dc-436f-a02e-24bf4021e3ff 234736 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:34:02.582: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6728  ed79c710-58dc-436f-a02e-24bf4021e3ff 234736 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 01/10/23 04:34:12.582
    Jan 10 04:34:12.588: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6728  ed79c710-58dc-436f-a02e-24bf4021e3ff 234793 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:34:12.588: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6728  ed79c710-58dc-436f-a02e-24bf4021e3ff 234793 0 2023-01-10 04:34:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-10 04:34:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 10 04:34:22.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-6728" for this suite. 01/10/23 04:34:22.592
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:34:22.599
Jan 10 04:34:22.599: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:34:22.6
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:22.623
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:22.63
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 01/10/23 04:34:22.635
Jan 10 04:34:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:34:26.834: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:34:41.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8680" for this suite. 01/10/23 04:34:41.444
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":210,"skipped":3597,"failed":0}
------------------------------
• [SLOW TEST] [18.850 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:34:22.599
    Jan 10 04:34:22.599: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:34:22.6
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:22.623
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:22.63
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 01/10/23 04:34:22.635
    Jan 10 04:34:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:34:26.834: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:34:41.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8680" for this suite. 01/10/23 04:34:41.444
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:34:41.451
Jan 10 04:34:41.451: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubelet-test 01/10/23 04:34:41.452
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:41.48
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:41.485
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Jan 10 04:34:41.511: INFO: Waiting up to 5m0s for pod "busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437" in namespace "kubelet-test-9941" to be "running and ready"
Jan 10 04:34:41.526: INFO: Pod "busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437": Phase="Pending", Reason="", readiness=false. Elapsed: 14.624619ms
Jan 10 04:34:41.526: INFO: The phase of Pod busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:34:43.531: INFO: Pod "busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437": Phase="Running", Reason="", readiness=true. Elapsed: 2.020252318s
Jan 10 04:34:43.533: INFO: The phase of Pod busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437 is Running (Ready = true)
Jan 10 04:34:43.533: INFO: Pod "busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 10 04:34:43.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9941" for this suite. 01/10/23 04:34:43.553
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":211,"skipped":3623,"failed":0}
------------------------------
• [2.107 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:34:41.451
    Jan 10 04:34:41.451: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubelet-test 01/10/23 04:34:41.452
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:41.48
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:41.485
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Jan 10 04:34:41.511: INFO: Waiting up to 5m0s for pod "busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437" in namespace "kubelet-test-9941" to be "running and ready"
    Jan 10 04:34:41.526: INFO: Pod "busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437": Phase="Pending", Reason="", readiness=false. Elapsed: 14.624619ms
    Jan 10 04:34:41.526: INFO: The phase of Pod busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:34:43.531: INFO: Pod "busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437": Phase="Running", Reason="", readiness=true. Elapsed: 2.020252318s
    Jan 10 04:34:43.533: INFO: The phase of Pod busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437 is Running (Ready = true)
    Jan 10 04:34:43.533: INFO: Pod "busybox-scheduling-70154960-efde-4f08-bc23-6de4fdce1437" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 10 04:34:43.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9941" for this suite. 01/10/23 04:34:43.553
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:34:43.56
Jan 10 04:34:43.561: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:34:43.561
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:43.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:43.583
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-4cca11b4-a4d7-4198-863b-1975fa2862fa 01/10/23 04:34:43.642
STEP: Creating the pod 01/10/23 04:34:43.647
Jan 10 04:34:43.659: INFO: Waiting up to 5m0s for pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781" in namespace "configmap-9557" to be "running"
Jan 10 04:34:43.667: INFO: Pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781": Phase="Pending", Reason="", readiness=false. Elapsed: 8.098736ms
Jan 10 04:34:45.670: INFO: Pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011606905s
Jan 10 04:34:47.670: INFO: Pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781": Phase="Running", Reason="", readiness=false. Elapsed: 4.010834787s
Jan 10 04:34:47.670: INFO: Pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781" satisfied condition "running"
STEP: Waiting for pod with text data 01/10/23 04:34:47.67
STEP: Waiting for pod with binary data 01/10/23 04:34:47.676
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:34:47.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9557" for this suite. 01/10/23 04:34:47.686
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":212,"skipped":3627,"failed":0}
------------------------------
• [4.132 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:34:43.56
    Jan 10 04:34:43.561: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:34:43.561
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:43.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:43.583
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-4cca11b4-a4d7-4198-863b-1975fa2862fa 01/10/23 04:34:43.642
    STEP: Creating the pod 01/10/23 04:34:43.647
    Jan 10 04:34:43.659: INFO: Waiting up to 5m0s for pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781" in namespace "configmap-9557" to be "running"
    Jan 10 04:34:43.667: INFO: Pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781": Phase="Pending", Reason="", readiness=false. Elapsed: 8.098736ms
    Jan 10 04:34:45.670: INFO: Pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011606905s
    Jan 10 04:34:47.670: INFO: Pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781": Phase="Running", Reason="", readiness=false. Elapsed: 4.010834787s
    Jan 10 04:34:47.670: INFO: Pod "pod-configmaps-909b76a8-aa95-49d0-822a-fb02d9bad781" satisfied condition "running"
    STEP: Waiting for pod with text data 01/10/23 04:34:47.67
    STEP: Waiting for pod with binary data 01/10/23 04:34:47.676
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:34:47.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9557" for this suite. 01/10/23 04:34:47.686
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:34:47.693
Jan 10 04:34:47.693: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:34:47.694
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:47.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:47.72
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-2790597b-dd78-45d0-a440-6598c2515aa4 01/10/23 04:34:47.727
STEP: Creating a pod to test consume configMaps 01/10/23 04:34:47.732
Jan 10 04:34:47.744: INFO: Waiting up to 5m0s for pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e" in namespace "configmap-1488" to be "Succeeded or Failed"
Jan 10 04:34:47.766: INFO: Pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.150587ms
Jan 10 04:34:49.770: INFO: Pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025249907s
Jan 10 04:34:51.770: INFO: Pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025579876s
STEP: Saw pod success 01/10/23 04:34:51.77
Jan 10 04:34:51.770: INFO: Pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e" satisfied condition "Succeeded or Failed"
Jan 10 04:34:51.773: INFO: Trying to get logs from node cncf-wk3 pod pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:34:51.79
Jan 10 04:34:51.802: INFO: Waiting for pod pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e to disappear
Jan 10 04:34:51.805: INFO: Pod pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:34:51.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1488" for this suite. 01/10/23 04:34:51.808
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":213,"skipped":3630,"failed":0}
------------------------------
• [4.124 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:34:47.693
    Jan 10 04:34:47.693: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:34:47.694
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:47.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:47.72
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-2790597b-dd78-45d0-a440-6598c2515aa4 01/10/23 04:34:47.727
    STEP: Creating a pod to test consume configMaps 01/10/23 04:34:47.732
    Jan 10 04:34:47.744: INFO: Waiting up to 5m0s for pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e" in namespace "configmap-1488" to be "Succeeded or Failed"
    Jan 10 04:34:47.766: INFO: Pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.150587ms
    Jan 10 04:34:49.770: INFO: Pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025249907s
    Jan 10 04:34:51.770: INFO: Pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025579876s
    STEP: Saw pod success 01/10/23 04:34:51.77
    Jan 10 04:34:51.770: INFO: Pod "pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e" satisfied condition "Succeeded or Failed"
    Jan 10 04:34:51.773: INFO: Trying to get logs from node cncf-wk3 pod pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:34:51.79
    Jan 10 04:34:51.802: INFO: Waiting for pod pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e to disappear
    Jan 10 04:34:51.805: INFO: Pod pod-configmaps-b56e8ee5-7526-4329-8de4-6c9c99a94a4e no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:34:51.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1488" for this suite. 01/10/23 04:34:51.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:34:51.819
Jan 10 04:34:51.819: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-preemption 01/10/23 04:34:51.82
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:51.848
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:51.852
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jan 10 04:34:51.882: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 10 04:35:51.911: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:35:51.914
Jan 10 04:35:51.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-preemption-path 01/10/23 04:35:51.915
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:35:51.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:35:51.945
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Jan 10 04:35:51.975: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Jan 10 04:35:51.980: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Jan 10 04:35:52.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-1705" for this suite. 01/10/23 04:35:52.016
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:35:52.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-323" for this suite. 01/10/23 04:35:52.045
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":214,"skipped":3680,"failed":0}
------------------------------
• [SLOW TEST] [60.308 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:34:51.819
    Jan 10 04:34:51.819: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-preemption 01/10/23 04:34:51.82
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:34:51.848
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:34:51.852
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jan 10 04:34:51.882: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 10 04:35:51.911: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:35:51.914
    Jan 10 04:35:51.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-preemption-path 01/10/23 04:35:51.915
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:35:51.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:35:51.945
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Jan 10 04:35:51.975: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Jan 10 04:35:51.980: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Jan 10 04:35:52.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-1705" for this suite. 01/10/23 04:35:52.016
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:35:52.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-323" for this suite. 01/10/23 04:35:52.045
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:35:52.13
Jan 10 04:35:52.130: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:35:52.132
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:35:52.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:35:52.168
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-127bd767-b8b1-4ed1-b427-790f1a158683 01/10/23 04:35:52.178
STEP: Creating a pod to test consume configMaps 01/10/23 04:35:52.187
Jan 10 04:35:52.197: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050" in namespace "projected-460" to be "Succeeded or Failed"
Jan 10 04:35:52.215: INFO: Pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050": Phase="Pending", Reason="", readiness=false. Elapsed: 17.25023ms
Jan 10 04:35:54.218: INFO: Pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020759747s
Jan 10 04:35:56.219: INFO: Pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021396198s
STEP: Saw pod success 01/10/23 04:35:56.219
Jan 10 04:35:56.219: INFO: Pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050" satisfied condition "Succeeded or Failed"
Jan 10 04:35:56.225: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:35:56.231
Jan 10 04:35:56.254: INFO: Waiting for pod pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050 to disappear
Jan 10 04:35:56.274: INFO: Pod pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 04:35:56.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-460" for this suite. 01/10/23 04:35:56.282
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":215,"skipped":3681,"failed":0}
------------------------------
• [4.171 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:35:52.13
    Jan 10 04:35:52.130: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:35:52.132
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:35:52.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:35:52.168
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-127bd767-b8b1-4ed1-b427-790f1a158683 01/10/23 04:35:52.178
    STEP: Creating a pod to test consume configMaps 01/10/23 04:35:52.187
    Jan 10 04:35:52.197: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050" in namespace "projected-460" to be "Succeeded or Failed"
    Jan 10 04:35:52.215: INFO: Pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050": Phase="Pending", Reason="", readiness=false. Elapsed: 17.25023ms
    Jan 10 04:35:54.218: INFO: Pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020759747s
    Jan 10 04:35:56.219: INFO: Pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021396198s
    STEP: Saw pod success 01/10/23 04:35:56.219
    Jan 10 04:35:56.219: INFO: Pod "pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050" satisfied condition "Succeeded or Failed"
    Jan 10 04:35:56.225: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:35:56.231
    Jan 10 04:35:56.254: INFO: Waiting for pod pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050 to disappear
    Jan 10 04:35:56.274: INFO: Pod pod-projected-configmaps-f94c313d-50da-452a-a039-825eda1b1050 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 04:35:56.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-460" for this suite. 01/10/23 04:35:56.282
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:35:56.301
Jan 10 04:35:56.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:35:56.303
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:35:56.394
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:35:56.405
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-d1083650-8ca5-4c10-8b0b-0f5b20cc56bc 01/10/23 04:35:56.425
STEP: Creating a pod to test consume secrets 01/10/23 04:35:56.469
Jan 10 04:35:56.513: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00" in namespace "projected-2117" to be "Succeeded or Failed"
Jan 10 04:35:56.586: INFO: Pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00": Phase="Pending", Reason="", readiness=false. Elapsed: 72.888337ms
Jan 10 04:35:58.590: INFO: Pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076413803s
Jan 10 04:36:00.591: INFO: Pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077057976s
STEP: Saw pod success 01/10/23 04:36:00.591
Jan 10 04:36:00.591: INFO: Pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00" satisfied condition "Succeeded or Failed"
Jan 10 04:36:00.593: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00 container projected-secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:36:00.599
Jan 10 04:36:00.607: INFO: Waiting for pod pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00 to disappear
Jan 10 04:36:00.613: INFO: Pod pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 10 04:36:00.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2117" for this suite. 01/10/23 04:36:00.615
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":216,"skipped":3681,"failed":0}
------------------------------
• [4.324 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:35:56.301
    Jan 10 04:35:56.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:35:56.303
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:35:56.394
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:35:56.405
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-d1083650-8ca5-4c10-8b0b-0f5b20cc56bc 01/10/23 04:35:56.425
    STEP: Creating a pod to test consume secrets 01/10/23 04:35:56.469
    Jan 10 04:35:56.513: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00" in namespace "projected-2117" to be "Succeeded or Failed"
    Jan 10 04:35:56.586: INFO: Pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00": Phase="Pending", Reason="", readiness=false. Elapsed: 72.888337ms
    Jan 10 04:35:58.590: INFO: Pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076413803s
    Jan 10 04:36:00.591: INFO: Pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077057976s
    STEP: Saw pod success 01/10/23 04:36:00.591
    Jan 10 04:36:00.591: INFO: Pod "pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00" satisfied condition "Succeeded or Failed"
    Jan 10 04:36:00.593: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00 container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:36:00.599
    Jan 10 04:36:00.607: INFO: Waiting for pod pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00 to disappear
    Jan 10 04:36:00.613: INFO: Pod pod-projected-secrets-b73f0430-02ca-4408-9639-0813504d3d00 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 10 04:36:00.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2117" for this suite. 01/10/23 04:36:00.615
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:36:00.627
Jan 10 04:36:00.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename job 01/10/23 04:36:00.628
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:36:00.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:36:00.656
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 01/10/23 04:36:00.659
STEP: Ensuring active pods == parallelism 01/10/23 04:36:00.663
STEP: Orphaning one of the Job's Pods 01/10/23 04:36:02.667
Jan 10 04:36:03.242: INFO: Successfully updated pod "adopt-release-bxpfr"
STEP: Checking that the Job readopts the Pod 01/10/23 04:36:03.242
Jan 10 04:36:03.242: INFO: Waiting up to 15m0s for pod "adopt-release-bxpfr" in namespace "job-9004" to be "adopted"
Jan 10 04:36:03.274: INFO: Pod "adopt-release-bxpfr": Phase="Running", Reason="", readiness=true. Elapsed: 31.989341ms
Jan 10 04:36:05.278: INFO: Pod "adopt-release-bxpfr": Phase="Running", Reason="", readiness=true. Elapsed: 2.036441825s
Jan 10 04:36:05.278: INFO: Pod "adopt-release-bxpfr" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 01/10/23 04:36:05.278
Jan 10 04:36:05.790: INFO: Successfully updated pod "adopt-release-bxpfr"
STEP: Checking that the Job releases the Pod 01/10/23 04:36:05.79
Jan 10 04:36:05.790: INFO: Waiting up to 15m0s for pod "adopt-release-bxpfr" in namespace "job-9004" to be "released"
Jan 10 04:36:05.794: INFO: Pod "adopt-release-bxpfr": Phase="Running", Reason="", readiness=true. Elapsed: 4.187255ms
Jan 10 04:36:07.800: INFO: Pod "adopt-release-bxpfr": Phase="Running", Reason="", readiness=true. Elapsed: 2.010009316s
Jan 10 04:36:07.800: INFO: Pod "adopt-release-bxpfr" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 10 04:36:07.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9004" for this suite. 01/10/23 04:36:07.818
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":217,"skipped":3681,"failed":0}
------------------------------
• [SLOW TEST] [7.207 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:36:00.627
    Jan 10 04:36:00.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename job 01/10/23 04:36:00.628
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:36:00.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:36:00.656
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 01/10/23 04:36:00.659
    STEP: Ensuring active pods == parallelism 01/10/23 04:36:00.663
    STEP: Orphaning one of the Job's Pods 01/10/23 04:36:02.667
    Jan 10 04:36:03.242: INFO: Successfully updated pod "adopt-release-bxpfr"
    STEP: Checking that the Job readopts the Pod 01/10/23 04:36:03.242
    Jan 10 04:36:03.242: INFO: Waiting up to 15m0s for pod "adopt-release-bxpfr" in namespace "job-9004" to be "adopted"
    Jan 10 04:36:03.274: INFO: Pod "adopt-release-bxpfr": Phase="Running", Reason="", readiness=true. Elapsed: 31.989341ms
    Jan 10 04:36:05.278: INFO: Pod "adopt-release-bxpfr": Phase="Running", Reason="", readiness=true. Elapsed: 2.036441825s
    Jan 10 04:36:05.278: INFO: Pod "adopt-release-bxpfr" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 01/10/23 04:36:05.278
    Jan 10 04:36:05.790: INFO: Successfully updated pod "adopt-release-bxpfr"
    STEP: Checking that the Job releases the Pod 01/10/23 04:36:05.79
    Jan 10 04:36:05.790: INFO: Waiting up to 15m0s for pod "adopt-release-bxpfr" in namespace "job-9004" to be "released"
    Jan 10 04:36:05.794: INFO: Pod "adopt-release-bxpfr": Phase="Running", Reason="", readiness=true. Elapsed: 4.187255ms
    Jan 10 04:36:07.800: INFO: Pod "adopt-release-bxpfr": Phase="Running", Reason="", readiness=true. Elapsed: 2.010009316s
    Jan 10 04:36:07.800: INFO: Pod "adopt-release-bxpfr" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 10 04:36:07.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9004" for this suite. 01/10/23 04:36:07.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:36:07.834
Jan 10 04:36:07.835: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-runtime 01/10/23 04:36:07.836
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:36:07.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:36:07.869
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 01/10/23 04:36:07.886
STEP: wait for the container to reach Succeeded 01/10/23 04:36:07.909
STEP: get the container status 01/10/23 04:36:11.954
STEP: the container should be terminated 01/10/23 04:36:11.966
STEP: the termination message should be set 01/10/23 04:36:11.967
Jan 10 04:36:11.967: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 01/10/23 04:36:11.967
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 10 04:36:12.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8267" for this suite. 01/10/23 04:36:12.012
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":218,"skipped":3688,"failed":0}
------------------------------
• [4.199 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:36:07.834
    Jan 10 04:36:07.835: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-runtime 01/10/23 04:36:07.836
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:36:07.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:36:07.869
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 01/10/23 04:36:07.886
    STEP: wait for the container to reach Succeeded 01/10/23 04:36:07.909
    STEP: get the container status 01/10/23 04:36:11.954
    STEP: the container should be terminated 01/10/23 04:36:11.966
    STEP: the termination message should be set 01/10/23 04:36:11.967
    Jan 10 04:36:11.967: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 01/10/23 04:36:11.967
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 10 04:36:12.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8267" for this suite. 01/10/23 04:36:12.012
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:36:12.053
Jan 10 04:36:12.053: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:36:12.056
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:36:12.164
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:36:12.221
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:36:12.347
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:36:13.361
STEP: Deploying the webhook pod 01/10/23 04:36:13.367
STEP: Wait for the deployment to be ready 01/10/23 04:36:13.379
Jan 10 04:36:13.384: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 01/10/23 04:36:15.391
STEP: Verifying the service has paired with the endpoint 01/10/23 04:36:15.398
Jan 10 04:36:16.398: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 01/10/23 04:36:16.4
Jan 10 04:36:16.412: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 04:36:16.521
STEP: Updating a validating webhook configuration's rules to not include the create operation 01/10/23 04:36:16.529
STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 04:36:16.539
STEP: Patching a validating webhook configuration's rules to include the create operation 01/10/23 04:36:16.553
STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 04:36:16.559
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:36:16.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5420" for this suite. 01/10/23 04:36:16.684
STEP: Destroying namespace "webhook-5420-markers" for this suite. 01/10/23 04:36:16.694
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":219,"skipped":3694,"failed":0}
------------------------------
• [4.738 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:36:12.053
    Jan 10 04:36:12.053: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:36:12.056
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:36:12.164
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:36:12.221
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:36:12.347
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:36:13.361
    STEP: Deploying the webhook pod 01/10/23 04:36:13.367
    STEP: Wait for the deployment to be ready 01/10/23 04:36:13.379
    Jan 10 04:36:13.384: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 01/10/23 04:36:15.391
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:36:15.398
    Jan 10 04:36:16.398: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 01/10/23 04:36:16.4
    Jan 10 04:36:16.412: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 04:36:16.521
    STEP: Updating a validating webhook configuration's rules to not include the create operation 01/10/23 04:36:16.529
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 04:36:16.539
    STEP: Patching a validating webhook configuration's rules to include the create operation 01/10/23 04:36:16.553
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/10/23 04:36:16.559
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:36:16.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5420" for this suite. 01/10/23 04:36:16.684
    STEP: Destroying namespace "webhook-5420-markers" for this suite. 01/10/23 04:36:16.694
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:36:16.791
Jan 10 04:36:16.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename gc 01/10/23 04:36:16.792
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:36:16.856
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:36:16.861
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 01/10/23 04:36:16.871
STEP: delete the rc 01/10/23 04:36:26.984
STEP: wait for the rc to be deleted 01/10/23 04:36:27.34
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 01/10/23 04:36:32.43
STEP: Gathering metrics 01/10/23 04:37:02.455
W0110 04:37:02.461423      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 10 04:37:02.461: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Jan 10 04:37:02.461: INFO: Deleting pod "simpletest.rc-2h6ck" in namespace "gc-4791"
Jan 10 04:37:02.525: INFO: Deleting pod "simpletest.rc-2n644" in namespace "gc-4791"
Jan 10 04:37:02.559: INFO: Deleting pod "simpletest.rc-2rddk" in namespace "gc-4791"
Jan 10 04:37:02.607: INFO: Deleting pod "simpletest.rc-44sg8" in namespace "gc-4791"
Jan 10 04:37:02.643: INFO: Deleting pod "simpletest.rc-45s2m" in namespace "gc-4791"
Jan 10 04:37:02.695: INFO: Deleting pod "simpletest.rc-482d8" in namespace "gc-4791"
Jan 10 04:37:02.745: INFO: Deleting pod "simpletest.rc-4cjdx" in namespace "gc-4791"
Jan 10 04:37:02.821: INFO: Deleting pod "simpletest.rc-4p8kp" in namespace "gc-4791"
Jan 10 04:37:02.910: INFO: Deleting pod "simpletest.rc-4v6jr" in namespace "gc-4791"
Jan 10 04:37:03.058: INFO: Deleting pod "simpletest.rc-52gc5" in namespace "gc-4791"
Jan 10 04:37:03.212: INFO: Deleting pod "simpletest.rc-5fdpw" in namespace "gc-4791"
Jan 10 04:37:03.350: INFO: Deleting pod "simpletest.rc-5lhjj" in namespace "gc-4791"
Jan 10 04:37:03.406: INFO: Deleting pod "simpletest.rc-5wk2q" in namespace "gc-4791"
Jan 10 04:37:03.440: INFO: Deleting pod "simpletest.rc-66mjm" in namespace "gc-4791"
Jan 10 04:37:03.458: INFO: Deleting pod "simpletest.rc-67sl6" in namespace "gc-4791"
Jan 10 04:37:03.487: INFO: Deleting pod "simpletest.rc-6xnbw" in namespace "gc-4791"
Jan 10 04:37:03.518: INFO: Deleting pod "simpletest.rc-76zhf" in namespace "gc-4791"
Jan 10 04:37:03.573: INFO: Deleting pod "simpletest.rc-7hw25" in namespace "gc-4791"
Jan 10 04:37:03.681: INFO: Deleting pod "simpletest.rc-7lt8m" in namespace "gc-4791"
Jan 10 04:37:03.838: INFO: Deleting pod "simpletest.rc-7n4qb" in namespace "gc-4791"
Jan 10 04:37:03.876: INFO: Deleting pod "simpletest.rc-85rhq" in namespace "gc-4791"
Jan 10 04:37:03.918: INFO: Deleting pod "simpletest.rc-87z8h" in namespace "gc-4791"
Jan 10 04:37:03.974: INFO: Deleting pod "simpletest.rc-8dhvd" in namespace "gc-4791"
Jan 10 04:37:04.000: INFO: Deleting pod "simpletest.rc-8wg8q" in namespace "gc-4791"
Jan 10 04:37:04.132: INFO: Deleting pod "simpletest.rc-9fh9p" in namespace "gc-4791"
Jan 10 04:37:04.312: INFO: Deleting pod "simpletest.rc-9gmkv" in namespace "gc-4791"
Jan 10 04:37:04.349: INFO: Deleting pod "simpletest.rc-9lwps" in namespace "gc-4791"
Jan 10 04:37:04.413: INFO: Deleting pod "simpletest.rc-9tjrr" in namespace "gc-4791"
Jan 10 04:37:04.578: INFO: Deleting pod "simpletest.rc-bc8zc" in namespace "gc-4791"
Jan 10 04:37:04.647: INFO: Deleting pod "simpletest.rc-bkxsl" in namespace "gc-4791"
Jan 10 04:37:04.739: INFO: Deleting pod "simpletest.rc-bmpk6" in namespace "gc-4791"
Jan 10 04:37:04.817: INFO: Deleting pod "simpletest.rc-c2wmj" in namespace "gc-4791"
Jan 10 04:37:04.872: INFO: Deleting pod "simpletest.rc-c7lnh" in namespace "gc-4791"
Jan 10 04:37:04.939: INFO: Deleting pod "simpletest.rc-c8vzd" in namespace "gc-4791"
Jan 10 04:37:04.981: INFO: Deleting pod "simpletest.rc-cmbsb" in namespace "gc-4791"
Jan 10 04:37:05.043: INFO: Deleting pod "simpletest.rc-cwdl7" in namespace "gc-4791"
Jan 10 04:37:05.074: INFO: Deleting pod "simpletest.rc-d4kdt" in namespace "gc-4791"
Jan 10 04:37:05.107: INFO: Deleting pod "simpletest.rc-d8bxj" in namespace "gc-4791"
Jan 10 04:37:05.187: INFO: Deleting pod "simpletest.rc-d8xwp" in namespace "gc-4791"
Jan 10 04:37:05.267: INFO: Deleting pod "simpletest.rc-d995p" in namespace "gc-4791"
Jan 10 04:37:05.306: INFO: Deleting pod "simpletest.rc-dk84l" in namespace "gc-4791"
Jan 10 04:37:05.352: INFO: Deleting pod "simpletest.rc-dz6g2" in namespace "gc-4791"
Jan 10 04:37:05.454: INFO: Deleting pod "simpletest.rc-f5zrj" in namespace "gc-4791"
Jan 10 04:37:05.497: INFO: Deleting pod "simpletest.rc-fkfj8" in namespace "gc-4791"
Jan 10 04:37:05.563: INFO: Deleting pod "simpletest.rc-g59x2" in namespace "gc-4791"
Jan 10 04:37:05.636: INFO: Deleting pod "simpletest.rc-g8b4k" in namespace "gc-4791"
Jan 10 04:37:05.712: INFO: Deleting pod "simpletest.rc-ggkz8" in namespace "gc-4791"
Jan 10 04:37:05.765: INFO: Deleting pod "simpletest.rc-h5bft" in namespace "gc-4791"
Jan 10 04:37:05.782: INFO: Deleting pod "simpletest.rc-h5tbh" in namespace "gc-4791"
Jan 10 04:37:05.830: INFO: Deleting pod "simpletest.rc-h6n2q" in namespace "gc-4791"
Jan 10 04:37:05.844: INFO: Deleting pod "simpletest.rc-h8hgq" in namespace "gc-4791"
Jan 10 04:37:05.904: INFO: Deleting pod "simpletest.rc-hf6z4" in namespace "gc-4791"
Jan 10 04:37:05.976: INFO: Deleting pod "simpletest.rc-hlcqg" in namespace "gc-4791"
Jan 10 04:37:05.993: INFO: Deleting pod "simpletest.rc-hrzwj" in namespace "gc-4791"
Jan 10 04:37:06.042: INFO: Deleting pod "simpletest.rc-j8vxk" in namespace "gc-4791"
Jan 10 04:37:06.098: INFO: Deleting pod "simpletest.rc-jv9wc" in namespace "gc-4791"
Jan 10 04:37:06.129: INFO: Deleting pod "simpletest.rc-k248b" in namespace "gc-4791"
Jan 10 04:37:06.206: INFO: Deleting pod "simpletest.rc-knhcv" in namespace "gc-4791"
Jan 10 04:37:06.316: INFO: Deleting pod "simpletest.rc-kzhbw" in namespace "gc-4791"
Jan 10 04:37:06.344: INFO: Deleting pod "simpletest.rc-lgbs7" in namespace "gc-4791"
Jan 10 04:37:06.388: INFO: Deleting pod "simpletest.rc-lwf8b" in namespace "gc-4791"
Jan 10 04:37:06.494: INFO: Deleting pod "simpletest.rc-m4v4p" in namespace "gc-4791"
Jan 10 04:37:06.539: INFO: Deleting pod "simpletest.rc-m6kc7" in namespace "gc-4791"
Jan 10 04:37:06.606: INFO: Deleting pod "simpletest.rc-mbd7s" in namespace "gc-4791"
Jan 10 04:37:06.741: INFO: Deleting pod "simpletest.rc-mdgrr" in namespace "gc-4791"
Jan 10 04:37:06.853: INFO: Deleting pod "simpletest.rc-mp749" in namespace "gc-4791"
Jan 10 04:37:06.975: INFO: Deleting pod "simpletest.rc-mrwfg" in namespace "gc-4791"
Jan 10 04:37:07.111: INFO: Deleting pod "simpletest.rc-mswdv" in namespace "gc-4791"
Jan 10 04:37:07.208: INFO: Deleting pod "simpletest.rc-n46ng" in namespace "gc-4791"
Jan 10 04:37:07.282: INFO: Deleting pod "simpletest.rc-n4f2w" in namespace "gc-4791"
Jan 10 04:37:07.410: INFO: Deleting pod "simpletest.rc-pmfl2" in namespace "gc-4791"
Jan 10 04:37:07.565: INFO: Deleting pod "simpletest.rc-prjlx" in namespace "gc-4791"
Jan 10 04:37:07.672: INFO: Deleting pod "simpletest.rc-px6xp" in namespace "gc-4791"
Jan 10 04:37:07.709: INFO: Deleting pod "simpletest.rc-pxjsv" in namespace "gc-4791"
Jan 10 04:37:07.885: INFO: Deleting pod "simpletest.rc-pzqjz" in namespace "gc-4791"
Jan 10 04:37:07.956: INFO: Deleting pod "simpletest.rc-q9hvg" in namespace "gc-4791"
Jan 10 04:37:08.008: INFO: Deleting pod "simpletest.rc-r8vhb" in namespace "gc-4791"
Jan 10 04:37:08.033: INFO: Deleting pod "simpletest.rc-rq86r" in namespace "gc-4791"
Jan 10 04:37:08.109: INFO: Deleting pod "simpletest.rc-s78tk" in namespace "gc-4791"
Jan 10 04:37:08.223: INFO: Deleting pod "simpletest.rc-sjk9x" in namespace "gc-4791"
Jan 10 04:37:08.365: INFO: Deleting pod "simpletest.rc-sktz9" in namespace "gc-4791"
Jan 10 04:37:08.444: INFO: Deleting pod "simpletest.rc-snplj" in namespace "gc-4791"
Jan 10 04:37:08.490: INFO: Deleting pod "simpletest.rc-sshm7" in namespace "gc-4791"
Jan 10 04:37:08.560: INFO: Deleting pod "simpletest.rc-t25rx" in namespace "gc-4791"
Jan 10 04:37:08.644: INFO: Deleting pod "simpletest.rc-tpb9h" in namespace "gc-4791"
Jan 10 04:37:08.751: INFO: Deleting pod "simpletest.rc-vd687" in namespace "gc-4791"
Jan 10 04:37:08.897: INFO: Deleting pod "simpletest.rc-vhbxl" in namespace "gc-4791"
Jan 10 04:37:08.935: INFO: Deleting pod "simpletest.rc-vntl9" in namespace "gc-4791"
Jan 10 04:37:09.039: INFO: Deleting pod "simpletest.rc-whck7" in namespace "gc-4791"
Jan 10 04:37:09.157: INFO: Deleting pod "simpletest.rc-wnhgf" in namespace "gc-4791"
Jan 10 04:37:09.255: INFO: Deleting pod "simpletest.rc-wtlgt" in namespace "gc-4791"
Jan 10 04:37:09.365: INFO: Deleting pod "simpletest.rc-wv4h5" in namespace "gc-4791"
Jan 10 04:37:09.446: INFO: Deleting pod "simpletest.rc-x98vv" in namespace "gc-4791"
Jan 10 04:37:09.549: INFO: Deleting pod "simpletest.rc-xj8qq" in namespace "gc-4791"
Jan 10 04:37:09.628: INFO: Deleting pod "simpletest.rc-xjl8t" in namespace "gc-4791"
Jan 10 04:37:09.687: INFO: Deleting pod "simpletest.rc-xz66p" in namespace "gc-4791"
Jan 10 04:37:09.788: INFO: Deleting pod "simpletest.rc-z4kjm" in namespace "gc-4791"
Jan 10 04:37:09.950: INFO: Deleting pod "simpletest.rc-zm7nc" in namespace "gc-4791"
Jan 10 04:37:10.167: INFO: Deleting pod "simpletest.rc-zp67n" in namespace "gc-4791"
Jan 10 04:37:10.231: INFO: Deleting pod "simpletest.rc-zzd6q" in namespace "gc-4791"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 10 04:37:10.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4791" for this suite. 01/10/23 04:37:10.333
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":220,"skipped":3695,"failed":0}
------------------------------
• [SLOW TEST] [53.569 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:36:16.791
    Jan 10 04:36:16.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename gc 01/10/23 04:36:16.792
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:36:16.856
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:36:16.861
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 01/10/23 04:36:16.871
    STEP: delete the rc 01/10/23 04:36:26.984
    STEP: wait for the rc to be deleted 01/10/23 04:36:27.34
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 01/10/23 04:36:32.43
    STEP: Gathering metrics 01/10/23 04:37:02.455
    W0110 04:37:02.461423      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 10 04:37:02.461: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Jan 10 04:37:02.461: INFO: Deleting pod "simpletest.rc-2h6ck" in namespace "gc-4791"
    Jan 10 04:37:02.525: INFO: Deleting pod "simpletest.rc-2n644" in namespace "gc-4791"
    Jan 10 04:37:02.559: INFO: Deleting pod "simpletest.rc-2rddk" in namespace "gc-4791"
    Jan 10 04:37:02.607: INFO: Deleting pod "simpletest.rc-44sg8" in namespace "gc-4791"
    Jan 10 04:37:02.643: INFO: Deleting pod "simpletest.rc-45s2m" in namespace "gc-4791"
    Jan 10 04:37:02.695: INFO: Deleting pod "simpletest.rc-482d8" in namespace "gc-4791"
    Jan 10 04:37:02.745: INFO: Deleting pod "simpletest.rc-4cjdx" in namespace "gc-4791"
    Jan 10 04:37:02.821: INFO: Deleting pod "simpletest.rc-4p8kp" in namespace "gc-4791"
    Jan 10 04:37:02.910: INFO: Deleting pod "simpletest.rc-4v6jr" in namespace "gc-4791"
    Jan 10 04:37:03.058: INFO: Deleting pod "simpletest.rc-52gc5" in namespace "gc-4791"
    Jan 10 04:37:03.212: INFO: Deleting pod "simpletest.rc-5fdpw" in namespace "gc-4791"
    Jan 10 04:37:03.350: INFO: Deleting pod "simpletest.rc-5lhjj" in namespace "gc-4791"
    Jan 10 04:37:03.406: INFO: Deleting pod "simpletest.rc-5wk2q" in namespace "gc-4791"
    Jan 10 04:37:03.440: INFO: Deleting pod "simpletest.rc-66mjm" in namespace "gc-4791"
    Jan 10 04:37:03.458: INFO: Deleting pod "simpletest.rc-67sl6" in namespace "gc-4791"
    Jan 10 04:37:03.487: INFO: Deleting pod "simpletest.rc-6xnbw" in namespace "gc-4791"
    Jan 10 04:37:03.518: INFO: Deleting pod "simpletest.rc-76zhf" in namespace "gc-4791"
    Jan 10 04:37:03.573: INFO: Deleting pod "simpletest.rc-7hw25" in namespace "gc-4791"
    Jan 10 04:37:03.681: INFO: Deleting pod "simpletest.rc-7lt8m" in namespace "gc-4791"
    Jan 10 04:37:03.838: INFO: Deleting pod "simpletest.rc-7n4qb" in namespace "gc-4791"
    Jan 10 04:37:03.876: INFO: Deleting pod "simpletest.rc-85rhq" in namespace "gc-4791"
    Jan 10 04:37:03.918: INFO: Deleting pod "simpletest.rc-87z8h" in namespace "gc-4791"
    Jan 10 04:37:03.974: INFO: Deleting pod "simpletest.rc-8dhvd" in namespace "gc-4791"
    Jan 10 04:37:04.000: INFO: Deleting pod "simpletest.rc-8wg8q" in namespace "gc-4791"
    Jan 10 04:37:04.132: INFO: Deleting pod "simpletest.rc-9fh9p" in namespace "gc-4791"
    Jan 10 04:37:04.312: INFO: Deleting pod "simpletest.rc-9gmkv" in namespace "gc-4791"
    Jan 10 04:37:04.349: INFO: Deleting pod "simpletest.rc-9lwps" in namespace "gc-4791"
    Jan 10 04:37:04.413: INFO: Deleting pod "simpletest.rc-9tjrr" in namespace "gc-4791"
    Jan 10 04:37:04.578: INFO: Deleting pod "simpletest.rc-bc8zc" in namespace "gc-4791"
    Jan 10 04:37:04.647: INFO: Deleting pod "simpletest.rc-bkxsl" in namespace "gc-4791"
    Jan 10 04:37:04.739: INFO: Deleting pod "simpletest.rc-bmpk6" in namespace "gc-4791"
    Jan 10 04:37:04.817: INFO: Deleting pod "simpletest.rc-c2wmj" in namespace "gc-4791"
    Jan 10 04:37:04.872: INFO: Deleting pod "simpletest.rc-c7lnh" in namespace "gc-4791"
    Jan 10 04:37:04.939: INFO: Deleting pod "simpletest.rc-c8vzd" in namespace "gc-4791"
    Jan 10 04:37:04.981: INFO: Deleting pod "simpletest.rc-cmbsb" in namespace "gc-4791"
    Jan 10 04:37:05.043: INFO: Deleting pod "simpletest.rc-cwdl7" in namespace "gc-4791"
    Jan 10 04:37:05.074: INFO: Deleting pod "simpletest.rc-d4kdt" in namespace "gc-4791"
    Jan 10 04:37:05.107: INFO: Deleting pod "simpletest.rc-d8bxj" in namespace "gc-4791"
    Jan 10 04:37:05.187: INFO: Deleting pod "simpletest.rc-d8xwp" in namespace "gc-4791"
    Jan 10 04:37:05.267: INFO: Deleting pod "simpletest.rc-d995p" in namespace "gc-4791"
    Jan 10 04:37:05.306: INFO: Deleting pod "simpletest.rc-dk84l" in namespace "gc-4791"
    Jan 10 04:37:05.352: INFO: Deleting pod "simpletest.rc-dz6g2" in namespace "gc-4791"
    Jan 10 04:37:05.454: INFO: Deleting pod "simpletest.rc-f5zrj" in namespace "gc-4791"
    Jan 10 04:37:05.497: INFO: Deleting pod "simpletest.rc-fkfj8" in namespace "gc-4791"
    Jan 10 04:37:05.563: INFO: Deleting pod "simpletest.rc-g59x2" in namespace "gc-4791"
    Jan 10 04:37:05.636: INFO: Deleting pod "simpletest.rc-g8b4k" in namespace "gc-4791"
    Jan 10 04:37:05.712: INFO: Deleting pod "simpletest.rc-ggkz8" in namespace "gc-4791"
    Jan 10 04:37:05.765: INFO: Deleting pod "simpletest.rc-h5bft" in namespace "gc-4791"
    Jan 10 04:37:05.782: INFO: Deleting pod "simpletest.rc-h5tbh" in namespace "gc-4791"
    Jan 10 04:37:05.830: INFO: Deleting pod "simpletest.rc-h6n2q" in namespace "gc-4791"
    Jan 10 04:37:05.844: INFO: Deleting pod "simpletest.rc-h8hgq" in namespace "gc-4791"
    Jan 10 04:37:05.904: INFO: Deleting pod "simpletest.rc-hf6z4" in namespace "gc-4791"
    Jan 10 04:37:05.976: INFO: Deleting pod "simpletest.rc-hlcqg" in namespace "gc-4791"
    Jan 10 04:37:05.993: INFO: Deleting pod "simpletest.rc-hrzwj" in namespace "gc-4791"
    Jan 10 04:37:06.042: INFO: Deleting pod "simpletest.rc-j8vxk" in namespace "gc-4791"
    Jan 10 04:37:06.098: INFO: Deleting pod "simpletest.rc-jv9wc" in namespace "gc-4791"
    Jan 10 04:37:06.129: INFO: Deleting pod "simpletest.rc-k248b" in namespace "gc-4791"
    Jan 10 04:37:06.206: INFO: Deleting pod "simpletest.rc-knhcv" in namespace "gc-4791"
    Jan 10 04:37:06.316: INFO: Deleting pod "simpletest.rc-kzhbw" in namespace "gc-4791"
    Jan 10 04:37:06.344: INFO: Deleting pod "simpletest.rc-lgbs7" in namespace "gc-4791"
    Jan 10 04:37:06.388: INFO: Deleting pod "simpletest.rc-lwf8b" in namespace "gc-4791"
    Jan 10 04:37:06.494: INFO: Deleting pod "simpletest.rc-m4v4p" in namespace "gc-4791"
    Jan 10 04:37:06.539: INFO: Deleting pod "simpletest.rc-m6kc7" in namespace "gc-4791"
    Jan 10 04:37:06.606: INFO: Deleting pod "simpletest.rc-mbd7s" in namespace "gc-4791"
    Jan 10 04:37:06.741: INFO: Deleting pod "simpletest.rc-mdgrr" in namespace "gc-4791"
    Jan 10 04:37:06.853: INFO: Deleting pod "simpletest.rc-mp749" in namespace "gc-4791"
    Jan 10 04:37:06.975: INFO: Deleting pod "simpletest.rc-mrwfg" in namespace "gc-4791"
    Jan 10 04:37:07.111: INFO: Deleting pod "simpletest.rc-mswdv" in namespace "gc-4791"
    Jan 10 04:37:07.208: INFO: Deleting pod "simpletest.rc-n46ng" in namespace "gc-4791"
    Jan 10 04:37:07.282: INFO: Deleting pod "simpletest.rc-n4f2w" in namespace "gc-4791"
    Jan 10 04:37:07.410: INFO: Deleting pod "simpletest.rc-pmfl2" in namespace "gc-4791"
    Jan 10 04:37:07.565: INFO: Deleting pod "simpletest.rc-prjlx" in namespace "gc-4791"
    Jan 10 04:37:07.672: INFO: Deleting pod "simpletest.rc-px6xp" in namespace "gc-4791"
    Jan 10 04:37:07.709: INFO: Deleting pod "simpletest.rc-pxjsv" in namespace "gc-4791"
    Jan 10 04:37:07.885: INFO: Deleting pod "simpletest.rc-pzqjz" in namespace "gc-4791"
    Jan 10 04:37:07.956: INFO: Deleting pod "simpletest.rc-q9hvg" in namespace "gc-4791"
    Jan 10 04:37:08.008: INFO: Deleting pod "simpletest.rc-r8vhb" in namespace "gc-4791"
    Jan 10 04:37:08.033: INFO: Deleting pod "simpletest.rc-rq86r" in namespace "gc-4791"
    Jan 10 04:37:08.109: INFO: Deleting pod "simpletest.rc-s78tk" in namespace "gc-4791"
    Jan 10 04:37:08.223: INFO: Deleting pod "simpletest.rc-sjk9x" in namespace "gc-4791"
    Jan 10 04:37:08.365: INFO: Deleting pod "simpletest.rc-sktz9" in namespace "gc-4791"
    Jan 10 04:37:08.444: INFO: Deleting pod "simpletest.rc-snplj" in namespace "gc-4791"
    Jan 10 04:37:08.490: INFO: Deleting pod "simpletest.rc-sshm7" in namespace "gc-4791"
    Jan 10 04:37:08.560: INFO: Deleting pod "simpletest.rc-t25rx" in namespace "gc-4791"
    Jan 10 04:37:08.644: INFO: Deleting pod "simpletest.rc-tpb9h" in namespace "gc-4791"
    Jan 10 04:37:08.751: INFO: Deleting pod "simpletest.rc-vd687" in namespace "gc-4791"
    Jan 10 04:37:08.897: INFO: Deleting pod "simpletest.rc-vhbxl" in namespace "gc-4791"
    Jan 10 04:37:08.935: INFO: Deleting pod "simpletest.rc-vntl9" in namespace "gc-4791"
    Jan 10 04:37:09.039: INFO: Deleting pod "simpletest.rc-whck7" in namespace "gc-4791"
    Jan 10 04:37:09.157: INFO: Deleting pod "simpletest.rc-wnhgf" in namespace "gc-4791"
    Jan 10 04:37:09.255: INFO: Deleting pod "simpletest.rc-wtlgt" in namespace "gc-4791"
    Jan 10 04:37:09.365: INFO: Deleting pod "simpletest.rc-wv4h5" in namespace "gc-4791"
    Jan 10 04:37:09.446: INFO: Deleting pod "simpletest.rc-x98vv" in namespace "gc-4791"
    Jan 10 04:37:09.549: INFO: Deleting pod "simpletest.rc-xj8qq" in namespace "gc-4791"
    Jan 10 04:37:09.628: INFO: Deleting pod "simpletest.rc-xjl8t" in namespace "gc-4791"
    Jan 10 04:37:09.687: INFO: Deleting pod "simpletest.rc-xz66p" in namespace "gc-4791"
    Jan 10 04:37:09.788: INFO: Deleting pod "simpletest.rc-z4kjm" in namespace "gc-4791"
    Jan 10 04:37:09.950: INFO: Deleting pod "simpletest.rc-zm7nc" in namespace "gc-4791"
    Jan 10 04:37:10.167: INFO: Deleting pod "simpletest.rc-zp67n" in namespace "gc-4791"
    Jan 10 04:37:10.231: INFO: Deleting pod "simpletest.rc-zzd6q" in namespace "gc-4791"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 10 04:37:10.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4791" for this suite. 01/10/23 04:37:10.333
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:37:10.362
Jan 10 04:37:10.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:37:10.363
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:37:10.626
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:37:10.694
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-a316dbd8-e30a-4d0f-bdc2-4c4d550231ee 01/10/23 04:37:10.723
STEP: Creating a pod to test consume secrets 01/10/23 04:37:10.833
Jan 10 04:37:10.904: INFO: Waiting up to 5m0s for pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8" in namespace "secrets-726" to be "Succeeded or Failed"
Jan 10 04:37:10.960: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8": Phase="Pending", Reason="", readiness=false. Elapsed: 55.936676ms
Jan 10 04:37:12.964: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060266983s
Jan 10 04:37:14.966: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061936171s
Jan 10 04:37:16.968: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063662123s
STEP: Saw pod success 01/10/23 04:37:16.968
Jan 10 04:37:16.968: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8" satisfied condition "Succeeded or Failed"
Jan 10 04:37:16.972: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8 container secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:37:16.985
Jan 10 04:37:17.007: INFO: Waiting for pod pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8 to disappear
Jan 10 04:37:17.014: INFO: Pod pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:37:17.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-726" for this suite. 01/10/23 04:37:17.023
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":221,"skipped":3709,"failed":0}
------------------------------
• [SLOW TEST] [6.675 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:37:10.362
    Jan 10 04:37:10.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:37:10.363
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:37:10.626
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:37:10.694
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-a316dbd8-e30a-4d0f-bdc2-4c4d550231ee 01/10/23 04:37:10.723
    STEP: Creating a pod to test consume secrets 01/10/23 04:37:10.833
    Jan 10 04:37:10.904: INFO: Waiting up to 5m0s for pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8" in namespace "secrets-726" to be "Succeeded or Failed"
    Jan 10 04:37:10.960: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8": Phase="Pending", Reason="", readiness=false. Elapsed: 55.936676ms
    Jan 10 04:37:12.964: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060266983s
    Jan 10 04:37:14.966: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061936171s
    Jan 10 04:37:16.968: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063662123s
    STEP: Saw pod success 01/10/23 04:37:16.968
    Jan 10 04:37:16.968: INFO: Pod "pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8" satisfied condition "Succeeded or Failed"
    Jan 10 04:37:16.972: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8 container secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:37:16.985
    Jan 10 04:37:17.007: INFO: Waiting for pod pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8 to disappear
    Jan 10 04:37:17.014: INFO: Pod pod-secrets-716d110b-2ccf-4436-9855-7084f04c2fd8 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:37:17.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-726" for this suite. 01/10/23 04:37:17.023
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:37:17.049
Jan 10 04:37:17.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:37:17.05
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:37:17.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:37:17.084
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-b9335090-aee8-4d44-9889-b0c2312beadb 01/10/23 04:37:17.087
STEP: Creating a pod to test consume secrets 01/10/23 04:37:17.094
Jan 10 04:37:17.106: INFO: Waiting up to 5m0s for pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61" in namespace "secrets-5916" to be "Succeeded or Failed"
Jan 10 04:37:17.114: INFO: Pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61": Phase="Pending", Reason="", readiness=false. Elapsed: 7.714009ms
Jan 10 04:37:19.118: INFO: Pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012042417s
Jan 10 04:37:21.118: INFO: Pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011458296s
STEP: Saw pod success 01/10/23 04:37:21.118
Jan 10 04:37:21.118: INFO: Pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61" satisfied condition "Succeeded or Failed"
Jan 10 04:37:21.122: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61 container secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:37:21.131
Jan 10 04:37:21.146: INFO: Waiting for pod pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61 to disappear
Jan 10 04:37:21.149: INFO: Pod pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:37:21.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5916" for this suite. 01/10/23 04:37:21.153
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":222,"skipped":3736,"failed":0}
------------------------------
• [4.112 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:37:17.049
    Jan 10 04:37:17.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:37:17.05
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:37:17.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:37:17.084
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-b9335090-aee8-4d44-9889-b0c2312beadb 01/10/23 04:37:17.087
    STEP: Creating a pod to test consume secrets 01/10/23 04:37:17.094
    Jan 10 04:37:17.106: INFO: Waiting up to 5m0s for pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61" in namespace "secrets-5916" to be "Succeeded or Failed"
    Jan 10 04:37:17.114: INFO: Pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61": Phase="Pending", Reason="", readiness=false. Elapsed: 7.714009ms
    Jan 10 04:37:19.118: INFO: Pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012042417s
    Jan 10 04:37:21.118: INFO: Pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011458296s
    STEP: Saw pod success 01/10/23 04:37:21.118
    Jan 10 04:37:21.118: INFO: Pod "pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61" satisfied condition "Succeeded or Failed"
    Jan 10 04:37:21.122: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61 container secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:37:21.131
    Jan 10 04:37:21.146: INFO: Waiting for pod pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61 to disappear
    Jan 10 04:37:21.149: INFO: Pod pod-secrets-1648620c-2f30-42ed-8306-b6bdcab18d61 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:37:21.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5916" for this suite. 01/10/23 04:37:21.153
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:37:21.161
Jan 10 04:37:21.161: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:37:21.164
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:37:21.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:37:21.192
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:37:21.294
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:37:22.09
STEP: Deploying the webhook pod 01/10/23 04:37:22.115
STEP: Wait for the deployment to be ready 01/10/23 04:37:22.186
Jan 10 04:37:22.203: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 04:37:24.222
STEP: Verifying the service has paired with the endpoint 01/10/23 04:37:24.245
Jan 10 04:37:25.245: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 01/10/23 04:37:25.248
Jan 10 04:37:25.263: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be denied by the webhook 01/10/23 04:37:25.371
STEP: create a pod that causes the webhook to hang 01/10/23 04:37:25.38
STEP: create a configmap that should be denied by the webhook 01/10/23 04:37:35.389
STEP: create a configmap that should be admitted by the webhook 01/10/23 04:37:35.532
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 01/10/23 04:37:35.545
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 01/10/23 04:37:35.557
STEP: create a namespace that bypass the webhook 01/10/23 04:37:35.564
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 01/10/23 04:37:35.581
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:37:35.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1067" for this suite. 01/10/23 04:37:35.636
STEP: Destroying namespace "webhook-1067-markers" for this suite. 01/10/23 04:37:35.65
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":223,"skipped":3742,"failed":0}
------------------------------
• [SLOW TEST] [14.661 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:37:21.161
    Jan 10 04:37:21.161: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:37:21.164
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:37:21.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:37:21.192
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:37:21.294
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:37:22.09
    STEP: Deploying the webhook pod 01/10/23 04:37:22.115
    STEP: Wait for the deployment to be ready 01/10/23 04:37:22.186
    Jan 10 04:37:22.203: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 04:37:24.222
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:37:24.245
    Jan 10 04:37:25.245: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 01/10/23 04:37:25.248
    Jan 10 04:37:25.263: INFO: Waiting for webhook configuration to be ready...
    STEP: create a pod that should be denied by the webhook 01/10/23 04:37:25.371
    STEP: create a pod that causes the webhook to hang 01/10/23 04:37:25.38
    STEP: create a configmap that should be denied by the webhook 01/10/23 04:37:35.389
    STEP: create a configmap that should be admitted by the webhook 01/10/23 04:37:35.532
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 01/10/23 04:37:35.545
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 01/10/23 04:37:35.557
    STEP: create a namespace that bypass the webhook 01/10/23 04:37:35.564
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 01/10/23 04:37:35.581
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:37:35.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1067" for this suite. 01/10/23 04:37:35.636
    STEP: Destroying namespace "webhook-1067-markers" for this suite. 01/10/23 04:37:35.65
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:37:35.831
Jan 10 04:37:35.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename cronjob 01/10/23 04:37:35.837
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:37:35.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:37:35.974
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 01/10/23 04:37:35.988
STEP: Ensuring a job is scheduled 01/10/23 04:37:35.998
STEP: Ensuring exactly one is scheduled 01/10/23 04:38:02.003
STEP: Ensuring exactly one running job exists by listing jobs explicitly 01/10/23 04:38:02.007
STEP: Ensuring the job is replaced with a new one 01/10/23 04:38:02.01
STEP: Removing cronjob 01/10/23 04:39:02.018
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 10 04:39:02.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2245" for this suite. 01/10/23 04:39:02.051
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":224,"skipped":3761,"failed":0}
------------------------------
• [SLOW TEST] [86.261 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:37:35.831
    Jan 10 04:37:35.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename cronjob 01/10/23 04:37:35.837
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:37:35.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:37:35.974
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 01/10/23 04:37:35.988
    STEP: Ensuring a job is scheduled 01/10/23 04:37:35.998
    STEP: Ensuring exactly one is scheduled 01/10/23 04:38:02.003
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 01/10/23 04:38:02.007
    STEP: Ensuring the job is replaced with a new one 01/10/23 04:38:02.01
    STEP: Removing cronjob 01/10/23 04:39:02.018
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 10 04:39:02.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2245" for this suite. 01/10/23 04:39:02.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:39:02.1
Jan 10 04:39:02.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:39:02.106
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:02.339
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:02.406
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 01/10/23 04:39:02.639
Jan 10 04:39:02.889: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240" in namespace "projected-6641" to be "Succeeded or Failed"
Jan 10 04:39:02.986: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240": Phase="Pending", Reason="", readiness=false. Elapsed: 96.835937ms
Jan 10 04:39:04.990: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100217255s
Jan 10 04:39:07.000: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110318178s
Jan 10 04:39:08.990: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.100159726s
STEP: Saw pod success 01/10/23 04:39:08.99
Jan 10 04:39:08.990: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240" satisfied condition "Succeeded or Failed"
Jan 10 04:39:08.992: INFO: Trying to get logs from node cncf-wk3 pod downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240 container client-container: <nil>
STEP: delete the pod 01/10/23 04:39:09.006
Jan 10 04:39:09.020: INFO: Waiting for pod downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240 to disappear
Jan 10 04:39:09.023: INFO: Pod downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 04:39:09.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6641" for this suite. 01/10/23 04:39:09.029
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":225,"skipped":3790,"failed":0}
------------------------------
• [SLOW TEST] [6.945 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:39:02.1
    Jan 10 04:39:02.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:39:02.106
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:02.339
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:02.406
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 01/10/23 04:39:02.639
    Jan 10 04:39:02.889: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240" in namespace "projected-6641" to be "Succeeded or Failed"
    Jan 10 04:39:02.986: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240": Phase="Pending", Reason="", readiness=false. Elapsed: 96.835937ms
    Jan 10 04:39:04.990: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100217255s
    Jan 10 04:39:07.000: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110318178s
    Jan 10 04:39:08.990: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.100159726s
    STEP: Saw pod success 01/10/23 04:39:08.99
    Jan 10 04:39:08.990: INFO: Pod "downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240" satisfied condition "Succeeded or Failed"
    Jan 10 04:39:08.992: INFO: Trying to get logs from node cncf-wk3 pod downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240 container client-container: <nil>
    STEP: delete the pod 01/10/23 04:39:09.006
    Jan 10 04:39:09.020: INFO: Waiting for pod downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240 to disappear
    Jan 10 04:39:09.023: INFO: Pod downwardapi-volume-cc549719-a465-4b30-be49-f25c8b15d240 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 04:39:09.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6641" for this suite. 01/10/23 04:39:09.029
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:39:09.047
Jan 10 04:39:09.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename endpointslicemirroring 01/10/23 04:39:09.048
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:09.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:09.128
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 01/10/23 04:39:09.154
Jan 10 04:39:09.164: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 01/10/23 04:39:11.168
Jan 10 04:39:11.174: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 01/10/23 04:39:13.177
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Jan 10 04:39:13.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-7535" for this suite. 01/10/23 04:39:13.203
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":226,"skipped":3801,"failed":0}
------------------------------
• [4.165 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:39:09.047
    Jan 10 04:39:09.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename endpointslicemirroring 01/10/23 04:39:09.048
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:09.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:09.128
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 01/10/23 04:39:09.154
    Jan 10 04:39:09.164: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 01/10/23 04:39:11.168
    Jan 10 04:39:11.174: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 01/10/23 04:39:13.177
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Jan 10 04:39:13.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-7535" for this suite. 01/10/23 04:39:13.203
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:39:13.214
Jan 10 04:39:13.214: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:39:13.215
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:13.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:13.284
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-0ea821f6-076b-4d90-950c-1fae1d9f5a5b 01/10/23 04:39:13.29
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:39:13.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7637" for this suite. 01/10/23 04:39:13.309
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":227,"skipped":3809,"failed":0}
------------------------------
• [0.110 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:39:13.214
    Jan 10 04:39:13.214: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:39:13.215
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:13.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:13.284
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-0ea821f6-076b-4d90-950c-1fae1d9f5a5b 01/10/23 04:39:13.29
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:39:13.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7637" for this suite. 01/10/23 04:39:13.309
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:39:13.332
Jan 10 04:39:13.332: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:39:13.333
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:13.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:13.384
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:39:13.422
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:39:13.957
STEP: Deploying the webhook pod 01/10/23 04:39:13.963
STEP: Wait for the deployment to be ready 01/10/23 04:39:13.976
Jan 10 04:39:13.996: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 04:39:16.009
STEP: Verifying the service has paired with the endpoint 01/10/23 04:39:16.017
Jan 10 04:39:17.017: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Jan 10 04:39:17.020: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Registering the custom resource webhook via the AdmissionRegistration API 01/10/23 04:39:17.598
STEP: Creating a custom resource that should be denied by the webhook 01/10/23 04:39:17.8
STEP: Creating a custom resource whose deletion would be denied by the webhook 01/10/23 04:39:20.545
STEP: Updating the custom resource with disallowed data should be denied 01/10/23 04:39:20.552
STEP: Deleting the custom resource should be denied 01/10/23 04:39:20.558
STEP: Remove the offending key and value from the custom resource data 01/10/23 04:39:20.564
STEP: Deleting the updated custom resource should be successful 01/10/23 04:39:20.573
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:39:21.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5070" for this suite. 01/10/23 04:39:21.262
STEP: Destroying namespace "webhook-5070-markers" for this suite. 01/10/23 04:39:21.287
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":228,"skipped":3822,"failed":0}
------------------------------
• [SLOW TEST] [8.356 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:39:13.332
    Jan 10 04:39:13.332: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:39:13.333
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:13.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:13.384
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:39:13.422
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:39:13.957
    STEP: Deploying the webhook pod 01/10/23 04:39:13.963
    STEP: Wait for the deployment to be ready 01/10/23 04:39:13.976
    Jan 10 04:39:13.996: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 04:39:16.009
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:39:16.017
    Jan 10 04:39:17.017: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Jan 10 04:39:17.020: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 01/10/23 04:39:17.598
    STEP: Creating a custom resource that should be denied by the webhook 01/10/23 04:39:17.8
    STEP: Creating a custom resource whose deletion would be denied by the webhook 01/10/23 04:39:20.545
    STEP: Updating the custom resource with disallowed data should be denied 01/10/23 04:39:20.552
    STEP: Deleting the custom resource should be denied 01/10/23 04:39:20.558
    STEP: Remove the offending key and value from the custom resource data 01/10/23 04:39:20.564
    STEP: Deleting the updated custom resource should be successful 01/10/23 04:39:20.573
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:39:21.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5070" for this suite. 01/10/23 04:39:21.262
    STEP: Destroying namespace "webhook-5070-markers" for this suite. 01/10/23 04:39:21.287
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:39:21.69
Jan 10 04:39:21.691: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename security-context-test 01/10/23 04:39:21.691
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:21.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:21.789
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Jan 10 04:39:21.861: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34" in namespace "security-context-test-7655" to be "Succeeded or Failed"
Jan 10 04:39:21.901: INFO: Pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34": Phase="Pending", Reason="", readiness=false. Elapsed: 39.594755ms
Jan 10 04:39:23.904: INFO: Pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043273579s
Jan 10 04:39:25.906: INFO: Pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044672686s
Jan 10 04:39:25.906: INFO: Pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34" satisfied condition "Succeeded or Failed"
Jan 10 04:39:25.912: INFO: Got logs for pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 10 04:39:25.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7655" for this suite. 01/10/23 04:39:25.916
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":229,"skipped":3881,"failed":0}
------------------------------
• [4.238 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:39:21.69
    Jan 10 04:39:21.691: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename security-context-test 01/10/23 04:39:21.691
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:21.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:21.789
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Jan 10 04:39:21.861: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34" in namespace "security-context-test-7655" to be "Succeeded or Failed"
    Jan 10 04:39:21.901: INFO: Pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34": Phase="Pending", Reason="", readiness=false. Elapsed: 39.594755ms
    Jan 10 04:39:23.904: INFO: Pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043273579s
    Jan 10 04:39:25.906: INFO: Pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044672686s
    Jan 10 04:39:25.906: INFO: Pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34" satisfied condition "Succeeded or Failed"
    Jan 10 04:39:25.912: INFO: Got logs for pod "busybox-privileged-false-4dd145b9-3e4f-4f20-9956-bafa7f5d4b34": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 10 04:39:25.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7655" for this suite. 01/10/23 04:39:25.916
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:39:25.929
Jan 10 04:39:25.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 04:39:25.93
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:25.953
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:25.96
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Jan 10 04:39:25.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:39:34.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7948" for this suite. 01/10/23 04:39:34.867
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":230,"skipped":3881,"failed":0}
------------------------------
• [SLOW TEST] [9.028 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:39:25.929
    Jan 10 04:39:25.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename custom-resource-definition 01/10/23 04:39:25.93
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:25.953
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:25.96
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Jan 10 04:39:25.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:39:34.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7948" for this suite. 01/10/23 04:39:34.867
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:39:34.958
Jan 10 04:39:34.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-probe 01/10/23 04:39:34.958
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:35.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:35.166
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d in namespace container-probe-9516 01/10/23 04:39:35.171
Jan 10 04:39:35.194: INFO: Waiting up to 5m0s for pod "liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d" in namespace "container-probe-9516" to be "not pending"
Jan 10 04:39:35.210: INFO: Pod "liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.729502ms
Jan 10 04:39:37.224: INFO: Pod "liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d": Phase="Running", Reason="", readiness=true. Elapsed: 2.029754425s
Jan 10 04:39:37.224: INFO: Pod "liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d" satisfied condition "not pending"
Jan 10 04:39:37.224: INFO: Started pod liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d in namespace container-probe-9516
STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 04:39:37.224
Jan 10 04:39:37.245: INFO: Initial restart count of pod liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is 0
Jan 10 04:39:57.310: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 1 (20.064997528s elapsed)
Jan 10 04:40:17.371: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 2 (40.125406748s elapsed)
Jan 10 04:40:37.417: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 3 (1m0.171579726s elapsed)
Jan 10 04:40:57.460: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 4 (1m20.214591214s elapsed)
Jan 10 04:42:01.600: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 5 (2m24.354898392s elapsed)
STEP: deleting the pod 01/10/23 04:42:01.6
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 10 04:42:01.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9516" for this suite. 01/10/23 04:42:01.689
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":231,"skipped":3883,"failed":0}
------------------------------
• [SLOW TEST] [146.761 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:39:34.958
    Jan 10 04:39:34.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-probe 01/10/23 04:39:34.958
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:39:35.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:39:35.166
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d in namespace container-probe-9516 01/10/23 04:39:35.171
    Jan 10 04:39:35.194: INFO: Waiting up to 5m0s for pod "liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d" in namespace "container-probe-9516" to be "not pending"
    Jan 10 04:39:35.210: INFO: Pod "liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.729502ms
    Jan 10 04:39:37.224: INFO: Pod "liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d": Phase="Running", Reason="", readiness=true. Elapsed: 2.029754425s
    Jan 10 04:39:37.224: INFO: Pod "liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d" satisfied condition "not pending"
    Jan 10 04:39:37.224: INFO: Started pod liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d in namespace container-probe-9516
    STEP: checking the pod's current state and verifying that restartCount is present 01/10/23 04:39:37.224
    Jan 10 04:39:37.245: INFO: Initial restart count of pod liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is 0
    Jan 10 04:39:57.310: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 1 (20.064997528s elapsed)
    Jan 10 04:40:17.371: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 2 (40.125406748s elapsed)
    Jan 10 04:40:37.417: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 3 (1m0.171579726s elapsed)
    Jan 10 04:40:57.460: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 4 (1m20.214591214s elapsed)
    Jan 10 04:42:01.600: INFO: Restart count of pod container-probe-9516/liveness-72477cd4-20cd-4c3b-9568-f20d8798ea2d is now 5 (2m24.354898392s elapsed)
    STEP: deleting the pod 01/10/23 04:42:01.6
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 10 04:42:01.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9516" for this suite. 01/10/23 04:42:01.689
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:42:01.719
Jan 10 04:42:01.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-preemption 01/10/23 04:42:01.72
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:42:01.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:42:01.94
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jan 10 04:42:02.107: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 10 04:43:02.200: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:43:02.206
Jan 10 04:43:02.206: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-preemption-path 01/10/23 04:43:02.207
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:43:02.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:43:02.4
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 01/10/23 04:43:02.427
STEP: Trying to launch a pod without a label to get a node which can launch it. 01/10/23 04:43:02.428
Jan 10 04:43:02.444: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-9617" to be "running"
Jan 10 04:43:02.469: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.909421ms
Jan 10 04:43:04.473: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.028588564s
Jan 10 04:43:04.474: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 01/10/23 04:43:04.476
Jan 10 04:43:04.496: INFO: found a healthy node: cncf-wk2
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Jan 10 04:43:18.612: INFO: pods created so far: [1 1 1]
Jan 10 04:43:18.612: INFO: length of pods created so far: 3
Jan 10 04:43:20.622: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Jan 10 04:43:27.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-9617" for this suite. 01/10/23 04:43:27.629
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:43:27.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4227" for this suite. 01/10/23 04:43:27.683
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":232,"skipped":3883,"failed":0}
------------------------------
• [SLOW TEST] [86.064 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:42:01.719
    Jan 10 04:42:01.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-preemption 01/10/23 04:42:01.72
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:42:01.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:42:01.94
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jan 10 04:42:02.107: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 10 04:43:02.200: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:43:02.206
    Jan 10 04:43:02.206: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-preemption-path 01/10/23 04:43:02.207
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:43:02.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:43:02.4
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 01/10/23 04:43:02.427
    STEP: Trying to launch a pod without a label to get a node which can launch it. 01/10/23 04:43:02.428
    Jan 10 04:43:02.444: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-9617" to be "running"
    Jan 10 04:43:02.469: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.909421ms
    Jan 10 04:43:04.473: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.028588564s
    Jan 10 04:43:04.474: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 01/10/23 04:43:04.476
    Jan 10 04:43:04.496: INFO: found a healthy node: cncf-wk2
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Jan 10 04:43:18.612: INFO: pods created so far: [1 1 1]
    Jan 10 04:43:18.612: INFO: length of pods created so far: 3
    Jan 10 04:43:20.622: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Jan 10 04:43:27.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-9617" for this suite. 01/10/23 04:43:27.629
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:43:27.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4227" for this suite. 01/10/23 04:43:27.683
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:43:27.787
Jan 10 04:43:27.787: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-preemption 01/10/23 04:43:27.788
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:43:27.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:43:27.851
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jan 10 04:43:27.885: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 10 04:44:27.919: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 01/10/23 04:44:27.922
Jan 10 04:44:27.952: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jan 10 04:44:27.965: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jan 10 04:44:28.011: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jan 10 04:44:28.024: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Jan 10 04:44:28.077: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Jan 10 04:44:28.151: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 01/10/23 04:44:28.152
Jan 10 04:44:28.152: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7828" to be "running"
Jan 10 04:44:28.185: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 33.483166ms
Jan 10 04:44:30.192: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040186979s
Jan 10 04:44:32.189: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036761329s
Jan 10 04:44:34.190: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038635815s
Jan 10 04:44:36.194: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.042723552s
Jan 10 04:44:38.190: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.037888171s
Jan 10 04:44:38.190: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Jan 10 04:44:38.190: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
Jan 10 04:44:38.193: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.753229ms
Jan 10 04:44:38.193: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Jan 10 04:44:38.193: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
Jan 10 04:44:38.195: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.478368ms
Jan 10 04:44:38.196: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Jan 10 04:44:38.196: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
Jan 10 04:44:38.198: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.638201ms
Jan 10 04:44:38.198: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Jan 10 04:44:38.198: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
Jan 10 04:44:38.201: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.588719ms
Jan 10 04:44:38.201: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Jan 10 04:44:38.201: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
Jan 10 04:44:38.203: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.029697ms
Jan 10 04:44:38.203: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 01/10/23 04:44:38.203
Jan 10 04:44:38.213: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Jan 10 04:44:38.222: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.027745ms
Jan 10 04:44:40.228: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015160309s
Jan 10 04:44:42.225: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.011677224s
Jan 10 04:44:42.225: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:44:42.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7828" for this suite. 01/10/23 04:44:42.257
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":233,"skipped":3890,"failed":0}
------------------------------
• [SLOW TEST] [74.530 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:43:27.787
    Jan 10 04:43:27.787: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-preemption 01/10/23 04:43:27.788
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:43:27.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:43:27.851
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jan 10 04:43:27.885: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 10 04:44:27.919: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 01/10/23 04:44:27.922
    Jan 10 04:44:27.952: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Jan 10 04:44:27.965: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Jan 10 04:44:28.011: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Jan 10 04:44:28.024: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Jan 10 04:44:28.077: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Jan 10 04:44:28.151: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 01/10/23 04:44:28.152
    Jan 10 04:44:28.152: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7828" to be "running"
    Jan 10 04:44:28.185: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 33.483166ms
    Jan 10 04:44:30.192: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040186979s
    Jan 10 04:44:32.189: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036761329s
    Jan 10 04:44:34.190: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038635815s
    Jan 10 04:44:36.194: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.042723552s
    Jan 10 04:44:38.190: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.037888171s
    Jan 10 04:44:38.190: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Jan 10 04:44:38.190: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
    Jan 10 04:44:38.193: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.753229ms
    Jan 10 04:44:38.193: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Jan 10 04:44:38.193: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
    Jan 10 04:44:38.195: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.478368ms
    Jan 10 04:44:38.196: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Jan 10 04:44:38.196: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
    Jan 10 04:44:38.198: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.638201ms
    Jan 10 04:44:38.198: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Jan 10 04:44:38.198: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
    Jan 10 04:44:38.201: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.588719ms
    Jan 10 04:44:38.201: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Jan 10 04:44:38.201: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-7828" to be "running"
    Jan 10 04:44:38.203: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.029697ms
    Jan 10 04:44:38.203: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 01/10/23 04:44:38.203
    Jan 10 04:44:38.213: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Jan 10 04:44:38.222: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.027745ms
    Jan 10 04:44:40.228: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015160309s
    Jan 10 04:44:42.225: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.011677224s
    Jan 10 04:44:42.225: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:44:42.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7828" for this suite. 01/10/23 04:44:42.257
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:44:42.317
Jan 10 04:44:42.317: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename statefulset 01/10/23 04:44:42.318
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:44:42.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:44:42.344
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6967 01/10/23 04:44:42.347
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Jan 10 04:44:42.384: INFO: Found 0 stateful pods, waiting for 1
Jan 10 04:44:52.390: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 01/10/23 04:44:52.404
W0110 04:44:52.416287      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jan 10 04:44:52.435: INFO: Found 1 stateful pods, waiting for 2
Jan 10 04:45:02.439: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 04:45:02.439: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 01/10/23 04:45:02.444
STEP: Delete all of the StatefulSets 01/10/23 04:45:02.447
STEP: Verify that StatefulSets have been deleted 01/10/23 04:45:02.451
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 10 04:45:02.455: INFO: Deleting all statefulset in ns statefulset-6967
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 10 04:45:02.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6967" for this suite. 01/10/23 04:45:02.481
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":234,"skipped":3894,"failed":0}
------------------------------
• [SLOW TEST] [20.218 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:44:42.317
    Jan 10 04:44:42.317: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename statefulset 01/10/23 04:44:42.318
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:44:42.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:44:42.344
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6967 01/10/23 04:44:42.347
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Jan 10 04:44:42.384: INFO: Found 0 stateful pods, waiting for 1
    Jan 10 04:44:52.390: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 01/10/23 04:44:52.404
    W0110 04:44:52.416287      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jan 10 04:44:52.435: INFO: Found 1 stateful pods, waiting for 2
    Jan 10 04:45:02.439: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 04:45:02.439: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 01/10/23 04:45:02.444
    STEP: Delete all of the StatefulSets 01/10/23 04:45:02.447
    STEP: Verify that StatefulSets have been deleted 01/10/23 04:45:02.451
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 10 04:45:02.455: INFO: Deleting all statefulset in ns statefulset-6967
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 10 04:45:02.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6967" for this suite. 01/10/23 04:45:02.481
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:45:02.536
Jan 10 04:45:02.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename watch 01/10/23 04:45:02.537
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:02.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:02.65
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 01/10/23 04:45:02.653
STEP: creating a new configmap 01/10/23 04:45:02.654
STEP: modifying the configmap once 01/10/23 04:45:02.664
STEP: changing the label value of the configmap 01/10/23 04:45:02.709
STEP: Expecting to observe a delete notification for the watched object 01/10/23 04:45:02.722
Jan 10 04:45:02.722: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240315 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:45:02.723: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240317 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:45:02.728: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240319 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 01/10/23 04:45:02.728
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 01/10/23 04:45:02.737
STEP: changing the label value of the configmap back 01/10/23 04:45:12.738
STEP: modifying the configmap a third time 01/10/23 04:45:12.747
STEP: deleting the configmap 01/10/23 04:45:12.756
STEP: Expecting to observe an add notification for the watched object when the label value was restored 01/10/23 04:45:12.76
Jan 10 04:45:12.761: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240400 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:45:12.761: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240401 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 10 04:45:12.761: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240402 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 10 04:45:12.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8846" for this suite. 01/10/23 04:45:12.765
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":235,"skipped":3935,"failed":0}
------------------------------
• [SLOW TEST] [10.240 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:45:02.536
    Jan 10 04:45:02.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename watch 01/10/23 04:45:02.537
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:02.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:02.65
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 01/10/23 04:45:02.653
    STEP: creating a new configmap 01/10/23 04:45:02.654
    STEP: modifying the configmap once 01/10/23 04:45:02.664
    STEP: changing the label value of the configmap 01/10/23 04:45:02.709
    STEP: Expecting to observe a delete notification for the watched object 01/10/23 04:45:02.722
    Jan 10 04:45:02.722: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240315 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:45:02.723: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240317 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:45:02.728: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240319 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 01/10/23 04:45:02.728
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 01/10/23 04:45:02.737
    STEP: changing the label value of the configmap back 01/10/23 04:45:12.738
    STEP: modifying the configmap a third time 01/10/23 04:45:12.747
    STEP: deleting the configmap 01/10/23 04:45:12.756
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 01/10/23 04:45:12.76
    Jan 10 04:45:12.761: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240400 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:45:12.761: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240401 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 10 04:45:12.761: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8846  fbf1e8ae-b0d4-4810-a904-60a5bcd28707 240402 0 2023-01-10 04:45:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-10 04:45:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 10 04:45:12.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8846" for this suite. 01/10/23 04:45:12.765
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:45:12.777
Jan 10 04:45:12.777: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename dns 01/10/23 04:45:12.778
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:12.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:12.823
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-39.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-39.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 01/10/23 04:45:12.831
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-39.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-39.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 01/10/23 04:45:12.831
STEP: creating a pod to probe /etc/hosts 01/10/23 04:45:12.831
STEP: submitting the pod to kubernetes 01/10/23 04:45:12.831
Jan 10 04:45:12.844: INFO: Waiting up to 15m0s for pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f" in namespace "dns-39" to be "running"
Jan 10 04:45:12.857: INFO: Pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.73364ms
Jan 10 04:45:14.860: INFO: Pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0158468s
Jan 10 04:45:16.862: INFO: Pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f": Phase="Running", Reason="", readiness=true. Elapsed: 4.017356798s
Jan 10 04:45:16.862: INFO: Pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f" satisfied condition "running"
STEP: retrieving the pod 01/10/23 04:45:16.862
STEP: looking for the results for each expected name from probers 01/10/23 04:45:16.87
Jan 10 04:45:16.892: INFO: DNS probes using dns-39/dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f succeeded

STEP: deleting the pod 01/10/23 04:45:16.893
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 10 04:45:16.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-39" for this suite. 01/10/23 04:45:16.911
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":236,"skipped":3963,"failed":0}
------------------------------
• [4.156 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:45:12.777
    Jan 10 04:45:12.777: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename dns 01/10/23 04:45:12.778
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:12.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:12.823
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-39.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-39.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     01/10/23 04:45:12.831
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-39.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-39.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     01/10/23 04:45:12.831
    STEP: creating a pod to probe /etc/hosts 01/10/23 04:45:12.831
    STEP: submitting the pod to kubernetes 01/10/23 04:45:12.831
    Jan 10 04:45:12.844: INFO: Waiting up to 15m0s for pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f" in namespace "dns-39" to be "running"
    Jan 10 04:45:12.857: INFO: Pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.73364ms
    Jan 10 04:45:14.860: INFO: Pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0158468s
    Jan 10 04:45:16.862: INFO: Pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f": Phase="Running", Reason="", readiness=true. Elapsed: 4.017356798s
    Jan 10 04:45:16.862: INFO: Pod "dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 04:45:16.862
    STEP: looking for the results for each expected name from probers 01/10/23 04:45:16.87
    Jan 10 04:45:16.892: INFO: DNS probes using dns-39/dns-test-0fbadead-f5e2-41d0-8558-cb8088b69c9f succeeded

    STEP: deleting the pod 01/10/23 04:45:16.893
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 10 04:45:16.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-39" for this suite. 01/10/23 04:45:16.911
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:45:16.943
Jan 10 04:45:16.943: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sysctl 01/10/23 04:45:16.944
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:16.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:17.001
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 01/10/23 04:45:17.009
STEP: Watching for error events or started pod 01/10/23 04:45:17.033
STEP: Waiting for pod completion 01/10/23 04:45:19.037
Jan 10 04:45:19.037: INFO: Waiting up to 3m0s for pod "sysctl-ae17a133-442b-4e45-9463-82cc9c0d231a" in namespace "sysctl-360" to be "completed"
Jan 10 04:45:19.040: INFO: Pod "sysctl-ae17a133-442b-4e45-9463-82cc9c0d231a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.701108ms
Jan 10 04:45:21.044: INFO: Pod "sysctl-ae17a133-442b-4e45-9463-82cc9c0d231a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006752116s
Jan 10 04:45:21.044: INFO: Pod "sysctl-ae17a133-442b-4e45-9463-82cc9c0d231a" satisfied condition "completed"
STEP: Checking that the pod succeeded 01/10/23 04:45:21.048
STEP: Getting logs from the pod 01/10/23 04:45:21.048
STEP: Checking that the sysctl is actually updated 01/10/23 04:45:21.072
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 10 04:45:21.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-360" for this suite. 01/10/23 04:45:21.078
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":237,"skipped":3978,"failed":0}
------------------------------
• [4.144 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:45:16.943
    Jan 10 04:45:16.943: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sysctl 01/10/23 04:45:16.944
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:16.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:17.001
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 01/10/23 04:45:17.009
    STEP: Watching for error events or started pod 01/10/23 04:45:17.033
    STEP: Waiting for pod completion 01/10/23 04:45:19.037
    Jan 10 04:45:19.037: INFO: Waiting up to 3m0s for pod "sysctl-ae17a133-442b-4e45-9463-82cc9c0d231a" in namespace "sysctl-360" to be "completed"
    Jan 10 04:45:19.040: INFO: Pod "sysctl-ae17a133-442b-4e45-9463-82cc9c0d231a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.701108ms
    Jan 10 04:45:21.044: INFO: Pod "sysctl-ae17a133-442b-4e45-9463-82cc9c0d231a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006752116s
    Jan 10 04:45:21.044: INFO: Pod "sysctl-ae17a133-442b-4e45-9463-82cc9c0d231a" satisfied condition "completed"
    STEP: Checking that the pod succeeded 01/10/23 04:45:21.048
    STEP: Getting logs from the pod 01/10/23 04:45:21.048
    STEP: Checking that the sysctl is actually updated 01/10/23 04:45:21.072
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 10 04:45:21.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-360" for this suite. 01/10/23 04:45:21.078
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:45:21.089
Jan 10 04:45:21.089: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename namespaces 01/10/23 04:45:21.09
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:21.17
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:21.197
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 01/10/23 04:45:21.21
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:21.281
STEP: Creating a service in the namespace 01/10/23 04:45:21.301
STEP: Deleting the namespace 01/10/23 04:45:21.349
STEP: Waiting for the namespace to be removed. 01/10/23 04:45:21.395
STEP: Recreating the namespace 01/10/23 04:45:28.398
STEP: Verifying there is no service in the namespace 01/10/23 04:45:28.421
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:45:28.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8213" for this suite. 01/10/23 04:45:28.431
STEP: Destroying namespace "nsdeletetest-3738" for this suite. 01/10/23 04:45:28.436
Jan 10 04:45:28.442: INFO: Namespace nsdeletetest-3738 was already deleted
STEP: Destroying namespace "nsdeletetest-8030" for this suite. 01/10/23 04:45:28.442
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":238,"skipped":3984,"failed":0}
------------------------------
• [SLOW TEST] [7.361 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:45:21.089
    Jan 10 04:45:21.089: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename namespaces 01/10/23 04:45:21.09
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:21.17
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:21.197
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 01/10/23 04:45:21.21
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:21.281
    STEP: Creating a service in the namespace 01/10/23 04:45:21.301
    STEP: Deleting the namespace 01/10/23 04:45:21.349
    STEP: Waiting for the namespace to be removed. 01/10/23 04:45:21.395
    STEP: Recreating the namespace 01/10/23 04:45:28.398
    STEP: Verifying there is no service in the namespace 01/10/23 04:45:28.421
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:45:28.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8213" for this suite. 01/10/23 04:45:28.431
    STEP: Destroying namespace "nsdeletetest-3738" for this suite. 01/10/23 04:45:28.436
    Jan 10 04:45:28.442: INFO: Namespace nsdeletetest-3738 was already deleted
    STEP: Destroying namespace "nsdeletetest-8030" for this suite. 01/10/23 04:45:28.442
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:45:28.456
Jan 10 04:45:28.457: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename events 01/10/23 04:45:28.457
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:28.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:28.481
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 01/10/23 04:45:28.494
STEP: get a list of Events with a label in the current namespace 01/10/23 04:45:28.516
STEP: delete a list of events 01/10/23 04:45:28.522
Jan 10 04:45:28.522: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 01/10/23 04:45:28.541
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Jan 10 04:45:28.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-744" for this suite. 01/10/23 04:45:28.547
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":239,"skipped":4011,"failed":0}
------------------------------
• [0.096 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:45:28.456
    Jan 10 04:45:28.457: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename events 01/10/23 04:45:28.457
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:28.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:28.481
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 01/10/23 04:45:28.494
    STEP: get a list of Events with a label in the current namespace 01/10/23 04:45:28.516
    STEP: delete a list of events 01/10/23 04:45:28.522
    Jan 10 04:45:28.522: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 01/10/23 04:45:28.541
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Jan 10 04:45:28.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-744" for this suite. 01/10/23 04:45:28.547
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:45:28.563
Jan 10 04:45:28.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename init-container 01/10/23 04:45:28.564
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:28.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:28.588
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 01/10/23 04:45:28.591
Jan 10 04:45:28.591: INFO: PodSpec: initContainers in spec.initContainers
Jan 10 04:46:13.762: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e02add87-7a39-48ce-a0f1-8b252affd809", GenerateName:"", Namespace:"init-container-3134", SelfLink:"", UID:"db41b402-5d4b-4f3b-823e-a5d57ccaf919", ResourceVersion:"240790", Generation:0, CreationTimestamp:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"591486104"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"8903753d73eac3032f0f5423bb69ae8bd180950d49dd3c1bff5116e2e30efb7b", "cni.projectcalico.org/podIP":"10.42.1.45/32", "cni.projectcalico.org/podIPs":"10.42.1.45/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c7db30), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 10, 4, 45, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c7db60), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 10, 4, 46, 13, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c7db90), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-qdds6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc006220720), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-qdds6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-qdds6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-qdds6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003115818), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"cncf-wk2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00098f180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0031158a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0031158c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0031158c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0031158cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0012dd920), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.3.44", PodIP:"10.42.1.45", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.42.1.45"}}, StartTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00098f260)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00098f340)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"docker-pullable://registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"docker://fc5fdf0c8fe1280b6cb5864b3491d862fd6732310e8c31e1a0bc606c8ef9ea11", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0062207a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006220780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc00311595f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 10 04:46:13.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3134" for this suite. 01/10/23 04:46:13.78
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":240,"skipped":4015,"failed":0}
------------------------------
• [SLOW TEST] [45.276 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:45:28.563
    Jan 10 04:45:28.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename init-container 01/10/23 04:45:28.564
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:45:28.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:45:28.588
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 01/10/23 04:45:28.591
    Jan 10 04:45:28.591: INFO: PodSpec: initContainers in spec.initContainers
    Jan 10 04:46:13.762: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e02add87-7a39-48ce-a0f1-8b252affd809", GenerateName:"", Namespace:"init-container-3134", SelfLink:"", UID:"db41b402-5d4b-4f3b-823e-a5d57ccaf919", ResourceVersion:"240790", Generation:0, CreationTimestamp:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"591486104"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"8903753d73eac3032f0f5423bb69ae8bd180950d49dd3c1bff5116e2e30efb7b", "cni.projectcalico.org/podIP":"10.42.1.45/32", "cni.projectcalico.org/podIPs":"10.42.1.45/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c7db30), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 10, 4, 45, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c7db60), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 10, 4, 46, 13, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c7db90), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-qdds6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc006220720), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-qdds6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-qdds6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-qdds6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003115818), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"cncf-wk2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00098f180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0031158a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0031158c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0031158c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0031158cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0012dd920), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.3.44", PodIP:"10.42.1.45", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.42.1.45"}}, StartTime:time.Date(2023, time.January, 10, 4, 45, 28, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00098f260)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00098f340)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"docker-pullable://registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"docker://fc5fdf0c8fe1280b6cb5864b3491d862fd6732310e8c31e1a0bc606c8ef9ea11", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0062207a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006220780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc00311595f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 10 04:46:13.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-3134" for this suite. 01/10/23 04:46:13.78
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:46:13.841
Jan 10 04:46:13.841: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:46:13.842
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:13.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:13.995
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:46:14.07
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:46:14.72
STEP: Deploying the webhook pod 01/10/23 04:46:14.728
STEP: Wait for the deployment to be ready 01/10/23 04:46:14.742
Jan 10 04:46:14.750: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 04:46:16.765
STEP: Verifying the service has paired with the endpoint 01/10/23 04:46:16.785
Jan 10 04:46:17.785: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 01/10/23 04:46:17.788
STEP: Registering slow webhook via the AdmissionRegistration API 01/10/23 04:46:17.788
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 01/10/23 04:46:17.801
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 01/10/23 04:46:18.809
STEP: Registering slow webhook via the AdmissionRegistration API 01/10/23 04:46:18.809
STEP: Having no error when timeout is longer than webhook latency 01/10/23 04:46:19.851
STEP: Registering slow webhook via the AdmissionRegistration API 01/10/23 04:46:19.851
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 01/10/23 04:46:24.891
STEP: Registering slow webhook via the AdmissionRegistration API 01/10/23 04:46:24.894
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:46:29.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-602" for this suite. 01/10/23 04:46:29.934
STEP: Destroying namespace "webhook-602-markers" for this suite. 01/10/23 04:46:29.941
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":241,"skipped":4035,"failed":0}
------------------------------
• [SLOW TEST] [16.195 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:46:13.841
    Jan 10 04:46:13.841: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:46:13.842
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:13.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:13.995
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:46:14.07
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:46:14.72
    STEP: Deploying the webhook pod 01/10/23 04:46:14.728
    STEP: Wait for the deployment to be ready 01/10/23 04:46:14.742
    Jan 10 04:46:14.750: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 04:46:16.765
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:46:16.785
    Jan 10 04:46:17.785: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 01/10/23 04:46:17.788
    STEP: Registering slow webhook via the AdmissionRegistration API 01/10/23 04:46:17.788
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 01/10/23 04:46:17.801
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 01/10/23 04:46:18.809
    STEP: Registering slow webhook via the AdmissionRegistration API 01/10/23 04:46:18.809
    STEP: Having no error when timeout is longer than webhook latency 01/10/23 04:46:19.851
    STEP: Registering slow webhook via the AdmissionRegistration API 01/10/23 04:46:19.851
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 01/10/23 04:46:24.891
    STEP: Registering slow webhook via the AdmissionRegistration API 01/10/23 04:46:24.894
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:46:29.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-602" for this suite. 01/10/23 04:46:29.934
    STEP: Destroying namespace "webhook-602-markers" for this suite. 01/10/23 04:46:29.941
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:46:30.036
Jan 10 04:46:30.036: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename containers 01/10/23 04:46:30.037
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:30.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:30.117
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 01/10/23 04:46:30.124
Jan 10 04:46:30.138: INFO: Waiting up to 5m0s for pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3" in namespace "containers-7135" to be "Succeeded or Failed"
Jan 10 04:46:30.148: INFO: Pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.462973ms
Jan 10 04:46:32.152: INFO: Pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014431177s
Jan 10 04:46:34.152: INFO: Pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013631462s
STEP: Saw pod success 01/10/23 04:46:34.152
Jan 10 04:46:34.152: INFO: Pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3" satisfied condition "Succeeded or Failed"
Jan 10 04:46:34.154: INFO: Trying to get logs from node cncf-wk2 pod client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:46:34.162
Jan 10 04:46:34.172: INFO: Waiting for pod client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3 to disappear
Jan 10 04:46:34.174: INFO: Pod client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jan 10 04:46:34.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7135" for this suite. 01/10/23 04:46:34.178
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":242,"skipped":4045,"failed":0}
------------------------------
• [4.147 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:46:30.036
    Jan 10 04:46:30.036: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename containers 01/10/23 04:46:30.037
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:30.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:30.117
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 01/10/23 04:46:30.124
    Jan 10 04:46:30.138: INFO: Waiting up to 5m0s for pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3" in namespace "containers-7135" to be "Succeeded or Failed"
    Jan 10 04:46:30.148: INFO: Pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.462973ms
    Jan 10 04:46:32.152: INFO: Pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014431177s
    Jan 10 04:46:34.152: INFO: Pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013631462s
    STEP: Saw pod success 01/10/23 04:46:34.152
    Jan 10 04:46:34.152: INFO: Pod "client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3" satisfied condition "Succeeded or Failed"
    Jan 10 04:46:34.154: INFO: Trying to get logs from node cncf-wk2 pod client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:46:34.162
    Jan 10 04:46:34.172: INFO: Waiting for pod client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3 to disappear
    Jan 10 04:46:34.174: INFO: Pod client-containers-2dfc89eb-a46d-475c-91dd-8dd8e5ebf3d3 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jan 10 04:46:34.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7135" for this suite. 01/10/23 04:46:34.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:46:34.187
Jan 10 04:46:34.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 04:46:34.188
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:34.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:34.264
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 01/10/23 04:46:34.266
Jan 10 04:46:34.272: INFO: Waiting up to 5m0s for pod "pod-n7hkz" in namespace "pods-5172" to be "running"
Jan 10 04:46:34.275: INFO: Pod "pod-n7hkz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.438669ms
Jan 10 04:46:36.278: INFO: Pod "pod-n7hkz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00596568s
Jan 10 04:46:38.278: INFO: Pod "pod-n7hkz": Phase="Running", Reason="", readiness=true. Elapsed: 4.006172206s
Jan 10 04:46:38.278: INFO: Pod "pod-n7hkz" satisfied condition "running"
STEP: patching /status 01/10/23 04:46:38.278
Jan 10 04:46:38.285: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 04:46:38.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5172" for this suite. 01/10/23 04:46:38.29
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":243,"skipped":4055,"failed":0}
------------------------------
• [4.123 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:46:34.187
    Jan 10 04:46:34.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 04:46:34.188
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:34.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:34.264
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 01/10/23 04:46:34.266
    Jan 10 04:46:34.272: INFO: Waiting up to 5m0s for pod "pod-n7hkz" in namespace "pods-5172" to be "running"
    Jan 10 04:46:34.275: INFO: Pod "pod-n7hkz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.438669ms
    Jan 10 04:46:36.278: INFO: Pod "pod-n7hkz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00596568s
    Jan 10 04:46:38.278: INFO: Pod "pod-n7hkz": Phase="Running", Reason="", readiness=true. Elapsed: 4.006172206s
    Jan 10 04:46:38.278: INFO: Pod "pod-n7hkz" satisfied condition "running"
    STEP: patching /status 01/10/23 04:46:38.278
    Jan 10 04:46:38.285: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 04:46:38.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5172" for this suite. 01/10/23 04:46:38.29
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:46:38.318
Jan 10 04:46:38.318: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename proxy 01/10/23 04:46:38.319
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:38.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:38.383
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 01/10/23 04:46:38.427
STEP: creating replication controller proxy-service-9hs57 in namespace proxy-4199 01/10/23 04:46:38.427
I0110 04:46:38.457583      19 runners.go:193] Created replication controller with name: proxy-service-9hs57, namespace: proxy-4199, replica count: 1
I0110 04:46:39.508696      19 runners.go:193] proxy-service-9hs57 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0110 04:46:40.508853      19 runners.go:193] proxy-service-9hs57 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 04:46:40.511: INFO: setup took 2.111868297s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 01/10/23 04:46:40.511
Jan 10 04:46:40.524: INFO: (0) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 12.069623ms)
Jan 10 04:46:40.530: INFO: (0) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 17.565132ms)
Jan 10 04:46:40.530: INFO: (0) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 18.1142ms)
Jan 10 04:46:40.530: INFO: (0) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 18.074688ms)
Jan 10 04:46:40.532: INFO: (0) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 20.108214ms)
Jan 10 04:46:40.532: INFO: (0) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 20.02808ms)
Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 20.151169ms)
Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 21.055815ms)
Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 20.479307ms)
Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 21.122248ms)
Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 20.283667ms)
Jan 10 04:46:40.536: INFO: (0) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 23.450396ms)
Jan 10 04:46:40.537: INFO: (0) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 25.002344ms)
Jan 10 04:46:40.538: INFO: (0) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 25.265746ms)
Jan 10 04:46:40.538: INFO: (0) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 25.716141ms)
Jan 10 04:46:40.538: INFO: (0) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 25.349819ms)
Jan 10 04:46:40.557: INFO: (1) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 18.545227ms)
Jan 10 04:46:40.557: INFO: (1) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 18.773521ms)
Jan 10 04:46:40.564: INFO: (1) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 25.509027ms)
Jan 10 04:46:40.565: INFO: (1) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 26.211448ms)
Jan 10 04:46:40.566: INFO: (1) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 27.351553ms)
Jan 10 04:46:40.569: INFO: (1) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 31.118714ms)
Jan 10 04:46:40.569: INFO: (1) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 30.902752ms)
Jan 10 04:46:40.570: INFO: (1) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 31.253615ms)
Jan 10 04:46:40.570: INFO: (1) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 31.2658ms)
Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 38.948636ms)
Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 38.332711ms)
Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 38.509412ms)
Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 38.616845ms)
Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 38.585364ms)
Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 38.309977ms)
Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 38.620925ms)
Jan 10 04:46:40.589: INFO: (2) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 11.222821ms)
Jan 10 04:46:40.589: INFO: (2) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 11.35176ms)
Jan 10 04:46:40.589: INFO: (2) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 11.316683ms)
Jan 10 04:46:40.590: INFO: (2) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 11.524652ms)
Jan 10 04:46:40.590: INFO: (2) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 11.605045ms)
Jan 10 04:46:40.590: INFO: (2) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 11.660792ms)
Jan 10 04:46:40.590: INFO: (2) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 11.994375ms)
Jan 10 04:46:40.592: INFO: (2) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 13.686067ms)
Jan 10 04:46:40.592: INFO: (2) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 14.215681ms)
Jan 10 04:46:40.593: INFO: (2) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 14.509791ms)
Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 15.112207ms)
Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 15.290491ms)
Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 15.62533ms)
Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 15.678359ms)
Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 15.904029ms)
Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 15.89149ms)
Jan 10 04:46:40.600: INFO: (3) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 5.035425ms)
Jan 10 04:46:40.603: INFO: (3) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 8.276804ms)
Jan 10 04:46:40.606: INFO: (3) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 11.728702ms)
Jan 10 04:46:40.608: INFO: (3) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 13.234739ms)
Jan 10 04:46:40.608: INFO: (3) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 13.565207ms)
Jan 10 04:46:40.611: INFO: (3) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 15.793747ms)
Jan 10 04:46:40.611: INFO: (3) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 16.293613ms)
Jan 10 04:46:40.611: INFO: (3) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 16.476317ms)
Jan 10 04:46:40.612: INFO: (3) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 16.565267ms)
Jan 10 04:46:40.614: INFO: (3) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 19.839979ms)
Jan 10 04:46:40.615: INFO: (3) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 20.038265ms)
Jan 10 04:46:40.615: INFO: (3) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 20.481432ms)
Jan 10 04:46:40.615: INFO: (3) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 20.287274ms)
Jan 10 04:46:40.615: INFO: (3) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 21.144051ms)
Jan 10 04:46:40.616: INFO: (3) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 20.495848ms)
Jan 10 04:46:40.616: INFO: (3) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 20.913333ms)
Jan 10 04:46:40.633: INFO: (4) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 17.164717ms)
Jan 10 04:46:40.633: INFO: (4) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 17.316977ms)
Jan 10 04:46:40.633: INFO: (4) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 16.892537ms)
Jan 10 04:46:40.634: INFO: (4) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 17.922071ms)
Jan 10 04:46:40.634: INFO: (4) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 17.713901ms)
Jan 10 04:46:40.634: INFO: (4) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 17.54145ms)
Jan 10 04:46:40.634: INFO: (4) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 17.931542ms)
Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 18.529231ms)
Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 18.777516ms)
Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 18.851756ms)
Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 18.777425ms)
Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 19.00157ms)
Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 19.59689ms)
Jan 10 04:46:40.636: INFO: (4) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 19.570108ms)
Jan 10 04:46:40.636: INFO: (4) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 19.79814ms)
Jan 10 04:46:40.636: INFO: (4) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 19.796526ms)
Jan 10 04:46:40.644: INFO: (5) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 7.424334ms)
Jan 10 04:46:40.654: INFO: (5) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 15.569294ms)
Jan 10 04:46:40.655: INFO: (5) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 16.072345ms)
Jan 10 04:46:40.655: INFO: (5) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 16.200475ms)
Jan 10 04:46:40.655: INFO: (5) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 16.252426ms)
Jan 10 04:46:40.655: INFO: (5) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 18.442977ms)
Jan 10 04:46:40.656: INFO: (5) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 17.613337ms)
Jan 10 04:46:40.656: INFO: (5) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 17.341401ms)
Jan 10 04:46:40.656: INFO: (5) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 17.39283ms)
Jan 10 04:46:40.656: INFO: (5) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 17.331426ms)
Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 18.112426ms)
Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 20.000815ms)
Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 18.032149ms)
Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 18.44983ms)
Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 18.543027ms)
Jan 10 04:46:40.659: INFO: (5) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 20.868393ms)
Jan 10 04:46:40.668: INFO: (6) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 8.52758ms)
Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 9.043936ms)
Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 8.97809ms)
Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 9.054383ms)
Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 9.690495ms)
Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 9.752859ms)
Jan 10 04:46:40.675: INFO: (6) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 15.004535ms)
Jan 10 04:46:40.675: INFO: (6) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 15.283576ms)
Jan 10 04:46:40.675: INFO: (6) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 15.594685ms)
Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 16.022641ms)
Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 16.067799ms)
Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 16.404129ms)
Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 16.141772ms)
Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 16.573703ms)
Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 16.386879ms)
Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 16.342366ms)
Jan 10 04:46:40.686: INFO: (7) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 8.995478ms)
Jan 10 04:46:40.686: INFO: (7) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 9.697434ms)
Jan 10 04:46:40.686: INFO: (7) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 9.530139ms)
Jan 10 04:46:40.687: INFO: (7) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 10.40389ms)
Jan 10 04:46:40.688: INFO: (7) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 11.614113ms)
Jan 10 04:46:40.689: INFO: (7) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 12.466803ms)
Jan 10 04:46:40.690: INFO: (7) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 12.776515ms)
Jan 10 04:46:40.690: INFO: (7) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 12.988716ms)
Jan 10 04:46:40.690: INFO: (7) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 12.900326ms)
Jan 10 04:46:40.690: INFO: (7) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 13.427726ms)
Jan 10 04:46:40.691: INFO: (7) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 14.617708ms)
Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 15.138207ms)
Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 15.258648ms)
Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 14.999772ms)
Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 15.646505ms)
Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 15.748187ms)
Jan 10 04:46:40.697: INFO: (8) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 4.484222ms)
Jan 10 04:46:40.698: INFO: (8) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 5.404717ms)
Jan 10 04:46:40.700: INFO: (8) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 7.877981ms)
Jan 10 04:46:40.700: INFO: (8) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 8.183233ms)
Jan 10 04:46:40.703: INFO: (8) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 10.234163ms)
Jan 10 04:46:40.703: INFO: (8) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 10.202413ms)
Jan 10 04:46:40.706: INFO: (8) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 13.357246ms)
Jan 10 04:46:40.707: INFO: (8) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 14.306592ms)
Jan 10 04:46:40.707: INFO: (8) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 14.748101ms)
Jan 10 04:46:40.707: INFO: (8) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 14.62319ms)
Jan 10 04:46:40.708: INFO: (8) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 15.015546ms)
Jan 10 04:46:40.708: INFO: (8) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 15.268251ms)
Jan 10 04:46:40.708: INFO: (8) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 15.716611ms)
Jan 10 04:46:40.708: INFO: (8) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 15.791332ms)
Jan 10 04:46:40.709: INFO: (8) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 16.053546ms)
Jan 10 04:46:40.709: INFO: (8) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 15.97854ms)
Jan 10 04:46:40.721: INFO: (9) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 11.957098ms)
Jan 10 04:46:40.721: INFO: (9) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 12.018246ms)
Jan 10 04:46:40.722: INFO: (9) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 13.08108ms)
Jan 10 04:46:40.726: INFO: (9) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 16.457171ms)
Jan 10 04:46:40.726: INFO: (9) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 17.251914ms)
Jan 10 04:46:40.726: INFO: (9) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 17.469847ms)
Jan 10 04:46:40.730: INFO: (9) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 20.628703ms)
Jan 10 04:46:40.731: INFO: (9) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 21.734176ms)
Jan 10 04:46:40.734: INFO: (9) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 24.027114ms)
Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 26.977706ms)
Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 26.982611ms)
Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 27.28594ms)
Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 27.588637ms)
Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 27.317598ms)
Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 27.548076ms)
Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 27.760484ms)
Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 11.564927ms)
Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 11.494258ms)
Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 13.042029ms)
Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 12.810627ms)
Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 12.897291ms)
Jan 10 04:46:40.757: INFO: (10) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 19.016863ms)
Jan 10 04:46:40.757: INFO: (10) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 19.104963ms)
Jan 10 04:46:40.758: INFO: (10) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 20.760427ms)
Jan 10 04:46:40.758: INFO: (10) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 20.384227ms)
Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 20.948911ms)
Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 20.865149ms)
Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 21.117878ms)
Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 21.320876ms)
Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 20.908631ms)
Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 21.228995ms)
Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 21.461131ms)
Jan 10 04:46:40.766: INFO: (11) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 6.581692ms)
Jan 10 04:46:40.766: INFO: (11) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 6.5079ms)
Jan 10 04:46:40.770: INFO: (11) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 10.493316ms)
Jan 10 04:46:40.771: INFO: (11) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 10.7316ms)
Jan 10 04:46:40.771: INFO: (11) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 10.827841ms)
Jan 10 04:46:40.776: INFO: (11) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 15.646764ms)
Jan 10 04:46:40.776: INFO: (11) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 15.986294ms)
Jan 10 04:46:40.777: INFO: (11) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 17.094923ms)
Jan 10 04:46:40.777: INFO: (11) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 17.076429ms)
Jan 10 04:46:40.778: INFO: (11) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 17.699195ms)
Jan 10 04:46:40.778: INFO: (11) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 17.58261ms)
Jan 10 04:46:40.778: INFO: (11) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 18.166435ms)
Jan 10 04:46:40.778: INFO: (11) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 18.46606ms)
Jan 10 04:46:40.779: INFO: (11) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 18.535455ms)
Jan 10 04:46:40.779: INFO: (11) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 18.302712ms)
Jan 10 04:46:40.779: INFO: (11) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 18.484284ms)
Jan 10 04:46:40.800: INFO: (12) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 21.164727ms)
Jan 10 04:46:40.802: INFO: (12) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 23.233364ms)
Jan 10 04:46:40.802: INFO: (12) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 22.955667ms)
Jan 10 04:46:40.803: INFO: (12) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 24.204454ms)
Jan 10 04:46:40.804: INFO: (12) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 24.790229ms)
Jan 10 04:46:40.804: INFO: (12) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 24.793473ms)
Jan 10 04:46:40.804: INFO: (12) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 25.090078ms)
Jan 10 04:46:40.805: INFO: (12) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 25.709373ms)
Jan 10 04:46:40.805: INFO: (12) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 25.863662ms)
Jan 10 04:46:40.806: INFO: (12) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 26.463471ms)
Jan 10 04:46:40.806: INFO: (12) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 26.637334ms)
Jan 10 04:46:40.806: INFO: (12) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 26.446127ms)
Jan 10 04:46:40.807: INFO: (12) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 27.086353ms)
Jan 10 04:46:40.807: INFO: (12) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 27.284715ms)
Jan 10 04:46:40.807: INFO: (12) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 27.410595ms)
Jan 10 04:46:40.808: INFO: (12) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 28.400595ms)
Jan 10 04:46:40.820: INFO: (13) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 11.758457ms)
Jan 10 04:46:40.821: INFO: (13) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 11.874048ms)
Jan 10 04:46:40.822: INFO: (13) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 13.787614ms)
Jan 10 04:46:40.822: INFO: (13) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 13.630026ms)
Jan 10 04:46:40.824: INFO: (13) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 15.467694ms)
Jan 10 04:46:40.824: INFO: (13) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 15.135777ms)
Jan 10 04:46:40.824: INFO: (13) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 15.221387ms)
Jan 10 04:46:40.825: INFO: (13) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 16.271945ms)
Jan 10 04:46:40.826: INFO: (13) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 16.428523ms)
Jan 10 04:46:40.826: INFO: (13) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 16.717154ms)
Jan 10 04:46:40.827: INFO: (13) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 17.855476ms)
Jan 10 04:46:40.827: INFO: (13) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 18.262883ms)
Jan 10 04:46:40.827: INFO: (13) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 18.565809ms)
Jan 10 04:46:40.828: INFO: (13) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 19.023378ms)
Jan 10 04:46:40.828: INFO: (13) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 19.237374ms)
Jan 10 04:46:40.829: INFO: (13) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 19.437152ms)
Jan 10 04:46:40.846: INFO: (14) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 17.214908ms)
Jan 10 04:46:40.846: INFO: (14) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 17.593056ms)
Jan 10 04:46:40.846: INFO: (14) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 17.350324ms)
Jan 10 04:46:40.847: INFO: (14) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 17.655694ms)
Jan 10 04:46:40.847: INFO: (14) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 17.64839ms)
Jan 10 04:46:40.848: INFO: (14) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 18.969055ms)
Jan 10 04:46:40.848: INFO: (14) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 18.918389ms)
Jan 10 04:46:40.848: INFO: (14) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 19.307894ms)
Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 19.653209ms)
Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 19.524152ms)
Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 19.792944ms)
Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 20.505766ms)
Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 19.958579ms)
Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 20.082786ms)
Jan 10 04:46:40.852: INFO: (14) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 22.759172ms)
Jan 10 04:46:40.852: INFO: (14) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 22.860614ms)
Jan 10 04:46:40.858: INFO: (15) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 5.259591ms)
Jan 10 04:46:40.858: INFO: (15) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 5.020959ms)
Jan 10 04:46:40.858: INFO: (15) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 4.987986ms)
Jan 10 04:46:40.867: INFO: (15) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 9.60664ms)
Jan 10 04:46:40.867: INFO: (15) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 9.688758ms)
Jan 10 04:46:40.867: INFO: (15) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 9.852003ms)
Jan 10 04:46:40.867: INFO: (15) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 9.784516ms)
Jan 10 04:46:40.870: INFO: (15) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 12.715021ms)
Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 16.346039ms)
Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 16.850531ms)
Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 16.690919ms)
Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 16.767791ms)
Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 20.998332ms)
Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 16.682831ms)
Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 16.857032ms)
Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 15.896666ms)
Jan 10 04:46:40.883: INFO: (16) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 9.4731ms)
Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 12.827944ms)
Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 13.015765ms)
Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 13.652566ms)
Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 13.715474ms)
Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 13.921143ms)
Jan 10 04:46:40.889: INFO: (16) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 14.09223ms)
Jan 10 04:46:40.889: INFO: (16) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 14.227178ms)
Jan 10 04:46:40.891: INFO: (16) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 16.915572ms)
Jan 10 04:46:40.892: INFO: (16) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 18.039748ms)
Jan 10 04:46:40.892: INFO: (16) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 17.23204ms)
Jan 10 04:46:40.892: INFO: (16) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 17.699049ms)
Jan 10 04:46:40.893: INFO: (16) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 18.429618ms)
Jan 10 04:46:40.893: INFO: (16) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 18.54387ms)
Jan 10 04:46:40.894: INFO: (16) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 19.252989ms)
Jan 10 04:46:40.894: INFO: (16) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 19.93542ms)
Jan 10 04:46:40.904: INFO: (17) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 10.023545ms)
Jan 10 04:46:40.904: INFO: (17) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 9.984015ms)
Jan 10 04:46:40.904: INFO: (17) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 10.048928ms)
Jan 10 04:46:40.908: INFO: (17) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 13.569761ms)
Jan 10 04:46:40.908: INFO: (17) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 13.762605ms)
Jan 10 04:46:40.910: INFO: (17) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 15.720528ms)
Jan 10 04:46:40.910: INFO: (17) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 15.951356ms)
Jan 10 04:46:40.911: INFO: (17) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 16.157008ms)
Jan 10 04:46:40.911: INFO: (17) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 16.06181ms)
Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 16.956191ms)
Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 17.199313ms)
Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 16.223527ms)
Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 17.614102ms)
Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 17.592413ms)
Jan 10 04:46:40.916: INFO: (17) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 19.925498ms)
Jan 10 04:46:40.916: INFO: (17) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 22.139428ms)
Jan 10 04:46:40.943: INFO: (18) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 25.778731ms)
Jan 10 04:46:40.943: INFO: (18) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 25.842783ms)
Jan 10 04:46:40.943: INFO: (18) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 25.945313ms)
Jan 10 04:46:40.944: INFO: (18) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 27.275842ms)
Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 27.610527ms)
Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 27.904963ms)
Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 28.263338ms)
Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 28.387005ms)
Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 28.167755ms)
Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 28.346468ms)
Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 31.73184ms)
Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 32.066982ms)
Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 32.443024ms)
Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 31.902257ms)
Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 32.050276ms)
Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 32.071439ms)
Jan 10 04:46:40.960: INFO: (19) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 9.587935ms)
Jan 10 04:46:40.960: INFO: (19) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 9.91315ms)
Jan 10 04:46:40.960: INFO: (19) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 10.683354ms)
Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 12.34585ms)
Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 12.692363ms)
Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 12.56174ms)
Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 12.420523ms)
Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 13.539897ms)
Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 12.964653ms)
Jan 10 04:46:40.964: INFO: (19) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 13.693627ms)
Jan 10 04:46:40.965: INFO: (19) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 14.787715ms)
Jan 10 04:46:40.965: INFO: (19) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 14.8103ms)
Jan 10 04:46:40.966: INFO: (19) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 15.658423ms)
Jan 10 04:46:40.966: INFO: (19) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 15.998625ms)
Jan 10 04:46:40.967: INFO: (19) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 16.753407ms)
Jan 10 04:46:40.967: INFO: (19) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 16.915761ms)
STEP: deleting ReplicationController proxy-service-9hs57 in namespace proxy-4199, will wait for the garbage collector to delete the pods 01/10/23 04:46:40.967
Jan 10 04:46:41.029: INFO: Deleting ReplicationController proxy-service-9hs57 took: 7.721301ms
Jan 10 04:46:41.130: INFO: Terminating ReplicationController proxy-service-9hs57 pods took: 100.75858ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jan 10 04:46:43.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4199" for this suite. 01/10/23 04:46:43.644
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":244,"skipped":4079,"failed":0}
------------------------------
• [SLOW TEST] [5.342 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:46:38.318
    Jan 10 04:46:38.318: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename proxy 01/10/23 04:46:38.319
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:38.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:38.383
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 01/10/23 04:46:38.427
    STEP: creating replication controller proxy-service-9hs57 in namespace proxy-4199 01/10/23 04:46:38.427
    I0110 04:46:38.457583      19 runners.go:193] Created replication controller with name: proxy-service-9hs57, namespace: proxy-4199, replica count: 1
    I0110 04:46:39.508696      19 runners.go:193] proxy-service-9hs57 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0110 04:46:40.508853      19 runners.go:193] proxy-service-9hs57 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 04:46:40.511: INFO: setup took 2.111868297s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 01/10/23 04:46:40.511
    Jan 10 04:46:40.524: INFO: (0) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 12.069623ms)
    Jan 10 04:46:40.530: INFO: (0) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 17.565132ms)
    Jan 10 04:46:40.530: INFO: (0) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 18.1142ms)
    Jan 10 04:46:40.530: INFO: (0) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 18.074688ms)
    Jan 10 04:46:40.532: INFO: (0) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 20.108214ms)
    Jan 10 04:46:40.532: INFO: (0) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 20.02808ms)
    Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 20.151169ms)
    Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 21.055815ms)
    Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 20.479307ms)
    Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 21.122248ms)
    Jan 10 04:46:40.533: INFO: (0) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 20.283667ms)
    Jan 10 04:46:40.536: INFO: (0) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 23.450396ms)
    Jan 10 04:46:40.537: INFO: (0) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 25.002344ms)
    Jan 10 04:46:40.538: INFO: (0) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 25.265746ms)
    Jan 10 04:46:40.538: INFO: (0) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 25.716141ms)
    Jan 10 04:46:40.538: INFO: (0) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 25.349819ms)
    Jan 10 04:46:40.557: INFO: (1) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 18.545227ms)
    Jan 10 04:46:40.557: INFO: (1) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 18.773521ms)
    Jan 10 04:46:40.564: INFO: (1) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 25.509027ms)
    Jan 10 04:46:40.565: INFO: (1) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 26.211448ms)
    Jan 10 04:46:40.566: INFO: (1) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 27.351553ms)
    Jan 10 04:46:40.569: INFO: (1) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 31.118714ms)
    Jan 10 04:46:40.569: INFO: (1) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 30.902752ms)
    Jan 10 04:46:40.570: INFO: (1) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 31.253615ms)
    Jan 10 04:46:40.570: INFO: (1) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 31.2658ms)
    Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 38.948636ms)
    Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 38.332711ms)
    Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 38.509412ms)
    Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 38.616845ms)
    Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 38.585364ms)
    Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 38.309977ms)
    Jan 10 04:46:40.577: INFO: (1) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 38.620925ms)
    Jan 10 04:46:40.589: INFO: (2) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 11.222821ms)
    Jan 10 04:46:40.589: INFO: (2) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 11.35176ms)
    Jan 10 04:46:40.589: INFO: (2) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 11.316683ms)
    Jan 10 04:46:40.590: INFO: (2) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 11.524652ms)
    Jan 10 04:46:40.590: INFO: (2) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 11.605045ms)
    Jan 10 04:46:40.590: INFO: (2) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 11.660792ms)
    Jan 10 04:46:40.590: INFO: (2) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 11.994375ms)
    Jan 10 04:46:40.592: INFO: (2) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 13.686067ms)
    Jan 10 04:46:40.592: INFO: (2) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 14.215681ms)
    Jan 10 04:46:40.593: INFO: (2) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 14.509791ms)
    Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 15.112207ms)
    Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 15.290491ms)
    Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 15.62533ms)
    Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 15.678359ms)
    Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 15.904029ms)
    Jan 10 04:46:40.594: INFO: (2) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 15.89149ms)
    Jan 10 04:46:40.600: INFO: (3) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 5.035425ms)
    Jan 10 04:46:40.603: INFO: (3) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 8.276804ms)
    Jan 10 04:46:40.606: INFO: (3) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 11.728702ms)
    Jan 10 04:46:40.608: INFO: (3) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 13.234739ms)
    Jan 10 04:46:40.608: INFO: (3) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 13.565207ms)
    Jan 10 04:46:40.611: INFO: (3) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 15.793747ms)
    Jan 10 04:46:40.611: INFO: (3) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 16.293613ms)
    Jan 10 04:46:40.611: INFO: (3) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 16.476317ms)
    Jan 10 04:46:40.612: INFO: (3) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 16.565267ms)
    Jan 10 04:46:40.614: INFO: (3) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 19.839979ms)
    Jan 10 04:46:40.615: INFO: (3) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 20.038265ms)
    Jan 10 04:46:40.615: INFO: (3) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 20.481432ms)
    Jan 10 04:46:40.615: INFO: (3) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 20.287274ms)
    Jan 10 04:46:40.615: INFO: (3) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 21.144051ms)
    Jan 10 04:46:40.616: INFO: (3) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 20.495848ms)
    Jan 10 04:46:40.616: INFO: (3) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 20.913333ms)
    Jan 10 04:46:40.633: INFO: (4) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 17.164717ms)
    Jan 10 04:46:40.633: INFO: (4) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 17.316977ms)
    Jan 10 04:46:40.633: INFO: (4) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 16.892537ms)
    Jan 10 04:46:40.634: INFO: (4) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 17.922071ms)
    Jan 10 04:46:40.634: INFO: (4) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 17.713901ms)
    Jan 10 04:46:40.634: INFO: (4) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 17.54145ms)
    Jan 10 04:46:40.634: INFO: (4) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 17.931542ms)
    Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 18.529231ms)
    Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 18.777516ms)
    Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 18.851756ms)
    Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 18.777425ms)
    Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 19.00157ms)
    Jan 10 04:46:40.635: INFO: (4) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 19.59689ms)
    Jan 10 04:46:40.636: INFO: (4) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 19.570108ms)
    Jan 10 04:46:40.636: INFO: (4) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 19.79814ms)
    Jan 10 04:46:40.636: INFO: (4) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 19.796526ms)
    Jan 10 04:46:40.644: INFO: (5) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 7.424334ms)
    Jan 10 04:46:40.654: INFO: (5) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 15.569294ms)
    Jan 10 04:46:40.655: INFO: (5) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 16.072345ms)
    Jan 10 04:46:40.655: INFO: (5) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 16.200475ms)
    Jan 10 04:46:40.655: INFO: (5) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 16.252426ms)
    Jan 10 04:46:40.655: INFO: (5) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 18.442977ms)
    Jan 10 04:46:40.656: INFO: (5) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 17.613337ms)
    Jan 10 04:46:40.656: INFO: (5) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 17.341401ms)
    Jan 10 04:46:40.656: INFO: (5) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 17.39283ms)
    Jan 10 04:46:40.656: INFO: (5) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 17.331426ms)
    Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 18.112426ms)
    Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 20.000815ms)
    Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 18.032149ms)
    Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 18.44983ms)
    Jan 10 04:46:40.657: INFO: (5) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 18.543027ms)
    Jan 10 04:46:40.659: INFO: (5) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 20.868393ms)
    Jan 10 04:46:40.668: INFO: (6) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 8.52758ms)
    Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 9.043936ms)
    Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 8.97809ms)
    Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 9.054383ms)
    Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 9.690495ms)
    Jan 10 04:46:40.669: INFO: (6) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 9.752859ms)
    Jan 10 04:46:40.675: INFO: (6) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 15.004535ms)
    Jan 10 04:46:40.675: INFO: (6) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 15.283576ms)
    Jan 10 04:46:40.675: INFO: (6) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 15.594685ms)
    Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 16.022641ms)
    Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 16.067799ms)
    Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 16.404129ms)
    Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 16.141772ms)
    Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 16.573703ms)
    Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 16.386879ms)
    Jan 10 04:46:40.676: INFO: (6) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 16.342366ms)
    Jan 10 04:46:40.686: INFO: (7) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 8.995478ms)
    Jan 10 04:46:40.686: INFO: (7) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 9.697434ms)
    Jan 10 04:46:40.686: INFO: (7) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 9.530139ms)
    Jan 10 04:46:40.687: INFO: (7) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 10.40389ms)
    Jan 10 04:46:40.688: INFO: (7) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 11.614113ms)
    Jan 10 04:46:40.689: INFO: (7) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 12.466803ms)
    Jan 10 04:46:40.690: INFO: (7) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 12.776515ms)
    Jan 10 04:46:40.690: INFO: (7) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 12.988716ms)
    Jan 10 04:46:40.690: INFO: (7) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 12.900326ms)
    Jan 10 04:46:40.690: INFO: (7) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 13.427726ms)
    Jan 10 04:46:40.691: INFO: (7) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 14.617708ms)
    Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 15.138207ms)
    Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 15.258648ms)
    Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 14.999772ms)
    Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 15.646505ms)
    Jan 10 04:46:40.692: INFO: (7) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 15.748187ms)
    Jan 10 04:46:40.697: INFO: (8) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 4.484222ms)
    Jan 10 04:46:40.698: INFO: (8) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 5.404717ms)
    Jan 10 04:46:40.700: INFO: (8) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 7.877981ms)
    Jan 10 04:46:40.700: INFO: (8) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 8.183233ms)
    Jan 10 04:46:40.703: INFO: (8) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 10.234163ms)
    Jan 10 04:46:40.703: INFO: (8) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 10.202413ms)
    Jan 10 04:46:40.706: INFO: (8) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 13.357246ms)
    Jan 10 04:46:40.707: INFO: (8) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 14.306592ms)
    Jan 10 04:46:40.707: INFO: (8) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 14.748101ms)
    Jan 10 04:46:40.707: INFO: (8) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 14.62319ms)
    Jan 10 04:46:40.708: INFO: (8) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 15.015546ms)
    Jan 10 04:46:40.708: INFO: (8) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 15.268251ms)
    Jan 10 04:46:40.708: INFO: (8) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 15.716611ms)
    Jan 10 04:46:40.708: INFO: (8) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 15.791332ms)
    Jan 10 04:46:40.709: INFO: (8) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 16.053546ms)
    Jan 10 04:46:40.709: INFO: (8) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 15.97854ms)
    Jan 10 04:46:40.721: INFO: (9) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 11.957098ms)
    Jan 10 04:46:40.721: INFO: (9) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 12.018246ms)
    Jan 10 04:46:40.722: INFO: (9) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 13.08108ms)
    Jan 10 04:46:40.726: INFO: (9) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 16.457171ms)
    Jan 10 04:46:40.726: INFO: (9) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 17.251914ms)
    Jan 10 04:46:40.726: INFO: (9) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 17.469847ms)
    Jan 10 04:46:40.730: INFO: (9) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 20.628703ms)
    Jan 10 04:46:40.731: INFO: (9) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 21.734176ms)
    Jan 10 04:46:40.734: INFO: (9) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 24.027114ms)
    Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 26.977706ms)
    Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 26.982611ms)
    Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 27.28594ms)
    Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 27.588637ms)
    Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 27.317598ms)
    Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 27.548076ms)
    Jan 10 04:46:40.737: INFO: (9) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 27.760484ms)
    Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 11.564927ms)
    Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 11.494258ms)
    Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 13.042029ms)
    Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 12.810627ms)
    Jan 10 04:46:40.750: INFO: (10) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 12.897291ms)
    Jan 10 04:46:40.757: INFO: (10) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 19.016863ms)
    Jan 10 04:46:40.757: INFO: (10) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 19.104963ms)
    Jan 10 04:46:40.758: INFO: (10) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 20.760427ms)
    Jan 10 04:46:40.758: INFO: (10) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 20.384227ms)
    Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 20.948911ms)
    Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 20.865149ms)
    Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 21.117878ms)
    Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 21.320876ms)
    Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 20.908631ms)
    Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 21.228995ms)
    Jan 10 04:46:40.759: INFO: (10) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 21.461131ms)
    Jan 10 04:46:40.766: INFO: (11) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 6.581692ms)
    Jan 10 04:46:40.766: INFO: (11) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 6.5079ms)
    Jan 10 04:46:40.770: INFO: (11) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 10.493316ms)
    Jan 10 04:46:40.771: INFO: (11) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 10.7316ms)
    Jan 10 04:46:40.771: INFO: (11) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 10.827841ms)
    Jan 10 04:46:40.776: INFO: (11) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 15.646764ms)
    Jan 10 04:46:40.776: INFO: (11) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 15.986294ms)
    Jan 10 04:46:40.777: INFO: (11) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 17.094923ms)
    Jan 10 04:46:40.777: INFO: (11) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 17.076429ms)
    Jan 10 04:46:40.778: INFO: (11) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 17.699195ms)
    Jan 10 04:46:40.778: INFO: (11) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 17.58261ms)
    Jan 10 04:46:40.778: INFO: (11) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 18.166435ms)
    Jan 10 04:46:40.778: INFO: (11) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 18.46606ms)
    Jan 10 04:46:40.779: INFO: (11) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 18.535455ms)
    Jan 10 04:46:40.779: INFO: (11) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 18.302712ms)
    Jan 10 04:46:40.779: INFO: (11) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 18.484284ms)
    Jan 10 04:46:40.800: INFO: (12) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 21.164727ms)
    Jan 10 04:46:40.802: INFO: (12) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 23.233364ms)
    Jan 10 04:46:40.802: INFO: (12) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 22.955667ms)
    Jan 10 04:46:40.803: INFO: (12) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 24.204454ms)
    Jan 10 04:46:40.804: INFO: (12) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 24.790229ms)
    Jan 10 04:46:40.804: INFO: (12) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 24.793473ms)
    Jan 10 04:46:40.804: INFO: (12) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 25.090078ms)
    Jan 10 04:46:40.805: INFO: (12) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 25.709373ms)
    Jan 10 04:46:40.805: INFO: (12) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 25.863662ms)
    Jan 10 04:46:40.806: INFO: (12) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 26.463471ms)
    Jan 10 04:46:40.806: INFO: (12) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 26.637334ms)
    Jan 10 04:46:40.806: INFO: (12) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 26.446127ms)
    Jan 10 04:46:40.807: INFO: (12) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 27.086353ms)
    Jan 10 04:46:40.807: INFO: (12) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 27.284715ms)
    Jan 10 04:46:40.807: INFO: (12) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 27.410595ms)
    Jan 10 04:46:40.808: INFO: (12) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 28.400595ms)
    Jan 10 04:46:40.820: INFO: (13) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 11.758457ms)
    Jan 10 04:46:40.821: INFO: (13) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 11.874048ms)
    Jan 10 04:46:40.822: INFO: (13) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 13.787614ms)
    Jan 10 04:46:40.822: INFO: (13) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 13.630026ms)
    Jan 10 04:46:40.824: INFO: (13) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 15.467694ms)
    Jan 10 04:46:40.824: INFO: (13) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 15.135777ms)
    Jan 10 04:46:40.824: INFO: (13) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 15.221387ms)
    Jan 10 04:46:40.825: INFO: (13) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 16.271945ms)
    Jan 10 04:46:40.826: INFO: (13) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 16.428523ms)
    Jan 10 04:46:40.826: INFO: (13) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 16.717154ms)
    Jan 10 04:46:40.827: INFO: (13) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 17.855476ms)
    Jan 10 04:46:40.827: INFO: (13) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 18.262883ms)
    Jan 10 04:46:40.827: INFO: (13) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 18.565809ms)
    Jan 10 04:46:40.828: INFO: (13) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 19.023378ms)
    Jan 10 04:46:40.828: INFO: (13) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 19.237374ms)
    Jan 10 04:46:40.829: INFO: (13) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 19.437152ms)
    Jan 10 04:46:40.846: INFO: (14) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 17.214908ms)
    Jan 10 04:46:40.846: INFO: (14) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 17.593056ms)
    Jan 10 04:46:40.846: INFO: (14) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 17.350324ms)
    Jan 10 04:46:40.847: INFO: (14) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 17.655694ms)
    Jan 10 04:46:40.847: INFO: (14) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 17.64839ms)
    Jan 10 04:46:40.848: INFO: (14) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 18.969055ms)
    Jan 10 04:46:40.848: INFO: (14) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 18.918389ms)
    Jan 10 04:46:40.848: INFO: (14) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 19.307894ms)
    Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 19.653209ms)
    Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 19.524152ms)
    Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 19.792944ms)
    Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 20.505766ms)
    Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 19.958579ms)
    Jan 10 04:46:40.849: INFO: (14) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 20.082786ms)
    Jan 10 04:46:40.852: INFO: (14) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 22.759172ms)
    Jan 10 04:46:40.852: INFO: (14) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 22.860614ms)
    Jan 10 04:46:40.858: INFO: (15) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 5.259591ms)
    Jan 10 04:46:40.858: INFO: (15) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 5.020959ms)
    Jan 10 04:46:40.858: INFO: (15) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 4.987986ms)
    Jan 10 04:46:40.867: INFO: (15) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 9.60664ms)
    Jan 10 04:46:40.867: INFO: (15) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 9.688758ms)
    Jan 10 04:46:40.867: INFO: (15) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 9.852003ms)
    Jan 10 04:46:40.867: INFO: (15) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 9.784516ms)
    Jan 10 04:46:40.870: INFO: (15) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 12.715021ms)
    Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 16.346039ms)
    Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 16.850531ms)
    Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 16.690919ms)
    Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 16.767791ms)
    Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 20.998332ms)
    Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 16.682831ms)
    Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 16.857032ms)
    Jan 10 04:46:40.874: INFO: (15) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 15.896666ms)
    Jan 10 04:46:40.883: INFO: (16) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 9.4731ms)
    Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 12.827944ms)
    Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 13.015765ms)
    Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 13.652566ms)
    Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 13.715474ms)
    Jan 10 04:46:40.888: INFO: (16) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 13.921143ms)
    Jan 10 04:46:40.889: INFO: (16) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 14.09223ms)
    Jan 10 04:46:40.889: INFO: (16) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 14.227178ms)
    Jan 10 04:46:40.891: INFO: (16) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 16.915572ms)
    Jan 10 04:46:40.892: INFO: (16) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 18.039748ms)
    Jan 10 04:46:40.892: INFO: (16) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 17.23204ms)
    Jan 10 04:46:40.892: INFO: (16) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 17.699049ms)
    Jan 10 04:46:40.893: INFO: (16) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 18.429618ms)
    Jan 10 04:46:40.893: INFO: (16) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 18.54387ms)
    Jan 10 04:46:40.894: INFO: (16) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 19.252989ms)
    Jan 10 04:46:40.894: INFO: (16) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 19.93542ms)
    Jan 10 04:46:40.904: INFO: (17) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 10.023545ms)
    Jan 10 04:46:40.904: INFO: (17) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 9.984015ms)
    Jan 10 04:46:40.904: INFO: (17) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 10.048928ms)
    Jan 10 04:46:40.908: INFO: (17) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 13.569761ms)
    Jan 10 04:46:40.908: INFO: (17) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 13.762605ms)
    Jan 10 04:46:40.910: INFO: (17) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 15.720528ms)
    Jan 10 04:46:40.910: INFO: (17) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 15.951356ms)
    Jan 10 04:46:40.911: INFO: (17) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 16.157008ms)
    Jan 10 04:46:40.911: INFO: (17) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 16.06181ms)
    Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 16.956191ms)
    Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 17.199313ms)
    Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 16.223527ms)
    Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 17.614102ms)
    Jan 10 04:46:40.912: INFO: (17) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 17.592413ms)
    Jan 10 04:46:40.916: INFO: (17) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 19.925498ms)
    Jan 10 04:46:40.916: INFO: (17) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 22.139428ms)
    Jan 10 04:46:40.943: INFO: (18) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 25.778731ms)
    Jan 10 04:46:40.943: INFO: (18) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 25.842783ms)
    Jan 10 04:46:40.943: INFO: (18) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 25.945313ms)
    Jan 10 04:46:40.944: INFO: (18) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 27.275842ms)
    Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 27.610527ms)
    Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 27.904963ms)
    Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 28.263338ms)
    Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 28.387005ms)
    Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 28.167755ms)
    Jan 10 04:46:40.945: INFO: (18) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 28.346468ms)
    Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 31.73184ms)
    Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 32.066982ms)
    Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 32.443024ms)
    Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 31.902257ms)
    Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 32.050276ms)
    Jan 10 04:46:40.949: INFO: (18) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 32.071439ms)
    Jan 10 04:46:40.960: INFO: (19) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">... (200; 9.587935ms)
    Jan 10 04:46:40.960: INFO: (19) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:443/proxy/tlsrewritem... (200; 9.91315ms)
    Jan 10 04:46:40.960: INFO: (19) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 10.683354ms)
    Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname2/proxy/: bar (200; 12.34585ms)
    Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname1/proxy/: foo (200; 12.692363ms)
    Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname1/proxy/: tls baz (200; 12.56174ms)
    Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/proxy-service-9hs57:portname1/proxy/: foo (200; 12.420523ms)
    Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/http:proxy-service-9hs57:portname2/proxy/: bar (200; 13.539897ms)
    Jan 10 04:46:40.963: INFO: (19) /api/v1/namespaces/proxy-4199/services/https:proxy-service-9hs57:tlsportname2/proxy/: tls qux (200; 12.964653ms)
    Jan 10 04:46:40.964: INFO: (19) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 13.693627ms)
    Jan 10 04:46:40.965: INFO: (19) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:1080/proxy/rewriteme">test<... (200; 14.787715ms)
    Jan 10 04:46:40.965: INFO: (19) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/: <a href="/api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm/proxy/rewriteme">test</a> (200; 14.8103ms)
    Jan 10 04:46:40.966: INFO: (19) /api/v1/namespaces/proxy-4199/pods/http:proxy-service-9hs57-2dpkm:160/proxy/: foo (200; 15.658423ms)
    Jan 10 04:46:40.966: INFO: (19) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:462/proxy/: tls qux (200; 15.998625ms)
    Jan 10 04:46:40.967: INFO: (19) /api/v1/namespaces/proxy-4199/pods/proxy-service-9hs57-2dpkm:162/proxy/: bar (200; 16.753407ms)
    Jan 10 04:46:40.967: INFO: (19) /api/v1/namespaces/proxy-4199/pods/https:proxy-service-9hs57-2dpkm:460/proxy/: tls baz (200; 16.915761ms)
    STEP: deleting ReplicationController proxy-service-9hs57 in namespace proxy-4199, will wait for the garbage collector to delete the pods 01/10/23 04:46:40.967
    Jan 10 04:46:41.029: INFO: Deleting ReplicationController proxy-service-9hs57 took: 7.721301ms
    Jan 10 04:46:41.130: INFO: Terminating ReplicationController proxy-service-9hs57 pods took: 100.75858ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jan 10 04:46:43.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-4199" for this suite. 01/10/23 04:46:43.644
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:46:43.663
Jan 10 04:46:43.664: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:46:43.665
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:43.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:43.746
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 01/10/23 04:46:43.774
Jan 10 04:46:43.775: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: rename a version 01/10/23 04:46:53.462
STEP: check the new version name is served 01/10/23 04:46:53.485
STEP: check the old version name is removed 01/10/23 04:46:57.602
STEP: check the other version is not changed 01/10/23 04:46:59.207
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:47:06.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-187" for this suite. 01/10/23 04:47:06.33
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":245,"skipped":4085,"failed":0}
------------------------------
• [SLOW TEST] [22.677 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:46:43.663
    Jan 10 04:46:43.664: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 04:46:43.665
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:46:43.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:46:43.746
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 01/10/23 04:46:43.774
    Jan 10 04:46:43.775: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: rename a version 01/10/23 04:46:53.462
    STEP: check the new version name is served 01/10/23 04:46:53.485
    STEP: check the old version name is removed 01/10/23 04:46:57.602
    STEP: check the other version is not changed 01/10/23 04:46:59.207
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:47:06.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-187" for this suite. 01/10/23 04:47:06.33
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:47:06.342
Jan 10 04:47:06.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:47:06.343
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:06.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:06.385
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-bb03689a-682c-4912-aed8-536986f94779 01/10/23 04:47:06.392
STEP: Creating a pod to test consume configMaps 01/10/23 04:47:06.405
Jan 10 04:47:06.428: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479" in namespace "projected-6088" to be "Succeeded or Failed"
Jan 10 04:47:06.446: INFO: Pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479": Phase="Pending", Reason="", readiness=false. Elapsed: 18.083322ms
Jan 10 04:47:08.461: INFO: Pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03277529s
Jan 10 04:47:10.451: INFO: Pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022804403s
STEP: Saw pod success 01/10/23 04:47:10.451
Jan 10 04:47:10.451: INFO: Pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479" satisfied condition "Succeeded or Failed"
Jan 10 04:47:10.458: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479 container projected-configmap-volume-test: <nil>
STEP: delete the pod 01/10/23 04:47:10.464
Jan 10 04:47:10.475: INFO: Waiting for pod pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479 to disappear
Jan 10 04:47:10.477: INFO: Pod pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 04:47:10.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6088" for this suite. 01/10/23 04:47:10.482
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":246,"skipped":4088,"failed":0}
------------------------------
• [4.146 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:47:06.342
    Jan 10 04:47:06.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:47:06.343
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:06.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:06.385
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-bb03689a-682c-4912-aed8-536986f94779 01/10/23 04:47:06.392
    STEP: Creating a pod to test consume configMaps 01/10/23 04:47:06.405
    Jan 10 04:47:06.428: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479" in namespace "projected-6088" to be "Succeeded or Failed"
    Jan 10 04:47:06.446: INFO: Pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479": Phase="Pending", Reason="", readiness=false. Elapsed: 18.083322ms
    Jan 10 04:47:08.461: INFO: Pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03277529s
    Jan 10 04:47:10.451: INFO: Pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022804403s
    STEP: Saw pod success 01/10/23 04:47:10.451
    Jan 10 04:47:10.451: INFO: Pod "pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479" satisfied condition "Succeeded or Failed"
    Jan 10 04:47:10.458: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:47:10.464
    Jan 10 04:47:10.475: INFO: Waiting for pod pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479 to disappear
    Jan 10 04:47:10.477: INFO: Pod pod-projected-configmaps-09137553-1363-4f07-94a2-4cc13d007479 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 04:47:10.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6088" for this suite. 01/10/23 04:47:10.482
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:47:10.492
Jan 10 04:47:10.492: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename daemonsets 01/10/23 04:47:10.493
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:10.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:10.526
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 01/10/23 04:47:10.572
STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:47:10.58
Jan 10 04:47:10.617: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:47:10.617: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:47:11.704: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:47:11.704: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:47:12.624: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 04:47:12.625: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:47:13.623: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 04:47:13.623: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 01/10/23 04:47:13.625
STEP: DeleteCollection of the DaemonSets 01/10/23 04:47:13.627
STEP: Verify that ReplicaSets have been deleted 01/10/23 04:47:13.633
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Jan 10 04:47:13.649: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"241314"},"items":null}

Jan 10 04:47:13.653: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"241314"},"items":[{"metadata":{"name":"daemon-set-h5k45","generateName":"daemon-set-","namespace":"daemonsets-195","uid":"18bcaf73-b22e-4707-9ed8-5b5de7d385b2","resourceVersion":"241311","creationTimestamp":"2023-01-10T04:47:10Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"1c5d8b1bb5cfaca10934a1ef0e6b141fd48ffb153034226c54a4f6a21b3dbb0f","cni.projectcalico.org/podIP":"10.42.0.109/32","cni.projectcalico.org/podIPs":"10.42.0.109/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cb7d9b61-53c5-4fde-a359-8dbcdacb718d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cb7d9b61-53c5-4fde-a359-8dbcdacb718d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.109\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-n5wzj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-n5wzj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf-cp-etcd-wk1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf-cp-etcd-wk1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"}],"hostIP":"172.31.15.218","podIP":"10.42.0.109","podIPs":[{"ip":"10.42.0.109"}],"startTime":"2023-01-10T04:47:10Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-10T04:47:12Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://d1bcd6ce570f5387efbb9d0afb8c324a78b496856f02c81087f91539f2733028","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-khbr8","generateName":"daemon-set-","namespace":"daemonsets-195","uid":"7c295869-d543-48d0-9f80-8ae0df3603f6","resourceVersion":"241299","creationTimestamp":"2023-01-10T04:47:10Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"63d1089ad801e11079d9d0d6526ffd73ea1abcfc8bf4c9290cd509a4c23a8615","cni.projectcalico.org/podIP":"10.42.2.163/32","cni.projectcalico.org/podIPs":"10.42.2.163/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cb7d9b61-53c5-4fde-a359-8dbcdacb718d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cb7d9b61-53c5-4fde-a359-8dbcdacb718d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.163\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-fsm89","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-fsm89","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf-wk3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf-wk3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:11Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:11Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"}],"hostIP":"172.31.7.114","podIP":"10.42.2.163","podIPs":[{"ip":"10.42.2.163"}],"startTime":"2023-01-10T04:47:10Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-10T04:47:11Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://40595fd5a3ecbf02fbabf28b52e62ea0901560623c880c80eb984b37a8bc50ce","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s5nxn","generateName":"daemon-set-","namespace":"daemonsets-195","uid":"f75d24fc-447e-4f2f-8f56-00d5ccf1b69c","resourceVersion":"241306","creationTimestamp":"2023-01-10T04:47:10Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f4a2362aa5567bfdff0efb4aa82d5a57d9bf69a75c1ad6674eb4b03642c35b99","cni.projectcalico.org/podIP":"10.42.1.51/32","cni.projectcalico.org/podIPs":"10.42.1.51/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cb7d9b61-53c5-4fde-a359-8dbcdacb718d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cb7d9b61-53c5-4fde-a359-8dbcdacb718d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.51\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-zzmmj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-zzmmj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf-wk2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf-wk2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:12Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:12Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"}],"hostIP":"172.31.3.44","podIP":"10.42.1.51","podIPs":[{"ip":"10.42.1.51"}],"startTime":"2023-01-10T04:47:10Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-10T04:47:11Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://33edac1b1593bd80dcbf6205399fe38412b356feb80faff5e992daa37c3a794a","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:47:13.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-195" for this suite. 01/10/23 04:47:13.693
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":247,"skipped":4107,"failed":0}
------------------------------
• [3.207 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:47:10.492
    Jan 10 04:47:10.492: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename daemonsets 01/10/23 04:47:10.493
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:10.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:10.526
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 01/10/23 04:47:10.572
    STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:47:10.58
    Jan 10 04:47:10.617: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:47:10.617: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:47:11.704: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:47:11.704: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:47:12.624: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 04:47:12.625: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:47:13.623: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 04:47:13.623: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 01/10/23 04:47:13.625
    STEP: DeleteCollection of the DaemonSets 01/10/23 04:47:13.627
    STEP: Verify that ReplicaSets have been deleted 01/10/23 04:47:13.633
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Jan 10 04:47:13.649: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"241314"},"items":null}

    Jan 10 04:47:13.653: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"241314"},"items":[{"metadata":{"name":"daemon-set-h5k45","generateName":"daemon-set-","namespace":"daemonsets-195","uid":"18bcaf73-b22e-4707-9ed8-5b5de7d385b2","resourceVersion":"241311","creationTimestamp":"2023-01-10T04:47:10Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"1c5d8b1bb5cfaca10934a1ef0e6b141fd48ffb153034226c54a4f6a21b3dbb0f","cni.projectcalico.org/podIP":"10.42.0.109/32","cni.projectcalico.org/podIPs":"10.42.0.109/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cb7d9b61-53c5-4fde-a359-8dbcdacb718d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cb7d9b61-53c5-4fde-a359-8dbcdacb718d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.109\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-n5wzj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-n5wzj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf-cp-etcd-wk1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf-cp-etcd-wk1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"}],"hostIP":"172.31.15.218","podIP":"10.42.0.109","podIPs":[{"ip":"10.42.0.109"}],"startTime":"2023-01-10T04:47:10Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-10T04:47:12Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://d1bcd6ce570f5387efbb9d0afb8c324a78b496856f02c81087f91539f2733028","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-khbr8","generateName":"daemon-set-","namespace":"daemonsets-195","uid":"7c295869-d543-48d0-9f80-8ae0df3603f6","resourceVersion":"241299","creationTimestamp":"2023-01-10T04:47:10Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"63d1089ad801e11079d9d0d6526ffd73ea1abcfc8bf4c9290cd509a4c23a8615","cni.projectcalico.org/podIP":"10.42.2.163/32","cni.projectcalico.org/podIPs":"10.42.2.163/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cb7d9b61-53c5-4fde-a359-8dbcdacb718d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cb7d9b61-53c5-4fde-a359-8dbcdacb718d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.163\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-fsm89","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-fsm89","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf-wk3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf-wk3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:11Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:11Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"}],"hostIP":"172.31.7.114","podIP":"10.42.2.163","podIPs":[{"ip":"10.42.2.163"}],"startTime":"2023-01-10T04:47:10Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-10T04:47:11Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://40595fd5a3ecbf02fbabf28b52e62ea0901560623c880c80eb984b37a8bc50ce","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s5nxn","generateName":"daemon-set-","namespace":"daemonsets-195","uid":"f75d24fc-447e-4f2f-8f56-00d5ccf1b69c","resourceVersion":"241306","creationTimestamp":"2023-01-10T04:47:10Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f4a2362aa5567bfdff0efb4aa82d5a57d9bf69a75c1ad6674eb4b03642c35b99","cni.projectcalico.org/podIP":"10.42.1.51/32","cni.projectcalico.org/podIPs":"10.42.1.51/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cb7d9b61-53c5-4fde-a359-8dbcdacb718d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:10Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cb7d9b61-53c5-4fde-a359-8dbcdacb718d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-10T04:47:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.51\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-zzmmj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-zzmmj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"cncf-wk2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["cncf-wk2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:12Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:12Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-10T04:47:10Z"}],"hostIP":"172.31.3.44","podIP":"10.42.1.51","podIPs":[{"ip":"10.42.1.51"}],"startTime":"2023-01-10T04:47:10Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-10T04:47:11Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://33edac1b1593bd80dcbf6205399fe38412b356feb80faff5e992daa37c3a794a","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:47:13.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-195" for this suite. 01/10/23 04:47:13.693
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:47:13.7
Jan 10 04:47:13.700: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 04:47:13.701
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:13.773
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:13.78
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 01/10/23 04:47:13.786
STEP: Ensuring ResourceQuota status is calculated 01/10/23 04:47:13.802
STEP: Creating a ResourceQuota with not best effort scope 01/10/23 04:47:15.812
STEP: Ensuring ResourceQuota status is calculated 01/10/23 04:47:15.817
STEP: Creating a best-effort pod 01/10/23 04:47:17.83
STEP: Ensuring resource quota with best effort scope captures the pod usage 01/10/23 04:47:17.875
STEP: Ensuring resource quota with not best effort ignored the pod usage 01/10/23 04:47:19.878
STEP: Deleting the pod 01/10/23 04:47:21.882
STEP: Ensuring resource quota status released the pod usage 01/10/23 04:47:21.9
STEP: Creating a not best-effort pod 01/10/23 04:47:23.903
STEP: Ensuring resource quota with not best effort scope captures the pod usage 01/10/23 04:47:23.912
STEP: Ensuring resource quota with best effort scope ignored the pod usage 01/10/23 04:47:25.914
STEP: Deleting the pod 01/10/23 04:47:27.918
STEP: Ensuring resource quota status released the pod usage 01/10/23 04:47:27.937
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 04:47:29.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7121" for this suite. 01/10/23 04:47:29.949
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":248,"skipped":4109,"failed":0}
------------------------------
• [SLOW TEST] [16.258 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:47:13.7
    Jan 10 04:47:13.700: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 04:47:13.701
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:13.773
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:13.78
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 01/10/23 04:47:13.786
    STEP: Ensuring ResourceQuota status is calculated 01/10/23 04:47:13.802
    STEP: Creating a ResourceQuota with not best effort scope 01/10/23 04:47:15.812
    STEP: Ensuring ResourceQuota status is calculated 01/10/23 04:47:15.817
    STEP: Creating a best-effort pod 01/10/23 04:47:17.83
    STEP: Ensuring resource quota with best effort scope captures the pod usage 01/10/23 04:47:17.875
    STEP: Ensuring resource quota with not best effort ignored the pod usage 01/10/23 04:47:19.878
    STEP: Deleting the pod 01/10/23 04:47:21.882
    STEP: Ensuring resource quota status released the pod usage 01/10/23 04:47:21.9
    STEP: Creating a not best-effort pod 01/10/23 04:47:23.903
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 01/10/23 04:47:23.912
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 01/10/23 04:47:25.914
    STEP: Deleting the pod 01/10/23 04:47:27.918
    STEP: Ensuring resource quota status released the pod usage 01/10/23 04:47:27.937
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 04:47:29.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7121" for this suite. 01/10/23 04:47:29.949
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:47:29.958
Jan 10 04:47:29.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename proxy 01/10/23 04:47:29.96
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:30.016
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:30.026
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Jan 10 04:47:30.032: INFO: Creating pod...
Jan 10 04:47:30.044: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7010" to be "running"
Jan 10 04:47:30.060: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 15.542166ms
Jan 10 04:47:32.065: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.020794568s
Jan 10 04:47:32.065: INFO: Pod "agnhost" satisfied condition "running"
Jan 10 04:47:32.065: INFO: Creating service...
Jan 10 04:47:32.075: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=DELETE
Jan 10 04:47:32.088: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jan 10 04:47:32.088: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=OPTIONS
Jan 10 04:47:32.093: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jan 10 04:47:32.093: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=PATCH
Jan 10 04:47:32.096: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jan 10 04:47:32.096: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=POST
Jan 10 04:47:32.100: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jan 10 04:47:32.100: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=PUT
Jan 10 04:47:32.104: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jan 10 04:47:32.104: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=DELETE
Jan 10 04:47:32.109: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jan 10 04:47:32.109: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=OPTIONS
Jan 10 04:47:32.115: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jan 10 04:47:32.115: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=PATCH
Jan 10 04:47:32.118: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jan 10 04:47:32.119: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=POST
Jan 10 04:47:32.122: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jan 10 04:47:32.122: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=PUT
Jan 10 04:47:32.132: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jan 10 04:47:32.132: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=GET
Jan 10 04:47:32.136: INFO: http.Client request:GET StatusCode:301
Jan 10 04:47:32.136: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=GET
Jan 10 04:47:32.139: INFO: http.Client request:GET StatusCode:301
Jan 10 04:47:32.139: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=HEAD
Jan 10 04:47:32.142: INFO: http.Client request:HEAD StatusCode:301
Jan 10 04:47:32.142: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=HEAD
Jan 10 04:47:32.145: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jan 10 04:47:32.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7010" for this suite. 01/10/23 04:47:32.153
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":249,"skipped":4111,"failed":0}
------------------------------
• [2.202 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:47:29.958
    Jan 10 04:47:29.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename proxy 01/10/23 04:47:29.96
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:30.016
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:30.026
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Jan 10 04:47:30.032: INFO: Creating pod...
    Jan 10 04:47:30.044: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7010" to be "running"
    Jan 10 04:47:30.060: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 15.542166ms
    Jan 10 04:47:32.065: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.020794568s
    Jan 10 04:47:32.065: INFO: Pod "agnhost" satisfied condition "running"
    Jan 10 04:47:32.065: INFO: Creating service...
    Jan 10 04:47:32.075: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=DELETE
    Jan 10 04:47:32.088: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jan 10 04:47:32.088: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=OPTIONS
    Jan 10 04:47:32.093: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jan 10 04:47:32.093: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=PATCH
    Jan 10 04:47:32.096: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jan 10 04:47:32.096: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=POST
    Jan 10 04:47:32.100: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jan 10 04:47:32.100: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=PUT
    Jan 10 04:47:32.104: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jan 10 04:47:32.104: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=DELETE
    Jan 10 04:47:32.109: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jan 10 04:47:32.109: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Jan 10 04:47:32.115: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jan 10 04:47:32.115: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=PATCH
    Jan 10 04:47:32.118: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jan 10 04:47:32.119: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=POST
    Jan 10 04:47:32.122: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jan 10 04:47:32.122: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=PUT
    Jan 10 04:47:32.132: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jan 10 04:47:32.132: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=GET
    Jan 10 04:47:32.136: INFO: http.Client request:GET StatusCode:301
    Jan 10 04:47:32.136: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=GET
    Jan 10 04:47:32.139: INFO: http.Client request:GET StatusCode:301
    Jan 10 04:47:32.139: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/pods/agnhost/proxy?method=HEAD
    Jan 10 04:47:32.142: INFO: http.Client request:HEAD StatusCode:301
    Jan 10 04:47:32.142: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-7010/services/e2e-proxy-test-service/proxy?method=HEAD
    Jan 10 04:47:32.145: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jan 10 04:47:32.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-7010" for this suite. 01/10/23 04:47:32.153
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:47:32.164
Jan 10 04:47:32.165: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:47:32.167
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:32.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:32.301
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 01/10/23 04:47:32.305
Jan 10 04:47:32.321: INFO: Waiting up to 5m0s for pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683" in namespace "emptydir-4203" to be "Succeeded or Failed"
Jan 10 04:47:32.325: INFO: Pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683": Phase="Pending", Reason="", readiness=false. Elapsed: 4.199689ms
Jan 10 04:47:34.329: INFO: Pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007994617s
Jan 10 04:47:36.329: INFO: Pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007490759s
STEP: Saw pod success 01/10/23 04:47:36.329
Jan 10 04:47:36.329: INFO: Pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683" satisfied condition "Succeeded or Failed"
Jan 10 04:47:36.331: INFO: Trying to get logs from node cncf-wk2 pod pod-d988ac02-b250-4c58-9b57-ed7d567f4683 container test-container: <nil>
STEP: delete the pod 01/10/23 04:47:36.337
Jan 10 04:47:36.347: INFO: Waiting for pod pod-d988ac02-b250-4c58-9b57-ed7d567f4683 to disappear
Jan 10 04:47:36.352: INFO: Pod pod-d988ac02-b250-4c58-9b57-ed7d567f4683 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:47:36.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4203" for this suite. 01/10/23 04:47:36.358
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":250,"skipped":4127,"failed":0}
------------------------------
• [4.202 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:47:32.164
    Jan 10 04:47:32.165: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:47:32.167
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:32.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:32.301
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 01/10/23 04:47:32.305
    Jan 10 04:47:32.321: INFO: Waiting up to 5m0s for pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683" in namespace "emptydir-4203" to be "Succeeded or Failed"
    Jan 10 04:47:32.325: INFO: Pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683": Phase="Pending", Reason="", readiness=false. Elapsed: 4.199689ms
    Jan 10 04:47:34.329: INFO: Pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007994617s
    Jan 10 04:47:36.329: INFO: Pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007490759s
    STEP: Saw pod success 01/10/23 04:47:36.329
    Jan 10 04:47:36.329: INFO: Pod "pod-d988ac02-b250-4c58-9b57-ed7d567f4683" satisfied condition "Succeeded or Failed"
    Jan 10 04:47:36.331: INFO: Trying to get logs from node cncf-wk2 pod pod-d988ac02-b250-4c58-9b57-ed7d567f4683 container test-container: <nil>
    STEP: delete the pod 01/10/23 04:47:36.337
    Jan 10 04:47:36.347: INFO: Waiting for pod pod-d988ac02-b250-4c58-9b57-ed7d567f4683 to disappear
    Jan 10 04:47:36.352: INFO: Pod pod-d988ac02-b250-4c58-9b57-ed7d567f4683 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:47:36.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4203" for this suite. 01/10/23 04:47:36.358
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:47:36.377
Jan 10 04:47:36.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:47:36.379
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:36.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:36.406
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-58f609f3-2ebd-4b83-8b3a-049a0b5c8842 01/10/23 04:47:36.424
STEP: Creating secret with name secret-projected-all-test-volume-054b9a79-bad7-4f35-8421-14f97bbf4a43 01/10/23 04:47:36.43
STEP: Creating a pod to test Check all projections for projected volume plugin 01/10/23 04:47:36.442
Jan 10 04:47:36.452: INFO: Waiting up to 5m0s for pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760" in namespace "projected-4387" to be "Succeeded or Failed"
Jan 10 04:47:36.455: INFO: Pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760": Phase="Pending", Reason="", readiness=false. Elapsed: 3.271785ms
Jan 10 04:47:38.458: INFO: Pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005924712s
Jan 10 04:47:40.459: INFO: Pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006771069s
STEP: Saw pod success 01/10/23 04:47:40.459
Jan 10 04:47:40.459: INFO: Pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760" satisfied condition "Succeeded or Failed"
Jan 10 04:47:40.462: INFO: Trying to get logs from node cncf-wk2 pod projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760 container projected-all-volume-test: <nil>
STEP: delete the pod 01/10/23 04:47:40.468
Jan 10 04:47:40.480: INFO: Waiting for pod projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760 to disappear
Jan 10 04:47:40.488: INFO: Pod projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Jan 10 04:47:40.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4387" for this suite. 01/10/23 04:47:40.491
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":251,"skipped":4197,"failed":0}
------------------------------
• [4.124 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:47:36.377
    Jan 10 04:47:36.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:47:36.379
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:36.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:36.406
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-58f609f3-2ebd-4b83-8b3a-049a0b5c8842 01/10/23 04:47:36.424
    STEP: Creating secret with name secret-projected-all-test-volume-054b9a79-bad7-4f35-8421-14f97bbf4a43 01/10/23 04:47:36.43
    STEP: Creating a pod to test Check all projections for projected volume plugin 01/10/23 04:47:36.442
    Jan 10 04:47:36.452: INFO: Waiting up to 5m0s for pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760" in namespace "projected-4387" to be "Succeeded or Failed"
    Jan 10 04:47:36.455: INFO: Pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760": Phase="Pending", Reason="", readiness=false. Elapsed: 3.271785ms
    Jan 10 04:47:38.458: INFO: Pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005924712s
    Jan 10 04:47:40.459: INFO: Pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006771069s
    STEP: Saw pod success 01/10/23 04:47:40.459
    Jan 10 04:47:40.459: INFO: Pod "projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760" satisfied condition "Succeeded or Failed"
    Jan 10 04:47:40.462: INFO: Trying to get logs from node cncf-wk2 pod projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760 container projected-all-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:47:40.468
    Jan 10 04:47:40.480: INFO: Waiting for pod projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760 to disappear
    Jan 10 04:47:40.488: INFO: Pod projected-volume-06e042da-1493-4e53-a5aa-9797aa4ea760 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Jan 10 04:47:40.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4387" for this suite. 01/10/23 04:47:40.491
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:47:40.509
Jan 10 04:47:40.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename svcaccounts 01/10/23 04:47:40.518
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:40.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:40.555
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Jan 10 04:47:40.604: INFO: created pod
Jan 10 04:47:40.605: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-8575" to be "Succeeded or Failed"
Jan 10 04:47:40.627: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 22.768047ms
Jan 10 04:47:42.630: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025188548s
Jan 10 04:47:44.630: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025323062s
STEP: Saw pod success 01/10/23 04:47:44.63
Jan 10 04:47:44.630: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Jan 10 04:48:14.632: INFO: polling logs
Jan 10 04:48:14.642: INFO: Pod logs: 
I0110 04:47:41.654284       1 log.go:195] OK: Got token
I0110 04:47:41.654379       1 log.go:195] validating with in-cluster discovery
I0110 04:47:41.654855       1 log.go:195] OK: got issuer https://52.14.11.230:6443
I0110 04:47:41.656150       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://52.14.11.230:6443", Subject:"system:serviceaccount:svcaccounts-8575:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1673326660, NotBefore:1673326060, IssuedAt:1673326060, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8575", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"82e5dc83-bdf2-4db1-a945-549bdc3082be"}}}
I0110 04:47:41.664531       1 log.go:195] OK: Constructed OIDC provider for issuer https://52.14.11.230:6443
I0110 04:47:41.670065       1 log.go:195] OK: Validated signature on JWT
I0110 04:47:41.670158       1 log.go:195] OK: Got valid claims from token!
I0110 04:47:41.670183       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://52.14.11.230:6443", Subject:"system:serviceaccount:svcaccounts-8575:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1673326660, NotBefore:1673326060, IssuedAt:1673326060, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8575", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"82e5dc83-bdf2-4db1-a945-549bdc3082be"}}}

Jan 10 04:48:14.642: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 10 04:48:14.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8575" for this suite. 01/10/23 04:48:14.65
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":252,"skipped":4241,"failed":0}
------------------------------
• [SLOW TEST] [34.147 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:47:40.509
    Jan 10 04:47:40.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename svcaccounts 01/10/23 04:47:40.518
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:47:40.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:47:40.555
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Jan 10 04:47:40.604: INFO: created pod
    Jan 10 04:47:40.605: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-8575" to be "Succeeded or Failed"
    Jan 10 04:47:40.627: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 22.768047ms
    Jan 10 04:47:42.630: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025188548s
    Jan 10 04:47:44.630: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025323062s
    STEP: Saw pod success 01/10/23 04:47:44.63
    Jan 10 04:47:44.630: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Jan 10 04:48:14.632: INFO: polling logs
    Jan 10 04:48:14.642: INFO: Pod logs: 
    I0110 04:47:41.654284       1 log.go:195] OK: Got token
    I0110 04:47:41.654379       1 log.go:195] validating with in-cluster discovery
    I0110 04:47:41.654855       1 log.go:195] OK: got issuer https://52.14.11.230:6443
    I0110 04:47:41.656150       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://52.14.11.230:6443", Subject:"system:serviceaccount:svcaccounts-8575:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1673326660, NotBefore:1673326060, IssuedAt:1673326060, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8575", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"82e5dc83-bdf2-4db1-a945-549bdc3082be"}}}
    I0110 04:47:41.664531       1 log.go:195] OK: Constructed OIDC provider for issuer https://52.14.11.230:6443
    I0110 04:47:41.670065       1 log.go:195] OK: Validated signature on JWT
    I0110 04:47:41.670158       1 log.go:195] OK: Got valid claims from token!
    I0110 04:47:41.670183       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://52.14.11.230:6443", Subject:"system:serviceaccount:svcaccounts-8575:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1673326660, NotBefore:1673326060, IssuedAt:1673326060, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8575", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"82e5dc83-bdf2-4db1-a945-549bdc3082be"}}}

    Jan 10 04:48:14.642: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 10 04:48:14.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8575" for this suite. 01/10/23 04:48:14.65
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:48:14.662
Jan 10 04:48:14.662: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:48:14.663
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:48:14.697
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:48:14.705
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-7506 01/10/23 04:48:14.708
Jan 10 04:48:14.715: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-7506" to be "running and ready"
Jan 10 04:48:14.717: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 1.915261ms
Jan 10 04:48:14.717: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:48:16.720: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.00531232s
Jan 10 04:48:16.720: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Jan 10 04:48:16.720: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Jan 10 04:48:16.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Jan 10 04:48:16.891: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Jan 10 04:48:16.891: INFO: stdout: "iptables"
Jan 10 04:48:16.891: INFO: proxyMode: iptables
Jan 10 04:48:16.900: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Jan 10 04:48:16.903: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-7506 01/10/23 04:48:16.903
STEP: creating replication controller affinity-nodeport-timeout in namespace services-7506 01/10/23 04:48:16.911
I0110 04:48:16.949600      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-7506, replica count: 3
I0110 04:48:20.002123      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 04:48:20.010: INFO: Creating new exec pod
Jan 10 04:48:20.015: INFO: Waiting up to 5m0s for pod "execpod-affinity65ghj" in namespace "services-7506" to be "running"
Jan 10 04:48:20.026: INFO: Pod "execpod-affinity65ghj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.919937ms
Jan 10 04:48:22.029: INFO: Pod "execpod-affinity65ghj": Phase="Running", Reason="", readiness=true. Elapsed: 2.013825981s
Jan 10 04:48:22.029: INFO: Pod "execpod-affinity65ghj" satisfied condition "running"
Jan 10 04:48:23.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Jan 10 04:48:23.268: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Jan 10 04:48:23.268: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:48:23.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.3.37 80'
Jan 10 04:48:23.462: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.3.37 80\nConnection to 10.43.3.37 80 port [tcp/http] succeeded!\n"
Jan 10 04:48:23.462: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:48:23.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.15.218 31672'
Jan 10 04:48:23.716: INFO: stderr: "+ nc -v -t -w 2 172.31.15.218 31672\n+ echo hostName\nConnection to 172.31.15.218 31672 port [tcp/*] succeeded!\n"
Jan 10 04:48:23.716: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:48:23.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.114 31672'
Jan 10 04:48:23.899: INFO: stderr: "+ + nc -v -t -w 2 172.31.7.114 31672\necho hostName\nConnection to 172.31.7.114 31672 port [tcp/*] succeeded!\n"
Jan 10 04:48:23.899: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:48:23.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.15.218:31672/ ; done'
Jan 10 04:48:24.157: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n"
Jan 10 04:48:24.157: INFO: stdout: "\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k"
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
Jan 10 04:48:24.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.15.218:31672/'
Jan 10 04:48:24.342: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n"
Jan 10 04:48:24.342: INFO: stdout: "affinity-nodeport-timeout-vhf5k"
Jan 10 04:48:44.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.15.218:31672/'
Jan 10 04:48:44.577: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n"
Jan 10 04:48:44.577: INFO: stdout: "affinity-nodeport-timeout-85bk5"
Jan 10 04:48:44.577: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-7506, will wait for the garbage collector to delete the pods 01/10/23 04:48:44.589
Jan 10 04:48:44.657: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.875269ms
Jan 10 04:48:44.758: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.582687ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:48:47.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7506" for this suite. 01/10/23 04:48:47.236
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":253,"skipped":4268,"failed":0}
------------------------------
• [SLOW TEST] [32.623 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:48:14.662
    Jan 10 04:48:14.662: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:48:14.663
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:48:14.697
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:48:14.705
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-7506 01/10/23 04:48:14.708
    Jan 10 04:48:14.715: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-7506" to be "running and ready"
    Jan 10 04:48:14.717: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 1.915261ms
    Jan 10 04:48:14.717: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:48:16.720: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.00531232s
    Jan 10 04:48:16.720: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Jan 10 04:48:16.720: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Jan 10 04:48:16.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Jan 10 04:48:16.891: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Jan 10 04:48:16.891: INFO: stdout: "iptables"
    Jan 10 04:48:16.891: INFO: proxyMode: iptables
    Jan 10 04:48:16.900: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Jan 10 04:48:16.903: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-7506 01/10/23 04:48:16.903
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-7506 01/10/23 04:48:16.911
    I0110 04:48:16.949600      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-7506, replica count: 3
    I0110 04:48:20.002123      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 04:48:20.010: INFO: Creating new exec pod
    Jan 10 04:48:20.015: INFO: Waiting up to 5m0s for pod "execpod-affinity65ghj" in namespace "services-7506" to be "running"
    Jan 10 04:48:20.026: INFO: Pod "execpod-affinity65ghj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.919937ms
    Jan 10 04:48:22.029: INFO: Pod "execpod-affinity65ghj": Phase="Running", Reason="", readiness=true. Elapsed: 2.013825981s
    Jan 10 04:48:22.029: INFO: Pod "execpod-affinity65ghj" satisfied condition "running"
    Jan 10 04:48:23.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Jan 10 04:48:23.268: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Jan 10 04:48:23.268: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:48:23.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.3.37 80'
    Jan 10 04:48:23.462: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.3.37 80\nConnection to 10.43.3.37 80 port [tcp/http] succeeded!\n"
    Jan 10 04:48:23.462: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:48:23.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.15.218 31672'
    Jan 10 04:48:23.716: INFO: stderr: "+ nc -v -t -w 2 172.31.15.218 31672\n+ echo hostName\nConnection to 172.31.15.218 31672 port [tcp/*] succeeded!\n"
    Jan 10 04:48:23.716: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:48:23.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.114 31672'
    Jan 10 04:48:23.899: INFO: stderr: "+ + nc -v -t -w 2 172.31.7.114 31672\necho hostName\nConnection to 172.31.7.114 31672 port [tcp/*] succeeded!\n"
    Jan 10 04:48:23.899: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:48:23.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.15.218:31672/ ; done'
    Jan 10 04:48:24.157: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n"
    Jan 10 04:48:24.157: INFO: stdout: "\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k\naffinity-nodeport-timeout-vhf5k"
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Received response from host: affinity-nodeport-timeout-vhf5k
    Jan 10 04:48:24.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.15.218:31672/'
    Jan 10 04:48:24.342: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n"
    Jan 10 04:48:24.342: INFO: stdout: "affinity-nodeport-timeout-vhf5k"
    Jan 10 04:48:44.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-7506 exec execpod-affinity65ghj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.15.218:31672/'
    Jan 10 04:48:44.577: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.15.218:31672/\n"
    Jan 10 04:48:44.577: INFO: stdout: "affinity-nodeport-timeout-85bk5"
    Jan 10 04:48:44.577: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-7506, will wait for the garbage collector to delete the pods 01/10/23 04:48:44.589
    Jan 10 04:48:44.657: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.875269ms
    Jan 10 04:48:44.758: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.582687ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:48:47.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7506" for this suite. 01/10/23 04:48:47.236
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:48:47.285
Jan 10 04:48:47.285: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:48:47.286
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:48:47.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:48:47.601
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-d960d16b-deba-4009-95b1-765f98618bb8 01/10/23 04:48:47.714
STEP: Creating configMap with name cm-test-opt-upd-9b5bed61-6d88-433c-a8f9-c171950b8341 01/10/23 04:48:47.752
STEP: Creating the pod 01/10/23 04:48:47.779
Jan 10 04:48:47.819: INFO: Waiting up to 5m0s for pod "pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8" in namespace "configmap-8966" to be "running and ready"
Jan 10 04:48:47.834: INFO: Pod "pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.538679ms
Jan 10 04:48:47.834: INFO: The phase of Pod pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:48:49.839: INFO: Pod "pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8": Phase="Running", Reason="", readiness=true. Elapsed: 2.014569819s
Jan 10 04:48:49.839: INFO: The phase of Pod pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8 is Running (Ready = true)
Jan 10 04:48:49.839: INFO: Pod "pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-d960d16b-deba-4009-95b1-765f98618bb8 01/10/23 04:48:49.864
STEP: Updating configmap cm-test-opt-upd-9b5bed61-6d88-433c-a8f9-c171950b8341 01/10/23 04:48:49.874
STEP: Creating configMap with name cm-test-opt-create-403378c0-a0d7-44de-9436-2c83961c15e8 01/10/23 04:48:49.878
STEP: waiting to observe update in volume 01/10/23 04:48:49.882
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:48:51.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8966" for this suite. 01/10/23 04:48:51.923
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":254,"skipped":4268,"failed":0}
------------------------------
• [4.645 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:48:47.285
    Jan 10 04:48:47.285: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:48:47.286
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:48:47.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:48:47.601
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-d960d16b-deba-4009-95b1-765f98618bb8 01/10/23 04:48:47.714
    STEP: Creating configMap with name cm-test-opt-upd-9b5bed61-6d88-433c-a8f9-c171950b8341 01/10/23 04:48:47.752
    STEP: Creating the pod 01/10/23 04:48:47.779
    Jan 10 04:48:47.819: INFO: Waiting up to 5m0s for pod "pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8" in namespace "configmap-8966" to be "running and ready"
    Jan 10 04:48:47.834: INFO: Pod "pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.538679ms
    Jan 10 04:48:47.834: INFO: The phase of Pod pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:48:49.839: INFO: Pod "pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8": Phase="Running", Reason="", readiness=true. Elapsed: 2.014569819s
    Jan 10 04:48:49.839: INFO: The phase of Pod pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8 is Running (Ready = true)
    Jan 10 04:48:49.839: INFO: Pod "pod-configmaps-a744e5a9-0a46-41ed-b68f-03dd7a8ecad8" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-d960d16b-deba-4009-95b1-765f98618bb8 01/10/23 04:48:49.864
    STEP: Updating configmap cm-test-opt-upd-9b5bed61-6d88-433c-a8f9-c171950b8341 01/10/23 04:48:49.874
    STEP: Creating configMap with name cm-test-opt-create-403378c0-a0d7-44de-9436-2c83961c15e8 01/10/23 04:48:49.878
    STEP: waiting to observe update in volume 01/10/23 04:48:49.882
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:48:51.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8966" for this suite. 01/10/23 04:48:51.923
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:48:51.932
Jan 10 04:48:51.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubelet-test 01/10/23 04:48:51.934
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:48:51.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:48:51.991
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 10 04:48:52.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-687" for this suite. 01/10/23 04:48:52.07
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":255,"skipped":4268,"failed":0}
------------------------------
• [0.145 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:48:51.932
    Jan 10 04:48:51.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubelet-test 01/10/23 04:48:51.934
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:48:51.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:48:51.991
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 10 04:48:52.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-687" for this suite. 01/10/23 04:48:52.07
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:48:52.084
Jan 10 04:48:52.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 04:48:52.086
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:48:52.127
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:48:52.137
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 01/10/23 04:48:52.144
Jan 10 04:48:52.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 create -f -'
Jan 10 04:48:53.232: INFO: stderr: ""
Jan 10 04:48:53.232: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 01/10/23 04:48:53.232
Jan 10 04:48:53.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 10 04:48:53.317: INFO: stderr: ""
Jan 10 04:48:53.317: INFO: stdout: "update-demo-nautilus-492vf update-demo-nautilus-sdrwh "
Jan 10 04:48:53.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 04:48:53.401: INFO: stderr: ""
Jan 10 04:48:53.401: INFO: stdout: ""
Jan 10 04:48:53.401: INFO: update-demo-nautilus-492vf is created but not running
Jan 10 04:48:58.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 10 04:48:58.534: INFO: stderr: ""
Jan 10 04:48:58.534: INFO: stdout: "update-demo-nautilus-492vf update-demo-nautilus-sdrwh "
Jan 10 04:48:58.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 04:48:58.619: INFO: stderr: ""
Jan 10 04:48:58.619: INFO: stdout: "true"
Jan 10 04:48:58.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 10 04:48:58.704: INFO: stderr: ""
Jan 10 04:48:58.704: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 10 04:48:58.704: INFO: validating pod update-demo-nautilus-492vf
Jan 10 04:48:58.714: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 10 04:48:58.714: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 10 04:48:58.714: INFO: update-demo-nautilus-492vf is verified up and running
Jan 10 04:48:58.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-sdrwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 04:48:58.822: INFO: stderr: ""
Jan 10 04:48:58.822: INFO: stdout: "true"
Jan 10 04:48:58.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-sdrwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 10 04:48:58.909: INFO: stderr: ""
Jan 10 04:48:58.909: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 10 04:48:58.909: INFO: validating pod update-demo-nautilus-sdrwh
Jan 10 04:48:58.916: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 10 04:48:58.916: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 10 04:48:58.916: INFO: update-demo-nautilus-sdrwh is verified up and running
STEP: scaling down the replication controller 01/10/23 04:48:58.916
Jan 10 04:48:58.920: INFO: scanned /root for discovery docs: <nil>
Jan 10 04:48:58.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Jan 10 04:49:00.052: INFO: stderr: ""
Jan 10 04:49:00.052: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 01/10/23 04:49:00.052
Jan 10 04:49:00.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 10 04:49:00.123: INFO: stderr: ""
Jan 10 04:49:00.123: INFO: stdout: "update-demo-nautilus-492vf update-demo-nautilus-sdrwh "
STEP: Replicas for name=update-demo: expected=1 actual=2 01/10/23 04:49:00.123
Jan 10 04:49:05.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 10 04:49:05.201: INFO: stderr: ""
Jan 10 04:49:05.201: INFO: stdout: "update-demo-nautilus-492vf "
Jan 10 04:49:05.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 04:49:05.286: INFO: stderr: ""
Jan 10 04:49:05.287: INFO: stdout: "true"
Jan 10 04:49:05.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 10 04:49:05.356: INFO: stderr: ""
Jan 10 04:49:05.356: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 10 04:49:05.356: INFO: validating pod update-demo-nautilus-492vf
Jan 10 04:49:05.359: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 10 04:49:05.359: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 10 04:49:05.359: INFO: update-demo-nautilus-492vf is verified up and running
STEP: scaling up the replication controller 01/10/23 04:49:05.359
Jan 10 04:49:05.361: INFO: scanned /root for discovery docs: <nil>
Jan 10 04:49:05.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Jan 10 04:49:06.503: INFO: stderr: ""
Jan 10 04:49:06.503: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 01/10/23 04:49:06.503
Jan 10 04:49:06.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 10 04:49:06.640: INFO: stderr: ""
Jan 10 04:49:06.640: INFO: stdout: "update-demo-nautilus-492vf update-demo-nautilus-xdc4x "
Jan 10 04:49:06.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 04:49:06.719: INFO: stderr: ""
Jan 10 04:49:06.719: INFO: stdout: "true"
Jan 10 04:49:06.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 10 04:49:06.812: INFO: stderr: ""
Jan 10 04:49:06.812: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 10 04:49:06.812: INFO: validating pod update-demo-nautilus-492vf
Jan 10 04:49:06.819: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 10 04:49:06.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 10 04:49:06.819: INFO: update-demo-nautilus-492vf is verified up and running
Jan 10 04:49:06.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-xdc4x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 10 04:49:06.895: INFO: stderr: ""
Jan 10 04:49:06.895: INFO: stdout: "true"
Jan 10 04:49:06.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-xdc4x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 10 04:49:06.970: INFO: stderr: ""
Jan 10 04:49:06.970: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 10 04:49:06.970: INFO: validating pod update-demo-nautilus-xdc4x
Jan 10 04:49:06.987: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 10 04:49:06.987: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 10 04:49:06.987: INFO: update-demo-nautilus-xdc4x is verified up and running
STEP: using delete to clean up resources 01/10/23 04:49:06.987
Jan 10 04:49:06.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 delete --grace-period=0 --force -f -'
Jan 10 04:49:07.133: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 04:49:07.133: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 10 04:49:07.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get rc,svc -l name=update-demo --no-headers'
Jan 10 04:49:07.473: INFO: stderr: "No resources found in kubectl-3854 namespace.\n"
Jan 10 04:49:07.473: INFO: stdout: ""
Jan 10 04:49:07.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 10 04:49:07.609: INFO: stderr: ""
Jan 10 04:49:07.609: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 04:49:07.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3854" for this suite. 01/10/23 04:49:07.612
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":256,"skipped":4292,"failed":0}
------------------------------
• [SLOW TEST] [15.531 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:48:52.084
    Jan 10 04:48:52.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 04:48:52.086
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:48:52.127
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:48:52.137
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 01/10/23 04:48:52.144
    Jan 10 04:48:52.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 create -f -'
    Jan 10 04:48:53.232: INFO: stderr: ""
    Jan 10 04:48:53.232: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 01/10/23 04:48:53.232
    Jan 10 04:48:53.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 10 04:48:53.317: INFO: stderr: ""
    Jan 10 04:48:53.317: INFO: stdout: "update-demo-nautilus-492vf update-demo-nautilus-sdrwh "
    Jan 10 04:48:53.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 04:48:53.401: INFO: stderr: ""
    Jan 10 04:48:53.401: INFO: stdout: ""
    Jan 10 04:48:53.401: INFO: update-demo-nautilus-492vf is created but not running
    Jan 10 04:48:58.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 10 04:48:58.534: INFO: stderr: ""
    Jan 10 04:48:58.534: INFO: stdout: "update-demo-nautilus-492vf update-demo-nautilus-sdrwh "
    Jan 10 04:48:58.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 04:48:58.619: INFO: stderr: ""
    Jan 10 04:48:58.619: INFO: stdout: "true"
    Jan 10 04:48:58.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 10 04:48:58.704: INFO: stderr: ""
    Jan 10 04:48:58.704: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 10 04:48:58.704: INFO: validating pod update-demo-nautilus-492vf
    Jan 10 04:48:58.714: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 10 04:48:58.714: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 10 04:48:58.714: INFO: update-demo-nautilus-492vf is verified up and running
    Jan 10 04:48:58.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-sdrwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 04:48:58.822: INFO: stderr: ""
    Jan 10 04:48:58.822: INFO: stdout: "true"
    Jan 10 04:48:58.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-sdrwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 10 04:48:58.909: INFO: stderr: ""
    Jan 10 04:48:58.909: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 10 04:48:58.909: INFO: validating pod update-demo-nautilus-sdrwh
    Jan 10 04:48:58.916: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 10 04:48:58.916: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 10 04:48:58.916: INFO: update-demo-nautilus-sdrwh is verified up and running
    STEP: scaling down the replication controller 01/10/23 04:48:58.916
    Jan 10 04:48:58.920: INFO: scanned /root for discovery docs: <nil>
    Jan 10 04:48:58.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Jan 10 04:49:00.052: INFO: stderr: ""
    Jan 10 04:49:00.052: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 01/10/23 04:49:00.052
    Jan 10 04:49:00.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 10 04:49:00.123: INFO: stderr: ""
    Jan 10 04:49:00.123: INFO: stdout: "update-demo-nautilus-492vf update-demo-nautilus-sdrwh "
    STEP: Replicas for name=update-demo: expected=1 actual=2 01/10/23 04:49:00.123
    Jan 10 04:49:05.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 10 04:49:05.201: INFO: stderr: ""
    Jan 10 04:49:05.201: INFO: stdout: "update-demo-nautilus-492vf "
    Jan 10 04:49:05.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 04:49:05.286: INFO: stderr: ""
    Jan 10 04:49:05.287: INFO: stdout: "true"
    Jan 10 04:49:05.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 10 04:49:05.356: INFO: stderr: ""
    Jan 10 04:49:05.356: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 10 04:49:05.356: INFO: validating pod update-demo-nautilus-492vf
    Jan 10 04:49:05.359: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 10 04:49:05.359: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 10 04:49:05.359: INFO: update-demo-nautilus-492vf is verified up and running
    STEP: scaling up the replication controller 01/10/23 04:49:05.359
    Jan 10 04:49:05.361: INFO: scanned /root for discovery docs: <nil>
    Jan 10 04:49:05.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Jan 10 04:49:06.503: INFO: stderr: ""
    Jan 10 04:49:06.503: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 01/10/23 04:49:06.503
    Jan 10 04:49:06.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 10 04:49:06.640: INFO: stderr: ""
    Jan 10 04:49:06.640: INFO: stdout: "update-demo-nautilus-492vf update-demo-nautilus-xdc4x "
    Jan 10 04:49:06.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 04:49:06.719: INFO: stderr: ""
    Jan 10 04:49:06.719: INFO: stdout: "true"
    Jan 10 04:49:06.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-492vf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 10 04:49:06.812: INFO: stderr: ""
    Jan 10 04:49:06.812: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 10 04:49:06.812: INFO: validating pod update-demo-nautilus-492vf
    Jan 10 04:49:06.819: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 10 04:49:06.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 10 04:49:06.819: INFO: update-demo-nautilus-492vf is verified up and running
    Jan 10 04:49:06.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-xdc4x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 10 04:49:06.895: INFO: stderr: ""
    Jan 10 04:49:06.895: INFO: stdout: "true"
    Jan 10 04:49:06.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods update-demo-nautilus-xdc4x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 10 04:49:06.970: INFO: stderr: ""
    Jan 10 04:49:06.970: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 10 04:49:06.970: INFO: validating pod update-demo-nautilus-xdc4x
    Jan 10 04:49:06.987: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 10 04:49:06.987: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 10 04:49:06.987: INFO: update-demo-nautilus-xdc4x is verified up and running
    STEP: using delete to clean up resources 01/10/23 04:49:06.987
    Jan 10 04:49:06.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 delete --grace-period=0 --force -f -'
    Jan 10 04:49:07.133: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 04:49:07.133: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Jan 10 04:49:07.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get rc,svc -l name=update-demo --no-headers'
    Jan 10 04:49:07.473: INFO: stderr: "No resources found in kubectl-3854 namespace.\n"
    Jan 10 04:49:07.473: INFO: stdout: ""
    Jan 10 04:49:07.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3854 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jan 10 04:49:07.609: INFO: stderr: ""
    Jan 10 04:49:07.609: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 04:49:07.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3854" for this suite. 01/10/23 04:49:07.612
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:07.619
Jan 10 04:49:07.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename dns 01/10/23 04:49:07.621
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:07.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:07.655
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 01/10/23 04:49:07.66
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7973.svc.cluster.local;sleep 1; done
 01/10/23 04:49:07.673
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7973.svc.cluster.local;sleep 1; done
 01/10/23 04:49:07.674
STEP: creating a pod to probe DNS 01/10/23 04:49:07.674
STEP: submitting the pod to kubernetes 01/10/23 04:49:07.674
Jan 10 04:49:07.694: INFO: Waiting up to 15m0s for pod "dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7" in namespace "dns-7973" to be "running"
Jan 10 04:49:07.698: INFO: Pod "dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.714774ms
Jan 10 04:49:09.716: INFO: Pod "dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7": Phase="Running", Reason="", readiness=true. Elapsed: 2.022081018s
Jan 10 04:49:09.716: INFO: Pod "dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7" satisfied condition "running"
STEP: retrieving the pod 01/10/23 04:49:09.716
STEP: looking for the results for each expected name from probers 01/10/23 04:49:09.77
Jan 10 04:49:09.805: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
Jan 10 04:49:09.848: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
Jan 10 04:49:09.905: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
Jan 10 04:49:09.917: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
Jan 10 04:49:09.942: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
Jan 10 04:49:09.972: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
Jan 10 04:49:09.981: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
Jan 10 04:49:09.989: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
Jan 10 04:49:09.989: INFO: Lookups using dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7973.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7973.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local jessie_udp@dns-test-service-2.dns-7973.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7973.svc.cluster.local]

Jan 10 04:49:15.025: INFO: DNS probes using dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7 succeeded

STEP: deleting the pod 01/10/23 04:49:15.025
STEP: deleting the test headless service 01/10/23 04:49:15.063
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 10 04:49:15.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7973" for this suite. 01/10/23 04:49:15.084
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":257,"skipped":4355,"failed":0}
------------------------------
• [SLOW TEST] [7.472 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:07.619
    Jan 10 04:49:07.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename dns 01/10/23 04:49:07.621
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:07.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:07.655
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 01/10/23 04:49:07.66
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7973.svc.cluster.local;sleep 1; done
     01/10/23 04:49:07.673
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7973.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7973.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7973.svc.cluster.local;sleep 1; done
     01/10/23 04:49:07.674
    STEP: creating a pod to probe DNS 01/10/23 04:49:07.674
    STEP: submitting the pod to kubernetes 01/10/23 04:49:07.674
    Jan 10 04:49:07.694: INFO: Waiting up to 15m0s for pod "dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7" in namespace "dns-7973" to be "running"
    Jan 10 04:49:07.698: INFO: Pod "dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.714774ms
    Jan 10 04:49:09.716: INFO: Pod "dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7": Phase="Running", Reason="", readiness=true. Elapsed: 2.022081018s
    Jan 10 04:49:09.716: INFO: Pod "dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 04:49:09.716
    STEP: looking for the results for each expected name from probers 01/10/23 04:49:09.77
    Jan 10 04:49:09.805: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
    Jan 10 04:49:09.848: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
    Jan 10 04:49:09.905: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
    Jan 10 04:49:09.917: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
    Jan 10 04:49:09.942: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
    Jan 10 04:49:09.972: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
    Jan 10 04:49:09.981: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
    Jan 10 04:49:09.989: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7973.svc.cluster.local from pod dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7: the server could not find the requested resource (get pods dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7)
    Jan 10 04:49:09.989: INFO: Lookups using dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7973.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7973.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7973.svc.cluster.local jessie_udp@dns-test-service-2.dns-7973.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7973.svc.cluster.local]

    Jan 10 04:49:15.025: INFO: DNS probes using dns-7973/dns-test-4269bda1-7633-439a-ac63-052d04fdc1e7 succeeded

    STEP: deleting the pod 01/10/23 04:49:15.025
    STEP: deleting the test headless service 01/10/23 04:49:15.063
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 10 04:49:15.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7973" for this suite. 01/10/23 04:49:15.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:15.093
Jan 10 04:49:15.093: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:49:15.094
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:15.127
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:15.131
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-5d8830e3-bf91-4822-b125-196326c8a23d 01/10/23 04:49:15.138
STEP: Creating configMap with name cm-test-opt-upd-51e7724b-a48e-4bea-a57b-58da92f4d685 01/10/23 04:49:15.147
STEP: Creating the pod 01/10/23 04:49:15.155
Jan 10 04:49:15.167: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7" in namespace "projected-700" to be "running and ready"
Jan 10 04:49:15.183: INFO: Pod "pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.986555ms
Jan 10 04:49:15.183: INFO: The phase of Pod pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:49:17.187: INFO: Pod "pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7": Phase="Running", Reason="", readiness=true. Elapsed: 2.020282442s
Jan 10 04:49:17.187: INFO: The phase of Pod pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7 is Running (Ready = true)
Jan 10 04:49:17.187: INFO: Pod "pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-5d8830e3-bf91-4822-b125-196326c8a23d 01/10/23 04:49:17.211
STEP: Updating configmap cm-test-opt-upd-51e7724b-a48e-4bea-a57b-58da92f4d685 01/10/23 04:49:17.216
STEP: Creating configMap with name cm-test-opt-create-29611280-6796-4871-9bc5-3e0ae2907fff 01/10/23 04:49:17.224
STEP: waiting to observe update in volume 01/10/23 04:49:17.228
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 04:49:19.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-700" for this suite. 01/10/23 04:49:19.27
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":258,"skipped":4380,"failed":0}
------------------------------
• [4.200 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:15.093
    Jan 10 04:49:15.093: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:49:15.094
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:15.127
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:15.131
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-5d8830e3-bf91-4822-b125-196326c8a23d 01/10/23 04:49:15.138
    STEP: Creating configMap with name cm-test-opt-upd-51e7724b-a48e-4bea-a57b-58da92f4d685 01/10/23 04:49:15.147
    STEP: Creating the pod 01/10/23 04:49:15.155
    Jan 10 04:49:15.167: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7" in namespace "projected-700" to be "running and ready"
    Jan 10 04:49:15.183: INFO: Pod "pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.986555ms
    Jan 10 04:49:15.183: INFO: The phase of Pod pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:49:17.187: INFO: Pod "pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7": Phase="Running", Reason="", readiness=true. Elapsed: 2.020282442s
    Jan 10 04:49:17.187: INFO: The phase of Pod pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7 is Running (Ready = true)
    Jan 10 04:49:17.187: INFO: Pod "pod-projected-configmaps-09ee5e1b-e764-40af-8d60-bd8305b108c7" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-5d8830e3-bf91-4822-b125-196326c8a23d 01/10/23 04:49:17.211
    STEP: Updating configmap cm-test-opt-upd-51e7724b-a48e-4bea-a57b-58da92f4d685 01/10/23 04:49:17.216
    STEP: Creating configMap with name cm-test-opt-create-29611280-6796-4871-9bc5-3e0ae2907fff 01/10/23 04:49:17.224
    STEP: waiting to observe update in volume 01/10/23 04:49:17.228
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 04:49:19.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-700" for this suite. 01/10/23 04:49:19.27
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:19.294
Jan 10 04:49:19.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 04:49:19.295
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:19.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:19.505
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/10/23 04:49:19.548
Jan 10 04:49:19.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-4196 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jan 10 04:49:19.768: INFO: stderr: ""
Jan 10 04:49:19.768: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 01/10/23 04:49:19.768
Jan 10 04:49:19.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-4196 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Jan 10 04:49:20.160: INFO: stderr: ""
Jan 10 04:49:20.160: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/10/23 04:49:20.16
Jan 10 04:49:20.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-4196 delete pods e2e-test-httpd-pod'
Jan 10 04:49:22.601: INFO: stderr: ""
Jan 10 04:49:22.601: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 04:49:22.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4196" for this suite. 01/10/23 04:49:22.605
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":259,"skipped":4398,"failed":0}
------------------------------
• [3.321 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:19.294
    Jan 10 04:49:19.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 04:49:19.295
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:19.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:19.505
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/10/23 04:49:19.548
    Jan 10 04:49:19.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-4196 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Jan 10 04:49:19.768: INFO: stderr: ""
    Jan 10 04:49:19.768: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 01/10/23 04:49:19.768
    Jan 10 04:49:19.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-4196 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Jan 10 04:49:20.160: INFO: stderr: ""
    Jan 10 04:49:20.160: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/10/23 04:49:20.16
    Jan 10 04:49:20.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-4196 delete pods e2e-test-httpd-pod'
    Jan 10 04:49:22.601: INFO: stderr: ""
    Jan 10 04:49:22.601: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 04:49:22.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4196" for this suite. 01/10/23 04:49:22.605
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:22.616
Jan 10 04:49:22.619: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replication-controller 01/10/23 04:49:22.62
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:22.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:22.682
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 01/10/23 04:49:22.692
STEP: When the matched label of one of its pods change 01/10/23 04:49:22.702
Jan 10 04:49:22.713: INFO: Pod name pod-release: Found 0 pods out of 1
Jan 10 04:49:27.716: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 01/10/23 04:49:27.733
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 10 04:49:27.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9597" for this suite. 01/10/23 04:49:27.761
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":260,"skipped":4419,"failed":0}
------------------------------
• [SLOW TEST] [5.154 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:22.616
    Jan 10 04:49:22.619: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replication-controller 01/10/23 04:49:22.62
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:22.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:22.682
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 01/10/23 04:49:22.692
    STEP: When the matched label of one of its pods change 01/10/23 04:49:22.702
    Jan 10 04:49:22.713: INFO: Pod name pod-release: Found 0 pods out of 1
    Jan 10 04:49:27.716: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 01/10/23 04:49:27.733
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 10 04:49:27.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9597" for this suite. 01/10/23 04:49:27.761
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:27.772
Jan 10 04:49:27.772: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename deployment 01/10/23 04:49:27.773
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:27.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:27.85
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 01/10/23 04:49:27.857
Jan 10 04:49:27.857: INFO: Creating simple deployment test-deployment-fhrlz
Jan 10 04:49:27.890: INFO: deployment "test-deployment-fhrlz" doesn't have the required revision set
STEP: Getting /status 01/10/23 04:49:29.9
Jan 10 04:49:29.903: INFO: Deployment test-deployment-fhrlz has Conditions: [{Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 01/10/23 04:49:29.903
Jan 10 04:49:29.912: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 49, 29, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 49, 27, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-fhrlz-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 01/10/23 04:49:29.912
Jan 10 04:49:29.914: INFO: Observed &Deployment event: ADDED
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fhrlz-777898ffcc"}
Jan 10 04:49:29.915: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fhrlz-777898ffcc"}
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jan 10 04:49:29.915: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-fhrlz-777898ffcc" is progressing.}
Jan 10 04:49:29.915: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}
Jan 10 04:49:29.915: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}
Jan 10 04:49:29.915: INFO: Found Deployment test-deployment-fhrlz in namespace deployment-9807 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jan 10 04:49:29.915: INFO: Deployment test-deployment-fhrlz has an updated status
STEP: patching the Statefulset Status 01/10/23 04:49:29.915
Jan 10 04:49:29.915: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jan 10 04:49:29.927: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 01/10/23 04:49:29.927
Jan 10 04:49:29.929: INFO: Observed &Deployment event: ADDED
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fhrlz-777898ffcc"}
Jan 10 04:49:29.929: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fhrlz-777898ffcc"}
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jan 10 04:49:29.929: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-fhrlz-777898ffcc" is progressing.}
Jan 10 04:49:29.929: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}
Jan 10 04:49:29.929: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}
Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jan 10 04:49:29.930: INFO: Observed &Deployment event: MODIFIED
Jan 10 04:49:29.930: INFO: Found deployment test-deployment-fhrlz in namespace deployment-9807 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Jan 10 04:49:29.930: INFO: Deployment test-deployment-fhrlz has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 10 04:49:29.939: INFO: Deployment "test-deployment-fhrlz":
&Deployment{ObjectMeta:{test-deployment-fhrlz  deployment-9807  06062072-6a7a-436a-83c7-faccbb1b6b15 242530 1 2023-01-10 04:49:27 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-01-10 04:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-01-10 04:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-01-10 04:49:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004fee1f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-fhrlz-777898ffcc",LastUpdateTime:2023-01-10 04:49:29 +0000 UTC,LastTransitionTime:2023-01-10 04:49:29 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jan 10 04:49:29.944: INFO: New ReplicaSet "test-deployment-fhrlz-777898ffcc" of Deployment "test-deployment-fhrlz":
&ReplicaSet{ObjectMeta:{test-deployment-fhrlz-777898ffcc  deployment-9807  a8a34666-6ebc-40bc-88d7-4c25ca1644a2 242522 1 2023-01-10 04:49:27 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-fhrlz 06062072-6a7a-436a-83c7-faccbb1b6b15 0xc004fee5e0 0xc004fee5e1}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06062072-6a7a-436a-83c7-faccbb1b6b15\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:49:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004fee6f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:49:29.952: INFO: Pod "test-deployment-fhrlz-777898ffcc-nrvj5" is available:
&Pod{ObjectMeta:{test-deployment-fhrlz-777898ffcc-nrvj5 test-deployment-fhrlz-777898ffcc- deployment-9807  3ad9ddad-dd7a-4793-adee-da0273310da9 242521 0 2023-01-10 04:49:27 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:b90cb2e16927d0a6e2d72c4db0e477d31392f1a28e0808bd8f26a43f57b633ea cni.projectcalico.org/podIP:10.42.1.63/32 cni.projectcalico.org/podIPs:10.42.1.63/32] [{apps/v1 ReplicaSet test-deployment-fhrlz-777898ffcc a8a34666-6ebc-40bc-88d7-4c25ca1644a2 0xc004feec30 0xc004feec31}] [] [{kube-controller-manager Update v1 2023-01-10 04:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a8a34666-6ebc-40bc-88d7-4c25ca1644a2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xz2xr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xz2xr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:49:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:49:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.63,StartTime:2023-01-10 04:49:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://e61434c75f515fab6117e180058fb3268244e951b587bb75d1d465faa962e89b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 10 04:49:29.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9807" for this suite. 01/10/23 04:49:29.958
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":261,"skipped":4439,"failed":0}
------------------------------
• [2.199 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:27.772
    Jan 10 04:49:27.772: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename deployment 01/10/23 04:49:27.773
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:27.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:27.85
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 01/10/23 04:49:27.857
    Jan 10 04:49:27.857: INFO: Creating simple deployment test-deployment-fhrlz
    Jan 10 04:49:27.890: INFO: deployment "test-deployment-fhrlz" doesn't have the required revision set
    STEP: Getting /status 01/10/23 04:49:29.9
    Jan 10 04:49:29.903: INFO: Deployment test-deployment-fhrlz has Conditions: [{Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 01/10/23 04:49:29.903
    Jan 10 04:49:29.912: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 49, 29, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 49, 27, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-fhrlz-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 01/10/23 04:49:29.912
    Jan 10 04:49:29.914: INFO: Observed &Deployment event: ADDED
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fhrlz-777898ffcc"}
    Jan 10 04:49:29.915: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fhrlz-777898ffcc"}
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jan 10 04:49:29.915: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-fhrlz-777898ffcc" is progressing.}
    Jan 10 04:49:29.915: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}
    Jan 10 04:49:29.915: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jan 10 04:49:29.915: INFO: Observed Deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}
    Jan 10 04:49:29.915: INFO: Found Deployment test-deployment-fhrlz in namespace deployment-9807 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jan 10 04:49:29.915: INFO: Deployment test-deployment-fhrlz has an updated status
    STEP: patching the Statefulset Status 01/10/23 04:49:29.915
    Jan 10 04:49:29.915: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jan 10 04:49:29.927: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 01/10/23 04:49:29.927
    Jan 10 04:49:29.929: INFO: Observed &Deployment event: ADDED
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fhrlz-777898ffcc"}
    Jan 10 04:49:29.929: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fhrlz-777898ffcc"}
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jan 10 04:49:29.929: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:27 +0000 UTC 2023-01-10 04:49:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-fhrlz-777898ffcc" is progressing.}
    Jan 10 04:49:29.929: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}
    Jan 10 04:49:29.929: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-10 04:49:29 +0000 UTC 2023-01-10 04:49:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fhrlz-777898ffcc" has successfully progressed.}
    Jan 10 04:49:29.929: INFO: Observed deployment test-deployment-fhrlz in namespace deployment-9807 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jan 10 04:49:29.930: INFO: Observed &Deployment event: MODIFIED
    Jan 10 04:49:29.930: INFO: Found deployment test-deployment-fhrlz in namespace deployment-9807 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Jan 10 04:49:29.930: INFO: Deployment test-deployment-fhrlz has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 10 04:49:29.939: INFO: Deployment "test-deployment-fhrlz":
    &Deployment{ObjectMeta:{test-deployment-fhrlz  deployment-9807  06062072-6a7a-436a-83c7-faccbb1b6b15 242530 1 2023-01-10 04:49:27 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-01-10 04:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-01-10 04:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-01-10 04:49:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004fee1f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-fhrlz-777898ffcc",LastUpdateTime:2023-01-10 04:49:29 +0000 UTC,LastTransitionTime:2023-01-10 04:49:29 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jan 10 04:49:29.944: INFO: New ReplicaSet "test-deployment-fhrlz-777898ffcc" of Deployment "test-deployment-fhrlz":
    &ReplicaSet{ObjectMeta:{test-deployment-fhrlz-777898ffcc  deployment-9807  a8a34666-6ebc-40bc-88d7-4c25ca1644a2 242522 1 2023-01-10 04:49:27 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-fhrlz 06062072-6a7a-436a-83c7-faccbb1b6b15 0xc004fee5e0 0xc004fee5e1}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06062072-6a7a-436a-83c7-faccbb1b6b15\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:49:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004fee6f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:49:29.952: INFO: Pod "test-deployment-fhrlz-777898ffcc-nrvj5" is available:
    &Pod{ObjectMeta:{test-deployment-fhrlz-777898ffcc-nrvj5 test-deployment-fhrlz-777898ffcc- deployment-9807  3ad9ddad-dd7a-4793-adee-da0273310da9 242521 0 2023-01-10 04:49:27 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:b90cb2e16927d0a6e2d72c4db0e477d31392f1a28e0808bd8f26a43f57b633ea cni.projectcalico.org/podIP:10.42.1.63/32 cni.projectcalico.org/podIPs:10.42.1.63/32] [{apps/v1 ReplicaSet test-deployment-fhrlz-777898ffcc a8a34666-6ebc-40bc-88d7-4c25ca1644a2 0xc004feec30 0xc004feec31}] [] [{kube-controller-manager Update v1 2023-01-10 04:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a8a34666-6ebc-40bc-88d7-4c25ca1644a2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xz2xr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xz2xr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:49:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:49:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.3.44,PodIP:10.42.1.63,StartTime:2023-01-10 04:49:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://e61434c75f515fab6117e180058fb3268244e951b587bb75d1d465faa962e89b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 10 04:49:29.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9807" for this suite. 01/10/23 04:49:29.958
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:29.977
Jan 10 04:49:29.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubelet-test 01/10/23 04:49:29.981
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:29.999
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:30.001
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 01/10/23 04:49:30.021
Jan 10 04:49:30.021: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed" in namespace "kubelet-test-2525" to be "completed"
Jan 10 04:49:30.032: INFO: Pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.923911ms
Jan 10 04:49:32.036: INFO: Pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014599125s
Jan 10 04:49:34.034: INFO: Pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013365077s
Jan 10 04:49:34.034: INFO: Pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 10 04:49:34.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2525" for this suite. 01/10/23 04:49:34.042
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":262,"skipped":4500,"failed":0}
------------------------------
• [4.071 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:29.977
    Jan 10 04:49:29.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubelet-test 01/10/23 04:49:29.981
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:29.999
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:30.001
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 01/10/23 04:49:30.021
    Jan 10 04:49:30.021: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed" in namespace "kubelet-test-2525" to be "completed"
    Jan 10 04:49:30.032: INFO: Pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.923911ms
    Jan 10 04:49:32.036: INFO: Pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014599125s
    Jan 10 04:49:34.034: INFO: Pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013365077s
    Jan 10 04:49:34.034: INFO: Pod "agnhost-host-aliasesa80e0e41-6a5c-40a8-866a-ad379e9134ed" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 10 04:49:34.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2525" for this suite. 01/10/23 04:49:34.042
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:34.048
Jan 10 04:49:34.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:49:34.049
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:34.069
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:34.073
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9237 01/10/23 04:49:34.077
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 01/10/23 04:49:34.102
STEP: creating service externalsvc in namespace services-9237 01/10/23 04:49:34.102
STEP: creating replication controller externalsvc in namespace services-9237 01/10/23 04:49:34.142
I0110 04:49:34.187972      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9237, replica count: 2
I0110 04:49:37.239144      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 01/10/23 04:49:37.241
Jan 10 04:49:37.254: INFO: Creating new exec pod
Jan 10 04:49:37.262: INFO: Waiting up to 5m0s for pod "execpodmtff6" in namespace "services-9237" to be "running"
Jan 10 04:49:37.286: INFO: Pod "execpodmtff6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.541468ms
Jan 10 04:49:39.293: INFO: Pod "execpodmtff6": Phase="Running", Reason="", readiness=true. Elapsed: 2.030562349s
Jan 10 04:49:39.293: INFO: Pod "execpodmtff6" satisfied condition "running"
Jan 10 04:49:39.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-9237 exec execpodmtff6 -- /bin/sh -x -c nslookup nodeport-service.services-9237.svc.cluster.local'
Jan 10 04:49:39.503: INFO: stderr: "+ nslookup nodeport-service.services-9237.svc.cluster.local\n"
Jan 10 04:49:39.503: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nnodeport-service.services-9237.svc.cluster.local\tcanonical name = externalsvc.services-9237.svc.cluster.local.\nName:\texternalsvc.services-9237.svc.cluster.local\nAddress: 10.43.28.2\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9237, will wait for the garbage collector to delete the pods 01/10/23 04:49:39.503
Jan 10 04:49:39.559: INFO: Deleting ReplicationController externalsvc took: 3.745069ms
Jan 10 04:49:39.660: INFO: Terminating ReplicationController externalsvc pods took: 100.983106ms
Jan 10 04:49:41.478: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:49:41.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9237" for this suite. 01/10/23 04:49:41.496
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":263,"skipped":4531,"failed":0}
------------------------------
• [SLOW TEST] [7.456 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:34.048
    Jan 10 04:49:34.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:49:34.049
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:34.069
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:34.073
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-9237 01/10/23 04:49:34.077
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 01/10/23 04:49:34.102
    STEP: creating service externalsvc in namespace services-9237 01/10/23 04:49:34.102
    STEP: creating replication controller externalsvc in namespace services-9237 01/10/23 04:49:34.142
    I0110 04:49:34.187972      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9237, replica count: 2
    I0110 04:49:37.239144      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 01/10/23 04:49:37.241
    Jan 10 04:49:37.254: INFO: Creating new exec pod
    Jan 10 04:49:37.262: INFO: Waiting up to 5m0s for pod "execpodmtff6" in namespace "services-9237" to be "running"
    Jan 10 04:49:37.286: INFO: Pod "execpodmtff6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.541468ms
    Jan 10 04:49:39.293: INFO: Pod "execpodmtff6": Phase="Running", Reason="", readiness=true. Elapsed: 2.030562349s
    Jan 10 04:49:39.293: INFO: Pod "execpodmtff6" satisfied condition "running"
    Jan 10 04:49:39.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-9237 exec execpodmtff6 -- /bin/sh -x -c nslookup nodeport-service.services-9237.svc.cluster.local'
    Jan 10 04:49:39.503: INFO: stderr: "+ nslookup nodeport-service.services-9237.svc.cluster.local\n"
    Jan 10 04:49:39.503: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nnodeport-service.services-9237.svc.cluster.local\tcanonical name = externalsvc.services-9237.svc.cluster.local.\nName:\texternalsvc.services-9237.svc.cluster.local\nAddress: 10.43.28.2\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-9237, will wait for the garbage collector to delete the pods 01/10/23 04:49:39.503
    Jan 10 04:49:39.559: INFO: Deleting ReplicationController externalsvc took: 3.745069ms
    Jan 10 04:49:39.660: INFO: Terminating ReplicationController externalsvc pods took: 100.983106ms
    Jan 10 04:49:41.478: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:49:41.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9237" for this suite. 01/10/23 04:49:41.496
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:41.518
Jan 10 04:49:41.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 04:49:41.52
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:41.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:41.546
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Jan 10 04:49:41.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: creating the pod 01/10/23 04:49:41.551
STEP: submitting the pod to kubernetes 01/10/23 04:49:41.551
Jan 10 04:49:41.567: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d" in namespace "pods-9261" to be "running and ready"
Jan 10 04:49:41.582: INFO: Pod "pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.826277ms
Jan 10 04:49:41.582: INFO: The phase of Pod pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:49:43.587: INFO: Pod "pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d": Phase="Running", Reason="", readiness=true. Elapsed: 2.019998544s
Jan 10 04:49:43.587: INFO: The phase of Pod pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d is Running (Ready = true)
Jan 10 04:49:43.587: INFO: Pod "pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 04:49:43.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9261" for this suite. 01/10/23 04:49:43.705
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":264,"skipped":4559,"failed":0}
------------------------------
• [2.193 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:41.518
    Jan 10 04:49:41.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 04:49:41.52
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:41.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:41.546
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Jan 10 04:49:41.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: creating the pod 01/10/23 04:49:41.551
    STEP: submitting the pod to kubernetes 01/10/23 04:49:41.551
    Jan 10 04:49:41.567: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d" in namespace "pods-9261" to be "running and ready"
    Jan 10 04:49:41.582: INFO: Pod "pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.826277ms
    Jan 10 04:49:41.582: INFO: The phase of Pod pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:49:43.587: INFO: Pod "pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d": Phase="Running", Reason="", readiness=true. Elapsed: 2.019998544s
    Jan 10 04:49:43.587: INFO: The phase of Pod pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d is Running (Ready = true)
    Jan 10 04:49:43.587: INFO: Pod "pod-exec-websocket-d70de2a4-4aa5-414b-b64b-b2dd3d1c879d" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 04:49:43.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9261" for this suite. 01/10/23 04:49:43.705
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:49:43.713
Jan 10 04:49:43.713: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pod-network-test 01/10/23 04:49:43.714
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:43.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:43.853
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-1070 01/10/23 04:49:43.898
STEP: creating a selector 01/10/23 04:49:43.898
STEP: Creating the service pods in kubernetes 01/10/23 04:49:43.898
Jan 10 04:49:43.898: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jan 10 04:49:43.988: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1070" to be "running and ready"
Jan 10 04:49:44.065: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 76.687117ms
Jan 10 04:49:44.065: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:49:46.069: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080705906s
Jan 10 04:49:46.069: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:49:48.073: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.084493264s
Jan 10 04:49:48.073: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:49:50.071: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.083157603s
Jan 10 04:49:50.071: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:49:52.069: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.08063566s
Jan 10 04:49:52.069: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:49:54.068: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.08037463s
Jan 10 04:49:54.069: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:49:56.068: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.079761615s
Jan 10 04:49:56.068: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:49:58.068: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.079927386s
Jan 10 04:49:58.068: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:50:00.088: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.099661725s
Jan 10 04:50:00.088: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:50:02.068: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.080089654s
Jan 10 04:50:02.068: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:50:04.069: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.081141909s
Jan 10 04:50:04.069: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 10 04:50:06.069: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.080804643s
Jan 10 04:50:06.069: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jan 10 04:50:06.069: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jan 10 04:50:06.073: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1070" to be "running and ready"
Jan 10 04:50:06.078: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.370673ms
Jan 10 04:50:06.078: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jan 10 04:50:06.078: INFO: Pod "netserver-1" satisfied condition "running and ready"
Jan 10 04:50:06.081: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-1070" to be "running and ready"
Jan 10 04:50:06.085: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.376644ms
Jan 10 04:50:06.085: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Jan 10 04:50:06.086: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 01/10/23 04:50:06.088
Jan 10 04:50:06.103: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1070" to be "running"
Jan 10 04:50:06.119: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.115943ms
Jan 10 04:50:08.123: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019359046s
Jan 10 04:50:08.123: INFO: Pod "test-container-pod" satisfied condition "running"
Jan 10 04:50:08.126: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jan 10 04:50:08.126: INFO: Breadth first check of 10.42.0.111 on host 172.31.15.218...
Jan 10 04:50:08.129: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.69:9080/dial?request=hostname&protocol=udp&host=10.42.0.111&port=8081&tries=1'] Namespace:pod-network-test-1070 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:50:08.129: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:50:08.130: INFO: ExecWithOptions: Clientset creation
Jan 10 04:50:08.130: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1070/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.69%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.0.111%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 10 04:50:08.197: INFO: Waiting for responses: map[]
Jan 10 04:50:08.197: INFO: reached 10.42.0.111 after 0/1 tries
Jan 10 04:50:08.197: INFO: Breadth first check of 10.42.1.68 on host 172.31.3.44...
Jan 10 04:50:08.203: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.69:9080/dial?request=hostname&protocol=udp&host=10.42.1.68&port=8081&tries=1'] Namespace:pod-network-test-1070 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:50:08.203: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:50:08.203: INFO: ExecWithOptions: Clientset creation
Jan 10 04:50:08.203: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1070/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.69%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.1.68%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 10 04:50:08.289: INFO: Waiting for responses: map[]
Jan 10 04:50:08.289: INFO: reached 10.42.1.68 after 0/1 tries
Jan 10 04:50:08.289: INFO: Breadth first check of 10.42.2.169 on host 172.31.7.114...
Jan 10 04:50:08.292: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.69:9080/dial?request=hostname&protocol=udp&host=10.42.2.169&port=8081&tries=1'] Namespace:pod-network-test-1070 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:50:08.292: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:50:08.293: INFO: ExecWithOptions: Clientset creation
Jan 10 04:50:08.293: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1070/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.69%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.2.169%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 10 04:50:08.359: INFO: Waiting for responses: map[]
Jan 10 04:50:08.360: INFO: reached 10.42.2.169 after 0/1 tries
Jan 10 04:50:08.360: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jan 10 04:50:08.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1070" for this suite. 01/10/23 04:50:08.363
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":265,"skipped":4590,"failed":0}
------------------------------
• [SLOW TEST] [24.657 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:49:43.713
    Jan 10 04:49:43.713: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pod-network-test 01/10/23 04:49:43.714
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:49:43.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:49:43.853
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-1070 01/10/23 04:49:43.898
    STEP: creating a selector 01/10/23 04:49:43.898
    STEP: Creating the service pods in kubernetes 01/10/23 04:49:43.898
    Jan 10 04:49:43.898: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jan 10 04:49:43.988: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1070" to be "running and ready"
    Jan 10 04:49:44.065: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 76.687117ms
    Jan 10 04:49:44.065: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:49:46.069: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080705906s
    Jan 10 04:49:46.069: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:49:48.073: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.084493264s
    Jan 10 04:49:48.073: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:49:50.071: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.083157603s
    Jan 10 04:49:50.071: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:49:52.069: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.08063566s
    Jan 10 04:49:52.069: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:49:54.068: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.08037463s
    Jan 10 04:49:54.069: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:49:56.068: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.079761615s
    Jan 10 04:49:56.068: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:49:58.068: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.079927386s
    Jan 10 04:49:58.068: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:50:00.088: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.099661725s
    Jan 10 04:50:00.088: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:50:02.068: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.080089654s
    Jan 10 04:50:02.068: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:50:04.069: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.081141909s
    Jan 10 04:50:04.069: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 10 04:50:06.069: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.080804643s
    Jan 10 04:50:06.069: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jan 10 04:50:06.069: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jan 10 04:50:06.073: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1070" to be "running and ready"
    Jan 10 04:50:06.078: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.370673ms
    Jan 10 04:50:06.078: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jan 10 04:50:06.078: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Jan 10 04:50:06.081: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-1070" to be "running and ready"
    Jan 10 04:50:06.085: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.376644ms
    Jan 10 04:50:06.085: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Jan 10 04:50:06.086: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 01/10/23 04:50:06.088
    Jan 10 04:50:06.103: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1070" to be "running"
    Jan 10 04:50:06.119: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.115943ms
    Jan 10 04:50:08.123: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019359046s
    Jan 10 04:50:08.123: INFO: Pod "test-container-pod" satisfied condition "running"
    Jan 10 04:50:08.126: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Jan 10 04:50:08.126: INFO: Breadth first check of 10.42.0.111 on host 172.31.15.218...
    Jan 10 04:50:08.129: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.69:9080/dial?request=hostname&protocol=udp&host=10.42.0.111&port=8081&tries=1'] Namespace:pod-network-test-1070 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:50:08.129: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:50:08.130: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:50:08.130: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1070/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.69%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.0.111%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 10 04:50:08.197: INFO: Waiting for responses: map[]
    Jan 10 04:50:08.197: INFO: reached 10.42.0.111 after 0/1 tries
    Jan 10 04:50:08.197: INFO: Breadth first check of 10.42.1.68 on host 172.31.3.44...
    Jan 10 04:50:08.203: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.69:9080/dial?request=hostname&protocol=udp&host=10.42.1.68&port=8081&tries=1'] Namespace:pod-network-test-1070 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:50:08.203: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:50:08.203: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:50:08.203: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1070/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.69%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.1.68%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 10 04:50:08.289: INFO: Waiting for responses: map[]
    Jan 10 04:50:08.289: INFO: reached 10.42.1.68 after 0/1 tries
    Jan 10 04:50:08.289: INFO: Breadth first check of 10.42.2.169 on host 172.31.7.114...
    Jan 10 04:50:08.292: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.69:9080/dial?request=hostname&protocol=udp&host=10.42.2.169&port=8081&tries=1'] Namespace:pod-network-test-1070 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:50:08.292: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:50:08.293: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:50:08.293: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1070/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.69%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.2.169%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 10 04:50:08.359: INFO: Waiting for responses: map[]
    Jan 10 04:50:08.360: INFO: reached 10.42.2.169 after 0/1 tries
    Jan 10 04:50:08.360: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jan 10 04:50:08.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1070" for this suite. 01/10/23 04:50:08.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:50:08.373
Jan 10 04:50:08.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:50:08.374
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:08.399
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:08.405
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-5106 01/10/23 04:50:08.408
STEP: creating service affinity-clusterip-transition in namespace services-5106 01/10/23 04:50:08.408
STEP: creating replication controller affinity-clusterip-transition in namespace services-5106 01/10/23 04:50:08.419
I0110 04:50:08.448973      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-5106, replica count: 3
I0110 04:50:11.500310      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 04:50:11.505: INFO: Creating new exec pod
Jan 10 04:50:11.511: INFO: Waiting up to 5m0s for pod "execpod-affinitypvxr2" in namespace "services-5106" to be "running"
Jan 10 04:50:11.516: INFO: Pod "execpod-affinitypvxr2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.178885ms
Jan 10 04:50:13.522: INFO: Pod "execpod-affinitypvxr2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010448639s
Jan 10 04:50:13.523: INFO: Pod "execpod-affinitypvxr2" satisfied condition "running"
Jan 10 04:50:14.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5106 exec execpod-affinitypvxr2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Jan 10 04:50:14.687: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Jan 10 04:50:14.687: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:50:14.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5106 exec execpod-affinitypvxr2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.236.197 80'
Jan 10 04:50:14.868: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.236.197 80\nConnection to 10.43.236.197 80 port [tcp/http] succeeded!\n"
Jan 10 04:50:14.868: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 04:50:14.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5106 exec execpod-affinitypvxr2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.236.197:80/ ; done'
Jan 10 04:50:15.171: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n"
Jan 10 04:50:15.171: INFO: stdout: "\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-k69ft"
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
Jan 10 04:50:15.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5106 exec execpod-affinitypvxr2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.236.197:80/ ; done'
Jan 10 04:50:15.453: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n"
Jan 10 04:50:15.453: INFO: stdout: "\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c"
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
Jan 10 04:50:15.454: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-5106, will wait for the garbage collector to delete the pods 01/10/23 04:50:15.464
Jan 10 04:50:15.524: INFO: Deleting ReplicationController affinity-clusterip-transition took: 3.786813ms
Jan 10 04:50:15.625: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.067935ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:50:18.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5106" for this suite. 01/10/23 04:50:18.193
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":266,"skipped":4621,"failed":0}
------------------------------
• [SLOW TEST] [9.829 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:50:08.373
    Jan 10 04:50:08.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:50:08.374
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:08.399
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:08.405
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-5106 01/10/23 04:50:08.408
    STEP: creating service affinity-clusterip-transition in namespace services-5106 01/10/23 04:50:08.408
    STEP: creating replication controller affinity-clusterip-transition in namespace services-5106 01/10/23 04:50:08.419
    I0110 04:50:08.448973      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-5106, replica count: 3
    I0110 04:50:11.500310      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 04:50:11.505: INFO: Creating new exec pod
    Jan 10 04:50:11.511: INFO: Waiting up to 5m0s for pod "execpod-affinitypvxr2" in namespace "services-5106" to be "running"
    Jan 10 04:50:11.516: INFO: Pod "execpod-affinitypvxr2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.178885ms
    Jan 10 04:50:13.522: INFO: Pod "execpod-affinitypvxr2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010448639s
    Jan 10 04:50:13.523: INFO: Pod "execpod-affinitypvxr2" satisfied condition "running"
    Jan 10 04:50:14.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5106 exec execpod-affinitypvxr2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Jan 10 04:50:14.687: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Jan 10 04:50:14.687: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:50:14.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5106 exec execpod-affinitypvxr2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.236.197 80'
    Jan 10 04:50:14.868: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.236.197 80\nConnection to 10.43.236.197 80 port [tcp/http] succeeded!\n"
    Jan 10 04:50:14.868: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 04:50:14.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5106 exec execpod-affinitypvxr2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.236.197:80/ ; done'
    Jan 10 04:50:15.171: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n"
    Jan 10 04:50:15.171: INFO: stdout: "\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-k69ft\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-l5g9q\naffinity-clusterip-transition-k69ft"
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-l5g9q
    Jan 10 04:50:15.171: INFO: Received response from host: affinity-clusterip-transition-k69ft
    Jan 10 04:50:15.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-5106 exec execpod-affinitypvxr2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.236.197:80/ ; done'
    Jan 10 04:50:15.453: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.236.197:80/\n"
    Jan 10 04:50:15.453: INFO: stdout: "\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c\naffinity-clusterip-transition-gkg8c"
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.453: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.454: INFO: Received response from host: affinity-clusterip-transition-gkg8c
    Jan 10 04:50:15.454: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-5106, will wait for the garbage collector to delete the pods 01/10/23 04:50:15.464
    Jan 10 04:50:15.524: INFO: Deleting ReplicationController affinity-clusterip-transition took: 3.786813ms
    Jan 10 04:50:15.625: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.067935ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:50:18.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5106" for this suite. 01/10/23 04:50:18.193
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:50:18.204
Jan 10 04:50:18.204: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename svcaccounts 01/10/23 04:50:18.205
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:18.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:18.24
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  01/10/23 04:50:18.244
Jan 10 04:50:18.254: INFO: Waiting up to 5m0s for pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905" in namespace "svcaccounts-4998" to be "Succeeded or Failed"
Jan 10 04:50:18.282: INFO: Pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905": Phase="Pending", Reason="", readiness=false. Elapsed: 28.083791ms
Jan 10 04:50:20.286: INFO: Pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032542905s
Jan 10 04:50:22.286: INFO: Pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032262745s
STEP: Saw pod success 01/10/23 04:50:22.286
Jan 10 04:50:22.286: INFO: Pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905" satisfied condition "Succeeded or Failed"
Jan 10 04:50:22.288: INFO: Trying to get logs from node cncf-wk2 pod test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:50:22.305
Jan 10 04:50:22.318: INFO: Waiting for pod test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905 to disappear
Jan 10 04:50:22.323: INFO: Pod test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 10 04:50:22.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4998" for this suite. 01/10/23 04:50:22.326
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":267,"skipped":4623,"failed":0}
------------------------------
• [4.127 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:50:18.204
    Jan 10 04:50:18.204: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename svcaccounts 01/10/23 04:50:18.205
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:18.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:18.24
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  01/10/23 04:50:18.244
    Jan 10 04:50:18.254: INFO: Waiting up to 5m0s for pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905" in namespace "svcaccounts-4998" to be "Succeeded or Failed"
    Jan 10 04:50:18.282: INFO: Pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905": Phase="Pending", Reason="", readiness=false. Elapsed: 28.083791ms
    Jan 10 04:50:20.286: INFO: Pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032542905s
    Jan 10 04:50:22.286: INFO: Pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032262745s
    STEP: Saw pod success 01/10/23 04:50:22.286
    Jan 10 04:50:22.286: INFO: Pod "test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905" satisfied condition "Succeeded or Failed"
    Jan 10 04:50:22.288: INFO: Trying to get logs from node cncf-wk2 pod test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:50:22.305
    Jan 10 04:50:22.318: INFO: Waiting for pod test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905 to disappear
    Jan 10 04:50:22.323: INFO: Pod test-pod-ab8bbbcc-a62f-49ec-9171-a109d2b85905 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 10 04:50:22.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4998" for this suite. 01/10/23 04:50:22.326
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:50:22.338
Jan 10 04:50:22.338: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:50:22.339
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:22.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:22.368
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-291a4114-7549-4497-ac39-e5585b4e6a75 01/10/23 04:50:22.444
STEP: Creating a pod to test consume secrets 01/10/23 04:50:22.468
Jan 10 04:50:22.482: INFO: Waiting up to 5m0s for pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2" in namespace "secrets-5512" to be "Succeeded or Failed"
Jan 10 04:50:22.503: INFO: Pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.906091ms
Jan 10 04:50:24.506: INFO: Pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024685333s
Jan 10 04:50:26.511: INFO: Pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029182857s
STEP: Saw pod success 01/10/23 04:50:26.511
Jan 10 04:50:26.511: INFO: Pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2" satisfied condition "Succeeded or Failed"
Jan 10 04:50:26.520: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2 container secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:50:26.536
Jan 10 04:50:26.581: INFO: Waiting for pod pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2 to disappear
Jan 10 04:50:26.601: INFO: Pod pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:50:26.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5512" for this suite. 01/10/23 04:50:26.617
STEP: Destroying namespace "secret-namespace-8899" for this suite. 01/10/23 04:50:26.629
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":268,"skipped":4632,"failed":0}
------------------------------
• [4.313 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:50:22.338
    Jan 10 04:50:22.338: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:50:22.339
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:22.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:22.368
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-291a4114-7549-4497-ac39-e5585b4e6a75 01/10/23 04:50:22.444
    STEP: Creating a pod to test consume secrets 01/10/23 04:50:22.468
    Jan 10 04:50:22.482: INFO: Waiting up to 5m0s for pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2" in namespace "secrets-5512" to be "Succeeded or Failed"
    Jan 10 04:50:22.503: INFO: Pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.906091ms
    Jan 10 04:50:24.506: INFO: Pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024685333s
    Jan 10 04:50:26.511: INFO: Pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029182857s
    STEP: Saw pod success 01/10/23 04:50:26.511
    Jan 10 04:50:26.511: INFO: Pod "pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2" satisfied condition "Succeeded or Failed"
    Jan 10 04:50:26.520: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2 container secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:50:26.536
    Jan 10 04:50:26.581: INFO: Waiting for pod pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2 to disappear
    Jan 10 04:50:26.601: INFO: Pod pod-secrets-a0f2cd07-3d54-4dce-915a-1f017b64d9a2 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:50:26.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5512" for this suite. 01/10/23 04:50:26.617
    STEP: Destroying namespace "secret-namespace-8899" for this suite. 01/10/23 04:50:26.629
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:50:26.654
Jan 10 04:50:26.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename daemonsets 01/10/23 04:50:26.655
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:26.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:26.781
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Jan 10 04:50:26.870: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:50:26.883
Jan 10 04:50:26.901: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:50:26.901: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:50:27.911: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:50:27.911: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:50:28.909: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 04:50:28.909: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 04:50:29.910: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 04:50:29.910: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 01/10/23 04:50:29.921
STEP: Check that daemon pods images are updated. 01/10/23 04:50:29.931
Jan 10 04:50:29.937: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:29.937: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:29.937: INFO: Wrong image for pod: daemon-set-qzf8q. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:30.951: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:30.951: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:31.957: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:31.957: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:32.954: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:32.954: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:32.954: INFO: Pod daemon-set-jh492 is not available
Jan 10 04:50:33.950: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:33.950: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:33.950: INFO: Pod daemon-set-jh492 is not available
Jan 10 04:50:34.955: INFO: Pod daemon-set-f9j8r is not available
Jan 10 04:50:34.955: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 10 04:50:37.950: INFO: Pod daemon-set-8rbkc is not available
STEP: Check that daemon pods are still running on every node of the cluster. 01/10/23 04:50:37.954
Jan 10 04:50:37.959: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 04:50:37.959: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
Jan 10 04:50:38.968: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 04:50:38.968: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
Jan 10 04:50:39.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 04:50:39.966: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/10/23 04:50:39.988
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4604, will wait for the garbage collector to delete the pods 01/10/23 04:50:39.988
Jan 10 04:50:40.052: INFO: Deleting DaemonSet.extensions daemon-set took: 5.601826ms
Jan 10 04:50:40.152: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.128569ms
Jan 10 04:50:42.654: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 04:50:42.655: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 10 04:50:42.656: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"243429"},"items":null}

Jan 10 04:50:42.658: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"243429"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:50:42.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4604" for this suite. 01/10/23 04:50:42.67
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":269,"skipped":4651,"failed":0}
------------------------------
• [SLOW TEST] [16.024 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:50:26.654
    Jan 10 04:50:26.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename daemonsets 01/10/23 04:50:26.655
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:26.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:26.781
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Jan 10 04:50:26.870: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 04:50:26.883
    Jan 10 04:50:26.901: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:50:26.901: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:50:27.911: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:50:27.911: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:50:28.909: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 04:50:28.909: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 04:50:29.910: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 04:50:29.910: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 01/10/23 04:50:29.921
    STEP: Check that daemon pods images are updated. 01/10/23 04:50:29.931
    Jan 10 04:50:29.937: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:29.937: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:29.937: INFO: Wrong image for pod: daemon-set-qzf8q. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:30.951: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:30.951: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:31.957: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:31.957: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:32.954: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:32.954: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:32.954: INFO: Pod daemon-set-jh492 is not available
    Jan 10 04:50:33.950: INFO: Wrong image for pod: daemon-set-72zch. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:33.950: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:33.950: INFO: Pod daemon-set-jh492 is not available
    Jan 10 04:50:34.955: INFO: Pod daemon-set-f9j8r is not available
    Jan 10 04:50:34.955: INFO: Wrong image for pod: daemon-set-h9vdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 10 04:50:37.950: INFO: Pod daemon-set-8rbkc is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 01/10/23 04:50:37.954
    Jan 10 04:50:37.959: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 04:50:37.959: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
    Jan 10 04:50:38.968: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 04:50:38.968: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
    Jan 10 04:50:39.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 04:50:39.966: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/10/23 04:50:39.988
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4604, will wait for the garbage collector to delete the pods 01/10/23 04:50:39.988
    Jan 10 04:50:40.052: INFO: Deleting DaemonSet.extensions daemon-set took: 5.601826ms
    Jan 10 04:50:40.152: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.128569ms
    Jan 10 04:50:42.654: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 04:50:42.655: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 10 04:50:42.656: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"243429"},"items":null}

    Jan 10 04:50:42.658: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"243429"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:50:42.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4604" for this suite. 01/10/23 04:50:42.67
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:50:42.678
Jan 10 04:50:42.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:50:42.679
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:42.705
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:42.714
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-1bbab0b4-aed1-4b94-9d7b-fec4d65b1e86 01/10/23 04:50:42.717
STEP: Creating a pod to test consume secrets 01/10/23 04:50:42.727
Jan 10 04:50:42.746: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff" in namespace "projected-7323" to be "Succeeded or Failed"
Jan 10 04:50:42.766: INFO: Pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff": Phase="Pending", Reason="", readiness=false. Elapsed: 19.992078ms
Jan 10 04:50:44.769: INFO: Pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023346244s
Jan 10 04:50:46.769: INFO: Pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023053128s
STEP: Saw pod success 01/10/23 04:50:46.769
Jan 10 04:50:46.770: INFO: Pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff" satisfied condition "Succeeded or Failed"
Jan 10 04:50:46.772: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff container projected-secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:50:46.779
Jan 10 04:50:46.789: INFO: Waiting for pod pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff to disappear
Jan 10 04:50:46.791: INFO: Pod pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 10 04:50:46.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7323" for this suite. 01/10/23 04:50:46.795
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":270,"skipped":4651,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:50:42.678
    Jan 10 04:50:42.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:50:42.679
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:42.705
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:42.714
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-1bbab0b4-aed1-4b94-9d7b-fec4d65b1e86 01/10/23 04:50:42.717
    STEP: Creating a pod to test consume secrets 01/10/23 04:50:42.727
    Jan 10 04:50:42.746: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff" in namespace "projected-7323" to be "Succeeded or Failed"
    Jan 10 04:50:42.766: INFO: Pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff": Phase="Pending", Reason="", readiness=false. Elapsed: 19.992078ms
    Jan 10 04:50:44.769: INFO: Pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023346244s
    Jan 10 04:50:46.769: INFO: Pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023053128s
    STEP: Saw pod success 01/10/23 04:50:46.769
    Jan 10 04:50:46.770: INFO: Pod "pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff" satisfied condition "Succeeded or Failed"
    Jan 10 04:50:46.772: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:50:46.779
    Jan 10 04:50:46.789: INFO: Waiting for pod pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff to disappear
    Jan 10 04:50:46.791: INFO: Pod pod-projected-secrets-8230b7bf-26ef-4c5e-ae76-7a6277c184ff no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 10 04:50:46.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7323" for this suite. 01/10/23 04:50:46.795
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:50:46.804
Jan 10 04:50:46.805: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 04:50:46.806
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:46.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:46.837
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Jan 10 04:50:46.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 create -f -'
Jan 10 04:50:47.107: INFO: stderr: ""
Jan 10 04:50:47.107: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Jan 10 04:50:47.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 create -f -'
Jan 10 04:50:47.613: INFO: stderr: ""
Jan 10 04:50:47.613: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 01/10/23 04:50:47.613
Jan 10 04:50:48.616: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 04:50:48.616: INFO: Found 0 / 1
Jan 10 04:50:49.619: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 04:50:49.619: INFO: Found 1 / 1
Jan 10 04:50:49.619: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 10 04:50:49.621: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 04:50:49.621: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 10 04:50:49.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe pod agnhost-primary-kh5bd'
Jan 10 04:50:49.744: INFO: stderr: ""
Jan 10 04:50:49.744: INFO: stdout: "Name:             agnhost-primary-kh5bd\nNamespace:        kubectl-5844\nPriority:         0\nService Account:  default\nNode:             cncf-wk2/172.31.3.44\nStart Time:       Tue, 10 Jan 2023 04:50:47 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 2f17c72d4249ba885afa02cd97fb6c7090b1dc3f8a6b24df41eccb1f4e906e6b\n                  cni.projectcalico.org/podIP: 10.42.1.76/32\n                  cni.projectcalico.org/podIPs: 10.42.1.76/32\nStatus:           Running\nIP:               10.42.1.76\nIPs:\n  IP:           10.42.1.76\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://6e25756c24dc7cc648e1630dd5d0485be656aca0967ea0fa9cc5e8b3066d5e4e\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 10 Jan 2023 04:50:48 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-s7w55 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-s7w55:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5844/agnhost-primary-kh5bd to cncf-wk2\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Jan 10 04:50:49.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe rc agnhost-primary'
Jan 10 04:50:49.958: INFO: stderr: ""
Jan 10 04:50:49.958: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5844\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-kh5bd\n"
Jan 10 04:50:49.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe service agnhost-primary'
Jan 10 04:50:50.052: INFO: stderr: ""
Jan 10 04:50:50.052: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5844\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.43.121.220\nIPs:               10.43.121.220\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.42.1.76:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 10 04:50:50.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe node cncf-cp-etcd-wk1'
Jan 10 04:50:50.171: INFO: stderr: ""
Jan 10 04:50:50.171: INFO: stdout: "Name:               cncf-cp-etcd-wk1\nRoles:              controlplane,etcd,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    cattle.io/creator=norman\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=cncf-cp-etcd-wk1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/controlplane=true\n                    node-role.kubernetes.io/etcd=true\n                    node-role.kubernetes.io/worker=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"fe:f4:f3:95:8c:83\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.31.15.218\n                    management.cattle.io/pod-limits: {\"memory\":\"170Mi\"}\n                    management.cattle.io/pod-requests: {\"cpu\":\"470m\",\"memory\":\"280Mi\",\"pods\":\"12\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 172.31.15.218/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.42.0.1\n                    rke.cattle.io/external-ip: 52.14.11.230\n                    rke.cattle.io/internal-ip: 172.31.15.218\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 09 Jan 2023 10:31:42 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  cncf-cp-etcd-wk1\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 10 Jan 2023 04:50:43 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 09 Jan 2023 10:32:19 +0000   Mon, 09 Jan 2023 10:32:19 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 10 Jan 2023 04:49:43 +0000   Mon, 09 Jan 2023 10:31:42 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 10 Jan 2023 04:49:43 +0000   Mon, 09 Jan 2023 10:31:42 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 10 Jan 2023 04:49:43 +0000   Mon, 09 Jan 2023 10:31:42 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 10 Jan 2023 04:49:43 +0000   Mon, 09 Jan 2023 11:00:39 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.15.218\n  Hostname:    cncf-cp-etcd-wk1\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      16197480Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3958708Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    2\n  ephemeral-storage:      14927597544\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3856308Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 \n  System UUID:                ec208332-c76f-37bf-c855-4755d272940c\n  Boot ID:                    1030e5ea-3ce6-4336-8426-f6304acb2e24\n  Kernel Version:             5.13.0-1022-aws\n  OS Image:                   Ubuntu 20.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.21\n  Kubelet Version:            v1.25.5\n  Kube-Proxy Version:         v1.25.5\nPodCIDR:                      10.42.0.0/24\nPodCIDRs:                     10.42.0.0/24\nNon-terminated Pods:          (12 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  cattle-fleet-system         fleet-agent-745f6c6b7-8rvwd                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               cattle-cluster-agent-5c558c4984-89k8k                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               cattle-cluster-agent-5c558c4984-rwcnh                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               cattle-node-agent-jk48f                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               kube-api-auth-gclz6                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               rancher-webhook-5d7cccbd5-27z2v                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  kube-system                 calico-kube-controllers-85d56898c-pmz4s                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  kube-system                 canal-b5cw4                                                250m (12%)    0 (0%)      0 (0%)           0 (0%)         18h\n  kube-system                 coredns-autoscaler-74d474f45c-rx5r4                        20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         18h\n  kube-system                 coredns-dfb7f8fd4-nhjj8                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     18h\n  kube-system                 metrics-server-c47f7c9bb-v98f6                             100m (5%)     0 (0%)      200Mi (5%)       0 (0%)         18h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r    0 (0%)        0 (0%)      0 (0%)           0 (0%)         75m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    470m (23%)  0 (0%)\n  memory                 280Mi (7%)  170Mi (4%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:                  <none>\n"
Jan 10 04:50:50.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe namespace kubectl-5844'
Jan 10 04:50:50.291: INFO: stderr: ""
Jan 10 04:50:50.291: INFO: stdout: "Name:         kubectl-5844\nLabels:       e2e-framework=kubectl\n              e2e-run=746c852c-3453-440b-884c-9c980578a8f7\n              kubernetes.io/metadata.name=kubectl-5844\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  cattle.io/status:\n                {\"Conditions\":[{\"Type\":\"ResourceQuotaInit\",\"Status\":\"True\",\"Message\":\"\",\"LastUpdateTime\":\"2023-01-10T04:50:47Z\"},{\"Type\":\"InitialRolesPopu...\n              lifecycle.cattle.io/create.namespace-auth: true\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 04:50:50.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5844" for this suite. 01/10/23 04:50:50.294
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":271,"skipped":4688,"failed":0}
------------------------------
• [3.495 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:50:46.804
    Jan 10 04:50:46.805: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 04:50:46.806
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:46.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:46.837
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Jan 10 04:50:46.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 create -f -'
    Jan 10 04:50:47.107: INFO: stderr: ""
    Jan 10 04:50:47.107: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Jan 10 04:50:47.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 create -f -'
    Jan 10 04:50:47.613: INFO: stderr: ""
    Jan 10 04:50:47.613: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 01/10/23 04:50:47.613
    Jan 10 04:50:48.616: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 04:50:48.616: INFO: Found 0 / 1
    Jan 10 04:50:49.619: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 04:50:49.619: INFO: Found 1 / 1
    Jan 10 04:50:49.619: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Jan 10 04:50:49.621: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 04:50:49.621: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jan 10 04:50:49.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe pod agnhost-primary-kh5bd'
    Jan 10 04:50:49.744: INFO: stderr: ""
    Jan 10 04:50:49.744: INFO: stdout: "Name:             agnhost-primary-kh5bd\nNamespace:        kubectl-5844\nPriority:         0\nService Account:  default\nNode:             cncf-wk2/172.31.3.44\nStart Time:       Tue, 10 Jan 2023 04:50:47 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 2f17c72d4249ba885afa02cd97fb6c7090b1dc3f8a6b24df41eccb1f4e906e6b\n                  cni.projectcalico.org/podIP: 10.42.1.76/32\n                  cni.projectcalico.org/podIPs: 10.42.1.76/32\nStatus:           Running\nIP:               10.42.1.76\nIPs:\n  IP:           10.42.1.76\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://6e25756c24dc7cc648e1630dd5d0485be656aca0967ea0fa9cc5e8b3066d5e4e\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 10 Jan 2023 04:50:48 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-s7w55 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-s7w55:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5844/agnhost-primary-kh5bd to cncf-wk2\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Jan 10 04:50:49.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe rc agnhost-primary'
    Jan 10 04:50:49.958: INFO: stderr: ""
    Jan 10 04:50:49.958: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5844\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-kh5bd\n"
    Jan 10 04:50:49.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe service agnhost-primary'
    Jan 10 04:50:50.052: INFO: stderr: ""
    Jan 10 04:50:50.052: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5844\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.43.121.220\nIPs:               10.43.121.220\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.42.1.76:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Jan 10 04:50:50.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe node cncf-cp-etcd-wk1'
    Jan 10 04:50:50.171: INFO: stderr: ""
    Jan 10 04:50:50.171: INFO: stdout: "Name:               cncf-cp-etcd-wk1\nRoles:              controlplane,etcd,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    cattle.io/creator=norman\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=cncf-cp-etcd-wk1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/controlplane=true\n                    node-role.kubernetes.io/etcd=true\n                    node-role.kubernetes.io/worker=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"fe:f4:f3:95:8c:83\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.31.15.218\n                    management.cattle.io/pod-limits: {\"memory\":\"170Mi\"}\n                    management.cattle.io/pod-requests: {\"cpu\":\"470m\",\"memory\":\"280Mi\",\"pods\":\"12\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 172.31.15.218/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.42.0.1\n                    rke.cattle.io/external-ip: 52.14.11.230\n                    rke.cattle.io/internal-ip: 172.31.15.218\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 09 Jan 2023 10:31:42 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  cncf-cp-etcd-wk1\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 10 Jan 2023 04:50:43 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 09 Jan 2023 10:32:19 +0000   Mon, 09 Jan 2023 10:32:19 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 10 Jan 2023 04:49:43 +0000   Mon, 09 Jan 2023 10:31:42 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 10 Jan 2023 04:49:43 +0000   Mon, 09 Jan 2023 10:31:42 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 10 Jan 2023 04:49:43 +0000   Mon, 09 Jan 2023 10:31:42 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 10 Jan 2023 04:49:43 +0000   Mon, 09 Jan 2023 11:00:39 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.15.218\n  Hostname:    cncf-cp-etcd-wk1\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      16197480Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3958708Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    2\n  ephemeral-storage:      14927597544\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3856308Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 \n  System UUID:                ec208332-c76f-37bf-c855-4755d272940c\n  Boot ID:                    1030e5ea-3ce6-4336-8426-f6304acb2e24\n  Kernel Version:             5.13.0-1022-aws\n  OS Image:                   Ubuntu 20.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.21\n  Kubelet Version:            v1.25.5\n  Kube-Proxy Version:         v1.25.5\nPodCIDR:                      10.42.0.0/24\nPodCIDRs:                     10.42.0.0/24\nNon-terminated Pods:          (12 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  cattle-fleet-system         fleet-agent-745f6c6b7-8rvwd                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               cattle-cluster-agent-5c558c4984-89k8k                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               cattle-cluster-agent-5c558c4984-rwcnh                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               cattle-node-agent-jk48f                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               kube-api-auth-gclz6                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  cattle-system               rancher-webhook-5d7cccbd5-27z2v                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  kube-system                 calico-kube-controllers-85d56898c-pmz4s                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h\n  kube-system                 canal-b5cw4                                                250m (12%)    0 (0%)      0 (0%)           0 (0%)         18h\n  kube-system                 coredns-autoscaler-74d474f45c-rx5r4                        20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         18h\n  kube-system                 coredns-dfb7f8fd4-nhjj8                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     18h\n  kube-system                 metrics-server-c47f7c9bb-v98f6                             100m (5%)     0 (0%)      200Mi (5%)       0 (0%)         18h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r    0 (0%)        0 (0%)      0 (0%)           0 (0%)         75m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    470m (23%)  0 (0%)\n  memory                 280Mi (7%)  170Mi (4%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:                  <none>\n"
    Jan 10 04:50:50.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-5844 describe namespace kubectl-5844'
    Jan 10 04:50:50.291: INFO: stderr: ""
    Jan 10 04:50:50.291: INFO: stdout: "Name:         kubectl-5844\nLabels:       e2e-framework=kubectl\n              e2e-run=746c852c-3453-440b-884c-9c980578a8f7\n              kubernetes.io/metadata.name=kubectl-5844\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  cattle.io/status:\n                {\"Conditions\":[{\"Type\":\"ResourceQuotaInit\",\"Status\":\"True\",\"Message\":\"\",\"LastUpdateTime\":\"2023-01-10T04:50:47Z\"},{\"Type\":\"InitialRolesPopu...\n              lifecycle.cattle.io/create.namespace-auth: true\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 04:50:50.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5844" for this suite. 01/10/23 04:50:50.294
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:50:50.3
Jan 10 04:50:50.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:50:50.3
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:50.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:50.329
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-2091/configmap-test-df2f6ac8-2cf1-4495-a36a-4f890e51350a 01/10/23 04:50:50.332
STEP: Creating a pod to test consume configMaps 01/10/23 04:50:50.336
Jan 10 04:50:50.352: INFO: Waiting up to 5m0s for pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca" in namespace "configmap-2091" to be "Succeeded or Failed"
Jan 10 04:50:50.368: INFO: Pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca": Phase="Pending", Reason="", readiness=false. Elapsed: 16.237119ms
Jan 10 04:50:52.371: INFO: Pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019090741s
Jan 10 04:50:54.371: INFO: Pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019559955s
STEP: Saw pod success 01/10/23 04:50:54.372
Jan 10 04:50:54.372: INFO: Pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca" satisfied condition "Succeeded or Failed"
Jan 10 04:50:54.374: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca container env-test: <nil>
STEP: delete the pod 01/10/23 04:50:54.384
Jan 10 04:50:54.395: INFO: Waiting for pod pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca to disappear
Jan 10 04:50:54.398: INFO: Pod pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:50:54.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2091" for this suite. 01/10/23 04:50:54.401
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":272,"skipped":4692,"failed":0}
------------------------------
• [4.107 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:50:50.3
    Jan 10 04:50:50.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:50:50.3
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:50.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:50.329
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-2091/configmap-test-df2f6ac8-2cf1-4495-a36a-4f890e51350a 01/10/23 04:50:50.332
    STEP: Creating a pod to test consume configMaps 01/10/23 04:50:50.336
    Jan 10 04:50:50.352: INFO: Waiting up to 5m0s for pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca" in namespace "configmap-2091" to be "Succeeded or Failed"
    Jan 10 04:50:50.368: INFO: Pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca": Phase="Pending", Reason="", readiness=false. Elapsed: 16.237119ms
    Jan 10 04:50:52.371: INFO: Pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019090741s
    Jan 10 04:50:54.371: INFO: Pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019559955s
    STEP: Saw pod success 01/10/23 04:50:54.372
    Jan 10 04:50:54.372: INFO: Pod "pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca" satisfied condition "Succeeded or Failed"
    Jan 10 04:50:54.374: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca container env-test: <nil>
    STEP: delete the pod 01/10/23 04:50:54.384
    Jan 10 04:50:54.395: INFO: Waiting for pod pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca to disappear
    Jan 10 04:50:54.398: INFO: Pod pod-configmaps-1e4d6e16-1508-403e-9d3f-42e6b51e77ca no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:50:54.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2091" for this suite. 01/10/23 04:50:54.401
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:50:54.409
Jan 10 04:50:54.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir-wrapper 01/10/23 04:50:54.41
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:54.431
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:54.448
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 01/10/23 04:50:54.458
STEP: Creating RC which spawns configmap-volume pods 01/10/23 04:50:54.717
Jan 10 04:50:54.774: INFO: Pod name wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77: Found 1 pods out of 5
Jan 10 04:50:59.802: INFO: Pod name wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77: Found 5 pods out of 5
STEP: Ensuring each pod is running 01/10/23 04:50:59.802
Jan 10 04:50:59.803: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:50:59.811: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 7.979483ms
Jan 10 04:51:01.815: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012810618s
Jan 10 04:51:03.815: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012222639s
Jan 10 04:51:05.815: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011961946s
Jan 10 04:51:07.820: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017665734s
Jan 10 04:51:09.825: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Running", Reason="", readiness=true. Elapsed: 10.022448049s
Jan 10 04:51:09.825: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w" satisfied condition "running"
Jan 10 04:51:09.826: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-gt977" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:09.838: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-gt977": Phase="Pending", Reason="", readiness=false. Elapsed: 10.649499ms
Jan 10 04:51:11.843: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-gt977": Phase="Running", Reason="", readiness=true. Elapsed: 2.016322924s
Jan 10 04:51:11.843: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-gt977" satisfied condition "running"
Jan 10 04:51:11.844: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-nzvz9" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:11.847: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-nzvz9": Phase="Running", Reason="", readiness=true. Elapsed: 2.965253ms
Jan 10 04:51:11.847: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-nzvz9" satisfied condition "running"
Jan 10 04:51:11.847: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-q9x46" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:11.849: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-q9x46": Phase="Running", Reason="", readiness=true. Elapsed: 2.6941ms
Jan 10 04:51:11.849: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-q9x46" satisfied condition "running"
Jan 10 04:51:11.849: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-szj8s" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:11.852: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-szj8s": Phase="Running", Reason="", readiness=true. Elapsed: 2.97804ms
Jan 10 04:51:11.853: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-szj8s" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77 in namespace emptydir-wrapper-8070, will wait for the garbage collector to delete the pods 01/10/23 04:51:11.853
Jan 10 04:51:11.930: INFO: Deleting ReplicationController wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77 took: 17.017237ms
Jan 10 04:51:12.230: INFO: Terminating ReplicationController wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77 pods took: 300.538397ms
STEP: Creating RC which spawns configmap-volume pods 01/10/23 04:51:15.334
Jan 10 04:51:15.344: INFO: Pod name wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164: Found 0 pods out of 5
Jan 10 04:51:20.351: INFO: Pod name wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164: Found 5 pods out of 5
STEP: Ensuring each pod is running 01/10/23 04:51:20.351
Jan 10 04:51:20.352: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:20.354: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.735721ms
Jan 10 04:51:22.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006307521s
Jan 10 04:51:24.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006869585s
Jan 10 04:51:26.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006639194s
Jan 10 04:51:28.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006519282s
Jan 10 04:51:30.359: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007608551s
Jan 10 04:51:32.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Running", Reason="", readiness=true. Elapsed: 12.006572997s
Jan 10 04:51:32.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw" satisfied condition "running"
Jan 10 04:51:32.358: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-7bxq8" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:32.361: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-7bxq8": Phase="Running", Reason="", readiness=true. Elapsed: 2.731262ms
Jan 10 04:51:32.361: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-7bxq8" satisfied condition "running"
Jan 10 04:51:32.361: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-fmr59" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:32.366: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-fmr59": Phase="Running", Reason="", readiness=true. Elapsed: 4.773093ms
Jan 10 04:51:32.366: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-fmr59" satisfied condition "running"
Jan 10 04:51:32.366: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-hs6h8" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:32.369: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-hs6h8": Phase="Running", Reason="", readiness=true. Elapsed: 2.716598ms
Jan 10 04:51:32.369: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-hs6h8" satisfied condition "running"
Jan 10 04:51:32.369: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-xmzgr" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:32.372: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-xmzgr": Phase="Running", Reason="", readiness=true. Elapsed: 2.553486ms
Jan 10 04:51:32.372: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-xmzgr" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164 in namespace emptydir-wrapper-8070, will wait for the garbage collector to delete the pods 01/10/23 04:51:32.372
Jan 10 04:51:32.433: INFO: Deleting ReplicationController wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164 took: 5.348297ms
Jan 10 04:51:32.633: INFO: Terminating ReplicationController wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164 pods took: 200.512995ms
STEP: Creating RC which spawns configmap-volume pods 01/10/23 04:51:37.038
Jan 10 04:51:37.053: INFO: Pod name wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417: Found 0 pods out of 5
Jan 10 04:51:42.064: INFO: Pod name wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417: Found 5 pods out of 5
STEP: Ensuring each pod is running 01/10/23 04:51:42.064
Jan 10 04:51:42.064: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:42.068: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.358759ms
Jan 10 04:51:44.073: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008953093s
Jan 10 04:51:46.071: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00761355s
Jan 10 04:51:48.082: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018477174s
Jan 10 04:51:50.072: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008624383s
Jan 10 04:51:52.072: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.008518906s
Jan 10 04:51:54.072: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Running", Reason="", readiness=true. Elapsed: 12.008533146s
Jan 10 04:51:54.072: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7" satisfied condition "running"
Jan 10 04:51:54.073: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-62qpx" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:54.075: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-62qpx": Phase="Running", Reason="", readiness=true. Elapsed: 2.478657ms
Jan 10 04:51:54.075: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-62qpx" satisfied condition "running"
Jan 10 04:51:54.075: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-d6qbt" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:54.077: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-d6qbt": Phase="Running", Reason="", readiness=true. Elapsed: 2.24046ms
Jan 10 04:51:54.078: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-d6qbt" satisfied condition "running"
Jan 10 04:51:54.078: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-gqrjz" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:54.080: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-gqrjz": Phase="Running", Reason="", readiness=true. Elapsed: 2.129523ms
Jan 10 04:51:54.080: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-gqrjz" satisfied condition "running"
Jan 10 04:51:54.080: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-wbkmx" in namespace "emptydir-wrapper-8070" to be "running"
Jan 10 04:51:54.083: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-wbkmx": Phase="Running", Reason="", readiness=true. Elapsed: 2.270023ms
Jan 10 04:51:54.083: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-wbkmx" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417 in namespace emptydir-wrapper-8070, will wait for the garbage collector to delete the pods 01/10/23 04:51:54.083
Jan 10 04:51:54.145: INFO: Deleting ReplicationController wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417 took: 10.048486ms
Jan 10 04:51:54.254: INFO: Terminating ReplicationController wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417 pods took: 109.047435ms
STEP: Cleaning up the configMaps 01/10/23 04:51:57.455
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Jan 10 04:51:57.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8070" for this suite. 01/10/23 04:51:57.683
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":273,"skipped":4705,"failed":0}
------------------------------
• [SLOW TEST] [63.283 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:50:54.409
    Jan 10 04:50:54.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir-wrapper 01/10/23 04:50:54.41
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:50:54.431
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:50:54.448
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 01/10/23 04:50:54.458
    STEP: Creating RC which spawns configmap-volume pods 01/10/23 04:50:54.717
    Jan 10 04:50:54.774: INFO: Pod name wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77: Found 1 pods out of 5
    Jan 10 04:50:59.802: INFO: Pod name wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77: Found 5 pods out of 5
    STEP: Ensuring each pod is running 01/10/23 04:50:59.802
    Jan 10 04:50:59.803: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:50:59.811: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 7.979483ms
    Jan 10 04:51:01.815: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012810618s
    Jan 10 04:51:03.815: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012222639s
    Jan 10 04:51:05.815: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011961946s
    Jan 10 04:51:07.820: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017665734s
    Jan 10 04:51:09.825: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w": Phase="Running", Reason="", readiness=true. Elapsed: 10.022448049s
    Jan 10 04:51:09.825: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-4jb8w" satisfied condition "running"
    Jan 10 04:51:09.826: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-gt977" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:09.838: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-gt977": Phase="Pending", Reason="", readiness=false. Elapsed: 10.649499ms
    Jan 10 04:51:11.843: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-gt977": Phase="Running", Reason="", readiness=true. Elapsed: 2.016322924s
    Jan 10 04:51:11.843: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-gt977" satisfied condition "running"
    Jan 10 04:51:11.844: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-nzvz9" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:11.847: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-nzvz9": Phase="Running", Reason="", readiness=true. Elapsed: 2.965253ms
    Jan 10 04:51:11.847: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-nzvz9" satisfied condition "running"
    Jan 10 04:51:11.847: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-q9x46" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:11.849: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-q9x46": Phase="Running", Reason="", readiness=true. Elapsed: 2.6941ms
    Jan 10 04:51:11.849: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-q9x46" satisfied condition "running"
    Jan 10 04:51:11.849: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-szj8s" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:11.852: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-szj8s": Phase="Running", Reason="", readiness=true. Elapsed: 2.97804ms
    Jan 10 04:51:11.853: INFO: Pod "wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77-szj8s" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77 in namespace emptydir-wrapper-8070, will wait for the garbage collector to delete the pods 01/10/23 04:51:11.853
    Jan 10 04:51:11.930: INFO: Deleting ReplicationController wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77 took: 17.017237ms
    Jan 10 04:51:12.230: INFO: Terminating ReplicationController wrapped-volume-race-ad6b55c8-a54f-4f31-b8cc-689e44a6cc77 pods took: 300.538397ms
    STEP: Creating RC which spawns configmap-volume pods 01/10/23 04:51:15.334
    Jan 10 04:51:15.344: INFO: Pod name wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164: Found 0 pods out of 5
    Jan 10 04:51:20.351: INFO: Pod name wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164: Found 5 pods out of 5
    STEP: Ensuring each pod is running 01/10/23 04:51:20.351
    Jan 10 04:51:20.352: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:20.354: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.735721ms
    Jan 10 04:51:22.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006307521s
    Jan 10 04:51:24.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006869585s
    Jan 10 04:51:26.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006639194s
    Jan 10 04:51:28.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006519282s
    Jan 10 04:51:30.359: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007608551s
    Jan 10 04:51:32.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw": Phase="Running", Reason="", readiness=true. Elapsed: 12.006572997s
    Jan 10 04:51:32.358: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-4wwxw" satisfied condition "running"
    Jan 10 04:51:32.358: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-7bxq8" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:32.361: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-7bxq8": Phase="Running", Reason="", readiness=true. Elapsed: 2.731262ms
    Jan 10 04:51:32.361: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-7bxq8" satisfied condition "running"
    Jan 10 04:51:32.361: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-fmr59" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:32.366: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-fmr59": Phase="Running", Reason="", readiness=true. Elapsed: 4.773093ms
    Jan 10 04:51:32.366: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-fmr59" satisfied condition "running"
    Jan 10 04:51:32.366: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-hs6h8" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:32.369: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-hs6h8": Phase="Running", Reason="", readiness=true. Elapsed: 2.716598ms
    Jan 10 04:51:32.369: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-hs6h8" satisfied condition "running"
    Jan 10 04:51:32.369: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-xmzgr" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:32.372: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-xmzgr": Phase="Running", Reason="", readiness=true. Elapsed: 2.553486ms
    Jan 10 04:51:32.372: INFO: Pod "wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164-xmzgr" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164 in namespace emptydir-wrapper-8070, will wait for the garbage collector to delete the pods 01/10/23 04:51:32.372
    Jan 10 04:51:32.433: INFO: Deleting ReplicationController wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164 took: 5.348297ms
    Jan 10 04:51:32.633: INFO: Terminating ReplicationController wrapped-volume-race-201fee89-e70f-4b39-881e-7f1789c33164 pods took: 200.512995ms
    STEP: Creating RC which spawns configmap-volume pods 01/10/23 04:51:37.038
    Jan 10 04:51:37.053: INFO: Pod name wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417: Found 0 pods out of 5
    Jan 10 04:51:42.064: INFO: Pod name wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417: Found 5 pods out of 5
    STEP: Ensuring each pod is running 01/10/23 04:51:42.064
    Jan 10 04:51:42.064: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:42.068: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.358759ms
    Jan 10 04:51:44.073: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008953093s
    Jan 10 04:51:46.071: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00761355s
    Jan 10 04:51:48.082: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018477174s
    Jan 10 04:51:50.072: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008624383s
    Jan 10 04:51:52.072: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.008518906s
    Jan 10 04:51:54.072: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7": Phase="Running", Reason="", readiness=true. Elapsed: 12.008533146s
    Jan 10 04:51:54.072: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-2qnz7" satisfied condition "running"
    Jan 10 04:51:54.073: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-62qpx" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:54.075: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-62qpx": Phase="Running", Reason="", readiness=true. Elapsed: 2.478657ms
    Jan 10 04:51:54.075: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-62qpx" satisfied condition "running"
    Jan 10 04:51:54.075: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-d6qbt" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:54.077: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-d6qbt": Phase="Running", Reason="", readiness=true. Elapsed: 2.24046ms
    Jan 10 04:51:54.078: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-d6qbt" satisfied condition "running"
    Jan 10 04:51:54.078: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-gqrjz" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:54.080: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-gqrjz": Phase="Running", Reason="", readiness=true. Elapsed: 2.129523ms
    Jan 10 04:51:54.080: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-gqrjz" satisfied condition "running"
    Jan 10 04:51:54.080: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-wbkmx" in namespace "emptydir-wrapper-8070" to be "running"
    Jan 10 04:51:54.083: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-wbkmx": Phase="Running", Reason="", readiness=true. Elapsed: 2.270023ms
    Jan 10 04:51:54.083: INFO: Pod "wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417-wbkmx" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417 in namespace emptydir-wrapper-8070, will wait for the garbage collector to delete the pods 01/10/23 04:51:54.083
    Jan 10 04:51:54.145: INFO: Deleting ReplicationController wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417 took: 10.048486ms
    Jan 10 04:51:54.254: INFO: Terminating ReplicationController wrapped-volume-race-07e26c37-dd82-486a-91e6-1ce5b0b50417 pods took: 109.047435ms
    STEP: Cleaning up the configMaps 01/10/23 04:51:57.455
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:51:57.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-8070" for this suite. 01/10/23 04:51:57.683
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:51:57.693
Jan 10 04:51:57.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-runtime 01/10/23 04:51:57.695
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:51:57.714
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:51:57.723
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 01/10/23 04:51:57.746
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 01/10/23 04:52:16.859
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 01/10/23 04:52:16.861
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 01/10/23 04:52:16.87
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 01/10/23 04:52:16.87
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 01/10/23 04:52:16.922
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 01/10/23 04:52:19.971
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 01/10/23 04:52:21.981
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 01/10/23 04:52:21.986
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 01/10/23 04:52:21.986
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 01/10/23 04:52:22.009
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 01/10/23 04:52:23.026
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 01/10/23 04:52:26.043
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 01/10/23 04:52:26.048
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 01/10/23 04:52:26.048
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 10 04:52:26.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3719" for this suite. 01/10/23 04:52:26.077
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":274,"skipped":4734,"failed":0}
------------------------------
• [SLOW TEST] [28.389 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:51:57.693
    Jan 10 04:51:57.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-runtime 01/10/23 04:51:57.695
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:51:57.714
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:51:57.723
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 01/10/23 04:51:57.746
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 01/10/23 04:52:16.859
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 01/10/23 04:52:16.861
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 01/10/23 04:52:16.87
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 01/10/23 04:52:16.87
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 01/10/23 04:52:16.922
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 01/10/23 04:52:19.971
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 01/10/23 04:52:21.981
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 01/10/23 04:52:21.986
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 01/10/23 04:52:21.986
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 01/10/23 04:52:22.009
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 01/10/23 04:52:23.026
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 01/10/23 04:52:26.043
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 01/10/23 04:52:26.048
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 01/10/23 04:52:26.048
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 10 04:52:26.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3719" for this suite. 01/10/23 04:52:26.077
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:26.101
Jan 10 04:52:26.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:52:26.103
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:26.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:26.136
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-2748e0ef-82a2-4bcb-a900-4903775f75d0 01/10/23 04:52:26.141
STEP: Creating a pod to test consume configMaps 01/10/23 04:52:26.15
Jan 10 04:52:26.172: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4" in namespace "projected-6797" to be "Succeeded or Failed"
Jan 10 04:52:26.193: INFO: Pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.809805ms
Jan 10 04:52:28.198: INFO: Pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02498564s
Jan 10 04:52:30.197: INFO: Pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023988307s
STEP: Saw pod success 01/10/23 04:52:30.197
Jan 10 04:52:30.197: INFO: Pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4" satisfied condition "Succeeded or Failed"
Jan 10 04:52:30.200: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4 container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:52:30.212
Jan 10 04:52:30.221: INFO: Waiting for pod pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4 to disappear
Jan 10 04:52:30.229: INFO: Pod pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 04:52:30.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6797" for this suite. 01/10/23 04:52:30.232
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":275,"skipped":4860,"failed":0}
------------------------------
• [4.137 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:26.101
    Jan 10 04:52:26.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:52:26.103
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:26.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:26.136
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-2748e0ef-82a2-4bcb-a900-4903775f75d0 01/10/23 04:52:26.141
    STEP: Creating a pod to test consume configMaps 01/10/23 04:52:26.15
    Jan 10 04:52:26.172: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4" in namespace "projected-6797" to be "Succeeded or Failed"
    Jan 10 04:52:26.193: INFO: Pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.809805ms
    Jan 10 04:52:28.198: INFO: Pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02498564s
    Jan 10 04:52:30.197: INFO: Pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023988307s
    STEP: Saw pod success 01/10/23 04:52:30.197
    Jan 10 04:52:30.197: INFO: Pod "pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4" satisfied condition "Succeeded or Failed"
    Jan 10 04:52:30.200: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4 container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:52:30.212
    Jan 10 04:52:30.221: INFO: Waiting for pod pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4 to disappear
    Jan 10 04:52:30.229: INFO: Pod pod-projected-configmaps-9b85cb68-f292-43ae-a914-eca9381903d4 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 04:52:30.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6797" for this suite. 01/10/23 04:52:30.232
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:30.241
Jan 10 04:52:30.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:52:30.242
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:30.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:30.269
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 01/10/23 04:52:30.272
Jan 10 04:52:30.283: INFO: Waiting up to 5m0s for pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6" in namespace "downward-api-8281" to be "running and ready"
Jan 10 04:52:30.294: INFO: Pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.29562ms
Jan 10 04:52:30.294: INFO: The phase of Pod labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:52:32.298: INFO: Pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014816092s
Jan 10 04:52:32.298: INFO: The phase of Pod labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6 is Running (Ready = true)
Jan 10 04:52:32.298: INFO: Pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6" satisfied condition "running and ready"
Jan 10 04:52:32.815: INFO: Successfully updated pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 04:52:34.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8281" for this suite. 01/10/23 04:52:34.843
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":276,"skipped":4902,"failed":0}
------------------------------
• [4.608 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:30.241
    Jan 10 04:52:30.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:52:30.242
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:30.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:30.269
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 01/10/23 04:52:30.272
    Jan 10 04:52:30.283: INFO: Waiting up to 5m0s for pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6" in namespace "downward-api-8281" to be "running and ready"
    Jan 10 04:52:30.294: INFO: Pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.29562ms
    Jan 10 04:52:30.294: INFO: The phase of Pod labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:52:32.298: INFO: Pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014816092s
    Jan 10 04:52:32.298: INFO: The phase of Pod labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6 is Running (Ready = true)
    Jan 10 04:52:32.298: INFO: Pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6" satisfied condition "running and ready"
    Jan 10 04:52:32.815: INFO: Successfully updated pod "labelsupdate840cabe9-86e2-4a33-8237-63afaf5f2fc6"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 04:52:34.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8281" for this suite. 01/10/23 04:52:34.843
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:34.849
Jan 10 04:52:34.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename gc 01/10/23 04:52:34.85
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:34.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:34.954
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Jan 10 04:52:35.031: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"33a75b66-2f1a-424d-84d4-36cf7d864a08", Controller:(*bool)(0xc00367929a), BlockOwnerDeletion:(*bool)(0xc00367929b)}}
Jan 10 04:52:35.052: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a40c3ec4-b451-4cfd-8736-aeb0d5fc334e", Controller:(*bool)(0xc00367953a), BlockOwnerDeletion:(*bool)(0xc00367953b)}}
Jan 10 04:52:35.091: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"52ce6c0e-0c09-4cad-b783-9047cafa1c84", Controller:(*bool)(0xc003679782), BlockOwnerDeletion:(*bool)(0xc003679783)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 10 04:52:40.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4696" for this suite. 01/10/23 04:52:40.123
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":277,"skipped":4909,"failed":0}
------------------------------
• [SLOW TEST] [5.280 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:34.849
    Jan 10 04:52:34.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename gc 01/10/23 04:52:34.85
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:34.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:34.954
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Jan 10 04:52:35.031: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"33a75b66-2f1a-424d-84d4-36cf7d864a08", Controller:(*bool)(0xc00367929a), BlockOwnerDeletion:(*bool)(0xc00367929b)}}
    Jan 10 04:52:35.052: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a40c3ec4-b451-4cfd-8736-aeb0d5fc334e", Controller:(*bool)(0xc00367953a), BlockOwnerDeletion:(*bool)(0xc00367953b)}}
    Jan 10 04:52:35.091: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"52ce6c0e-0c09-4cad-b783-9047cafa1c84", Controller:(*bool)(0xc003679782), BlockOwnerDeletion:(*bool)(0xc003679783)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 10 04:52:40.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4696" for this suite. 01/10/23 04:52:40.123
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:40.145
Jan 10 04:52:40.145: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubelet-test 01/10/23 04:52:40.146
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:40.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:40.197
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 10 04:52:44.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8465" for this suite. 01/10/23 04:52:44.309
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":278,"skipped":4930,"failed":0}
------------------------------
• [4.178 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:40.145
    Jan 10 04:52:40.145: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubelet-test 01/10/23 04:52:40.146
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:40.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:40.197
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 10 04:52:44.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8465" for this suite. 01/10/23 04:52:44.309
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:44.345
Jan 10 04:52:44.345: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:52:44.353
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:44.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:44.439
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 01/10/23 04:52:44.443
Jan 10 04:52:44.453: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5" in namespace "projected-4337" to be "Succeeded or Failed"
Jan 10 04:52:44.463: INFO: Pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.259073ms
Jan 10 04:52:46.469: INFO: Pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015135719s
Jan 10 04:52:48.466: INFO: Pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013010397s
STEP: Saw pod success 01/10/23 04:52:48.466
Jan 10 04:52:48.467: INFO: Pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5" satisfied condition "Succeeded or Failed"
Jan 10 04:52:48.468: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5 container client-container: <nil>
STEP: delete the pod 01/10/23 04:52:48.477
Jan 10 04:52:48.488: INFO: Waiting for pod downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5 to disappear
Jan 10 04:52:48.492: INFO: Pod downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 04:52:48.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4337" for this suite. 01/10/23 04:52:48.495
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":279,"skipped":4948,"failed":0}
------------------------------
• [4.157 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:44.345
    Jan 10 04:52:44.345: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:52:44.353
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:44.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:44.439
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 01/10/23 04:52:44.443
    Jan 10 04:52:44.453: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5" in namespace "projected-4337" to be "Succeeded or Failed"
    Jan 10 04:52:44.463: INFO: Pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.259073ms
    Jan 10 04:52:46.469: INFO: Pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015135719s
    Jan 10 04:52:48.466: INFO: Pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013010397s
    STEP: Saw pod success 01/10/23 04:52:48.466
    Jan 10 04:52:48.467: INFO: Pod "downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5" satisfied condition "Succeeded or Failed"
    Jan 10 04:52:48.468: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5 container client-container: <nil>
    STEP: delete the pod 01/10/23 04:52:48.477
    Jan 10 04:52:48.488: INFO: Waiting for pod downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5 to disappear
    Jan 10 04:52:48.492: INFO: Pod downwardapi-volume-06e0c21b-2365-4cdf-9ea4-d3d192be0bd5 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 04:52:48.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4337" for this suite. 01/10/23 04:52:48.495
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:48.506
Jan 10 04:52:48.507: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 04:52:48.521
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:48.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:48.551
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 01/10/23 04:52:48.556
Jan 10 04:52:48.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3661 api-versions'
Jan 10 04:52:48.643: INFO: stderr: ""
Jan 10 04:52:48.643: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncatalog.cattle.io/v1\ncertificates.k8s.io/v1\ncluster.cattle.io/v3\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmanagement.cattle.io/v3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nui.cattle.io/v1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 04:52:48.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3661" for this suite. 01/10/23 04:52:48.651
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":280,"skipped":5003,"failed":0}
------------------------------
• [0.149 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:48.506
    Jan 10 04:52:48.507: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 04:52:48.521
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:48.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:48.551
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 01/10/23 04:52:48.556
    Jan 10 04:52:48.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-3661 api-versions'
    Jan 10 04:52:48.643: INFO: stderr: ""
    Jan 10 04:52:48.643: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncatalog.cattle.io/v1\ncertificates.k8s.io/v1\ncluster.cattle.io/v3\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmanagement.cattle.io/v3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nui.cattle.io/v1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 04:52:48.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3661" for this suite. 01/10/23 04:52:48.651
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:48.656
Jan 10 04:52:48.656: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replicaset 01/10/23 04:52:48.657
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:48.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:48.749
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 01/10/23 04:52:48.758
STEP: Verify that the required pods have come up 01/10/23 04:52:48.768
Jan 10 04:52:48.773: INFO: Pod name sample-pod: Found 0 pods out of 3
Jan 10 04:52:53.780: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 01/10/23 04:52:53.78
Jan 10 04:52:53.782: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 01/10/23 04:52:53.782
STEP: DeleteCollection of the ReplicaSets 01/10/23 04:52:53.789
STEP: After DeleteCollection verify that ReplicaSets have been deleted 01/10/23 04:52:53.798
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 10 04:52:53.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8499" for this suite. 01/10/23 04:52:53.817
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":281,"skipped":5009,"failed":0}
------------------------------
• [SLOW TEST] [5.183 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:48.656
    Jan 10 04:52:48.656: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replicaset 01/10/23 04:52:48.657
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:48.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:48.749
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 01/10/23 04:52:48.758
    STEP: Verify that the required pods have come up 01/10/23 04:52:48.768
    Jan 10 04:52:48.773: INFO: Pod name sample-pod: Found 0 pods out of 3
    Jan 10 04:52:53.780: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 01/10/23 04:52:53.78
    Jan 10 04:52:53.782: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 01/10/23 04:52:53.782
    STEP: DeleteCollection of the ReplicaSets 01/10/23 04:52:53.789
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 01/10/23 04:52:53.798
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 10 04:52:53.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8499" for this suite. 01/10/23 04:52:53.817
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:53.84
Jan 10 04:52:53.840: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 04:52:53.84
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:53.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:53.976
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 01/10/23 04:52:54.017
STEP: submitting the pod to kubernetes 01/10/23 04:52:54.017
STEP: verifying QOS class is set on the pod 01/10/23 04:52:54.041
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Jan 10 04:52:54.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8407" for this suite. 01/10/23 04:52:54.069
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":282,"skipped":5015,"failed":0}
------------------------------
• [0.254 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:53.84
    Jan 10 04:52:53.840: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 04:52:53.84
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:53.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:53.976
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 01/10/23 04:52:54.017
    STEP: submitting the pod to kubernetes 01/10/23 04:52:54.017
    STEP: verifying QOS class is set on the pod 01/10/23 04:52:54.041
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Jan 10 04:52:54.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8407" for this suite. 01/10/23 04:52:54.069
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:54.097
Jan 10 04:52:54.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:52:54.098
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:54.156
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:54.175
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-963523cb-fbdf-4536-a45b-48c5149859b2 01/10/23 04:52:54.191
STEP: Creating a pod to test consume configMaps 01/10/23 04:52:54.219
Jan 10 04:52:54.251: INFO: Waiting up to 5m0s for pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a" in namespace "configmap-351" to be "Succeeded or Failed"
Jan 10 04:52:54.288: INFO: Pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a": Phase="Pending", Reason="", readiness=false. Elapsed: 36.560212ms
Jan 10 04:52:56.291: INFO: Pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039816694s
Jan 10 04:52:58.292: INFO: Pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04105978s
STEP: Saw pod success 01/10/23 04:52:58.292
Jan 10 04:52:58.292: INFO: Pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a" satisfied condition "Succeeded or Failed"
Jan 10 04:52:58.296: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:52:58.302
Jan 10 04:52:58.312: INFO: Waiting for pod pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a to disappear
Jan 10 04:52:58.315: INFO: Pod pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:52:58.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-351" for this suite. 01/10/23 04:52:58.318
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":283,"skipped":5023,"failed":0}
------------------------------
• [4.226 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:54.097
    Jan 10 04:52:54.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:52:54.098
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:54.156
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:54.175
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-963523cb-fbdf-4536-a45b-48c5149859b2 01/10/23 04:52:54.191
    STEP: Creating a pod to test consume configMaps 01/10/23 04:52:54.219
    Jan 10 04:52:54.251: INFO: Waiting up to 5m0s for pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a" in namespace "configmap-351" to be "Succeeded or Failed"
    Jan 10 04:52:54.288: INFO: Pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a": Phase="Pending", Reason="", readiness=false. Elapsed: 36.560212ms
    Jan 10 04:52:56.291: INFO: Pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039816694s
    Jan 10 04:52:58.292: INFO: Pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04105978s
    STEP: Saw pod success 01/10/23 04:52:58.292
    Jan 10 04:52:58.292: INFO: Pod "pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a" satisfied condition "Succeeded or Failed"
    Jan 10 04:52:58.296: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:52:58.302
    Jan 10 04:52:58.312: INFO: Waiting for pod pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a to disappear
    Jan 10 04:52:58.315: INFO: Pod pod-configmaps-51465ddf-9156-4567-b38d-9d9c415d527a no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:52:58.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-351" for this suite. 01/10/23 04:52:58.318
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:52:58.324
Jan 10 04:52:58.324: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename deployment 01/10/23 04:52:58.325
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:58.364
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:58.38
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Jan 10 04:52:58.399: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 10 04:52:58.435: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 10 04:53:03.442: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/10/23 04:53:03.442
Jan 10 04:53:03.442: INFO: Creating deployment "test-rolling-update-deployment"
Jan 10 04:53:03.459: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 10 04:53:03.488: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 10 04:53:05.511: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 10 04:53:05.516: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 10 04:53:05.538: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-80  6dbefcb6-194a-4313-a0ef-f0e44e883225 245398 1 2023-01-10 04:53:03 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-01-10 04:53:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00388c068 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-10 04:53:03 +0000 UTC,LastTransitionTime:2023-01-10 04:53:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-01-10 04:53:05 +0000 UTC,LastTransitionTime:2023-01-10 04:53:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jan 10 04:53:05.544: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-80  4a45c0d0-95fc-433f-bcea-14b683b4ba2b 245388 1 2023-01-10 04:53:03 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 6dbefcb6-194a-4313-a0ef-f0e44e883225 0xc0038c6cc7 0xc0038c6cc8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:53:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6dbefcb6-194a-4313-a0ef-f0e44e883225\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038c6d78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:53:05.544: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 10 04:53:05.544: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-80  afcbd4d0-1231-4806-9d14-2865684bcdd2 245397 2 2023-01-10 04:52:58 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 6dbefcb6-194a-4313-a0ef-f0e44e883225 0xc0038c6b97 0xc0038c6b98}] [] [{e2e.test Update apps/v1 2023-01-10 04:52:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6dbefcb6-194a-4313-a0ef-f0e44e883225\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0038c6c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 10 04:53:05.550: INFO: Pod "test-rolling-update-deployment-78f575d8ff-r8cjn" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-r8cjn test-rolling-update-deployment-78f575d8ff- deployment-80  cbf5a530-106e-4a38-a7f1-193014161098 245387 0 2023-01-10 04:53:03 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:6232621cceb67b8a54e7b8102d244f6a4118d2df47d99fd8b94095d5d78008c7 cni.projectcalico.org/podIP:10.42.2.180/32 cni.projectcalico.org/podIPs:10.42.2.180/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 4a45c0d0-95fc-433f-bcea-14b683b4ba2b 0xc00388c437 0xc00388c438}] [] [{kube-controller-manager Update v1 2023-01-10 04:53:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a45c0d0-95fc-433f-bcea-14b683b4ba2b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:53:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.180\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-56wwp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-56wwp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:53:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:53:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:53:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:53:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.180,StartTime:2023-01-10 04:53:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:53:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:docker://911a217d9a225a437c87e83d58573d1148ddb8291d51c201b26369cb29fd6da1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.180,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 10 04:53:05.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-80" for this suite. 01/10/23 04:53:05.556
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":284,"skipped":5032,"failed":0}
------------------------------
• [SLOW TEST] [7.247 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:52:58.324
    Jan 10 04:52:58.324: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename deployment 01/10/23 04:52:58.325
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:52:58.364
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:52:58.38
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Jan 10 04:52:58.399: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Jan 10 04:52:58.435: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jan 10 04:53:03.442: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/10/23 04:53:03.442
    Jan 10 04:53:03.442: INFO: Creating deployment "test-rolling-update-deployment"
    Jan 10 04:53:03.459: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Jan 10 04:53:03.488: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Jan 10 04:53:05.511: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Jan 10 04:53:05.516: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 10 04:53:05.538: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-80  6dbefcb6-194a-4313-a0ef-f0e44e883225 245398 1 2023-01-10 04:53:03 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-01-10 04:53:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00388c068 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-10 04:53:03 +0000 UTC,LastTransitionTime:2023-01-10 04:53:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-01-10 04:53:05 +0000 UTC,LastTransitionTime:2023-01-10 04:53:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jan 10 04:53:05.544: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-80  4a45c0d0-95fc-433f-bcea-14b683b4ba2b 245388 1 2023-01-10 04:53:03 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 6dbefcb6-194a-4313-a0ef-f0e44e883225 0xc0038c6cc7 0xc0038c6cc8}] [] [{kube-controller-manager Update apps/v1 2023-01-10 04:53:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6dbefcb6-194a-4313-a0ef-f0e44e883225\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038c6d78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:53:05.544: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Jan 10 04:53:05.544: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-80  afcbd4d0-1231-4806-9d14-2865684bcdd2 245397 2 2023-01-10 04:52:58 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 6dbefcb6-194a-4313-a0ef-f0e44e883225 0xc0038c6b97 0xc0038c6b98}] [] [{e2e.test Update apps/v1 2023-01-10 04:52:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6dbefcb6-194a-4313-a0ef-f0e44e883225\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0038c6c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 10 04:53:05.550: INFO: Pod "test-rolling-update-deployment-78f575d8ff-r8cjn" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-r8cjn test-rolling-update-deployment-78f575d8ff- deployment-80  cbf5a530-106e-4a38-a7f1-193014161098 245387 0 2023-01-10 04:53:03 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:6232621cceb67b8a54e7b8102d244f6a4118d2df47d99fd8b94095d5d78008c7 cni.projectcalico.org/podIP:10.42.2.180/32 cni.projectcalico.org/podIPs:10.42.2.180/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 4a45c0d0-95fc-433f-bcea-14b683b4ba2b 0xc00388c437 0xc00388c438}] [] [{kube-controller-manager Update v1 2023-01-10 04:53:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a45c0d0-95fc-433f-bcea-14b683b4ba2b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-10 04:53:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-10 04:53:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.180\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-56wwp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-56wwp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cncf-wk3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:53:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:53:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:53:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-10 04:53:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.7.114,PodIP:10.42.2.180,StartTime:2023-01-10 04:53:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-10 04:53:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:docker://911a217d9a225a437c87e83d58573d1148ddb8291d51c201b26369cb29fd6da1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.180,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 10 04:53:05.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-80" for this suite. 01/10/23 04:53:05.556
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:05.573
Jan 10 04:53:05.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:53:05.574
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:05.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:05.681
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 01/10/23 04:53:05.686
Jan 10 04:53:05.714: INFO: Waiting up to 5m0s for pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676" in namespace "emptydir-3840" to be "Succeeded or Failed"
Jan 10 04:53:05.770: INFO: Pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676": Phase="Pending", Reason="", readiness=false. Elapsed: 56.732223ms
Jan 10 04:53:07.776: INFO: Pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062352469s
Jan 10 04:53:09.777: INFO: Pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063602497s
STEP: Saw pod success 01/10/23 04:53:09.777
Jan 10 04:53:09.778: INFO: Pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676" satisfied condition "Succeeded or Failed"
Jan 10 04:53:09.786: INFO: Trying to get logs from node cncf-wk2 pod pod-01634e1e-0c14-420e-992a-eec4a9fdd676 container test-container: <nil>
STEP: delete the pod 01/10/23 04:53:09.808
Jan 10 04:53:09.859: INFO: Waiting for pod pod-01634e1e-0c14-420e-992a-eec4a9fdd676 to disappear
Jan 10 04:53:09.866: INFO: Pod pod-01634e1e-0c14-420e-992a-eec4a9fdd676 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:53:09.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3840" for this suite. 01/10/23 04:53:09.89
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":285,"skipped":5052,"failed":0}
------------------------------
• [4.355 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:05.573
    Jan 10 04:53:05.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:53:05.574
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:05.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:05.681
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 01/10/23 04:53:05.686
    Jan 10 04:53:05.714: INFO: Waiting up to 5m0s for pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676" in namespace "emptydir-3840" to be "Succeeded or Failed"
    Jan 10 04:53:05.770: INFO: Pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676": Phase="Pending", Reason="", readiness=false. Elapsed: 56.732223ms
    Jan 10 04:53:07.776: INFO: Pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062352469s
    Jan 10 04:53:09.777: INFO: Pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063602497s
    STEP: Saw pod success 01/10/23 04:53:09.777
    Jan 10 04:53:09.778: INFO: Pod "pod-01634e1e-0c14-420e-992a-eec4a9fdd676" satisfied condition "Succeeded or Failed"
    Jan 10 04:53:09.786: INFO: Trying to get logs from node cncf-wk2 pod pod-01634e1e-0c14-420e-992a-eec4a9fdd676 container test-container: <nil>
    STEP: delete the pod 01/10/23 04:53:09.808
    Jan 10 04:53:09.859: INFO: Waiting for pod pod-01634e1e-0c14-420e-992a-eec4a9fdd676 to disappear
    Jan 10 04:53:09.866: INFO: Pod pod-01634e1e-0c14-420e-992a-eec4a9fdd676 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:53:09.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3840" for this suite. 01/10/23 04:53:09.89
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:09.928
Jan 10 04:53:09.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:53:09.929
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:10.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:10.111
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 01/10/23 04:53:10.147
Jan 10 04:53:10.214: INFO: Waiting up to 5m0s for pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee" in namespace "downward-api-3027" to be "Succeeded or Failed"
Jan 10 04:53:10.248: INFO: Pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee": Phase="Pending", Reason="", readiness=false. Elapsed: 33.619489ms
Jan 10 04:53:12.253: INFO: Pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038512723s
Jan 10 04:53:14.252: INFO: Pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038237606s
STEP: Saw pod success 01/10/23 04:53:14.252
Jan 10 04:53:14.253: INFO: Pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee" satisfied condition "Succeeded or Failed"
Jan 10 04:53:14.255: INFO: Trying to get logs from node cncf-wk2 pod downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee container dapi-container: <nil>
STEP: delete the pod 01/10/23 04:53:14.262
Jan 10 04:53:14.275: INFO: Waiting for pod downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee to disappear
Jan 10 04:53:14.286: INFO: Pod downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 10 04:53:14.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3027" for this suite. 01/10/23 04:53:14.29
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":286,"skipped":5057,"failed":0}
------------------------------
• [4.379 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:09.928
    Jan 10 04:53:09.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:53:09.929
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:10.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:10.111
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 01/10/23 04:53:10.147
    Jan 10 04:53:10.214: INFO: Waiting up to 5m0s for pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee" in namespace "downward-api-3027" to be "Succeeded or Failed"
    Jan 10 04:53:10.248: INFO: Pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee": Phase="Pending", Reason="", readiness=false. Elapsed: 33.619489ms
    Jan 10 04:53:12.253: INFO: Pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038512723s
    Jan 10 04:53:14.252: INFO: Pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038237606s
    STEP: Saw pod success 01/10/23 04:53:14.252
    Jan 10 04:53:14.253: INFO: Pod "downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee" satisfied condition "Succeeded or Failed"
    Jan 10 04:53:14.255: INFO: Trying to get logs from node cncf-wk2 pod downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee container dapi-container: <nil>
    STEP: delete the pod 01/10/23 04:53:14.262
    Jan 10 04:53:14.275: INFO: Waiting for pod downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee to disappear
    Jan 10 04:53:14.286: INFO: Pod downward-api-b8e0ac50-f68d-4b08-aeaa-2f3ba40c93ee no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 10 04:53:14.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3027" for this suite. 01/10/23 04:53:14.29
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:14.308
Jan 10 04:53:14.308: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 04:53:14.309
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:14.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:14.382
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 04:53:14.464
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:53:15.302
STEP: Deploying the webhook pod 01/10/23 04:53:15.309
STEP: Wait for the deployment to be ready 01/10/23 04:53:15.321
Jan 10 04:53:15.334: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 10 04:53:17.349: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 53, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 53, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 53, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 53, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/10/23 04:53:19.353
STEP: Verifying the service has paired with the endpoint 01/10/23 04:53:19.36
Jan 10 04:53:20.361: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 01/10/23 04:53:20.364
STEP: create a namespace for the webhook 01/10/23 04:53:20.378
STEP: create a configmap should be unconditionally rejected by the webhook 01/10/23 04:53:20.388
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 04:53:20.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8985" for this suite. 01/10/23 04:53:20.427
STEP: Destroying namespace "webhook-8985-markers" for this suite. 01/10/23 04:53:20.439
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":287,"skipped":5068,"failed":0}
------------------------------
• [SLOW TEST] [6.322 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:14.308
    Jan 10 04:53:14.308: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 04:53:14.309
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:14.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:14.382
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 04:53:14.464
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 04:53:15.302
    STEP: Deploying the webhook pod 01/10/23 04:53:15.309
    STEP: Wait for the deployment to be ready 01/10/23 04:53:15.321
    Jan 10 04:53:15.334: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 10 04:53:17.349: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 4, 53, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 53, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 4, 53, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 4, 53, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/10/23 04:53:19.353
    STEP: Verifying the service has paired with the endpoint 01/10/23 04:53:19.36
    Jan 10 04:53:20.361: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 01/10/23 04:53:20.364
    STEP: create a namespace for the webhook 01/10/23 04:53:20.378
    STEP: create a configmap should be unconditionally rejected by the webhook 01/10/23 04:53:20.388
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 04:53:20.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8985" for this suite. 01/10/23 04:53:20.427
    STEP: Destroying namespace "webhook-8985-markers" for this suite. 01/10/23 04:53:20.439
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:20.645
Jan 10 04:53:20.645: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename security-context-test 01/10/23 04:53:20.648
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:20.736
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:20.775
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Jan 10 04:53:20.836: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871" in namespace "security-context-test-4462" to be "Succeeded or Failed"
Jan 10 04:53:20.876: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871": Phase="Pending", Reason="", readiness=false. Elapsed: 40.322502ms
Jan 10 04:53:22.880: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043843647s
Jan 10 04:53:24.880: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044243963s
Jan 10 04:53:26.879: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043315193s
Jan 10 04:53:26.880: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 10 04:53:26.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4462" for this suite. 01/10/23 04:53:26.889
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":288,"skipped":5084,"failed":0}
------------------------------
• [SLOW TEST] [6.251 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:20.645
    Jan 10 04:53:20.645: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename security-context-test 01/10/23 04:53:20.648
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:20.736
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:20.775
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Jan 10 04:53:20.836: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871" in namespace "security-context-test-4462" to be "Succeeded or Failed"
    Jan 10 04:53:20.876: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871": Phase="Pending", Reason="", readiness=false. Elapsed: 40.322502ms
    Jan 10 04:53:22.880: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043843647s
    Jan 10 04:53:24.880: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044243963s
    Jan 10 04:53:26.879: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043315193s
    Jan 10 04:53:26.880: INFO: Pod "alpine-nnp-false-d5773b98-750b-48fb-82f5-864e2b1fb871" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 10 04:53:26.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4462" for this suite. 01/10/23 04:53:26.889
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:26.9
Jan 10 04:53:26.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:53:26.903
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:26.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:26.933
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-a3ee0c4e-77ec-46c5-b6cc-2607b1b5da89 01/10/23 04:53:26.939
STEP: Creating a pod to test consume secrets 01/10/23 04:53:26.955
Jan 10 04:53:26.972: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26" in namespace "projected-9387" to be "Succeeded or Failed"
Jan 10 04:53:27.026: INFO: Pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26": Phase="Pending", Reason="", readiness=false. Elapsed: 53.954286ms
Jan 10 04:53:29.029: INFO: Pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057679091s
Jan 10 04:53:31.029: INFO: Pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057342257s
STEP: Saw pod success 01/10/23 04:53:31.029
Jan 10 04:53:31.029: INFO: Pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26" satisfied condition "Succeeded or Failed"
Jan 10 04:53:31.032: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26 container secret-volume-test: <nil>
STEP: delete the pod 01/10/23 04:53:31.042
Jan 10 04:53:31.056: INFO: Waiting for pod pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26 to disappear
Jan 10 04:53:31.061: INFO: Pod pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 10 04:53:31.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9387" for this suite. 01/10/23 04:53:31.064
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":289,"skipped":5092,"failed":0}
------------------------------
• [4.168 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:26.9
    Jan 10 04:53:26.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:53:26.903
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:26.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:26.933
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-a3ee0c4e-77ec-46c5-b6cc-2607b1b5da89 01/10/23 04:53:26.939
    STEP: Creating a pod to test consume secrets 01/10/23 04:53:26.955
    Jan 10 04:53:26.972: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26" in namespace "projected-9387" to be "Succeeded or Failed"
    Jan 10 04:53:27.026: INFO: Pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26": Phase="Pending", Reason="", readiness=false. Elapsed: 53.954286ms
    Jan 10 04:53:29.029: INFO: Pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057679091s
    Jan 10 04:53:31.029: INFO: Pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057342257s
    STEP: Saw pod success 01/10/23 04:53:31.029
    Jan 10 04:53:31.029: INFO: Pod "pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26" satisfied condition "Succeeded or Failed"
    Jan 10 04:53:31.032: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26 container secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 04:53:31.042
    Jan 10 04:53:31.056: INFO: Waiting for pod pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26 to disappear
    Jan 10 04:53:31.061: INFO: Pod pod-projected-secrets-8b45ed6a-2f12-40d2-9c7b-45faf17ddb26 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 10 04:53:31.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9387" for this suite. 01/10/23 04:53:31.064
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:31.071
Jan 10 04:53:31.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 04:53:31.072
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:31.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:31.108
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 01/10/23 04:53:31.15
Jan 10 04:53:31.168: INFO: Waiting up to 5m0s for pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f" in namespace "emptydir-7650" to be "Succeeded or Failed"
Jan 10 04:53:31.182: INFO: Pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.477126ms
Jan 10 04:53:33.186: INFO: Pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017965362s
Jan 10 04:53:35.187: INFO: Pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018305314s
STEP: Saw pod success 01/10/23 04:53:35.187
Jan 10 04:53:35.187: INFO: Pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f" satisfied condition "Succeeded or Failed"
Jan 10 04:53:35.194: INFO: Trying to get logs from node cncf-wk2 pod pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f container test-container: <nil>
STEP: delete the pod 01/10/23 04:53:35.205
Jan 10 04:53:35.219: INFO: Waiting for pod pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f to disappear
Jan 10 04:53:35.234: INFO: Pod pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 04:53:35.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7650" for this suite. 01/10/23 04:53:35.239
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":290,"skipped":5102,"failed":0}
------------------------------
• [4.176 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:31.071
    Jan 10 04:53:31.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 04:53:31.072
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:31.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:31.108
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 01/10/23 04:53:31.15
    Jan 10 04:53:31.168: INFO: Waiting up to 5m0s for pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f" in namespace "emptydir-7650" to be "Succeeded or Failed"
    Jan 10 04:53:31.182: INFO: Pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.477126ms
    Jan 10 04:53:33.186: INFO: Pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017965362s
    Jan 10 04:53:35.187: INFO: Pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018305314s
    STEP: Saw pod success 01/10/23 04:53:35.187
    Jan 10 04:53:35.187: INFO: Pod "pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f" satisfied condition "Succeeded or Failed"
    Jan 10 04:53:35.194: INFO: Trying to get logs from node cncf-wk2 pod pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f container test-container: <nil>
    STEP: delete the pod 01/10/23 04:53:35.205
    Jan 10 04:53:35.219: INFO: Waiting for pod pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f to disappear
    Jan 10 04:53:35.234: INFO: Pod pod-fdbfb2c9-4ad5-49e7-ab88-ffe3d5bd620f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 04:53:35.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7650" for this suite. 01/10/23 04:53:35.239
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:35.253
Jan 10 04:53:35.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:53:35.255
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:35.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:35.333
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-a1932b4f-4f0d-4094-b0ac-c0be7857708e 01/10/23 04:53:35.355
STEP: Creating a pod to test consume secrets 01/10/23 04:53:35.379
Jan 10 04:53:35.414: INFO: Waiting up to 5m0s for pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32" in namespace "secrets-5834" to be "Succeeded or Failed"
Jan 10 04:53:35.474: INFO: Pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32": Phase="Pending", Reason="", readiness=false. Elapsed: 59.894221ms
Jan 10 04:53:37.478: INFO: Pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063326806s
Jan 10 04:53:39.478: INFO: Pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063546479s
STEP: Saw pod success 01/10/23 04:53:39.478
Jan 10 04:53:39.478: INFO: Pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32" satisfied condition "Succeeded or Failed"
Jan 10 04:53:39.480: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32 container secret-env-test: <nil>
STEP: delete the pod 01/10/23 04:53:39.486
Jan 10 04:53:39.496: INFO: Waiting for pod pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32 to disappear
Jan 10 04:53:39.498: INFO: Pod pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:53:39.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5834" for this suite. 01/10/23 04:53:39.504
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":291,"skipped":5130,"failed":0}
------------------------------
• [4.257 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:35.253
    Jan 10 04:53:35.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:53:35.255
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:35.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:35.333
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-a1932b4f-4f0d-4094-b0ac-c0be7857708e 01/10/23 04:53:35.355
    STEP: Creating a pod to test consume secrets 01/10/23 04:53:35.379
    Jan 10 04:53:35.414: INFO: Waiting up to 5m0s for pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32" in namespace "secrets-5834" to be "Succeeded or Failed"
    Jan 10 04:53:35.474: INFO: Pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32": Phase="Pending", Reason="", readiness=false. Elapsed: 59.894221ms
    Jan 10 04:53:37.478: INFO: Pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063326806s
    Jan 10 04:53:39.478: INFO: Pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063546479s
    STEP: Saw pod success 01/10/23 04:53:39.478
    Jan 10 04:53:39.478: INFO: Pod "pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32" satisfied condition "Succeeded or Failed"
    Jan 10 04:53:39.480: INFO: Trying to get logs from node cncf-wk2 pod pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32 container secret-env-test: <nil>
    STEP: delete the pod 01/10/23 04:53:39.486
    Jan 10 04:53:39.496: INFO: Waiting for pod pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32 to disappear
    Jan 10 04:53:39.498: INFO: Pod pod-secrets-f59ec821-aeed-45a3-bb2d-1ecca6a07c32 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:53:39.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5834" for this suite. 01/10/23 04:53:39.504
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:39.513
Jan 10 04:53:39.513: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 04:53:39.514
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:39.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:39.54
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 01/10/23 04:53:39.546
STEP: listing secrets in all namespaces to ensure that there are more than zero 01/10/23 04:53:39.555
STEP: patching the secret 01/10/23 04:53:39.565
STEP: deleting the secret using a LabelSelector 01/10/23 04:53:39.581
STEP: listing secrets in all namespaces, searching for label name and value in patch 01/10/23 04:53:39.587
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jan 10 04:53:39.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8994" for this suite. 01/10/23 04:53:39.598
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":292,"skipped":5140,"failed":0}
------------------------------
• [0.092 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:39.513
    Jan 10 04:53:39.513: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 04:53:39.514
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:39.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:39.54
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 01/10/23 04:53:39.546
    STEP: listing secrets in all namespaces to ensure that there are more than zero 01/10/23 04:53:39.555
    STEP: patching the secret 01/10/23 04:53:39.565
    STEP: deleting the secret using a LabelSelector 01/10/23 04:53:39.581
    STEP: listing secrets in all namespaces, searching for label name and value in patch 01/10/23 04:53:39.587
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 04:53:39.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8994" for this suite. 01/10/23 04:53:39.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:39.616
Jan 10 04:53:39.616: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 04:53:39.616
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:39.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:39.689
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 01/10/23 04:53:39.712
Jan 10 04:53:39.775: INFO: Waiting up to 5m0s for pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167" in namespace "projected-592" to be "running and ready"
Jan 10 04:53:39.795: INFO: Pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167": Phase="Pending", Reason="", readiness=false. Elapsed: 19.938317ms
Jan 10 04:53:39.795: INFO: The phase of Pod annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:53:41.799: INFO: Pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167": Phase="Running", Reason="", readiness=true. Elapsed: 2.023562878s
Jan 10 04:53:41.799: INFO: The phase of Pod annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167 is Running (Ready = true)
Jan 10 04:53:41.799: INFO: Pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167" satisfied condition "running and ready"
Jan 10 04:53:42.321: INFO: Successfully updated pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 04:53:44.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-592" for this suite. 01/10/23 04:53:44.342
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":293,"skipped":5218,"failed":0}
------------------------------
• [4.741 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:39.616
    Jan 10 04:53:39.616: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 04:53:39.616
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:39.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:39.689
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 01/10/23 04:53:39.712
    Jan 10 04:53:39.775: INFO: Waiting up to 5m0s for pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167" in namespace "projected-592" to be "running and ready"
    Jan 10 04:53:39.795: INFO: Pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167": Phase="Pending", Reason="", readiness=false. Elapsed: 19.938317ms
    Jan 10 04:53:39.795: INFO: The phase of Pod annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:53:41.799: INFO: Pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167": Phase="Running", Reason="", readiness=true. Elapsed: 2.023562878s
    Jan 10 04:53:41.799: INFO: The phase of Pod annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167 is Running (Ready = true)
    Jan 10 04:53:41.799: INFO: Pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167" satisfied condition "running and ready"
    Jan 10 04:53:42.321: INFO: Successfully updated pod "annotationupdateff50fa1e-8176-4c1c-bcb6-70a6ca4f8167"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 04:53:44.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-592" for this suite. 01/10/23 04:53:44.342
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:44.362
Jan 10 04:53:44.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename events 01/10/23 04:53:44.363
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:44.437
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:44.454
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 01/10/23 04:53:44.476
Jan 10 04:53:44.487: INFO: created test-event-1
Jan 10 04:53:44.498: INFO: created test-event-2
Jan 10 04:53:44.522: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 01/10/23 04:53:44.522
STEP: delete collection of events 01/10/23 04:53:44.531
Jan 10 04:53:44.531: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 01/10/23 04:53:44.599
Jan 10 04:53:44.600: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Jan 10 04:53:44.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7080" for this suite. 01/10/23 04:53:44.623
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":294,"skipped":5261,"failed":0}
------------------------------
• [0.284 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:44.362
    Jan 10 04:53:44.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename events 01/10/23 04:53:44.363
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:44.437
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:44.454
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 01/10/23 04:53:44.476
    Jan 10 04:53:44.487: INFO: created test-event-1
    Jan 10 04:53:44.498: INFO: created test-event-2
    Jan 10 04:53:44.522: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 01/10/23 04:53:44.522
    STEP: delete collection of events 01/10/23 04:53:44.531
    Jan 10 04:53:44.531: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 01/10/23 04:53:44.599
    Jan 10 04:53:44.600: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Jan 10 04:53:44.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-7080" for this suite. 01/10/23 04:53:44.623
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:44.647
Jan 10 04:53:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename tables 01/10/23 04:53:44.648
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:44.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:44.757
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Jan 10 04:53:44.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9493" for this suite. 01/10/23 04:53:44.8
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":295,"skipped":5293,"failed":0}
------------------------------
• [0.187 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:44.647
    Jan 10 04:53:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename tables 01/10/23 04:53:44.648
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:44.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:44.757
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Jan 10 04:53:44.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-9493" for this suite. 01/10/23 04:53:44.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:44.852
Jan 10 04:53:44.852: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:53:44.853
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:44.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:44.908
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-4c529fe1-af61-458f-a171-1e97d7d58d29 01/10/23 04:53:44.921
STEP: Creating a pod to test consume configMaps 01/10/23 04:53:44.94
Jan 10 04:53:45.008: INFO: Waiting up to 5m0s for pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e" in namespace "configmap-7484" to be "Succeeded or Failed"
Jan 10 04:53:45.017: INFO: Pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.298468ms
Jan 10 04:53:47.021: INFO: Pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012862136s
Jan 10 04:53:49.020: INFO: Pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012271644s
STEP: Saw pod success 01/10/23 04:53:49.02
Jan 10 04:53:49.021: INFO: Pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e" satisfied condition "Succeeded or Failed"
Jan 10 04:53:49.023: INFO: Trying to get logs from node cncf-wk3 pod pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e container agnhost-container: <nil>
STEP: delete the pod 01/10/23 04:53:49.039
Jan 10 04:53:49.048: INFO: Waiting for pod pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e to disappear
Jan 10 04:53:49.053: INFO: Pod pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:53:49.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7484" for this suite. 01/10/23 04:53:49.056
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":296,"skipped":5320,"failed":0}
------------------------------
• [4.209 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:44.852
    Jan 10 04:53:44.852: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:53:44.853
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:44.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:44.908
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-4c529fe1-af61-458f-a171-1e97d7d58d29 01/10/23 04:53:44.921
    STEP: Creating a pod to test consume configMaps 01/10/23 04:53:44.94
    Jan 10 04:53:45.008: INFO: Waiting up to 5m0s for pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e" in namespace "configmap-7484" to be "Succeeded or Failed"
    Jan 10 04:53:45.017: INFO: Pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.298468ms
    Jan 10 04:53:47.021: INFO: Pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012862136s
    Jan 10 04:53:49.020: INFO: Pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012271644s
    STEP: Saw pod success 01/10/23 04:53:49.02
    Jan 10 04:53:49.021: INFO: Pod "pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e" satisfied condition "Succeeded or Failed"
    Jan 10 04:53:49.023: INFO: Trying to get logs from node cncf-wk3 pod pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 04:53:49.039
    Jan 10 04:53:49.048: INFO: Waiting for pod pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e to disappear
    Jan 10 04:53:49.053: INFO: Pod pod-configmaps-f2c7c6e6-fbe4-4e25-b683-bd8a76c9759e no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:53:49.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7484" for this suite. 01/10/23 04:53:49.056
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:49.062
Jan 10 04:53:49.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename dns 01/10/23 04:53:49.063
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:49.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:49.112
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 01/10/23 04:53:49.125
Jan 10 04:53:49.138: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-2807  887ed34a-111a-4874-bb23-1ff204edd137 245940 0 2023-01-10 04:53:49 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-01-10 04:53:49 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zbfv7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zbfv7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 10 04:53:49.138: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-2807" to be "running and ready"
Jan 10 04:53:49.160: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 21.829575ms
Jan 10 04:53:49.160: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:53:51.164: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.025408346s
Jan 10 04:53:51.164: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Jan 10 04:53:51.164: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 01/10/23 04:53:51.164
Jan 10 04:53:51.164: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2807 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:53:51.164: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:53:51.164: INFO: ExecWithOptions: Clientset creation
Jan 10 04:53:51.164: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/dns-2807/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 01/10/23 04:53:51.275
Jan 10 04:53:51.275: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2807 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 10 04:53:51.275: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
Jan 10 04:53:51.280: INFO: ExecWithOptions: Clientset creation
Jan 10 04:53:51.280: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/dns-2807/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 10 04:53:51.383: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 10 04:53:51.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2807" for this suite. 01/10/23 04:53:51.402
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":297,"skipped":5337,"failed":0}
------------------------------
• [2.344 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:49.062
    Jan 10 04:53:49.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename dns 01/10/23 04:53:49.063
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:49.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:49.112
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 01/10/23 04:53:49.125
    Jan 10 04:53:49.138: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-2807  887ed34a-111a-4874-bb23-1ff204edd137 245940 0 2023-01-10 04:53:49 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-01-10 04:53:49 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zbfv7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zbfv7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 10 04:53:49.138: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-2807" to be "running and ready"
    Jan 10 04:53:49.160: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 21.829575ms
    Jan 10 04:53:49.160: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:53:51.164: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.025408346s
    Jan 10 04:53:51.164: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Jan 10 04:53:51.164: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 01/10/23 04:53:51.164
    Jan 10 04:53:51.164: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2807 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:53:51.164: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:53:51.164: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:53:51.164: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/dns-2807/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 01/10/23 04:53:51.275
    Jan 10 04:53:51.275: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2807 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 10 04:53:51.275: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    Jan 10 04:53:51.280: INFO: ExecWithOptions: Clientset creation
    Jan 10 04:53:51.280: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/dns-2807/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 10 04:53:51.383: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 10 04:53:51.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2807" for this suite. 01/10/23 04:53:51.402
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:53:51.408
Jan 10 04:53:51.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-pred 01/10/23 04:53:51.41
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:51.435
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:51.439
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jan 10 04:53:51.443: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 10 04:53:51.453: INFO: Waiting for terminating namespaces to be deleted...
Jan 10 04:53:51.458: INFO: 
Logging pods the apiserver thinks is on node cncf-cp-etcd-wk1 before test
Jan 10 04:53:51.471: INFO: fleet-agent-745f6c6b7-8rvwd from cattle-fleet-system started at 2023-01-09 10:33:25 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.471: INFO: 	Container fleet-agent ready: true, restart count 1
Jan 10 04:53:51.472: INFO: cattle-cluster-agent-5c558c4984-89k8k from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.472: INFO: 	Container cluster-register ready: true, restart count 0
Jan 10 04:53:51.472: INFO: cattle-cluster-agent-5c558c4984-rwcnh from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.472: INFO: 	Container cluster-register ready: true, restart count 10
Jan 10 04:53:51.472: INFO: cattle-node-agent-jk48f from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.472: INFO: 	Container agent ready: true, restart count 0
Jan 10 04:53:51.472: INFO: kube-api-auth-gclz6 from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.472: INFO: 	Container kube-api-auth ready: true, restart count 0
Jan 10 04:53:51.472: INFO: rancher-webhook-5d7cccbd5-27z2v from cattle-system started at 2023-01-09 10:33:12 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.472: INFO: 	Container rancher-webhook ready: true, restart count 0
Jan 10 04:53:51.473: INFO: calico-kube-controllers-85d56898c-pmz4s from kube-system started at 2023-01-09 10:31:56 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container calico-kube-controllers ready: true, restart count 10
Jan 10 04:53:51.473: INFO: canal-b5cw4 from kube-system started at 2023-01-09 10:31:56 +0000 UTC (2 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 04:53:51.473: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 04:53:51.473: INFO: coredns-autoscaler-74d474f45c-rx5r4 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container autoscaler ready: true, restart count 0
Jan 10 04:53:51.473: INFO: coredns-dfb7f8fd4-nhjj8 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container coredns ready: true, restart count 0
Jan 10 04:53:51.473: INFO: metrics-server-c47f7c9bb-v98f6 from kube-system started at 2023-01-09 10:32:16 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container metrics-server ready: true, restart count 0
Jan 10 04:53:51.473: INFO: rke-coredns-addon-deploy-job-vp4pw from kube-system started at 2023-01-09 10:43:38 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Jan 10 04:53:51.473: INFO: rke-metrics-addon-deploy-job-tqspg from kube-system started at 2023-01-09 10:32:13 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Jan 10 04:53:51.473: INFO: rke-network-plugin-deploy-job-ks979 from kube-system started at 2023-01-09 10:31:53 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Jan 10 04:53:51.473: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 04:53:51.473: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 04:53:51.473: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 10 04:53:51.473: INFO: 
Logging pods the apiserver thinks is on node cncf-wk2 before test
Jan 10 04:53:51.484: INFO: cattle-node-agent-sbqnv from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.484: INFO: 	Container agent ready: true, restart count 0
Jan 10 04:53:51.484: INFO: canal-dvpz6 from kube-system started at 2023-01-09 10:33:29 +0000 UTC (2 container statuses recorded)
Jan 10 04:53:51.484: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 04:53:51.484: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 04:53:51.484: INFO: pod-qos-class-fb4ba352-1745-4ce1-a1be-788e87d1bba0 from pods-8407 started at 2023-01-10 04:52:54 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.484: INFO: 	Container agnhost ready: false, restart count 0
Jan 10 04:53:51.484: INFO: sonobuoy from sonobuoy started at 2023-01-10 03:35:32 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.484: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 10 04:53:51.484: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 04:53:51.484: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 04:53:51.484: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 10 04:53:51.484: INFO: 
Logging pods the apiserver thinks is on node cncf-wk3 before test
Jan 10 04:53:51.489: INFO: cattle-node-agent-tt8zp from cattle-system started at 2023-01-09 10:34:17 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.489: INFO: 	Container agent ready: true, restart count 0
Jan 10 04:53:51.489: INFO: canal-4dc8j from kube-system started at 2023-01-09 10:34:17 +0000 UTC (2 container statuses recorded)
Jan 10 04:53:51.489: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 04:53:51.489: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 04:53:51.489: INFO: coredns-dfb7f8fd4-qdm8v from kube-system started at 2023-01-09 11:16:48 +0000 UTC (1 container statuses recorded)
Jan 10 04:53:51.489: INFO: 	Container coredns ready: true, restart count 0
Jan 10 04:53:51.489: INFO: sonobuoy-e2e-job-fcdcc673a5c843f7 from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 04:53:51.489: INFO: 	Container e2e ready: true, restart count 0
Jan 10 04:53:51.489: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 04:53:51.489: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 04:53:51.489: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 04:53:51.489: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 01/10/23 04:53:51.489
Jan 10 04:53:51.500: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-7582" to be "running"
Jan 10 04:53:51.513: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 12.881455ms
Jan 10 04:53:53.518: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.017246196s
Jan 10 04:53:53.521: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 01/10/23 04:53:53.528
STEP: Trying to apply a random label on the found node. 01/10/23 04:53:53.562
STEP: verifying the node has the label kubernetes.io/e2e-a7aa9230-e56e-42cd-8399-21ebc8f33b26 95 01/10/23 04:53:53.588
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 01/10/23 04:53:53.593
Jan 10 04:53:53.618: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-7582" to be "not pending"
Jan 10 04:53:53.630: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.469735ms
Jan 10 04:53:55.634: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.015447678s
Jan 10 04:53:55.634: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.3.44 on the node which pod4 resides and expect not scheduled 01/10/23 04:53:55.634
Jan 10 04:53:55.651: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-7582" to be "not pending"
Jan 10 04:53:55.657: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.462662ms
Jan 10 04:53:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009331522s
Jan 10 04:53:59.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010767198s
Jan 10 04:54:01.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010508828s
Jan 10 04:54:03.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009597837s
Jan 10 04:54:05.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.009452711s
Jan 10 04:54:07.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009495097s
Jan 10 04:54:09.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.012114849s
Jan 10 04:54:11.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.009340042s
Jan 10 04:54:13.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.009682744s
Jan 10 04:54:15.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.009110294s
Jan 10 04:54:17.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.009400014s
Jan 10 04:54:19.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.010935019s
Jan 10 04:54:21.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.011546303s
Jan 10 04:54:23.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.009907864s
Jan 10 04:54:25.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.012507685s
Jan 10 04:54:27.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.009338264s
Jan 10 04:54:29.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.009585547s
Jan 10 04:54:31.677: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.025904598s
Jan 10 04:54:33.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.009572784s
Jan 10 04:54:35.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.011603387s
Jan 10 04:54:37.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.010297225s
Jan 10 04:54:39.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.010199522s
Jan 10 04:54:41.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.009488269s
Jan 10 04:54:43.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.009362374s
Jan 10 04:54:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.009026834s
Jan 10 04:54:47.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.009235782s
Jan 10 04:54:49.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.009640793s
Jan 10 04:54:51.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.011371678s
Jan 10 04:54:53.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.011035703s
Jan 10 04:54:55.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.010024063s
Jan 10 04:54:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.009679804s
Jan 10 04:54:59.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.010038816s
Jan 10 04:55:01.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.010008393s
Jan 10 04:55:03.667: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.015942695s
Jan 10 04:55:05.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.010382876s
Jan 10 04:55:07.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.009314953s
Jan 10 04:55:09.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.010006146s
Jan 10 04:55:11.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.009121741s
Jan 10 04:55:13.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.009987014s
Jan 10 04:55:15.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.011316822s
Jan 10 04:55:17.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.010350395s
Jan 10 04:55:19.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.011032998s
Jan 10 04:55:21.668: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.017326531s
Jan 10 04:55:23.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.009898479s
Jan 10 04:55:25.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.009516755s
Jan 10 04:55:27.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.00997489s
Jan 10 04:55:29.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.009440107s
Jan 10 04:55:31.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.010383034s
Jan 10 04:55:33.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.010319242s
Jan 10 04:55:35.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.01089579s
Jan 10 04:55:37.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.009728697s
Jan 10 04:55:39.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.009595446s
Jan 10 04:55:41.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.009985174s
Jan 10 04:55:43.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.010936741s
Jan 10 04:55:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.009594264s
Jan 10 04:55:47.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.009622924s
Jan 10 04:55:49.664: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.012901045s
Jan 10 04:55:51.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.009842418s
Jan 10 04:55:53.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.009975542s
Jan 10 04:55:55.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.009374058s
Jan 10 04:55:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.009618698s
Jan 10 04:55:59.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.010971665s
Jan 10 04:56:01.669: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.018516316s
Jan 10 04:56:03.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.010361541s
Jan 10 04:56:05.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.010006783s
Jan 10 04:56:07.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.011435214s
Jan 10 04:56:09.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.010533602s
Jan 10 04:56:11.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.011235114s
Jan 10 04:56:13.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.010040134s
Jan 10 04:56:15.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.012557315s
Jan 10 04:56:17.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.009562077s
Jan 10 04:56:19.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.010246126s
Jan 10 04:56:21.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.01284367s
Jan 10 04:56:23.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.009592407s
Jan 10 04:56:25.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.011795744s
Jan 10 04:56:27.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.010794004s
Jan 10 04:56:29.669: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.018788322s
Jan 10 04:56:31.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.009801217s
Jan 10 04:56:33.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.009779956s
Jan 10 04:56:35.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.012372613s
Jan 10 04:56:37.678: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.027738284s
Jan 10 04:56:39.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.010777151s
Jan 10 04:56:41.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.010825408s
Jan 10 04:56:43.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.010005195s
Jan 10 04:56:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.009071973s
Jan 10 04:56:47.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.010137084s
Jan 10 04:56:49.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.010607784s
Jan 10 04:56:51.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.009901596s
Jan 10 04:56:53.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.009369327s
Jan 10 04:56:55.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.010985304s
Jan 10 04:56:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.009812772s
Jan 10 04:56:59.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.010633992s
Jan 10 04:57:01.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.010286402s
Jan 10 04:57:03.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.009769537s
Jan 10 04:57:05.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.009696623s
Jan 10 04:57:07.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.012074458s
Jan 10 04:57:09.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.010803566s
Jan 10 04:57:11.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.009548411s
Jan 10 04:57:13.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.009682758s
Jan 10 04:57:15.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.009765067s
Jan 10 04:57:17.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.009441768s
Jan 10 04:57:19.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.009639537s
Jan 10 04:57:21.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.009674603s
Jan 10 04:57:23.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.011997984s
Jan 10 04:57:25.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.009693281s
Jan 10 04:57:27.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.009362681s
Jan 10 04:57:29.674: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.023159014s
Jan 10 04:57:31.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.010590512s
Jan 10 04:57:33.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.010956813s
Jan 10 04:57:35.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.009587043s
Jan 10 04:57:37.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.009295949s
Jan 10 04:57:39.666: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.014931725s
Jan 10 04:57:41.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.009818237s
Jan 10 04:57:43.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.00960625s
Jan 10 04:57:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.009332885s
Jan 10 04:57:47.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.009534043s
Jan 10 04:57:49.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.012705181s
Jan 10 04:57:51.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.010368202s
Jan 10 04:57:53.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.009690312s
Jan 10 04:57:55.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.010731145s
Jan 10 04:57:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.009233211s
Jan 10 04:57:59.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.011498582s
Jan 10 04:58:01.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.01242644s
Jan 10 04:58:03.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.012479023s
Jan 10 04:58:05.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.009429603s
Jan 10 04:58:07.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.00929329s
Jan 10 04:58:09.664: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.013464451s
Jan 10 04:58:11.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.010695068s
Jan 10 04:58:13.667: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.015890299s
Jan 10 04:58:15.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.010180487s
Jan 10 04:58:17.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.00971228s
Jan 10 04:58:19.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.010353913s
Jan 10 04:58:21.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.00961208s
Jan 10 04:58:23.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.008948569s
Jan 10 04:58:25.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.010581242s
Jan 10 04:58:27.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.010461713s
Jan 10 04:58:29.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.009669608s
Jan 10 04:58:31.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.009430946s
Jan 10 04:58:33.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.009979376s
Jan 10 04:58:35.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.009779969s
Jan 10 04:58:37.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.009600138s
Jan 10 04:58:39.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.009130108s
Jan 10 04:58:41.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.00904308s
Jan 10 04:58:43.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.009392779s
Jan 10 04:58:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.009487954s
Jan 10 04:58:47.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.009377257s
Jan 10 04:58:49.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.01098641s
Jan 10 04:58:51.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.009280361s
Jan 10 04:58:53.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.01096644s
Jan 10 04:58:55.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.009801441s
Jan 10 04:58:55.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.012175649s
STEP: removing the label kubernetes.io/e2e-a7aa9230-e56e-42cd-8399-21ebc8f33b26 off the node cncf-wk2 01/10/23 04:58:55.663
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a7aa9230-e56e-42cd-8399-21ebc8f33b26 01/10/23 04:58:55.674
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:58:55.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7582" for this suite. 01/10/23 04:58:55.688
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":298,"skipped":5338,"failed":0}
------------------------------
• [SLOW TEST] [304.284 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:53:51.408
    Jan 10 04:53:51.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-pred 01/10/23 04:53:51.41
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:53:51.435
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:53:51.439
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jan 10 04:53:51.443: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jan 10 04:53:51.453: INFO: Waiting for terminating namespaces to be deleted...
    Jan 10 04:53:51.458: INFO: 
    Logging pods the apiserver thinks is on node cncf-cp-etcd-wk1 before test
    Jan 10 04:53:51.471: INFO: fleet-agent-745f6c6b7-8rvwd from cattle-fleet-system started at 2023-01-09 10:33:25 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.471: INFO: 	Container fleet-agent ready: true, restart count 1
    Jan 10 04:53:51.472: INFO: cattle-cluster-agent-5c558c4984-89k8k from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.472: INFO: 	Container cluster-register ready: true, restart count 0
    Jan 10 04:53:51.472: INFO: cattle-cluster-agent-5c558c4984-rwcnh from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.472: INFO: 	Container cluster-register ready: true, restart count 10
    Jan 10 04:53:51.472: INFO: cattle-node-agent-jk48f from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.472: INFO: 	Container agent ready: true, restart count 0
    Jan 10 04:53:51.472: INFO: kube-api-auth-gclz6 from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.472: INFO: 	Container kube-api-auth ready: true, restart count 0
    Jan 10 04:53:51.472: INFO: rancher-webhook-5d7cccbd5-27z2v from cattle-system started at 2023-01-09 10:33:12 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.472: INFO: 	Container rancher-webhook ready: true, restart count 0
    Jan 10 04:53:51.473: INFO: calico-kube-controllers-85d56898c-pmz4s from kube-system started at 2023-01-09 10:31:56 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container calico-kube-controllers ready: true, restart count 10
    Jan 10 04:53:51.473: INFO: canal-b5cw4 from kube-system started at 2023-01-09 10:31:56 +0000 UTC (2 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 04:53:51.473: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 04:53:51.473: INFO: coredns-autoscaler-74d474f45c-rx5r4 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container autoscaler ready: true, restart count 0
    Jan 10 04:53:51.473: INFO: coredns-dfb7f8fd4-nhjj8 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container coredns ready: true, restart count 0
    Jan 10 04:53:51.473: INFO: metrics-server-c47f7c9bb-v98f6 from kube-system started at 2023-01-09 10:32:16 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container metrics-server ready: true, restart count 0
    Jan 10 04:53:51.473: INFO: rke-coredns-addon-deploy-job-vp4pw from kube-system started at 2023-01-09 10:43:38 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
    Jan 10 04:53:51.473: INFO: rke-metrics-addon-deploy-job-tqspg from kube-system started at 2023-01-09 10:32:13 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
    Jan 10 04:53:51.473: INFO: rke-network-plugin-deploy-job-ks979 from kube-system started at 2023-01-09 10:31:53 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
    Jan 10 04:53:51.473: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 04:53:51.473: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 04:53:51.473: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 10 04:53:51.473: INFO: 
    Logging pods the apiserver thinks is on node cncf-wk2 before test
    Jan 10 04:53:51.484: INFO: cattle-node-agent-sbqnv from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.484: INFO: 	Container agent ready: true, restart count 0
    Jan 10 04:53:51.484: INFO: canal-dvpz6 from kube-system started at 2023-01-09 10:33:29 +0000 UTC (2 container statuses recorded)
    Jan 10 04:53:51.484: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 04:53:51.484: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 04:53:51.484: INFO: pod-qos-class-fb4ba352-1745-4ce1-a1be-788e87d1bba0 from pods-8407 started at 2023-01-10 04:52:54 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.484: INFO: 	Container agnhost ready: false, restart count 0
    Jan 10 04:53:51.484: INFO: sonobuoy from sonobuoy started at 2023-01-10 03:35:32 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.484: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jan 10 04:53:51.484: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 04:53:51.484: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 04:53:51.484: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 10 04:53:51.484: INFO: 
    Logging pods the apiserver thinks is on node cncf-wk3 before test
    Jan 10 04:53:51.489: INFO: cattle-node-agent-tt8zp from cattle-system started at 2023-01-09 10:34:17 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.489: INFO: 	Container agent ready: true, restart count 0
    Jan 10 04:53:51.489: INFO: canal-4dc8j from kube-system started at 2023-01-09 10:34:17 +0000 UTC (2 container statuses recorded)
    Jan 10 04:53:51.489: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 04:53:51.489: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 04:53:51.489: INFO: coredns-dfb7f8fd4-qdm8v from kube-system started at 2023-01-09 11:16:48 +0000 UTC (1 container statuses recorded)
    Jan 10 04:53:51.489: INFO: 	Container coredns ready: true, restart count 0
    Jan 10 04:53:51.489: INFO: sonobuoy-e2e-job-fcdcc673a5c843f7 from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 04:53:51.489: INFO: 	Container e2e ready: true, restart count 0
    Jan 10 04:53:51.489: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 04:53:51.489: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 04:53:51.489: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 04:53:51.489: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 01/10/23 04:53:51.489
    Jan 10 04:53:51.500: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-7582" to be "running"
    Jan 10 04:53:51.513: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 12.881455ms
    Jan 10 04:53:53.518: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.017246196s
    Jan 10 04:53:53.521: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 01/10/23 04:53:53.528
    STEP: Trying to apply a random label on the found node. 01/10/23 04:53:53.562
    STEP: verifying the node has the label kubernetes.io/e2e-a7aa9230-e56e-42cd-8399-21ebc8f33b26 95 01/10/23 04:53:53.588
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 01/10/23 04:53:53.593
    Jan 10 04:53:53.618: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-7582" to be "not pending"
    Jan 10 04:53:53.630: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.469735ms
    Jan 10 04:53:55.634: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.015447678s
    Jan 10 04:53:55.634: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.3.44 on the node which pod4 resides and expect not scheduled 01/10/23 04:53:55.634
    Jan 10 04:53:55.651: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-7582" to be "not pending"
    Jan 10 04:53:55.657: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.462662ms
    Jan 10 04:53:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009331522s
    Jan 10 04:53:59.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010767198s
    Jan 10 04:54:01.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010508828s
    Jan 10 04:54:03.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009597837s
    Jan 10 04:54:05.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.009452711s
    Jan 10 04:54:07.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009495097s
    Jan 10 04:54:09.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.012114849s
    Jan 10 04:54:11.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.009340042s
    Jan 10 04:54:13.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.009682744s
    Jan 10 04:54:15.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.009110294s
    Jan 10 04:54:17.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.009400014s
    Jan 10 04:54:19.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.010935019s
    Jan 10 04:54:21.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.011546303s
    Jan 10 04:54:23.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.009907864s
    Jan 10 04:54:25.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.012507685s
    Jan 10 04:54:27.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.009338264s
    Jan 10 04:54:29.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.009585547s
    Jan 10 04:54:31.677: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.025904598s
    Jan 10 04:54:33.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.009572784s
    Jan 10 04:54:35.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.011603387s
    Jan 10 04:54:37.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.010297225s
    Jan 10 04:54:39.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.010199522s
    Jan 10 04:54:41.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.009488269s
    Jan 10 04:54:43.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.009362374s
    Jan 10 04:54:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.009026834s
    Jan 10 04:54:47.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.009235782s
    Jan 10 04:54:49.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.009640793s
    Jan 10 04:54:51.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.011371678s
    Jan 10 04:54:53.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.011035703s
    Jan 10 04:54:55.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.010024063s
    Jan 10 04:54:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.009679804s
    Jan 10 04:54:59.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.010038816s
    Jan 10 04:55:01.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.010008393s
    Jan 10 04:55:03.667: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.015942695s
    Jan 10 04:55:05.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.010382876s
    Jan 10 04:55:07.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.009314953s
    Jan 10 04:55:09.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.010006146s
    Jan 10 04:55:11.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.009121741s
    Jan 10 04:55:13.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.009987014s
    Jan 10 04:55:15.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.011316822s
    Jan 10 04:55:17.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.010350395s
    Jan 10 04:55:19.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.011032998s
    Jan 10 04:55:21.668: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.017326531s
    Jan 10 04:55:23.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.009898479s
    Jan 10 04:55:25.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.009516755s
    Jan 10 04:55:27.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.00997489s
    Jan 10 04:55:29.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.009440107s
    Jan 10 04:55:31.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.010383034s
    Jan 10 04:55:33.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.010319242s
    Jan 10 04:55:35.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.01089579s
    Jan 10 04:55:37.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.009728697s
    Jan 10 04:55:39.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.009595446s
    Jan 10 04:55:41.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.009985174s
    Jan 10 04:55:43.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.010936741s
    Jan 10 04:55:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.009594264s
    Jan 10 04:55:47.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.009622924s
    Jan 10 04:55:49.664: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.012901045s
    Jan 10 04:55:51.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.009842418s
    Jan 10 04:55:53.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.009975542s
    Jan 10 04:55:55.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.009374058s
    Jan 10 04:55:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.009618698s
    Jan 10 04:55:59.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.010971665s
    Jan 10 04:56:01.669: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.018516316s
    Jan 10 04:56:03.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.010361541s
    Jan 10 04:56:05.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.010006783s
    Jan 10 04:56:07.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.011435214s
    Jan 10 04:56:09.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.010533602s
    Jan 10 04:56:11.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.011235114s
    Jan 10 04:56:13.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.010040134s
    Jan 10 04:56:15.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.012557315s
    Jan 10 04:56:17.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.009562077s
    Jan 10 04:56:19.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.010246126s
    Jan 10 04:56:21.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.01284367s
    Jan 10 04:56:23.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.009592407s
    Jan 10 04:56:25.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.011795744s
    Jan 10 04:56:27.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.010794004s
    Jan 10 04:56:29.669: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.018788322s
    Jan 10 04:56:31.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.009801217s
    Jan 10 04:56:33.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.009779956s
    Jan 10 04:56:35.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.012372613s
    Jan 10 04:56:37.678: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.027738284s
    Jan 10 04:56:39.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.010777151s
    Jan 10 04:56:41.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.010825408s
    Jan 10 04:56:43.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.010005195s
    Jan 10 04:56:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.009071973s
    Jan 10 04:56:47.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.010137084s
    Jan 10 04:56:49.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.010607784s
    Jan 10 04:56:51.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.009901596s
    Jan 10 04:56:53.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.009369327s
    Jan 10 04:56:55.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.010985304s
    Jan 10 04:56:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.009812772s
    Jan 10 04:56:59.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.010633992s
    Jan 10 04:57:01.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.010286402s
    Jan 10 04:57:03.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.009769537s
    Jan 10 04:57:05.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.009696623s
    Jan 10 04:57:07.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.012074458s
    Jan 10 04:57:09.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.010803566s
    Jan 10 04:57:11.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.009548411s
    Jan 10 04:57:13.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.009682758s
    Jan 10 04:57:15.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.009765067s
    Jan 10 04:57:17.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.009441768s
    Jan 10 04:57:19.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.009639537s
    Jan 10 04:57:21.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.009674603s
    Jan 10 04:57:23.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.011997984s
    Jan 10 04:57:25.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.009693281s
    Jan 10 04:57:27.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.009362681s
    Jan 10 04:57:29.674: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.023159014s
    Jan 10 04:57:31.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.010590512s
    Jan 10 04:57:33.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.010956813s
    Jan 10 04:57:35.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.009587043s
    Jan 10 04:57:37.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.009295949s
    Jan 10 04:57:39.666: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.014931725s
    Jan 10 04:57:41.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.009818237s
    Jan 10 04:57:43.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.00960625s
    Jan 10 04:57:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.009332885s
    Jan 10 04:57:47.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.009534043s
    Jan 10 04:57:49.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.012705181s
    Jan 10 04:57:51.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.010368202s
    Jan 10 04:57:53.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.009690312s
    Jan 10 04:57:55.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.010731145s
    Jan 10 04:57:57.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.009233211s
    Jan 10 04:57:59.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.011498582s
    Jan 10 04:58:01.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.01242644s
    Jan 10 04:58:03.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.012479023s
    Jan 10 04:58:05.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.009429603s
    Jan 10 04:58:07.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.00929329s
    Jan 10 04:58:09.664: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.013464451s
    Jan 10 04:58:11.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.010695068s
    Jan 10 04:58:13.667: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.015890299s
    Jan 10 04:58:15.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.010180487s
    Jan 10 04:58:17.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.00971228s
    Jan 10 04:58:19.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.010353913s
    Jan 10 04:58:21.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.00961208s
    Jan 10 04:58:23.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.008948569s
    Jan 10 04:58:25.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.010581242s
    Jan 10 04:58:27.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.010461713s
    Jan 10 04:58:29.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.009669608s
    Jan 10 04:58:31.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.009430946s
    Jan 10 04:58:33.661: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.009979376s
    Jan 10 04:58:35.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.009779969s
    Jan 10 04:58:37.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.009600138s
    Jan 10 04:58:39.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.009130108s
    Jan 10 04:58:41.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.00904308s
    Jan 10 04:58:43.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.009392779s
    Jan 10 04:58:45.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.009487954s
    Jan 10 04:58:47.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.009377257s
    Jan 10 04:58:49.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.01098641s
    Jan 10 04:58:51.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.009280361s
    Jan 10 04:58:53.662: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.01096644s
    Jan 10 04:58:55.660: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.009801441s
    Jan 10 04:58:55.663: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.012175649s
    STEP: removing the label kubernetes.io/e2e-a7aa9230-e56e-42cd-8399-21ebc8f33b26 off the node cncf-wk2 01/10/23 04:58:55.663
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-a7aa9230-e56e-42cd-8399-21ebc8f33b26 01/10/23 04:58:55.674
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:58:55.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-7582" for this suite. 01/10/23 04:58:55.688
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:58:55.693
Jan 10 04:58:55.693: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 04:58:55.694
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:58:55.736
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:58:55.744
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 01/10/23 04:58:55.76
STEP: fetching the ConfigMap 01/10/23 04:58:55.77
STEP: patching the ConfigMap 01/10/23 04:58:55.773
STEP: listing all ConfigMaps in all namespaces with a label selector 01/10/23 04:58:55.782
STEP: deleting the ConfigMap by collection with a label selector 01/10/23 04:58:55.838
STEP: listing all ConfigMaps in test namespace 01/10/23 04:58:55.843
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 04:58:55.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8795" for this suite. 01/10/23 04:58:55.848
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":299,"skipped":5346,"failed":0}
------------------------------
• [0.160 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:58:55.693
    Jan 10 04:58:55.693: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 04:58:55.694
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:58:55.736
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:58:55.744
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 01/10/23 04:58:55.76
    STEP: fetching the ConfigMap 01/10/23 04:58:55.77
    STEP: patching the ConfigMap 01/10/23 04:58:55.773
    STEP: listing all ConfigMaps in all namespaces with a label selector 01/10/23 04:58:55.782
    STEP: deleting the ConfigMap by collection with a label selector 01/10/23 04:58:55.838
    STEP: listing all ConfigMaps in test namespace 01/10/23 04:58:55.843
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 04:58:55.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8795" for this suite. 01/10/23 04:58:55.848
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:58:55.856
Jan 10 04:58:55.856: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename watch 01/10/23 04:58:55.857
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:58:55.893
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:58:55.904
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 01/10/23 04:58:55.909
STEP: starting a background goroutine to produce watch events 01/10/23 04:58:55.914
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 01/10/23 04:58:55.914
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 10 04:58:58.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3694" for this suite. 01/10/23 04:58:58.711
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":300,"skipped":5378,"failed":0}
------------------------------
• [2.907 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:58:55.856
    Jan 10 04:58:55.856: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename watch 01/10/23 04:58:55.857
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:58:55.893
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:58:55.904
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 01/10/23 04:58:55.909
    STEP: starting a background goroutine to produce watch events 01/10/23 04:58:55.914
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 01/10/23 04:58:55.914
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 10 04:58:58.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3694" for this suite. 01/10/23 04:58:58.711
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:58:58.767
Jan 10 04:58:58.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:58:58.768
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:58:58.795
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:58:58.799
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 01/10/23 04:58:58.802
Jan 10 04:58:58.813: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db" in namespace "downward-api-3905" to be "Succeeded or Failed"
Jan 10 04:58:58.842: INFO: Pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db": Phase="Pending", Reason="", readiness=false. Elapsed: 28.112739ms
Jan 10 04:59:00.860: INFO: Pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046438179s
Jan 10 04:59:02.846: INFO: Pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031910681s
STEP: Saw pod success 01/10/23 04:59:02.846
Jan 10 04:59:02.846: INFO: Pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db" satisfied condition "Succeeded or Failed"
Jan 10 04:59:02.848: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db container client-container: <nil>
STEP: delete the pod 01/10/23 04:59:02.862
Jan 10 04:59:02.878: INFO: Waiting for pod downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db to disappear
Jan 10 04:59:02.882: INFO: Pod downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 04:59:02.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3905" for this suite. 01/10/23 04:59:02.885
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":301,"skipped":5387,"failed":0}
------------------------------
• [4.126 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:58:58.767
    Jan 10 04:58:58.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:58:58.768
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:58:58.795
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:58:58.799
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 01/10/23 04:58:58.802
    Jan 10 04:58:58.813: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db" in namespace "downward-api-3905" to be "Succeeded or Failed"
    Jan 10 04:58:58.842: INFO: Pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db": Phase="Pending", Reason="", readiness=false. Elapsed: 28.112739ms
    Jan 10 04:59:00.860: INFO: Pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046438179s
    Jan 10 04:59:02.846: INFO: Pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031910681s
    STEP: Saw pod success 01/10/23 04:59:02.846
    Jan 10 04:59:02.846: INFO: Pod "downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db" satisfied condition "Succeeded or Failed"
    Jan 10 04:59:02.848: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db container client-container: <nil>
    STEP: delete the pod 01/10/23 04:59:02.862
    Jan 10 04:59:02.878: INFO: Waiting for pod downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db to disappear
    Jan 10 04:59:02.882: INFO: Pod downwardapi-volume-3122098b-581d-45df-8f56-128d72d819db no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 04:59:02.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3905" for this suite. 01/10/23 04:59:02.885
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:59:02.912
Jan 10 04:59:02.913: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-probe 01/10/23 04:59:02.913
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:02.946
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:02.953
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Jan 10 04:59:02.971: INFO: Waiting up to 5m0s for pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f" in namespace "container-probe-5726" to be "running and ready"
Jan 10 04:59:02.983: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.808326ms
Jan 10 04:59:02.983: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:59:04.988: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 2.01650325s
Jan 10 04:59:04.988: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:06.995: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 4.023365039s
Jan 10 04:59:06.995: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:08.987: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 6.015995011s
Jan 10 04:59:08.987: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:10.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 8.014954171s
Jan 10 04:59:10.986: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:12.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 10.014613782s
Jan 10 04:59:12.986: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:14.988: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 12.016447646s
Jan 10 04:59:14.988: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:16.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 14.014575777s
Jan 10 04:59:16.986: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:18.987: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 16.01591664s
Jan 10 04:59:18.987: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:20.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 18.015265473s
Jan 10 04:59:20.987: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:22.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 20.015348284s
Jan 10 04:59:22.987: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
Jan 10 04:59:24.987: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=true. Elapsed: 22.016234185s
Jan 10 04:59:24.988: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = true)
Jan 10 04:59:24.988: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f" satisfied condition "running and ready"
Jan 10 04:59:24.990: INFO: Container started at 2023-01-10 04:59:03 +0000 UTC, pod became ready at 2023-01-10 04:59:23 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 10 04:59:24.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5726" for this suite. 01/10/23 04:59:24.993
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":302,"skipped":5441,"failed":0}
------------------------------
• [SLOW TEST] [22.086 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:59:02.912
    Jan 10 04:59:02.913: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-probe 01/10/23 04:59:02.913
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:02.946
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:02.953
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Jan 10 04:59:02.971: INFO: Waiting up to 5m0s for pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f" in namespace "container-probe-5726" to be "running and ready"
    Jan 10 04:59:02.983: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.808326ms
    Jan 10 04:59:02.983: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:59:04.988: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 2.01650325s
    Jan 10 04:59:04.988: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:06.995: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 4.023365039s
    Jan 10 04:59:06.995: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:08.987: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 6.015995011s
    Jan 10 04:59:08.987: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:10.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 8.014954171s
    Jan 10 04:59:10.986: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:12.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 10.014613782s
    Jan 10 04:59:12.986: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:14.988: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 12.016447646s
    Jan 10 04:59:14.988: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:16.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 14.014575777s
    Jan 10 04:59:16.986: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:18.987: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 16.01591664s
    Jan 10 04:59:18.987: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:20.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 18.015265473s
    Jan 10 04:59:20.987: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:22.986: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=false. Elapsed: 20.015348284s
    Jan 10 04:59:22.987: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = false)
    Jan 10 04:59:24.987: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f": Phase="Running", Reason="", readiness=true. Elapsed: 22.016234185s
    Jan 10 04:59:24.988: INFO: The phase of Pod test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f is Running (Ready = true)
    Jan 10 04:59:24.988: INFO: Pod "test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f" satisfied condition "running and ready"
    Jan 10 04:59:24.990: INFO: Container started at 2023-01-10 04:59:03 +0000 UTC, pod became ready at 2023-01-10 04:59:23 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 10 04:59:24.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5726" for this suite. 01/10/23 04:59:24.993
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:59:25.005
Jan 10 04:59:25.005: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:59:25.007
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:25.027
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:25.03
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 01/10/23 04:59:25.071
Jan 10 04:59:25.089: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22" in namespace "downward-api-15" to be "Succeeded or Failed"
Jan 10 04:59:25.101: INFO: Pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22": Phase="Pending", Reason="", readiness=false. Elapsed: 11.717875ms
Jan 10 04:59:27.106: INFO: Pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016077702s
Jan 10 04:59:29.106: INFO: Pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016824747s
STEP: Saw pod success 01/10/23 04:59:29.107
Jan 10 04:59:29.107: INFO: Pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22" satisfied condition "Succeeded or Failed"
Jan 10 04:59:29.111: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22 container client-container: <nil>
STEP: delete the pod 01/10/23 04:59:29.117
Jan 10 04:59:29.128: INFO: Waiting for pod downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22 to disappear
Jan 10 04:59:29.131: INFO: Pod downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 04:59:29.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-15" for this suite. 01/10/23 04:59:29.135
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":303,"skipped":5502,"failed":0}
------------------------------
• [4.137 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:59:25.005
    Jan 10 04:59:25.005: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:59:25.007
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:25.027
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:25.03
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 01/10/23 04:59:25.071
    Jan 10 04:59:25.089: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22" in namespace "downward-api-15" to be "Succeeded or Failed"
    Jan 10 04:59:25.101: INFO: Pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22": Phase="Pending", Reason="", readiness=false. Elapsed: 11.717875ms
    Jan 10 04:59:27.106: INFO: Pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016077702s
    Jan 10 04:59:29.106: INFO: Pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016824747s
    STEP: Saw pod success 01/10/23 04:59:29.107
    Jan 10 04:59:29.107: INFO: Pod "downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22" satisfied condition "Succeeded or Failed"
    Jan 10 04:59:29.111: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22 container client-container: <nil>
    STEP: delete the pod 01/10/23 04:59:29.117
    Jan 10 04:59:29.128: INFO: Waiting for pod downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22 to disappear
    Jan 10 04:59:29.131: INFO: Pod downwardapi-volume-8ac753ca-809f-41f6-9eaa-efdc2b3a1a22 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 04:59:29.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-15" for this suite. 01/10/23 04:59:29.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:59:29.168
Jan 10 04:59:29.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-pred 01/10/23 04:59:29.169
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:29.196
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:29.202
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jan 10 04:59:29.208: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 10 04:59:29.236: INFO: Waiting for terminating namespaces to be deleted...
Jan 10 04:59:29.244: INFO: 
Logging pods the apiserver thinks is on node cncf-cp-etcd-wk1 before test
Jan 10 04:59:29.279: INFO: fleet-agent-745f6c6b7-8rvwd from cattle-fleet-system started at 2023-01-09 10:33:25 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container fleet-agent ready: true, restart count 1
Jan 10 04:59:29.279: INFO: cattle-cluster-agent-5c558c4984-89k8k from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container cluster-register ready: true, restart count 0
Jan 10 04:59:29.279: INFO: cattle-cluster-agent-5c558c4984-rwcnh from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container cluster-register ready: true, restart count 10
Jan 10 04:59:29.279: INFO: cattle-node-agent-jk48f from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container agent ready: true, restart count 0
Jan 10 04:59:29.279: INFO: kube-api-auth-gclz6 from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container kube-api-auth ready: true, restart count 0
Jan 10 04:59:29.279: INFO: rancher-webhook-5d7cccbd5-27z2v from cattle-system started at 2023-01-09 10:33:12 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container rancher-webhook ready: true, restart count 0
Jan 10 04:59:29.279: INFO: calico-kube-controllers-85d56898c-pmz4s from kube-system started at 2023-01-09 10:31:56 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container calico-kube-controllers ready: true, restart count 10
Jan 10 04:59:29.279: INFO: canal-b5cw4 from kube-system started at 2023-01-09 10:31:56 +0000 UTC (2 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 04:59:29.279: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 04:59:29.279: INFO: coredns-autoscaler-74d474f45c-rx5r4 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container autoscaler ready: true, restart count 0
Jan 10 04:59:29.279: INFO: coredns-dfb7f8fd4-nhjj8 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container coredns ready: true, restart count 0
Jan 10 04:59:29.279: INFO: metrics-server-c47f7c9bb-v98f6 from kube-system started at 2023-01-09 10:32:16 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container metrics-server ready: true, restart count 0
Jan 10 04:59:29.279: INFO: rke-coredns-addon-deploy-job-vp4pw from kube-system started at 2023-01-09 10:43:38 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Jan 10 04:59:29.279: INFO: rke-metrics-addon-deploy-job-tqspg from kube-system started at 2023-01-09 10:32:13 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Jan 10 04:59:29.279: INFO: rke-network-plugin-deploy-job-ks979 from kube-system started at 2023-01-09 10:31:53 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Jan 10 04:59:29.279: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 04:59:29.279: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 04:59:29.279: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 10 04:59:29.279: INFO: 
Logging pods the apiserver thinks is on node cncf-wk2 before test
Jan 10 04:59:29.321: INFO: cattle-node-agent-sbqnv from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.321: INFO: 	Container agent ready: true, restart count 0
Jan 10 04:59:29.321: INFO: test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f from container-probe-5726 started at 2023-01-10 04:59:02 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.321: INFO: 	Container test-webserver ready: true, restart count 0
Jan 10 04:59:29.321: INFO: canal-dvpz6 from kube-system started at 2023-01-09 10:33:29 +0000 UTC (2 container statuses recorded)
Jan 10 04:59:29.321: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 04:59:29.322: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 04:59:29.322: INFO: sonobuoy from sonobuoy started at 2023-01-10 03:35:32 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.322: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 10 04:59:29.322: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 04:59:29.322: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 04:59:29.322: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 10 04:59:29.322: INFO: 
Logging pods the apiserver thinks is on node cncf-wk3 before test
Jan 10 04:59:29.337: INFO: cattle-node-agent-tt8zp from cattle-system started at 2023-01-09 10:34:17 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.337: INFO: 	Container agent ready: true, restart count 0
Jan 10 04:59:29.337: INFO: canal-4dc8j from kube-system started at 2023-01-09 10:34:17 +0000 UTC (2 container statuses recorded)
Jan 10 04:59:29.337: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 04:59:29.337: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 04:59:29.337: INFO: coredns-dfb7f8fd4-qdm8v from kube-system started at 2023-01-09 11:16:48 +0000 UTC (1 container statuses recorded)
Jan 10 04:59:29.337: INFO: 	Container coredns ready: true, restart count 0
Jan 10 04:59:29.337: INFO: sonobuoy-e2e-job-fcdcc673a5c843f7 from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 04:59:29.337: INFO: 	Container e2e ready: true, restart count 0
Jan 10 04:59:29.337: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 04:59:29.337: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 04:59:29.337: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 04:59:29.337: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 01/10/23 04:59:29.337
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1738d9d4c201b6eb], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 01/10/23 04:59:29.406
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jan 10 04:59:30.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7397" for this suite. 01/10/23 04:59:30.385
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":304,"skipped":5554,"failed":0}
------------------------------
• [1.222 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:59:29.168
    Jan 10 04:59:29.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-pred 01/10/23 04:59:29.169
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:29.196
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:29.202
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jan 10 04:59:29.208: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jan 10 04:59:29.236: INFO: Waiting for terminating namespaces to be deleted...
    Jan 10 04:59:29.244: INFO: 
    Logging pods the apiserver thinks is on node cncf-cp-etcd-wk1 before test
    Jan 10 04:59:29.279: INFO: fleet-agent-745f6c6b7-8rvwd from cattle-fleet-system started at 2023-01-09 10:33:25 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container fleet-agent ready: true, restart count 1
    Jan 10 04:59:29.279: INFO: cattle-cluster-agent-5c558c4984-89k8k from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container cluster-register ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: cattle-cluster-agent-5c558c4984-rwcnh from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container cluster-register ready: true, restart count 10
    Jan 10 04:59:29.279: INFO: cattle-node-agent-jk48f from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container agent ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: kube-api-auth-gclz6 from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container kube-api-auth ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: rancher-webhook-5d7cccbd5-27z2v from cattle-system started at 2023-01-09 10:33:12 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container rancher-webhook ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: calico-kube-controllers-85d56898c-pmz4s from kube-system started at 2023-01-09 10:31:56 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container calico-kube-controllers ready: true, restart count 10
    Jan 10 04:59:29.279: INFO: canal-b5cw4 from kube-system started at 2023-01-09 10:31:56 +0000 UTC (2 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: coredns-autoscaler-74d474f45c-rx5r4 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container autoscaler ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: coredns-dfb7f8fd4-nhjj8 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container coredns ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: metrics-server-c47f7c9bb-v98f6 from kube-system started at 2023-01-09 10:32:16 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container metrics-server ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: rke-coredns-addon-deploy-job-vp4pw from kube-system started at 2023-01-09 10:43:38 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
    Jan 10 04:59:29.279: INFO: rke-metrics-addon-deploy-job-tqspg from kube-system started at 2023-01-09 10:32:13 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
    Jan 10 04:59:29.279: INFO: rke-network-plugin-deploy-job-ks979 from kube-system started at 2023-01-09 10:31:53 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
    Jan 10 04:59:29.279: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 04:59:29.279: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 10 04:59:29.279: INFO: 
    Logging pods the apiserver thinks is on node cncf-wk2 before test
    Jan 10 04:59:29.321: INFO: cattle-node-agent-sbqnv from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.321: INFO: 	Container agent ready: true, restart count 0
    Jan 10 04:59:29.321: INFO: test-webserver-ba783d1a-9c48-4558-9e94-4a583ecb7b3f from container-probe-5726 started at 2023-01-10 04:59:02 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.321: INFO: 	Container test-webserver ready: true, restart count 0
    Jan 10 04:59:29.321: INFO: canal-dvpz6 from kube-system started at 2023-01-09 10:33:29 +0000 UTC (2 container statuses recorded)
    Jan 10 04:59:29.321: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 04:59:29.322: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 04:59:29.322: INFO: sonobuoy from sonobuoy started at 2023-01-10 03:35:32 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.322: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jan 10 04:59:29.322: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 04:59:29.322: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 04:59:29.322: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 10 04:59:29.322: INFO: 
    Logging pods the apiserver thinks is on node cncf-wk3 before test
    Jan 10 04:59:29.337: INFO: cattle-node-agent-tt8zp from cattle-system started at 2023-01-09 10:34:17 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.337: INFO: 	Container agent ready: true, restart count 0
    Jan 10 04:59:29.337: INFO: canal-4dc8j from kube-system started at 2023-01-09 10:34:17 +0000 UTC (2 container statuses recorded)
    Jan 10 04:59:29.337: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 04:59:29.337: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 04:59:29.337: INFO: coredns-dfb7f8fd4-qdm8v from kube-system started at 2023-01-09 11:16:48 +0000 UTC (1 container statuses recorded)
    Jan 10 04:59:29.337: INFO: 	Container coredns ready: true, restart count 0
    Jan 10 04:59:29.337: INFO: sonobuoy-e2e-job-fcdcc673a5c843f7 from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 04:59:29.337: INFO: 	Container e2e ready: true, restart count 0
    Jan 10 04:59:29.337: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 04:59:29.337: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 04:59:29.337: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 04:59:29.337: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 01/10/23 04:59:29.337
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1738d9d4c201b6eb], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 01/10/23 04:59:29.406
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 04:59:30.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-7397" for this suite. 01/10/23 04:59:30.385
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:59:30.392
Jan 10 04:59:30.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 04:59:30.393
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:30.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:30.428
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Jan 10 04:59:30.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: creating the pod 01/10/23 04:59:30.435
STEP: submitting the pod to kubernetes 01/10/23 04:59:30.435
Jan 10 04:59:30.449: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e" in namespace "pods-5567" to be "running and ready"
Jan 10 04:59:30.454: INFO: Pod "pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095396ms
Jan 10 04:59:30.454: INFO: The phase of Pod pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e is Pending, waiting for it to be Running (with Ready = true)
Jan 10 04:59:32.457: INFO: Pod "pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e": Phase="Running", Reason="", readiness=true. Elapsed: 2.008354284s
Jan 10 04:59:32.458: INFO: The phase of Pod pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e is Running (Ready = true)
Jan 10 04:59:32.458: INFO: Pod "pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 04:59:32.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5567" for this suite. 01/10/23 04:59:32.472
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":305,"skipped":5588,"failed":0}
------------------------------
• [2.087 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:59:30.392
    Jan 10 04:59:30.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 04:59:30.393
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:30.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:30.428
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Jan 10 04:59:30.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: creating the pod 01/10/23 04:59:30.435
    STEP: submitting the pod to kubernetes 01/10/23 04:59:30.435
    Jan 10 04:59:30.449: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e" in namespace "pods-5567" to be "running and ready"
    Jan 10 04:59:30.454: INFO: Pod "pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095396ms
    Jan 10 04:59:30.454: INFO: The phase of Pod pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 04:59:32.457: INFO: Pod "pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e": Phase="Running", Reason="", readiness=true. Elapsed: 2.008354284s
    Jan 10 04:59:32.458: INFO: The phase of Pod pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e is Running (Ready = true)
    Jan 10 04:59:32.458: INFO: Pod "pod-logs-websocket-37ad21bc-a15d-42b0-acaa-429a89d9792e" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 04:59:32.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5567" for this suite. 01/10/23 04:59:32.472
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:59:32.481
Jan 10 04:59:32.481: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 04:59:32.482
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:32.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:32.509
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 01/10/23 04:59:32.522
STEP: waiting for available Endpoint 01/10/23 04:59:32.526
STEP: listing all Endpoints 01/10/23 04:59:32.528
STEP: updating the Endpoint 01/10/23 04:59:32.535
STEP: fetching the Endpoint 01/10/23 04:59:32.542
STEP: patching the Endpoint 01/10/23 04:59:32.544
STEP: fetching the Endpoint 01/10/23 04:59:32.557
STEP: deleting the Endpoint by Collection 01/10/23 04:59:32.559
STEP: waiting for Endpoint deletion 01/10/23 04:59:32.565
STEP: fetching the Endpoint 01/10/23 04:59:32.567
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 04:59:32.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4866" for this suite. 01/10/23 04:59:32.573
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":306,"skipped":5591,"failed":0}
------------------------------
• [0.102 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:59:32.481
    Jan 10 04:59:32.481: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 04:59:32.482
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:32.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:32.509
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 01/10/23 04:59:32.522
    STEP: waiting for available Endpoint 01/10/23 04:59:32.526
    STEP: listing all Endpoints 01/10/23 04:59:32.528
    STEP: updating the Endpoint 01/10/23 04:59:32.535
    STEP: fetching the Endpoint 01/10/23 04:59:32.542
    STEP: patching the Endpoint 01/10/23 04:59:32.544
    STEP: fetching the Endpoint 01/10/23 04:59:32.557
    STEP: deleting the Endpoint by Collection 01/10/23 04:59:32.559
    STEP: waiting for Endpoint deletion 01/10/23 04:59:32.565
    STEP: fetching the Endpoint 01/10/23 04:59:32.567
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 04:59:32.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4866" for this suite. 01/10/23 04:59:32.573
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:59:32.584
Jan 10 04:59:32.584: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 04:59:32.586
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:32.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:32.636
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 01/10/23 04:59:32.655
Jan 10 04:59:32.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b" in namespace "downward-api-4297" to be "Succeeded or Failed"
Jan 10 04:59:32.680: INFO: Pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.907529ms
Jan 10 04:59:34.683: INFO: Pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018511637s
Jan 10 04:59:36.684: INFO: Pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019309581s
STEP: Saw pod success 01/10/23 04:59:36.684
Jan 10 04:59:36.684: INFO: Pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b" satisfied condition "Succeeded or Failed"
Jan 10 04:59:36.686: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b container client-container: <nil>
STEP: delete the pod 01/10/23 04:59:36.693
Jan 10 04:59:36.705: INFO: Waiting for pod downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b to disappear
Jan 10 04:59:36.708: INFO: Pod downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 04:59:36.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4297" for this suite. 01/10/23 04:59:36.711
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":307,"skipped":5601,"failed":0}
------------------------------
• [4.132 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:59:32.584
    Jan 10 04:59:32.584: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 04:59:32.586
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:32.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:32.636
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 01/10/23 04:59:32.655
    Jan 10 04:59:32.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b" in namespace "downward-api-4297" to be "Succeeded or Failed"
    Jan 10 04:59:32.680: INFO: Pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.907529ms
    Jan 10 04:59:34.683: INFO: Pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018511637s
    Jan 10 04:59:36.684: INFO: Pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019309581s
    STEP: Saw pod success 01/10/23 04:59:36.684
    Jan 10 04:59:36.684: INFO: Pod "downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b" satisfied condition "Succeeded or Failed"
    Jan 10 04:59:36.686: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b container client-container: <nil>
    STEP: delete the pod 01/10/23 04:59:36.693
    Jan 10 04:59:36.705: INFO: Waiting for pod downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b to disappear
    Jan 10 04:59:36.708: INFO: Pod downwardapi-volume-743eaa8a-6543-431c-b4b0-63c40bd1c07b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 04:59:36.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4297" for this suite. 01/10/23 04:59:36.711
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 04:59:36.725
Jan 10 04:59:36.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename statefulset 01/10/23 04:59:36.726
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:36.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:36.749
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5736 01/10/23 04:59:36.752
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 01/10/23 04:59:36.761
Jan 10 04:59:36.784: INFO: Found 0 stateful pods, waiting for 3
Jan 10 04:59:46.788: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 04:59:46.788: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 04:59:46.788: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 01/10/23 04:59:46.795
Jan 10 04:59:46.813: INFO: Updating stateful set ss2
STEP: Creating a new revision 01/10/23 04:59:46.813
STEP: Not applying an update when the partition is greater than the number of replicas 01/10/23 04:59:56.828
STEP: Performing a canary update 01/10/23 04:59:56.828
Jan 10 04:59:56.850: INFO: Updating stateful set ss2
Jan 10 04:59:56.894: INFO: Waiting for Pod statefulset-5736/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 01/10/23 05:00:06.906
Jan 10 05:00:07.048: INFO: Found 1 stateful pods, waiting for 3
Jan 10 05:00:17.052: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 05:00:17.052: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 05:00:17.052: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 01/10/23 05:00:17.057
Jan 10 05:00:17.081: INFO: Updating stateful set ss2
Jan 10 05:00:17.104: INFO: Waiting for Pod statefulset-5736/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jan 10 05:00:27.171: INFO: Updating stateful set ss2
Jan 10 05:00:27.204: INFO: Waiting for StatefulSet statefulset-5736/ss2 to complete update
Jan 10 05:00:27.204: INFO: Waiting for Pod statefulset-5736/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 10 05:00:37.211: INFO: Deleting all statefulset in ns statefulset-5736
Jan 10 05:00:37.213: INFO: Scaling statefulset ss2 to 0
Jan 10 05:00:47.230: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 05:00:47.233: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 10 05:00:47.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5736" for this suite. 01/10/23 05:00:47.256
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":308,"skipped":5650,"failed":0}
------------------------------
• [SLOW TEST] [70.543 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 04:59:36.725
    Jan 10 04:59:36.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename statefulset 01/10/23 04:59:36.726
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 04:59:36.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 04:59:36.749
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5736 01/10/23 04:59:36.752
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 01/10/23 04:59:36.761
    Jan 10 04:59:36.784: INFO: Found 0 stateful pods, waiting for 3
    Jan 10 04:59:46.788: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 04:59:46.788: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 04:59:46.788: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 01/10/23 04:59:46.795
    Jan 10 04:59:46.813: INFO: Updating stateful set ss2
    STEP: Creating a new revision 01/10/23 04:59:46.813
    STEP: Not applying an update when the partition is greater than the number of replicas 01/10/23 04:59:56.828
    STEP: Performing a canary update 01/10/23 04:59:56.828
    Jan 10 04:59:56.850: INFO: Updating stateful set ss2
    Jan 10 04:59:56.894: INFO: Waiting for Pod statefulset-5736/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 01/10/23 05:00:06.906
    Jan 10 05:00:07.048: INFO: Found 1 stateful pods, waiting for 3
    Jan 10 05:00:17.052: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 05:00:17.052: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 10 05:00:17.052: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 01/10/23 05:00:17.057
    Jan 10 05:00:17.081: INFO: Updating stateful set ss2
    Jan 10 05:00:17.104: INFO: Waiting for Pod statefulset-5736/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jan 10 05:00:27.171: INFO: Updating stateful set ss2
    Jan 10 05:00:27.204: INFO: Waiting for StatefulSet statefulset-5736/ss2 to complete update
    Jan 10 05:00:27.204: INFO: Waiting for Pod statefulset-5736/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 10 05:00:37.211: INFO: Deleting all statefulset in ns statefulset-5736
    Jan 10 05:00:37.213: INFO: Scaling statefulset ss2 to 0
    Jan 10 05:00:47.230: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 05:00:47.233: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 10 05:00:47.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5736" for this suite. 01/10/23 05:00:47.256
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:00:47.307
Jan 10 05:00:47.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 05:00:47.308
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:00:47.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:00:47.346
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 05:00:47.4
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:00:48.016
STEP: Deploying the webhook pod 01/10/23 05:00:48.048
STEP: Wait for the deployment to be ready 01/10/23 05:00:48.079
Jan 10 05:00:48.105: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 05:00:50.134
STEP: Verifying the service has paired with the endpoint 01/10/23 05:00:50.151
Jan 10 05:00:51.151: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 01/10/23 05:00:51.153
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 01/10/23 05:00:51.155
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 01/10/23 05:00:51.155
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 01/10/23 05:00:51.155
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 01/10/23 05:00:51.156
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 01/10/23 05:00:51.156
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 01/10/23 05:00:51.157
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 05:00:51.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6473" for this suite. 01/10/23 05:00:51.16
STEP: Destroying namespace "webhook-6473-markers" for this suite. 01/10/23 05:00:51.166
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":309,"skipped":5671,"failed":0}
------------------------------
• [3.947 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:00:47.307
    Jan 10 05:00:47.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 05:00:47.308
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:00:47.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:00:47.346
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 05:00:47.4
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:00:48.016
    STEP: Deploying the webhook pod 01/10/23 05:00:48.048
    STEP: Wait for the deployment to be ready 01/10/23 05:00:48.079
    Jan 10 05:00:48.105: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 05:00:50.134
    STEP: Verifying the service has paired with the endpoint 01/10/23 05:00:50.151
    Jan 10 05:00:51.151: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 01/10/23 05:00:51.153
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 01/10/23 05:00:51.155
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 01/10/23 05:00:51.155
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 01/10/23 05:00:51.155
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 01/10/23 05:00:51.156
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 01/10/23 05:00:51.156
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 01/10/23 05:00:51.157
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 05:00:51.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6473" for this suite. 01/10/23 05:00:51.16
    STEP: Destroying namespace "webhook-6473-markers" for this suite. 01/10/23 05:00:51.166
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:00:51.245
Jan 10 05:00:51.245: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename sched-pred 01/10/23 05:00:51.246
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:00:51.3
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:00:51.314
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jan 10 05:00:51.323: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 10 05:00:51.334: INFO: Waiting for terminating namespaces to be deleted...
Jan 10 05:00:51.339: INFO: 
Logging pods the apiserver thinks is on node cncf-cp-etcd-wk1 before test
Jan 10 05:00:51.348: INFO: fleet-agent-745f6c6b7-8rvwd from cattle-fleet-system started at 2023-01-09 10:33:25 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container fleet-agent ready: true, restart count 1
Jan 10 05:00:51.348: INFO: cattle-cluster-agent-5c558c4984-89k8k from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container cluster-register ready: true, restart count 0
Jan 10 05:00:51.348: INFO: cattle-cluster-agent-5c558c4984-rwcnh from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container cluster-register ready: true, restart count 10
Jan 10 05:00:51.348: INFO: cattle-node-agent-jk48f from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container agent ready: true, restart count 0
Jan 10 05:00:51.348: INFO: kube-api-auth-gclz6 from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container kube-api-auth ready: true, restart count 0
Jan 10 05:00:51.348: INFO: rancher-webhook-5d7cccbd5-27z2v from cattle-system started at 2023-01-09 10:33:12 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container rancher-webhook ready: true, restart count 0
Jan 10 05:00:51.348: INFO: calico-kube-controllers-85d56898c-pmz4s from kube-system started at 2023-01-09 10:31:56 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container calico-kube-controllers ready: true, restart count 10
Jan 10 05:00:51.348: INFO: canal-b5cw4 from kube-system started at 2023-01-09 10:31:56 +0000 UTC (2 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 05:00:51.348: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 05:00:51.348: INFO: coredns-autoscaler-74d474f45c-rx5r4 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container autoscaler ready: true, restart count 0
Jan 10 05:00:51.348: INFO: coredns-dfb7f8fd4-nhjj8 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container coredns ready: true, restart count 0
Jan 10 05:00:51.348: INFO: metrics-server-c47f7c9bb-v98f6 from kube-system started at 2023-01-09 10:32:16 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container metrics-server ready: true, restart count 0
Jan 10 05:00:51.348: INFO: rke-coredns-addon-deploy-job-vp4pw from kube-system started at 2023-01-09 10:43:38 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.348: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Jan 10 05:00:51.348: INFO: rke-metrics-addon-deploy-job-tqspg from kube-system started at 2023-01-09 10:32:13 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.349: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Jan 10 05:00:51.349: INFO: rke-network-plugin-deploy-job-ks979 from kube-system started at 2023-01-09 10:31:53 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.349: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Jan 10 05:00:51.349: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 05:00:51.349: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 05:00:51.349: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 10 05:00:51.349: INFO: 
Logging pods the apiserver thinks is on node cncf-wk2 before test
Jan 10 05:00:51.355: INFO: cattle-node-agent-sbqnv from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.355: INFO: 	Container agent ready: true, restart count 0
Jan 10 05:00:51.355: INFO: canal-dvpz6 from kube-system started at 2023-01-09 10:33:29 +0000 UTC (2 container statuses recorded)
Jan 10 05:00:51.355: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 05:00:51.355: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 05:00:51.355: INFO: sonobuoy from sonobuoy started at 2023-01-10 03:35:32 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.355: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 10 05:00:51.355: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 05:00:51.355: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 05:00:51.355: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 10 05:00:51.355: INFO: 
Logging pods the apiserver thinks is on node cncf-wk3 before test
Jan 10 05:00:51.361: INFO: cattle-node-agent-tt8zp from cattle-system started at 2023-01-09 10:34:17 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.361: INFO: 	Container agent ready: true, restart count 0
Jan 10 05:00:51.361: INFO: canal-4dc8j from kube-system started at 2023-01-09 10:34:17 +0000 UTC (2 container statuses recorded)
Jan 10 05:00:51.361: INFO: 	Container calico-node ready: true, restart count 0
Jan 10 05:00:51.361: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 10 05:00:51.361: INFO: coredns-dfb7f8fd4-qdm8v from kube-system started at 2023-01-09 11:16:48 +0000 UTC (1 container statuses recorded)
Jan 10 05:00:51.361: INFO: 	Container coredns ready: true, restart count 0
Jan 10 05:00:51.361: INFO: sonobuoy-e2e-job-fcdcc673a5c843f7 from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 05:00:51.361: INFO: 	Container e2e ready: true, restart count 0
Jan 10 05:00:51.361: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 05:00:51.361: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
Jan 10 05:00:51.361: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 10 05:00:51.361: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node cncf-cp-etcd-wk1 01/10/23 05:00:51.388
STEP: verifying the node has the label node cncf-wk2 01/10/23 05:00:51.408
STEP: verifying the node has the label node cncf-wk3 01/10/23 05:00:51.438
Jan 10 05:00:51.455: INFO: Pod fleet-agent-745f6c6b7-8rvwd requesting resource cpu=0m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.455: INFO: Pod cattle-cluster-agent-5c558c4984-89k8k requesting resource cpu=0m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.455: INFO: Pod cattle-cluster-agent-5c558c4984-rwcnh requesting resource cpu=0m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.456: INFO: Pod cattle-node-agent-jk48f requesting resource cpu=0m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.456: INFO: Pod cattle-node-agent-sbqnv requesting resource cpu=0m on Node cncf-wk2
Jan 10 05:00:51.456: INFO: Pod cattle-node-agent-tt8zp requesting resource cpu=0m on Node cncf-wk3
Jan 10 05:00:51.456: INFO: Pod kube-api-auth-gclz6 requesting resource cpu=0m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.456: INFO: Pod rancher-webhook-5d7cccbd5-27z2v requesting resource cpu=0m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.456: INFO: Pod calico-kube-controllers-85d56898c-pmz4s requesting resource cpu=0m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.457: INFO: Pod canal-4dc8j requesting resource cpu=250m on Node cncf-wk3
Jan 10 05:00:51.457: INFO: Pod canal-b5cw4 requesting resource cpu=250m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.457: INFO: Pod canal-dvpz6 requesting resource cpu=250m on Node cncf-wk2
Jan 10 05:00:51.457: INFO: Pod coredns-autoscaler-74d474f45c-rx5r4 requesting resource cpu=20m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.457: INFO: Pod coredns-dfb7f8fd4-nhjj8 requesting resource cpu=100m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.457: INFO: Pod coredns-dfb7f8fd4-qdm8v requesting resource cpu=100m on Node cncf-wk3
Jan 10 05:00:51.457: INFO: Pod metrics-server-c47f7c9bb-v98f6 requesting resource cpu=100m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.458: INFO: Pod sonobuoy requesting resource cpu=0m on Node cncf-wk2
Jan 10 05:00:51.458: INFO: Pod sonobuoy-e2e-job-fcdcc673a5c843f7 requesting resource cpu=0m on Node cncf-wk3
Jan 10 05:00:51.458: INFO: Pod sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b requesting resource cpu=0m on Node cncf-wk3
Jan 10 05:00:51.458: INFO: Pod sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r requesting resource cpu=0m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.458: INFO: Pod sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz requesting resource cpu=0m on Node cncf-wk2
STEP: Starting Pods to consume most of the cluster CPU. 01/10/23 05:00:51.458
Jan 10 05:00:51.459: INFO: Creating a pod which consumes cpu=1071m on Node cncf-cp-etcd-wk1
Jan 10 05:00:51.465: INFO: Creating a pod which consumes cpu=1225m on Node cncf-wk2
Jan 10 05:00:51.485: INFO: Creating a pod which consumes cpu=1155m on Node cncf-wk3
Jan 10 05:00:51.520: INFO: Waiting up to 5m0s for pod "filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70" in namespace "sched-pred-6762" to be "running"
Jan 10 05:00:51.553: INFO: Pod "filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70": Phase="Pending", Reason="", readiness=false. Elapsed: 32.662781ms
Jan 10 05:00:53.558: INFO: Pod "filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70": Phase="Running", Reason="", readiness=true. Elapsed: 2.037437586s
Jan 10 05:00:53.558: INFO: Pod "filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70" satisfied condition "running"
Jan 10 05:00:53.558: INFO: Waiting up to 5m0s for pod "filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938" in namespace "sched-pred-6762" to be "running"
Jan 10 05:00:53.560: INFO: Pod "filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938": Phase="Running", Reason="", readiness=true. Elapsed: 2.394049ms
Jan 10 05:00:53.561: INFO: Pod "filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938" satisfied condition "running"
Jan 10 05:00:53.561: INFO: Waiting up to 5m0s for pod "filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2" in namespace "sched-pred-6762" to be "running"
Jan 10 05:00:53.565: INFO: Pod "filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048379ms
Jan 10 05:00:55.568: INFO: Pod "filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2": Phase="Running", Reason="", readiness=true. Elapsed: 2.007537951s
Jan 10 05:00:55.568: INFO: Pod "filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 01/10/23 05:00:55.568
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2.1738d9e7e2d65637], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6762/filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2 to cncf-wk3] 01/10/23 05:00:55.571
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2.1738d9e8251c46e8], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/10/23 05:00:55.571
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2.1738d9e828ae17f7], Reason = [Created], Message = [Created container filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2] 01/10/23 05:00:55.571
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2.1738d9e82ec2d27d], Reason = [Started], Message = [Started container filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2] 01/10/23 05:00:55.571
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938.1738d9e7e1af0bba], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6762/filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938 to cncf-wk2] 01/10/23 05:00:55.571
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938.1738d9e80cff84cf], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/10/23 05:00:55.572
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938.1738d9e80fd77795], Reason = [Created], Message = [Created container filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938] 01/10/23 05:00:55.572
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938.1738d9e815e236c7], Reason = [Started], Message = [Started container filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938] 01/10/23 05:00:55.572
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70.1738d9e7df638dd5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6762/filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70 to cncf-cp-etcd-wk1] 01/10/23 05:00:55.572
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70.1738d9e8116d48c9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/10/23 05:00:55.572
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70.1738d9e815b35fa1], Reason = [Created], Message = [Created container filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70] 01/10/23 05:00:55.572
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70.1738d9e81e5c9f2a], Reason = [Started], Message = [Started container filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70] 01/10/23 05:00:55.572
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1738d9e8d3e8d2bd], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 01/10/23 05:00:55.587
STEP: removing the label node off the node cncf-cp-etcd-wk1 01/10/23 05:00:56.584
STEP: verifying the node doesn't have the label node 01/10/23 05:00:56.604
STEP: removing the label node off the node cncf-wk2 01/10/23 05:00:56.614
STEP: verifying the node doesn't have the label node 01/10/23 05:00:56.699
STEP: removing the label node off the node cncf-wk3 01/10/23 05:00:56.713
STEP: verifying the node doesn't have the label node 01/10/23 05:00:56.763
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jan 10 05:00:56.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6762" for this suite. 01/10/23 05:00:56.781
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":310,"skipped":5671,"failed":0}
------------------------------
• [SLOW TEST] [5.552 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:00:51.245
    Jan 10 05:00:51.245: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename sched-pred 01/10/23 05:00:51.246
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:00:51.3
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:00:51.314
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jan 10 05:00:51.323: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jan 10 05:00:51.334: INFO: Waiting for terminating namespaces to be deleted...
    Jan 10 05:00:51.339: INFO: 
    Logging pods the apiserver thinks is on node cncf-cp-etcd-wk1 before test
    Jan 10 05:00:51.348: INFO: fleet-agent-745f6c6b7-8rvwd from cattle-fleet-system started at 2023-01-09 10:33:25 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container fleet-agent ready: true, restart count 1
    Jan 10 05:00:51.348: INFO: cattle-cluster-agent-5c558c4984-89k8k from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container cluster-register ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: cattle-cluster-agent-5c558c4984-rwcnh from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container cluster-register ready: true, restart count 10
    Jan 10 05:00:51.348: INFO: cattle-node-agent-jk48f from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container agent ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: kube-api-auth-gclz6 from cattle-system started at 2023-01-09 10:32:34 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container kube-api-auth ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: rancher-webhook-5d7cccbd5-27z2v from cattle-system started at 2023-01-09 10:33:12 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container rancher-webhook ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: calico-kube-controllers-85d56898c-pmz4s from kube-system started at 2023-01-09 10:31:56 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container calico-kube-controllers ready: true, restart count 10
    Jan 10 05:00:51.348: INFO: canal-b5cw4 from kube-system started at 2023-01-09 10:31:56 +0000 UTC (2 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: coredns-autoscaler-74d474f45c-rx5r4 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container autoscaler ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: coredns-dfb7f8fd4-nhjj8 from kube-system started at 2023-01-09 10:32:06 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container coredns ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: metrics-server-c47f7c9bb-v98f6 from kube-system started at 2023-01-09 10:32:16 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container metrics-server ready: true, restart count 0
    Jan 10 05:00:51.348: INFO: rke-coredns-addon-deploy-job-vp4pw from kube-system started at 2023-01-09 10:43:38 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.348: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
    Jan 10 05:00:51.348: INFO: rke-metrics-addon-deploy-job-tqspg from kube-system started at 2023-01-09 10:32:13 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.349: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
    Jan 10 05:00:51.349: INFO: rke-network-plugin-deploy-job-ks979 from kube-system started at 2023-01-09 10:31:53 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.349: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
    Jan 10 05:00:51.349: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 05:00:51.349: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 05:00:51.349: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 10 05:00:51.349: INFO: 
    Logging pods the apiserver thinks is on node cncf-wk2 before test
    Jan 10 05:00:51.355: INFO: cattle-node-agent-sbqnv from cattle-system started at 2023-01-09 10:33:29 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.355: INFO: 	Container agent ready: true, restart count 0
    Jan 10 05:00:51.355: INFO: canal-dvpz6 from kube-system started at 2023-01-09 10:33:29 +0000 UTC (2 container statuses recorded)
    Jan 10 05:00:51.355: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 05:00:51.355: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 05:00:51.355: INFO: sonobuoy from sonobuoy started at 2023-01-10 03:35:32 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.355: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jan 10 05:00:51.355: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 05:00:51.355: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 05:00:51.355: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 10 05:00:51.355: INFO: 
    Logging pods the apiserver thinks is on node cncf-wk3 before test
    Jan 10 05:00:51.361: INFO: cattle-node-agent-tt8zp from cattle-system started at 2023-01-09 10:34:17 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.361: INFO: 	Container agent ready: true, restart count 0
    Jan 10 05:00:51.361: INFO: canal-4dc8j from kube-system started at 2023-01-09 10:34:17 +0000 UTC (2 container statuses recorded)
    Jan 10 05:00:51.361: INFO: 	Container calico-node ready: true, restart count 0
    Jan 10 05:00:51.361: INFO: 	Container kube-flannel ready: true, restart count 0
    Jan 10 05:00:51.361: INFO: coredns-dfb7f8fd4-qdm8v from kube-system started at 2023-01-09 11:16:48 +0000 UTC (1 container statuses recorded)
    Jan 10 05:00:51.361: INFO: 	Container coredns ready: true, restart count 0
    Jan 10 05:00:51.361: INFO: sonobuoy-e2e-job-fcdcc673a5c843f7 from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 05:00:51.361: INFO: 	Container e2e ready: true, restart count 0
    Jan 10 05:00:51.361: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 05:00:51.361: INFO: sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b from sonobuoy started at 2023-01-10 03:35:35 +0000 UTC (2 container statuses recorded)
    Jan 10 05:00:51.361: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 10 05:00:51.361: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node cncf-cp-etcd-wk1 01/10/23 05:00:51.388
    STEP: verifying the node has the label node cncf-wk2 01/10/23 05:00:51.408
    STEP: verifying the node has the label node cncf-wk3 01/10/23 05:00:51.438
    Jan 10 05:00:51.455: INFO: Pod fleet-agent-745f6c6b7-8rvwd requesting resource cpu=0m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.455: INFO: Pod cattle-cluster-agent-5c558c4984-89k8k requesting resource cpu=0m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.455: INFO: Pod cattle-cluster-agent-5c558c4984-rwcnh requesting resource cpu=0m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.456: INFO: Pod cattle-node-agent-jk48f requesting resource cpu=0m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.456: INFO: Pod cattle-node-agent-sbqnv requesting resource cpu=0m on Node cncf-wk2
    Jan 10 05:00:51.456: INFO: Pod cattle-node-agent-tt8zp requesting resource cpu=0m on Node cncf-wk3
    Jan 10 05:00:51.456: INFO: Pod kube-api-auth-gclz6 requesting resource cpu=0m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.456: INFO: Pod rancher-webhook-5d7cccbd5-27z2v requesting resource cpu=0m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.456: INFO: Pod calico-kube-controllers-85d56898c-pmz4s requesting resource cpu=0m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.457: INFO: Pod canal-4dc8j requesting resource cpu=250m on Node cncf-wk3
    Jan 10 05:00:51.457: INFO: Pod canal-b5cw4 requesting resource cpu=250m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.457: INFO: Pod canal-dvpz6 requesting resource cpu=250m on Node cncf-wk2
    Jan 10 05:00:51.457: INFO: Pod coredns-autoscaler-74d474f45c-rx5r4 requesting resource cpu=20m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.457: INFO: Pod coredns-dfb7f8fd4-nhjj8 requesting resource cpu=100m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.457: INFO: Pod coredns-dfb7f8fd4-qdm8v requesting resource cpu=100m on Node cncf-wk3
    Jan 10 05:00:51.457: INFO: Pod metrics-server-c47f7c9bb-v98f6 requesting resource cpu=100m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.458: INFO: Pod sonobuoy requesting resource cpu=0m on Node cncf-wk2
    Jan 10 05:00:51.458: INFO: Pod sonobuoy-e2e-job-fcdcc673a5c843f7 requesting resource cpu=0m on Node cncf-wk3
    Jan 10 05:00:51.458: INFO: Pod sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-85z6b requesting resource cpu=0m on Node cncf-wk3
    Jan 10 05:00:51.458: INFO: Pod sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-kh86r requesting resource cpu=0m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.458: INFO: Pod sonobuoy-systemd-logs-daemon-set-c5d3262a269044d7-l8bfz requesting resource cpu=0m on Node cncf-wk2
    STEP: Starting Pods to consume most of the cluster CPU. 01/10/23 05:00:51.458
    Jan 10 05:00:51.459: INFO: Creating a pod which consumes cpu=1071m on Node cncf-cp-etcd-wk1
    Jan 10 05:00:51.465: INFO: Creating a pod which consumes cpu=1225m on Node cncf-wk2
    Jan 10 05:00:51.485: INFO: Creating a pod which consumes cpu=1155m on Node cncf-wk3
    Jan 10 05:00:51.520: INFO: Waiting up to 5m0s for pod "filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70" in namespace "sched-pred-6762" to be "running"
    Jan 10 05:00:51.553: INFO: Pod "filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70": Phase="Pending", Reason="", readiness=false. Elapsed: 32.662781ms
    Jan 10 05:00:53.558: INFO: Pod "filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70": Phase="Running", Reason="", readiness=true. Elapsed: 2.037437586s
    Jan 10 05:00:53.558: INFO: Pod "filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70" satisfied condition "running"
    Jan 10 05:00:53.558: INFO: Waiting up to 5m0s for pod "filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938" in namespace "sched-pred-6762" to be "running"
    Jan 10 05:00:53.560: INFO: Pod "filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938": Phase="Running", Reason="", readiness=true. Elapsed: 2.394049ms
    Jan 10 05:00:53.561: INFO: Pod "filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938" satisfied condition "running"
    Jan 10 05:00:53.561: INFO: Waiting up to 5m0s for pod "filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2" in namespace "sched-pred-6762" to be "running"
    Jan 10 05:00:53.565: INFO: Pod "filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048379ms
    Jan 10 05:00:55.568: INFO: Pod "filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2": Phase="Running", Reason="", readiness=true. Elapsed: 2.007537951s
    Jan 10 05:00:55.568: INFO: Pod "filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 01/10/23 05:00:55.568
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2.1738d9e7e2d65637], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6762/filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2 to cncf-wk3] 01/10/23 05:00:55.571
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2.1738d9e8251c46e8], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/10/23 05:00:55.571
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2.1738d9e828ae17f7], Reason = [Created], Message = [Created container filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2] 01/10/23 05:00:55.571
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2.1738d9e82ec2d27d], Reason = [Started], Message = [Started container filler-pod-22ccd773-7bc2-4e8a-88f1-529fafd93af2] 01/10/23 05:00:55.571
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938.1738d9e7e1af0bba], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6762/filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938 to cncf-wk2] 01/10/23 05:00:55.571
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938.1738d9e80cff84cf], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/10/23 05:00:55.572
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938.1738d9e80fd77795], Reason = [Created], Message = [Created container filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938] 01/10/23 05:00:55.572
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938.1738d9e815e236c7], Reason = [Started], Message = [Started container filler-pod-bf4856a8-2598-469f-8362-23a1ce5e0938] 01/10/23 05:00:55.572
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70.1738d9e7df638dd5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6762/filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70 to cncf-cp-etcd-wk1] 01/10/23 05:00:55.572
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70.1738d9e8116d48c9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/10/23 05:00:55.572
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70.1738d9e815b35fa1], Reason = [Created], Message = [Created container filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70] 01/10/23 05:00:55.572
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70.1738d9e81e5c9f2a], Reason = [Started], Message = [Started container filler-pod-ec58f4fa-a830-4106-95f3-db5096d67b70] 01/10/23 05:00:55.572
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.1738d9e8d3e8d2bd], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 01/10/23 05:00:55.587
    STEP: removing the label node off the node cncf-cp-etcd-wk1 01/10/23 05:00:56.584
    STEP: verifying the node doesn't have the label node 01/10/23 05:00:56.604
    STEP: removing the label node off the node cncf-wk2 01/10/23 05:00:56.614
    STEP: verifying the node doesn't have the label node 01/10/23 05:00:56.699
    STEP: removing the label node off the node cncf-wk3 01/10/23 05:00:56.713
    STEP: verifying the node doesn't have the label node 01/10/23 05:00:56.763
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 05:00:56.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-6762" for this suite. 01/10/23 05:00:56.781
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:00:56.802
Jan 10 05:00:56.802: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 05:00:56.816
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:00:56.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:00:56.865
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-da08397b-a1f6-46a9-9ae3-20c5a4df436d 01/10/23 05:00:56.884
STEP: Creating a pod to test consume configMaps 01/10/23 05:00:56.89
Jan 10 05:00:56.902: INFO: Waiting up to 5m0s for pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342" in namespace "configmap-69" to be "Succeeded or Failed"
Jan 10 05:00:56.918: INFO: Pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342": Phase="Pending", Reason="", readiness=false. Elapsed: 15.787352ms
Jan 10 05:00:58.921: INFO: Pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018628005s
Jan 10 05:01:00.922: INFO: Pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019526267s
STEP: Saw pod success 01/10/23 05:01:00.922
Jan 10 05:01:00.922: INFO: Pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342" satisfied condition "Succeeded or Failed"
Jan 10 05:01:00.924: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342 container configmap-volume-test: <nil>
STEP: delete the pod 01/10/23 05:01:00.93
Jan 10 05:01:00.951: INFO: Waiting for pod pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342 to disappear
Jan 10 05:01:00.957: INFO: Pod pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 05:01:00.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-69" for this suite. 01/10/23 05:01:00.967
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":311,"skipped":5687,"failed":0}
------------------------------
• [4.173 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:00:56.802
    Jan 10 05:00:56.802: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 05:00:56.816
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:00:56.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:00:56.865
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-da08397b-a1f6-46a9-9ae3-20c5a4df436d 01/10/23 05:00:56.884
    STEP: Creating a pod to test consume configMaps 01/10/23 05:00:56.89
    Jan 10 05:00:56.902: INFO: Waiting up to 5m0s for pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342" in namespace "configmap-69" to be "Succeeded or Failed"
    Jan 10 05:00:56.918: INFO: Pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342": Phase="Pending", Reason="", readiness=false. Elapsed: 15.787352ms
    Jan 10 05:00:58.921: INFO: Pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018628005s
    Jan 10 05:01:00.922: INFO: Pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019526267s
    STEP: Saw pod success 01/10/23 05:01:00.922
    Jan 10 05:01:00.922: INFO: Pod "pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342" satisfied condition "Succeeded or Failed"
    Jan 10 05:01:00.924: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342 container configmap-volume-test: <nil>
    STEP: delete the pod 01/10/23 05:01:00.93
    Jan 10 05:01:00.951: INFO: Waiting for pod pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342 to disappear
    Jan 10 05:01:00.957: INFO: Pod pod-configmaps-033f33d3-144e-478f-9269-37a46cf49342 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 05:01:00.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-69" for this suite. 01/10/23 05:01:00.967
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:00.984
Jan 10 05:01:00.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename gc 01/10/23 05:01:00.985
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:01.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:01.018
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 01/10/23 05:01:01.024
STEP: Wait for the Deployment to create new ReplicaSet 01/10/23 05:01:01.032
STEP: delete the deployment 01/10/23 05:01:01.546
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 01/10/23 05:01:01.558
STEP: Gathering metrics 01/10/23 05:01:02.15
W0110 05:01:02.168419      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 10 05:01:02.168: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 10 05:01:02.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5553" for this suite. 01/10/23 05:01:02.178
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":312,"skipped":5714,"failed":0}
------------------------------
• [1.203 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:00.984
    Jan 10 05:01:00.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename gc 01/10/23 05:01:00.985
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:01.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:01.018
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 01/10/23 05:01:01.024
    STEP: Wait for the Deployment to create new ReplicaSet 01/10/23 05:01:01.032
    STEP: delete the deployment 01/10/23 05:01:01.546
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 01/10/23 05:01:01.558
    STEP: Gathering metrics 01/10/23 05:01:02.15
    W0110 05:01:02.168419      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 10 05:01:02.168: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 10 05:01:02.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5553" for this suite. 01/10/23 05:01:02.178
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:02.187
Jan 10 05:01:02.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 05:01:02.188
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:02.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:02.323
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 01/10/23 05:01:02.351
STEP: setting up watch 01/10/23 05:01:02.351
STEP: submitting the pod to kubernetes 01/10/23 05:01:02.456
STEP: verifying the pod is in kubernetes 01/10/23 05:01:02.474
STEP: verifying pod creation was observed 01/10/23 05:01:02.491
Jan 10 05:01:02.492: INFO: Waiting up to 5m0s for pod "pod-submit-remove-83d8c086-e956-43ad-9ff8-2df0eb1aba77" in namespace "pods-5699" to be "running"
Jan 10 05:01:02.506: INFO: Pod "pod-submit-remove-83d8c086-e956-43ad-9ff8-2df0eb1aba77": Phase="Pending", Reason="", readiness=false. Elapsed: 14.160451ms
Jan 10 05:01:04.529: INFO: Pod "pod-submit-remove-83d8c086-e956-43ad-9ff8-2df0eb1aba77": Phase="Running", Reason="", readiness=true. Elapsed: 2.037103641s
Jan 10 05:01:04.529: INFO: Pod "pod-submit-remove-83d8c086-e956-43ad-9ff8-2df0eb1aba77" satisfied condition "running"
STEP: deleting the pod gracefully 01/10/23 05:01:04.531
STEP: verifying pod deletion was observed 01/10/23 05:01:04.535
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 05:01:07.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5699" for this suite. 01/10/23 05:01:07.292
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":313,"skipped":5714,"failed":0}
------------------------------
• [SLOW TEST] [5.115 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:02.187
    Jan 10 05:01:02.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 05:01:02.188
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:02.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:02.323
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 01/10/23 05:01:02.351
    STEP: setting up watch 01/10/23 05:01:02.351
    STEP: submitting the pod to kubernetes 01/10/23 05:01:02.456
    STEP: verifying the pod is in kubernetes 01/10/23 05:01:02.474
    STEP: verifying pod creation was observed 01/10/23 05:01:02.491
    Jan 10 05:01:02.492: INFO: Waiting up to 5m0s for pod "pod-submit-remove-83d8c086-e956-43ad-9ff8-2df0eb1aba77" in namespace "pods-5699" to be "running"
    Jan 10 05:01:02.506: INFO: Pod "pod-submit-remove-83d8c086-e956-43ad-9ff8-2df0eb1aba77": Phase="Pending", Reason="", readiness=false. Elapsed: 14.160451ms
    Jan 10 05:01:04.529: INFO: Pod "pod-submit-remove-83d8c086-e956-43ad-9ff8-2df0eb1aba77": Phase="Running", Reason="", readiness=true. Elapsed: 2.037103641s
    Jan 10 05:01:04.529: INFO: Pod "pod-submit-remove-83d8c086-e956-43ad-9ff8-2df0eb1aba77" satisfied condition "running"
    STEP: deleting the pod gracefully 01/10/23 05:01:04.531
    STEP: verifying pod deletion was observed 01/10/23 05:01:04.535
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 05:01:07.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5699" for this suite. 01/10/23 05:01:07.292
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:07.302
Jan 10 05:01:07.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 05:01:07.303
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:07.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:07.354
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 01/10/23 05:01:07.361
Jan 10 05:01:07.361: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Jan 10 05:01:07.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
Jan 10 05:01:07.792: INFO: stderr: ""
Jan 10 05:01:07.792: INFO: stdout: "service/agnhost-replica created\n"
Jan 10 05:01:07.792: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Jan 10 05:01:07.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
Jan 10 05:01:08.191: INFO: stderr: ""
Jan 10 05:01:08.191: INFO: stdout: "service/agnhost-primary created\n"
Jan 10 05:01:08.191: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 10 05:01:08.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
Jan 10 05:01:08.425: INFO: stderr: ""
Jan 10 05:01:08.425: INFO: stdout: "service/frontend created\n"
Jan 10 05:01:08.425: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Jan 10 05:01:08.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
Jan 10 05:01:08.706: INFO: stderr: ""
Jan 10 05:01:08.706: INFO: stdout: "deployment.apps/frontend created\n"
Jan 10 05:01:08.706: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 10 05:01:08.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
Jan 10 05:01:08.966: INFO: stderr: ""
Jan 10 05:01:08.966: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Jan 10 05:01:08.967: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 10 05:01:08.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
Jan 10 05:01:09.363: INFO: stderr: ""
Jan 10 05:01:09.363: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 01/10/23 05:01:09.363
Jan 10 05:01:09.363: INFO: Waiting for all frontend pods to be Running.
Jan 10 05:01:14.415: INFO: Waiting for frontend to serve content.
Jan 10 05:01:14.423: INFO: Trying to add a new entry to the guestbook.
Jan 10 05:01:14.446: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 01/10/23 05:01:14.46
Jan 10 05:01:14.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
Jan 10 05:01:14.583: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 05:01:14.583: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 01/10/23 05:01:14.583
Jan 10 05:01:14.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
Jan 10 05:01:14.705: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 05:01:14.705: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 01/10/23 05:01:14.705
Jan 10 05:01:14.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
Jan 10 05:01:14.800: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 05:01:14.800: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 01/10/23 05:01:14.8
Jan 10 05:01:14.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
Jan 10 05:01:14.871: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 05:01:14.871: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 01/10/23 05:01:14.871
Jan 10 05:01:14.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
Jan 10 05:01:15.029: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 05:01:15.030: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 01/10/23 05:01:15.03
Jan 10 05:01:15.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
Jan 10 05:01:15.172: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 05:01:15.172: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 05:01:15.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2439" for this suite. 01/10/23 05:01:15.178
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":314,"skipped":5720,"failed":0}
------------------------------
• [SLOW TEST] [7.888 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:07.302
    Jan 10 05:01:07.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 05:01:07.303
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:07.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:07.354
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 01/10/23 05:01:07.361
    Jan 10 05:01:07.361: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Jan 10 05:01:07.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
    Jan 10 05:01:07.792: INFO: stderr: ""
    Jan 10 05:01:07.792: INFO: stdout: "service/agnhost-replica created\n"
    Jan 10 05:01:07.792: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Jan 10 05:01:07.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
    Jan 10 05:01:08.191: INFO: stderr: ""
    Jan 10 05:01:08.191: INFO: stdout: "service/agnhost-primary created\n"
    Jan 10 05:01:08.191: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Jan 10 05:01:08.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
    Jan 10 05:01:08.425: INFO: stderr: ""
    Jan 10 05:01:08.425: INFO: stdout: "service/frontend created\n"
    Jan 10 05:01:08.425: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Jan 10 05:01:08.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
    Jan 10 05:01:08.706: INFO: stderr: ""
    Jan 10 05:01:08.706: INFO: stdout: "deployment.apps/frontend created\n"
    Jan 10 05:01:08.706: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Jan 10 05:01:08.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
    Jan 10 05:01:08.966: INFO: stderr: ""
    Jan 10 05:01:08.966: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Jan 10 05:01:08.967: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Jan 10 05:01:08.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 create -f -'
    Jan 10 05:01:09.363: INFO: stderr: ""
    Jan 10 05:01:09.363: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 01/10/23 05:01:09.363
    Jan 10 05:01:09.363: INFO: Waiting for all frontend pods to be Running.
    Jan 10 05:01:14.415: INFO: Waiting for frontend to serve content.
    Jan 10 05:01:14.423: INFO: Trying to add a new entry to the guestbook.
    Jan 10 05:01:14.446: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 01/10/23 05:01:14.46
    Jan 10 05:01:14.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
    Jan 10 05:01:14.583: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 05:01:14.583: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 01/10/23 05:01:14.583
    Jan 10 05:01:14.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
    Jan 10 05:01:14.705: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 05:01:14.705: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 01/10/23 05:01:14.705
    Jan 10 05:01:14.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
    Jan 10 05:01:14.800: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 05:01:14.800: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 01/10/23 05:01:14.8
    Jan 10 05:01:14.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
    Jan 10 05:01:14.871: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 05:01:14.871: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 01/10/23 05:01:14.871
    Jan 10 05:01:14.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
    Jan 10 05:01:15.029: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 05:01:15.030: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 01/10/23 05:01:15.03
    Jan 10 05:01:15.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-2439 delete --grace-period=0 --force -f -'
    Jan 10 05:01:15.172: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 05:01:15.172: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 05:01:15.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2439" for this suite. 01/10/23 05:01:15.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:15.191
Jan 10 05:01:15.191: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename namespaces 01/10/23 05:01:15.192
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:15.286
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:15.289
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 01/10/23 05:01:15.309
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:15.394
STEP: Creating a pod in the namespace 01/10/23 05:01:15.418
STEP: Waiting for the pod to have running status 01/10/23 05:01:15.494
Jan 10 05:01:15.494: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-1859" to be "running"
Jan 10 05:01:15.512: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 17.829928ms
Jan 10 05:01:17.516: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021612084s
Jan 10 05:01:17.516: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 01/10/23 05:01:17.516
STEP: Waiting for the namespace to be removed. 01/10/23 05:01:17.523
STEP: Recreating the namespace 01/10/23 05:01:28.526
STEP: Verifying there are no pods in the namespace 01/10/23 05:01:28.562
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jan 10 05:01:28.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-216" for this suite. 01/10/23 05:01:28.574
STEP: Destroying namespace "nsdeletetest-1859" for this suite. 01/10/23 05:01:28.583
Jan 10 05:01:28.626: INFO: Namespace nsdeletetest-1859 was already deleted
STEP: Destroying namespace "nsdeletetest-543" for this suite. 01/10/23 05:01:28.626
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":315,"skipped":5727,"failed":0}
------------------------------
• [SLOW TEST] [13.454 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:15.191
    Jan 10 05:01:15.191: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename namespaces 01/10/23 05:01:15.192
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:15.286
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:15.289
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 01/10/23 05:01:15.309
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:15.394
    STEP: Creating a pod in the namespace 01/10/23 05:01:15.418
    STEP: Waiting for the pod to have running status 01/10/23 05:01:15.494
    Jan 10 05:01:15.494: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-1859" to be "running"
    Jan 10 05:01:15.512: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 17.829928ms
    Jan 10 05:01:17.516: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021612084s
    Jan 10 05:01:17.516: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 01/10/23 05:01:17.516
    STEP: Waiting for the namespace to be removed. 01/10/23 05:01:17.523
    STEP: Recreating the namespace 01/10/23 05:01:28.526
    STEP: Verifying there are no pods in the namespace 01/10/23 05:01:28.562
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 05:01:28.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-216" for this suite. 01/10/23 05:01:28.574
    STEP: Destroying namespace "nsdeletetest-1859" for this suite. 01/10/23 05:01:28.583
    Jan 10 05:01:28.626: INFO: Namespace nsdeletetest-1859 was already deleted
    STEP: Destroying namespace "nsdeletetest-543" for this suite. 01/10/23 05:01:28.626
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:28.65
Jan 10 05:01:28.650: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubelet-test 01/10/23 05:01:28.652
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:28.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:28.74
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Jan 10 05:01:28.758: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5" in namespace "kubelet-test-8452" to be "running and ready"
Jan 10 05:01:28.784: INFO: Pod "busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 25.187512ms
Jan 10 05:01:28.784: INFO: The phase of Pod busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:01:30.787: INFO: Pod "busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5": Phase="Running", Reason="", readiness=true. Elapsed: 2.028554523s
Jan 10 05:01:30.787: INFO: The phase of Pod busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5 is Running (Ready = true)
Jan 10 05:01:30.787: INFO: Pod "busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 10 05:01:30.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8452" for this suite. 01/10/23 05:01:30.799
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":316,"skipped":5765,"failed":0}
------------------------------
• [2.153 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:28.65
    Jan 10 05:01:28.650: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubelet-test 01/10/23 05:01:28.652
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:28.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:28.74
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Jan 10 05:01:28.758: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5" in namespace "kubelet-test-8452" to be "running and ready"
    Jan 10 05:01:28.784: INFO: Pod "busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 25.187512ms
    Jan 10 05:01:28.784: INFO: The phase of Pod busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:01:30.787: INFO: Pod "busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5": Phase="Running", Reason="", readiness=true. Elapsed: 2.028554523s
    Jan 10 05:01:30.787: INFO: The phase of Pod busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5 is Running (Ready = true)
    Jan 10 05:01:30.787: INFO: Pod "busybox-readonly-fs03bcde85-2693-41e4-838b-b8a933baa1d5" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 10 05:01:30.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8452" for this suite. 01/10/23 05:01:30.799
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:30.804
Jan 10 05:01:30.804: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 05:01:30.805
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:30.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:30.84
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 01/10/23 05:01:30.844
Jan 10 05:01:30.851: INFO: Waiting up to 5m0s for pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd" in namespace "emptydir-3581" to be "Succeeded or Failed"
Jan 10 05:01:30.872: INFO: Pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.53666ms
Jan 10 05:01:32.876: INFO: Pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024244937s
Jan 10 05:01:34.876: INFO: Pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024724112s
STEP: Saw pod success 01/10/23 05:01:34.876
Jan 10 05:01:34.877: INFO: Pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd" satisfied condition "Succeeded or Failed"
Jan 10 05:01:34.879: INFO: Trying to get logs from node cncf-wk2 pod pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd container test-container: <nil>
STEP: delete the pod 01/10/23 05:01:34.884
Jan 10 05:01:34.898: INFO: Waiting for pod pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd to disappear
Jan 10 05:01:34.901: INFO: Pod pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 05:01:34.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3581" for this suite. 01/10/23 05:01:34.908
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":317,"skipped":5773,"failed":0}
------------------------------
• [4.114 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:30.804
    Jan 10 05:01:30.804: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 05:01:30.805
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:30.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:30.84
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 01/10/23 05:01:30.844
    Jan 10 05:01:30.851: INFO: Waiting up to 5m0s for pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd" in namespace "emptydir-3581" to be "Succeeded or Failed"
    Jan 10 05:01:30.872: INFO: Pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.53666ms
    Jan 10 05:01:32.876: INFO: Pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024244937s
    Jan 10 05:01:34.876: INFO: Pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024724112s
    STEP: Saw pod success 01/10/23 05:01:34.876
    Jan 10 05:01:34.877: INFO: Pod "pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd" satisfied condition "Succeeded or Failed"
    Jan 10 05:01:34.879: INFO: Trying to get logs from node cncf-wk2 pod pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd container test-container: <nil>
    STEP: delete the pod 01/10/23 05:01:34.884
    Jan 10 05:01:34.898: INFO: Waiting for pod pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd to disappear
    Jan 10 05:01:34.901: INFO: Pod pod-08ded61e-4e9e-41c7-b0d9-93d3476b08cd no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 05:01:34.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3581" for this suite. 01/10/23 05:01:34.908
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:34.922
Jan 10 05:01:34.922: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 05:01:34.923
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:34.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:34.963
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 05:01:35.01
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:01:35.459
STEP: Deploying the webhook pod 01/10/23 05:01:35.466
STEP: Wait for the deployment to be ready 01/10/23 05:01:35.476
Jan 10 05:01:35.481: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 01/10/23 05:01:37.491
STEP: Verifying the service has paired with the endpoint 01/10/23 05:01:37.507
Jan 10 05:01:38.509: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 01/10/23 05:01:38.512
STEP: Creating a custom resource definition that should be denied by the webhook 01/10/23 05:01:38.53
Jan 10 05:01:38.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 05:01:38.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1735" for this suite. 01/10/23 05:01:38.576
STEP: Destroying namespace "webhook-1735-markers" for this suite. 01/10/23 05:01:38.591
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":318,"skipped":5778,"failed":0}
------------------------------
• [3.796 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:34.922
    Jan 10 05:01:34.922: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 05:01:34.923
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:34.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:34.963
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 05:01:35.01
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:01:35.459
    STEP: Deploying the webhook pod 01/10/23 05:01:35.466
    STEP: Wait for the deployment to be ready 01/10/23 05:01:35.476
    Jan 10 05:01:35.481: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 01/10/23 05:01:37.491
    STEP: Verifying the service has paired with the endpoint 01/10/23 05:01:37.507
    Jan 10 05:01:38.509: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 01/10/23 05:01:38.512
    STEP: Creating a custom resource definition that should be denied by the webhook 01/10/23 05:01:38.53
    Jan 10 05:01:38.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 05:01:38.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1735" for this suite. 01/10/23 05:01:38.576
    STEP: Destroying namespace "webhook-1735-markers" for this suite. 01/10/23 05:01:38.591
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:38.719
Jan 10 05:01:38.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename services 01/10/23 05:01:38.72
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:38.747
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:38.75
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-2782 01/10/23 05:01:38.753
STEP: creating service affinity-nodeport-transition in namespace services-2782 01/10/23 05:01:38.754
STEP: creating replication controller affinity-nodeport-transition in namespace services-2782 01/10/23 05:01:38.775
I0110 05:01:38.796297      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2782, replica count: 3
I0110 05:01:41.847413      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 10 05:01:41.870: INFO: Creating new exec pod
Jan 10 05:01:41.877: INFO: Waiting up to 5m0s for pod "execpod-affinitypt6m4" in namespace "services-2782" to be "running"
Jan 10 05:01:41.884: INFO: Pod "execpod-affinitypt6m4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.240761ms
Jan 10 05:01:43.895: INFO: Pod "execpod-affinitypt6m4": Phase="Running", Reason="", readiness=true. Elapsed: 2.017449964s
Jan 10 05:01:43.895: INFO: Pod "execpod-affinitypt6m4" satisfied condition "running"
Jan 10 05:01:44.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Jan 10 05:01:45.050: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Jan 10 05:01:45.050: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 05:01:45.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.185.194 80'
Jan 10 05:01:45.319: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.185.194 80\nConnection to 10.43.185.194 80 port [tcp/http] succeeded!\n"
Jan 10 05:01:45.319: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 05:01:45.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 31087'
Jan 10 05:01:45.476: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 31087\nConnection to 172.31.3.44 31087 port [tcp/*] succeeded!\n"
Jan 10 05:01:45.476: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 05:01:45.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.114 31087'
Jan 10 05:01:45.627: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.7.114 31087\nConnection to 172.31.7.114 31087 port [tcp/*] succeeded!\n"
Jan 10 05:01:45.627: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 10 05:01:45.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.15.218:31087/ ; done'
Jan 10 05:01:45.972: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n"
Jan 10 05:01:45.972: INFO: stdout: "\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-x99d2\naffinity-nodeport-transition-x99d2\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-x99d2\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-cftcr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-x99d2\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-cftcr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-cftcr\naffinity-nodeport-transition-qqthr"
Jan 10 05:01:45.972: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-x99d2
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-x99d2
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-x99d2
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-cftcr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-x99d2
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-cftcr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-cftcr
Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.15.218:31087/ ; done'
Jan 10 05:01:46.248: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n"
Jan 10 05:01:46.248: INFO: stdout: "\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr"
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
Jan 10 05:01:46.248: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2782, will wait for the garbage collector to delete the pods 01/10/23 05:01:46.261
Jan 10 05:01:46.320: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.095075ms
Jan 10 05:01:46.421: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.5406ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 10 05:01:48.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2782" for this suite. 01/10/23 05:01:48.27
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":319,"skipped":5781,"failed":0}
------------------------------
• [SLOW TEST] [9.560 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:38.719
    Jan 10 05:01:38.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename services 01/10/23 05:01:38.72
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:38.747
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:38.75
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-2782 01/10/23 05:01:38.753
    STEP: creating service affinity-nodeport-transition in namespace services-2782 01/10/23 05:01:38.754
    STEP: creating replication controller affinity-nodeport-transition in namespace services-2782 01/10/23 05:01:38.775
    I0110 05:01:38.796297      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2782, replica count: 3
    I0110 05:01:41.847413      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 10 05:01:41.870: INFO: Creating new exec pod
    Jan 10 05:01:41.877: INFO: Waiting up to 5m0s for pod "execpod-affinitypt6m4" in namespace "services-2782" to be "running"
    Jan 10 05:01:41.884: INFO: Pod "execpod-affinitypt6m4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.240761ms
    Jan 10 05:01:43.895: INFO: Pod "execpod-affinitypt6m4": Phase="Running", Reason="", readiness=true. Elapsed: 2.017449964s
    Jan 10 05:01:43.895: INFO: Pod "execpod-affinitypt6m4" satisfied condition "running"
    Jan 10 05:01:44.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Jan 10 05:01:45.050: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Jan 10 05:01:45.050: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 05:01:45.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.185.194 80'
    Jan 10 05:01:45.319: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.185.194 80\nConnection to 10.43.185.194 80 port [tcp/http] succeeded!\n"
    Jan 10 05:01:45.319: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 05:01:45.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.3.44 31087'
    Jan 10 05:01:45.476: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.3.44 31087\nConnection to 172.31.3.44 31087 port [tcp/*] succeeded!\n"
    Jan 10 05:01:45.476: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 05:01:45.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.114 31087'
    Jan 10 05:01:45.627: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.7.114 31087\nConnection to 172.31.7.114 31087 port [tcp/*] succeeded!\n"
    Jan 10 05:01:45.627: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 10 05:01:45.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.15.218:31087/ ; done'
    Jan 10 05:01:45.972: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n"
    Jan 10 05:01:45.972: INFO: stdout: "\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-x99d2\naffinity-nodeport-transition-x99d2\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-x99d2\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-cftcr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-x99d2\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-cftcr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-cftcr\naffinity-nodeport-transition-qqthr"
    Jan 10 05:01:45.972: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-x99d2
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-x99d2
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-x99d2
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-cftcr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-x99d2
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-cftcr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-cftcr
    Jan 10 05:01:45.973: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=services-2782 exec execpod-affinitypt6m4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.15.218:31087/ ; done'
    Jan 10 05:01:46.248: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.15.218:31087/\n"
    Jan 10 05:01:46.248: INFO: stdout: "\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr\naffinity-nodeport-transition-qqthr"
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Received response from host: affinity-nodeport-transition-qqthr
    Jan 10 05:01:46.248: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2782, will wait for the garbage collector to delete the pods 01/10/23 05:01:46.261
    Jan 10 05:01:46.320: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.095075ms
    Jan 10 05:01:46.421: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.5406ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 10 05:01:48.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2782" for this suite. 01/10/23 05:01:48.27
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:48.283
Jan 10 05:01:48.283: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename secrets 01/10/23 05:01:48.284
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:48.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:48.325
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 10 05:01:48.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1435" for this suite. 01/10/23 05:01:48.444
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":320,"skipped":5792,"failed":0}
------------------------------
• [0.167 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:48.283
    Jan 10 05:01:48.283: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename secrets 01/10/23 05:01:48.284
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:48.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:48.325
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 10 05:01:48.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1435" for this suite. 01/10/23 05:01:48.444
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:48.456
Jan 10 05:01:48.457: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 05:01:48.458
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:48.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:48.576
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 05:01:48.617
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:01:48.799
STEP: Deploying the webhook pod 01/10/23 05:01:48.803
STEP: Wait for the deployment to be ready 01/10/23 05:01:48.814
Jan 10 05:01:48.842: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 05:01:50.854
STEP: Verifying the service has paired with the endpoint 01/10/23 05:01:50.909
Jan 10 05:01:51.909: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Jan 10 05:01:51.912: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8569-crds.webhook.example.com via the AdmissionRegistration API 01/10/23 05:01:52.439
Jan 10 05:01:52.591: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook 01/10/23 05:01:52.722
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 05:01:55.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2004" for this suite. 01/10/23 05:01:55.433
STEP: Destroying namespace "webhook-2004-markers" for this suite. 01/10/23 05:01:55.536
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":321,"skipped":5805,"failed":0}
------------------------------
• [SLOW TEST] [7.437 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:48.456
    Jan 10 05:01:48.457: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 05:01:48.458
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:48.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:48.576
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 05:01:48.617
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:01:48.799
    STEP: Deploying the webhook pod 01/10/23 05:01:48.803
    STEP: Wait for the deployment to be ready 01/10/23 05:01:48.814
    Jan 10 05:01:48.842: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 05:01:50.854
    STEP: Verifying the service has paired with the endpoint 01/10/23 05:01:50.909
    Jan 10 05:01:51.909: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Jan 10 05:01:51.912: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8569-crds.webhook.example.com via the AdmissionRegistration API 01/10/23 05:01:52.439
    Jan 10 05:01:52.591: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource that should be mutated by the webhook 01/10/23 05:01:52.722
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 05:01:55.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2004" for this suite. 01/10/23 05:01:55.433
    STEP: Destroying namespace "webhook-2004-markers" for this suite. 01/10/23 05:01:55.536
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:01:55.896
Jan 10 05:01:55.896: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename security-context 01/10/23 05:01:55.897
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:56.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:56.103
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 01/10/23 05:01:56.145
Jan 10 05:01:56.185: INFO: Waiting up to 5m0s for pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78" in namespace "security-context-5738" to be "Succeeded or Failed"
Jan 10 05:01:56.233: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78": Phase="Pending", Reason="", readiness=false. Elapsed: 47.614246ms
Jan 10 05:01:58.236: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050845038s
Jan 10 05:02:00.237: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052351713s
Jan 10 05:02:02.237: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051604339s
STEP: Saw pod success 01/10/23 05:02:02.237
Jan 10 05:02:02.237: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78" satisfied condition "Succeeded or Failed"
Jan 10 05:02:02.240: INFO: Trying to get logs from node cncf-wk2 pod security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78 container test-container: <nil>
STEP: delete the pod 01/10/23 05:02:02.249
Jan 10 05:02:02.266: INFO: Waiting for pod security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78 to disappear
Jan 10 05:02:02.269: INFO: Pod security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 10 05:02:02.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5738" for this suite. 01/10/23 05:02:02.275
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":322,"skipped":5856,"failed":0}
------------------------------
• [SLOW TEST] [6.383 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:01:55.896
    Jan 10 05:01:55.896: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename security-context 01/10/23 05:01:55.897
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:01:56.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:01:56.103
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 01/10/23 05:01:56.145
    Jan 10 05:01:56.185: INFO: Waiting up to 5m0s for pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78" in namespace "security-context-5738" to be "Succeeded or Failed"
    Jan 10 05:01:56.233: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78": Phase="Pending", Reason="", readiness=false. Elapsed: 47.614246ms
    Jan 10 05:01:58.236: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050845038s
    Jan 10 05:02:00.237: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052351713s
    Jan 10 05:02:02.237: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051604339s
    STEP: Saw pod success 01/10/23 05:02:02.237
    Jan 10 05:02:02.237: INFO: Pod "security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78" satisfied condition "Succeeded or Failed"
    Jan 10 05:02:02.240: INFO: Trying to get logs from node cncf-wk2 pod security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78 container test-container: <nil>
    STEP: delete the pod 01/10/23 05:02:02.249
    Jan 10 05:02:02.266: INFO: Waiting for pod security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78 to disappear
    Jan 10 05:02:02.269: INFO: Pod security-context-c7108a1a-bbea-496a-9cf4-026f8d614f78 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 10 05:02:02.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5738" for this suite. 01/10/23 05:02:02.275
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:02:02.281
Jan 10 05:02:02.281: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 05:02:02.282
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:02:02.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:02:02.338
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-02003a81-8e01-46e4-a0ef-0fabc7b167f5 01/10/23 05:02:02.348
STEP: Creating secret with name s-test-opt-upd-5a13280e-6c37-45c7-9fbd-878dec10bd27 01/10/23 05:02:02.37
STEP: Creating the pod 01/10/23 05:02:02.396
Jan 10 05:02:02.432: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0" in namespace "projected-8462" to be "running and ready"
Jan 10 05:02:02.453: INFO: Pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0": Phase="Pending", Reason="", readiness=false. Elapsed: 21.361737ms
Jan 10 05:02:02.454: INFO: The phase of Pod pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:02:04.471: INFO: Pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038812544s
Jan 10 05:02:04.471: INFO: The phase of Pod pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:02:06.457: INFO: Pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0": Phase="Running", Reason="", readiness=true. Elapsed: 4.025149085s
Jan 10 05:02:06.457: INFO: The phase of Pod pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0 is Running (Ready = true)
Jan 10 05:02:06.457: INFO: Pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-02003a81-8e01-46e4-a0ef-0fabc7b167f5 01/10/23 05:02:06.482
STEP: Updating secret s-test-opt-upd-5a13280e-6c37-45c7-9fbd-878dec10bd27 01/10/23 05:02:06.488
STEP: Creating secret with name s-test-opt-create-f197774a-a94d-40a7-97a1-06b2089b1b85 01/10/23 05:02:06.494
STEP: waiting to observe update in volume 01/10/23 05:02:06.5
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 10 05:03:22.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8462" for this suite. 01/10/23 05:03:22.908
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":323,"skipped":5898,"failed":0}
------------------------------
• [SLOW TEST] [80.635 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:02:02.281
    Jan 10 05:02:02.281: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 05:02:02.282
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:02:02.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:02:02.338
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-02003a81-8e01-46e4-a0ef-0fabc7b167f5 01/10/23 05:02:02.348
    STEP: Creating secret with name s-test-opt-upd-5a13280e-6c37-45c7-9fbd-878dec10bd27 01/10/23 05:02:02.37
    STEP: Creating the pod 01/10/23 05:02:02.396
    Jan 10 05:02:02.432: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0" in namespace "projected-8462" to be "running and ready"
    Jan 10 05:02:02.453: INFO: Pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0": Phase="Pending", Reason="", readiness=false. Elapsed: 21.361737ms
    Jan 10 05:02:02.454: INFO: The phase of Pod pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:02:04.471: INFO: Pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038812544s
    Jan 10 05:02:04.471: INFO: The phase of Pod pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:02:06.457: INFO: Pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0": Phase="Running", Reason="", readiness=true. Elapsed: 4.025149085s
    Jan 10 05:02:06.457: INFO: The phase of Pod pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0 is Running (Ready = true)
    Jan 10 05:02:06.457: INFO: Pod "pod-projected-secrets-8081e7b6-713c-42e6-8aaf-4b74632136d0" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-02003a81-8e01-46e4-a0ef-0fabc7b167f5 01/10/23 05:02:06.482
    STEP: Updating secret s-test-opt-upd-5a13280e-6c37-45c7-9fbd-878dec10bd27 01/10/23 05:02:06.488
    STEP: Creating secret with name s-test-opt-create-f197774a-a94d-40a7-97a1-06b2089b1b85 01/10/23 05:02:06.494
    STEP: waiting to observe update in volume 01/10/23 05:02:06.5
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 10 05:03:22.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8462" for this suite. 01/10/23 05:03:22.908
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:03:22.923
Jan 10 05:03:22.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename job 01/10/23 05:03:22.926
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:03:22.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:03:23.003
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 01/10/23 05:03:23.009
STEP: Patching the Job 01/10/23 05:03:23.014
STEP: Watching for Job to be patched 01/10/23 05:03:23.032
Jan 10 05:03:23.034: INFO: Event ADDED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2] and annotations: map[batch.kubernetes.io/job-tracking:]
Jan 10 05:03:23.034: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2] and annotations: map[batch.kubernetes.io/job-tracking:]
Jan 10 05:03:23.034: INFO: Event MODIFIED found for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 01/10/23 05:03:23.034
STEP: Watching for Job to be updated 01/10/23 05:03:23.047
Jan 10 05:03:23.049: INFO: Event MODIFIED found for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 10 05:03:23.049: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 01/10/23 05:03:23.049
Jan 10 05:03:23.052: INFO: Job: e2e-r85x2 as labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched]
STEP: Waiting for job to complete 01/10/23 05:03:23.052
STEP: Delete a job collection with a labelselector 01/10/23 05:03:33.055
STEP: Watching for Job to be deleted 01/10/23 05:03:33.061
Jan 10 05:03:33.063: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 10 05:03:33.063: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 10 05:03:33.065: INFO: Event DELETED found for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 01/10/23 05:03:33.065
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 10 05:03:33.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9615" for this suite. 01/10/23 05:03:33.075
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":324,"skipped":5954,"failed":0}
------------------------------
• [SLOW TEST] [10.175 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:03:22.923
    Jan 10 05:03:22.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename job 01/10/23 05:03:22.926
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:03:22.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:03:23.003
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 01/10/23 05:03:23.009
    STEP: Patching the Job 01/10/23 05:03:23.014
    STEP: Watching for Job to be patched 01/10/23 05:03:23.032
    Jan 10 05:03:23.034: INFO: Event ADDED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2] and annotations: map[batch.kubernetes.io/job-tracking:]
    Jan 10 05:03:23.034: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2] and annotations: map[batch.kubernetes.io/job-tracking:]
    Jan 10 05:03:23.034: INFO: Event MODIFIED found for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 01/10/23 05:03:23.034
    STEP: Watching for Job to be updated 01/10/23 05:03:23.047
    Jan 10 05:03:23.049: INFO: Event MODIFIED found for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 10 05:03:23.049: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 01/10/23 05:03:23.049
    Jan 10 05:03:23.052: INFO: Job: e2e-r85x2 as labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched]
    STEP: Waiting for job to complete 01/10/23 05:03:23.052
    STEP: Delete a job collection with a labelselector 01/10/23 05:03:33.055
    STEP: Watching for Job to be deleted 01/10/23 05:03:33.061
    Jan 10 05:03:33.063: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 10 05:03:33.063: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 10 05:03:33.065: INFO: Event MODIFIED observed for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 10 05:03:33.065: INFO: Event DELETED found for Job e2e-r85x2 in namespace job-9615 with labels: map[e2e-job-label:e2e-r85x2 e2e-r85x2:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 01/10/23 05:03:33.065
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 10 05:03:33.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9615" for this suite. 01/10/23 05:03:33.075
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:03:33.102
Jan 10 05:03:33.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 05:03:33.103
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:03:33.298
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:03:33.37
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-c1934cdf-675d-4ed2-bddd-12a7e91b65d7 01/10/23 05:03:33.381
STEP: Creating a pod to test consume secrets 01/10/23 05:03:33.39
Jan 10 05:03:33.425: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2" in namespace "projected-1070" to be "Succeeded or Failed"
Jan 10 05:03:33.449: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2": Phase="Pending", Reason="", readiness=false. Elapsed: 23.81076ms
Jan 10 05:03:35.452: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027081333s
Jan 10 05:03:37.452: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026906716s
Jan 10 05:03:39.454: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028535663s
STEP: Saw pod success 01/10/23 05:03:39.454
Jan 10 05:03:39.454: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2" satisfied condition "Succeeded or Failed"
Jan 10 05:03:39.459: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2 container projected-secret-volume-test: <nil>
STEP: delete the pod 01/10/23 05:03:39.469
Jan 10 05:03:39.483: INFO: Waiting for pod pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2 to disappear
Jan 10 05:03:39.485: INFO: Pod pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 10 05:03:39.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1070" for this suite. 01/10/23 05:03:39.489
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":325,"skipped":5984,"failed":0}
------------------------------
• [SLOW TEST] [6.393 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:03:33.102
    Jan 10 05:03:33.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 05:03:33.103
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:03:33.298
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:03:33.37
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-c1934cdf-675d-4ed2-bddd-12a7e91b65d7 01/10/23 05:03:33.381
    STEP: Creating a pod to test consume secrets 01/10/23 05:03:33.39
    Jan 10 05:03:33.425: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2" in namespace "projected-1070" to be "Succeeded or Failed"
    Jan 10 05:03:33.449: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2": Phase="Pending", Reason="", readiness=false. Elapsed: 23.81076ms
    Jan 10 05:03:35.452: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027081333s
    Jan 10 05:03:37.452: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026906716s
    Jan 10 05:03:39.454: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028535663s
    STEP: Saw pod success 01/10/23 05:03:39.454
    Jan 10 05:03:39.454: INFO: Pod "pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2" satisfied condition "Succeeded or Failed"
    Jan 10 05:03:39.459: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2 container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/10/23 05:03:39.469
    Jan 10 05:03:39.483: INFO: Waiting for pod pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2 to disappear
    Jan 10 05:03:39.485: INFO: Pod pod-projected-secrets-fc854117-9dbd-4402-b7e2-39c09d6f71f2 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 10 05:03:39.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1070" for this suite. 01/10/23 05:03:39.489
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:03:39.499
Jan 10 05:03:39.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-probe 01/10/23 05:03:39.5
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:03:39.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:03:39.523
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 10 05:04:39.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-133" for this suite. 01/10/23 05:04:39.546
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":326,"skipped":6016,"failed":0}
------------------------------
• [SLOW TEST] [60.051 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:03:39.499
    Jan 10 05:03:39.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-probe 01/10/23 05:03:39.5
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:03:39.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:03:39.523
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 10 05:04:39.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-133" for this suite. 01/10/23 05:04:39.546
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:04:39.559
Jan 10 05:04:39.559: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename configmap 01/10/23 05:04:39.561
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:04:39.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:04:39.632
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-5990/configmap-test-13cf4bee-e23e-4b65-bac1-976bcdeb0ca7 01/10/23 05:04:39.638
STEP: Creating a pod to test consume configMaps 01/10/23 05:04:39.642
Jan 10 05:04:39.661: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066" in namespace "configmap-5990" to be "Succeeded or Failed"
Jan 10 05:04:39.670: INFO: Pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066": Phase="Pending", Reason="", readiness=false. Elapsed: 8.656636ms
Jan 10 05:04:41.673: INFO: Pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011763184s
Jan 10 05:04:43.673: INFO: Pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011866999s
STEP: Saw pod success 01/10/23 05:04:43.673
Jan 10 05:04:43.674: INFO: Pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066" satisfied condition "Succeeded or Failed"
Jan 10 05:04:43.676: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066 container env-test: <nil>
STEP: delete the pod 01/10/23 05:04:43.684
Jan 10 05:04:43.694: INFO: Waiting for pod pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066 to disappear
Jan 10 05:04:43.697: INFO: Pod pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jan 10 05:04:43.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5990" for this suite. 01/10/23 05:04:43.701
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":327,"skipped":6038,"failed":0}
------------------------------
• [4.146 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:04:39.559
    Jan 10 05:04:39.559: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename configmap 01/10/23 05:04:39.561
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:04:39.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:04:39.632
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-5990/configmap-test-13cf4bee-e23e-4b65-bac1-976bcdeb0ca7 01/10/23 05:04:39.638
    STEP: Creating a pod to test consume configMaps 01/10/23 05:04:39.642
    Jan 10 05:04:39.661: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066" in namespace "configmap-5990" to be "Succeeded or Failed"
    Jan 10 05:04:39.670: INFO: Pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066": Phase="Pending", Reason="", readiness=false. Elapsed: 8.656636ms
    Jan 10 05:04:41.673: INFO: Pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011763184s
    Jan 10 05:04:43.673: INFO: Pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011866999s
    STEP: Saw pod success 01/10/23 05:04:43.673
    Jan 10 05:04:43.674: INFO: Pod "pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066" satisfied condition "Succeeded or Failed"
    Jan 10 05:04:43.676: INFO: Trying to get logs from node cncf-wk2 pod pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066 container env-test: <nil>
    STEP: delete the pod 01/10/23 05:04:43.684
    Jan 10 05:04:43.694: INFO: Waiting for pod pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066 to disappear
    Jan 10 05:04:43.697: INFO: Pod pod-configmaps-5c992f7d-898b-493f-a0ed-328e6c38f066 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 10 05:04:43.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5990" for this suite. 01/10/23 05:04:43.701
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:04:43.71
Jan 10 05:04:43.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 05:04:43.711
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:04:43.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:04:43.747
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 01/10/23 05:05:00.755
STEP: Creating a ResourceQuota 01/10/23 05:05:05.758
STEP: Ensuring resource quota status is calculated 01/10/23 05:05:05.768
STEP: Creating a ConfigMap 01/10/23 05:05:07.771
STEP: Ensuring resource quota status captures configMap creation 01/10/23 05:05:07.789
STEP: Deleting a ConfigMap 01/10/23 05:05:09.794
STEP: Ensuring resource quota status released usage 01/10/23 05:05:09.802
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 05:05:11.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4673" for this suite. 01/10/23 05:05:11.811
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":328,"skipped":6078,"failed":0}
------------------------------
• [SLOW TEST] [28.107 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:04:43.71
    Jan 10 05:04:43.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 05:04:43.711
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:04:43.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:04:43.747
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 01/10/23 05:05:00.755
    STEP: Creating a ResourceQuota 01/10/23 05:05:05.758
    STEP: Ensuring resource quota status is calculated 01/10/23 05:05:05.768
    STEP: Creating a ConfigMap 01/10/23 05:05:07.771
    STEP: Ensuring resource quota status captures configMap creation 01/10/23 05:05:07.789
    STEP: Deleting a ConfigMap 01/10/23 05:05:09.794
    STEP: Ensuring resource quota status released usage 01/10/23 05:05:09.802
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 05:05:11.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4673" for this suite. 01/10/23 05:05:11.811
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:05:11.819
Jan 10 05:05:11.819: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename dns 01/10/23 05:05:11.82
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:11.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:11.871
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 01/10/23 05:05:11.874
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9706.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9706.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 01/10/23 05:05:11.878
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9706.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9706.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 01/10/23 05:05:11.878
STEP: creating a pod to probe DNS 01/10/23 05:05:11.879
STEP: submitting the pod to kubernetes 01/10/23 05:05:11.879
Jan 10 05:05:11.915: INFO: Waiting up to 15m0s for pod "dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba" in namespace "dns-9706" to be "running"
Jan 10 05:05:11.930: INFO: Pod "dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba": Phase="Pending", Reason="", readiness=false. Elapsed: 14.918895ms
Jan 10 05:05:13.934: INFO: Pod "dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba": Phase="Running", Reason="", readiness=true. Elapsed: 2.018810043s
Jan 10 05:05:13.934: INFO: Pod "dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba" satisfied condition "running"
STEP: retrieving the pod 01/10/23 05:05:13.934
STEP: looking for the results for each expected name from probers 01/10/23 05:05:13.936
Jan 10 05:05:13.946: INFO: DNS probes using dns-9706/dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba succeeded

STEP: deleting the pod 01/10/23 05:05:13.946
STEP: deleting the test headless service 01/10/23 05:05:13.969
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 10 05:05:13.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9706" for this suite. 01/10/23 05:05:13.988
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":329,"skipped":6081,"failed":0}
------------------------------
• [2.176 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:05:11.819
    Jan 10 05:05:11.819: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename dns 01/10/23 05:05:11.82
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:11.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:11.871
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 01/10/23 05:05:11.874
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9706.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9706.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     01/10/23 05:05:11.878
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9706.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9706.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     01/10/23 05:05:11.878
    STEP: creating a pod to probe DNS 01/10/23 05:05:11.879
    STEP: submitting the pod to kubernetes 01/10/23 05:05:11.879
    Jan 10 05:05:11.915: INFO: Waiting up to 15m0s for pod "dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba" in namespace "dns-9706" to be "running"
    Jan 10 05:05:11.930: INFO: Pod "dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba": Phase="Pending", Reason="", readiness=false. Elapsed: 14.918895ms
    Jan 10 05:05:13.934: INFO: Pod "dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba": Phase="Running", Reason="", readiness=true. Elapsed: 2.018810043s
    Jan 10 05:05:13.934: INFO: Pod "dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba" satisfied condition "running"
    STEP: retrieving the pod 01/10/23 05:05:13.934
    STEP: looking for the results for each expected name from probers 01/10/23 05:05:13.936
    Jan 10 05:05:13.946: INFO: DNS probes using dns-9706/dns-test-5ef9f0e6-ef14-4b7b-9766-88a64f214cba succeeded

    STEP: deleting the pod 01/10/23 05:05:13.946
    STEP: deleting the test headless service 01/10/23 05:05:13.969
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 10 05:05:13.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9706" for this suite. 01/10/23 05:05:13.988
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:05:14.003
Jan 10 05:05:14.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename daemonsets 01/10/23 05:05:14.004
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:14.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:14.044
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 01/10/23 05:05:14.081
STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 05:05:14.091
Jan 10 05:05:14.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:05:14.109: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 05:05:15.125: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:05:15.125: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
Jan 10 05:05:16.121: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 05:05:16.121: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 01/10/23 05:05:16.123
Jan 10 05:05:16.140: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 05:05:16.141: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
Jan 10 05:05:17.169: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 05:05:17.170: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
Jan 10 05:05:18.148: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 05:05:18.149: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
Jan 10 05:05:19.151: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 05:05:19.151: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
Jan 10 05:05:20.147: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 10 05:05:20.147: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
Jan 10 05:05:21.148: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jan 10 05:05:21.148: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/10/23 05:05:21.15
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3569, will wait for the garbage collector to delete the pods 01/10/23 05:05:21.15
Jan 10 05:05:21.214: INFO: Deleting DaemonSet.extensions daemon-set took: 11.364741ms
Jan 10 05:05:21.314: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.364886ms
Jan 10 05:05:24.117: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:05:24.117: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 10 05:05:24.119: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"250482"},"items":null}

Jan 10 05:05:24.121: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"250482"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 10 05:05:24.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3569" for this suite. 01/10/23 05:05:24.135
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":330,"skipped":6105,"failed":0}
------------------------------
• [SLOW TEST] [10.140 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:05:14.003
    Jan 10 05:05:14.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename daemonsets 01/10/23 05:05:14.004
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:14.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:14.044
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 01/10/23 05:05:14.081
    STEP: Check that daemon pods launch on every node of the cluster. 01/10/23 05:05:14.091
    Jan 10 05:05:14.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:05:14.109: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 05:05:15.125: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:05:15.125: INFO: Node cncf-cp-etcd-wk1 is running 0 daemon pod, expected 1
    Jan 10 05:05:16.121: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 05:05:16.121: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 01/10/23 05:05:16.123
    Jan 10 05:05:16.140: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 05:05:16.141: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
    Jan 10 05:05:17.169: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 05:05:17.170: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
    Jan 10 05:05:18.148: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 05:05:18.149: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
    Jan 10 05:05:19.151: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 05:05:19.151: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
    Jan 10 05:05:20.147: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 10 05:05:20.147: INFO: Node cncf-wk3 is running 0 daemon pod, expected 1
    Jan 10 05:05:21.148: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jan 10 05:05:21.148: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/10/23 05:05:21.15
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3569, will wait for the garbage collector to delete the pods 01/10/23 05:05:21.15
    Jan 10 05:05:21.214: INFO: Deleting DaemonSet.extensions daemon-set took: 11.364741ms
    Jan 10 05:05:21.314: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.364886ms
    Jan 10 05:05:24.117: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:05:24.117: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 10 05:05:24.119: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"250482"},"items":null}

    Jan 10 05:05:24.121: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"250482"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 05:05:24.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3569" for this suite. 01/10/23 05:05:24.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:05:24.145
Jan 10 05:05:24.145: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename var-expansion 01/10/23 05:05:24.146
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:24.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:24.173
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 01/10/23 05:05:24.175
Jan 10 05:05:24.187: INFO: Waiting up to 5m0s for pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600" in namespace "var-expansion-7968" to be "Succeeded or Failed"
Jan 10 05:05:24.193: INFO: Pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600": Phase="Pending", Reason="", readiness=false. Elapsed: 5.316511ms
Jan 10 05:05:26.197: INFO: Pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009024885s
Jan 10 05:05:28.197: INFO: Pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009124451s
STEP: Saw pod success 01/10/23 05:05:28.197
Jan 10 05:05:28.197: INFO: Pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600" satisfied condition "Succeeded or Failed"
Jan 10 05:05:28.201: INFO: Trying to get logs from node cncf-wk2 pod var-expansion-e873befe-0746-4d0f-aaed-702f1f866600 container dapi-container: <nil>
STEP: delete the pod 01/10/23 05:05:28.215
Jan 10 05:05:28.240: INFO: Waiting for pod var-expansion-e873befe-0746-4d0f-aaed-702f1f866600 to disappear
Jan 10 05:05:28.248: INFO: Pod var-expansion-e873befe-0746-4d0f-aaed-702f1f866600 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 10 05:05:28.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7968" for this suite. 01/10/23 05:05:28.253
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":331,"skipped":6116,"failed":0}
------------------------------
• [4.117 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:05:24.145
    Jan 10 05:05:24.145: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename var-expansion 01/10/23 05:05:24.146
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:24.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:24.173
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 01/10/23 05:05:24.175
    Jan 10 05:05:24.187: INFO: Waiting up to 5m0s for pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600" in namespace "var-expansion-7968" to be "Succeeded or Failed"
    Jan 10 05:05:24.193: INFO: Pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600": Phase="Pending", Reason="", readiness=false. Elapsed: 5.316511ms
    Jan 10 05:05:26.197: INFO: Pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009024885s
    Jan 10 05:05:28.197: INFO: Pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009124451s
    STEP: Saw pod success 01/10/23 05:05:28.197
    Jan 10 05:05:28.197: INFO: Pod "var-expansion-e873befe-0746-4d0f-aaed-702f1f866600" satisfied condition "Succeeded or Failed"
    Jan 10 05:05:28.201: INFO: Trying to get logs from node cncf-wk2 pod var-expansion-e873befe-0746-4d0f-aaed-702f1f866600 container dapi-container: <nil>
    STEP: delete the pod 01/10/23 05:05:28.215
    Jan 10 05:05:28.240: INFO: Waiting for pod var-expansion-e873befe-0746-4d0f-aaed-702f1f866600 to disappear
    Jan 10 05:05:28.248: INFO: Pod var-expansion-e873befe-0746-4d0f-aaed-702f1f866600 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 10 05:05:28.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7968" for this suite. 01/10/23 05:05:28.253
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:05:28.265
Jan 10 05:05:28.265: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename subpath 01/10/23 05:05:28.266
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:28.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:28.372
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/10/23 05:05:28.377
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-pcc5 01/10/23 05:05:28.411
STEP: Creating a pod to test atomic-volume-subpath 01/10/23 05:05:28.412
Jan 10 05:05:28.425: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-pcc5" in namespace "subpath-2560" to be "Succeeded or Failed"
Jan 10 05:05:28.451: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.33231ms
Jan 10 05:05:30.486: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.061139963s
Jan 10 05:05:32.454: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 4.029265191s
Jan 10 05:05:34.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 6.030249532s
Jan 10 05:05:36.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 8.02958066s
Jan 10 05:05:38.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 10.029746497s
Jan 10 05:05:40.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 12.030244822s
Jan 10 05:05:42.454: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 14.029551732s
Jan 10 05:05:44.457: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 16.031804764s
Jan 10 05:05:46.456: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 18.030770729s
Jan 10 05:05:48.460: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 20.035443315s
Jan 10 05:05:50.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=false. Elapsed: 22.029599483s
Jan 10 05:05:52.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.029596345s
STEP: Saw pod success 01/10/23 05:05:52.455
Jan 10 05:05:52.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5" satisfied condition "Succeeded or Failed"
Jan 10 05:05:52.457: INFO: Trying to get logs from node cncf-wk2 pod pod-subpath-test-downwardapi-pcc5 container test-container-subpath-downwardapi-pcc5: <nil>
STEP: delete the pod 01/10/23 05:05:52.463
Jan 10 05:05:52.475: INFO: Waiting for pod pod-subpath-test-downwardapi-pcc5 to disappear
Jan 10 05:05:52.478: INFO: Pod pod-subpath-test-downwardapi-pcc5 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-pcc5 01/10/23 05:05:52.478
Jan 10 05:05:52.478: INFO: Deleting pod "pod-subpath-test-downwardapi-pcc5" in namespace "subpath-2560"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 10 05:05:52.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2560" for this suite. 01/10/23 05:05:52.483
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":332,"skipped":6122,"failed":0}
------------------------------
• [SLOW TEST] [24.226 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:05:28.265
    Jan 10 05:05:28.265: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename subpath 01/10/23 05:05:28.266
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:28.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:28.372
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/10/23 05:05:28.377
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-pcc5 01/10/23 05:05:28.411
    STEP: Creating a pod to test atomic-volume-subpath 01/10/23 05:05:28.412
    Jan 10 05:05:28.425: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-pcc5" in namespace "subpath-2560" to be "Succeeded or Failed"
    Jan 10 05:05:28.451: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.33231ms
    Jan 10 05:05:30.486: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.061139963s
    Jan 10 05:05:32.454: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 4.029265191s
    Jan 10 05:05:34.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 6.030249532s
    Jan 10 05:05:36.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 8.02958066s
    Jan 10 05:05:38.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 10.029746497s
    Jan 10 05:05:40.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 12.030244822s
    Jan 10 05:05:42.454: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 14.029551732s
    Jan 10 05:05:44.457: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 16.031804764s
    Jan 10 05:05:46.456: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 18.030770729s
    Jan 10 05:05:48.460: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=true. Elapsed: 20.035443315s
    Jan 10 05:05:50.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Running", Reason="", readiness=false. Elapsed: 22.029599483s
    Jan 10 05:05:52.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.029596345s
    STEP: Saw pod success 01/10/23 05:05:52.455
    Jan 10 05:05:52.455: INFO: Pod "pod-subpath-test-downwardapi-pcc5" satisfied condition "Succeeded or Failed"
    Jan 10 05:05:52.457: INFO: Trying to get logs from node cncf-wk2 pod pod-subpath-test-downwardapi-pcc5 container test-container-subpath-downwardapi-pcc5: <nil>
    STEP: delete the pod 01/10/23 05:05:52.463
    Jan 10 05:05:52.475: INFO: Waiting for pod pod-subpath-test-downwardapi-pcc5 to disappear
    Jan 10 05:05:52.478: INFO: Pod pod-subpath-test-downwardapi-pcc5 no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-pcc5 01/10/23 05:05:52.478
    Jan 10 05:05:52.478: INFO: Deleting pod "pod-subpath-test-downwardapi-pcc5" in namespace "subpath-2560"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 10 05:05:52.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2560" for this suite. 01/10/23 05:05:52.483
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:05:52.499
Jan 10 05:05:52.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename var-expansion 01/10/23 05:05:52.516
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:52.549
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:52.553
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 01/10/23 05:05:52.56
Jan 10 05:05:52.590: INFO: Waiting up to 5m0s for pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415" in namespace "var-expansion-4808" to be "Succeeded or Failed"
Jan 10 05:05:52.606: INFO: Pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415": Phase="Pending", Reason="", readiness=false. Elapsed: 15.723703ms
Jan 10 05:05:54.614: INFO: Pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023356801s
Jan 10 05:05:56.609: INFO: Pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01912567s
STEP: Saw pod success 01/10/23 05:05:56.61
Jan 10 05:05:56.610: INFO: Pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415" satisfied condition "Succeeded or Failed"
Jan 10 05:05:56.612: INFO: Trying to get logs from node cncf-wk2 pod var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415 container dapi-container: <nil>
STEP: delete the pod 01/10/23 05:05:56.625
Jan 10 05:05:56.646: INFO: Waiting for pod var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415 to disappear
Jan 10 05:05:56.657: INFO: Pod var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 10 05:05:56.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4808" for this suite. 01/10/23 05:05:56.66
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":333,"skipped":6141,"failed":0}
------------------------------
• [4.172 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:05:52.499
    Jan 10 05:05:52.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename var-expansion 01/10/23 05:05:52.516
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:52.549
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:52.553
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 01/10/23 05:05:52.56
    Jan 10 05:05:52.590: INFO: Waiting up to 5m0s for pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415" in namespace "var-expansion-4808" to be "Succeeded or Failed"
    Jan 10 05:05:52.606: INFO: Pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415": Phase="Pending", Reason="", readiness=false. Elapsed: 15.723703ms
    Jan 10 05:05:54.614: INFO: Pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023356801s
    Jan 10 05:05:56.609: INFO: Pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01912567s
    STEP: Saw pod success 01/10/23 05:05:56.61
    Jan 10 05:05:56.610: INFO: Pod "var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415" satisfied condition "Succeeded or Failed"
    Jan 10 05:05:56.612: INFO: Trying to get logs from node cncf-wk2 pod var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415 container dapi-container: <nil>
    STEP: delete the pod 01/10/23 05:05:56.625
    Jan 10 05:05:56.646: INFO: Waiting for pod var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415 to disappear
    Jan 10 05:05:56.657: INFO: Pod var-expansion-31ad2333-8af5-4221-a719-ba295f9d7415 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 10 05:05:56.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4808" for this suite. 01/10/23 05:05:56.66
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:05:56.675
Jan 10 05:05:56.675: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 05:05:56.678
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:56.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:56.735
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 01/10/23 05:05:56.742
Jan 10 05:05:56.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 create -f -'
Jan 10 05:05:58.866: INFO: stderr: ""
Jan 10 05:05:58.866: INFO: stdout: "pod/pause created\n"
Jan 10 05:05:58.866: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 10 05:05:58.866: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1375" to be "running and ready"
Jan 10 05:05:58.882: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 15.704374ms
Jan 10 05:05:58.882: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'cncf-wk2' to be 'Running' but was 'Pending'
Jan 10 05:06:00.884: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.018387506s
Jan 10 05:06:00.884: INFO: Pod "pause" satisfied condition "running and ready"
Jan 10 05:06:00.884: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 01/10/23 05:06:00.884
Jan 10 05:06:00.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 label pods pause testing-label=testing-label-value'
Jan 10 05:06:01.158: INFO: stderr: ""
Jan 10 05:06:01.158: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 01/10/23 05:06:01.158
Jan 10 05:06:01.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 get pod pause -L testing-label'
Jan 10 05:06:01.542: INFO: stderr: ""
Jan 10 05:06:01.542: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod 01/10/23 05:06:01.542
Jan 10 05:06:01.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 label pods pause testing-label-'
Jan 10 05:06:01.952: INFO: stderr: ""
Jan 10 05:06:01.952: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 01/10/23 05:06:01.953
Jan 10 05:06:01.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 get pod pause -L testing-label'
Jan 10 05:06:02.156: INFO: stderr: ""
Jan 10 05:06:02.156: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 01/10/23 05:06:02.156
Jan 10 05:06:02.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 delete --grace-period=0 --force -f -'
Jan 10 05:06:02.268: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 10 05:06:02.268: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 10 05:06:02.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 get rc,svc -l name=pause --no-headers'
Jan 10 05:06:02.372: INFO: stderr: "No resources found in kubectl-1375 namespace.\n"
Jan 10 05:06:02.372: INFO: stdout: ""
Jan 10 05:06:02.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 10 05:06:02.561: INFO: stderr: ""
Jan 10 05:06:02.561: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 05:06:02.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1375" for this suite. 01/10/23 05:06:02.565
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":334,"skipped":6153,"failed":0}
------------------------------
• [SLOW TEST] [5.896 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:05:56.675
    Jan 10 05:05:56.675: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 05:05:56.678
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:05:56.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:05:56.735
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 01/10/23 05:05:56.742
    Jan 10 05:05:56.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 create -f -'
    Jan 10 05:05:58.866: INFO: stderr: ""
    Jan 10 05:05:58.866: INFO: stdout: "pod/pause created\n"
    Jan 10 05:05:58.866: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Jan 10 05:05:58.866: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1375" to be "running and ready"
    Jan 10 05:05:58.882: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 15.704374ms
    Jan 10 05:05:58.882: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'cncf-wk2' to be 'Running' but was 'Pending'
    Jan 10 05:06:00.884: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.018387506s
    Jan 10 05:06:00.884: INFO: Pod "pause" satisfied condition "running and ready"
    Jan 10 05:06:00.884: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 01/10/23 05:06:00.884
    Jan 10 05:06:00.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 label pods pause testing-label=testing-label-value'
    Jan 10 05:06:01.158: INFO: stderr: ""
    Jan 10 05:06:01.158: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 01/10/23 05:06:01.158
    Jan 10 05:06:01.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 get pod pause -L testing-label'
    Jan 10 05:06:01.542: INFO: stderr: ""
    Jan 10 05:06:01.542: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 01/10/23 05:06:01.542
    Jan 10 05:06:01.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 label pods pause testing-label-'
    Jan 10 05:06:01.952: INFO: stderr: ""
    Jan 10 05:06:01.952: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 01/10/23 05:06:01.953
    Jan 10 05:06:01.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 get pod pause -L testing-label'
    Jan 10 05:06:02.156: INFO: stderr: ""
    Jan 10 05:06:02.156: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 01/10/23 05:06:02.156
    Jan 10 05:06:02.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 delete --grace-period=0 --force -f -'
    Jan 10 05:06:02.268: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 10 05:06:02.268: INFO: stdout: "pod \"pause\" force deleted\n"
    Jan 10 05:06:02.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 get rc,svc -l name=pause --no-headers'
    Jan 10 05:06:02.372: INFO: stderr: "No resources found in kubectl-1375 namespace.\n"
    Jan 10 05:06:02.372: INFO: stdout: ""
    Jan 10 05:06:02.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-1375 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jan 10 05:06:02.561: INFO: stderr: ""
    Jan 10 05:06:02.561: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 05:06:02.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1375" for this suite. 01/10/23 05:06:02.565
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:06:02.581
Jan 10 05:06:02.582: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename svcaccounts 01/10/23 05:06:02.583
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:02.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:02.612
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 01/10/23 05:06:02.626
STEP: watching for the ServiceAccount to be added 01/10/23 05:06:02.641
STEP: patching the ServiceAccount 01/10/23 05:06:02.645
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 01/10/23 05:06:02.656
STEP: deleting the ServiceAccount 01/10/23 05:06:02.659
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 10 05:06:02.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6949" for this suite. 01/10/23 05:06:02.679
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":335,"skipped":6211,"failed":0}
------------------------------
• [0.104 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:06:02.581
    Jan 10 05:06:02.582: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename svcaccounts 01/10/23 05:06:02.583
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:02.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:02.612
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 01/10/23 05:06:02.626
    STEP: watching for the ServiceAccount to be added 01/10/23 05:06:02.641
    STEP: patching the ServiceAccount 01/10/23 05:06:02.645
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 01/10/23 05:06:02.656
    STEP: deleting the ServiceAccount 01/10/23 05:06:02.659
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 10 05:06:02.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6949" for this suite. 01/10/23 05:06:02.679
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:06:02.686
Jan 10 05:06:02.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename disruption 01/10/23 05:06:02.687
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:02.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:02.746
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 01/10/23 05:06:02.754
STEP: Updating PodDisruptionBudget status 01/10/23 05:06:04.765
STEP: Waiting for all pods to be running 01/10/23 05:06:04.778
Jan 10 05:06:04.796: INFO: running pods: 0 < 1
STEP: locating a running pod 01/10/23 05:06:06.801
STEP: Waiting for the pdb to be processed 01/10/23 05:06:06.814
STEP: Patching PodDisruptionBudget status 01/10/23 05:06:06.823
STEP: Waiting for the pdb to be processed 01/10/23 05:06:06.836
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 10 05:06:06.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2002" for this suite. 01/10/23 05:06:06.862
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":336,"skipped":6212,"failed":0}
------------------------------
• [4.183 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:06:02.686
    Jan 10 05:06:02.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename disruption 01/10/23 05:06:02.687
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:02.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:02.746
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 01/10/23 05:06:02.754
    STEP: Updating PodDisruptionBudget status 01/10/23 05:06:04.765
    STEP: Waiting for all pods to be running 01/10/23 05:06:04.778
    Jan 10 05:06:04.796: INFO: running pods: 0 < 1
    STEP: locating a running pod 01/10/23 05:06:06.801
    STEP: Waiting for the pdb to be processed 01/10/23 05:06:06.814
    STEP: Patching PodDisruptionBudget status 01/10/23 05:06:06.823
    STEP: Waiting for the pdb to be processed 01/10/23 05:06:06.836
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 10 05:06:06.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2002" for this suite. 01/10/23 05:06:06.862
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:06:06.871
Jan 10 05:06:06.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename security-context-test 01/10/23 05:06:06.872
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:06.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:06.916
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Jan 10 05:06:06.987: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89" in namespace "security-context-test-4159" to be "Succeeded or Failed"
Jan 10 05:06:06.998: INFO: Pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89": Phase="Pending", Reason="", readiness=false. Elapsed: 11.406626ms
Jan 10 05:06:09.005: INFO: Pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017989547s
Jan 10 05:06:11.007: INFO: Pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019548319s
Jan 10 05:06:11.007: INFO: Pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 10 05:06:11.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4159" for this suite. 01/10/23 05:06:11.011
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":337,"skipped":6219,"failed":0}
------------------------------
• [4.148 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:06:06.871
    Jan 10 05:06:06.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename security-context-test 01/10/23 05:06:06.872
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:06.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:06.916
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Jan 10 05:06:06.987: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89" in namespace "security-context-test-4159" to be "Succeeded or Failed"
    Jan 10 05:06:06.998: INFO: Pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89": Phase="Pending", Reason="", readiness=false. Elapsed: 11.406626ms
    Jan 10 05:06:09.005: INFO: Pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017989547s
    Jan 10 05:06:11.007: INFO: Pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019548319s
    Jan 10 05:06:11.007: INFO: Pod "busybox-readonly-false-c80707ce-2e8c-434b-9ed6-a160d2276f89" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 10 05:06:11.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4159" for this suite. 01/10/23 05:06:11.011
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:06:11.036
Jan 10 05:06:11.036: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 05:06:11.037
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:11.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:11.145
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 05:06:11.213
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:06:11.849
STEP: Deploying the webhook pod 01/10/23 05:06:11.856
STEP: Wait for the deployment to be ready 01/10/23 05:06:11.868
Jan 10 05:06:11.880: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/10/23 05:06:13.891
STEP: Verifying the service has paired with the endpoint 01/10/23 05:06:13.906
Jan 10 05:06:14.906: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 01/10/23 05:06:14.967
STEP: Creating a configMap that should be mutated 01/10/23 05:06:14.978
STEP: Deleting the collection of validation webhooks 01/10/23 05:06:15
STEP: Creating a configMap that should not be mutated 01/10/23 05:06:15.04
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 05:06:15.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4848" for this suite. 01/10/23 05:06:15.053
STEP: Destroying namespace "webhook-4848-markers" for this suite. 01/10/23 05:06:15.059
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":338,"skipped":6228,"failed":0}
------------------------------
• [4.125 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:06:11.036
    Jan 10 05:06:11.036: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 05:06:11.037
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:11.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:11.145
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 05:06:11.213
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:06:11.849
    STEP: Deploying the webhook pod 01/10/23 05:06:11.856
    STEP: Wait for the deployment to be ready 01/10/23 05:06:11.868
    Jan 10 05:06:11.880: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/10/23 05:06:13.891
    STEP: Verifying the service has paired with the endpoint 01/10/23 05:06:13.906
    Jan 10 05:06:14.906: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 01/10/23 05:06:14.967
    STEP: Creating a configMap that should be mutated 01/10/23 05:06:14.978
    STEP: Deleting the collection of validation webhooks 01/10/23 05:06:15
    STEP: Creating a configMap that should not be mutated 01/10/23 05:06:15.04
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 05:06:15.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4848" for this suite. 01/10/23 05:06:15.053
    STEP: Destroying namespace "webhook-4848-markers" for this suite. 01/10/23 05:06:15.059
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:06:15.165
Jan 10 05:06:15.165: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-lifecycle-hook 01/10/23 05:06:15.166
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:15.218
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:15.224
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 01/10/23 05:06:15.244
Jan 10 05:06:15.266: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9353" to be "running and ready"
Jan 10 05:06:15.282: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 16.051504ms
Jan 10 05:06:15.282: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:06:17.288: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.021849666s
Jan 10 05:06:17.288: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jan 10 05:06:17.288: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 01/10/23 05:06:17.291
Jan 10 05:06:17.308: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9353" to be "running and ready"
Jan 10 05:06:17.322: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 13.63037ms
Jan 10 05:06:17.322: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:06:19.325: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.016460311s
Jan 10 05:06:19.325: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Jan 10 05:06:19.325: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 01/10/23 05:06:19.327
Jan 10 05:06:19.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 05:06:19.337: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 05:06:21.338: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 05:06:21.340: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 05:06:23.338: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 05:06:23.340: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 01/10/23 05:06:23.341
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jan 10 05:06:23.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9353" for this suite. 01/10/23 05:06:23.357
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":339,"skipped":6243,"failed":0}
------------------------------
• [SLOW TEST] [8.198 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:06:15.165
    Jan 10 05:06:15.165: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-lifecycle-hook 01/10/23 05:06:15.166
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:15.218
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:15.224
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 01/10/23 05:06:15.244
    Jan 10 05:06:15.266: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9353" to be "running and ready"
    Jan 10 05:06:15.282: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 16.051504ms
    Jan 10 05:06:15.282: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:06:17.288: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.021849666s
    Jan 10 05:06:17.288: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jan 10 05:06:17.288: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 01/10/23 05:06:17.291
    Jan 10 05:06:17.308: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9353" to be "running and ready"
    Jan 10 05:06:17.322: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 13.63037ms
    Jan 10 05:06:17.322: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:06:19.325: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.016460311s
    Jan 10 05:06:19.325: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Jan 10 05:06:19.325: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 01/10/23 05:06:19.327
    Jan 10 05:06:19.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jan 10 05:06:19.337: INFO: Pod pod-with-prestop-exec-hook still exists
    Jan 10 05:06:21.338: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jan 10 05:06:21.340: INFO: Pod pod-with-prestop-exec-hook still exists
    Jan 10 05:06:23.338: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jan 10 05:06:23.340: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 01/10/23 05:06:23.341
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jan 10 05:06:23.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9353" for this suite. 01/10/23 05:06:23.357
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:06:23.366
Jan 10 05:06:23.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename taint-multiple-pods 01/10/23 05:06:23.367
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:23.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:23.392
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Jan 10 05:06:23.395: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 10 05:07:23.423: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Jan 10 05:07:23.429: INFO: Starting informer...
STEP: Starting pods... 01/10/23 05:07:23.429
Jan 10 05:07:23.469: INFO: Pod1 is running on cncf-wk2. Tainting Node
Jan 10 05:07:23.500: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8108" to be "running"
Jan 10 05:07:23.517: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.813026ms
Jan 10 05:07:25.522: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021478123s
Jan 10 05:07:27.522: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.021977513s
Jan 10 05:07:27.522: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Jan 10 05:07:27.522: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8108" to be "running"
Jan 10 05:07:27.525: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.614131ms
Jan 10 05:07:27.525: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Jan 10 05:07:27.525: INFO: Pod2 is running on cncf-wk2. Tainting Node
STEP: Trying to apply a taint on the Node 01/10/23 05:07:27.525
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/10/23 05:07:27.552
STEP: Waiting for Pod1 and Pod2 to be deleted 01/10/23 05:07:27.565
Jan 10 05:07:34.014: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Jan 10 05:07:53.421: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/10/23 05:07:53.432
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Jan 10 05:07:53.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8108" for this suite. 01/10/23 05:07:53.446
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":340,"skipped":6269,"failed":0}
------------------------------
• [SLOW TEST] [90.093 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:06:23.366
    Jan 10 05:06:23.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename taint-multiple-pods 01/10/23 05:06:23.367
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:06:23.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:06:23.392
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Jan 10 05:06:23.395: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 10 05:07:23.423: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Jan 10 05:07:23.429: INFO: Starting informer...
    STEP: Starting pods... 01/10/23 05:07:23.429
    Jan 10 05:07:23.469: INFO: Pod1 is running on cncf-wk2. Tainting Node
    Jan 10 05:07:23.500: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8108" to be "running"
    Jan 10 05:07:23.517: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.813026ms
    Jan 10 05:07:25.522: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021478123s
    Jan 10 05:07:27.522: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.021977513s
    Jan 10 05:07:27.522: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Jan 10 05:07:27.522: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8108" to be "running"
    Jan 10 05:07:27.525: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.614131ms
    Jan 10 05:07:27.525: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Jan 10 05:07:27.525: INFO: Pod2 is running on cncf-wk2. Tainting Node
    STEP: Trying to apply a taint on the Node 01/10/23 05:07:27.525
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/10/23 05:07:27.552
    STEP: Waiting for Pod1 and Pod2 to be deleted 01/10/23 05:07:27.565
    Jan 10 05:07:34.014: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Jan 10 05:07:53.421: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/10/23 05:07:53.432
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 05:07:53.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-8108" for this suite. 01/10/23 05:07:53.446
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:07:53.463
Jan 10 05:07:53.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 05:07:53.466
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:07:53.519
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:07:53.538
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 01/10/23 05:07:53.552
STEP: Getting a ResourceQuota 01/10/23 05:07:53.563
STEP: Updating a ResourceQuota 01/10/23 05:07:53.578
STEP: Verifying a ResourceQuota was modified 01/10/23 05:07:53.584
STEP: Deleting a ResourceQuota 01/10/23 05:07:53.587
STEP: Verifying the deleted ResourceQuota 01/10/23 05:07:53.591
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 05:07:53.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9074" for this suite. 01/10/23 05:07:53.596
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":341,"skipped":6284,"failed":0}
------------------------------
• [0.137 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:07:53.463
    Jan 10 05:07:53.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 05:07:53.466
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:07:53.519
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:07:53.538
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 01/10/23 05:07:53.552
    STEP: Getting a ResourceQuota 01/10/23 05:07:53.563
    STEP: Updating a ResourceQuota 01/10/23 05:07:53.578
    STEP: Verifying a ResourceQuota was modified 01/10/23 05:07:53.584
    STEP: Deleting a ResourceQuota 01/10/23 05:07:53.587
    STEP: Verifying the deleted ResourceQuota 01/10/23 05:07:53.591
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 05:07:53.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9074" for this suite. 01/10/23 05:07:53.596
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:07:53.602
Jan 10 05:07:53.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename svcaccounts 01/10/23 05:07:53.603
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:07:53.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:07:53.631
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Jan 10 05:07:53.656: INFO: Waiting up to 5m0s for pod "pod-service-account-455694ce-2025-4798-866a-684becfafa56" in namespace "svcaccounts-5526" to be "running"
Jan 10 05:07:53.670: INFO: Pod "pod-service-account-455694ce-2025-4798-866a-684becfafa56": Phase="Pending", Reason="", readiness=false. Elapsed: 13.895065ms
Jan 10 05:07:55.674: INFO: Pod "pod-service-account-455694ce-2025-4798-866a-684becfafa56": Phase="Running", Reason="", readiness=true. Elapsed: 2.018135937s
Jan 10 05:07:55.674: INFO: Pod "pod-service-account-455694ce-2025-4798-866a-684becfafa56" satisfied condition "running"
STEP: reading a file in the container 01/10/23 05:07:55.674
Jan 10 05:07:55.674: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5526 pod-service-account-455694ce-2025-4798-866a-684becfafa56 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 01/10/23 05:07:55.891
Jan 10 05:07:55.891: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5526 pod-service-account-455694ce-2025-4798-866a-684becfafa56 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 01/10/23 05:07:56.045
Jan 10 05:07:56.045: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5526 pod-service-account-455694ce-2025-4798-866a-684becfafa56 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Jan 10 05:07:56.206: INFO: Got root ca configmap in namespace "svcaccounts-5526"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 10 05:07:56.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5526" for this suite. 01/10/23 05:07:56.218
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":342,"skipped":6302,"failed":0}
------------------------------
• [2.629 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:07:53.602
    Jan 10 05:07:53.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename svcaccounts 01/10/23 05:07:53.603
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:07:53.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:07:53.631
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Jan 10 05:07:53.656: INFO: Waiting up to 5m0s for pod "pod-service-account-455694ce-2025-4798-866a-684becfafa56" in namespace "svcaccounts-5526" to be "running"
    Jan 10 05:07:53.670: INFO: Pod "pod-service-account-455694ce-2025-4798-866a-684becfafa56": Phase="Pending", Reason="", readiness=false. Elapsed: 13.895065ms
    Jan 10 05:07:55.674: INFO: Pod "pod-service-account-455694ce-2025-4798-866a-684becfafa56": Phase="Running", Reason="", readiness=true. Elapsed: 2.018135937s
    Jan 10 05:07:55.674: INFO: Pod "pod-service-account-455694ce-2025-4798-866a-684becfafa56" satisfied condition "running"
    STEP: reading a file in the container 01/10/23 05:07:55.674
    Jan 10 05:07:55.674: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5526 pod-service-account-455694ce-2025-4798-866a-684becfafa56 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 01/10/23 05:07:55.891
    Jan 10 05:07:55.891: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5526 pod-service-account-455694ce-2025-4798-866a-684becfafa56 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 01/10/23 05:07:56.045
    Jan 10 05:07:56.045: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5526 pod-service-account-455694ce-2025-4798-866a-684becfafa56 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Jan 10 05:07:56.206: INFO: Got root ca configmap in namespace "svcaccounts-5526"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 10 05:07:56.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5526" for this suite. 01/10/23 05:07:56.218
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:07:56.232
Jan 10 05:07:56.232: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename replicaset 01/10/23 05:07:56.234
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:07:56.313
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:07:56.33
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Jan 10 05:07:56.346: INFO: Creating ReplicaSet my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791
Jan 10 05:07:56.404: INFO: Pod name my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791: Found 0 pods out of 1
Jan 10 05:08:01.414: INFO: Pod name my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791: Found 1 pods out of 1
Jan 10 05:08:01.414: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791" is running
Jan 10 05:08:01.414: INFO: Waiting up to 5m0s for pod "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz" in namespace "replicaset-6525" to be "running"
Jan 10 05:08:01.417: INFO: Pod "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz": Phase="Running", Reason="", readiness=true. Elapsed: 3.158897ms
Jan 10 05:08:01.417: INFO: Pod "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz" satisfied condition "running"
Jan 10 05:08:01.417: INFO: Pod "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 05:07:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 05:07:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 05:07:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 05:07:56 +0000 UTC Reason: Message:}])
Jan 10 05:08:01.417: INFO: Trying to dial the pod
Jan 10 05:08:06.426: INFO: Controller my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791: Got expected result from replica 1 [my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz]: "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 10 05:08:06.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6525" for this suite. 01/10/23 05:08:06.429
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":343,"skipped":6333,"failed":0}
------------------------------
• [SLOW TEST] [10.202 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:07:56.232
    Jan 10 05:07:56.232: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename replicaset 01/10/23 05:07:56.234
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:07:56.313
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:07:56.33
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Jan 10 05:07:56.346: INFO: Creating ReplicaSet my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791
    Jan 10 05:07:56.404: INFO: Pod name my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791: Found 0 pods out of 1
    Jan 10 05:08:01.414: INFO: Pod name my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791: Found 1 pods out of 1
    Jan 10 05:08:01.414: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791" is running
    Jan 10 05:08:01.414: INFO: Waiting up to 5m0s for pod "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz" in namespace "replicaset-6525" to be "running"
    Jan 10 05:08:01.417: INFO: Pod "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz": Phase="Running", Reason="", readiness=true. Elapsed: 3.158897ms
    Jan 10 05:08:01.417: INFO: Pod "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz" satisfied condition "running"
    Jan 10 05:08:01.417: INFO: Pod "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 05:07:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 05:07:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 05:07:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-10 05:07:56 +0000 UTC Reason: Message:}])
    Jan 10 05:08:01.417: INFO: Trying to dial the pod
    Jan 10 05:08:06.426: INFO: Controller my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791: Got expected result from replica 1 [my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz]: "my-hostname-basic-43f747b5-cfe6-43a1-adf9-76b73a036791-dwjjz", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 10 05:08:06.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6525" for this suite. 01/10/23 05:08:06.429
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:08:06.435
Jan 10 05:08:06.435: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename prestop 01/10/23 05:08:06.436
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:06.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:06.476
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-358 01/10/23 05:08:06.48
STEP: Waiting for pods to come up. 01/10/23 05:08:06.485
Jan 10 05:08:06.485: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-358" to be "running"
Jan 10 05:08:06.494: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 8.299911ms
Jan 10 05:08:08.499: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.013219709s
Jan 10 05:08:08.499: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-358 01/10/23 05:08:08.503
Jan 10 05:08:08.506: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-358" to be "running"
Jan 10 05:08:08.520: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 13.464899ms
Jan 10 05:08:10.523: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.016824558s
Jan 10 05:08:10.523: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 01/10/23 05:08:10.523
Jan 10 05:08:15.538: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 01/10/23 05:08:15.538
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Jan 10 05:08:15.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-358" for this suite. 01/10/23 05:08:15.552
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":344,"skipped":6339,"failed":0}
------------------------------
• [SLOW TEST] [9.124 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:08:06.435
    Jan 10 05:08:06.435: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename prestop 01/10/23 05:08:06.436
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:06.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:06.476
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-358 01/10/23 05:08:06.48
    STEP: Waiting for pods to come up. 01/10/23 05:08:06.485
    Jan 10 05:08:06.485: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-358" to be "running"
    Jan 10 05:08:06.494: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 8.299911ms
    Jan 10 05:08:08.499: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.013219709s
    Jan 10 05:08:08.499: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-358 01/10/23 05:08:08.503
    Jan 10 05:08:08.506: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-358" to be "running"
    Jan 10 05:08:08.520: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 13.464899ms
    Jan 10 05:08:10.523: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.016824558s
    Jan 10 05:08:10.523: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 01/10/23 05:08:10.523
    Jan 10 05:08:15.538: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 01/10/23 05:08:15.538
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Jan 10 05:08:15.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-358" for this suite. 01/10/23 05:08:15.552
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:08:15.564
Jan 10 05:08:15.564: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename kubectl 01/10/23 05:08:15.565
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:15.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:15.594
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 01/10/23 05:08:15.608
Jan 10 05:08:15.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-9221 create -f -'
Jan 10 05:08:16.170: INFO: stderr: ""
Jan 10 05:08:16.170: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 01/10/23 05:08:16.17
Jan 10 05:08:17.173: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 05:08:17.173: INFO: Found 0 / 1
Jan 10 05:08:18.183: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 05:08:18.183: INFO: Found 0 / 1
Jan 10 05:08:19.173: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 05:08:19.173: INFO: Found 1 / 1
Jan 10 05:08:19.173: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 01/10/23 05:08:19.173
Jan 10 05:08:19.175: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 05:08:19.175: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 10 05:08:19.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-9221 patch pod agnhost-primary-cwpzp -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 10 05:08:19.306: INFO: stderr: ""
Jan 10 05:08:19.307: INFO: stdout: "pod/agnhost-primary-cwpzp patched\n"
STEP: checking annotations 01/10/23 05:08:19.307
Jan 10 05:08:19.309: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 10 05:08:19.310: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 10 05:08:19.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9221" for this suite. 01/10/23 05:08:19.313
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":345,"skipped":6357,"failed":0}
------------------------------
• [3.754 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:08:15.564
    Jan 10 05:08:15.564: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename kubectl 01/10/23 05:08:15.565
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:15.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:15.594
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 01/10/23 05:08:15.608
    Jan 10 05:08:15.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-9221 create -f -'
    Jan 10 05:08:16.170: INFO: stderr: ""
    Jan 10 05:08:16.170: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 01/10/23 05:08:16.17
    Jan 10 05:08:17.173: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 05:08:17.173: INFO: Found 0 / 1
    Jan 10 05:08:18.183: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 05:08:18.183: INFO: Found 0 / 1
    Jan 10 05:08:19.173: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 05:08:19.173: INFO: Found 1 / 1
    Jan 10 05:08:19.173: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 01/10/23 05:08:19.173
    Jan 10 05:08:19.175: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 05:08:19.175: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jan 10 05:08:19.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=kubectl-9221 patch pod agnhost-primary-cwpzp -p {"metadata":{"annotations":{"x":"y"}}}'
    Jan 10 05:08:19.306: INFO: stderr: ""
    Jan 10 05:08:19.307: INFO: stdout: "pod/agnhost-primary-cwpzp patched\n"
    STEP: checking annotations 01/10/23 05:08:19.307
    Jan 10 05:08:19.309: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 10 05:08:19.310: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 10 05:08:19.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9221" for this suite. 01/10/23 05:08:19.313
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:08:19.319
Jan 10 05:08:19.319: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 05:08:19.32
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:19.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:19.411
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Jan 10 05:08:19.424: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 01/10/23 05:08:23.667
Jan 10 05:08:23.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 create -f -'
Jan 10 05:08:24.368: INFO: stderr: ""
Jan 10 05:08:24.368: INFO: stdout: "e2e-test-crd-publish-openapi-8517-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jan 10 05:08:24.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 delete e2e-test-crd-publish-openapi-8517-crds test-foo'
Jan 10 05:08:24.456: INFO: stderr: ""
Jan 10 05:08:24.456: INFO: stdout: "e2e-test-crd-publish-openapi-8517-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Jan 10 05:08:24.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 apply -f -'
Jan 10 05:08:24.731: INFO: stderr: ""
Jan 10 05:08:24.731: INFO: stdout: "e2e-test-crd-publish-openapi-8517-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jan 10 05:08:24.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 delete e2e-test-crd-publish-openapi-8517-crds test-foo'
Jan 10 05:08:24.800: INFO: stderr: ""
Jan 10 05:08:24.800: INFO: stdout: "e2e-test-crd-publish-openapi-8517-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 01/10/23 05:08:24.8
Jan 10 05:08:24.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 create -f -'
Jan 10 05:08:25.041: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 01/10/23 05:08:25.041
Jan 10 05:08:25.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 create -f -'
Jan 10 05:08:25.299: INFO: rc: 1
Jan 10 05:08:25.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 apply -f -'
Jan 10 05:08:25.609: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 01/10/23 05:08:25.61
Jan 10 05:08:25.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 create -f -'
Jan 10 05:08:25.836: INFO: rc: 1
Jan 10 05:08:25.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 apply -f -'
Jan 10 05:08:26.083: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 01/10/23 05:08:26.083
Jan 10 05:08:26.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds'
Jan 10 05:08:26.312: INFO: stderr: ""
Jan 10 05:08:26.313: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 01/10/23 05:08:26.313
Jan 10 05:08:26.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds.metadata'
Jan 10 05:08:26.579: INFO: stderr: ""
Jan 10 05:08:26.579: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Jan 10 05:08:26.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds.spec'
Jan 10 05:08:26.821: INFO: stderr: ""
Jan 10 05:08:26.821: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Jan 10 05:08:26.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds.spec.bars'
Jan 10 05:08:27.090: INFO: stderr: ""
Jan 10 05:08:27.090: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 01/10/23 05:08:27.09
Jan 10 05:08:27.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds.spec.bars2'
Jan 10 05:08:27.318: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 05:08:31.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9752" for this suite. 01/10/23 05:08:31.399
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":346,"skipped":6363,"failed":0}
------------------------------
• [SLOW TEST] [12.087 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:08:19.319
    Jan 10 05:08:19.319: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename crd-publish-openapi 01/10/23 05:08:19.32
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:19.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:19.411
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Jan 10 05:08:19.424: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 01/10/23 05:08:23.667
    Jan 10 05:08:23.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 create -f -'
    Jan 10 05:08:24.368: INFO: stderr: ""
    Jan 10 05:08:24.368: INFO: stdout: "e2e-test-crd-publish-openapi-8517-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Jan 10 05:08:24.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 delete e2e-test-crd-publish-openapi-8517-crds test-foo'
    Jan 10 05:08:24.456: INFO: stderr: ""
    Jan 10 05:08:24.456: INFO: stdout: "e2e-test-crd-publish-openapi-8517-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Jan 10 05:08:24.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 apply -f -'
    Jan 10 05:08:24.731: INFO: stderr: ""
    Jan 10 05:08:24.731: INFO: stdout: "e2e-test-crd-publish-openapi-8517-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Jan 10 05:08:24.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 delete e2e-test-crd-publish-openapi-8517-crds test-foo'
    Jan 10 05:08:24.800: INFO: stderr: ""
    Jan 10 05:08:24.800: INFO: stdout: "e2e-test-crd-publish-openapi-8517-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 01/10/23 05:08:24.8
    Jan 10 05:08:24.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 create -f -'
    Jan 10 05:08:25.041: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 01/10/23 05:08:25.041
    Jan 10 05:08:25.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 create -f -'
    Jan 10 05:08:25.299: INFO: rc: 1
    Jan 10 05:08:25.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 apply -f -'
    Jan 10 05:08:25.609: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 01/10/23 05:08:25.61
    Jan 10 05:08:25.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 create -f -'
    Jan 10 05:08:25.836: INFO: rc: 1
    Jan 10 05:08:25.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 --namespace=crd-publish-openapi-9752 apply -f -'
    Jan 10 05:08:26.083: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 01/10/23 05:08:26.083
    Jan 10 05:08:26.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds'
    Jan 10 05:08:26.312: INFO: stderr: ""
    Jan 10 05:08:26.313: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 01/10/23 05:08:26.313
    Jan 10 05:08:26.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds.metadata'
    Jan 10 05:08:26.579: INFO: stderr: ""
    Jan 10 05:08:26.579: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Jan 10 05:08:26.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds.spec'
    Jan 10 05:08:26.821: INFO: stderr: ""
    Jan 10 05:08:26.821: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Jan 10 05:08:26.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds.spec.bars'
    Jan 10 05:08:27.090: INFO: stderr: ""
    Jan 10 05:08:27.090: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8517-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 01/10/23 05:08:27.09
    Jan 10 05:08:27.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1442525850 --namespace=crd-publish-openapi-9752 explain e2e-test-crd-publish-openapi-8517-crds.spec.bars2'
    Jan 10 05:08:27.318: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 05:08:31.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9752" for this suite. 01/10/23 05:08:31.399
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:08:31.411
Jan 10 05:08:31.411: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 05:08:31.412
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:31.442
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:31.447
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 01/10/23 05:08:31.456
Jan 10 05:08:31.467: INFO: Waiting up to 5m0s for pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25" in namespace "projected-5025" to be "running and ready"
Jan 10 05:08:31.484: INFO: Pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25": Phase="Pending", Reason="", readiness=false. Elapsed: 17.782493ms
Jan 10 05:08:31.484: INFO: The phase of Pod labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:08:33.494: INFO: Pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25": Phase="Running", Reason="", readiness=true. Elapsed: 2.02742888s
Jan 10 05:08:33.494: INFO: The phase of Pod labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25 is Running (Ready = true)
Jan 10 05:08:33.494: INFO: Pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25" satisfied condition "running and ready"
Jan 10 05:08:34.052: INFO: Successfully updated pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 05:08:38.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5025" for this suite. 01/10/23 05:08:38.095
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":347,"skipped":6378,"failed":0}
------------------------------
• [SLOW TEST] [6.692 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:08:31.411
    Jan 10 05:08:31.411: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 05:08:31.412
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:31.442
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:31.447
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 01/10/23 05:08:31.456
    Jan 10 05:08:31.467: INFO: Waiting up to 5m0s for pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25" in namespace "projected-5025" to be "running and ready"
    Jan 10 05:08:31.484: INFO: Pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25": Phase="Pending", Reason="", readiness=false. Elapsed: 17.782493ms
    Jan 10 05:08:31.484: INFO: The phase of Pod labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:08:33.494: INFO: Pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25": Phase="Running", Reason="", readiness=true. Elapsed: 2.02742888s
    Jan 10 05:08:33.494: INFO: The phase of Pod labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25 is Running (Ready = true)
    Jan 10 05:08:33.494: INFO: Pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25" satisfied condition "running and ready"
    Jan 10 05:08:34.052: INFO: Successfully updated pod "labelsupdateef04d69c-869c-41b3-9420-9bdbbc550d25"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 05:08:38.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5025" for this suite. 01/10/23 05:08:38.095
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:08:38.105
Jan 10 05:08:38.105: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 05:08:38.106
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:38.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:38.152
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-34e5dbd9-b55a-48ea-ae96-df8c9f55d54a 01/10/23 05:08:38.158
STEP: Creating a pod to test consume configMaps 01/10/23 05:08:38.163
Jan 10 05:08:38.177: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb" in namespace "projected-4419" to be "Succeeded or Failed"
Jan 10 05:08:38.192: INFO: Pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.343276ms
Jan 10 05:08:40.195: INFO: Pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017590517s
Jan 10 05:08:42.196: INFO: Pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018362349s
STEP: Saw pod success 01/10/23 05:08:42.196
Jan 10 05:08:42.196: INFO: Pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb" satisfied condition "Succeeded or Failed"
Jan 10 05:08:42.199: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb container agnhost-container: <nil>
STEP: delete the pod 01/10/23 05:08:42.205
Jan 10 05:08:42.218: INFO: Waiting for pod pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb to disappear
Jan 10 05:08:42.220: INFO: Pod pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 10 05:08:42.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4419" for this suite. 01/10/23 05:08:42.223
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":348,"skipped":6426,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:08:38.105
    Jan 10 05:08:38.105: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 05:08:38.106
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:38.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:38.152
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-34e5dbd9-b55a-48ea-ae96-df8c9f55d54a 01/10/23 05:08:38.158
    STEP: Creating a pod to test consume configMaps 01/10/23 05:08:38.163
    Jan 10 05:08:38.177: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb" in namespace "projected-4419" to be "Succeeded or Failed"
    Jan 10 05:08:38.192: INFO: Pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.343276ms
    Jan 10 05:08:40.195: INFO: Pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017590517s
    Jan 10 05:08:42.196: INFO: Pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018362349s
    STEP: Saw pod success 01/10/23 05:08:42.196
    Jan 10 05:08:42.196: INFO: Pod "pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb" satisfied condition "Succeeded or Failed"
    Jan 10 05:08:42.199: INFO: Trying to get logs from node cncf-wk2 pod pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb container agnhost-container: <nil>
    STEP: delete the pod 01/10/23 05:08:42.205
    Jan 10 05:08:42.218: INFO: Waiting for pod pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb to disappear
    Jan 10 05:08:42.220: INFO: Pod pod-projected-configmaps-2a348d45-b653-4fcf-bed9-ecee19e2e3eb no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 10 05:08:42.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4419" for this suite. 01/10/23 05:08:42.223
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:08:42.229
Jan 10 05:08:42.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename daemonsets 01/10/23 05:08:42.23
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:42.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:42.276
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Jan 10 05:08:42.324: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 01/10/23 05:08:42.339
Jan 10 05:08:42.344: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:08:42.345: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 01/10/23 05:08:42.345
Jan 10 05:08:42.373: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:08:42.373: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
Jan 10 05:08:43.376: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:08:43.376: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
Jan 10 05:08:44.377: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 10 05:08:44.377: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 01/10/23 05:08:44.378
Jan 10 05:08:44.396: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 10 05:08:44.396: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Jan 10 05:08:45.403: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:08:45.403: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 01/10/23 05:08:45.403
Jan 10 05:08:45.416: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:08:45.416: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
Jan 10 05:08:46.420: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:08:46.420: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
Jan 10 05:08:47.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:08:47.426: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
Jan 10 05:08:48.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 10 05:08:48.421: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/10/23 05:08:48.425
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8781, will wait for the garbage collector to delete the pods 01/10/23 05:08:48.426
Jan 10 05:08:48.488: INFO: Deleting DaemonSet.extensions daemon-set took: 6.885412ms
Jan 10 05:08:48.590: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.252788ms
Jan 10 05:08:51.299: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 10 05:08:51.299: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 10 05:08:51.303: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"251983"},"items":null}

Jan 10 05:08:51.305: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"251983"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 10 05:08:51.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8781" for this suite. 01/10/23 05:08:51.352
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":349,"skipped":6444,"failed":0}
------------------------------
• [SLOW TEST] [9.139 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:08:42.229
    Jan 10 05:08:42.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename daemonsets 01/10/23 05:08:42.23
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:42.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:42.276
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Jan 10 05:08:42.324: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 01/10/23 05:08:42.339
    Jan 10 05:08:42.344: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:08:42.345: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 01/10/23 05:08:42.345
    Jan 10 05:08:42.373: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:08:42.373: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
    Jan 10 05:08:43.376: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:08:43.376: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
    Jan 10 05:08:44.377: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 10 05:08:44.377: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 01/10/23 05:08:44.378
    Jan 10 05:08:44.396: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 10 05:08:44.396: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Jan 10 05:08:45.403: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:08:45.403: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 01/10/23 05:08:45.403
    Jan 10 05:08:45.416: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:08:45.416: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
    Jan 10 05:08:46.420: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:08:46.420: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
    Jan 10 05:08:47.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:08:47.426: INFO: Node cncf-wk2 is running 0 daemon pod, expected 1
    Jan 10 05:08:48.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 10 05:08:48.421: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/10/23 05:08:48.425
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8781, will wait for the garbage collector to delete the pods 01/10/23 05:08:48.426
    Jan 10 05:08:48.488: INFO: Deleting DaemonSet.extensions daemon-set took: 6.885412ms
    Jan 10 05:08:48.590: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.252788ms
    Jan 10 05:08:51.299: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 10 05:08:51.299: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 10 05:08:51.303: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"251983"},"items":null}

    Jan 10 05:08:51.305: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"251983"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 10 05:08:51.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8781" for this suite. 01/10/23 05:08:51.352
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:08:51.369
Jan 10 05:08:51.369: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 05:08:51.37
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:51.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:51.423
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 01/10/23 05:08:51.426
Jan 10 05:08:51.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2" in namespace "downward-api-3330" to be "Succeeded or Failed"
Jan 10 05:08:51.452: INFO: Pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.753297ms
Jan 10 05:08:53.456: INFO: Pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017307137s
Jan 10 05:08:55.456: INFO: Pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017549787s
STEP: Saw pod success 01/10/23 05:08:55.456
Jan 10 05:08:55.456: INFO: Pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2" satisfied condition "Succeeded or Failed"
Jan 10 05:08:55.458: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2 container client-container: <nil>
STEP: delete the pod 01/10/23 05:08:55.465
Jan 10 05:08:55.476: INFO: Waiting for pod downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2 to disappear
Jan 10 05:08:55.481: INFO: Pod downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 05:08:55.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3330" for this suite. 01/10/23 05:08:55.484
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":350,"skipped":6451,"failed":0}
------------------------------
• [4.120 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:08:51.369
    Jan 10 05:08:51.369: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 05:08:51.37
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:51.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:51.423
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 01/10/23 05:08:51.426
    Jan 10 05:08:51.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2" in namespace "downward-api-3330" to be "Succeeded or Failed"
    Jan 10 05:08:51.452: INFO: Pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.753297ms
    Jan 10 05:08:53.456: INFO: Pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017307137s
    Jan 10 05:08:55.456: INFO: Pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017549787s
    STEP: Saw pod success 01/10/23 05:08:55.456
    Jan 10 05:08:55.456: INFO: Pod "downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2" satisfied condition "Succeeded or Failed"
    Jan 10 05:08:55.458: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2 container client-container: <nil>
    STEP: delete the pod 01/10/23 05:08:55.465
    Jan 10 05:08:55.476: INFO: Waiting for pod downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2 to disappear
    Jan 10 05:08:55.481: INFO: Pod downwardapi-volume-8bae58e6-80a1-4159-9d5b-f26a5f08f9c2 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 05:08:55.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3330" for this suite. 01/10/23 05:08:55.484
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:08:55.49
Jan 10 05:08:55.491: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename pods 01/10/23 05:08:55.492
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:55.519
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:55.522
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 01/10/23 05:08:55.527
STEP: submitting the pod to kubernetes 01/10/23 05:08:55.527
Jan 10 05:08:55.539: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428" in namespace "pods-2526" to be "running and ready"
Jan 10 05:08:55.547: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Pending", Reason="", readiness=false. Elapsed: 8.445911ms
Jan 10 05:08:55.547: INFO: The phase of Pod pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428 is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:08:57.550: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Running", Reason="", readiness=true. Elapsed: 2.011404949s
Jan 10 05:08:57.550: INFO: The phase of Pod pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428 is Running (Ready = true)
Jan 10 05:08:57.550: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 01/10/23 05:08:57.552
STEP: updating the pod 01/10/23 05:08:57.559
Jan 10 05:08:58.075: INFO: Successfully updated pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428"
Jan 10 05:08:58.075: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428" in namespace "pods-2526" to be "terminated with reason DeadlineExceeded"
Jan 10 05:08:58.082: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Running", Reason="", readiness=true. Elapsed: 6.706727ms
Jan 10 05:09:00.086: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Running", Reason="", readiness=true. Elapsed: 2.010233452s
Jan 10 05:09:02.086: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Running", Reason="", readiness=false. Elapsed: 4.010786562s
Jan 10 05:09:04.086: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.010420063s
Jan 10 05:09:04.086: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 10 05:09:04.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2526" for this suite. 01/10/23 05:09:04.092
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":351,"skipped":6462,"failed":0}
------------------------------
• [SLOW TEST] [8.608 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:08:55.49
    Jan 10 05:08:55.491: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename pods 01/10/23 05:08:55.492
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:08:55.519
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:08:55.522
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 01/10/23 05:08:55.527
    STEP: submitting the pod to kubernetes 01/10/23 05:08:55.527
    Jan 10 05:08:55.539: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428" in namespace "pods-2526" to be "running and ready"
    Jan 10 05:08:55.547: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Pending", Reason="", readiness=false. Elapsed: 8.445911ms
    Jan 10 05:08:55.547: INFO: The phase of Pod pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428 is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:08:57.550: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Running", Reason="", readiness=true. Elapsed: 2.011404949s
    Jan 10 05:08:57.550: INFO: The phase of Pod pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428 is Running (Ready = true)
    Jan 10 05:08:57.550: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 01/10/23 05:08:57.552
    STEP: updating the pod 01/10/23 05:08:57.559
    Jan 10 05:08:58.075: INFO: Successfully updated pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428"
    Jan 10 05:08:58.075: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428" in namespace "pods-2526" to be "terminated with reason DeadlineExceeded"
    Jan 10 05:08:58.082: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Running", Reason="", readiness=true. Elapsed: 6.706727ms
    Jan 10 05:09:00.086: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Running", Reason="", readiness=true. Elapsed: 2.010233452s
    Jan 10 05:09:02.086: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Running", Reason="", readiness=false. Elapsed: 4.010786562s
    Jan 10 05:09:04.086: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.010420063s
    Jan 10 05:09:04.086: INFO: Pod "pod-update-activedeadlineseconds-73646ee6-cb9f-4316-98fc-b064fd048428" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 10 05:09:04.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2526" for this suite. 01/10/23 05:09:04.092
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:09:04.1
Jan 10 05:09:04.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename projected 01/10/23 05:09:04.101
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:04.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:04.146
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 01/10/23 05:09:04.153
Jan 10 05:09:04.165: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c" in namespace "projected-54" to be "Succeeded or Failed"
Jan 10 05:09:04.187: INFO: Pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c": Phase="Pending", Reason="", readiness=false. Elapsed: 21.798445ms
Jan 10 05:09:06.191: INFO: Pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025420788s
Jan 10 05:09:08.192: INFO: Pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026755782s
STEP: Saw pod success 01/10/23 05:09:08.192
Jan 10 05:09:08.192: INFO: Pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c" satisfied condition "Succeeded or Failed"
Jan 10 05:09:08.195: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c container client-container: <nil>
STEP: delete the pod 01/10/23 05:09:08.201
Jan 10 05:09:08.221: INFO: Waiting for pod downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c to disappear
Jan 10 05:09:08.229: INFO: Pod downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 10 05:09:08.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-54" for this suite. 01/10/23 05:09:08.235
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":352,"skipped":6466,"failed":0}
------------------------------
• [4.139 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:09:04.1
    Jan 10 05:09:04.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename projected 01/10/23 05:09:04.101
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:04.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:04.146
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 01/10/23 05:09:04.153
    Jan 10 05:09:04.165: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c" in namespace "projected-54" to be "Succeeded or Failed"
    Jan 10 05:09:04.187: INFO: Pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c": Phase="Pending", Reason="", readiness=false. Elapsed: 21.798445ms
    Jan 10 05:09:06.191: INFO: Pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025420788s
    Jan 10 05:09:08.192: INFO: Pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026755782s
    STEP: Saw pod success 01/10/23 05:09:08.192
    Jan 10 05:09:08.192: INFO: Pod "downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c" satisfied condition "Succeeded or Failed"
    Jan 10 05:09:08.195: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c container client-container: <nil>
    STEP: delete the pod 01/10/23 05:09:08.201
    Jan 10 05:09:08.221: INFO: Waiting for pod downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c to disappear
    Jan 10 05:09:08.229: INFO: Pod downwardapi-volume-05fa6772-9423-484a-a373-d7da66b5cb1c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 10 05:09:08.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-54" for this suite. 01/10/23 05:09:08.235
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:09:08.241
Jan 10 05:09:08.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename downward-api 01/10/23 05:09:08.242
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:08.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:08.299
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 01/10/23 05:09:08.312
Jan 10 05:09:08.332: INFO: Waiting up to 5m0s for pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3" in namespace "downward-api-5415" to be "Succeeded or Failed"
Jan 10 05:09:08.347: INFO: Pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.271717ms
Jan 10 05:09:10.353: INFO: Pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020417244s
Jan 10 05:09:12.361: INFO: Pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028420169s
STEP: Saw pod success 01/10/23 05:09:12.361
Jan 10 05:09:12.361: INFO: Pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3" satisfied condition "Succeeded or Failed"
Jan 10 05:09:12.367: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3 container client-container: <nil>
STEP: delete the pod 01/10/23 05:09:12.379
Jan 10 05:09:12.396: INFO: Waiting for pod downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3 to disappear
Jan 10 05:09:12.409: INFO: Pod downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 10 05:09:12.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5415" for this suite. 01/10/23 05:09:12.414
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":353,"skipped":6484,"failed":0}
------------------------------
• [4.187 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:09:08.241
    Jan 10 05:09:08.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename downward-api 01/10/23 05:09:08.242
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:08.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:08.299
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 01/10/23 05:09:08.312
    Jan 10 05:09:08.332: INFO: Waiting up to 5m0s for pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3" in namespace "downward-api-5415" to be "Succeeded or Failed"
    Jan 10 05:09:08.347: INFO: Pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.271717ms
    Jan 10 05:09:10.353: INFO: Pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020417244s
    Jan 10 05:09:12.361: INFO: Pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028420169s
    STEP: Saw pod success 01/10/23 05:09:12.361
    Jan 10 05:09:12.361: INFO: Pod "downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3" satisfied condition "Succeeded or Failed"
    Jan 10 05:09:12.367: INFO: Trying to get logs from node cncf-wk2 pod downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3 container client-container: <nil>
    STEP: delete the pod 01/10/23 05:09:12.379
    Jan 10 05:09:12.396: INFO: Waiting for pod downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3 to disappear
    Jan 10 05:09:12.409: INFO: Pod downwardapi-volume-834ece66-4bcf-4358-8ca8-02f8db36e1a3 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 10 05:09:12.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5415" for this suite. 01/10/23 05:09:12.414
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:09:12.431
Jan 10 05:09:12.431: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename statefulset 01/10/23 05:09:12.432
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:12.467
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:12.48
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8138 01/10/23 05:09:12.485
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-8138 01/10/23 05:09:12.511
Jan 10 05:09:12.577: INFO: Found 0 stateful pods, waiting for 1
Jan 10 05:09:22.581: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 01/10/23 05:09:22.585
STEP: Getting /status 01/10/23 05:09:22.591
Jan 10 05:09:22.595: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 01/10/23 05:09:22.595
Jan 10 05:09:22.604: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 01/10/23 05:09:22.605
Jan 10 05:09:22.607: INFO: Observed &StatefulSet event: ADDED
Jan 10 05:09:22.607: INFO: Found Statefulset ss in namespace statefulset-8138 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jan 10 05:09:22.607: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 01/10/23 05:09:22.607
Jan 10 05:09:22.607: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jan 10 05:09:22.614: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 01/10/23 05:09:22.615
Jan 10 05:09:22.617: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 10 05:09:22.618: INFO: Deleting all statefulset in ns statefulset-8138
Jan 10 05:09:22.620: INFO: Scaling statefulset ss to 0
Jan 10 05:09:32.651: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 05:09:32.660: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 10 05:09:32.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8138" for this suite. 01/10/23 05:09:32.707
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":354,"skipped":6500,"failed":0}
------------------------------
• [SLOW TEST] [20.293 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:09:12.431
    Jan 10 05:09:12.431: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename statefulset 01/10/23 05:09:12.432
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:12.467
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:12.48
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8138 01/10/23 05:09:12.485
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-8138 01/10/23 05:09:12.511
    Jan 10 05:09:12.577: INFO: Found 0 stateful pods, waiting for 1
    Jan 10 05:09:22.581: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 01/10/23 05:09:22.585
    STEP: Getting /status 01/10/23 05:09:22.591
    Jan 10 05:09:22.595: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 01/10/23 05:09:22.595
    Jan 10 05:09:22.604: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 01/10/23 05:09:22.605
    Jan 10 05:09:22.607: INFO: Observed &StatefulSet event: ADDED
    Jan 10 05:09:22.607: INFO: Found Statefulset ss in namespace statefulset-8138 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jan 10 05:09:22.607: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 01/10/23 05:09:22.607
    Jan 10 05:09:22.607: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jan 10 05:09:22.614: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 01/10/23 05:09:22.615
    Jan 10 05:09:22.617: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 10 05:09:22.618: INFO: Deleting all statefulset in ns statefulset-8138
    Jan 10 05:09:22.620: INFO: Scaling statefulset ss to 0
    Jan 10 05:09:32.651: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 10 05:09:32.660: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 10 05:09:32.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8138" for this suite. 01/10/23 05:09:32.707
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:09:32.725
Jan 10 05:09:32.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename emptydir 01/10/23 05:09:32.727
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:32.793
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:32.798
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 01/10/23 05:09:32.802
Jan 10 05:09:32.855: INFO: Waiting up to 5m0s for pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c" in namespace "emptydir-2396" to be "Succeeded or Failed"
Jan 10 05:09:32.860: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.663193ms
Jan 10 05:09:34.864: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009069975s
Jan 10 05:09:36.864: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009096003s
Jan 10 05:09:38.864: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009418843s
STEP: Saw pod success 01/10/23 05:09:38.864
Jan 10 05:09:38.864: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c" satisfied condition "Succeeded or Failed"
Jan 10 05:09:38.867: INFO: Trying to get logs from node cncf-wk2 pod pod-c38508a5-21a4-4685-b912-ab293f1e407c container test-container: <nil>
STEP: delete the pod 01/10/23 05:09:38.874
Jan 10 05:09:38.885: INFO: Waiting for pod pod-c38508a5-21a4-4685-b912-ab293f1e407c to disappear
Jan 10 05:09:38.889: INFO: Pod pod-c38508a5-21a4-4685-b912-ab293f1e407c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 10 05:09:38.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2396" for this suite. 01/10/23 05:09:38.905
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":355,"skipped":6512,"failed":0}
------------------------------
• [SLOW TEST] [6.187 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:09:32.725
    Jan 10 05:09:32.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename emptydir 01/10/23 05:09:32.727
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:32.793
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:32.798
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 01/10/23 05:09:32.802
    Jan 10 05:09:32.855: INFO: Waiting up to 5m0s for pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c" in namespace "emptydir-2396" to be "Succeeded or Failed"
    Jan 10 05:09:32.860: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.663193ms
    Jan 10 05:09:34.864: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009069975s
    Jan 10 05:09:36.864: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009096003s
    Jan 10 05:09:38.864: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009418843s
    STEP: Saw pod success 01/10/23 05:09:38.864
    Jan 10 05:09:38.864: INFO: Pod "pod-c38508a5-21a4-4685-b912-ab293f1e407c" satisfied condition "Succeeded or Failed"
    Jan 10 05:09:38.867: INFO: Trying to get logs from node cncf-wk2 pod pod-c38508a5-21a4-4685-b912-ab293f1e407c container test-container: <nil>
    STEP: delete the pod 01/10/23 05:09:38.874
    Jan 10 05:09:38.885: INFO: Waiting for pod pod-c38508a5-21a4-4685-b912-ab293f1e407c to disappear
    Jan 10 05:09:38.889: INFO: Pod pod-c38508a5-21a4-4685-b912-ab293f1e407c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 10 05:09:38.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2396" for this suite. 01/10/23 05:09:38.905
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:09:38.918
Jan 10 05:09:38.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename container-lifecycle-hook 01/10/23 05:09:38.92
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:38.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:38.972
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 01/10/23 05:09:38.992
Jan 10 05:09:39.007: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-740" to be "running and ready"
Jan 10 05:09:39.021: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 14.527824ms
Jan 10 05:09:39.022: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:09:41.026: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.018790184s
Jan 10 05:09:41.026: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jan 10 05:09:41.026: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 01/10/23 05:09:41.028
Jan 10 05:09:41.032: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-740" to be "running and ready"
Jan 10 05:09:41.043: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.462021ms
Jan 10 05:09:41.043: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 10 05:09:43.047: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.015223935s
Jan 10 05:09:43.047: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Jan 10 05:09:43.047: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 01/10/23 05:09:43.052
STEP: delete the pod with lifecycle hook 01/10/23 05:09:43.072
Jan 10 05:09:43.079: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 10 05:09:43.091: INFO: Pod pod-with-poststart-http-hook still exists
Jan 10 05:09:45.099: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 10 05:09:45.102: INFO: Pod pod-with-poststart-http-hook still exists
Jan 10 05:09:47.098: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 10 05:09:47.102: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jan 10 05:09:47.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-740" for this suite. 01/10/23 05:09:47.106
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":356,"skipped":6527,"failed":0}
------------------------------
• [SLOW TEST] [8.195 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:09:38.918
    Jan 10 05:09:38.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename container-lifecycle-hook 01/10/23 05:09:38.92
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:38.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:38.972
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 01/10/23 05:09:38.992
    Jan 10 05:09:39.007: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-740" to be "running and ready"
    Jan 10 05:09:39.021: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 14.527824ms
    Jan 10 05:09:39.022: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:09:41.026: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.018790184s
    Jan 10 05:09:41.026: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jan 10 05:09:41.026: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 01/10/23 05:09:41.028
    Jan 10 05:09:41.032: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-740" to be "running and ready"
    Jan 10 05:09:41.043: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.462021ms
    Jan 10 05:09:41.043: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 10 05:09:43.047: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.015223935s
    Jan 10 05:09:43.047: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Jan 10 05:09:43.047: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 01/10/23 05:09:43.052
    STEP: delete the pod with lifecycle hook 01/10/23 05:09:43.072
    Jan 10 05:09:43.079: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jan 10 05:09:43.091: INFO: Pod pod-with-poststart-http-hook still exists
    Jan 10 05:09:45.099: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jan 10 05:09:45.102: INFO: Pod pod-with-poststart-http-hook still exists
    Jan 10 05:09:47.098: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jan 10 05:09:47.102: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jan 10 05:09:47.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-740" for this suite. 01/10/23 05:09:47.106
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:09:47.112
Jan 10 05:09:47.112: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename webhook 01/10/23 05:09:47.113
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:47.135
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:47.144
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/10/23 05:09:47.174
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:09:47.775
STEP: Deploying the webhook pod 01/10/23 05:09:47.781
STEP: Wait for the deployment to be ready 01/10/23 05:09:47.794
Jan 10 05:09:47.803: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jan 10 05:09:49.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 5, 9, 47, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 5, 9, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 5, 9, 47, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 5, 9, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/10/23 05:09:51.814
STEP: Verifying the service has paired with the endpoint 01/10/23 05:09:51.828
Jan 10 05:09:52.831: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 01/10/23 05:09:52.834
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 01/10/23 05:09:52.848
STEP: Creating a dummy validating-webhook-configuration object 01/10/23 05:09:52.873
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 01/10/23 05:09:52.888
STEP: Creating a dummy mutating-webhook-configuration object 01/10/23 05:09:52.893
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 01/10/23 05:09:52.904
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 10 05:09:52.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2405" for this suite. 01/10/23 05:09:52.921
STEP: Destroying namespace "webhook-2405-markers" for this suite. 01/10/23 05:09:52.926
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":357,"skipped":6536,"failed":0}
------------------------------
• [SLOW TEST] [5.940 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:09:47.112
    Jan 10 05:09:47.112: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename webhook 01/10/23 05:09:47.113
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:47.135
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:47.144
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/10/23 05:09:47.174
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/10/23 05:09:47.775
    STEP: Deploying the webhook pod 01/10/23 05:09:47.781
    STEP: Wait for the deployment to be ready 01/10/23 05:09:47.794
    Jan 10 05:09:47.803: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Jan 10 05:09:49.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 10, 5, 9, 47, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 5, 9, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 10, 5, 9, 47, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 10, 5, 9, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/10/23 05:09:51.814
    STEP: Verifying the service has paired with the endpoint 01/10/23 05:09:51.828
    Jan 10 05:09:52.831: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 01/10/23 05:09:52.834
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 01/10/23 05:09:52.848
    STEP: Creating a dummy validating-webhook-configuration object 01/10/23 05:09:52.873
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 01/10/23 05:09:52.888
    STEP: Creating a dummy mutating-webhook-configuration object 01/10/23 05:09:52.893
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 01/10/23 05:09:52.904
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 10 05:09:52.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2405" for this suite. 01/10/23 05:09:52.921
    STEP: Destroying namespace "webhook-2405-markers" for this suite. 01/10/23 05:09:52.926
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:09:53.053
Jan 10 05:09:53.053: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename var-expansion 01/10/23 05:09:53.054
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:53.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:53.097
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 01/10/23 05:09:53.103
Jan 10 05:09:53.117: INFO: Waiting up to 5m0s for pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf" in namespace "var-expansion-3545" to be "Succeeded or Failed"
Jan 10 05:09:53.128: INFO: Pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.324319ms
Jan 10 05:09:55.131: INFO: Pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013213034s
Jan 10 05:09:57.132: INFO: Pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014650846s
STEP: Saw pod success 01/10/23 05:09:57.132
Jan 10 05:09:57.132: INFO: Pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf" satisfied condition "Succeeded or Failed"
Jan 10 05:09:57.137: INFO: Trying to get logs from node cncf-wk2 pod var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf container dapi-container: <nil>
STEP: delete the pod 01/10/23 05:09:57.154
Jan 10 05:09:57.165: INFO: Waiting for pod var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf to disappear
Jan 10 05:09:57.174: INFO: Pod var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 10 05:09:57.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3545" for this suite. 01/10/23 05:09:57.178
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":358,"skipped":6553,"failed":0}
------------------------------
• [4.137 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:09:53.053
    Jan 10 05:09:53.053: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename var-expansion 01/10/23 05:09:53.054
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:53.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:53.097
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 01/10/23 05:09:53.103
    Jan 10 05:09:53.117: INFO: Waiting up to 5m0s for pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf" in namespace "var-expansion-3545" to be "Succeeded or Failed"
    Jan 10 05:09:53.128: INFO: Pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.324319ms
    Jan 10 05:09:55.131: INFO: Pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013213034s
    Jan 10 05:09:57.132: INFO: Pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014650846s
    STEP: Saw pod success 01/10/23 05:09:57.132
    Jan 10 05:09:57.132: INFO: Pod "var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf" satisfied condition "Succeeded or Failed"
    Jan 10 05:09:57.137: INFO: Trying to get logs from node cncf-wk2 pod var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf container dapi-container: <nil>
    STEP: delete the pod 01/10/23 05:09:57.154
    Jan 10 05:09:57.165: INFO: Waiting for pod var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf to disappear
    Jan 10 05:09:57.174: INFO: Pod var-expansion-6890c3f1-5e60-4d86-a9cb-95307dfedcbf no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 10 05:09:57.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3545" for this suite. 01/10/23 05:09:57.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:09:57.197
Jan 10 05:09:57.197: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename resourcequota 01/10/23 05:09:57.198
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:57.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:57.265
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 01/10/23 05:09:57.293
STEP: Ensuring ResourceQuota status is calculated 01/10/23 05:09:57.302
STEP: Creating a ResourceQuota with not terminating scope 01/10/23 05:09:59.307
STEP: Ensuring ResourceQuota status is calculated 01/10/23 05:09:59.312
STEP: Creating a long running pod 01/10/23 05:10:01.317
STEP: Ensuring resource quota with not terminating scope captures the pod usage 01/10/23 05:10:01.354
STEP: Ensuring resource quota with terminating scope ignored the pod usage 01/10/23 05:10:03.359
STEP: Deleting the pod 01/10/23 05:10:05.364
STEP: Ensuring resource quota status released the pod usage 01/10/23 05:10:05.381
STEP: Creating a terminating pod 01/10/23 05:10:07.384
STEP: Ensuring resource quota with terminating scope captures the pod usage 01/10/23 05:10:07.395
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 01/10/23 05:10:09.399
STEP: Deleting the pod 01/10/23 05:10:11.402
STEP: Ensuring resource quota status released the pod usage 01/10/23 05:10:11.42
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 10 05:10:13.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2241" for this suite. 01/10/23 05:10:13.427
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":359,"skipped":6584,"failed":0}
------------------------------
• [SLOW TEST] [16.234 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:09:57.197
    Jan 10 05:09:57.197: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename resourcequota 01/10/23 05:09:57.198
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:09:57.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:09:57.265
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 01/10/23 05:09:57.293
    STEP: Ensuring ResourceQuota status is calculated 01/10/23 05:09:57.302
    STEP: Creating a ResourceQuota with not terminating scope 01/10/23 05:09:59.307
    STEP: Ensuring ResourceQuota status is calculated 01/10/23 05:09:59.312
    STEP: Creating a long running pod 01/10/23 05:10:01.317
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 01/10/23 05:10:01.354
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 01/10/23 05:10:03.359
    STEP: Deleting the pod 01/10/23 05:10:05.364
    STEP: Ensuring resource quota status released the pod usage 01/10/23 05:10:05.381
    STEP: Creating a terminating pod 01/10/23 05:10:07.384
    STEP: Ensuring resource quota with terminating scope captures the pod usage 01/10/23 05:10:07.395
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 01/10/23 05:10:09.399
    STEP: Deleting the pod 01/10/23 05:10:11.402
    STEP: Ensuring resource quota status released the pod usage 01/10/23 05:10:11.42
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 10 05:10:13.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2241" for this suite. 01/10/23 05:10:13.427
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:10:13.434
Jan 10 05:10:13.435: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename init-container 01/10/23 05:10:13.435
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:10:13.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:10:13.476
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 01/10/23 05:10:13.484
Jan 10 05:10:13.484: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 10 05:10:17.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2042" for this suite. 01/10/23 05:10:17.644
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":360,"skipped":6618,"failed":0}
------------------------------
• [4.220 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:10:13.434
    Jan 10 05:10:13.435: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename init-container 01/10/23 05:10:13.435
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:10:13.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:10:13.476
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 01/10/23 05:10:13.484
    Jan 10 05:10:13.484: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 10 05:10:17.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2042" for this suite. 01/10/23 05:10:17.644
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:10:17.655
Jan 10 05:10:17.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename server-version 01/10/23 05:10:17.656
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:10:17.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:10:17.687
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 01/10/23 05:10:17.692
STEP: Confirm major version 01/10/23 05:10:17.698
Jan 10 05:10:17.699: INFO: Major version: 1
STEP: Confirm minor version 01/10/23 05:10:17.7
Jan 10 05:10:17.700: INFO: cleanMinorVersion: 25
Jan 10 05:10:17.700: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Jan 10 05:10:17.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-6078" for this suite. 01/10/23 05:10:17.708
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":361,"skipped":6635,"failed":0}
------------------------------
• [0.059 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:10:17.655
    Jan 10 05:10:17.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename server-version 01/10/23 05:10:17.656
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:10:17.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:10:17.687
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 01/10/23 05:10:17.692
    STEP: Confirm major version 01/10/23 05:10:17.698
    Jan 10 05:10:17.699: INFO: Major version: 1
    STEP: Confirm minor version 01/10/23 05:10:17.7
    Jan 10 05:10:17.700: INFO: cleanMinorVersion: 25
    Jan 10 05:10:17.700: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Jan 10 05:10:17.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-6078" for this suite. 01/10/23 05:10:17.708
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/10/23 05:10:17.721
Jan 10 05:10:17.721: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
STEP: Building a namespace api object, basename subpath 01/10/23 05:10:17.722
STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:10:17.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:10:17.755
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/10/23 05:10:17.759
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-sqtn 01/10/23 05:10:17.773
STEP: Creating a pod to test atomic-volume-subpath 01/10/23 05:10:17.773
Jan 10 05:10:17.783: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sqtn" in namespace "subpath-13" to be "Succeeded or Failed"
Jan 10 05:10:17.798: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Pending", Reason="", readiness=false. Elapsed: 14.881484ms
Jan 10 05:10:19.801: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.018686738s
Jan 10 05:10:21.805: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 4.022751645s
Jan 10 05:10:23.801: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 6.018339505s
Jan 10 05:10:25.802: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 8.018983558s
Jan 10 05:10:27.801: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 10.018288731s
Jan 10 05:10:29.800: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 12.017730706s
Jan 10 05:10:31.802: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 14.019210906s
Jan 10 05:10:33.802: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 16.018980958s
Jan 10 05:10:35.804: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 18.021662729s
Jan 10 05:10:37.800: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 20.017610559s
Jan 10 05:10:39.800: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=false. Elapsed: 22.017786676s
Jan 10 05:10:41.801: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.01832544s
STEP: Saw pod success 01/10/23 05:10:41.801
Jan 10 05:10:41.801: INFO: Pod "pod-subpath-test-configmap-sqtn" satisfied condition "Succeeded or Failed"
Jan 10 05:10:41.804: INFO: Trying to get logs from node cncf-wk2 pod pod-subpath-test-configmap-sqtn container test-container-subpath-configmap-sqtn: <nil>
STEP: delete the pod 01/10/23 05:10:41.81
Jan 10 05:10:41.818: INFO: Waiting for pod pod-subpath-test-configmap-sqtn to disappear
Jan 10 05:10:41.825: INFO: Pod pod-subpath-test-configmap-sqtn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-sqtn 01/10/23 05:10:41.826
Jan 10 05:10:41.826: INFO: Deleting pod "pod-subpath-test-configmap-sqtn" in namespace "subpath-13"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 10 05:10:41.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-13" for this suite. 01/10/23 05:10:41.833
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":362,"skipped":6681,"failed":0}
------------------------------
• [SLOW TEST] [24.116 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/10/23 05:10:17.721
    Jan 10 05:10:17.721: INFO: >>> kubeConfig: /tmp/kubeconfig-1442525850
    STEP: Building a namespace api object, basename subpath 01/10/23 05:10:17.722
    STEP: Waiting for a default service account to be provisioned in namespace 01/10/23 05:10:17.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/10/23 05:10:17.755
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/10/23 05:10:17.759
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-sqtn 01/10/23 05:10:17.773
    STEP: Creating a pod to test atomic-volume-subpath 01/10/23 05:10:17.773
    Jan 10 05:10:17.783: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sqtn" in namespace "subpath-13" to be "Succeeded or Failed"
    Jan 10 05:10:17.798: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Pending", Reason="", readiness=false. Elapsed: 14.881484ms
    Jan 10 05:10:19.801: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.018686738s
    Jan 10 05:10:21.805: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 4.022751645s
    Jan 10 05:10:23.801: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 6.018339505s
    Jan 10 05:10:25.802: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 8.018983558s
    Jan 10 05:10:27.801: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 10.018288731s
    Jan 10 05:10:29.800: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 12.017730706s
    Jan 10 05:10:31.802: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 14.019210906s
    Jan 10 05:10:33.802: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 16.018980958s
    Jan 10 05:10:35.804: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 18.021662729s
    Jan 10 05:10:37.800: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=true. Elapsed: 20.017610559s
    Jan 10 05:10:39.800: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Running", Reason="", readiness=false. Elapsed: 22.017786676s
    Jan 10 05:10:41.801: INFO: Pod "pod-subpath-test-configmap-sqtn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.01832544s
    STEP: Saw pod success 01/10/23 05:10:41.801
    Jan 10 05:10:41.801: INFO: Pod "pod-subpath-test-configmap-sqtn" satisfied condition "Succeeded or Failed"
    Jan 10 05:10:41.804: INFO: Trying to get logs from node cncf-wk2 pod pod-subpath-test-configmap-sqtn container test-container-subpath-configmap-sqtn: <nil>
    STEP: delete the pod 01/10/23 05:10:41.81
    Jan 10 05:10:41.818: INFO: Waiting for pod pod-subpath-test-configmap-sqtn to disappear
    Jan 10 05:10:41.825: INFO: Pod pod-subpath-test-configmap-sqtn no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-sqtn 01/10/23 05:10:41.826
    Jan 10 05:10:41.826: INFO: Deleting pod "pod-subpath-test-configmap-sqtn" in namespace "subpath-13"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 10 05:10:41.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-13" for this suite. 01/10/23 05:10:41.833
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6704,"failed":0}
Jan 10 05:10:41.849: INFO: Running AfterSuite actions on all nodes
Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Jan 10 05:10:41.849: INFO: Running AfterSuite actions on node 1
Jan 10 05:10:41.849: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Jan 10 05:10:41.849: INFO: Running AfterSuite actions on all nodes
    Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Jan 10 05:10:41.849: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Jan 10 05:10:41.849: INFO: Running AfterSuite actions on node 1
    Jan 10 05:10:41.849: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.148 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7066 Specs in 5690.258 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6704 Skipped
PASS

Ginkgo ran 1 suite in 1h34m50.72574981s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

